HloModule pmap__multi_device_update_fn__2.16072, input_output_alias={ {0}: (0, {}, may-alias), {1}: (1, {}, may-alias), {2}: (2, {}, may-alias), {3}: (3, {}, may-alias), {4}: (4, {}, may-alias), {5}: (5, {}, may-alias), {6}: (6, {}, may-alias), {7}: (7, {}, may-alias), {8}: (8, {}, may-alias), {9}: (9, {}, may-alias), {10}: (10, {}, may-alias), {11}: (11, {}, may-alias), {12}: (12, {}, may-alias), {13}: (13, {}, may-alias), {14}: (14, {}, may-alias), {15}: (15, {}, may-alias), {16}: (16, {}, may-alias), {17}: (17, {}, may-alias), {18}: (18, {}, may-alias), {19}: (19, {}, may-alias), {20}: (20, {}, may-alias), {21}: (21, {}, may-alias), {22}: (22, {}, may-alias), {23}: (23, {}, may-alias), {24}: (24, {}, may-alias), {25}: (25, {}, may-alias), {26}: (26, {}, may-alias), {27}: (27, {}, may-alias), {28}: (28, {}, may-alias), {29}: (29, {}, may-alias), {30}: (30, {}, may-alias), {31}: (31, {}, may-alias), {32}: (32, {}, may-alias), {33}: (33, {}, may-alias), {34}: (34, {}, may-alias), {35}: (35, {}, may-alias), {36}: (36, {}, may-alias), {37}: (37, {}, may-alias), {38}: (38, {}, may-alias), {39}: (39, {}, may-alias), {40}: (40, {}, may-alias), {41}: (41, {}, may-alias), {42}: (42, {}, may-alias), {43}: (43, {}, may-alias), {44}: (44, {}, may-alias), {45}: (45, {}, may-alias), {46}: (46, {}, may-alias), {47}: (47, {}, may-alias), {48}: (48, {}, may-alias), {49}: (49, {}, may-alias), {50}: (50, {}, may-alias), {51}: (51, {}, may-alias), {52}: (52, {}, may-alias), {53}: (53, {}, may-alias), {54}: (54, {}, may-alias), {55}: (55, {}, may-alias), {56}: (56, {}, may-alias), {57}: (57, {}, may-alias), {58}: (58, {}, may-alias), {59}: (59, {}, may-alias), {60}: (60, {}, may-alias), {61}: (61, {}, may-alias), {62}: (62, {}, may-alias), {63}: (63, {}, may-alias), {64}: (64, {}, may-alias), {65}: (65, {}, may-alias), {66}: (66, {}, may-alias), {67}: (67, {}, may-alias), {68}: (68, {}, may-alias), {69}: (69, {}, may-alias), {70}: (70, {}, may-alias), {71}: (71, {}, may-alias), {72}: (72, {}, may-alias), {73}: (73, {}, may-alias), {74}: (74, {}, may-alias), {75}: (75, {}, may-alias) }

%primitive_computation_add__1.7672 (parameter.7673: f32[], parameter.7674: f32[]) -> f32[] {
  %parameter.7673 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.7674 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.7675 = f32[] add(f32[] %parameter.7673, f32[] %parameter.7674), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.12504 (parameter.12505: f32[], parameter.12506: f32[]) -> f32[] {
  %parameter.12505 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.12506 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.12507 = f32[] add(f32[] %parameter.12505, f32[] %parameter.12506), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.12509 (parameter.12510: f32[], parameter.12511: f32[]) -> f32[] {
  %parameter.12510 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.12511 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.12512 = f32[] add(f32[] %parameter.12510, f32[] %parameter.12511), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.12519 (parameter.12520: f32[], parameter.12521: f32[]) -> f32[] {
  %parameter.12520 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.12521 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.12522 = f32[] add(f32[] %parameter.12520, f32[] %parameter.12521), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.12529 (parameter.12530: f32[], parameter.12531: f32[]) -> f32[] {
  %parameter.12530 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.12531 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.12532 = f32[] add(f32[] %parameter.12530, f32[] %parameter.12531), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.12539 (parameter.12540: f32[], parameter.12541: f32[]) -> f32[] {
  %parameter.12540 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.12541 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.12542 = f32[] add(f32[] %parameter.12540, f32[] %parameter.12541), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.12554 (parameter.12555: f32[], parameter.12556: f32[]) -> f32[] {
  %parameter.12555 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.12556 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.12557 = f32[] add(f32[] %parameter.12555, f32[] %parameter.12556), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.12604 (parameter.12605: f32[], parameter.12606: f32[]) -> f32[] {
  %parameter.12605 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.12606 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.12607 = f32[] add(f32[] %parameter.12605, f32[] %parameter.12606), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.12614 (parameter.12615: f32[], parameter.12616: f32[]) -> f32[] {
  %parameter.12615 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.12616 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.12617 = f32[] add(f32[] %parameter.12615, f32[] %parameter.12616), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.12624 (parameter.12625: f32[], parameter.12626: f32[]) -> f32[] {
  %parameter.12625 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.12626 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.12627 = f32[] add(f32[] %parameter.12625, f32[] %parameter.12626), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.12634 (parameter.12635: f32[], parameter.12636: f32[]) -> f32[] {
  %parameter.12635 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.12636 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.12637 = f32[] add(f32[] %parameter.12635, f32[] %parameter.12636), metadata={op_type="add" op_name="add"}
}

%fused_computation (param_0: f32[64,16,1024], param_1.1880: f32[16,2048], param_2.1476: s32[]) -> f32[64,16,1024] {
  %param_0 = f32[64,16,1024]{2,1,0} parameter(0)
  %param_1.1880 = f32[16,2048]{1,0} parameter(1)
  %slice.818 = f32[16,1024]{1,0} slice(f32[16,2048]{1,0} %param_1.1880), slice={[0:16], [0:1024]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(16, 1024)\n                                                     start_indices=(0, 0)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %bitcast.407 = f32[1,16,1024]{2,1,0} bitcast(f32[16,1024]{1,0} %slice.818), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_11882 = s32[] constant(64), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_2.1476 = s32[] parameter(2)
  %subtract.339 = s32[] subtract(s32[] %constant_11882, s32[] %param_2.1476), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_11881 = s32[] constant(-1)
  %add.2129 = s32[] add(s32[] %subtract.339, s32[] %constant_11881), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_10592 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.1423 = pred[] compare(s32[] %add.2129, s32[] %constant_10592), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_11879 = s32[] constant(63)
  %add.2128 = s32[] add(s32[] %subtract.339, s32[] %constant_11879), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %select.1413 = s32[] select(pred[] %compare.1423, s32[] %add.2128, s32[] %add.2129), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.491 = f32[64,16,1024]{2,1,0} dynamic-update-slice(f32[64,16,1024]{2,1,0} %param_0, f32[1,16,1024]{2,1,0} %bitcast.407, s32[] %select.1413, s32[] %constant_10592, s32[] %constant_10592), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%primitive_computation_add__1.7759 (parameter.7760: f32[], parameter.7761: f32[]) -> f32[] {
  %parameter.7760 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.7761 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.7762 = f32[] add(f32[] %parameter.7760, f32[] %parameter.7761), metadata={op_type="add" op_name="add"}
}

%fused_computation.2 (param_0.3: f32[4096], param_1.7: f32[16,4096]) -> f32[4096] {
  %param_0.3 = f32[4096]{0} parameter(0)
  %param_1.7 = f32[16,4096]{1,0} parameter(1)
  %constant_10598 = f32[] constant(0), metadata={op_type="pad" op_name="pmap(_multi_device_update_fn)/scan/while/body/pad[ padding_config=((0, 0, 0), (3072, 0, 0)) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  %reduce.173 = f32[4096]{0} reduce(f32[16,4096]{1,0} %param_1.7, f32[] %constant_10598), dimensions={0}, to_apply=%primitive_computation_add__1.7759, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/scan/while/body/reduce_sum[ axes=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  ROOT %add.1761 = f32[4096]{0} add(f32[4096]{0} %param_0.3, f32[4096]{0} %reduce.173), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
}

%fused_computation.3 (param_0.1548: f32[64,16,1024], param_1.1882: f32[16,1024], param_2.1477: f32[64,16,1024], param_3.1246: f32[64,16,1024], param_4.519: f32[64,16,1024], param_5.260: f32[64,16,1024], param_6.205: f32[64,16,1024], param_7.213: f32[64,16,1024], param_8.156: s32[], param_9.93: f32[64,16,1024], param_10.109: f32[64,16,1024], param_11.136: f32[16,2048], param_12.98: f32[64,16,1024], param_13.71: f32[64,16,1024]) -> f32[16,4096] {
  %param_10.109 = f32[64,16,1024]{2,1,0} parameter(10)
  %constant_11826 = s32[] constant(64), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_8.156 = s32[] parameter(8)
  %subtract.345 = s32[] subtract(s32[] %constant_11826, s32[] %param_8.156), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_11824 = s32[] constant(-1)
  %add.2143 = s32[] add(s32[] %subtract.345, s32[] %constant_11824), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_10603 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.1430 = pred[] compare(s32[] %add.2143, s32[] %constant_10603), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_11822 = s32[] constant(63)
  %add.2142 = s32[] add(s32[] %subtract.345, s32[] %constant_11822), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %select.1420 = s32[] select(pred[] %compare.1430, s32[] %add.2142, s32[] %add.2143), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %dynamic-slice.416 = f32[1,16,1024]{2,1,0} dynamic-slice(f32[64,16,1024]{2,1,0} %param_10.109, s32[] %select.1420, s32[] %constant_10603, s32[] %constant_10603), dynamic_slice_sizes={1,16,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %bitcast.801 = f32[16,1024]{1,0} bitcast(f32[1,16,1024]{2,1,0} %dynamic-slice.416), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_12.98 = f32[64,16,1024]{2,1,0} parameter(12)
  %dynamic-slice.420 = f32[1,16,1024]{2,1,0} dynamic-slice(f32[64,16,1024]{2,1,0} %param_12.98, s32[] %select.1420, s32[] %constant_10603, s32[] %constant_10603), dynamic_slice_sizes={1,16,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %bitcast.805 = f32[16,1024]{1,0} bitcast(f32[1,16,1024]{2,1,0} %dynamic-slice.420), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_11.136 = f32[16,2048]{1,0} parameter(11)
  %slice.956 = f32[16,1024]{1,0} slice(f32[16,2048]{1,0} %param_11.136), slice={[0:16], [1024:2048]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(16, 2048)\n                                                     start_indices=(0, 1024)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=65}
  %add.2152 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %bitcast.805, f32[16,1024]{1,0} %slice.956), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %multiply.797 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %bitcast.801, f32[16,1024]{1,0} %add.2152), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  %param_7.213 = f32[64,16,1024]{2,1,0} parameter(7)
  %dynamic-slice.291 = f32[1,16,1024]{2,1,0} dynamic-slice(f32[64,16,1024]{2,1,0} %param_7.213, s32[] %select.1420, s32[] %constant_10603, s32[] %constant_10603), dynamic_slice_sizes={1,16,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %bitcast.414 = f32[16,1024]{1,0} bitcast(f32[1,16,1024]{2,1,0} %dynamic-slice.291), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.796 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %multiply.797, f32[16,1024]{1,0} %bitcast.414), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %param_13.71 = f32[64,16,1024]{2,1,0} parameter(13)
  %dynamic-slice.424 = f32[1,16,1024]{2,1,0} dynamic-slice(f32[64,16,1024]{2,1,0} %param_13.71, s32[] %select.1420, s32[] %constant_10603, s32[] %constant_10603), dynamic_slice_sizes={1,16,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %bitcast.809 = f32[16,1024]{1,0} bitcast(f32[1,16,1024]{2,1,0} %dynamic-slice.424), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.795 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %multiply.796, f32[16,1024]{1,0} %bitcast.809), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %constant_10600 = f32[] constant(0), metadata={op_type="pad" op_name="pmap(_multi_device_update_fn)/scan/while/body/pad[ padding_config=((0, 0, 0), (3072, 0, 0)) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  %pad.127 = f32[16,4096]{1,0} pad(f32[16,1024]{1,0} %multiply.795, f32[] %constant_10600), padding=0_0x3072_0, metadata={op_type="pad" op_name="pmap(_multi_device_update_fn)/scan/while/body/pad[ padding_config=((0, 0, 0), (3072, 0, 0)) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  %param_6.205 = f32[64,16,1024]{2,1,0} parameter(6)
  %dynamic-slice.290 = f32[1,16,1024]{2,1,0} dynamic-slice(f32[64,16,1024]{2,1,0} %param_6.205, s32[] %select.1420, s32[] %constant_10603, s32[] %constant_10603), dynamic_slice_sizes={1,16,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %bitcast.413 = f32[16,1024]{1,0} bitcast(f32[1,16,1024]{2,1,0} %dynamic-slice.290), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_1.1882 = f32[16,1024]{1,0} parameter(1)
  %multiply.794 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %bitcast.413, f32[16,1024]{1,0} %param_1.1882), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %param_5.260 = f32[64,16,1024]{2,1,0} parameter(5)
  %dynamic-slice.289 = f32[1,16,1024]{2,1,0} dynamic-slice(f32[64,16,1024]{2,1,0} %param_5.260, s32[] %select.1420, s32[] %constant_10603, s32[] %constant_10603), dynamic_slice_sizes={1,16,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %bitcast.412 = f32[16,1024]{1,0} bitcast(f32[1,16,1024]{2,1,0} %dynamic-slice.289), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.793 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %multiply.794, f32[16,1024]{1,0} %bitcast.412), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %param_4.519 = f32[64,16,1024]{2,1,0} parameter(4)
  %dynamic-slice.288 = f32[1,16,1024]{2,1,0} dynamic-slice(f32[64,16,1024]{2,1,0} %param_4.519, s32[] %select.1420, s32[] %constant_10603, s32[] %constant_10603), dynamic_slice_sizes={1,16,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %bitcast.411 = f32[16,1024]{1,0} bitcast(f32[1,16,1024]{2,1,0} %dynamic-slice.288), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.792 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %multiply.793, f32[16,1024]{1,0} %bitcast.411), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %add.1765 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %multiply.793, f32[16,1024]{1,0} %multiply.792), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %pad.126 = f32[16,4096]{1,0} pad(f32[16,1024]{1,0} %add.1765, f32[] %constant_10600), padding=0_0x1024_2048, metadata={op_type="pad" op_name="pmap(_multi_device_update_fn)/scan/while/body/pad[ padding_config=((0, 0, 0), (1024, 2048, 0)) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  %add.1764 = f32[16,4096]{1,0} add(f32[16,4096]{1,0} %pad.127, f32[16,4096]{1,0} %pad.126), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %multiply.791 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %param_1.1882, f32[16,1024]{1,0} %bitcast.411), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %param_3.1246 = f32[64,16,1024]{2,1,0} parameter(3)
  %dynamic-slice.287 = f32[1,16,1024]{2,1,0} dynamic-slice(f32[64,16,1024]{2,1,0} %param_3.1246, s32[] %select.1420, s32[] %constant_10603, s32[] %constant_10603), dynamic_slice_sizes={1,16,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %bitcast.410 = f32[16,1024]{1,0} bitcast(f32[1,16,1024]{2,1,0} %dynamic-slice.287), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.790 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %multiply.791, f32[16,1024]{1,0} %bitcast.410), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %multiply.789 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %multiply.790, f32[16,1024]{1,0} %bitcast.413), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %pad.125 = f32[16,4096]{1,0} pad(f32[16,1024]{1,0} %multiply.789, f32[] %constant_10600), padding=0_0x0_3072, metadata={op_type="pad" op_name="pmap(_multi_device_update_fn)/scan/while/body/pad[ padding_config=((0, 0, 0), (0, 3072, 0)) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  %add.1763 = f32[16,4096]{1,0} add(f32[16,4096]{1,0} %add.1764, f32[16,4096]{1,0} %pad.125), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %param_2.1477 = f32[64,16,1024]{2,1,0} parameter(2)
  %dynamic-slice.286 = f32[1,16,1024]{2,1,0} dynamic-slice(f32[64,16,1024]{2,1,0} %param_2.1477, s32[] %select.1420, s32[] %constant_10603, s32[] %constant_10603), dynamic_slice_sizes={1,16,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %bitcast.409 = f32[16,1024]{1,0} bitcast(f32[1,16,1024]{2,1,0} %dynamic-slice.286), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.788 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %bitcast.409, f32[16,1024]{1,0} %param_1.1882), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %param_0.1548 = f32[64,16,1024]{2,1,0} parameter(0)
  %dynamic-slice.285 = f32[1,16,1024]{2,1,0} dynamic-slice(f32[64,16,1024]{2,1,0} %param_0.1548, s32[] %select.1420, s32[] %constant_10603, s32[] %constant_10603), dynamic_slice_sizes={1,16,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %bitcast.408 = f32[16,1024]{1,0} bitcast(f32[1,16,1024]{2,1,0} %dynamic-slice.285), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.787 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %multiply.788, f32[16,1024]{1,0} %bitcast.408), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %param_9.93 = f32[64,16,1024]{2,1,0} parameter(9)
  %dynamic-slice.412 = f32[1,16,1024]{2,1,0} dynamic-slice(f32[64,16,1024]{2,1,0} %param_9.93, s32[] %select.1420, s32[] %constant_10603, s32[] %constant_10603), dynamic_slice_sizes={1,16,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %bitcast.797 = f32[16,1024]{1,0} bitcast(f32[1,16,1024]{2,1,0} %dynamic-slice.412), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.786 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %multiply.787, f32[16,1024]{1,0} %bitcast.797), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %pad.124 = f32[16,4096]{1,0} pad(f32[16,1024]{1,0} %multiply.786, f32[] %constant_10600), padding=0_0x2048_1024, metadata={op_type="pad" op_name="pmap(_multi_device_update_fn)/scan/while/body/pad[ padding_config=((0, 0, 0), (2048, 1024, 0)) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  ROOT %add.1762 = f32[16,4096]{1,0} add(f32[16,4096]{1,0} %add.1763, f32[16,4096]{1,0} %pad.124), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
}

%fused_computation.5 (param_0.1552: f32[64,16,1024], param_1.1893: f32[16,2048], param_2.1484: s32[], param_3.1255: f32[64,16,1024], param_4.528: f32[64,16,1024], param_5.270: f32[64,16,1024]) -> f32[16,1024] {
  %param_1.1893 = f32[16,2048]{1,0} parameter(1)
  %slice.820 = f32[16,1024]{1,0} slice(f32[16,2048]{1,0} %param_1.1893), slice={[0:16], [0:1024]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(16, 1024)\n                                                     start_indices=(0, 0)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=65}
  %param_4.528 = f32[64,16,1024]{2,1,0} parameter(4)
  %constant_11869 = s32[] constant(64), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_2.1484 = s32[] parameter(2)
  %subtract.351 = s32[] subtract(s32[] %constant_11869, s32[] %param_2.1484), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_11868 = s32[] constant(-1)
  %add.2161 = s32[] add(s32[] %subtract.351, s32[] %constant_11868), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_10606 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.1437 = pred[] compare(s32[] %add.2161, s32[] %constant_10606), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_11863 = s32[] constant(63)
  %add.2160 = s32[] add(s32[] %subtract.351, s32[] %constant_11863), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %select.1427 = s32[] select(pred[] %compare.1437, s32[] %add.2160, s32[] %add.2161), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %dynamic-slice.422 = f32[1,16,1024]{2,1,0} dynamic-slice(f32[64,16,1024]{2,1,0} %param_4.528, s32[] %select.1427, s32[] %constant_10606, s32[] %constant_10606), dynamic_slice_sizes={1,16,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %bitcast.807 = f32[16,1024]{1,0} bitcast(f32[1,16,1024]{2,1,0} %dynamic-slice.422), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %slice.958 = f32[16,1024]{1,0} slice(f32[16,2048]{1,0} %param_1.1893), slice={[0:16], [1024:2048]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(16, 2048)\n                                                     start_indices=(0, 1024)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=65}
  %add.2159 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %bitcast.807, f32[16,1024]{1,0} %slice.958), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %param_5.270 = f32[64,16,1024]{2,1,0} parameter(5)
  %dynamic-slice.426 = f32[1,16,1024]{2,1,0} dynamic-slice(f32[64,16,1024]{2,1,0} %param_5.270, s32[] %select.1427, s32[] %constant_10606, s32[] %constant_10606), dynamic_slice_sizes={1,16,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %bitcast.811 = f32[16,1024]{1,0} bitcast(f32[1,16,1024]{2,1,0} %dynamic-slice.426), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.800 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %add.2159, f32[16,1024]{1,0} %bitcast.811), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  %param_0.1552 = f32[64,16,1024]{2,1,0} parameter(0)
  %dynamic-slice.293 = f32[1,16,1024]{2,1,0} dynamic-slice(f32[64,16,1024]{2,1,0} %param_0.1552, s32[] %select.1427, s32[] %constant_10606, s32[] %constant_10606), dynamic_slice_sizes={1,16,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %bitcast.416 = f32[16,1024]{1,0} bitcast(f32[1,16,1024]{2,1,0} %dynamic-slice.293), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.799 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %multiply.800, f32[16,1024]{1,0} %bitcast.416), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  %add.1767 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %slice.820, f32[16,1024]{1,0} %multiply.799), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %param_3.1255 = f32[64,16,1024]{2,1,0} parameter(3)
  %dynamic-slice.418 = f32[1,16,1024]{2,1,0} dynamic-slice(f32[64,16,1024]{2,1,0} %param_3.1255, s32[] %select.1427, s32[] %constant_10606, s32[] %constant_10606), dynamic_slice_sizes={1,16,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %bitcast.803 = f32[16,1024]{1,0} bitcast(f32[1,16,1024]{2,1,0} %dynamic-slice.418), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.798 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %multiply.799, f32[16,1024]{1,0} %bitcast.803), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  ROOT %add.1766 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %add.1767, f32[16,1024]{1,0} %multiply.798), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
}

%fused_computation.9 (param_0.18: f32[64,16,2048], param_1.1864: s32[], param_2.2315: f32[16,1024], param_3.2072: f32[64,16,1024], param_4.1062: f32[16,2048]) -> (f32[16,2048], f32[16,2048]) {
  %param_0.18 = f32[64,16,2048]{2,1,0} parameter(0)
  %constant_11795 = s32[] constant(64), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_1.1864 = s32[] parameter(1)
  %subtract.325 = s32[] subtract(s32[] %constant_11795, s32[] %param_1.1864), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_11794 = s32[] constant(-1)
  %add.2097 = s32[] add(s32[] %subtract.325, s32[] %constant_11794), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_10614 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.1407 = pred[] compare(s32[] %add.2097, s32[] %constant_10614), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_11791 = s32[] constant(63)
  %add.2096 = s32[] add(s32[] %subtract.325, s32[] %constant_11791), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %select.1397 = s32[] select(pred[] %compare.1407, s32[] %add.2096, s32[] %add.2097), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %dynamic-slice.297 = f32[1,16,2048]{2,1,0} dynamic-slice(f32[64,16,2048]{2,1,0} %param_0.18, s32[] %select.1397, s32[] %constant_10614, s32[] %constant_10614), dynamic_slice_sizes={1,16,2048}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 16, 2048) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %bitcast.420 = f32[16,2048]{1,0} bitcast(f32[1,16,2048]{2,1,0} %dynamic-slice.297), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_4.1062 = f32[16,2048]{1,0} parameter(4)
  %slice.819.clone.1 = f32[16,1024]{1,0} slice(f32[16,2048]{1,0} %param_4.1062), slice={[0:16], [1024:2048]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(16, 2048)\n                                                     start_indices=(0, 1024)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %constant_10595_clone_1 = f32[] constant(0), metadata={op_type="pad" op_name="pmap(_multi_device_update_fn)/scan/while/body/pad[ padding_config=((0, 0, 0), (3072, 0, 0)) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  %pad.123.clone.1 = f32[16,2048]{1,0} pad(f32[16,1024]{1,0} %slice.819.clone.1, f32[] %constant_10595_clone_1), padding=0_0x1024_0, metadata={op_type="pad" op_name="pmap(_multi_device_update_fn)/scan/while/body/pad[ padding_config=((0, 0, 0), (1024, 0, 0)) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=54}
  %param_2.2315 = f32[16,1024]{1,0} parameter(2)
  %param_3.2072 = f32[64,16,1024]{2,1,0} parameter(3)
  %dynamic-slice.414.clone.1 = f32[1,16,1024]{2,1,0} dynamic-slice(f32[64,16,1024]{2,1,0} %param_3.2072, s32[] %select.1397, s32[] %constant_10614, s32[] %constant_10614), dynamic_slice_sizes={1,16,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %bitcast.799.clone.1 = f32[16,1024]{1,0} bitcast(f32[1,16,1024]{2,1,0} %dynamic-slice.414.clone.1), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.785.clone.1 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %param_2.2315, f32[16,1024]{1,0} %bitcast.799.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %pad.122.clone.1 = f32[16,2048]{1,0} pad(f32[16,1024]{1,0} %multiply.785.clone.1, f32[] %constant_10595_clone_1), padding=0_0x0_1024, metadata={op_type="pad" op_name="pmap(_multi_device_update_fn)/scan/while/body/pad[ padding_config=((0, 0, 0), (0, 1024, 0)) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=54}
  %add.1760.clone.1 = f32[16,2048]{1,0} add(f32[16,2048]{1,0} %pad.123.clone.1, f32[16,2048]{1,0} %pad.122.clone.1), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  ROOT %tuple.465 = (f32[16,2048]{1,0}, f32[16,2048]{1,0}) tuple(f32[16,2048]{1,0} %bitcast.420, f32[16,2048]{1,0} %add.1760.clone.1)
}

%body_computation__45.7767.clone.clone (parameter.63: (f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[64,16,2048], f32[64,16,1024], /*index=5*/f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], /*index=10*/f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[2048,4096], s32[], /*index=15*/f32[2048,4096], f32[4096], f32[16,2048], f32[64,16,1024])) -> (f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[64,16,2048], f32[64,16,1024], /*index=5*/f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], /*index=10*/f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[2048,4096], s32[], /*index=15*/f32[2048,4096], f32[4096], f32[16,2048], f32[64,16,1024]) {
  %parameter.63 = (f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) parameter(0)
  %get-tuple-element.6336 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.63), index=0
  %get-tuple-element.6337 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.63), index=1
  %get-tuple-element.6338 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.63), index=2
  %get-tuple-element.6339 = f32[64,16,2048]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.63), index=3
  %get-tuple-element.6340 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.63), index=4
  %get-tuple-element.6341 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.63), index=5
  %get-tuple-element.6342 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.63), index=6
  %get-tuple-element.6343 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.63), index=7
  %get-tuple-element.6344 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.63), index=8
  %get-tuple-element.6345 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.63), index=9
  %get-tuple-element.6346 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.63), index=10
  %get-tuple-element.6347 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.63), index=11
  %get-tuple-element.6349 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.63), index=12
  %get-tuple-element.6350 = f32[2048,4096]{1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.63), index=13
  %get-tuple-element.6354 = f32[16,2048]{1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.63), index=17
  %get-tuple-element.6351 = s32[] get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.63), index=14
  %fusion.5 = f32[16,1024]{1,0} fusion(f32[64,16,1024]{2,1,0} %get-tuple-element.6346, f32[16,2048]{1,0} %get-tuple-element.6354, s32[] %get-tuple-element.6351, f32[64,16,1024]{2,1,0} %get-tuple-element.6345, f32[64,16,1024]{2,1,0} %get-tuple-element.6336, /*index=5*/f32[64,16,1024]{2,1,0} %get-tuple-element.6347), kind=kLoop, calls=%fused_computation.5, metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %fusion.3 = f32[16,4096]{1,0} fusion(f32[64,16,1024]{2,1,0} %get-tuple-element.6340, f32[16,1024]{1,0} %fusion.5, f32[64,16,1024]{2,1,0} %get-tuple-element.6338, f32[64,16,1024]{2,1,0} %get-tuple-element.6342, f32[64,16,1024]{2,1,0} %get-tuple-element.6343, /*index=5*/f32[64,16,1024]{2,1,0} %get-tuple-element.6344, f32[64,16,1024]{2,1,0} %get-tuple-element.6341, f32[64,16,1024]{2,1,0} %get-tuple-element.6349, s32[] %get-tuple-element.6351, f32[64,16,1024]{2,1,0} %get-tuple-element.6337, /*index=10*/f32[64,16,1024]{2,1,0} %get-tuple-element.6345, f32[16,2048]{1,0} %get-tuple-element.6354, f32[64,16,1024]{2,1,0} %get-tuple-element.6336, f32[64,16,1024]{2,1,0} %get-tuple-element.6347), kind=kLoop, calls=%fused_computation.3, metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %custom-call.94 = f32[16,2048]{1,0} custom-call(f32[16,4096]{1,0} %fusion.3, f32[2048,4096]{1,0} %get-tuple-element.6350), custom_call_target="__cublas$gemm", metadata={op_type="dot_general" op_name="pmap(_multi_device_update_fn)/scan/while/body/dot_general[ dimension_numbers=(((1,), (1,)), ((), ()))\n                                                           precision=None\n                                                           preferred_element_type=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}, backend_config="{\"alpha_real\":1,\"alpha_imag\":0,\"beta\":0,\"dot_dimension_numbers\":{\"lhs_contracting_dimensions\":[\"1\"],\"rhs_contracting_dimensions\":[\"1\"],\"lhs_batch_dimensions\":[],\"rhs_batch_dimensions\":[]},\"batch_size\":\"1\",\"selected_algorithm\":\"-1\"}"
  %fusion.9 = (f32[16,2048]{1,0}, f32[16,2048]{1,0}) fusion(f32[64,16,2048]{2,1,0} %get-tuple-element.6339, s32[] %get-tuple-element.6351, f32[16,1024]{1,0} %fusion.5, f32[64,16,1024]{2,1,0} %get-tuple-element.6337, f32[16,2048]{1,0} %custom-call.94), kind=kLoop, calls=%fused_computation.9, control-predecessors={%fusion.5, %fusion.3}, metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.6355 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.63), index=18
  %fusion = f32[64,16,1024]{2,1,0} fusion(f32[64,16,1024]{2,1,0} %get-tuple-element.6355, f32[16,2048]{1,0} %custom-call.94, s32[] %get-tuple-element.6351), kind=kLoop, calls=%fused_computation, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_8369 = s32[] constant(1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.1210 = s32[] add(s32[] %get-tuple-element.6351, s32[] %constant_8369), control-predecessors={%fusion, %fusion.9, %fusion.5, %fusion.3}, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.5036 = f32[16,2048]{1,0} get-tuple-element((f32[16,2048]{1,0}, f32[16,2048]{1,0}) %fusion.9), index=0
  %get-tuple-element.6352 = f32[2048,4096]{1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.63), index=15
  %custom-call.93 = f32[2048,4096]{1,0} custom-call(f32[16,2048]{1,0} %get-tuple-element.5036, f32[16,4096]{1,0} %fusion.3, f32[2048,4096]{1,0} %get-tuple-element.6352), custom_call_target="__cublas$gemm", metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}, backend_config="{\"alpha_real\":1,\"alpha_imag\":0,\"beta\":1,\"dot_dimension_numbers\":{\"lhs_contracting_dimensions\":[\"0\"],\"rhs_contracting_dimensions\":[\"0\"],\"lhs_batch_dimensions\":[],\"rhs_batch_dimensions\":[]},\"batch_size\":\"1\",\"selected_algorithm\":\"4\"}"
  %get-tuple-element.6353 = f32[4096]{0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.63), index=16
  %fusion.2 = f32[4096]{0} fusion(f32[4096]{0} %get-tuple-element.6353, f32[16,4096]{1,0} %fusion.3), kind=kLoop, calls=%fused_computation.2, metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %get-tuple-element.5037 = f32[16,2048]{1,0} get-tuple-element((f32[16,2048]{1,0}, f32[16,2048]{1,0}) %fusion.9), index=1
  ROOT %tuple.814 = (f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) tuple(f32[64,16,1024]{2,1,0} %get-tuple-element.6336, f32[64,16,1024]{2,1,0} %get-tuple-element.6337, f32[64,16,1024]{2,1,0} %get-tuple-element.6338, f32[64,16,2048]{2,1,0} %get-tuple-element.6339, f32[64,16,1024]{2,1,0} %get-tuple-element.6340, /*index=5*/f32[64,16,1024]{2,1,0} %get-tuple-element.6341, f32[64,16,1024]{2,1,0} %get-tuple-element.6342, f32[64,16,1024]{2,1,0} %get-tuple-element.6343, f32[64,16,1024]{2,1,0} %get-tuple-element.6344, f32[64,16,1024]{2,1,0} %get-tuple-element.6345, /*index=10*/f32[64,16,1024]{2,1,0} %get-tuple-element.6346, f32[64,16,1024]{2,1,0} %get-tuple-element.6347, f32[64,16,1024]{2,1,0} %get-tuple-element.6349, f32[2048,4096]{1,0} %get-tuple-element.6350, s32[] %add.1210, /*index=15*/f32[2048,4096]{1,0} %custom-call.93, f32[4096]{0} %fusion.2, f32[16,2048]{1,0} %get-tuple-element.5037, f32[64,16,1024]{2,1,0} %fusion)
}

%cond_computation__45.8178.clone.clone (parameter.64: (f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[64,16,2048], f32[64,16,1024], /*index=5*/f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], /*index=10*/f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[2048,4096], s32[], /*index=15*/f32[2048,4096], f32[4096], f32[16,2048], f32[64,16,1024])) -> pred[] {
  %parameter.64 = (f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) parameter(0)
  %get-tuple-element.3306 = s32[] get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.64), index=14
  %constant_8378 = s32[] constant(64), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/cond/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %compare.1107 = pred[] compare(s32[] %get-tuple-element.3306, s32[] %constant_8378), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/cond/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.11 (param_0.23: f32[64,16,1024], param_1.1914: f32[16,2048], param_2.1516: s32[]) -> f32[64,16,1024] {
  %param_0.23 = f32[64,16,1024]{2,1,0} parameter(0)
  %param_1.1914 = f32[16,2048]{1,0} parameter(1)
  %slice.822 = f32[16,1024]{1,0} slice(f32[16,2048]{1,0} %param_1.1914), slice={[0:16], [0:1024]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(16, 1024)\n                                                     start_indices=(0, 0)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %bitcast.421 = f32[1,16,1024]{2,1,0} bitcast(f32[16,1024]{1,0} %slice.822), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_12085 = s32[] constant(64), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_2.1516 = s32[] parameter(2)
  %subtract.371 = s32[] subtract(s32[] %constant_12085, s32[] %param_2.1516), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_12083 = s32[] constant(-1)
  %add.2207 = s32[] add(s32[] %subtract.371, s32[] %constant_12083), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_10618 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.1460 = pred[] compare(s32[] %add.2207, s32[] %constant_10618), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_12081 = s32[] constant(63)
  %add.2206 = s32[] add(s32[] %subtract.371, s32[] %constant_12081), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %select.1450 = s32[] select(pred[] %compare.1460, s32[] %add.2206, s32[] %add.2207), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.492 = f32[64,16,1024]{2,1,0} dynamic-update-slice(f32[64,16,1024]{2,1,0} %param_0.23, f32[1,16,1024]{2,1,0} %bitcast.421, s32[] %select.1450, s32[] %constant_10618, s32[] %constant_10618), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%primitive_computation_add__1.8271 (parameter.8272: f32[], parameter.8273: f32[]) -> f32[] {
  %parameter.8272 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.8273 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.8274 = f32[] add(f32[] %parameter.8272, f32[] %parameter.8273), metadata={op_type="add" op_name="add"}
}

%fused_computation.13 (param_0.26: f32[4096], param_1.38: f32[16,4096]) -> f32[4096] {
  %param_0.26 = f32[4096]{0} parameter(0)
  %param_1.38 = f32[16,4096]{1,0} parameter(1)
  %constant_10623 = f32[] constant(0), metadata={op_type="pad" op_name="pmap(_multi_device_update_fn)/scan/while/body/pad[ padding_config=((0, 0, 0), (3072, 0, 0)) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  %reduce.174 = f32[4096]{0} reduce(f32[16,4096]{1,0} %param_1.38, f32[] %constant_10623), dimensions={0}, to_apply=%primitive_computation_add__1.8271, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/scan/while/body/reduce_sum[ axes=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  ROOT %add.1772 = f32[4096]{0} add(f32[4096]{0} %param_0.26, f32[4096]{0} %reduce.174), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
}

%fused_computation.14 (param_0.1566: f32[64,16,1024], param_1.1916: f32[16,1024], param_2.1517: f32[64,16,1024], param_3.1280: f32[64,16,1024], param_4.541: f32[64,16,1024], param_5.279: f32[64,16,1024], param_6.229: f32[64,16,1024], param_7.234: f32[64,16,1024], param_8.169: s32[], param_9.101: f32[64,16,1024], param_10.114: f32[64,16,1024], param_11.141: f32[16,2048], param_12.110: f32[64,16,1024], param_13.92: f32[64,16,1024]) -> f32[16,4096] {
  %param_10.114 = f32[64,16,1024]{2,1,0} parameter(10)
  %constant_12021 = s32[] constant(64), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_8.169 = s32[] parameter(8)
  %subtract.377 = s32[] subtract(s32[] %constant_12021, s32[] %param_8.169), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_12020 = s32[] constant(-1)
  %add.2221 = s32[] add(s32[] %subtract.377, s32[] %constant_12020), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_10629 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.1467 = pred[] compare(s32[] %add.2221, s32[] %constant_10629), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_12018 = s32[] constant(63)
  %add.2220 = s32[] add(s32[] %subtract.377, s32[] %constant_12018), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %select.1457 = s32[] select(pred[] %compare.1467, s32[] %add.2220, s32[] %add.2221), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %dynamic-slice.432 = f32[1,16,1024]{2,1,0} dynamic-slice(f32[64,16,1024]{2,1,0} %param_10.114, s32[] %select.1457, s32[] %constant_10629, s32[] %constant_10629), dynamic_slice_sizes={1,16,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %bitcast.817 = f32[16,1024]{1,0} bitcast(f32[1,16,1024]{2,1,0} %dynamic-slice.432), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_12.110 = f32[64,16,1024]{2,1,0} parameter(12)
  %dynamic-slice.436 = f32[1,16,1024]{2,1,0} dynamic-slice(f32[64,16,1024]{2,1,0} %param_12.110, s32[] %select.1457, s32[] %constant_10629, s32[] %constant_10629), dynamic_slice_sizes={1,16,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %bitcast.821 = f32[16,1024]{1,0} bitcast(f32[1,16,1024]{2,1,0} %dynamic-slice.436), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_11.141 = f32[16,2048]{1,0} parameter(11)
  %slice.960 = f32[16,1024]{1,0} slice(f32[16,2048]{1,0} %param_11.141), slice={[0:16], [1024:2048]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(16, 2048)\n                                                     start_indices=(0, 1024)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=65}
  %add.2230 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %bitcast.821, f32[16,1024]{1,0} %slice.960), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %multiply.813 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %bitcast.817, f32[16,1024]{1,0} %add.2230), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  %param_7.234 = f32[64,16,1024]{2,1,0} parameter(7)
  %dynamic-slice.304 = f32[1,16,1024]{2,1,0} dynamic-slice(f32[64,16,1024]{2,1,0} %param_7.234, s32[] %select.1457, s32[] %constant_10629, s32[] %constant_10629), dynamic_slice_sizes={1,16,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %bitcast.428 = f32[16,1024]{1,0} bitcast(f32[1,16,1024]{2,1,0} %dynamic-slice.304), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.812 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %multiply.813, f32[16,1024]{1,0} %bitcast.428), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %param_13.92 = f32[64,16,1024]{2,1,0} parameter(13)
  %dynamic-slice.440 = f32[1,16,1024]{2,1,0} dynamic-slice(f32[64,16,1024]{2,1,0} %param_13.92, s32[] %select.1457, s32[] %constant_10629, s32[] %constant_10629), dynamic_slice_sizes={1,16,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %bitcast.825 = f32[16,1024]{1,0} bitcast(f32[1,16,1024]{2,1,0} %dynamic-slice.440), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.811 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %multiply.812, f32[16,1024]{1,0} %bitcast.825), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %constant_10626 = f32[] constant(0), metadata={op_type="pad" op_name="pmap(_multi_device_update_fn)/scan/while/body/pad[ padding_config=((0, 0, 0), (3072, 0, 0)) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  %pad.133 = f32[16,4096]{1,0} pad(f32[16,1024]{1,0} %multiply.811, f32[] %constant_10626), padding=0_0x3072_0, metadata={op_type="pad" op_name="pmap(_multi_device_update_fn)/scan/while/body/pad[ padding_config=((0, 0, 0), (3072, 0, 0)) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  %param_6.229 = f32[64,16,1024]{2,1,0} parameter(6)
  %dynamic-slice.303 = f32[1,16,1024]{2,1,0} dynamic-slice(f32[64,16,1024]{2,1,0} %param_6.229, s32[] %select.1457, s32[] %constant_10629, s32[] %constant_10629), dynamic_slice_sizes={1,16,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %bitcast.427 = f32[16,1024]{1,0} bitcast(f32[1,16,1024]{2,1,0} %dynamic-slice.303), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_1.1916 = f32[16,1024]{1,0} parameter(1)
  %multiply.810 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %bitcast.427, f32[16,1024]{1,0} %param_1.1916), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %param_5.279 = f32[64,16,1024]{2,1,0} parameter(5)
  %dynamic-slice.302 = f32[1,16,1024]{2,1,0} dynamic-slice(f32[64,16,1024]{2,1,0} %param_5.279, s32[] %select.1457, s32[] %constant_10629, s32[] %constant_10629), dynamic_slice_sizes={1,16,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %bitcast.426 = f32[16,1024]{1,0} bitcast(f32[1,16,1024]{2,1,0} %dynamic-slice.302), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.809 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %multiply.810, f32[16,1024]{1,0} %bitcast.426), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %param_4.541 = f32[64,16,1024]{2,1,0} parameter(4)
  %dynamic-slice.301 = f32[1,16,1024]{2,1,0} dynamic-slice(f32[64,16,1024]{2,1,0} %param_4.541, s32[] %select.1457, s32[] %constant_10629, s32[] %constant_10629), dynamic_slice_sizes={1,16,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %bitcast.425 = f32[16,1024]{1,0} bitcast(f32[1,16,1024]{2,1,0} %dynamic-slice.301), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.808 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %multiply.809, f32[16,1024]{1,0} %bitcast.425), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %add.1776 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %multiply.809, f32[16,1024]{1,0} %multiply.808), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %pad.132 = f32[16,4096]{1,0} pad(f32[16,1024]{1,0} %add.1776, f32[] %constant_10626), padding=0_0x1024_2048, metadata={op_type="pad" op_name="pmap(_multi_device_update_fn)/scan/while/body/pad[ padding_config=((0, 0, 0), (1024, 2048, 0)) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  %add.1775 = f32[16,4096]{1,0} add(f32[16,4096]{1,0} %pad.133, f32[16,4096]{1,0} %pad.132), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %multiply.807 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %param_1.1916, f32[16,1024]{1,0} %bitcast.425), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %param_3.1280 = f32[64,16,1024]{2,1,0} parameter(3)
  %dynamic-slice.300 = f32[1,16,1024]{2,1,0} dynamic-slice(f32[64,16,1024]{2,1,0} %param_3.1280, s32[] %select.1457, s32[] %constant_10629, s32[] %constant_10629), dynamic_slice_sizes={1,16,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %bitcast.424 = f32[16,1024]{1,0} bitcast(f32[1,16,1024]{2,1,0} %dynamic-slice.300), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.806 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %multiply.807, f32[16,1024]{1,0} %bitcast.424), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %multiply.805 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %multiply.806, f32[16,1024]{1,0} %bitcast.427), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %pad.131 = f32[16,4096]{1,0} pad(f32[16,1024]{1,0} %multiply.805, f32[] %constant_10626), padding=0_0x0_3072, metadata={op_type="pad" op_name="pmap(_multi_device_update_fn)/scan/while/body/pad[ padding_config=((0, 0, 0), (0, 3072, 0)) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  %add.1774 = f32[16,4096]{1,0} add(f32[16,4096]{1,0} %add.1775, f32[16,4096]{1,0} %pad.131), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %param_2.1517 = f32[64,16,1024]{2,1,0} parameter(2)
  %dynamic-slice.299 = f32[1,16,1024]{2,1,0} dynamic-slice(f32[64,16,1024]{2,1,0} %param_2.1517, s32[] %select.1457, s32[] %constant_10629, s32[] %constant_10629), dynamic_slice_sizes={1,16,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %bitcast.423 = f32[16,1024]{1,0} bitcast(f32[1,16,1024]{2,1,0} %dynamic-slice.299), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.804 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %bitcast.423, f32[16,1024]{1,0} %param_1.1916), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %param_0.1566 = f32[64,16,1024]{2,1,0} parameter(0)
  %dynamic-slice.298 = f32[1,16,1024]{2,1,0} dynamic-slice(f32[64,16,1024]{2,1,0} %param_0.1566, s32[] %select.1457, s32[] %constant_10629, s32[] %constant_10629), dynamic_slice_sizes={1,16,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %bitcast.422 = f32[16,1024]{1,0} bitcast(f32[1,16,1024]{2,1,0} %dynamic-slice.298), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.803 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %multiply.804, f32[16,1024]{1,0} %bitcast.422), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %param_9.101 = f32[64,16,1024]{2,1,0} parameter(9)
  %dynamic-slice.428 = f32[1,16,1024]{2,1,0} dynamic-slice(f32[64,16,1024]{2,1,0} %param_9.101, s32[] %select.1457, s32[] %constant_10629, s32[] %constant_10629), dynamic_slice_sizes={1,16,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %bitcast.813 = f32[16,1024]{1,0} bitcast(f32[1,16,1024]{2,1,0} %dynamic-slice.428), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.802 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %multiply.803, f32[16,1024]{1,0} %bitcast.813), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %pad.130 = f32[16,4096]{1,0} pad(f32[16,1024]{1,0} %multiply.802, f32[] %constant_10626), padding=0_0x2048_1024, metadata={op_type="pad" op_name="pmap(_multi_device_update_fn)/scan/while/body/pad[ padding_config=((0, 0, 0), (2048, 1024, 0)) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  ROOT %add.1773 = f32[16,4096]{1,0} add(f32[16,4096]{1,0} %add.1774, f32[16,4096]{1,0} %pad.130), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
}

%fused_computation.16 (param_0.1570: f32[64,16,1024], param_1.1927: f32[16,2048], param_2.1524: s32[], param_3.1289: f32[64,16,1024], param_4.550: f32[64,16,1024], param_5.289: f32[64,16,1024]) -> f32[16,1024] {
  %param_1.1927 = f32[16,2048]{1,0} parameter(1)
  %slice.824 = f32[16,1024]{1,0} slice(f32[16,2048]{1,0} %param_1.1927), slice={[0:16], [0:1024]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(16, 1024)\n                                                     start_indices=(0, 0)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=65}
  %param_4.550 = f32[64,16,1024]{2,1,0} parameter(4)
  %constant_12065 = s32[] constant(64), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_2.1524 = s32[] parameter(2)
  %subtract.383 = s32[] subtract(s32[] %constant_12065, s32[] %param_2.1524), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_12064 = s32[] constant(-1)
  %add.2240 = s32[] add(s32[] %subtract.383, s32[] %constant_12064), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_10631 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.1474 = pred[] compare(s32[] %add.2240, s32[] %constant_10631), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_12060 = s32[] constant(63)
  %add.2238 = s32[] add(s32[] %subtract.383, s32[] %constant_12060), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %select.1464 = s32[] select(pred[] %compare.1474, s32[] %add.2238, s32[] %add.2240), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %dynamic-slice.438 = f32[1,16,1024]{2,1,0} dynamic-slice(f32[64,16,1024]{2,1,0} %param_4.550, s32[] %select.1464, s32[] %constant_10631, s32[] %constant_10631), dynamic_slice_sizes={1,16,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %bitcast.823 = f32[16,1024]{1,0} bitcast(f32[1,16,1024]{2,1,0} %dynamic-slice.438), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %slice.962 = f32[16,1024]{1,0} slice(f32[16,2048]{1,0} %param_1.1927), slice={[0:16], [1024:2048]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(16, 2048)\n                                                     start_indices=(0, 1024)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=65}
  %add.2237 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %bitcast.823, f32[16,1024]{1,0} %slice.962), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %param_5.289 = f32[64,16,1024]{2,1,0} parameter(5)
  %dynamic-slice.442 = f32[1,16,1024]{2,1,0} dynamic-slice(f32[64,16,1024]{2,1,0} %param_5.289, s32[] %select.1464, s32[] %constant_10631, s32[] %constant_10631), dynamic_slice_sizes={1,16,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %bitcast.827 = f32[16,1024]{1,0} bitcast(f32[1,16,1024]{2,1,0} %dynamic-slice.442), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.816 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %add.2237, f32[16,1024]{1,0} %bitcast.827), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  %param_0.1570 = f32[64,16,1024]{2,1,0} parameter(0)
  %dynamic-slice.306 = f32[1,16,1024]{2,1,0} dynamic-slice(f32[64,16,1024]{2,1,0} %param_0.1570, s32[] %select.1464, s32[] %constant_10631, s32[] %constant_10631), dynamic_slice_sizes={1,16,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %bitcast.430 = f32[16,1024]{1,0} bitcast(f32[1,16,1024]{2,1,0} %dynamic-slice.306), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.815 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %multiply.816, f32[16,1024]{1,0} %bitcast.430), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  %add.1778 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %slice.824, f32[16,1024]{1,0} %multiply.815), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %param_3.1289 = f32[64,16,1024]{2,1,0} parameter(3)
  %dynamic-slice.434 = f32[1,16,1024]{2,1,0} dynamic-slice(f32[64,16,1024]{2,1,0} %param_3.1289, s32[] %select.1464, s32[] %constant_10631, s32[] %constant_10631), dynamic_slice_sizes={1,16,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %bitcast.819 = f32[16,1024]{1,0} bitcast(f32[1,16,1024]{2,1,0} %dynamic-slice.434), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.814 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %multiply.815, f32[16,1024]{1,0} %bitcast.819), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  ROOT %add.1777 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %add.1778, f32[16,1024]{1,0} %multiply.814), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
}

%fused_computation.20 (param_0.41: f32[64,16,2048], param_1.1898: s32[], param_2.2318: f32[16,1024], param_3.2077: f32[64,16,1024], param_4.1067: f32[16,2048]) -> (f32[16,2048], f32[16,2048]) {
  %param_0.41 = f32[64,16,2048]{2,1,0} parameter(0)
  %constant_11984 = s32[] constant(64), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_1.1898 = s32[] parameter(1)
  %subtract.357 = s32[] subtract(s32[] %constant_11984, s32[] %param_1.1898), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_11983 = s32[] constant(-1)
  %add.2175 = s32[] add(s32[] %subtract.357, s32[] %constant_11983), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_10638 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.1444 = pred[] compare(s32[] %add.2175, s32[] %constant_10638), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_11981 = s32[] constant(63)
  %add.2174 = s32[] add(s32[] %subtract.357, s32[] %constant_11981), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %select.1434 = s32[] select(pred[] %compare.1444, s32[] %add.2174, s32[] %add.2175), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %dynamic-slice.310 = f32[1,16,2048]{2,1,0} dynamic-slice(f32[64,16,2048]{2,1,0} %param_0.41, s32[] %select.1434, s32[] %constant_10638, s32[] %constant_10638), dynamic_slice_sizes={1,16,2048}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 16, 2048) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %bitcast.434 = f32[16,2048]{1,0} bitcast(f32[1,16,2048]{2,1,0} %dynamic-slice.310), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_4.1067 = f32[16,2048]{1,0} parameter(4)
  %slice.823.clone.1 = f32[16,1024]{1,0} slice(f32[16,2048]{1,0} %param_4.1067), slice={[0:16], [1024:2048]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(16, 2048)\n                                                     start_indices=(0, 1024)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %constant_10621_clone_1 = f32[] constant(0), metadata={op_type="pad" op_name="pmap(_multi_device_update_fn)/scan/while/body/pad[ padding_config=((0, 0, 0), (3072, 0, 0)) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  %pad.129.clone.1 = f32[16,2048]{1,0} pad(f32[16,1024]{1,0} %slice.823.clone.1, f32[] %constant_10621_clone_1), padding=0_0x1024_0, metadata={op_type="pad" op_name="pmap(_multi_device_update_fn)/scan/while/body/pad[ padding_config=((0, 0, 0), (1024, 0, 0)) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=54}
  %param_2.2318 = f32[16,1024]{1,0} parameter(2)
  %param_3.2077 = f32[64,16,1024]{2,1,0} parameter(3)
  %dynamic-slice.430.clone.1 = f32[1,16,1024]{2,1,0} dynamic-slice(f32[64,16,1024]{2,1,0} %param_3.2077, s32[] %select.1434, s32[] %constant_10638, s32[] %constant_10638), dynamic_slice_sizes={1,16,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %bitcast.815.clone.1 = f32[16,1024]{1,0} bitcast(f32[1,16,1024]{2,1,0} %dynamic-slice.430.clone.1), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.801.clone.1 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %param_2.2318, f32[16,1024]{1,0} %bitcast.815.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %pad.128.clone.1 = f32[16,2048]{1,0} pad(f32[16,1024]{1,0} %multiply.801.clone.1, f32[] %constant_10621_clone_1), padding=0_0x0_1024, metadata={op_type="pad" op_name="pmap(_multi_device_update_fn)/scan/while/body/pad[ padding_config=((0, 0, 0), (0, 1024, 0)) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=54}
  %add.1771.clone.1 = f32[16,2048]{1,0} add(f32[16,2048]{1,0} %pad.129.clone.1, f32[16,2048]{1,0} %pad.128.clone.1), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  ROOT %tuple.466 = (f32[16,2048]{1,0}, f32[16,2048]{1,0}) tuple(f32[16,2048]{1,0} %bitcast.434, f32[16,2048]{1,0} %add.1771.clone.1)
}

%body_computation__46.8279.clone.clone (parameter.65: (f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[64,16,2048], f32[64,16,1024], /*index=5*/f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], /*index=10*/f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[2048,4096], s32[], /*index=15*/f32[2048,4096], f32[4096], f32[16,2048], f32[64,16,1024])) -> (f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[64,16,2048], f32[64,16,1024], /*index=5*/f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], /*index=10*/f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[2048,4096], s32[], /*index=15*/f32[2048,4096], f32[4096], f32[16,2048], f32[64,16,1024]) {
  %parameter.65 = (f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) parameter(0)
  %get-tuple-element.6395 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.65), index=0
  %get-tuple-element.6396 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.65), index=1
  %get-tuple-element.6397 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.65), index=2
  %get-tuple-element.6398 = f32[64,16,2048]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.65), index=3
  %get-tuple-element.6399 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.65), index=4
  %get-tuple-element.6400 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.65), index=5
  %get-tuple-element.6401 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.65), index=6
  %get-tuple-element.6402 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.65), index=7
  %get-tuple-element.6403 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.65), index=8
  %get-tuple-element.6404 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.65), index=9
  %get-tuple-element.6405 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.65), index=10
  %get-tuple-element.6406 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.65), index=11
  %get-tuple-element.6407 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.65), index=12
  %get-tuple-element.6408 = f32[2048,4096]{1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.65), index=13
  %get-tuple-element.6412 = f32[16,2048]{1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.65), index=17
  %get-tuple-element.6409 = s32[] get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.65), index=14
  %fusion.16 = f32[16,1024]{1,0} fusion(f32[64,16,1024]{2,1,0} %get-tuple-element.6405, f32[16,2048]{1,0} %get-tuple-element.6412, s32[] %get-tuple-element.6409, f32[64,16,1024]{2,1,0} %get-tuple-element.6404, f32[64,16,1024]{2,1,0} %get-tuple-element.6395, /*index=5*/f32[64,16,1024]{2,1,0} %get-tuple-element.6406), kind=kLoop, calls=%fused_computation.16, metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %fusion.14 = f32[16,4096]{1,0} fusion(f32[64,16,1024]{2,1,0} %get-tuple-element.6399, f32[16,1024]{1,0} %fusion.16, f32[64,16,1024]{2,1,0} %get-tuple-element.6397, f32[64,16,1024]{2,1,0} %get-tuple-element.6401, f32[64,16,1024]{2,1,0} %get-tuple-element.6402, /*index=5*/f32[64,16,1024]{2,1,0} %get-tuple-element.6403, f32[64,16,1024]{2,1,0} %get-tuple-element.6400, f32[64,16,1024]{2,1,0} %get-tuple-element.6407, s32[] %get-tuple-element.6409, f32[64,16,1024]{2,1,0} %get-tuple-element.6396, /*index=10*/f32[64,16,1024]{2,1,0} %get-tuple-element.6404, f32[16,2048]{1,0} %get-tuple-element.6412, f32[64,16,1024]{2,1,0} %get-tuple-element.6395, f32[64,16,1024]{2,1,0} %get-tuple-element.6406), kind=kLoop, calls=%fused_computation.14, metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %custom-call.97 = f32[16,2048]{1,0} custom-call(f32[16,4096]{1,0} %fusion.14, f32[2048,4096]{1,0} %get-tuple-element.6408), custom_call_target="__cublas$gemm", metadata={op_type="dot_general" op_name="pmap(_multi_device_update_fn)/scan/while/body/dot_general[ dimension_numbers=(((1,), (1,)), ((), ()))\n                                                           precision=None\n                                                           preferred_element_type=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}, backend_config="{\"alpha_real\":1,\"alpha_imag\":0,\"beta\":0,\"dot_dimension_numbers\":{\"lhs_contracting_dimensions\":[\"1\"],\"rhs_contracting_dimensions\":[\"1\"],\"lhs_batch_dimensions\":[],\"rhs_batch_dimensions\":[]},\"batch_size\":\"1\",\"selected_algorithm\":\"-1\"}"
  %fusion.20 = (f32[16,2048]{1,0}, f32[16,2048]{1,0}) fusion(f32[64,16,2048]{2,1,0} %get-tuple-element.6398, s32[] %get-tuple-element.6409, f32[16,1024]{1,0} %fusion.16, f32[64,16,1024]{2,1,0} %get-tuple-element.6396, f32[16,2048]{1,0} %custom-call.97), kind=kLoop, calls=%fused_computation.20, control-predecessors={%fusion.16, %fusion.14}, metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.6413 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.65), index=18
  %fusion.11 = f32[64,16,1024]{2,1,0} fusion(f32[64,16,1024]{2,1,0} %get-tuple-element.6413, f32[16,2048]{1,0} %custom-call.97, s32[] %get-tuple-element.6409), kind=kLoop, calls=%fused_computation.11, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_8516 = s32[] constant(1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.1255 = s32[] add(s32[] %get-tuple-element.6409, s32[] %constant_8516), control-predecessors={%fusion.11, %fusion.20, %fusion.16, %fusion.14}, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.5038 = f32[16,2048]{1,0} get-tuple-element((f32[16,2048]{1,0}, f32[16,2048]{1,0}) %fusion.20), index=0
  %get-tuple-element.6410 = f32[2048,4096]{1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.65), index=15
  %custom-call.96 = f32[2048,4096]{1,0} custom-call(f32[16,2048]{1,0} %get-tuple-element.5038, f32[16,4096]{1,0} %fusion.14, f32[2048,4096]{1,0} %get-tuple-element.6410), custom_call_target="__cublas$gemm", metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}, backend_config="{\"alpha_real\":1,\"alpha_imag\":0,\"beta\":1,\"dot_dimension_numbers\":{\"lhs_contracting_dimensions\":[\"0\"],\"rhs_contracting_dimensions\":[\"0\"],\"lhs_batch_dimensions\":[],\"rhs_batch_dimensions\":[]},\"batch_size\":\"1\",\"selected_algorithm\":\"4\"}"
  %get-tuple-element.6411 = f32[4096]{0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.65), index=16
  %fusion.13 = f32[4096]{0} fusion(f32[4096]{0} %get-tuple-element.6411, f32[16,4096]{1,0} %fusion.14), kind=kLoop, calls=%fused_computation.13, metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %get-tuple-element.5039 = f32[16,2048]{1,0} get-tuple-element((f32[16,2048]{1,0}, f32[16,2048]{1,0}) %fusion.20), index=1
  ROOT %tuple.817 = (f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) tuple(f32[64,16,1024]{2,1,0} %get-tuple-element.6395, f32[64,16,1024]{2,1,0} %get-tuple-element.6396, f32[64,16,1024]{2,1,0} %get-tuple-element.6397, f32[64,16,2048]{2,1,0} %get-tuple-element.6398, f32[64,16,1024]{2,1,0} %get-tuple-element.6399, /*index=5*/f32[64,16,1024]{2,1,0} %get-tuple-element.6400, f32[64,16,1024]{2,1,0} %get-tuple-element.6401, f32[64,16,1024]{2,1,0} %get-tuple-element.6402, f32[64,16,1024]{2,1,0} %get-tuple-element.6403, f32[64,16,1024]{2,1,0} %get-tuple-element.6404, /*index=10*/f32[64,16,1024]{2,1,0} %get-tuple-element.6405, f32[64,16,1024]{2,1,0} %get-tuple-element.6406, f32[64,16,1024]{2,1,0} %get-tuple-element.6407, f32[2048,4096]{1,0} %get-tuple-element.6408, s32[] %add.1255, /*index=15*/f32[2048,4096]{1,0} %custom-call.96, f32[4096]{0} %fusion.13, f32[16,2048]{1,0} %get-tuple-element.5039, f32[64,16,1024]{2,1,0} %fusion.11)
}

%cond_computation__46.8690.clone.clone (parameter.66: (f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[64,16,2048], f32[64,16,1024], /*index=5*/f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], /*index=10*/f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[2048,4096], s32[], /*index=15*/f32[2048,4096], f32[4096], f32[16,2048], f32[64,16,1024])) -> pred[] {
  %parameter.66 = (f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) parameter(0)
  %get-tuple-element.3375 = s32[] get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.66), index=14
  %constant_8522 = s32[] constant(64), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/cond/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %compare.1122 = pred[] compare(s32[] %get-tuple-element.3375, s32[] %constant_8522), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/cond/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.22 (param_0.46: f32[64,16,1024], param_1.1948: f32[16,2048], param_2.1556: s32[]) -> f32[64,16,1024] {
  %param_0.46 = f32[64,16,1024]{2,1,0} parameter(0)
  %param_1.1948 = f32[16,2048]{1,0} parameter(1)
  %slice.826 = f32[16,1024]{1,0} slice(f32[16,2048]{1,0} %param_1.1948), slice={[0:16], [0:1024]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(16, 1024)\n                                                     start_indices=(0, 0)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %bitcast.435 = f32[1,16,1024]{2,1,0} bitcast(f32[16,1024]{1,0} %slice.826), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_12384 = s32[] constant(64), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_2.1556 = s32[] parameter(2)
  %subtract.403 = s32[] subtract(s32[] %constant_12384, s32[] %param_2.1556), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_12382 = s32[] constant(-1)
  %add.2285 = s32[] add(s32[] %subtract.403, s32[] %constant_12382), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_10644 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.1497 = pred[] compare(s32[] %add.2285, s32[] %constant_10644), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_12379 = s32[] constant(63)
  %add.2284 = s32[] add(s32[] %subtract.403, s32[] %constant_12379), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %select.1487 = s32[] select(pred[] %compare.1497, s32[] %add.2284, s32[] %add.2285), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.493 = f32[64,16,1024]{2,1,0} dynamic-update-slice(f32[64,16,1024]{2,1,0} %param_0.46, f32[1,16,1024]{2,1,0} %bitcast.435, s32[] %select.1487, s32[] %constant_10644, s32[] %constant_10644), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%primitive_computation_add__1.8783 (parameter.8784: f32[], parameter.8785: f32[]) -> f32[] {
  %parameter.8784 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.8785 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.8786 = f32[] add(f32[] %parameter.8784, f32[] %parameter.8785), metadata={op_type="add" op_name="add"}
}

%fused_computation.24 (param_0.49: f32[4096], param_1.69: f32[16,4096]) -> f32[4096] {
  %param_0.49 = f32[4096]{0} parameter(0)
  %param_1.69 = f32[16,4096]{1,0} parameter(1)
  %constant_10649 = f32[] constant(0), metadata={op_type="pad" op_name="pmap(_multi_device_update_fn)/scan/while/body/pad[ padding_config=((0, 0, 0), (3072, 0, 0)) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  %reduce.175 = f32[4096]{0} reduce(f32[16,4096]{1,0} %param_1.69, f32[] %constant_10649), dimensions={0}, to_apply=%primitive_computation_add__1.8783, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/scan/while/body/reduce_sum[ axes=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  ROOT %add.1783 = f32[4096]{0} add(f32[4096]{0} %param_0.49, f32[4096]{0} %reduce.175), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
}

%fused_computation.25 (param_0.1584: f32[64,16,1024], param_1.1950: f32[16,1024], param_2.1557: f32[64,16,1024], param_3.1314: f32[64,16,1024], param_4.563: f32[64,16,1024], param_5.298: f32[64,16,1024], param_6.253: f32[64,16,1024], param_7.255: f32[64,16,1024], param_8.182: s32[], param_9.109: f32[64,16,1024], param_10.119: f32[64,16,1024], param_11.146: f32[16,2048], param_12.122: f32[64,16,1024], param_13.113: f32[64,16,1024]) -> f32[16,4096] {
  %param_10.119 = f32[64,16,1024]{2,1,0} parameter(10)
  %constant_12340 = s32[] constant(64), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_8.182 = s32[] parameter(8)
  %subtract.409 = s32[] subtract(s32[] %constant_12340, s32[] %param_8.182), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_12339 = s32[] constant(-1)
  %add.2297 = s32[] add(s32[] %subtract.409, s32[] %constant_12339), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_10654 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.1503 = pred[] compare(s32[] %add.2297, s32[] %constant_10654), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_12337 = s32[] constant(63)
  %add.2296 = s32[] add(s32[] %subtract.409, s32[] %constant_12337), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %select.1494 = s32[] select(pred[] %compare.1503, s32[] %add.2296, s32[] %add.2297), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %dynamic-slice.448 = f32[1,16,1024]{2,1,0} dynamic-slice(f32[64,16,1024]{2,1,0} %param_10.119, s32[] %select.1494, s32[] %constant_10654, s32[] %constant_10654), dynamic_slice_sizes={1,16,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %bitcast.833 = f32[16,1024]{1,0} bitcast(f32[1,16,1024]{2,1,0} %dynamic-slice.448), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_12.122 = f32[64,16,1024]{2,1,0} parameter(12)
  %dynamic-slice.452 = f32[1,16,1024]{2,1,0} dynamic-slice(f32[64,16,1024]{2,1,0} %param_12.122, s32[] %select.1494, s32[] %constant_10654, s32[] %constant_10654), dynamic_slice_sizes={1,16,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %bitcast.837 = f32[16,1024]{1,0} bitcast(f32[1,16,1024]{2,1,0} %dynamic-slice.452), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_11.146 = f32[16,2048]{1,0} parameter(11)
  %slice.964 = f32[16,1024]{1,0} slice(f32[16,2048]{1,0} %param_11.146), slice={[0:16], [1024:2048]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(16, 2048)\n                                                     start_indices=(0, 1024)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=65}
  %add.2305 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %bitcast.837, f32[16,1024]{1,0} %slice.964), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %multiply.829 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %bitcast.833, f32[16,1024]{1,0} %add.2305), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  %param_7.255 = f32[64,16,1024]{2,1,0} parameter(7)
  %dynamic-slice.317 = f32[1,16,1024]{2,1,0} dynamic-slice(f32[64,16,1024]{2,1,0} %param_7.255, s32[] %select.1494, s32[] %constant_10654, s32[] %constant_10654), dynamic_slice_sizes={1,16,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %bitcast.442 = f32[16,1024]{1,0} bitcast(f32[1,16,1024]{2,1,0} %dynamic-slice.317), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.828 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %multiply.829, f32[16,1024]{1,0} %bitcast.442), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %param_13.113 = f32[64,16,1024]{2,1,0} parameter(13)
  %dynamic-slice.456 = f32[1,16,1024]{2,1,0} dynamic-slice(f32[64,16,1024]{2,1,0} %param_13.113, s32[] %select.1494, s32[] %constant_10654, s32[] %constant_10654), dynamic_slice_sizes={1,16,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %bitcast.841 = f32[16,1024]{1,0} bitcast(f32[1,16,1024]{2,1,0} %dynamic-slice.456), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.827 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %multiply.828, f32[16,1024]{1,0} %bitcast.841), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %constant_10652 = f32[] constant(0), metadata={op_type="pad" op_name="pmap(_multi_device_update_fn)/scan/while/body/pad[ padding_config=((0, 0, 0), (3072, 0, 0)) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  %pad.139 = f32[16,4096]{1,0} pad(f32[16,1024]{1,0} %multiply.827, f32[] %constant_10652), padding=0_0x3072_0, metadata={op_type="pad" op_name="pmap(_multi_device_update_fn)/scan/while/body/pad[ padding_config=((0, 0, 0), (3072, 0, 0)) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  %param_6.253 = f32[64,16,1024]{2,1,0} parameter(6)
  %dynamic-slice.316 = f32[1,16,1024]{2,1,0} dynamic-slice(f32[64,16,1024]{2,1,0} %param_6.253, s32[] %select.1494, s32[] %constant_10654, s32[] %constant_10654), dynamic_slice_sizes={1,16,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %bitcast.441 = f32[16,1024]{1,0} bitcast(f32[1,16,1024]{2,1,0} %dynamic-slice.316), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_1.1950 = f32[16,1024]{1,0} parameter(1)
  %multiply.826 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %bitcast.441, f32[16,1024]{1,0} %param_1.1950), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %param_5.298 = f32[64,16,1024]{2,1,0} parameter(5)
  %dynamic-slice.315 = f32[1,16,1024]{2,1,0} dynamic-slice(f32[64,16,1024]{2,1,0} %param_5.298, s32[] %select.1494, s32[] %constant_10654, s32[] %constant_10654), dynamic_slice_sizes={1,16,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %bitcast.440 = f32[16,1024]{1,0} bitcast(f32[1,16,1024]{2,1,0} %dynamic-slice.315), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.825 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %multiply.826, f32[16,1024]{1,0} %bitcast.440), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %param_4.563 = f32[64,16,1024]{2,1,0} parameter(4)
  %dynamic-slice.314 = f32[1,16,1024]{2,1,0} dynamic-slice(f32[64,16,1024]{2,1,0} %param_4.563, s32[] %select.1494, s32[] %constant_10654, s32[] %constant_10654), dynamic_slice_sizes={1,16,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %bitcast.439 = f32[16,1024]{1,0} bitcast(f32[1,16,1024]{2,1,0} %dynamic-slice.314), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.824 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %multiply.825, f32[16,1024]{1,0} %bitcast.439), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %add.1787 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %multiply.825, f32[16,1024]{1,0} %multiply.824), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %pad.138 = f32[16,4096]{1,0} pad(f32[16,1024]{1,0} %add.1787, f32[] %constant_10652), padding=0_0x1024_2048, metadata={op_type="pad" op_name="pmap(_multi_device_update_fn)/scan/while/body/pad[ padding_config=((0, 0, 0), (1024, 2048, 0)) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  %add.1786 = f32[16,4096]{1,0} add(f32[16,4096]{1,0} %pad.139, f32[16,4096]{1,0} %pad.138), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %multiply.823 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %param_1.1950, f32[16,1024]{1,0} %bitcast.439), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %param_3.1314 = f32[64,16,1024]{2,1,0} parameter(3)
  %dynamic-slice.313 = f32[1,16,1024]{2,1,0} dynamic-slice(f32[64,16,1024]{2,1,0} %param_3.1314, s32[] %select.1494, s32[] %constant_10654, s32[] %constant_10654), dynamic_slice_sizes={1,16,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %bitcast.438 = f32[16,1024]{1,0} bitcast(f32[1,16,1024]{2,1,0} %dynamic-slice.313), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.822 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %multiply.823, f32[16,1024]{1,0} %bitcast.438), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %multiply.821 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %multiply.822, f32[16,1024]{1,0} %bitcast.441), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %pad.137 = f32[16,4096]{1,0} pad(f32[16,1024]{1,0} %multiply.821, f32[] %constant_10652), padding=0_0x0_3072, metadata={op_type="pad" op_name="pmap(_multi_device_update_fn)/scan/while/body/pad[ padding_config=((0, 0, 0), (0, 3072, 0)) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  %add.1785 = f32[16,4096]{1,0} add(f32[16,4096]{1,0} %add.1786, f32[16,4096]{1,0} %pad.137), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %param_2.1557 = f32[64,16,1024]{2,1,0} parameter(2)
  %dynamic-slice.312 = f32[1,16,1024]{2,1,0} dynamic-slice(f32[64,16,1024]{2,1,0} %param_2.1557, s32[] %select.1494, s32[] %constant_10654, s32[] %constant_10654), dynamic_slice_sizes={1,16,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %bitcast.437 = f32[16,1024]{1,0} bitcast(f32[1,16,1024]{2,1,0} %dynamic-slice.312), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.820 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %bitcast.437, f32[16,1024]{1,0} %param_1.1950), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %param_0.1584 = f32[64,16,1024]{2,1,0} parameter(0)
  %dynamic-slice.311 = f32[1,16,1024]{2,1,0} dynamic-slice(f32[64,16,1024]{2,1,0} %param_0.1584, s32[] %select.1494, s32[] %constant_10654, s32[] %constant_10654), dynamic_slice_sizes={1,16,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %bitcast.436 = f32[16,1024]{1,0} bitcast(f32[1,16,1024]{2,1,0} %dynamic-slice.311), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.819 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %multiply.820, f32[16,1024]{1,0} %bitcast.436), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %param_9.109 = f32[64,16,1024]{2,1,0} parameter(9)
  %dynamic-slice.444 = f32[1,16,1024]{2,1,0} dynamic-slice(f32[64,16,1024]{2,1,0} %param_9.109, s32[] %select.1494, s32[] %constant_10654, s32[] %constant_10654), dynamic_slice_sizes={1,16,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %bitcast.829 = f32[16,1024]{1,0} bitcast(f32[1,16,1024]{2,1,0} %dynamic-slice.444), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.818 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %multiply.819, f32[16,1024]{1,0} %bitcast.829), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %pad.136 = f32[16,4096]{1,0} pad(f32[16,1024]{1,0} %multiply.818, f32[] %constant_10652), padding=0_0x2048_1024, metadata={op_type="pad" op_name="pmap(_multi_device_update_fn)/scan/while/body/pad[ padding_config=((0, 0, 0), (2048, 1024, 0)) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  ROOT %add.1784 = f32[16,4096]{1,0} add(f32[16,4096]{1,0} %add.1785, f32[16,4096]{1,0} %pad.136), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
}

%fused_computation.27 (param_0.1588: f32[64,16,1024], param_1.1961: f32[16,2048], param_2.1564: s32[], param_3.1323: f32[64,16,1024], param_4.572: f32[64,16,1024], param_5.308: f32[64,16,1024]) -> f32[16,1024] {
  %param_1.1961 = f32[16,2048]{1,0} parameter(1)
  %slice.828 = f32[16,1024]{1,0} slice(f32[16,2048]{1,0} %param_1.1961), slice={[0:16], [0:1024]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(16, 1024)\n                                                     start_indices=(0, 0)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=65}
  %param_4.572 = f32[64,16,1024]{2,1,0} parameter(4)
  %constant_12373 = s32[] constant(64), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_2.1564 = s32[] parameter(2)
  %subtract.415 = s32[] subtract(s32[] %constant_12373, s32[] %param_2.1564), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_12371 = s32[] constant(-1)
  %add.2313 = s32[] add(s32[] %subtract.415, s32[] %constant_12371), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_10655 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.1511 = pred[] compare(s32[] %add.2313, s32[] %constant_10655), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_12368 = s32[] constant(63)
  %add.2312 = s32[] add(s32[] %subtract.415, s32[] %constant_12368), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %select.1501 = s32[] select(pred[] %compare.1511, s32[] %add.2312, s32[] %add.2313), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %dynamic-slice.454 = f32[1,16,1024]{2,1,0} dynamic-slice(f32[64,16,1024]{2,1,0} %param_4.572, s32[] %select.1501, s32[] %constant_10655, s32[] %constant_10655), dynamic_slice_sizes={1,16,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %bitcast.839 = f32[16,1024]{1,0} bitcast(f32[1,16,1024]{2,1,0} %dynamic-slice.454), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %slice.966 = f32[16,1024]{1,0} slice(f32[16,2048]{1,0} %param_1.1961), slice={[0:16], [1024:2048]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(16, 2048)\n                                                     start_indices=(0, 1024)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=65}
  %add.2311 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %bitcast.839, f32[16,1024]{1,0} %slice.966), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %param_5.308 = f32[64,16,1024]{2,1,0} parameter(5)
  %dynamic-slice.458 = f32[1,16,1024]{2,1,0} dynamic-slice(f32[64,16,1024]{2,1,0} %param_5.308, s32[] %select.1501, s32[] %constant_10655, s32[] %constant_10655), dynamic_slice_sizes={1,16,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %bitcast.843 = f32[16,1024]{1,0} bitcast(f32[1,16,1024]{2,1,0} %dynamic-slice.458), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.832 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %add.2311, f32[16,1024]{1,0} %bitcast.843), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  %param_0.1588 = f32[64,16,1024]{2,1,0} parameter(0)
  %dynamic-slice.319 = f32[1,16,1024]{2,1,0} dynamic-slice(f32[64,16,1024]{2,1,0} %param_0.1588, s32[] %select.1501, s32[] %constant_10655, s32[] %constant_10655), dynamic_slice_sizes={1,16,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %bitcast.444 = f32[16,1024]{1,0} bitcast(f32[1,16,1024]{2,1,0} %dynamic-slice.319), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.831 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %multiply.832, f32[16,1024]{1,0} %bitcast.444), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  %add.1789 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %slice.828, f32[16,1024]{1,0} %multiply.831), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %param_3.1323 = f32[64,16,1024]{2,1,0} parameter(3)
  %dynamic-slice.450 = f32[1,16,1024]{2,1,0} dynamic-slice(f32[64,16,1024]{2,1,0} %param_3.1323, s32[] %select.1501, s32[] %constant_10655, s32[] %constant_10655), dynamic_slice_sizes={1,16,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %bitcast.835 = f32[16,1024]{1,0} bitcast(f32[1,16,1024]{2,1,0} %dynamic-slice.450), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.830 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %multiply.831, f32[16,1024]{1,0} %bitcast.835), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  ROOT %add.1788 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %add.1789, f32[16,1024]{1,0} %multiply.830), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
}

%fused_computation.31 (param_0.64: f32[64,16,2048], param_1.1932: s32[], param_2.2321: f32[16,1024], param_3.2082: f32[64,16,1024], param_4.1072: f32[16,2048]) -> (f32[16,2048], f32[16,2048]) {
  %param_0.64 = f32[64,16,2048]{2,1,0} parameter(0)
  %constant_12289 = s32[] constant(64), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_1.1932 = s32[] parameter(1)
  %subtract.389 = s32[] subtract(s32[] %constant_12289, s32[] %param_1.1932), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_12288 = s32[] constant(-1)
  %add.2253 = s32[] add(s32[] %subtract.389, s32[] %constant_12288), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_10664 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.1480 = pred[] compare(s32[] %add.2253, s32[] %constant_10664), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_12283 = s32[] constant(63)
  %add.2252 = s32[] add(s32[] %subtract.389, s32[] %constant_12283), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %select.1471 = s32[] select(pred[] %compare.1480, s32[] %add.2252, s32[] %add.2253), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %dynamic-slice.323 = f32[1,16,2048]{2,1,0} dynamic-slice(f32[64,16,2048]{2,1,0} %param_0.64, s32[] %select.1471, s32[] %constant_10664, s32[] %constant_10664), dynamic_slice_sizes={1,16,2048}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 16, 2048) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %bitcast.448 = f32[16,2048]{1,0} bitcast(f32[1,16,2048]{2,1,0} %dynamic-slice.323), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_4.1072 = f32[16,2048]{1,0} parameter(4)
  %slice.827.clone.1 = f32[16,1024]{1,0} slice(f32[16,2048]{1,0} %param_4.1072), slice={[0:16], [1024:2048]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(16, 2048)\n                                                     start_indices=(0, 1024)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %constant_10646_clone_1 = f32[] constant(0), metadata={op_type="pad" op_name="pmap(_multi_device_update_fn)/scan/while/body/pad[ padding_config=((0, 0, 0), (3072, 0, 0)) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  %pad.135.clone.1 = f32[16,2048]{1,0} pad(f32[16,1024]{1,0} %slice.827.clone.1, f32[] %constant_10646_clone_1), padding=0_0x1024_0, metadata={op_type="pad" op_name="pmap(_multi_device_update_fn)/scan/while/body/pad[ padding_config=((0, 0, 0), (1024, 0, 0)) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=54}
  %param_2.2321 = f32[16,1024]{1,0} parameter(2)
  %param_3.2082 = f32[64,16,1024]{2,1,0} parameter(3)
  %dynamic-slice.446.clone.1 = f32[1,16,1024]{2,1,0} dynamic-slice(f32[64,16,1024]{2,1,0} %param_3.2082, s32[] %select.1471, s32[] %constant_10664, s32[] %constant_10664), dynamic_slice_sizes={1,16,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %bitcast.831.clone.1 = f32[16,1024]{1,0} bitcast(f32[1,16,1024]{2,1,0} %dynamic-slice.446.clone.1), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.817.clone.1 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %param_2.2321, f32[16,1024]{1,0} %bitcast.831.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %pad.134.clone.1 = f32[16,2048]{1,0} pad(f32[16,1024]{1,0} %multiply.817.clone.1, f32[] %constant_10646_clone_1), padding=0_0x0_1024, metadata={op_type="pad" op_name="pmap(_multi_device_update_fn)/scan/while/body/pad[ padding_config=((0, 0, 0), (0, 1024, 0)) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=54}
  %add.1782.clone.1 = f32[16,2048]{1,0} add(f32[16,2048]{1,0} %pad.135.clone.1, f32[16,2048]{1,0} %pad.134.clone.1), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  ROOT %tuple.467 = (f32[16,2048]{1,0}, f32[16,2048]{1,0}) tuple(f32[16,2048]{1,0} %bitcast.448, f32[16,2048]{1,0} %add.1782.clone.1)
}

%body_computation__47.8791.clone.clone (parameter.67: (f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[64,16,2048], f32[64,16,1024], /*index=5*/f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], /*index=10*/f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[2048,4096], s32[], /*index=15*/f32[2048,4096], f32[4096], f32[16,2048], f32[64,16,1024])) -> (f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[64,16,2048], f32[64,16,1024], /*index=5*/f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], /*index=10*/f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[2048,4096], s32[], /*index=15*/f32[2048,4096], f32[4096], f32[16,2048], f32[64,16,1024]) {
  %parameter.67 = (f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) parameter(0)
  %get-tuple-element.6452 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.67), index=0
  %get-tuple-element.6453 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.67), index=1
  %get-tuple-element.6454 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.67), index=2
  %get-tuple-element.6455 = f32[64,16,2048]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.67), index=3
  %get-tuple-element.6456 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.67), index=4
  %get-tuple-element.6457 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.67), index=5
  %get-tuple-element.6458 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.67), index=6
  %get-tuple-element.6459 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.67), index=7
  %get-tuple-element.6460 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.67), index=8
  %get-tuple-element.6461 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.67), index=9
  %get-tuple-element.6462 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.67), index=10
  %get-tuple-element.6463 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.67), index=11
  %get-tuple-element.6464 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.67), index=12
  %get-tuple-element.6465 = f32[2048,4096]{1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.67), index=13
  %get-tuple-element.6469 = f32[16,2048]{1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.67), index=17
  %get-tuple-element.6466 = s32[] get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.67), index=14
  %fusion.27 = f32[16,1024]{1,0} fusion(f32[64,16,1024]{2,1,0} %get-tuple-element.6462, f32[16,2048]{1,0} %get-tuple-element.6469, s32[] %get-tuple-element.6466, f32[64,16,1024]{2,1,0} %get-tuple-element.6461, f32[64,16,1024]{2,1,0} %get-tuple-element.6452, /*index=5*/f32[64,16,1024]{2,1,0} %get-tuple-element.6463), kind=kLoop, calls=%fused_computation.27, metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %fusion.25 = f32[16,4096]{1,0} fusion(f32[64,16,1024]{2,1,0} %get-tuple-element.6456, f32[16,1024]{1,0} %fusion.27, f32[64,16,1024]{2,1,0} %get-tuple-element.6454, f32[64,16,1024]{2,1,0} %get-tuple-element.6458, f32[64,16,1024]{2,1,0} %get-tuple-element.6459, /*index=5*/f32[64,16,1024]{2,1,0} %get-tuple-element.6460, f32[64,16,1024]{2,1,0} %get-tuple-element.6457, f32[64,16,1024]{2,1,0} %get-tuple-element.6464, s32[] %get-tuple-element.6466, f32[64,16,1024]{2,1,0} %get-tuple-element.6453, /*index=10*/f32[64,16,1024]{2,1,0} %get-tuple-element.6461, f32[16,2048]{1,0} %get-tuple-element.6469, f32[64,16,1024]{2,1,0} %get-tuple-element.6452, f32[64,16,1024]{2,1,0} %get-tuple-element.6463), kind=kLoop, calls=%fused_computation.25, metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %custom-call.100 = f32[16,2048]{1,0} custom-call(f32[16,4096]{1,0} %fusion.25, f32[2048,4096]{1,0} %get-tuple-element.6465), custom_call_target="__cublas$gemm", metadata={op_type="dot_general" op_name="pmap(_multi_device_update_fn)/scan/while/body/dot_general[ dimension_numbers=(((1,), (1,)), ((), ()))\n                                                           precision=None\n                                                           preferred_element_type=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}, backend_config="{\"alpha_real\":1,\"alpha_imag\":0,\"beta\":0,\"dot_dimension_numbers\":{\"lhs_contracting_dimensions\":[\"1\"],\"rhs_contracting_dimensions\":[\"1\"],\"lhs_batch_dimensions\":[],\"rhs_batch_dimensions\":[]},\"batch_size\":\"1\",\"selected_algorithm\":\"-1\"}"
  %fusion.31 = (f32[16,2048]{1,0}, f32[16,2048]{1,0}) fusion(f32[64,16,2048]{2,1,0} %get-tuple-element.6455, s32[] %get-tuple-element.6466, f32[16,1024]{1,0} %fusion.27, f32[64,16,1024]{2,1,0} %get-tuple-element.6453, f32[16,2048]{1,0} %custom-call.100), kind=kLoop, calls=%fused_computation.31, control-predecessors={%fusion.27, %fusion.25}, metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.6470 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.67), index=18
  %fusion.22 = f32[64,16,1024]{2,1,0} fusion(f32[64,16,1024]{2,1,0} %get-tuple-element.6470, f32[16,2048]{1,0} %custom-call.100, s32[] %get-tuple-element.6466), kind=kLoop, calls=%fused_computation.22, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_8637 = s32[] constant(1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.1298 = s32[] add(s32[] %get-tuple-element.6466, s32[] %constant_8637), control-predecessors={%fusion.22, %fusion.31, %fusion.27, %fusion.25}, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.5040 = f32[16,2048]{1,0} get-tuple-element((f32[16,2048]{1,0}, f32[16,2048]{1,0}) %fusion.31), index=0
  %get-tuple-element.6467 = f32[2048,4096]{1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.67), index=15
  %custom-call.99 = f32[2048,4096]{1,0} custom-call(f32[16,2048]{1,0} %get-tuple-element.5040, f32[16,4096]{1,0} %fusion.25, f32[2048,4096]{1,0} %get-tuple-element.6467), custom_call_target="__cublas$gemm", metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}, backend_config="{\"alpha_real\":1,\"alpha_imag\":0,\"beta\":1,\"dot_dimension_numbers\":{\"lhs_contracting_dimensions\":[\"0\"],\"rhs_contracting_dimensions\":[\"0\"],\"lhs_batch_dimensions\":[],\"rhs_batch_dimensions\":[]},\"batch_size\":\"1\",\"selected_algorithm\":\"4\"}"
  %get-tuple-element.6468 = f32[4096]{0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.67), index=16
  %fusion.24 = f32[4096]{0} fusion(f32[4096]{0} %get-tuple-element.6468, f32[16,4096]{1,0} %fusion.25), kind=kLoop, calls=%fused_computation.24, metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %get-tuple-element.5041 = f32[16,2048]{1,0} get-tuple-element((f32[16,2048]{1,0}, f32[16,2048]{1,0}) %fusion.31), index=1
  ROOT %tuple.820 = (f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) tuple(f32[64,16,1024]{2,1,0} %get-tuple-element.6452, f32[64,16,1024]{2,1,0} %get-tuple-element.6453, f32[64,16,1024]{2,1,0} %get-tuple-element.6454, f32[64,16,2048]{2,1,0} %get-tuple-element.6455, f32[64,16,1024]{2,1,0} %get-tuple-element.6456, /*index=5*/f32[64,16,1024]{2,1,0} %get-tuple-element.6457, f32[64,16,1024]{2,1,0} %get-tuple-element.6458, f32[64,16,1024]{2,1,0} %get-tuple-element.6459, f32[64,16,1024]{2,1,0} %get-tuple-element.6460, f32[64,16,1024]{2,1,0} %get-tuple-element.6461, /*index=10*/f32[64,16,1024]{2,1,0} %get-tuple-element.6462, f32[64,16,1024]{2,1,0} %get-tuple-element.6463, f32[64,16,1024]{2,1,0} %get-tuple-element.6464, f32[2048,4096]{1,0} %get-tuple-element.6465, s32[] %add.1298, /*index=15*/f32[2048,4096]{1,0} %custom-call.99, f32[4096]{0} %fusion.24, f32[16,2048]{1,0} %get-tuple-element.5041, f32[64,16,1024]{2,1,0} %fusion.22)
}

%cond_computation__47.9202.clone.clone (parameter.68: (f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[64,16,2048], f32[64,16,1024], /*index=5*/f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], /*index=10*/f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[2048,4096], s32[], /*index=15*/f32[2048,4096], f32[4096], f32[16,2048], f32[64,16,1024])) -> pred[] {
  %parameter.68 = (f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) parameter(0)
  %get-tuple-element.3459 = s32[] get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.68), index=14
  %constant_8643 = s32[] constant(64), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/cond/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %compare.1137 = pred[] compare(s32[] %get-tuple-element.3459, s32[] %constant_8643), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/cond/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.33 (param_0.69: f32[64,16,1024], param_1.1982: f32[16,2048], param_2.1596: s32[]) -> f32[64,16,1024] {
  %param_0.69 = f32[64,16,1024]{2,1,0} parameter(0)
  %param_1.1982 = f32[16,2048]{1,0} parameter(1)
  %slice.830 = f32[16,1024]{1,0} slice(f32[16,2048]{1,0} %param_1.1982), slice={[0:16], [0:1024]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(16, 1024)\n                                                     start_indices=(0, 0)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %bitcast.449 = f32[1,16,1024]{2,1,0} bitcast(f32[16,1024]{1,0} %slice.830), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_12563 = s32[] constant(64), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_2.1596 = s32[] parameter(2)
  %subtract.435 = s32[] subtract(s32[] %constant_12563, s32[] %param_2.1596), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_12562 = s32[] constant(-1)
  %add.2353 = s32[] add(s32[] %subtract.435, s32[] %constant_12562), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_10669 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.1534 = pred[] compare(s32[] %add.2353, s32[] %constant_10669), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_12560 = s32[] constant(63)
  %add.2352 = s32[] add(s32[] %subtract.435, s32[] %constant_12560), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %select.1524 = s32[] select(pred[] %compare.1534, s32[] %add.2352, s32[] %add.2353), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.494 = f32[64,16,1024]{2,1,0} dynamic-update-slice(f32[64,16,1024]{2,1,0} %param_0.69, f32[1,16,1024]{2,1,0} %bitcast.449, s32[] %select.1524, s32[] %constant_10669, s32[] %constant_10669), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%primitive_computation_add__1.9295 (parameter.9296: f32[], parameter.9297: f32[]) -> f32[] {
  %parameter.9296 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.9297 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.9298 = f32[] add(f32[] %parameter.9296, f32[] %parameter.9297), metadata={op_type="add" op_name="add"}
}

%fused_computation.35 (param_0.72: f32[4096], param_1.100: f32[16,4096]) -> f32[4096] {
  %param_0.72 = f32[4096]{0} parameter(0)
  %param_1.100 = f32[16,4096]{1,0} parameter(1)
  %constant_10675 = f32[] constant(0), metadata={op_type="pad" op_name="pmap(_multi_device_update_fn)/scan/while/body/pad[ padding_config=((0, 0, 0), (3072, 0, 0)) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  %reduce.176 = f32[4096]{0} reduce(f32[16,4096]{1,0} %param_1.100, f32[] %constant_10675), dimensions={0}, to_apply=%primitive_computation_add__1.9295, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/scan/while/body/reduce_sum[ axes=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  ROOT %add.1794 = f32[4096]{0} add(f32[4096]{0} %param_0.72, f32[4096]{0} %reduce.176), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
}

%fused_computation.36 (param_0.1602: f32[64,16,1024], param_1.1984: f32[16,1024], param_2.1597: f32[64,16,1024], param_3.1348: f32[64,16,1024], param_4.585: f32[64,16,1024], param_5.317: f32[64,16,1024], param_6.277: f32[64,16,1024], param_7.276: f32[64,16,1024], param_8.195: s32[], param_9.117: f32[64,16,1024], param_10.124: f32[64,16,1024], param_11.151: f32[16,2048], param_12.134: f32[64,16,1024], param_13.134: f32[64,16,1024]) -> f32[16,4096] {
  %param_10.124 = f32[64,16,1024]{2,1,0} parameter(10)
  %constant_12527 = s32[] constant(64), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_8.195 = s32[] parameter(8)
  %subtract.441 = s32[] subtract(s32[] %constant_12527, s32[] %param_8.195), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_12526 = s32[] constant(-1)
  %add.2365 = s32[] add(s32[] %subtract.441, s32[] %constant_12526), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_10678 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.1540 = pred[] compare(s32[] %add.2365, s32[] %constant_10678), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_12524 = s32[] constant(63)
  %add.2364 = s32[] add(s32[] %subtract.441, s32[] %constant_12524), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %select.1531 = s32[] select(pred[] %compare.1540, s32[] %add.2364, s32[] %add.2365), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %dynamic-slice.464 = f32[1,16,1024]{2,1,0} dynamic-slice(f32[64,16,1024]{2,1,0} %param_10.124, s32[] %select.1531, s32[] %constant_10678, s32[] %constant_10678), dynamic_slice_sizes={1,16,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %bitcast.849 = f32[16,1024]{1,0} bitcast(f32[1,16,1024]{2,1,0} %dynamic-slice.464), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_12.134 = f32[64,16,1024]{2,1,0} parameter(12)
  %dynamic-slice.468 = f32[1,16,1024]{2,1,0} dynamic-slice(f32[64,16,1024]{2,1,0} %param_12.134, s32[] %select.1531, s32[] %constant_10678, s32[] %constant_10678), dynamic_slice_sizes={1,16,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %bitcast.853 = f32[16,1024]{1,0} bitcast(f32[1,16,1024]{2,1,0} %dynamic-slice.468), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_11.151 = f32[16,2048]{1,0} parameter(11)
  %slice.968 = f32[16,1024]{1,0} slice(f32[16,2048]{1,0} %param_11.151), slice={[0:16], [1024:2048]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(16, 2048)\n                                                     start_indices=(0, 1024)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=65}
  %add.2373 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %bitcast.853, f32[16,1024]{1,0} %slice.968), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %multiply.845 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %bitcast.849, f32[16,1024]{1,0} %add.2373), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  %param_7.276 = f32[64,16,1024]{2,1,0} parameter(7)
  %dynamic-slice.330 = f32[1,16,1024]{2,1,0} dynamic-slice(f32[64,16,1024]{2,1,0} %param_7.276, s32[] %select.1531, s32[] %constant_10678, s32[] %constant_10678), dynamic_slice_sizes={1,16,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %bitcast.456 = f32[16,1024]{1,0} bitcast(f32[1,16,1024]{2,1,0} %dynamic-slice.330), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.844 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %multiply.845, f32[16,1024]{1,0} %bitcast.456), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %param_13.134 = f32[64,16,1024]{2,1,0} parameter(13)
  %dynamic-slice.472 = f32[1,16,1024]{2,1,0} dynamic-slice(f32[64,16,1024]{2,1,0} %param_13.134, s32[] %select.1531, s32[] %constant_10678, s32[] %constant_10678), dynamic_slice_sizes={1,16,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %bitcast.857 = f32[16,1024]{1,0} bitcast(f32[1,16,1024]{2,1,0} %dynamic-slice.472), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.843 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %multiply.844, f32[16,1024]{1,0} %bitcast.857), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %constant_10677 = f32[] constant(0), metadata={op_type="pad" op_name="pmap(_multi_device_update_fn)/scan/while/body/pad[ padding_config=((0, 0, 0), (3072, 0, 0)) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  %pad.145 = f32[16,4096]{1,0} pad(f32[16,1024]{1,0} %multiply.843, f32[] %constant_10677), padding=0_0x3072_0, metadata={op_type="pad" op_name="pmap(_multi_device_update_fn)/scan/while/body/pad[ padding_config=((0, 0, 0), (3072, 0, 0)) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  %param_6.277 = f32[64,16,1024]{2,1,0} parameter(6)
  %dynamic-slice.329 = f32[1,16,1024]{2,1,0} dynamic-slice(f32[64,16,1024]{2,1,0} %param_6.277, s32[] %select.1531, s32[] %constant_10678, s32[] %constant_10678), dynamic_slice_sizes={1,16,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %bitcast.455 = f32[16,1024]{1,0} bitcast(f32[1,16,1024]{2,1,0} %dynamic-slice.329), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_1.1984 = f32[16,1024]{1,0} parameter(1)
  %multiply.842 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %bitcast.455, f32[16,1024]{1,0} %param_1.1984), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %param_5.317 = f32[64,16,1024]{2,1,0} parameter(5)
  %dynamic-slice.328 = f32[1,16,1024]{2,1,0} dynamic-slice(f32[64,16,1024]{2,1,0} %param_5.317, s32[] %select.1531, s32[] %constant_10678, s32[] %constant_10678), dynamic_slice_sizes={1,16,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %bitcast.454 = f32[16,1024]{1,0} bitcast(f32[1,16,1024]{2,1,0} %dynamic-slice.328), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.841 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %multiply.842, f32[16,1024]{1,0} %bitcast.454), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %param_4.585 = f32[64,16,1024]{2,1,0} parameter(4)
  %dynamic-slice.327 = f32[1,16,1024]{2,1,0} dynamic-slice(f32[64,16,1024]{2,1,0} %param_4.585, s32[] %select.1531, s32[] %constant_10678, s32[] %constant_10678), dynamic_slice_sizes={1,16,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %bitcast.453 = f32[16,1024]{1,0} bitcast(f32[1,16,1024]{2,1,0} %dynamic-slice.327), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.840 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %multiply.841, f32[16,1024]{1,0} %bitcast.453), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %add.1798 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %multiply.841, f32[16,1024]{1,0} %multiply.840), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %pad.144 = f32[16,4096]{1,0} pad(f32[16,1024]{1,0} %add.1798, f32[] %constant_10677), padding=0_0x1024_2048, metadata={op_type="pad" op_name="pmap(_multi_device_update_fn)/scan/while/body/pad[ padding_config=((0, 0, 0), (1024, 2048, 0)) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  %add.1797 = f32[16,4096]{1,0} add(f32[16,4096]{1,0} %pad.145, f32[16,4096]{1,0} %pad.144), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %multiply.839 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %param_1.1984, f32[16,1024]{1,0} %bitcast.453), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %param_3.1348 = f32[64,16,1024]{2,1,0} parameter(3)
  %dynamic-slice.326 = f32[1,16,1024]{2,1,0} dynamic-slice(f32[64,16,1024]{2,1,0} %param_3.1348, s32[] %select.1531, s32[] %constant_10678, s32[] %constant_10678), dynamic_slice_sizes={1,16,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %bitcast.452 = f32[16,1024]{1,0} bitcast(f32[1,16,1024]{2,1,0} %dynamic-slice.326), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.838 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %multiply.839, f32[16,1024]{1,0} %bitcast.452), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %multiply.837 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %multiply.838, f32[16,1024]{1,0} %bitcast.455), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %pad.143 = f32[16,4096]{1,0} pad(f32[16,1024]{1,0} %multiply.837, f32[] %constant_10677), padding=0_0x0_3072, metadata={op_type="pad" op_name="pmap(_multi_device_update_fn)/scan/while/body/pad[ padding_config=((0, 0, 0), (0, 3072, 0)) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  %add.1796 = f32[16,4096]{1,0} add(f32[16,4096]{1,0} %add.1797, f32[16,4096]{1,0} %pad.143), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %param_2.1597 = f32[64,16,1024]{2,1,0} parameter(2)
  %dynamic-slice.325 = f32[1,16,1024]{2,1,0} dynamic-slice(f32[64,16,1024]{2,1,0} %param_2.1597, s32[] %select.1531, s32[] %constant_10678, s32[] %constant_10678), dynamic_slice_sizes={1,16,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %bitcast.451 = f32[16,1024]{1,0} bitcast(f32[1,16,1024]{2,1,0} %dynamic-slice.325), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.836 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %bitcast.451, f32[16,1024]{1,0} %param_1.1984), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %param_0.1602 = f32[64,16,1024]{2,1,0} parameter(0)
  %dynamic-slice.324 = f32[1,16,1024]{2,1,0} dynamic-slice(f32[64,16,1024]{2,1,0} %param_0.1602, s32[] %select.1531, s32[] %constant_10678, s32[] %constant_10678), dynamic_slice_sizes={1,16,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %bitcast.450 = f32[16,1024]{1,0} bitcast(f32[1,16,1024]{2,1,0} %dynamic-slice.324), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.835 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %multiply.836, f32[16,1024]{1,0} %bitcast.450), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %param_9.117 = f32[64,16,1024]{2,1,0} parameter(9)
  %dynamic-slice.460 = f32[1,16,1024]{2,1,0} dynamic-slice(f32[64,16,1024]{2,1,0} %param_9.117, s32[] %select.1531, s32[] %constant_10678, s32[] %constant_10678), dynamic_slice_sizes={1,16,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %bitcast.845 = f32[16,1024]{1,0} bitcast(f32[1,16,1024]{2,1,0} %dynamic-slice.460), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.834 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %multiply.835, f32[16,1024]{1,0} %bitcast.845), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %pad.142 = f32[16,4096]{1,0} pad(f32[16,1024]{1,0} %multiply.834, f32[] %constant_10677), padding=0_0x2048_1024, metadata={op_type="pad" op_name="pmap(_multi_device_update_fn)/scan/while/body/pad[ padding_config=((0, 0, 0), (2048, 1024, 0)) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  ROOT %add.1795 = f32[16,4096]{1,0} add(f32[16,4096]{1,0} %add.1796, f32[16,4096]{1,0} %pad.142), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
}

%fused_computation.38 (param_0.1606: f32[64,16,1024], param_1.1995: f32[16,2048], param_2.1604: s32[], param_3.1357: f32[64,16,1024], param_4.594: f32[64,16,1024], param_5.327: f32[64,16,1024]) -> f32[16,1024] {
  %param_1.1995 = f32[16,2048]{1,0} parameter(1)
  %slice.832 = f32[16,1024]{1,0} slice(f32[16,2048]{1,0} %param_1.1995), slice={[0:16], [0:1024]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(16, 1024)\n                                                     start_indices=(0, 0)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=65}
  %param_4.594 = f32[64,16,1024]{2,1,0} parameter(4)
  %constant_12554 = s32[] constant(64), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_2.1604 = s32[] parameter(2)
  %subtract.447 = s32[] subtract(s32[] %constant_12554, s32[] %param_2.1604), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_12553 = s32[] constant(-1)
  %add.2381 = s32[] add(s32[] %subtract.447, s32[] %constant_12553), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_10679 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.1547 = pred[] compare(s32[] %add.2381, s32[] %constant_10679), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_12551 = s32[] constant(63)
  %add.2380 = s32[] add(s32[] %subtract.447, s32[] %constant_12551), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %select.1537 = s32[] select(pred[] %compare.1547, s32[] %add.2380, s32[] %add.2381), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %dynamic-slice.470 = f32[1,16,1024]{2,1,0} dynamic-slice(f32[64,16,1024]{2,1,0} %param_4.594, s32[] %select.1537, s32[] %constant_10679, s32[] %constant_10679), dynamic_slice_sizes={1,16,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %bitcast.855 = f32[16,1024]{1,0} bitcast(f32[1,16,1024]{2,1,0} %dynamic-slice.470), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %slice.970 = f32[16,1024]{1,0} slice(f32[16,2048]{1,0} %param_1.1995), slice={[0:16], [1024:2048]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(16, 2048)\n                                                     start_indices=(0, 1024)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=65}
  %add.2379 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %bitcast.855, f32[16,1024]{1,0} %slice.970), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %param_5.327 = f32[64,16,1024]{2,1,0} parameter(5)
  %dynamic-slice.474 = f32[1,16,1024]{2,1,0} dynamic-slice(f32[64,16,1024]{2,1,0} %param_5.327, s32[] %select.1537, s32[] %constant_10679, s32[] %constant_10679), dynamic_slice_sizes={1,16,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %bitcast.859 = f32[16,1024]{1,0} bitcast(f32[1,16,1024]{2,1,0} %dynamic-slice.474), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.848 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %add.2379, f32[16,1024]{1,0} %bitcast.859), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  %param_0.1606 = f32[64,16,1024]{2,1,0} parameter(0)
  %dynamic-slice.332 = f32[1,16,1024]{2,1,0} dynamic-slice(f32[64,16,1024]{2,1,0} %param_0.1606, s32[] %select.1537, s32[] %constant_10679, s32[] %constant_10679), dynamic_slice_sizes={1,16,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %bitcast.458 = f32[16,1024]{1,0} bitcast(f32[1,16,1024]{2,1,0} %dynamic-slice.332), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.847 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %multiply.848, f32[16,1024]{1,0} %bitcast.458), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  %add.1800 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %slice.832, f32[16,1024]{1,0} %multiply.847), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %param_3.1357 = f32[64,16,1024]{2,1,0} parameter(3)
  %dynamic-slice.466 = f32[1,16,1024]{2,1,0} dynamic-slice(f32[64,16,1024]{2,1,0} %param_3.1357, s32[] %select.1537, s32[] %constant_10679, s32[] %constant_10679), dynamic_slice_sizes={1,16,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %bitcast.851 = f32[16,1024]{1,0} bitcast(f32[1,16,1024]{2,1,0} %dynamic-slice.466), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.846 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %multiply.847, f32[16,1024]{1,0} %bitcast.851), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  ROOT %add.1799 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %add.1800, f32[16,1024]{1,0} %multiply.846), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
}

%fused_computation.42 (param_0.87: f32[64,16,2048], param_1.1966: s32[], param_2.2324: f32[16,1024], param_3.2087: f32[64,16,1024], param_4.1077: f32[16,2048]) -> (f32[16,2048], f32[16,2048]) {
  %param_0.87 = f32[64,16,2048]{2,1,0} parameter(0)
  %constant_12500 = s32[] constant(64), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_1.1966 = s32[] parameter(1)
  %subtract.421 = s32[] subtract(s32[] %constant_12500, s32[] %param_1.1966), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_12499 = s32[] constant(-1)
  %add.2325 = s32[] add(s32[] %subtract.421, s32[] %constant_12499), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_10690 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.1517 = pred[] compare(s32[] %add.2325, s32[] %constant_10690), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_12496 = s32[] constant(63)
  %add.2324 = s32[] add(s32[] %subtract.421, s32[] %constant_12496), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %select.1508 = s32[] select(pred[] %compare.1517, s32[] %add.2324, s32[] %add.2325), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %dynamic-slice.336 = f32[1,16,2048]{2,1,0} dynamic-slice(f32[64,16,2048]{2,1,0} %param_0.87, s32[] %select.1508, s32[] %constant_10690, s32[] %constant_10690), dynamic_slice_sizes={1,16,2048}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 16, 2048) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %bitcast.462 = f32[16,2048]{1,0} bitcast(f32[1,16,2048]{2,1,0} %dynamic-slice.336), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_4.1077 = f32[16,2048]{1,0} parameter(4)
  %slice.831.clone.1 = f32[16,1024]{1,0} slice(f32[16,2048]{1,0} %param_4.1077), slice={[0:16], [1024:2048]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(16, 2048)\n                                                     start_indices=(0, 1024)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %constant_10672_clone_1 = f32[] constant(0), metadata={op_type="pad" op_name="pmap(_multi_device_update_fn)/scan/while/body/pad[ padding_config=((0, 0, 0), (3072, 0, 0)) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  %pad.141.clone.1 = f32[16,2048]{1,0} pad(f32[16,1024]{1,0} %slice.831.clone.1, f32[] %constant_10672_clone_1), padding=0_0x1024_0, metadata={op_type="pad" op_name="pmap(_multi_device_update_fn)/scan/while/body/pad[ padding_config=((0, 0, 0), (1024, 0, 0)) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=54}
  %param_2.2324 = f32[16,1024]{1,0} parameter(2)
  %param_3.2087 = f32[64,16,1024]{2,1,0} parameter(3)
  %dynamic-slice.462.clone.1 = f32[1,16,1024]{2,1,0} dynamic-slice(f32[64,16,1024]{2,1,0} %param_3.2087, s32[] %select.1508, s32[] %constant_10690, s32[] %constant_10690), dynamic_slice_sizes={1,16,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %bitcast.847.clone.1 = f32[16,1024]{1,0} bitcast(f32[1,16,1024]{2,1,0} %dynamic-slice.462.clone.1), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.833.clone.1 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %param_2.2324, f32[16,1024]{1,0} %bitcast.847.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %pad.140.clone.1 = f32[16,2048]{1,0} pad(f32[16,1024]{1,0} %multiply.833.clone.1, f32[] %constant_10672_clone_1), padding=0_0x0_1024, metadata={op_type="pad" op_name="pmap(_multi_device_update_fn)/scan/while/body/pad[ padding_config=((0, 0, 0), (0, 1024, 0)) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=54}
  %add.1793.clone.1 = f32[16,2048]{1,0} add(f32[16,2048]{1,0} %pad.141.clone.1, f32[16,2048]{1,0} %pad.140.clone.1), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  ROOT %tuple.468 = (f32[16,2048]{1,0}, f32[16,2048]{1,0}) tuple(f32[16,2048]{1,0} %bitcast.462, f32[16,2048]{1,0} %add.1793.clone.1)
}

%body_computation__48.9303.clone.clone (parameter.69: (f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[64,16,2048], f32[64,16,1024], /*index=5*/f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], /*index=10*/f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[2048,4096], s32[], /*index=15*/f32[2048,4096], f32[4096], f32[16,2048], f32[64,16,1024])) -> (f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[64,16,2048], f32[64,16,1024], /*index=5*/f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], /*index=10*/f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[2048,4096], s32[], /*index=15*/f32[2048,4096], f32[4096], f32[16,2048], f32[64,16,1024]) {
  %parameter.69 = (f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) parameter(0)
  %get-tuple-element.6509 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.69), index=0
  %get-tuple-element.6510 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.69), index=1
  %get-tuple-element.6511 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.69), index=2
  %get-tuple-element.6512 = f32[64,16,2048]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.69), index=3
  %get-tuple-element.6513 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.69), index=4
  %get-tuple-element.6514 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.69), index=5
  %get-tuple-element.6515 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.69), index=6
  %get-tuple-element.6516 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.69), index=7
  %get-tuple-element.6517 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.69), index=8
  %get-tuple-element.6518 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.69), index=9
  %get-tuple-element.6519 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.69), index=10
  %get-tuple-element.6520 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.69), index=11
  %get-tuple-element.6521 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.69), index=12
  %get-tuple-element.6522 = f32[2048,4096]{1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.69), index=13
  %get-tuple-element.6526 = f32[16,2048]{1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.69), index=17
  %get-tuple-element.6523 = s32[] get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.69), index=14
  %fusion.38 = f32[16,1024]{1,0} fusion(f32[64,16,1024]{2,1,0} %get-tuple-element.6519, f32[16,2048]{1,0} %get-tuple-element.6526, s32[] %get-tuple-element.6523, f32[64,16,1024]{2,1,0} %get-tuple-element.6518, f32[64,16,1024]{2,1,0} %get-tuple-element.6509, /*index=5*/f32[64,16,1024]{2,1,0} %get-tuple-element.6520), kind=kLoop, calls=%fused_computation.38, metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %fusion.36 = f32[16,4096]{1,0} fusion(f32[64,16,1024]{2,1,0} %get-tuple-element.6513, f32[16,1024]{1,0} %fusion.38, f32[64,16,1024]{2,1,0} %get-tuple-element.6511, f32[64,16,1024]{2,1,0} %get-tuple-element.6515, f32[64,16,1024]{2,1,0} %get-tuple-element.6516, /*index=5*/f32[64,16,1024]{2,1,0} %get-tuple-element.6517, f32[64,16,1024]{2,1,0} %get-tuple-element.6514, f32[64,16,1024]{2,1,0} %get-tuple-element.6521, s32[] %get-tuple-element.6523, f32[64,16,1024]{2,1,0} %get-tuple-element.6510, /*index=10*/f32[64,16,1024]{2,1,0} %get-tuple-element.6518, f32[16,2048]{1,0} %get-tuple-element.6526, f32[64,16,1024]{2,1,0} %get-tuple-element.6509, f32[64,16,1024]{2,1,0} %get-tuple-element.6520), kind=kLoop, calls=%fused_computation.36, metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %custom-call.103 = f32[16,2048]{1,0} custom-call(f32[16,4096]{1,0} %fusion.36, f32[2048,4096]{1,0} %get-tuple-element.6522), custom_call_target="__cublas$gemm", metadata={op_type="dot_general" op_name="pmap(_multi_device_update_fn)/scan/while/body/dot_general[ dimension_numbers=(((1,), (1,)), ((), ()))\n                                                           precision=None\n                                                           preferred_element_type=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}, backend_config="{\"alpha_real\":1,\"alpha_imag\":0,\"beta\":0,\"dot_dimension_numbers\":{\"lhs_contracting_dimensions\":[\"1\"],\"rhs_contracting_dimensions\":[\"1\"],\"lhs_batch_dimensions\":[],\"rhs_batch_dimensions\":[]},\"batch_size\":\"1\",\"selected_algorithm\":\"-1\"}"
  %fusion.42 = (f32[16,2048]{1,0}, f32[16,2048]{1,0}) fusion(f32[64,16,2048]{2,1,0} %get-tuple-element.6512, s32[] %get-tuple-element.6523, f32[16,1024]{1,0} %fusion.38, f32[64,16,1024]{2,1,0} %get-tuple-element.6510, f32[16,2048]{1,0} %custom-call.103), kind=kLoop, calls=%fused_computation.42, control-predecessors={%fusion.38, %fusion.36}, metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.6527 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.69), index=18
  %fusion.33 = f32[64,16,1024]{2,1,0} fusion(f32[64,16,1024]{2,1,0} %get-tuple-element.6527, f32[16,2048]{1,0} %custom-call.103, s32[] %get-tuple-element.6523), kind=kLoop, calls=%fused_computation.33, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_8730 = s32[] constant(1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.1344 = s32[] add(s32[] %get-tuple-element.6523, s32[] %constant_8730), control-predecessors={%fusion.33, %fusion.42, %fusion.38, %fusion.36}, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.5042 = f32[16,2048]{1,0} get-tuple-element((f32[16,2048]{1,0}, f32[16,2048]{1,0}) %fusion.42), index=0
  %get-tuple-element.6524 = f32[2048,4096]{1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.69), index=15
  %custom-call.102 = f32[2048,4096]{1,0} custom-call(f32[16,2048]{1,0} %get-tuple-element.5042, f32[16,4096]{1,0} %fusion.36, f32[2048,4096]{1,0} %get-tuple-element.6524), custom_call_target="__cublas$gemm", metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}, backend_config="{\"alpha_real\":1,\"alpha_imag\":0,\"beta\":1,\"dot_dimension_numbers\":{\"lhs_contracting_dimensions\":[\"0\"],\"rhs_contracting_dimensions\":[\"0\"],\"lhs_batch_dimensions\":[],\"rhs_batch_dimensions\":[]},\"batch_size\":\"1\",\"selected_algorithm\":\"4\"}"
  %get-tuple-element.6525 = f32[4096]{0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.69), index=16
  %fusion.35 = f32[4096]{0} fusion(f32[4096]{0} %get-tuple-element.6525, f32[16,4096]{1,0} %fusion.36), kind=kLoop, calls=%fused_computation.35, metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %get-tuple-element.5043 = f32[16,2048]{1,0} get-tuple-element((f32[16,2048]{1,0}, f32[16,2048]{1,0}) %fusion.42), index=1
  ROOT %tuple.823 = (f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) tuple(f32[64,16,1024]{2,1,0} %get-tuple-element.6509, f32[64,16,1024]{2,1,0} %get-tuple-element.6510, f32[64,16,1024]{2,1,0} %get-tuple-element.6511, f32[64,16,2048]{2,1,0} %get-tuple-element.6512, f32[64,16,1024]{2,1,0} %get-tuple-element.6513, /*index=5*/f32[64,16,1024]{2,1,0} %get-tuple-element.6514, f32[64,16,1024]{2,1,0} %get-tuple-element.6515, f32[64,16,1024]{2,1,0} %get-tuple-element.6516, f32[64,16,1024]{2,1,0} %get-tuple-element.6517, f32[64,16,1024]{2,1,0} %get-tuple-element.6518, /*index=10*/f32[64,16,1024]{2,1,0} %get-tuple-element.6519, f32[64,16,1024]{2,1,0} %get-tuple-element.6520, f32[64,16,1024]{2,1,0} %get-tuple-element.6521, f32[2048,4096]{1,0} %get-tuple-element.6522, s32[] %add.1344, /*index=15*/f32[2048,4096]{1,0} %custom-call.102, f32[4096]{0} %fusion.35, f32[16,2048]{1,0} %get-tuple-element.5043, f32[64,16,1024]{2,1,0} %fusion.33)
}

%cond_computation__48.9714.clone.clone (parameter.70: (f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[64,16,2048], f32[64,16,1024], /*index=5*/f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], /*index=10*/f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[2048,4096], s32[], /*index=15*/f32[2048,4096], f32[4096], f32[16,2048], f32[64,16,1024])) -> pred[] {
  %parameter.70 = (f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) parameter(0)
  %get-tuple-element.3522 = s32[] get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.70), index=14
  %constant_8734 = s32[] constant(64), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/cond/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %compare.1152 = pred[] compare(s32[] %get-tuple-element.3522, s32[] %constant_8734), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/cond/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.44 (param_0.92: f32[64,16,1024], param_1.2016: f32[16,2048], param_2.1636: s32[]) -> f32[64,16,1024] {
  %param_0.92 = f32[64,16,1024]{2,1,0} parameter(0)
  %param_1.2016 = f32[16,2048]{1,0} parameter(1)
  %slice.834 = f32[16,1024]{1,0} slice(f32[16,2048]{1,0} %param_1.2016), slice={[0:16], [0:1024]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(16, 1024)\n                                                     start_indices=(0, 0)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %bitcast.463 = f32[1,16,1024]{2,1,0} bitcast(f32[16,1024]{1,0} %slice.834), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_12743 = s32[] constant(64), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_2.1636 = s32[] parameter(2)
  %subtract.467 = s32[] subtract(s32[] %constant_12743, s32[] %param_2.1636), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_12741 = s32[] constant(-1)
  %add.2421 = s32[] add(s32[] %subtract.467, s32[] %constant_12741), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_10695 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.1570 = pred[] compare(s32[] %add.2421, s32[] %constant_10695), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_12738 = s32[] constant(63)
  %add.2420 = s32[] add(s32[] %subtract.467, s32[] %constant_12738), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %select.1560 = s32[] select(pred[] %compare.1570, s32[] %add.2420, s32[] %add.2421), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.495 = f32[64,16,1024]{2,1,0} dynamic-update-slice(f32[64,16,1024]{2,1,0} %param_0.92, f32[1,16,1024]{2,1,0} %bitcast.463, s32[] %select.1560, s32[] %constant_10695, s32[] %constant_10695), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%primitive_computation_add__1.9921 (parameter.9922: f32[], parameter.9923: f32[]) -> f32[] {
  %parameter.9922 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.9923 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.9924 = f32[] add(f32[] %parameter.9922, f32[] %parameter.9923), metadata={op_type="add" op_name="add"}
}

%fused_computation.46 (param_0.95: f32[4096], param_1.131: f32[16,4096]) -> f32[4096] {
  %param_0.95 = f32[4096]{0} parameter(0)
  %param_1.131 = f32[16,4096]{1,0} parameter(1)
  %constant_10700 = f32[] constant(0), metadata={op_type="pad" op_name="pmap(_multi_device_update_fn)/scan/while/body/pad[ padding_config=((0, 0, 0), (3072, 0, 0)) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  %reduce.177 = f32[4096]{0} reduce(f32[16,4096]{1,0} %param_1.131, f32[] %constant_10700), dimensions={0}, to_apply=%primitive_computation_add__1.9921, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/scan/while/body/reduce_sum[ axes=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  ROOT %add.1805 = f32[4096]{0} add(f32[4096]{0} %param_0.95, f32[4096]{0} %reduce.177), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
}

%fused_computation.47 (param_0.1620: f32[64,16,1024], param_1.2018: f32[16,1024], param_2.1637: f32[64,16,1024], param_3.1382: f32[64,16,1024], param_4.607: f32[64,16,1024], param_5.336: f32[64,16,1024], param_6.301: f32[64,16,1024], param_7.297: f32[64,16,1024], param_8.208: s32[], param_9.125: f32[64,16,1024], param_10.129: f32[64,16,1024], param_11.156: f32[16,2048], param_12.146: f32[64,16,1024], param_13.155: f32[64,16,1024]) -> f32[16,4096] {
  %param_10.129 = f32[64,16,1024]{2,1,0} parameter(10)
  %constant_12689 = s32[] constant(64), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_8.208 = s32[] parameter(8)
  %subtract.473 = s32[] subtract(s32[] %constant_12689, s32[] %param_8.208), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_12687 = s32[] constant(-1)
  %add.2433 = s32[] add(s32[] %subtract.473, s32[] %constant_12687), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_10702 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.1577 = pred[] compare(s32[] %add.2433, s32[] %constant_10702), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_12684 = s32[] constant(63)
  %add.2432 = s32[] add(s32[] %subtract.473, s32[] %constant_12684), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %select.1567 = s32[] select(pred[] %compare.1577, s32[] %add.2432, s32[] %add.2433), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %dynamic-slice.480 = f32[1,16,1024]{2,1,0} dynamic-slice(f32[64,16,1024]{2,1,0} %param_10.129, s32[] %select.1567, s32[] %constant_10702, s32[] %constant_10702), dynamic_slice_sizes={1,16,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %bitcast.865 = f32[16,1024]{1,0} bitcast(f32[1,16,1024]{2,1,0} %dynamic-slice.480), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_12.146 = f32[64,16,1024]{2,1,0} parameter(12)
  %dynamic-slice.484 = f32[1,16,1024]{2,1,0} dynamic-slice(f32[64,16,1024]{2,1,0} %param_12.146, s32[] %select.1567, s32[] %constant_10702, s32[] %constant_10702), dynamic_slice_sizes={1,16,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %bitcast.869 = f32[16,1024]{1,0} bitcast(f32[1,16,1024]{2,1,0} %dynamic-slice.484), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_11.156 = f32[16,2048]{1,0} parameter(11)
  %slice.972 = f32[16,1024]{1,0} slice(f32[16,2048]{1,0} %param_11.156), slice={[0:16], [1024:2048]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(16, 2048)\n                                                     start_indices=(0, 1024)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=65}
  %add.2441 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %bitcast.869, f32[16,1024]{1,0} %slice.972), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %multiply.861 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %bitcast.865, f32[16,1024]{1,0} %add.2441), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  %param_7.297 = f32[64,16,1024]{2,1,0} parameter(7)
  %dynamic-slice.343 = f32[1,16,1024]{2,1,0} dynamic-slice(f32[64,16,1024]{2,1,0} %param_7.297, s32[] %select.1567, s32[] %constant_10702, s32[] %constant_10702), dynamic_slice_sizes={1,16,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %bitcast.470 = f32[16,1024]{1,0} bitcast(f32[1,16,1024]{2,1,0} %dynamic-slice.343), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.860 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %multiply.861, f32[16,1024]{1,0} %bitcast.470), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %param_13.155 = f32[64,16,1024]{2,1,0} parameter(13)
  %dynamic-slice.488 = f32[1,16,1024]{2,1,0} dynamic-slice(f32[64,16,1024]{2,1,0} %param_13.155, s32[] %select.1567, s32[] %constant_10702, s32[] %constant_10702), dynamic_slice_sizes={1,16,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %bitcast.873 = f32[16,1024]{1,0} bitcast(f32[1,16,1024]{2,1,0} %dynamic-slice.488), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.859 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %multiply.860, f32[16,1024]{1,0} %bitcast.873), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %constant_10701 = f32[] constant(0), metadata={op_type="pad" op_name="pmap(_multi_device_update_fn)/scan/while/body/pad[ padding_config=((0, 0, 0), (3072, 0, 0)) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  %pad.151 = f32[16,4096]{1,0} pad(f32[16,1024]{1,0} %multiply.859, f32[] %constant_10701), padding=0_0x3072_0, metadata={op_type="pad" op_name="pmap(_multi_device_update_fn)/scan/while/body/pad[ padding_config=((0, 0, 0), (3072, 0, 0)) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  %param_6.301 = f32[64,16,1024]{2,1,0} parameter(6)
  %dynamic-slice.342 = f32[1,16,1024]{2,1,0} dynamic-slice(f32[64,16,1024]{2,1,0} %param_6.301, s32[] %select.1567, s32[] %constant_10702, s32[] %constant_10702), dynamic_slice_sizes={1,16,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %bitcast.469 = f32[16,1024]{1,0} bitcast(f32[1,16,1024]{2,1,0} %dynamic-slice.342), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_1.2018 = f32[16,1024]{1,0} parameter(1)
  %multiply.858 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %bitcast.469, f32[16,1024]{1,0} %param_1.2018), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %param_5.336 = f32[64,16,1024]{2,1,0} parameter(5)
  %dynamic-slice.341 = f32[1,16,1024]{2,1,0} dynamic-slice(f32[64,16,1024]{2,1,0} %param_5.336, s32[] %select.1567, s32[] %constant_10702, s32[] %constant_10702), dynamic_slice_sizes={1,16,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %bitcast.468 = f32[16,1024]{1,0} bitcast(f32[1,16,1024]{2,1,0} %dynamic-slice.341), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.857 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %multiply.858, f32[16,1024]{1,0} %bitcast.468), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %param_4.607 = f32[64,16,1024]{2,1,0} parameter(4)
  %dynamic-slice.340 = f32[1,16,1024]{2,1,0} dynamic-slice(f32[64,16,1024]{2,1,0} %param_4.607, s32[] %select.1567, s32[] %constant_10702, s32[] %constant_10702), dynamic_slice_sizes={1,16,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %bitcast.467 = f32[16,1024]{1,0} bitcast(f32[1,16,1024]{2,1,0} %dynamic-slice.340), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.856 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %multiply.857, f32[16,1024]{1,0} %bitcast.467), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %add.1809 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %multiply.857, f32[16,1024]{1,0} %multiply.856), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %pad.150 = f32[16,4096]{1,0} pad(f32[16,1024]{1,0} %add.1809, f32[] %constant_10701), padding=0_0x1024_2048, metadata={op_type="pad" op_name="pmap(_multi_device_update_fn)/scan/while/body/pad[ padding_config=((0, 0, 0), (1024, 2048, 0)) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  %add.1808 = f32[16,4096]{1,0} add(f32[16,4096]{1,0} %pad.151, f32[16,4096]{1,0} %pad.150), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %multiply.855 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %param_1.2018, f32[16,1024]{1,0} %bitcast.467), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %param_3.1382 = f32[64,16,1024]{2,1,0} parameter(3)
  %dynamic-slice.339 = f32[1,16,1024]{2,1,0} dynamic-slice(f32[64,16,1024]{2,1,0} %param_3.1382, s32[] %select.1567, s32[] %constant_10702, s32[] %constant_10702), dynamic_slice_sizes={1,16,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %bitcast.466 = f32[16,1024]{1,0} bitcast(f32[1,16,1024]{2,1,0} %dynamic-slice.339), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.854 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %multiply.855, f32[16,1024]{1,0} %bitcast.466), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %multiply.853 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %multiply.854, f32[16,1024]{1,0} %bitcast.469), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %pad.149 = f32[16,4096]{1,0} pad(f32[16,1024]{1,0} %multiply.853, f32[] %constant_10701), padding=0_0x0_3072, metadata={op_type="pad" op_name="pmap(_multi_device_update_fn)/scan/while/body/pad[ padding_config=((0, 0, 0), (0, 3072, 0)) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  %add.1807 = f32[16,4096]{1,0} add(f32[16,4096]{1,0} %add.1808, f32[16,4096]{1,0} %pad.149), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %param_2.1637 = f32[64,16,1024]{2,1,0} parameter(2)
  %dynamic-slice.338 = f32[1,16,1024]{2,1,0} dynamic-slice(f32[64,16,1024]{2,1,0} %param_2.1637, s32[] %select.1567, s32[] %constant_10702, s32[] %constant_10702), dynamic_slice_sizes={1,16,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %bitcast.465 = f32[16,1024]{1,0} bitcast(f32[1,16,1024]{2,1,0} %dynamic-slice.338), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.852 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %bitcast.465, f32[16,1024]{1,0} %param_1.2018), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %param_0.1620 = f32[64,16,1024]{2,1,0} parameter(0)
  %dynamic-slice.337 = f32[1,16,1024]{2,1,0} dynamic-slice(f32[64,16,1024]{2,1,0} %param_0.1620, s32[] %select.1567, s32[] %constant_10702, s32[] %constant_10702), dynamic_slice_sizes={1,16,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %bitcast.464 = f32[16,1024]{1,0} bitcast(f32[1,16,1024]{2,1,0} %dynamic-slice.337), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.851 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %multiply.852, f32[16,1024]{1,0} %bitcast.464), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %param_9.125 = f32[64,16,1024]{2,1,0} parameter(9)
  %dynamic-slice.476 = f32[1,16,1024]{2,1,0} dynamic-slice(f32[64,16,1024]{2,1,0} %param_9.125, s32[] %select.1567, s32[] %constant_10702, s32[] %constant_10702), dynamic_slice_sizes={1,16,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %bitcast.861 = f32[16,1024]{1,0} bitcast(f32[1,16,1024]{2,1,0} %dynamic-slice.476), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.850 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %multiply.851, f32[16,1024]{1,0} %bitcast.861), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %pad.148 = f32[16,4096]{1,0} pad(f32[16,1024]{1,0} %multiply.850, f32[] %constant_10701), padding=0_0x2048_1024, metadata={op_type="pad" op_name="pmap(_multi_device_update_fn)/scan/while/body/pad[ padding_config=((0, 0, 0), (2048, 1024, 0)) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  ROOT %add.1806 = f32[16,4096]{1,0} add(f32[16,4096]{1,0} %add.1807, f32[16,4096]{1,0} %pad.148), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
}

%fused_computation.49 (param_0.1624: f32[64,16,1024], param_1.2029: f32[16,2048], param_2.1644: s32[], param_3.1391: f32[64,16,1024], param_4.616: f32[64,16,1024], param_5.346: f32[64,16,1024]) -> f32[16,1024] {
  %param_1.2029 = f32[16,2048]{1,0} parameter(1)
  %slice.836 = f32[16,1024]{1,0} slice(f32[16,2048]{1,0} %param_1.2029), slice={[0:16], [0:1024]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(16, 1024)\n                                                     start_indices=(0, 0)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=65}
  %param_4.616 = f32[64,16,1024]{2,1,0} parameter(4)
  %constant_12729 = s32[] constant(64), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_2.1644 = s32[] parameter(2)
  %subtract.479 = s32[] subtract(s32[] %constant_12729, s32[] %param_2.1644), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_12728 = s32[] constant(-1)
  %add.2449 = s32[] add(s32[] %subtract.479, s32[] %constant_12728), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_10704 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.1584 = pred[] compare(s32[] %add.2449, s32[] %constant_10704), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_12725 = s32[] constant(63)
  %add.2448 = s32[] add(s32[] %subtract.479, s32[] %constant_12725), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %select.1574 = s32[] select(pred[] %compare.1584, s32[] %add.2448, s32[] %add.2449), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %dynamic-slice.486 = f32[1,16,1024]{2,1,0} dynamic-slice(f32[64,16,1024]{2,1,0} %param_4.616, s32[] %select.1574, s32[] %constant_10704, s32[] %constant_10704), dynamic_slice_sizes={1,16,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %bitcast.871 = f32[16,1024]{1,0} bitcast(f32[1,16,1024]{2,1,0} %dynamic-slice.486), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %slice.974 = f32[16,1024]{1,0} slice(f32[16,2048]{1,0} %param_1.2029), slice={[0:16], [1024:2048]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(16, 2048)\n                                                     start_indices=(0, 1024)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=65}
  %add.2447 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %bitcast.871, f32[16,1024]{1,0} %slice.974), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %param_5.346 = f32[64,16,1024]{2,1,0} parameter(5)
  %dynamic-slice.490 = f32[1,16,1024]{2,1,0} dynamic-slice(f32[64,16,1024]{2,1,0} %param_5.346, s32[] %select.1574, s32[] %constant_10704, s32[] %constant_10704), dynamic_slice_sizes={1,16,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %bitcast.875 = f32[16,1024]{1,0} bitcast(f32[1,16,1024]{2,1,0} %dynamic-slice.490), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.864 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %add.2447, f32[16,1024]{1,0} %bitcast.875), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  %param_0.1624 = f32[64,16,1024]{2,1,0} parameter(0)
  %dynamic-slice.345 = f32[1,16,1024]{2,1,0} dynamic-slice(f32[64,16,1024]{2,1,0} %param_0.1624, s32[] %select.1574, s32[] %constant_10704, s32[] %constant_10704), dynamic_slice_sizes={1,16,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %bitcast.472 = f32[16,1024]{1,0} bitcast(f32[1,16,1024]{2,1,0} %dynamic-slice.345), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.863 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %multiply.864, f32[16,1024]{1,0} %bitcast.472), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  %add.1811 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %slice.836, f32[16,1024]{1,0} %multiply.863), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %param_3.1391 = f32[64,16,1024]{2,1,0} parameter(3)
  %dynamic-slice.482 = f32[1,16,1024]{2,1,0} dynamic-slice(f32[64,16,1024]{2,1,0} %param_3.1391, s32[] %select.1574, s32[] %constant_10704, s32[] %constant_10704), dynamic_slice_sizes={1,16,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %bitcast.867 = f32[16,1024]{1,0} bitcast(f32[1,16,1024]{2,1,0} %dynamic-slice.482), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.862 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %multiply.863, f32[16,1024]{1,0} %bitcast.867), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  ROOT %add.1810 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %add.1811, f32[16,1024]{1,0} %multiply.862), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
}

%fused_computation.53 (param_0.110: f32[64,16,2048], param_1.2000: s32[], param_2.2327: f32[16,1024], param_3.2092: f32[64,16,1024], param_4.1082: f32[16,2048]) -> (f32[16,2048], f32[16,2048]) {
  %param_0.110 = f32[64,16,2048]{2,1,0} parameter(0)
  %constant_12660 = s32[] constant(64), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_1.2000 = s32[] parameter(1)
  %subtract.453 = s32[] subtract(s32[] %constant_12660, s32[] %param_1.2000), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_12659 = s32[] constant(-1)
  %add.2393 = s32[] add(s32[] %subtract.453, s32[] %constant_12659), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_10715 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.1554 = pred[] compare(s32[] %add.2393, s32[] %constant_10715), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_12657 = s32[] constant(63)
  %add.2392 = s32[] add(s32[] %subtract.453, s32[] %constant_12657), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %select.1544 = s32[] select(pred[] %compare.1554, s32[] %add.2392, s32[] %add.2393), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %dynamic-slice.349 = f32[1,16,2048]{2,1,0} dynamic-slice(f32[64,16,2048]{2,1,0} %param_0.110, s32[] %select.1544, s32[] %constant_10715, s32[] %constant_10715), dynamic_slice_sizes={1,16,2048}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 16, 2048) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %bitcast.476 = f32[16,2048]{1,0} bitcast(f32[1,16,2048]{2,1,0} %dynamic-slice.349), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_4.1082 = f32[16,2048]{1,0} parameter(4)
  %slice.835.clone.1 = f32[16,1024]{1,0} slice(f32[16,2048]{1,0} %param_4.1082), slice={[0:16], [1024:2048]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(16, 2048)\n                                                     start_indices=(0, 1024)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %constant_10698_clone_1 = f32[] constant(0), metadata={op_type="pad" op_name="pmap(_multi_device_update_fn)/scan/while/body/pad[ padding_config=((0, 0, 0), (3072, 0, 0)) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  %pad.147.clone.1 = f32[16,2048]{1,0} pad(f32[16,1024]{1,0} %slice.835.clone.1, f32[] %constant_10698_clone_1), padding=0_0x1024_0, metadata={op_type="pad" op_name="pmap(_multi_device_update_fn)/scan/while/body/pad[ padding_config=((0, 0, 0), (1024, 0, 0)) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=54}
  %param_2.2327 = f32[16,1024]{1,0} parameter(2)
  %param_3.2092 = f32[64,16,1024]{2,1,0} parameter(3)
  %dynamic-slice.478.clone.1 = f32[1,16,1024]{2,1,0} dynamic-slice(f32[64,16,1024]{2,1,0} %param_3.2092, s32[] %select.1544, s32[] %constant_10715, s32[] %constant_10715), dynamic_slice_sizes={1,16,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %bitcast.863.clone.1 = f32[16,1024]{1,0} bitcast(f32[1,16,1024]{2,1,0} %dynamic-slice.478.clone.1), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.849.clone.1 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %param_2.2327, f32[16,1024]{1,0} %bitcast.863.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %pad.146.clone.1 = f32[16,2048]{1,0} pad(f32[16,1024]{1,0} %multiply.849.clone.1, f32[] %constant_10698_clone_1), padding=0_0x0_1024, metadata={op_type="pad" op_name="pmap(_multi_device_update_fn)/scan/while/body/pad[ padding_config=((0, 0, 0), (0, 1024, 0)) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=54}
  %add.1804.clone.1 = f32[16,2048]{1,0} add(f32[16,2048]{1,0} %pad.147.clone.1, f32[16,2048]{1,0} %pad.146.clone.1), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  ROOT %tuple.469 = (f32[16,2048]{1,0}, f32[16,2048]{1,0}) tuple(f32[16,2048]{1,0} %bitcast.476, f32[16,2048]{1,0} %add.1804.clone.1)
}

%body_computation__49.9929.clone.clone (parameter.71: (f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[64,16,2048], f32[64,16,1024], /*index=5*/f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], /*index=10*/f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[2048,4096], s32[], /*index=15*/f32[2048,4096], f32[4096], f32[16,2048], f32[64,16,1024])) -> (f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[64,16,2048], f32[64,16,1024], /*index=5*/f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], /*index=10*/f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[2048,4096], s32[], /*index=15*/f32[2048,4096], f32[4096], f32[16,2048], f32[64,16,1024]) {
  %parameter.71 = (f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) parameter(0)
  %get-tuple-element.6566 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.71), index=0
  %get-tuple-element.6567 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.71), index=1
  %get-tuple-element.6568 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.71), index=2
  %get-tuple-element.6569 = f32[64,16,2048]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.71), index=3
  %get-tuple-element.6570 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.71), index=4
  %get-tuple-element.6571 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.71), index=5
  %get-tuple-element.6572 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.71), index=6
  %get-tuple-element.6573 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.71), index=7
  %get-tuple-element.6574 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.71), index=8
  %get-tuple-element.6575 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.71), index=9
  %get-tuple-element.6576 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.71), index=10
  %get-tuple-element.6577 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.71), index=11
  %get-tuple-element.6578 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.71), index=12
  %get-tuple-element.6579 = f32[2048,4096]{1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.71), index=13
  %get-tuple-element.6583 = f32[16,2048]{1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.71), index=17
  %get-tuple-element.6580 = s32[] get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.71), index=14
  %fusion.49 = f32[16,1024]{1,0} fusion(f32[64,16,1024]{2,1,0} %get-tuple-element.6576, f32[16,2048]{1,0} %get-tuple-element.6583, s32[] %get-tuple-element.6580, f32[64,16,1024]{2,1,0} %get-tuple-element.6575, f32[64,16,1024]{2,1,0} %get-tuple-element.6566, /*index=5*/f32[64,16,1024]{2,1,0} %get-tuple-element.6577), kind=kLoop, calls=%fused_computation.49, metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %fusion.47 = f32[16,4096]{1,0} fusion(f32[64,16,1024]{2,1,0} %get-tuple-element.6570, f32[16,1024]{1,0} %fusion.49, f32[64,16,1024]{2,1,0} %get-tuple-element.6568, f32[64,16,1024]{2,1,0} %get-tuple-element.6572, f32[64,16,1024]{2,1,0} %get-tuple-element.6573, /*index=5*/f32[64,16,1024]{2,1,0} %get-tuple-element.6574, f32[64,16,1024]{2,1,0} %get-tuple-element.6571, f32[64,16,1024]{2,1,0} %get-tuple-element.6578, s32[] %get-tuple-element.6580, f32[64,16,1024]{2,1,0} %get-tuple-element.6567, /*index=10*/f32[64,16,1024]{2,1,0} %get-tuple-element.6575, f32[16,2048]{1,0} %get-tuple-element.6583, f32[64,16,1024]{2,1,0} %get-tuple-element.6566, f32[64,16,1024]{2,1,0} %get-tuple-element.6577), kind=kLoop, calls=%fused_computation.47, metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %custom-call.106 = f32[16,2048]{1,0} custom-call(f32[16,4096]{1,0} %fusion.47, f32[2048,4096]{1,0} %get-tuple-element.6579), custom_call_target="__cublas$gemm", metadata={op_type="dot_general" op_name="pmap(_multi_device_update_fn)/scan/while/body/dot_general[ dimension_numbers=(((1,), (1,)), ((), ()))\n                                                           precision=None\n                                                           preferred_element_type=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}, backend_config="{\"alpha_real\":1,\"alpha_imag\":0,\"beta\":0,\"dot_dimension_numbers\":{\"lhs_contracting_dimensions\":[\"1\"],\"rhs_contracting_dimensions\":[\"1\"],\"lhs_batch_dimensions\":[],\"rhs_batch_dimensions\":[]},\"batch_size\":\"1\",\"selected_algorithm\":\"-1\"}"
  %fusion.53 = (f32[16,2048]{1,0}, f32[16,2048]{1,0}) fusion(f32[64,16,2048]{2,1,0} %get-tuple-element.6569, s32[] %get-tuple-element.6580, f32[16,1024]{1,0} %fusion.49, f32[64,16,1024]{2,1,0} %get-tuple-element.6567, f32[16,2048]{1,0} %custom-call.106), kind=kLoop, calls=%fused_computation.53, control-predecessors={%fusion.49, %fusion.47}, metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.6584 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.71), index=18
  %fusion.44 = f32[64,16,1024]{2,1,0} fusion(f32[64,16,1024]{2,1,0} %get-tuple-element.6584, f32[16,2048]{1,0} %custom-call.106, s32[] %get-tuple-element.6580), kind=kLoop, calls=%fused_computation.44, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_8810 = s32[] constant(1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.1390 = s32[] add(s32[] %get-tuple-element.6580, s32[] %constant_8810), control-predecessors={%fusion.44, %fusion.53, %fusion.49, %fusion.47}, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.5044 = f32[16,2048]{1,0} get-tuple-element((f32[16,2048]{1,0}, f32[16,2048]{1,0}) %fusion.53), index=0
  %get-tuple-element.6581 = f32[2048,4096]{1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.71), index=15
  %custom-call.105 = f32[2048,4096]{1,0} custom-call(f32[16,2048]{1,0} %get-tuple-element.5044, f32[16,4096]{1,0} %fusion.47, f32[2048,4096]{1,0} %get-tuple-element.6581), custom_call_target="__cublas$gemm", metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}, backend_config="{\"alpha_real\":1,\"alpha_imag\":0,\"beta\":1,\"dot_dimension_numbers\":{\"lhs_contracting_dimensions\":[\"0\"],\"rhs_contracting_dimensions\":[\"0\"],\"lhs_batch_dimensions\":[],\"rhs_batch_dimensions\":[]},\"batch_size\":\"1\",\"selected_algorithm\":\"4\"}"
  %get-tuple-element.6582 = f32[4096]{0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.71), index=16
  %fusion.46 = f32[4096]{0} fusion(f32[4096]{0} %get-tuple-element.6582, f32[16,4096]{1,0} %fusion.47), kind=kLoop, calls=%fused_computation.46, metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %get-tuple-element.5045 = f32[16,2048]{1,0} get-tuple-element((f32[16,2048]{1,0}, f32[16,2048]{1,0}) %fusion.53), index=1
  ROOT %tuple.826 = (f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) tuple(f32[64,16,1024]{2,1,0} %get-tuple-element.6566, f32[64,16,1024]{2,1,0} %get-tuple-element.6567, f32[64,16,1024]{2,1,0} %get-tuple-element.6568, f32[64,16,2048]{2,1,0} %get-tuple-element.6569, f32[64,16,1024]{2,1,0} %get-tuple-element.6570, /*index=5*/f32[64,16,1024]{2,1,0} %get-tuple-element.6571, f32[64,16,1024]{2,1,0} %get-tuple-element.6572, f32[64,16,1024]{2,1,0} %get-tuple-element.6573, f32[64,16,1024]{2,1,0} %get-tuple-element.6574, f32[64,16,1024]{2,1,0} %get-tuple-element.6575, /*index=10*/f32[64,16,1024]{2,1,0} %get-tuple-element.6576, f32[64,16,1024]{2,1,0} %get-tuple-element.6577, f32[64,16,1024]{2,1,0} %get-tuple-element.6578, f32[2048,4096]{1,0} %get-tuple-element.6579, s32[] %add.1390, /*index=15*/f32[2048,4096]{1,0} %custom-call.105, f32[4096]{0} %fusion.46, f32[16,2048]{1,0} %get-tuple-element.5045, f32[64,16,1024]{2,1,0} %fusion.44)
}

%cond_computation__49.10340.clone.clone (parameter.72: (f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[64,16,2048], f32[64,16,1024], /*index=5*/f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], /*index=10*/f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[2048,4096], s32[], /*index=15*/f32[2048,4096], f32[4096], f32[16,2048], f32[64,16,1024])) -> pred[] {
  %parameter.72 = (f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) parameter(0)
  %get-tuple-element.3583 = s32[] get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.72), index=14
  %constant_8814 = s32[] constant(64), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/cond/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %compare.1167 = pred[] compare(s32[] %get-tuple-element.3583, s32[] %constant_8814), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/cond/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.55 (param_0.115: f32[64,16,1024], param_1.2050: f32[16,2048], param_2.1676: s32[]) -> f32[64,16,1024] {
  %param_0.115 = f32[64,16,1024]{2,1,0} parameter(0)
  %param_1.2050 = f32[16,2048]{1,0} parameter(1)
  %slice.838 = f32[16,1024]{1,0} slice(f32[16,2048]{1,0} %param_1.2050), slice={[0:16], [0:1024]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(16, 1024)\n                                                     start_indices=(0, 0)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %bitcast.477 = f32[1,16,1024]{2,1,0} bitcast(f32[16,1024]{1,0} %slice.838), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_12915 = s32[] constant(64), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_2.1676 = s32[] parameter(2)
  %subtract.499 = s32[] subtract(s32[] %constant_12915, s32[] %param_2.1676), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_12914 = s32[] constant(-1)
  %add.2489 = s32[] add(s32[] %subtract.499, s32[] %constant_12914), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_10721 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.1605 = pred[] compare(s32[] %add.2489, s32[] %constant_10721), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_12912 = s32[] constant(63)
  %add.2488 = s32[] add(s32[] %subtract.499, s32[] %constant_12912), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %select.1597 = s32[] select(pred[] %compare.1605, s32[] %add.2488, s32[] %add.2489), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.496 = f32[64,16,1024]{2,1,0} dynamic-update-slice(f32[64,16,1024]{2,1,0} %param_0.115, f32[1,16,1024]{2,1,0} %bitcast.477, s32[] %select.1597, s32[] %constant_10721, s32[] %constant_10721), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%primitive_computation_add__1.10433 (parameter.10434: f32[], parameter.10435: f32[]) -> f32[] {
  %parameter.10434 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.10435 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.10436 = f32[] add(f32[] %parameter.10434, f32[] %parameter.10435), metadata={op_type="add" op_name="add"}
}

%fused_computation.57 (param_0.118: f32[4096], param_1.162: f32[16,4096]) -> f32[4096] {
  %param_0.118 = f32[4096]{0} parameter(0)
  %param_1.162 = f32[16,4096]{1,0} parameter(1)
  %constant_10724 = f32[] constant(0), metadata={op_type="pad" op_name="pmap(_multi_device_update_fn)/scan/while/body/pad[ padding_config=((0, 0, 0), (3072, 0, 0)) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  %reduce.178 = f32[4096]{0} reduce(f32[16,4096]{1,0} %param_1.162, f32[] %constant_10724), dimensions={0}, to_apply=%primitive_computation_add__1.10433, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/scan/while/body/reduce_sum[ axes=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  ROOT %add.1816 = f32[4096]{0} add(f32[4096]{0} %param_0.118, f32[4096]{0} %reduce.178), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
}

%fused_computation.58 (param_0.1638: f32[64,16,1024], param_1.2052: f32[16,1024], param_2.1677: f32[64,16,1024], param_3.1416: f32[64,16,1024], param_4.629: f32[64,16,1024], param_5.355: f32[64,16,1024], param_6.325: f32[64,16,1024], param_7.318: f32[64,16,1024], param_8.221: s32[], param_9.133: f32[64,16,1024], param_10.134: f32[64,16,1024], param_11.161: f32[16,2048], param_12.158: f32[64,16,1024], param_13.176: f32[64,16,1024]) -> f32[16,4096] {
  %param_10.134 = f32[64,16,1024]{2,1,0} parameter(10)
  %constant_12879 = s32[] constant(64), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_8.221 = s32[] parameter(8)
  %subtract.505 = s32[] subtract(s32[] %constant_12879, s32[] %param_8.221), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_12878 = s32[] constant(-1)
  %add.2501 = s32[] add(s32[] %subtract.505, s32[] %constant_12878), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_10727 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.1611 = pred[] compare(s32[] %add.2501, s32[] %constant_10727), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_12876 = s32[] constant(63)
  %add.2500 = s32[] add(s32[] %subtract.505, s32[] %constant_12876), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %select.1603 = s32[] select(pred[] %compare.1611, s32[] %add.2500, s32[] %add.2501), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %dynamic-slice.496 = f32[1,16,1024]{2,1,0} dynamic-slice(f32[64,16,1024]{2,1,0} %param_10.134, s32[] %select.1603, s32[] %constant_10727, s32[] %constant_10727), dynamic_slice_sizes={1,16,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %bitcast.881 = f32[16,1024]{1,0} bitcast(f32[1,16,1024]{2,1,0} %dynamic-slice.496), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_12.158 = f32[64,16,1024]{2,1,0} parameter(12)
  %dynamic-slice.500 = f32[1,16,1024]{2,1,0} dynamic-slice(f32[64,16,1024]{2,1,0} %param_12.158, s32[] %select.1603, s32[] %constant_10727, s32[] %constant_10727), dynamic_slice_sizes={1,16,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %bitcast.885 = f32[16,1024]{1,0} bitcast(f32[1,16,1024]{2,1,0} %dynamic-slice.500), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_11.161 = f32[16,2048]{1,0} parameter(11)
  %slice.976 = f32[16,1024]{1,0} slice(f32[16,2048]{1,0} %param_11.161), slice={[0:16], [1024:2048]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(16, 2048)\n                                                     start_indices=(0, 1024)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=65}
  %add.2509 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %bitcast.885, f32[16,1024]{1,0} %slice.976), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %multiply.877 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %bitcast.881, f32[16,1024]{1,0} %add.2509), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  %param_7.318 = f32[64,16,1024]{2,1,0} parameter(7)
  %dynamic-slice.356 = f32[1,16,1024]{2,1,0} dynamic-slice(f32[64,16,1024]{2,1,0} %param_7.318, s32[] %select.1603, s32[] %constant_10727, s32[] %constant_10727), dynamic_slice_sizes={1,16,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %bitcast.484 = f32[16,1024]{1,0} bitcast(f32[1,16,1024]{2,1,0} %dynamic-slice.356), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.876 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %multiply.877, f32[16,1024]{1,0} %bitcast.484), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %param_13.176 = f32[64,16,1024]{2,1,0} parameter(13)
  %dynamic-slice.504 = f32[1,16,1024]{2,1,0} dynamic-slice(f32[64,16,1024]{2,1,0} %param_13.176, s32[] %select.1603, s32[] %constant_10727, s32[] %constant_10727), dynamic_slice_sizes={1,16,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %bitcast.889 = f32[16,1024]{1,0} bitcast(f32[1,16,1024]{2,1,0} %dynamic-slice.504), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.875 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %multiply.876, f32[16,1024]{1,0} %bitcast.889), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %constant_10725 = f32[] constant(0), metadata={op_type="pad" op_name="pmap(_multi_device_update_fn)/scan/while/body/pad[ padding_config=((0, 0, 0), (3072, 0, 0)) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  %pad.157 = f32[16,4096]{1,0} pad(f32[16,1024]{1,0} %multiply.875, f32[] %constant_10725), padding=0_0x3072_0, metadata={op_type="pad" op_name="pmap(_multi_device_update_fn)/scan/while/body/pad[ padding_config=((0, 0, 0), (3072, 0, 0)) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  %param_6.325 = f32[64,16,1024]{2,1,0} parameter(6)
  %dynamic-slice.355 = f32[1,16,1024]{2,1,0} dynamic-slice(f32[64,16,1024]{2,1,0} %param_6.325, s32[] %select.1603, s32[] %constant_10727, s32[] %constant_10727), dynamic_slice_sizes={1,16,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %bitcast.483 = f32[16,1024]{1,0} bitcast(f32[1,16,1024]{2,1,0} %dynamic-slice.355), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_1.2052 = f32[16,1024]{1,0} parameter(1)
  %multiply.874 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %bitcast.483, f32[16,1024]{1,0} %param_1.2052), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %param_5.355 = f32[64,16,1024]{2,1,0} parameter(5)
  %dynamic-slice.354 = f32[1,16,1024]{2,1,0} dynamic-slice(f32[64,16,1024]{2,1,0} %param_5.355, s32[] %select.1603, s32[] %constant_10727, s32[] %constant_10727), dynamic_slice_sizes={1,16,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %bitcast.482 = f32[16,1024]{1,0} bitcast(f32[1,16,1024]{2,1,0} %dynamic-slice.354), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.873 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %multiply.874, f32[16,1024]{1,0} %bitcast.482), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %param_4.629 = f32[64,16,1024]{2,1,0} parameter(4)
  %dynamic-slice.353 = f32[1,16,1024]{2,1,0} dynamic-slice(f32[64,16,1024]{2,1,0} %param_4.629, s32[] %select.1603, s32[] %constant_10727, s32[] %constant_10727), dynamic_slice_sizes={1,16,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %bitcast.481 = f32[16,1024]{1,0} bitcast(f32[1,16,1024]{2,1,0} %dynamic-slice.353), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.872 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %multiply.873, f32[16,1024]{1,0} %bitcast.481), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %add.1820 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %multiply.873, f32[16,1024]{1,0} %multiply.872), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %pad.156 = f32[16,4096]{1,0} pad(f32[16,1024]{1,0} %add.1820, f32[] %constant_10725), padding=0_0x1024_2048, metadata={op_type="pad" op_name="pmap(_multi_device_update_fn)/scan/while/body/pad[ padding_config=((0, 0, 0), (1024, 2048, 0)) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  %add.1819 = f32[16,4096]{1,0} add(f32[16,4096]{1,0} %pad.157, f32[16,4096]{1,0} %pad.156), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %multiply.871 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %param_1.2052, f32[16,1024]{1,0} %bitcast.481), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %param_3.1416 = f32[64,16,1024]{2,1,0} parameter(3)
  %dynamic-slice.352 = f32[1,16,1024]{2,1,0} dynamic-slice(f32[64,16,1024]{2,1,0} %param_3.1416, s32[] %select.1603, s32[] %constant_10727, s32[] %constant_10727), dynamic_slice_sizes={1,16,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %bitcast.480 = f32[16,1024]{1,0} bitcast(f32[1,16,1024]{2,1,0} %dynamic-slice.352), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.870 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %multiply.871, f32[16,1024]{1,0} %bitcast.480), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %multiply.869 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %multiply.870, f32[16,1024]{1,0} %bitcast.483), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %pad.155 = f32[16,4096]{1,0} pad(f32[16,1024]{1,0} %multiply.869, f32[] %constant_10725), padding=0_0x0_3072, metadata={op_type="pad" op_name="pmap(_multi_device_update_fn)/scan/while/body/pad[ padding_config=((0, 0, 0), (0, 3072, 0)) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  %add.1818 = f32[16,4096]{1,0} add(f32[16,4096]{1,0} %add.1819, f32[16,4096]{1,0} %pad.155), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %param_2.1677 = f32[64,16,1024]{2,1,0} parameter(2)
  %dynamic-slice.351 = f32[1,16,1024]{2,1,0} dynamic-slice(f32[64,16,1024]{2,1,0} %param_2.1677, s32[] %select.1603, s32[] %constant_10727, s32[] %constant_10727), dynamic_slice_sizes={1,16,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %bitcast.479 = f32[16,1024]{1,0} bitcast(f32[1,16,1024]{2,1,0} %dynamic-slice.351), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.868 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %bitcast.479, f32[16,1024]{1,0} %param_1.2052), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %param_0.1638 = f32[64,16,1024]{2,1,0} parameter(0)
  %dynamic-slice.350 = f32[1,16,1024]{2,1,0} dynamic-slice(f32[64,16,1024]{2,1,0} %param_0.1638, s32[] %select.1603, s32[] %constant_10727, s32[] %constant_10727), dynamic_slice_sizes={1,16,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %bitcast.478 = f32[16,1024]{1,0} bitcast(f32[1,16,1024]{2,1,0} %dynamic-slice.350), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.867 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %multiply.868, f32[16,1024]{1,0} %bitcast.478), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %param_9.133 = f32[64,16,1024]{2,1,0} parameter(9)
  %dynamic-slice.492 = f32[1,16,1024]{2,1,0} dynamic-slice(f32[64,16,1024]{2,1,0} %param_9.133, s32[] %select.1603, s32[] %constant_10727, s32[] %constant_10727), dynamic_slice_sizes={1,16,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %bitcast.877 = f32[16,1024]{1,0} bitcast(f32[1,16,1024]{2,1,0} %dynamic-slice.492), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.866 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %multiply.867, f32[16,1024]{1,0} %bitcast.877), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %pad.154 = f32[16,4096]{1,0} pad(f32[16,1024]{1,0} %multiply.866, f32[] %constant_10725), padding=0_0x2048_1024, metadata={op_type="pad" op_name="pmap(_multi_device_update_fn)/scan/while/body/pad[ padding_config=((0, 0, 0), (2048, 1024, 0)) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  ROOT %add.1817 = f32[16,4096]{1,0} add(f32[16,4096]{1,0} %add.1818, f32[16,4096]{1,0} %pad.154), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
}

%fused_computation.60 (param_0.1642: f32[64,16,1024], param_1.2063: f32[16,2048], param_2.1684: s32[], param_3.1425: f32[64,16,1024], param_4.638: f32[64,16,1024], param_5.365: f32[64,16,1024]) -> f32[16,1024] {
  %param_1.2063 = f32[16,2048]{1,0} parameter(1)
  %slice.840 = f32[16,1024]{1,0} slice(f32[16,2048]{1,0} %param_1.2063), slice={[0:16], [0:1024]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(16, 1024)\n                                                     start_indices=(0, 0)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=65}
  %param_4.638 = f32[64,16,1024]{2,1,0} parameter(4)
  %constant_12906 = s32[] constant(64), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_2.1684 = s32[] parameter(2)
  %subtract.511 = s32[] subtract(s32[] %constant_12906, s32[] %param_2.1684), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_12905 = s32[] constant(-1)
  %add.2517 = s32[] add(s32[] %subtract.511, s32[] %constant_12905), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_10729 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.1617 = pred[] compare(s32[] %add.2517, s32[] %constant_10729), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_12903 = s32[] constant(63)
  %add.2516 = s32[] add(s32[] %subtract.511, s32[] %constant_12903), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %select.1609 = s32[] select(pred[] %compare.1617, s32[] %add.2516, s32[] %add.2517), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %dynamic-slice.502 = f32[1,16,1024]{2,1,0} dynamic-slice(f32[64,16,1024]{2,1,0} %param_4.638, s32[] %select.1609, s32[] %constant_10729, s32[] %constant_10729), dynamic_slice_sizes={1,16,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %bitcast.887 = f32[16,1024]{1,0} bitcast(f32[1,16,1024]{2,1,0} %dynamic-slice.502), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %slice.978 = f32[16,1024]{1,0} slice(f32[16,2048]{1,0} %param_1.2063), slice={[0:16], [1024:2048]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(16, 2048)\n                                                     start_indices=(0, 1024)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=65}
  %add.2515 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %bitcast.887, f32[16,1024]{1,0} %slice.978), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %param_5.365 = f32[64,16,1024]{2,1,0} parameter(5)
  %dynamic-slice.506 = f32[1,16,1024]{2,1,0} dynamic-slice(f32[64,16,1024]{2,1,0} %param_5.365, s32[] %select.1609, s32[] %constant_10729, s32[] %constant_10729), dynamic_slice_sizes={1,16,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %bitcast.891 = f32[16,1024]{1,0} bitcast(f32[1,16,1024]{2,1,0} %dynamic-slice.506), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.880 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %add.2515, f32[16,1024]{1,0} %bitcast.891), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  %param_0.1642 = f32[64,16,1024]{2,1,0} parameter(0)
  %dynamic-slice.358 = f32[1,16,1024]{2,1,0} dynamic-slice(f32[64,16,1024]{2,1,0} %param_0.1642, s32[] %select.1609, s32[] %constant_10729, s32[] %constant_10729), dynamic_slice_sizes={1,16,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %bitcast.486 = f32[16,1024]{1,0} bitcast(f32[1,16,1024]{2,1,0} %dynamic-slice.358), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.879 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %multiply.880, f32[16,1024]{1,0} %bitcast.486), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  %add.1822 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %slice.840, f32[16,1024]{1,0} %multiply.879), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %param_3.1425 = f32[64,16,1024]{2,1,0} parameter(3)
  %dynamic-slice.498 = f32[1,16,1024]{2,1,0} dynamic-slice(f32[64,16,1024]{2,1,0} %param_3.1425, s32[] %select.1609, s32[] %constant_10729, s32[] %constant_10729), dynamic_slice_sizes={1,16,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %bitcast.883 = f32[16,1024]{1,0} bitcast(f32[1,16,1024]{2,1,0} %dynamic-slice.498), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.878 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %multiply.879, f32[16,1024]{1,0} %bitcast.883), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  ROOT %add.1821 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %add.1822, f32[16,1024]{1,0} %multiply.878), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
}

%fused_computation.64 (param_0.133: f32[64,16,2048], param_1.2034: s32[], param_2.2330: f32[16,1024], param_3.2097: f32[64,16,1024], param_4.1087: f32[16,2048]) -> (f32[16,2048], f32[16,2048]) {
  %param_0.133 = f32[64,16,2048]{2,1,0} parameter(0)
  %constant_12851 = s32[] constant(64), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_1.2034 = s32[] parameter(1)
  %subtract.485 = s32[] subtract(s32[] %constant_12851, s32[] %param_1.2034), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_12850 = s32[] constant(-1)
  %add.2461 = s32[] add(s32[] %subtract.485, s32[] %constant_12850), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_10741 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.1591 = pred[] compare(s32[] %add.2461, s32[] %constant_10741), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_12848 = s32[] constant(63)
  %add.2460 = s32[] add(s32[] %subtract.485, s32[] %constant_12848), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %select.1581 = s32[] select(pred[] %compare.1591, s32[] %add.2460, s32[] %add.2461), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %dynamic-slice.362 = f32[1,16,2048]{2,1,0} dynamic-slice(f32[64,16,2048]{2,1,0} %param_0.133, s32[] %select.1581, s32[] %constant_10741, s32[] %constant_10741), dynamic_slice_sizes={1,16,2048}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 16, 2048) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %bitcast.490 = f32[16,2048]{1,0} bitcast(f32[1,16,2048]{2,1,0} %dynamic-slice.362), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_4.1087 = f32[16,2048]{1,0} parameter(4)
  %slice.839.clone.1 = f32[16,1024]{1,0} slice(f32[16,2048]{1,0} %param_4.1087), slice={[0:16], [1024:2048]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(16, 2048)\n                                                     start_indices=(0, 1024)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %constant_10723_clone_1 = f32[] constant(0), metadata={op_type="pad" op_name="pmap(_multi_device_update_fn)/scan/while/body/pad[ padding_config=((0, 0, 0), (3072, 0, 0)) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  %pad.153.clone.1 = f32[16,2048]{1,0} pad(f32[16,1024]{1,0} %slice.839.clone.1, f32[] %constant_10723_clone_1), padding=0_0x1024_0, metadata={op_type="pad" op_name="pmap(_multi_device_update_fn)/scan/while/body/pad[ padding_config=((0, 0, 0), (1024, 0, 0)) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=54}
  %param_2.2330 = f32[16,1024]{1,0} parameter(2)
  %param_3.2097 = f32[64,16,1024]{2,1,0} parameter(3)
  %dynamic-slice.494.clone.1 = f32[1,16,1024]{2,1,0} dynamic-slice(f32[64,16,1024]{2,1,0} %param_3.2097, s32[] %select.1581, s32[] %constant_10741, s32[] %constant_10741), dynamic_slice_sizes={1,16,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %bitcast.879.clone.1 = f32[16,1024]{1,0} bitcast(f32[1,16,1024]{2,1,0} %dynamic-slice.494.clone.1), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.865.clone.1 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %param_2.2330, f32[16,1024]{1,0} %bitcast.879.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %pad.152.clone.1 = f32[16,2048]{1,0} pad(f32[16,1024]{1,0} %multiply.865.clone.1, f32[] %constant_10723_clone_1), padding=0_0x0_1024, metadata={op_type="pad" op_name="pmap(_multi_device_update_fn)/scan/while/body/pad[ padding_config=((0, 0, 0), (0, 1024, 0)) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=54}
  %add.1815.clone.1 = f32[16,2048]{1,0} add(f32[16,2048]{1,0} %pad.153.clone.1, f32[16,2048]{1,0} %pad.152.clone.1), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  ROOT %tuple.470 = (f32[16,2048]{1,0}, f32[16,2048]{1,0}) tuple(f32[16,2048]{1,0} %bitcast.490, f32[16,2048]{1,0} %add.1815.clone.1)
}

%body_computation__50.10441.clone.clone (parameter.73: (f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[64,16,2048], f32[64,16,1024], /*index=5*/f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], /*index=10*/f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[2048,4096], s32[], /*index=15*/f32[2048,4096], f32[4096], f32[16,2048], f32[64,16,1024])) -> (f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[64,16,2048], f32[64,16,1024], /*index=5*/f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], /*index=10*/f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[2048,4096], s32[], /*index=15*/f32[2048,4096], f32[4096], f32[16,2048], f32[64,16,1024]) {
  %parameter.73 = (f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) parameter(0)
  %get-tuple-element.6623 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.73), index=0
  %get-tuple-element.6624 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.73), index=1
  %get-tuple-element.6625 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.73), index=2
  %get-tuple-element.6626 = f32[64,16,2048]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.73), index=3
  %get-tuple-element.6627 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.73), index=4
  %get-tuple-element.6628 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.73), index=5
  %get-tuple-element.6629 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.73), index=6
  %get-tuple-element.6630 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.73), index=7
  %get-tuple-element.6631 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.73), index=8
  %get-tuple-element.6632 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.73), index=9
  %get-tuple-element.6633 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.73), index=10
  %get-tuple-element.6634 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.73), index=11
  %get-tuple-element.6635 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.73), index=12
  %get-tuple-element.6636 = f32[2048,4096]{1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.73), index=13
  %get-tuple-element.6640 = f32[16,2048]{1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.73), index=17
  %get-tuple-element.6637 = s32[] get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.73), index=14
  %fusion.60 = f32[16,1024]{1,0} fusion(f32[64,16,1024]{2,1,0} %get-tuple-element.6633, f32[16,2048]{1,0} %get-tuple-element.6640, s32[] %get-tuple-element.6637, f32[64,16,1024]{2,1,0} %get-tuple-element.6632, f32[64,16,1024]{2,1,0} %get-tuple-element.6623, /*index=5*/f32[64,16,1024]{2,1,0} %get-tuple-element.6634), kind=kLoop, calls=%fused_computation.60, metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %fusion.58 = f32[16,4096]{1,0} fusion(f32[64,16,1024]{2,1,0} %get-tuple-element.6627, f32[16,1024]{1,0} %fusion.60, f32[64,16,1024]{2,1,0} %get-tuple-element.6625, f32[64,16,1024]{2,1,0} %get-tuple-element.6629, f32[64,16,1024]{2,1,0} %get-tuple-element.6630, /*index=5*/f32[64,16,1024]{2,1,0} %get-tuple-element.6631, f32[64,16,1024]{2,1,0} %get-tuple-element.6628, f32[64,16,1024]{2,1,0} %get-tuple-element.6635, s32[] %get-tuple-element.6637, f32[64,16,1024]{2,1,0} %get-tuple-element.6624, /*index=10*/f32[64,16,1024]{2,1,0} %get-tuple-element.6632, f32[16,2048]{1,0} %get-tuple-element.6640, f32[64,16,1024]{2,1,0} %get-tuple-element.6623, f32[64,16,1024]{2,1,0} %get-tuple-element.6634), kind=kLoop, calls=%fused_computation.58, metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %custom-call.109 = f32[16,2048]{1,0} custom-call(f32[16,4096]{1,0} %fusion.58, f32[2048,4096]{1,0} %get-tuple-element.6636), custom_call_target="__cublas$gemm", metadata={op_type="dot_general" op_name="pmap(_multi_device_update_fn)/scan/while/body/dot_general[ dimension_numbers=(((1,), (1,)), ((), ()))\n                                                           precision=None\n                                                           preferred_element_type=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}, backend_config="{\"alpha_real\":1,\"alpha_imag\":0,\"beta\":0,\"dot_dimension_numbers\":{\"lhs_contracting_dimensions\":[\"1\"],\"rhs_contracting_dimensions\":[\"1\"],\"lhs_batch_dimensions\":[],\"rhs_batch_dimensions\":[]},\"batch_size\":\"1\",\"selected_algorithm\":\"-1\"}"
  %fusion.64 = (f32[16,2048]{1,0}, f32[16,2048]{1,0}) fusion(f32[64,16,2048]{2,1,0} %get-tuple-element.6626, s32[] %get-tuple-element.6637, f32[16,1024]{1,0} %fusion.60, f32[64,16,1024]{2,1,0} %get-tuple-element.6624, f32[16,2048]{1,0} %custom-call.109), kind=kLoop, calls=%fused_computation.64, control-predecessors={%fusion.60, %fusion.58}, metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.6641 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.73), index=18
  %fusion.55 = f32[64,16,1024]{2,1,0} fusion(f32[64,16,1024]{2,1,0} %get-tuple-element.6641, f32[16,2048]{1,0} %custom-call.109, s32[] %get-tuple-element.6637), kind=kLoop, calls=%fused_computation.55, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_8950 = s32[] constant(1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.1436 = s32[] add(s32[] %get-tuple-element.6637, s32[] %constant_8950), control-predecessors={%fusion.55, %fusion.64, %fusion.60, %fusion.58}, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.5046 = f32[16,2048]{1,0} get-tuple-element((f32[16,2048]{1,0}, f32[16,2048]{1,0}) %fusion.64), index=0
  %get-tuple-element.6638 = f32[2048,4096]{1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.73), index=15
  %custom-call.108 = f32[2048,4096]{1,0} custom-call(f32[16,2048]{1,0} %get-tuple-element.5046, f32[16,4096]{1,0} %fusion.58, f32[2048,4096]{1,0} %get-tuple-element.6638), custom_call_target="__cublas$gemm", metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}, backend_config="{\"alpha_real\":1,\"alpha_imag\":0,\"beta\":1,\"dot_dimension_numbers\":{\"lhs_contracting_dimensions\":[\"0\"],\"rhs_contracting_dimensions\":[\"0\"],\"lhs_batch_dimensions\":[],\"rhs_batch_dimensions\":[]},\"batch_size\":\"1\",\"selected_algorithm\":\"4\"}"
  %get-tuple-element.6639 = f32[4096]{0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.73), index=16
  %fusion.57 = f32[4096]{0} fusion(f32[4096]{0} %get-tuple-element.6639, f32[16,4096]{1,0} %fusion.58), kind=kLoop, calls=%fused_computation.57, metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %get-tuple-element.5047 = f32[16,2048]{1,0} get-tuple-element((f32[16,2048]{1,0}, f32[16,2048]{1,0}) %fusion.64), index=1
  ROOT %tuple.829 = (f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) tuple(f32[64,16,1024]{2,1,0} %get-tuple-element.6623, f32[64,16,1024]{2,1,0} %get-tuple-element.6624, f32[64,16,1024]{2,1,0} %get-tuple-element.6625, f32[64,16,2048]{2,1,0} %get-tuple-element.6626, f32[64,16,1024]{2,1,0} %get-tuple-element.6627, /*index=5*/f32[64,16,1024]{2,1,0} %get-tuple-element.6628, f32[64,16,1024]{2,1,0} %get-tuple-element.6629, f32[64,16,1024]{2,1,0} %get-tuple-element.6630, f32[64,16,1024]{2,1,0} %get-tuple-element.6631, f32[64,16,1024]{2,1,0} %get-tuple-element.6632, /*index=10*/f32[64,16,1024]{2,1,0} %get-tuple-element.6633, f32[64,16,1024]{2,1,0} %get-tuple-element.6634, f32[64,16,1024]{2,1,0} %get-tuple-element.6635, f32[2048,4096]{1,0} %get-tuple-element.6636, s32[] %add.1436, /*index=15*/f32[2048,4096]{1,0} %custom-call.108, f32[4096]{0} %fusion.57, f32[16,2048]{1,0} %get-tuple-element.5047, f32[64,16,1024]{2,1,0} %fusion.55)
}

%cond_computation__50.10852.clone.clone (parameter.74: (f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[64,16,2048], f32[64,16,1024], /*index=5*/f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], /*index=10*/f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[2048,4096], s32[], /*index=15*/f32[2048,4096], f32[4096], f32[16,2048], f32[64,16,1024])) -> pred[] {
  %parameter.74 = (f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) parameter(0)
  %get-tuple-element.3644 = s32[] get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.74), index=14
  %constant_8959 = s32[] constant(64), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/cond/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %compare.1182 = pred[] compare(s32[] %get-tuple-element.3644, s32[] %constant_8959), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/cond/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.66 (param_0.138: f32[64,16,1024], param_1.2084: f32[16,2048], param_2.1716: s32[]) -> f32[64,16,1024] {
  %param_0.138 = f32[64,16,1024]{2,1,0} parameter(0)
  %param_1.2084 = f32[16,2048]{1,0} parameter(1)
  %slice.842 = f32[16,1024]{1,0} slice(f32[16,2048]{1,0} %param_1.2084), slice={[0:16], [0:1024]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(16, 1024)\n                                                     start_indices=(0, 0)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %bitcast.491 = f32[1,16,1024]{2,1,0} bitcast(f32[16,1024]{1,0} %slice.842), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_13098 = s32[] constant(64), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_2.1716 = s32[] parameter(2)
  %subtract.531 = s32[] subtract(s32[] %constant_13098, s32[] %param_2.1716), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_13097 = s32[] constant(-1)
  %add.2557 = s32[] add(s32[] %subtract.531, s32[] %constant_13097), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_10746 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.1638 = pred[] compare(s32[] %add.2557, s32[] %constant_10746), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_13095 = s32[] constant(63)
  %add.2556 = s32[] add(s32[] %subtract.531, s32[] %constant_13095), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %select.1629 = s32[] select(pred[] %compare.1638, s32[] %add.2556, s32[] %add.2557), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.497 = f32[64,16,1024]{2,1,0} dynamic-update-slice(f32[64,16,1024]{2,1,0} %param_0.138, f32[1,16,1024]{2,1,0} %bitcast.491, s32[] %select.1629, s32[] %constant_10746, s32[] %constant_10746), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%primitive_computation_add__1.10945 (parameter.10946: f32[], parameter.10947: f32[]) -> f32[] {
  %parameter.10946 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.10947 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.10948 = f32[] add(f32[] %parameter.10946, f32[] %parameter.10947), metadata={op_type="add" op_name="add"}
}

%fused_computation.68 (param_0.141: f32[4096], param_1.193: f32[16,4096]) -> f32[4096] {
  %param_0.141 = f32[4096]{0} parameter(0)
  %param_1.193 = f32[16,4096]{1,0} parameter(1)
  %constant_10748 = f32[] constant(0), metadata={op_type="pad" op_name="pmap(_multi_device_update_fn)/scan/while/body/pad[ padding_config=((0, 0, 0), (3072, 0, 0)) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  %reduce.179 = f32[4096]{0} reduce(f32[16,4096]{1,0} %param_1.193, f32[] %constant_10748), dimensions={0}, to_apply=%primitive_computation_add__1.10945, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/scan/while/body/reduce_sum[ axes=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  ROOT %add.1827 = f32[4096]{0} add(f32[4096]{0} %param_0.141, f32[4096]{0} %reduce.179), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
}

%fused_computation.69 (param_0.1656: f32[64,16,1024], param_1.2086: f32[16,1024], param_2.1717: f32[64,16,1024], param_3.1450: f32[64,16,1024], param_4.651: f32[64,16,1024], param_5.374: f32[64,16,1024], param_6.349: f32[64,16,1024], param_7.339: f32[64,16,1024], param_8.234: s32[], param_9.141: f32[64,16,1024], param_10.139: f32[64,16,1024], param_11.166: f32[16,2048], param_12.170: f32[64,16,1024], param_13.197: f32[64,16,1024]) -> f32[16,4096] {
  %param_10.139 = f32[64,16,1024]{2,1,0} parameter(10)
  %constant_13055 = s32[] constant(64), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_8.234 = s32[] parameter(8)
  %subtract.537 = s32[] subtract(s32[] %constant_13055, s32[] %param_8.234), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_13054 = s32[] constant(-1)
  %add.2570 = s32[] add(s32[] %subtract.537, s32[] %constant_13054), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_10752 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.1644 = pred[] compare(s32[] %add.2570, s32[] %constant_10752), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_13052 = s32[] constant(63)
  %add.2569 = s32[] add(s32[] %subtract.537, s32[] %constant_13052), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %select.1635 = s32[] select(pred[] %compare.1644, s32[] %add.2569, s32[] %add.2570), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %dynamic-slice.512 = f32[1,16,1024]{2,1,0} dynamic-slice(f32[64,16,1024]{2,1,0} %param_10.139, s32[] %select.1635, s32[] %constant_10752, s32[] %constant_10752), dynamic_slice_sizes={1,16,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %bitcast.897 = f32[16,1024]{1,0} bitcast(f32[1,16,1024]{2,1,0} %dynamic-slice.512), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_12.170 = f32[64,16,1024]{2,1,0} parameter(12)
  %dynamic-slice.516 = f32[1,16,1024]{2,1,0} dynamic-slice(f32[64,16,1024]{2,1,0} %param_12.170, s32[] %select.1635, s32[] %constant_10752, s32[] %constant_10752), dynamic_slice_sizes={1,16,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %bitcast.901 = f32[16,1024]{1,0} bitcast(f32[1,16,1024]{2,1,0} %dynamic-slice.516), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_11.166 = f32[16,2048]{1,0} parameter(11)
  %slice.980 = f32[16,1024]{1,0} slice(f32[16,2048]{1,0} %param_11.166), slice={[0:16], [1024:2048]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(16, 2048)\n                                                     start_indices=(0, 1024)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=65}
  %add.2579 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %bitcast.901, f32[16,1024]{1,0} %slice.980), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %multiply.893 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %bitcast.897, f32[16,1024]{1,0} %add.2579), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  %param_7.339 = f32[64,16,1024]{2,1,0} parameter(7)
  %dynamic-slice.369 = f32[1,16,1024]{2,1,0} dynamic-slice(f32[64,16,1024]{2,1,0} %param_7.339, s32[] %select.1635, s32[] %constant_10752, s32[] %constant_10752), dynamic_slice_sizes={1,16,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %bitcast.498 = f32[16,1024]{1,0} bitcast(f32[1,16,1024]{2,1,0} %dynamic-slice.369), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.892 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %multiply.893, f32[16,1024]{1,0} %bitcast.498), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %param_13.197 = f32[64,16,1024]{2,1,0} parameter(13)
  %dynamic-slice.520 = f32[1,16,1024]{2,1,0} dynamic-slice(f32[64,16,1024]{2,1,0} %param_13.197, s32[] %select.1635, s32[] %constant_10752, s32[] %constant_10752), dynamic_slice_sizes={1,16,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %bitcast.905 = f32[16,1024]{1,0} bitcast(f32[1,16,1024]{2,1,0} %dynamic-slice.520), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.891 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %multiply.892, f32[16,1024]{1,0} %bitcast.905), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %constant_10750 = f32[] constant(0), metadata={op_type="pad" op_name="pmap(_multi_device_update_fn)/scan/while/body/pad[ padding_config=((0, 0, 0), (3072, 0, 0)) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  %pad.163 = f32[16,4096]{1,0} pad(f32[16,1024]{1,0} %multiply.891, f32[] %constant_10750), padding=0_0x3072_0, metadata={op_type="pad" op_name="pmap(_multi_device_update_fn)/scan/while/body/pad[ padding_config=((0, 0, 0), (3072, 0, 0)) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  %param_6.349 = f32[64,16,1024]{2,1,0} parameter(6)
  %dynamic-slice.368 = f32[1,16,1024]{2,1,0} dynamic-slice(f32[64,16,1024]{2,1,0} %param_6.349, s32[] %select.1635, s32[] %constant_10752, s32[] %constant_10752), dynamic_slice_sizes={1,16,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %bitcast.497 = f32[16,1024]{1,0} bitcast(f32[1,16,1024]{2,1,0} %dynamic-slice.368), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_1.2086 = f32[16,1024]{1,0} parameter(1)
  %multiply.890 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %bitcast.497, f32[16,1024]{1,0} %param_1.2086), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %param_5.374 = f32[64,16,1024]{2,1,0} parameter(5)
  %dynamic-slice.367 = f32[1,16,1024]{2,1,0} dynamic-slice(f32[64,16,1024]{2,1,0} %param_5.374, s32[] %select.1635, s32[] %constant_10752, s32[] %constant_10752), dynamic_slice_sizes={1,16,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %bitcast.496 = f32[16,1024]{1,0} bitcast(f32[1,16,1024]{2,1,0} %dynamic-slice.367), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.889 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %multiply.890, f32[16,1024]{1,0} %bitcast.496), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %param_4.651 = f32[64,16,1024]{2,1,0} parameter(4)
  %dynamic-slice.366 = f32[1,16,1024]{2,1,0} dynamic-slice(f32[64,16,1024]{2,1,0} %param_4.651, s32[] %select.1635, s32[] %constant_10752, s32[] %constant_10752), dynamic_slice_sizes={1,16,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %bitcast.495 = f32[16,1024]{1,0} bitcast(f32[1,16,1024]{2,1,0} %dynamic-slice.366), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.888 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %multiply.889, f32[16,1024]{1,0} %bitcast.495), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %add.1831 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %multiply.889, f32[16,1024]{1,0} %multiply.888), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %pad.162 = f32[16,4096]{1,0} pad(f32[16,1024]{1,0} %add.1831, f32[] %constant_10750), padding=0_0x1024_2048, metadata={op_type="pad" op_name="pmap(_multi_device_update_fn)/scan/while/body/pad[ padding_config=((0, 0, 0), (1024, 2048, 0)) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  %add.1830 = f32[16,4096]{1,0} add(f32[16,4096]{1,0} %pad.163, f32[16,4096]{1,0} %pad.162), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %multiply.887 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %param_1.2086, f32[16,1024]{1,0} %bitcast.495), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %param_3.1450 = f32[64,16,1024]{2,1,0} parameter(3)
  %dynamic-slice.365 = f32[1,16,1024]{2,1,0} dynamic-slice(f32[64,16,1024]{2,1,0} %param_3.1450, s32[] %select.1635, s32[] %constant_10752, s32[] %constant_10752), dynamic_slice_sizes={1,16,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %bitcast.494 = f32[16,1024]{1,0} bitcast(f32[1,16,1024]{2,1,0} %dynamic-slice.365), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.886 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %multiply.887, f32[16,1024]{1,0} %bitcast.494), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %multiply.885 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %multiply.886, f32[16,1024]{1,0} %bitcast.497), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %pad.161 = f32[16,4096]{1,0} pad(f32[16,1024]{1,0} %multiply.885, f32[] %constant_10750), padding=0_0x0_3072, metadata={op_type="pad" op_name="pmap(_multi_device_update_fn)/scan/while/body/pad[ padding_config=((0, 0, 0), (0, 3072, 0)) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  %add.1829 = f32[16,4096]{1,0} add(f32[16,4096]{1,0} %add.1830, f32[16,4096]{1,0} %pad.161), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %param_2.1717 = f32[64,16,1024]{2,1,0} parameter(2)
  %dynamic-slice.364 = f32[1,16,1024]{2,1,0} dynamic-slice(f32[64,16,1024]{2,1,0} %param_2.1717, s32[] %select.1635, s32[] %constant_10752, s32[] %constant_10752), dynamic_slice_sizes={1,16,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %bitcast.493 = f32[16,1024]{1,0} bitcast(f32[1,16,1024]{2,1,0} %dynamic-slice.364), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.884 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %bitcast.493, f32[16,1024]{1,0} %param_1.2086), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %param_0.1656 = f32[64,16,1024]{2,1,0} parameter(0)
  %dynamic-slice.363 = f32[1,16,1024]{2,1,0} dynamic-slice(f32[64,16,1024]{2,1,0} %param_0.1656, s32[] %select.1635, s32[] %constant_10752, s32[] %constant_10752), dynamic_slice_sizes={1,16,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %bitcast.492 = f32[16,1024]{1,0} bitcast(f32[1,16,1024]{2,1,0} %dynamic-slice.363), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.883 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %multiply.884, f32[16,1024]{1,0} %bitcast.492), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %param_9.141 = f32[64,16,1024]{2,1,0} parameter(9)
  %dynamic-slice.508 = f32[1,16,1024]{2,1,0} dynamic-slice(f32[64,16,1024]{2,1,0} %param_9.141, s32[] %select.1635, s32[] %constant_10752, s32[] %constant_10752), dynamic_slice_sizes={1,16,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %bitcast.893 = f32[16,1024]{1,0} bitcast(f32[1,16,1024]{2,1,0} %dynamic-slice.508), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.882 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %multiply.883, f32[16,1024]{1,0} %bitcast.893), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %pad.160 = f32[16,4096]{1,0} pad(f32[16,1024]{1,0} %multiply.882, f32[] %constant_10750), padding=0_0x2048_1024, metadata={op_type="pad" op_name="pmap(_multi_device_update_fn)/scan/while/body/pad[ padding_config=((0, 0, 0), (2048, 1024, 0)) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  ROOT %add.1828 = f32[16,4096]{1,0} add(f32[16,4096]{1,0} %add.1829, f32[16,4096]{1,0} %pad.160), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
}

%fused_computation.71 (param_0.1660: f32[64,16,1024], param_1.2097: f32[16,2048], param_2.1724: s32[], param_3.1459: f32[64,16,1024], param_4.660: f32[64,16,1024], param_5.384: f32[64,16,1024]) -> f32[16,1024] {
  %param_1.2097 = f32[16,2048]{1,0} parameter(1)
  %slice.844 = f32[16,1024]{1,0} slice(f32[16,2048]{1,0} %param_1.2097), slice={[0:16], [0:1024]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(16, 1024)\n                                                     start_indices=(0, 0)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=65}
  %param_4.660 = f32[64,16,1024]{2,1,0} parameter(4)
  %constant_13087 = s32[] constant(64), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_2.1724 = s32[] parameter(2)
  %subtract.543 = s32[] subtract(s32[] %constant_13087, s32[] %param_2.1724), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_13086 = s32[] constant(-1)
  %add.2588 = s32[] add(s32[] %subtract.543, s32[] %constant_13086), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_10753 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.1650 = pred[] compare(s32[] %add.2588, s32[] %constant_10753), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_13083 = s32[] constant(63)
  %add.2587 = s32[] add(s32[] %subtract.543, s32[] %constant_13083), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %select.1641 = s32[] select(pred[] %compare.1650, s32[] %add.2587, s32[] %add.2588), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %dynamic-slice.518 = f32[1,16,1024]{2,1,0} dynamic-slice(f32[64,16,1024]{2,1,0} %param_4.660, s32[] %select.1641, s32[] %constant_10753, s32[] %constant_10753), dynamic_slice_sizes={1,16,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %bitcast.903 = f32[16,1024]{1,0} bitcast(f32[1,16,1024]{2,1,0} %dynamic-slice.518), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %slice.982 = f32[16,1024]{1,0} slice(f32[16,2048]{1,0} %param_1.2097), slice={[0:16], [1024:2048]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(16, 2048)\n                                                     start_indices=(0, 1024)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=65}
  %add.2586 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %bitcast.903, f32[16,1024]{1,0} %slice.982), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %param_5.384 = f32[64,16,1024]{2,1,0} parameter(5)
  %dynamic-slice.522 = f32[1,16,1024]{2,1,0} dynamic-slice(f32[64,16,1024]{2,1,0} %param_5.384, s32[] %select.1641, s32[] %constant_10753, s32[] %constant_10753), dynamic_slice_sizes={1,16,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %bitcast.907 = f32[16,1024]{1,0} bitcast(f32[1,16,1024]{2,1,0} %dynamic-slice.522), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.896 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %add.2586, f32[16,1024]{1,0} %bitcast.907), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  %param_0.1660 = f32[64,16,1024]{2,1,0} parameter(0)
  %dynamic-slice.371 = f32[1,16,1024]{2,1,0} dynamic-slice(f32[64,16,1024]{2,1,0} %param_0.1660, s32[] %select.1641, s32[] %constant_10753, s32[] %constant_10753), dynamic_slice_sizes={1,16,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %bitcast.500 = f32[16,1024]{1,0} bitcast(f32[1,16,1024]{2,1,0} %dynamic-slice.371), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.895 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %multiply.896, f32[16,1024]{1,0} %bitcast.500), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  %add.1833 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %slice.844, f32[16,1024]{1,0} %multiply.895), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %param_3.1459 = f32[64,16,1024]{2,1,0} parameter(3)
  %dynamic-slice.514 = f32[1,16,1024]{2,1,0} dynamic-slice(f32[64,16,1024]{2,1,0} %param_3.1459, s32[] %select.1641, s32[] %constant_10753, s32[] %constant_10753), dynamic_slice_sizes={1,16,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %bitcast.899 = f32[16,1024]{1,0} bitcast(f32[1,16,1024]{2,1,0} %dynamic-slice.514), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.894 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %multiply.895, f32[16,1024]{1,0} %bitcast.899), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  ROOT %add.1832 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %add.1833, f32[16,1024]{1,0} %multiply.894), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
}

%fused_computation.75 (param_0.156: f32[64,16,2048], param_1.2068: s32[], param_2.2333: f32[16,1024], param_3.2102: f32[64,16,1024], param_4.1092: f32[16,2048]) -> (f32[16,2048], f32[16,2048]) {
  %param_0.156 = f32[64,16,2048]{2,1,0} parameter(0)
  %constant_13023 = s32[] constant(64), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_1.2068 = s32[] parameter(1)
  %subtract.517 = s32[] subtract(s32[] %constant_13023, s32[] %param_1.2068), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_13022 = s32[] constant(-1)
  %add.2529 = s32[] add(s32[] %subtract.517, s32[] %constant_13022), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_10767 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.1623 = pred[] compare(s32[] %add.2529, s32[] %constant_10767), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_13020 = s32[] constant(63)
  %add.2528 = s32[] add(s32[] %subtract.517, s32[] %constant_13020), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %select.1615 = s32[] select(pred[] %compare.1623, s32[] %add.2528, s32[] %add.2529), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %dynamic-slice.375 = f32[1,16,2048]{2,1,0} dynamic-slice(f32[64,16,2048]{2,1,0} %param_0.156, s32[] %select.1615, s32[] %constant_10767, s32[] %constant_10767), dynamic_slice_sizes={1,16,2048}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 16, 2048) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %bitcast.504 = f32[16,2048]{1,0} bitcast(f32[1,16,2048]{2,1,0} %dynamic-slice.375), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_4.1092 = f32[16,2048]{1,0} parameter(4)
  %slice.843.clone.1 = f32[16,1024]{1,0} slice(f32[16,2048]{1,0} %param_4.1092), slice={[0:16], [1024:2048]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(16, 2048)\n                                                     start_indices=(0, 1024)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %constant_10747_clone_1 = f32[] constant(0), metadata={op_type="pad" op_name="pmap(_multi_device_update_fn)/scan/while/body/pad[ padding_config=((0, 0, 0), (3072, 0, 0)) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  %pad.159.clone.1 = f32[16,2048]{1,0} pad(f32[16,1024]{1,0} %slice.843.clone.1, f32[] %constant_10747_clone_1), padding=0_0x1024_0, metadata={op_type="pad" op_name="pmap(_multi_device_update_fn)/scan/while/body/pad[ padding_config=((0, 0, 0), (1024, 0, 0)) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=54}
  %param_2.2333 = f32[16,1024]{1,0} parameter(2)
  %param_3.2102 = f32[64,16,1024]{2,1,0} parameter(3)
  %dynamic-slice.510.clone.1 = f32[1,16,1024]{2,1,0} dynamic-slice(f32[64,16,1024]{2,1,0} %param_3.2102, s32[] %select.1615, s32[] %constant_10767, s32[] %constant_10767), dynamic_slice_sizes={1,16,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %bitcast.895.clone.1 = f32[16,1024]{1,0} bitcast(f32[1,16,1024]{2,1,0} %dynamic-slice.510.clone.1), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.881.clone.1 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %param_2.2333, f32[16,1024]{1,0} %bitcast.895.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %pad.158.clone.1 = f32[16,2048]{1,0} pad(f32[16,1024]{1,0} %multiply.881.clone.1, f32[] %constant_10747_clone_1), padding=0_0x0_1024, metadata={op_type="pad" op_name="pmap(_multi_device_update_fn)/scan/while/body/pad[ padding_config=((0, 0, 0), (0, 1024, 0)) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=54}
  %add.1826.clone.1 = f32[16,2048]{1,0} add(f32[16,2048]{1,0} %pad.159.clone.1, f32[16,2048]{1,0} %pad.158.clone.1), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  ROOT %tuple.471 = (f32[16,2048]{1,0}, f32[16,2048]{1,0}) tuple(f32[16,2048]{1,0} %bitcast.504, f32[16,2048]{1,0} %add.1826.clone.1)
}

%body_computation__51.10953.clone.clone (parameter.75: (f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[64,16,2048], f32[64,16,1024], /*index=5*/f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], /*index=10*/f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[2048,4096], s32[], /*index=15*/f32[2048,4096], f32[4096], f32[16,2048], f32[64,16,1024])) -> (f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[64,16,2048], f32[64,16,1024], /*index=5*/f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], /*index=10*/f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[2048,4096], s32[], /*index=15*/f32[2048,4096], f32[4096], f32[16,2048], f32[64,16,1024]) {
  %parameter.75 = (f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) parameter(0)
  %get-tuple-element.6680 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.75), index=0
  %get-tuple-element.6681 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.75), index=1
  %get-tuple-element.6682 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.75), index=2
  %get-tuple-element.6683 = f32[64,16,2048]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.75), index=3
  %get-tuple-element.6684 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.75), index=4
  %get-tuple-element.6685 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.75), index=5
  %get-tuple-element.6686 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.75), index=6
  %get-tuple-element.6687 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.75), index=7
  %get-tuple-element.6688 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.75), index=8
  %get-tuple-element.6689 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.75), index=9
  %get-tuple-element.6690 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.75), index=10
  %get-tuple-element.6691 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.75), index=11
  %get-tuple-element.6714 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.75), index=12
  %get-tuple-element.6715 = f32[2048,4096]{1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.75), index=13
  %get-tuple-element.6760 = f32[16,2048]{1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.75), index=17
  %get-tuple-element.6716 = s32[] get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.75), index=14
  %fusion.71 = f32[16,1024]{1,0} fusion(f32[64,16,1024]{2,1,0} %get-tuple-element.6690, f32[16,2048]{1,0} %get-tuple-element.6760, s32[] %get-tuple-element.6716, f32[64,16,1024]{2,1,0} %get-tuple-element.6689, f32[64,16,1024]{2,1,0} %get-tuple-element.6680, /*index=5*/f32[64,16,1024]{2,1,0} %get-tuple-element.6691), kind=kLoop, calls=%fused_computation.71, metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %fusion.69 = f32[16,4096]{1,0} fusion(f32[64,16,1024]{2,1,0} %get-tuple-element.6684, f32[16,1024]{1,0} %fusion.71, f32[64,16,1024]{2,1,0} %get-tuple-element.6682, f32[64,16,1024]{2,1,0} %get-tuple-element.6686, f32[64,16,1024]{2,1,0} %get-tuple-element.6687, /*index=5*/f32[64,16,1024]{2,1,0} %get-tuple-element.6688, f32[64,16,1024]{2,1,0} %get-tuple-element.6685, f32[64,16,1024]{2,1,0} %get-tuple-element.6714, s32[] %get-tuple-element.6716, f32[64,16,1024]{2,1,0} %get-tuple-element.6681, /*index=10*/f32[64,16,1024]{2,1,0} %get-tuple-element.6689, f32[16,2048]{1,0} %get-tuple-element.6760, f32[64,16,1024]{2,1,0} %get-tuple-element.6680, f32[64,16,1024]{2,1,0} %get-tuple-element.6691), kind=kLoop, calls=%fused_computation.69, metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %custom-call.112 = f32[16,2048]{1,0} custom-call(f32[16,4096]{1,0} %fusion.69, f32[2048,4096]{1,0} %get-tuple-element.6715), custom_call_target="__cublas$gemm", metadata={op_type="dot_general" op_name="pmap(_multi_device_update_fn)/scan/while/body/dot_general[ dimension_numbers=(((1,), (1,)), ((), ()))\n                                                           precision=None\n                                                           preferred_element_type=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}, backend_config="{\"alpha_real\":1,\"alpha_imag\":0,\"beta\":0,\"dot_dimension_numbers\":{\"lhs_contracting_dimensions\":[\"1\"],\"rhs_contracting_dimensions\":[\"1\"],\"lhs_batch_dimensions\":[],\"rhs_batch_dimensions\":[]},\"batch_size\":\"1\",\"selected_algorithm\":\"-1\"}"
  %fusion.75 = (f32[16,2048]{1,0}, f32[16,2048]{1,0}) fusion(f32[64,16,2048]{2,1,0} %get-tuple-element.6683, s32[] %get-tuple-element.6716, f32[16,1024]{1,0} %fusion.71, f32[64,16,1024]{2,1,0} %get-tuple-element.6681, f32[16,2048]{1,0} %custom-call.112), kind=kLoop, calls=%fused_computation.75, control-predecessors={%fusion.71, %fusion.69}, metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.6779 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.75), index=18
  %fusion.66 = f32[64,16,1024]{2,1,0} fusion(f32[64,16,1024]{2,1,0} %get-tuple-element.6779, f32[16,2048]{1,0} %custom-call.112, s32[] %get-tuple-element.6716), kind=kLoop, calls=%fused_computation.66, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_9097 = s32[] constant(1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.1482 = s32[] add(s32[] %get-tuple-element.6716, s32[] %constant_9097), control-predecessors={%fusion.66, %fusion.75, %fusion.71, %fusion.69}, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.5048 = f32[16,2048]{1,0} get-tuple-element((f32[16,2048]{1,0}, f32[16,2048]{1,0}) %fusion.75), index=0
  %get-tuple-element.6717 = f32[2048,4096]{1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.75), index=15
  %custom-call.111 = f32[2048,4096]{1,0} custom-call(f32[16,2048]{1,0} %get-tuple-element.5048, f32[16,4096]{1,0} %fusion.69, f32[2048,4096]{1,0} %get-tuple-element.6717), custom_call_target="__cublas$gemm", metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}, backend_config="{\"alpha_real\":1,\"alpha_imag\":0,\"beta\":1,\"dot_dimension_numbers\":{\"lhs_contracting_dimensions\":[\"0\"],\"rhs_contracting_dimensions\":[\"0\"],\"lhs_batch_dimensions\":[],\"rhs_batch_dimensions\":[]},\"batch_size\":\"1\",\"selected_algorithm\":\"4\"}"
  %get-tuple-element.6740 = f32[4096]{0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.75), index=16
  %fusion.68 = f32[4096]{0} fusion(f32[4096]{0} %get-tuple-element.6740, f32[16,4096]{1,0} %fusion.69), kind=kLoop, calls=%fused_computation.68, metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %get-tuple-element.5049 = f32[16,2048]{1,0} get-tuple-element((f32[16,2048]{1,0}, f32[16,2048]{1,0}) %fusion.75), index=1
  ROOT %tuple.832 = (f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) tuple(f32[64,16,1024]{2,1,0} %get-tuple-element.6680, f32[64,16,1024]{2,1,0} %get-tuple-element.6681, f32[64,16,1024]{2,1,0} %get-tuple-element.6682, f32[64,16,2048]{2,1,0} %get-tuple-element.6683, f32[64,16,1024]{2,1,0} %get-tuple-element.6684, /*index=5*/f32[64,16,1024]{2,1,0} %get-tuple-element.6685, f32[64,16,1024]{2,1,0} %get-tuple-element.6686, f32[64,16,1024]{2,1,0} %get-tuple-element.6687, f32[64,16,1024]{2,1,0} %get-tuple-element.6688, f32[64,16,1024]{2,1,0} %get-tuple-element.6689, /*index=10*/f32[64,16,1024]{2,1,0} %get-tuple-element.6690, f32[64,16,1024]{2,1,0} %get-tuple-element.6691, f32[64,16,1024]{2,1,0} %get-tuple-element.6714, f32[2048,4096]{1,0} %get-tuple-element.6715, s32[] %add.1482, /*index=15*/f32[2048,4096]{1,0} %custom-call.111, f32[4096]{0} %fusion.68, f32[16,2048]{1,0} %get-tuple-element.5049, f32[64,16,1024]{2,1,0} %fusion.66)
}

%cond_computation__51.11364.clone.clone (parameter.76: (f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[64,16,2048], f32[64,16,1024], /*index=5*/f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], /*index=10*/f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[2048,4096], s32[], /*index=15*/f32[2048,4096], f32[4096], f32[16,2048], f32[64,16,1024])) -> pred[] {
  %parameter.76 = (f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) parameter(0)
  %get-tuple-element.3705 = s32[] get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.76), index=14
  %constant_9103 = s32[] constant(64), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/cond/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %compare.1197 = pred[] compare(s32[] %get-tuple-element.3705, s32[] %constant_9103), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/cond/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.77 (param_0.161: f32[64,16,1024], param_1.2118: f32[16,2048], param_2.1756: s32[]) -> f32[64,16,1024] {
  %param_0.161 = f32[64,16,1024]{2,1,0} parameter(0)
  %param_1.2118 = f32[16,2048]{1,0} parameter(1)
  %slice.846 = f32[16,1024]{1,0} slice(f32[16,2048]{1,0} %param_1.2118), slice={[0:16], [0:1024]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(16, 1024)\n                                                     start_indices=(0, 0)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %bitcast.505 = f32[1,16,1024]{2,1,0} bitcast(f32[16,1024]{1,0} %slice.846), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_13291 = s32[] constant(64), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_2.1756 = s32[] parameter(2)
  %subtract.563 = s32[] subtract(s32[] %constant_13291, s32[] %param_2.1756), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_13290 = s32[] constant(-1)
  %add.2633 = s32[] add(s32[] %subtract.563, s32[] %constant_13290), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_10770 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.1670 = pred[] compare(s32[] %add.2633, s32[] %constant_10770), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_13287 = s32[] constant(63)
  %add.2632 = s32[] add(s32[] %subtract.563, s32[] %constant_13287), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %select.1661 = s32[] select(pred[] %compare.1670, s32[] %add.2632, s32[] %add.2633), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.498 = f32[64,16,1024]{2,1,0} dynamic-update-slice(f32[64,16,1024]{2,1,0} %param_0.161, f32[1,16,1024]{2,1,0} %bitcast.505, s32[] %select.1661, s32[] %constant_10770, s32[] %constant_10770), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%primitive_computation_add__1.11457 (parameter.11458: f32[], parameter.11459: f32[]) -> f32[] {
  %parameter.11458 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.11459 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.11460 = f32[] add(f32[] %parameter.11458, f32[] %parameter.11459), metadata={op_type="add" op_name="add"}
}

%fused_computation.79 (param_0.164: f32[4096], param_1.224: f32[16,4096]) -> f32[4096] {
  %param_0.164 = f32[4096]{0} parameter(0)
  %param_1.224 = f32[16,4096]{1,0} parameter(1)
  %constant_10772 = f32[] constant(0), metadata={op_type="pad" op_name="pmap(_multi_device_update_fn)/scan/while/body/pad[ padding_config=((0, 0, 0), (3072, 0, 0)) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  %reduce.180 = f32[4096]{0} reduce(f32[16,4096]{1,0} %param_1.224, f32[] %constant_10772), dimensions={0}, to_apply=%primitive_computation_add__1.11457, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/scan/while/body/reduce_sum[ axes=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  ROOT %add.1838 = f32[4096]{0} add(f32[4096]{0} %param_0.164, f32[4096]{0} %reduce.180), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
}

%fused_computation.80 (param_0.1674: f32[64,16,1024], param_1.2120: f32[16,1024], param_2.1757: f32[64,16,1024], param_3.1484: f32[64,16,1024], param_4.673: f32[64,16,1024], param_5.393: f32[64,16,1024], param_6.373: f32[64,16,1024], param_7.360: f32[64,16,1024], param_8.247: s32[], param_9.149: f32[64,16,1024], param_10.144: f32[64,16,1024], param_11.171: f32[16,2048], param_12.182: f32[64,16,1024], param_13.218: f32[64,16,1024]) -> f32[16,4096] {
  %param_10.144 = f32[64,16,1024]{2,1,0} parameter(10)
  %constant_13248 = s32[] constant(64), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_8.247 = s32[] parameter(8)
  %subtract.569 = s32[] subtract(s32[] %constant_13248, s32[] %param_8.247), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_13247 = s32[] constant(-1)
  %add.2646 = s32[] add(s32[] %subtract.569, s32[] %constant_13247), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_10774 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.1676 = pred[] compare(s32[] %add.2646, s32[] %constant_10774), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_13244 = s32[] constant(63)
  %add.2645 = s32[] add(s32[] %subtract.569, s32[] %constant_13244), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %select.1667 = s32[] select(pred[] %compare.1676, s32[] %add.2645, s32[] %add.2646), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %dynamic-slice.528 = f32[1,16,1024]{2,1,0} dynamic-slice(f32[64,16,1024]{2,1,0} %param_10.144, s32[] %select.1667, s32[] %constant_10774, s32[] %constant_10774), dynamic_slice_sizes={1,16,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %bitcast.913 = f32[16,1024]{1,0} bitcast(f32[1,16,1024]{2,1,0} %dynamic-slice.528), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_12.182 = f32[64,16,1024]{2,1,0} parameter(12)
  %dynamic-slice.532 = f32[1,16,1024]{2,1,0} dynamic-slice(f32[64,16,1024]{2,1,0} %param_12.182, s32[] %select.1667, s32[] %constant_10774, s32[] %constant_10774), dynamic_slice_sizes={1,16,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %bitcast.917 = f32[16,1024]{1,0} bitcast(f32[1,16,1024]{2,1,0} %dynamic-slice.532), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_11.171 = f32[16,2048]{1,0} parameter(11)
  %slice.984 = f32[16,1024]{1,0} slice(f32[16,2048]{1,0} %param_11.171), slice={[0:16], [1024:2048]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(16, 2048)\n                                                     start_indices=(0, 1024)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=65}
  %add.2654 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %bitcast.917, f32[16,1024]{1,0} %slice.984), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %multiply.909 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %bitcast.913, f32[16,1024]{1,0} %add.2654), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  %param_7.360 = f32[64,16,1024]{2,1,0} parameter(7)
  %dynamic-slice.382 = f32[1,16,1024]{2,1,0} dynamic-slice(f32[64,16,1024]{2,1,0} %param_7.360, s32[] %select.1667, s32[] %constant_10774, s32[] %constant_10774), dynamic_slice_sizes={1,16,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %bitcast.512 = f32[16,1024]{1,0} bitcast(f32[1,16,1024]{2,1,0} %dynamic-slice.382), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.908 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %multiply.909, f32[16,1024]{1,0} %bitcast.512), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %param_13.218 = f32[64,16,1024]{2,1,0} parameter(13)
  %dynamic-slice.536 = f32[1,16,1024]{2,1,0} dynamic-slice(f32[64,16,1024]{2,1,0} %param_13.218, s32[] %select.1667, s32[] %constant_10774, s32[] %constant_10774), dynamic_slice_sizes={1,16,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %bitcast.921 = f32[16,1024]{1,0} bitcast(f32[1,16,1024]{2,1,0} %dynamic-slice.536), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.907 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %multiply.908, f32[16,1024]{1,0} %bitcast.921), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %constant_10773 = f32[] constant(0), metadata={op_type="pad" op_name="pmap(_multi_device_update_fn)/scan/while/body/pad[ padding_config=((0, 0, 0), (3072, 0, 0)) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  %pad.169 = f32[16,4096]{1,0} pad(f32[16,1024]{1,0} %multiply.907, f32[] %constant_10773), padding=0_0x3072_0, metadata={op_type="pad" op_name="pmap(_multi_device_update_fn)/scan/while/body/pad[ padding_config=((0, 0, 0), (3072, 0, 0)) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  %param_6.373 = f32[64,16,1024]{2,1,0} parameter(6)
  %dynamic-slice.381 = f32[1,16,1024]{2,1,0} dynamic-slice(f32[64,16,1024]{2,1,0} %param_6.373, s32[] %select.1667, s32[] %constant_10774, s32[] %constant_10774), dynamic_slice_sizes={1,16,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %bitcast.511 = f32[16,1024]{1,0} bitcast(f32[1,16,1024]{2,1,0} %dynamic-slice.381), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_1.2120 = f32[16,1024]{1,0} parameter(1)
  %multiply.906 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %bitcast.511, f32[16,1024]{1,0} %param_1.2120), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %param_5.393 = f32[64,16,1024]{2,1,0} parameter(5)
  %dynamic-slice.380 = f32[1,16,1024]{2,1,0} dynamic-slice(f32[64,16,1024]{2,1,0} %param_5.393, s32[] %select.1667, s32[] %constant_10774, s32[] %constant_10774), dynamic_slice_sizes={1,16,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %bitcast.510 = f32[16,1024]{1,0} bitcast(f32[1,16,1024]{2,1,0} %dynamic-slice.380), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.905 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %multiply.906, f32[16,1024]{1,0} %bitcast.510), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %param_4.673 = f32[64,16,1024]{2,1,0} parameter(4)
  %dynamic-slice.379 = f32[1,16,1024]{2,1,0} dynamic-slice(f32[64,16,1024]{2,1,0} %param_4.673, s32[] %select.1667, s32[] %constant_10774, s32[] %constant_10774), dynamic_slice_sizes={1,16,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %bitcast.509 = f32[16,1024]{1,0} bitcast(f32[1,16,1024]{2,1,0} %dynamic-slice.379), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.904 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %multiply.905, f32[16,1024]{1,0} %bitcast.509), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %add.1842 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %multiply.905, f32[16,1024]{1,0} %multiply.904), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %pad.168 = f32[16,4096]{1,0} pad(f32[16,1024]{1,0} %add.1842, f32[] %constant_10773), padding=0_0x1024_2048, metadata={op_type="pad" op_name="pmap(_multi_device_update_fn)/scan/while/body/pad[ padding_config=((0, 0, 0), (1024, 2048, 0)) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  %add.1841 = f32[16,4096]{1,0} add(f32[16,4096]{1,0} %pad.169, f32[16,4096]{1,0} %pad.168), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %multiply.903 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %param_1.2120, f32[16,1024]{1,0} %bitcast.509), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %param_3.1484 = f32[64,16,1024]{2,1,0} parameter(3)
  %dynamic-slice.378 = f32[1,16,1024]{2,1,0} dynamic-slice(f32[64,16,1024]{2,1,0} %param_3.1484, s32[] %select.1667, s32[] %constant_10774, s32[] %constant_10774), dynamic_slice_sizes={1,16,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %bitcast.508 = f32[16,1024]{1,0} bitcast(f32[1,16,1024]{2,1,0} %dynamic-slice.378), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.902 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %multiply.903, f32[16,1024]{1,0} %bitcast.508), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %multiply.901 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %multiply.902, f32[16,1024]{1,0} %bitcast.511), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %pad.167 = f32[16,4096]{1,0} pad(f32[16,1024]{1,0} %multiply.901, f32[] %constant_10773), padding=0_0x0_3072, metadata={op_type="pad" op_name="pmap(_multi_device_update_fn)/scan/while/body/pad[ padding_config=((0, 0, 0), (0, 3072, 0)) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  %add.1840 = f32[16,4096]{1,0} add(f32[16,4096]{1,0} %add.1841, f32[16,4096]{1,0} %pad.167), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %param_2.1757 = f32[64,16,1024]{2,1,0} parameter(2)
  %dynamic-slice.377 = f32[1,16,1024]{2,1,0} dynamic-slice(f32[64,16,1024]{2,1,0} %param_2.1757, s32[] %select.1667, s32[] %constant_10774, s32[] %constant_10774), dynamic_slice_sizes={1,16,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %bitcast.507 = f32[16,1024]{1,0} bitcast(f32[1,16,1024]{2,1,0} %dynamic-slice.377), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.900 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %bitcast.507, f32[16,1024]{1,0} %param_1.2120), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %param_0.1674 = f32[64,16,1024]{2,1,0} parameter(0)
  %dynamic-slice.376 = f32[1,16,1024]{2,1,0} dynamic-slice(f32[64,16,1024]{2,1,0} %param_0.1674, s32[] %select.1667, s32[] %constant_10774, s32[] %constant_10774), dynamic_slice_sizes={1,16,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %bitcast.506 = f32[16,1024]{1,0} bitcast(f32[1,16,1024]{2,1,0} %dynamic-slice.376), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.899 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %multiply.900, f32[16,1024]{1,0} %bitcast.506), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %param_9.149 = f32[64,16,1024]{2,1,0} parameter(9)
  %dynamic-slice.524 = f32[1,16,1024]{2,1,0} dynamic-slice(f32[64,16,1024]{2,1,0} %param_9.149, s32[] %select.1667, s32[] %constant_10774, s32[] %constant_10774), dynamic_slice_sizes={1,16,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %bitcast.909 = f32[16,1024]{1,0} bitcast(f32[1,16,1024]{2,1,0} %dynamic-slice.524), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.898 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %multiply.899, f32[16,1024]{1,0} %bitcast.909), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %pad.166 = f32[16,4096]{1,0} pad(f32[16,1024]{1,0} %multiply.898, f32[] %constant_10773), padding=0_0x2048_1024, metadata={op_type="pad" op_name="pmap(_multi_device_update_fn)/scan/while/body/pad[ padding_config=((0, 0, 0), (2048, 1024, 0)) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  ROOT %add.1839 = f32[16,4096]{1,0} add(f32[16,4096]{1,0} %add.1840, f32[16,4096]{1,0} %pad.166), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
}

%fused_computation.82 (param_0.1678: f32[64,16,1024], param_1.2131: f32[16,2048], param_2.1764: s32[], param_3.1493: f32[64,16,1024], param_4.682: f32[64,16,1024], param_5.403: f32[64,16,1024]) -> f32[16,1024] {
  %param_1.2131 = f32[16,2048]{1,0} parameter(1)
  %slice.848 = f32[16,1024]{1,0} slice(f32[16,2048]{1,0} %param_1.2131), slice={[0:16], [0:1024]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(16, 1024)\n                                                     start_indices=(0, 0)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=65}
  %param_4.682 = f32[64,16,1024]{2,1,0} parameter(4)
  %constant_13280 = s32[] constant(64), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_2.1764 = s32[] parameter(2)
  %subtract.575 = s32[] subtract(s32[] %constant_13280, s32[] %param_2.1764), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_13279 = s32[] constant(-1)
  %add.2663 = s32[] add(s32[] %subtract.575, s32[] %constant_13279), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_10775 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.1682 = pred[] compare(s32[] %add.2663, s32[] %constant_10775), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_13276 = s32[] constant(63)
  %add.2662 = s32[] add(s32[] %subtract.575, s32[] %constant_13276), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %select.1673 = s32[] select(pred[] %compare.1682, s32[] %add.2662, s32[] %add.2663), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %dynamic-slice.534 = f32[1,16,1024]{2,1,0} dynamic-slice(f32[64,16,1024]{2,1,0} %param_4.682, s32[] %select.1673, s32[] %constant_10775, s32[] %constant_10775), dynamic_slice_sizes={1,16,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %bitcast.919 = f32[16,1024]{1,0} bitcast(f32[1,16,1024]{2,1,0} %dynamic-slice.534), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %slice.986 = f32[16,1024]{1,0} slice(f32[16,2048]{1,0} %param_1.2131), slice={[0:16], [1024:2048]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(16, 2048)\n                                                     start_indices=(0, 1024)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=65}
  %add.2661 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %bitcast.919, f32[16,1024]{1,0} %slice.986), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %param_5.403 = f32[64,16,1024]{2,1,0} parameter(5)
  %dynamic-slice.538 = f32[1,16,1024]{2,1,0} dynamic-slice(f32[64,16,1024]{2,1,0} %param_5.403, s32[] %select.1673, s32[] %constant_10775, s32[] %constant_10775), dynamic_slice_sizes={1,16,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %bitcast.923 = f32[16,1024]{1,0} bitcast(f32[1,16,1024]{2,1,0} %dynamic-slice.538), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.912 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %add.2661, f32[16,1024]{1,0} %bitcast.923), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  %param_0.1678 = f32[64,16,1024]{2,1,0} parameter(0)
  %dynamic-slice.384 = f32[1,16,1024]{2,1,0} dynamic-slice(f32[64,16,1024]{2,1,0} %param_0.1678, s32[] %select.1673, s32[] %constant_10775, s32[] %constant_10775), dynamic_slice_sizes={1,16,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %bitcast.514 = f32[16,1024]{1,0} bitcast(f32[1,16,1024]{2,1,0} %dynamic-slice.384), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.911 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %multiply.912, f32[16,1024]{1,0} %bitcast.514), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  %add.1844 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %slice.848, f32[16,1024]{1,0} %multiply.911), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %param_3.1493 = f32[64,16,1024]{2,1,0} parameter(3)
  %dynamic-slice.530 = f32[1,16,1024]{2,1,0} dynamic-slice(f32[64,16,1024]{2,1,0} %param_3.1493, s32[] %select.1673, s32[] %constant_10775, s32[] %constant_10775), dynamic_slice_sizes={1,16,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %bitcast.915 = f32[16,1024]{1,0} bitcast(f32[1,16,1024]{2,1,0} %dynamic-slice.530), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.910 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %multiply.911, f32[16,1024]{1,0} %bitcast.915), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  ROOT %add.1843 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %add.1844, f32[16,1024]{1,0} %multiply.910), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
}

%fused_computation.86 (param_0.179: f32[64,16,2048], param_1.2102: s32[], param_2.2336: f32[16,1024], param_3.2107: f32[64,16,1024], param_4.1097: f32[16,2048]) -> (f32[16,2048], f32[16,2048]) {
  %param_0.179 = f32[64,16,2048]{2,1,0} parameter(0)
  %constant_13214 = s32[] constant(64), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_1.2102 = s32[] parameter(1)
  %subtract.549 = s32[] subtract(s32[] %constant_13214, s32[] %param_1.2102), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_13213 = s32[] constant(-1)
  %add.2602 = s32[] add(s32[] %subtract.549, s32[] %constant_13213), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_10781 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.1656 = pred[] compare(s32[] %add.2602, s32[] %constant_10781), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_13211 = s32[] constant(63)
  %add.2601 = s32[] add(s32[] %subtract.549, s32[] %constant_13211), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %select.1647 = s32[] select(pred[] %compare.1656, s32[] %add.2601, s32[] %add.2602), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %dynamic-slice.388 = f32[1,16,2048]{2,1,0} dynamic-slice(f32[64,16,2048]{2,1,0} %param_0.179, s32[] %select.1647, s32[] %constant_10781, s32[] %constant_10781), dynamic_slice_sizes={1,16,2048}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 16, 2048) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %bitcast.518 = f32[16,2048]{1,0} bitcast(f32[1,16,2048]{2,1,0} %dynamic-slice.388), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_4.1097 = f32[16,2048]{1,0} parameter(4)
  %slice.847.clone.1 = f32[16,1024]{1,0} slice(f32[16,2048]{1,0} %param_4.1097), slice={[0:16], [1024:2048]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(16, 2048)\n                                                     start_indices=(0, 1024)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %constant_10771_clone_1 = f32[] constant(0), metadata={op_type="pad" op_name="pmap(_multi_device_update_fn)/scan/while/body/pad[ padding_config=((0, 0, 0), (3072, 0, 0)) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  %pad.165.clone.1 = f32[16,2048]{1,0} pad(f32[16,1024]{1,0} %slice.847.clone.1, f32[] %constant_10771_clone_1), padding=0_0x1024_0, metadata={op_type="pad" op_name="pmap(_multi_device_update_fn)/scan/while/body/pad[ padding_config=((0, 0, 0), (1024, 0, 0)) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=54}
  %param_2.2336 = f32[16,1024]{1,0} parameter(2)
  %param_3.2107 = f32[64,16,1024]{2,1,0} parameter(3)
  %dynamic-slice.526.clone.1 = f32[1,16,1024]{2,1,0} dynamic-slice(f32[64,16,1024]{2,1,0} %param_3.2107, s32[] %select.1647, s32[] %constant_10781, s32[] %constant_10781), dynamic_slice_sizes={1,16,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %bitcast.911.clone.1 = f32[16,1024]{1,0} bitcast(f32[1,16,1024]{2,1,0} %dynamic-slice.526.clone.1), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.897.clone.1 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %param_2.2336, f32[16,1024]{1,0} %bitcast.911.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %pad.164.clone.1 = f32[16,2048]{1,0} pad(f32[16,1024]{1,0} %multiply.897.clone.1, f32[] %constant_10771_clone_1), padding=0_0x0_1024, metadata={op_type="pad" op_name="pmap(_multi_device_update_fn)/scan/while/body/pad[ padding_config=((0, 0, 0), (0, 1024, 0)) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=54}
  %add.1837.clone.1 = f32[16,2048]{1,0} add(f32[16,2048]{1,0} %pad.165.clone.1, f32[16,2048]{1,0} %pad.164.clone.1), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  ROOT %tuple.472 = (f32[16,2048]{1,0}, f32[16,2048]{1,0}) tuple(f32[16,2048]{1,0} %bitcast.518, f32[16,2048]{1,0} %add.1837.clone.1)
}

%body_computation__52.11465.clone.clone (parameter.77: (f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[64,16,2048], f32[64,16,1024], /*index=5*/f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], /*index=10*/f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[2048,4096], s32[], /*index=15*/f32[2048,4096], f32[4096], f32[16,2048], f32[64,16,1024])) -> (f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[64,16,2048], f32[64,16,1024], /*index=5*/f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], /*index=10*/f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[2048,4096], s32[], /*index=15*/f32[2048,4096], f32[4096], f32[16,2048], f32[64,16,1024]) {
  %parameter.77 = (f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) parameter(0)
  %get-tuple-element.6822 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.77), index=0
  %get-tuple-element.6823 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.77), index=1
  %get-tuple-element.6824 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.77), index=2
  %get-tuple-element.6825 = f32[64,16,2048]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.77), index=3
  %get-tuple-element.6826 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.77), index=4
  %get-tuple-element.6827 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.77), index=5
  %get-tuple-element.6828 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.77), index=6
  %get-tuple-element.6829 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.77), index=7
  %get-tuple-element.6832 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.77), index=8
  %get-tuple-element.6833 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.77), index=9
  %get-tuple-element.6834 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.77), index=10
  %get-tuple-element.6835 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.77), index=11
  %get-tuple-element.6836 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.77), index=12
  %get-tuple-element.6837 = f32[2048,4096]{1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.77), index=13
  %get-tuple-element.6842 = f32[16,2048]{1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.77), index=17
  %get-tuple-element.6838 = s32[] get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.77), index=14
  %fusion.82 = f32[16,1024]{1,0} fusion(f32[64,16,1024]{2,1,0} %get-tuple-element.6834, f32[16,2048]{1,0} %get-tuple-element.6842, s32[] %get-tuple-element.6838, f32[64,16,1024]{2,1,0} %get-tuple-element.6833, f32[64,16,1024]{2,1,0} %get-tuple-element.6822, /*index=5*/f32[64,16,1024]{2,1,0} %get-tuple-element.6835), kind=kLoop, calls=%fused_computation.82, metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %fusion.80 = f32[16,4096]{1,0} fusion(f32[64,16,1024]{2,1,0} %get-tuple-element.6826, f32[16,1024]{1,0} %fusion.82, f32[64,16,1024]{2,1,0} %get-tuple-element.6824, f32[64,16,1024]{2,1,0} %get-tuple-element.6828, f32[64,16,1024]{2,1,0} %get-tuple-element.6829, /*index=5*/f32[64,16,1024]{2,1,0} %get-tuple-element.6832, f32[64,16,1024]{2,1,0} %get-tuple-element.6827, f32[64,16,1024]{2,1,0} %get-tuple-element.6836, s32[] %get-tuple-element.6838, f32[64,16,1024]{2,1,0} %get-tuple-element.6823, /*index=10*/f32[64,16,1024]{2,1,0} %get-tuple-element.6833, f32[16,2048]{1,0} %get-tuple-element.6842, f32[64,16,1024]{2,1,0} %get-tuple-element.6822, f32[64,16,1024]{2,1,0} %get-tuple-element.6835), kind=kLoop, calls=%fused_computation.80, metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %custom-call.115 = f32[16,2048]{1,0} custom-call(f32[16,4096]{1,0} %fusion.80, f32[2048,4096]{1,0} %get-tuple-element.6837), custom_call_target="__cublas$gemm", metadata={op_type="dot_general" op_name="pmap(_multi_device_update_fn)/scan/while/body/dot_general[ dimension_numbers=(((1,), (1,)), ((), ()))\n                                                           precision=None\n                                                           preferred_element_type=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}, backend_config="{\"alpha_real\":1,\"alpha_imag\":0,\"beta\":0,\"dot_dimension_numbers\":{\"lhs_contracting_dimensions\":[\"1\"],\"rhs_contracting_dimensions\":[\"1\"],\"lhs_batch_dimensions\":[],\"rhs_batch_dimensions\":[]},\"batch_size\":\"1\",\"selected_algorithm\":\"-1\"}"
  %fusion.86 = (f32[16,2048]{1,0}, f32[16,2048]{1,0}) fusion(f32[64,16,2048]{2,1,0} %get-tuple-element.6825, s32[] %get-tuple-element.6838, f32[16,1024]{1,0} %fusion.82, f32[64,16,1024]{2,1,0} %get-tuple-element.6823, f32[16,2048]{1,0} %custom-call.115), kind=kLoop, calls=%fused_computation.86, control-predecessors={%fusion.82, %fusion.80}, metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.6844 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.77), index=18
  %fusion.77 = f32[64,16,1024]{2,1,0} fusion(f32[64,16,1024]{2,1,0} %get-tuple-element.6844, f32[16,2048]{1,0} %custom-call.115, s32[] %get-tuple-element.6838), kind=kLoop, calls=%fused_computation.77, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_9203 = s32[] constant(1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.1528 = s32[] add(s32[] %get-tuple-element.6838, s32[] %constant_9203), control-predecessors={%fusion.77, %fusion.86, %fusion.82, %fusion.80}, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.5050 = f32[16,2048]{1,0} get-tuple-element((f32[16,2048]{1,0}, f32[16,2048]{1,0}) %fusion.86), index=0
  %get-tuple-element.6840 = f32[2048,4096]{1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.77), index=15
  %custom-call.114 = f32[2048,4096]{1,0} custom-call(f32[16,2048]{1,0} %get-tuple-element.5050, f32[16,4096]{1,0} %fusion.80, f32[2048,4096]{1,0} %get-tuple-element.6840), custom_call_target="__cublas$gemm", metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}, backend_config="{\"alpha_real\":1,\"alpha_imag\":0,\"beta\":1,\"dot_dimension_numbers\":{\"lhs_contracting_dimensions\":[\"0\"],\"rhs_contracting_dimensions\":[\"0\"],\"lhs_batch_dimensions\":[],\"rhs_batch_dimensions\":[]},\"batch_size\":\"1\",\"selected_algorithm\":\"4\"}"
  %get-tuple-element.6841 = f32[4096]{0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.77), index=16
  %fusion.79 = f32[4096]{0} fusion(f32[4096]{0} %get-tuple-element.6841, f32[16,4096]{1,0} %fusion.80), kind=kLoop, calls=%fused_computation.79, metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %get-tuple-element.5051 = f32[16,2048]{1,0} get-tuple-element((f32[16,2048]{1,0}, f32[16,2048]{1,0}) %fusion.86), index=1
  ROOT %tuple.835 = (f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) tuple(f32[64,16,1024]{2,1,0} %get-tuple-element.6822, f32[64,16,1024]{2,1,0} %get-tuple-element.6823, f32[64,16,1024]{2,1,0} %get-tuple-element.6824, f32[64,16,2048]{2,1,0} %get-tuple-element.6825, f32[64,16,1024]{2,1,0} %get-tuple-element.6826, /*index=5*/f32[64,16,1024]{2,1,0} %get-tuple-element.6827, f32[64,16,1024]{2,1,0} %get-tuple-element.6828, f32[64,16,1024]{2,1,0} %get-tuple-element.6829, f32[64,16,1024]{2,1,0} %get-tuple-element.6832, f32[64,16,1024]{2,1,0} %get-tuple-element.6833, /*index=10*/f32[64,16,1024]{2,1,0} %get-tuple-element.6834, f32[64,16,1024]{2,1,0} %get-tuple-element.6835, f32[64,16,1024]{2,1,0} %get-tuple-element.6836, f32[2048,4096]{1,0} %get-tuple-element.6837, s32[] %add.1528, /*index=15*/f32[2048,4096]{1,0} %custom-call.114, f32[4096]{0} %fusion.79, f32[16,2048]{1,0} %get-tuple-element.5051, f32[64,16,1024]{2,1,0} %fusion.77)
}

%cond_computation__52.11876.clone.clone (parameter.78: (f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[64,16,2048], f32[64,16,1024], /*index=5*/f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], /*index=10*/f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[2048,4096], s32[], /*index=15*/f32[2048,4096], f32[4096], f32[16,2048], f32[64,16,1024])) -> pred[] {
  %parameter.78 = (f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) parameter(0)
  %get-tuple-element.3766 = s32[] get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.78), index=14
  %constant_9207 = s32[] constant(64), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/cond/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %compare.1214 = pred[] compare(s32[] %get-tuple-element.3766, s32[] %constant_9207), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/cond/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.88 (param_0.184: f32[64,16,1024], param_1.2152: f32[16,2048], param_2.1796: s32[]) -> f32[64,16,1024] {
  %param_0.184 = f32[64,16,1024]{2,1,0} parameter(0)
  %param_1.2152 = f32[16,2048]{1,0} parameter(1)
  %slice.850 = f32[16,1024]{1,0} slice(f32[16,2048]{1,0} %param_1.2152), slice={[0:16], [0:1024]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(16, 1024)\n                                                     start_indices=(0, 0)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %bitcast.519 = f32[1,16,1024]{2,1,0} bitcast(f32[16,1024]{1,0} %slice.850), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_13484 = s32[] constant(64), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_2.1796 = s32[] parameter(2)
  %subtract.595 = s32[] subtract(s32[] %constant_13484, s32[] %param_2.1796), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_13483 = s32[] constant(-1)
  %add.2709 = s32[] add(s32[] %subtract.595, s32[] %constant_13483), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_10783 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.1702 = pred[] compare(s32[] %add.2709, s32[] %constant_10783), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_13480 = s32[] constant(63)
  %add.2708 = s32[] add(s32[] %subtract.595, s32[] %constant_13480), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %select.1693 = s32[] select(pred[] %compare.1702, s32[] %add.2708, s32[] %add.2709), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.499 = f32[64,16,1024]{2,1,0} dynamic-update-slice(f32[64,16,1024]{2,1,0} %param_0.184, f32[1,16,1024]{2,1,0} %bitcast.519, s32[] %select.1693, s32[] %constant_10783, s32[] %constant_10783), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%primitive_computation_add__1.11998 (parameter.11999: f32[], parameter.12000: f32[]) -> f32[] {
  %parameter.11999 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.12000 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.12001 = f32[] add(f32[] %parameter.11999, f32[] %parameter.12000), metadata={op_type="add" op_name="add"}
}

%fused_computation.90 (param_0.187: f32[4096], param_1.255: f32[16,4096]) -> f32[4096] {
  %param_0.187 = f32[4096]{0} parameter(0)
  %param_1.255 = f32[16,4096]{1,0} parameter(1)
  %constant_10785 = f32[] constant(0), metadata={op_type="pad" op_name="pmap(_multi_device_update_fn)/scan/while/body/pad[ padding_config=((0, 0, 0), (3072, 0, 0)) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  %reduce.181 = f32[4096]{0} reduce(f32[16,4096]{1,0} %param_1.255, f32[] %constant_10785), dimensions={0}, to_apply=%primitive_computation_add__1.11998, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/scan/while/body/reduce_sum[ axes=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  ROOT %add.1849 = f32[4096]{0} add(f32[4096]{0} %param_0.187, f32[4096]{0} %reduce.181), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
}

%fused_computation.91 (param_0.1692: f32[64,16,1024], param_1.2154: f32[16,1024], param_2.1797: f32[64,16,1024], param_3.1518: f32[64,16,1024], param_4.695: f32[64,16,1024], param_5.412: f32[64,16,1024], param_6.397: f32[64,16,1024], param_7.381: f32[64,16,1024], param_8.260: s32[], param_9.157: f32[64,16,1024], param_10.149: f32[64,16,1024], param_11.176: f32[16,2048], param_12.194: f32[64,16,1024], param_13.239: f32[64,16,1024]) -> f32[16,4096] {
  %param_10.149 = f32[64,16,1024]{2,1,0} parameter(10)
  %constant_13440 = s32[] constant(64), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_8.260 = s32[] parameter(8)
  %subtract.601 = s32[] subtract(s32[] %constant_13440, s32[] %param_8.260), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_13439 = s32[] constant(-1)
  %add.2723 = s32[] add(s32[] %subtract.601, s32[] %constant_13439), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_10787 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.1708 = pred[] compare(s32[] %add.2723, s32[] %constant_10787), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_13436 = s32[] constant(63)
  %add.2722 = s32[] add(s32[] %subtract.601, s32[] %constant_13436), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %select.1699 = s32[] select(pred[] %compare.1708, s32[] %add.2722, s32[] %add.2723), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %dynamic-slice.544 = f32[1,16,1024]{2,1,0} dynamic-slice(f32[64,16,1024]{2,1,0} %param_10.149, s32[] %select.1699, s32[] %constant_10787, s32[] %constant_10787), dynamic_slice_sizes={1,16,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %bitcast.929 = f32[16,1024]{1,0} bitcast(f32[1,16,1024]{2,1,0} %dynamic-slice.544), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_12.194 = f32[64,16,1024]{2,1,0} parameter(12)
  %dynamic-slice.549 = f32[1,16,1024]{2,1,0} dynamic-slice(f32[64,16,1024]{2,1,0} %param_12.194, s32[] %select.1699, s32[] %constant_10787, s32[] %constant_10787), dynamic_slice_sizes={1,16,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %bitcast.933 = f32[16,1024]{1,0} bitcast(f32[1,16,1024]{2,1,0} %dynamic-slice.549), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_11.176 = f32[16,2048]{1,0} parameter(11)
  %slice.988 = f32[16,1024]{1,0} slice(f32[16,2048]{1,0} %param_11.176), slice={[0:16], [1024:2048]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(16, 2048)\n                                                     start_indices=(0, 1024)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=65}
  %add.2732 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %bitcast.933, f32[16,1024]{1,0} %slice.988), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %multiply.925 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %bitcast.929, f32[16,1024]{1,0} %add.2732), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  %param_7.381 = f32[64,16,1024]{2,1,0} parameter(7)
  %dynamic-slice.395 = f32[1,16,1024]{2,1,0} dynamic-slice(f32[64,16,1024]{2,1,0} %param_7.381, s32[] %select.1699, s32[] %constant_10787, s32[] %constant_10787), dynamic_slice_sizes={1,16,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %bitcast.526 = f32[16,1024]{1,0} bitcast(f32[1,16,1024]{2,1,0} %dynamic-slice.395), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.924 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %multiply.925, f32[16,1024]{1,0} %bitcast.526), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %param_13.239 = f32[64,16,1024]{2,1,0} parameter(13)
  %dynamic-slice.553 = f32[1,16,1024]{2,1,0} dynamic-slice(f32[64,16,1024]{2,1,0} %param_13.239, s32[] %select.1699, s32[] %constant_10787, s32[] %constant_10787), dynamic_slice_sizes={1,16,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %bitcast.937 = f32[16,1024]{1,0} bitcast(f32[1,16,1024]{2,1,0} %dynamic-slice.553), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.923 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %multiply.924, f32[16,1024]{1,0} %bitcast.937), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %constant_10786 = f32[] constant(0), metadata={op_type="pad" op_name="pmap(_multi_device_update_fn)/scan/while/body/pad[ padding_config=((0, 0, 0), (3072, 0, 0)) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  %pad.175 = f32[16,4096]{1,0} pad(f32[16,1024]{1,0} %multiply.923, f32[] %constant_10786), padding=0_0x3072_0, metadata={op_type="pad" op_name="pmap(_multi_device_update_fn)/scan/while/body/pad[ padding_config=((0, 0, 0), (3072, 0, 0)) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  %param_6.397 = f32[64,16,1024]{2,1,0} parameter(6)
  %dynamic-slice.394 = f32[1,16,1024]{2,1,0} dynamic-slice(f32[64,16,1024]{2,1,0} %param_6.397, s32[] %select.1699, s32[] %constant_10787, s32[] %constant_10787), dynamic_slice_sizes={1,16,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %bitcast.525 = f32[16,1024]{1,0} bitcast(f32[1,16,1024]{2,1,0} %dynamic-slice.394), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_1.2154 = f32[16,1024]{1,0} parameter(1)
  %multiply.922 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %bitcast.525, f32[16,1024]{1,0} %param_1.2154), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %param_5.412 = f32[64,16,1024]{2,1,0} parameter(5)
  %dynamic-slice.393 = f32[1,16,1024]{2,1,0} dynamic-slice(f32[64,16,1024]{2,1,0} %param_5.412, s32[] %select.1699, s32[] %constant_10787, s32[] %constant_10787), dynamic_slice_sizes={1,16,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %bitcast.524 = f32[16,1024]{1,0} bitcast(f32[1,16,1024]{2,1,0} %dynamic-slice.393), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.921 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %multiply.922, f32[16,1024]{1,0} %bitcast.524), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %param_4.695 = f32[64,16,1024]{2,1,0} parameter(4)
  %dynamic-slice.392 = f32[1,16,1024]{2,1,0} dynamic-slice(f32[64,16,1024]{2,1,0} %param_4.695, s32[] %select.1699, s32[] %constant_10787, s32[] %constant_10787), dynamic_slice_sizes={1,16,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %bitcast.523 = f32[16,1024]{1,0} bitcast(f32[1,16,1024]{2,1,0} %dynamic-slice.392), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.920 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %multiply.921, f32[16,1024]{1,0} %bitcast.523), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %add.1853 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %multiply.921, f32[16,1024]{1,0} %multiply.920), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %pad.174 = f32[16,4096]{1,0} pad(f32[16,1024]{1,0} %add.1853, f32[] %constant_10786), padding=0_0x1024_2048, metadata={op_type="pad" op_name="pmap(_multi_device_update_fn)/scan/while/body/pad[ padding_config=((0, 0, 0), (1024, 2048, 0)) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  %add.1852 = f32[16,4096]{1,0} add(f32[16,4096]{1,0} %pad.175, f32[16,4096]{1,0} %pad.174), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %multiply.919 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %param_1.2154, f32[16,1024]{1,0} %bitcast.523), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %param_3.1518 = f32[64,16,1024]{2,1,0} parameter(3)
  %dynamic-slice.391 = f32[1,16,1024]{2,1,0} dynamic-slice(f32[64,16,1024]{2,1,0} %param_3.1518, s32[] %select.1699, s32[] %constant_10787, s32[] %constant_10787), dynamic_slice_sizes={1,16,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %bitcast.522 = f32[16,1024]{1,0} bitcast(f32[1,16,1024]{2,1,0} %dynamic-slice.391), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.918 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %multiply.919, f32[16,1024]{1,0} %bitcast.522), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %multiply.917 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %multiply.918, f32[16,1024]{1,0} %bitcast.525), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %pad.173 = f32[16,4096]{1,0} pad(f32[16,1024]{1,0} %multiply.917, f32[] %constant_10786), padding=0_0x0_3072, metadata={op_type="pad" op_name="pmap(_multi_device_update_fn)/scan/while/body/pad[ padding_config=((0, 0, 0), (0, 3072, 0)) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  %add.1851 = f32[16,4096]{1,0} add(f32[16,4096]{1,0} %add.1852, f32[16,4096]{1,0} %pad.173), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %param_2.1797 = f32[64,16,1024]{2,1,0} parameter(2)
  %dynamic-slice.390 = f32[1,16,1024]{2,1,0} dynamic-slice(f32[64,16,1024]{2,1,0} %param_2.1797, s32[] %select.1699, s32[] %constant_10787, s32[] %constant_10787), dynamic_slice_sizes={1,16,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %bitcast.521 = f32[16,1024]{1,0} bitcast(f32[1,16,1024]{2,1,0} %dynamic-slice.390), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.916 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %bitcast.521, f32[16,1024]{1,0} %param_1.2154), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %param_0.1692 = f32[64,16,1024]{2,1,0} parameter(0)
  %dynamic-slice.389 = f32[1,16,1024]{2,1,0} dynamic-slice(f32[64,16,1024]{2,1,0} %param_0.1692, s32[] %select.1699, s32[] %constant_10787, s32[] %constant_10787), dynamic_slice_sizes={1,16,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %bitcast.520 = f32[16,1024]{1,0} bitcast(f32[1,16,1024]{2,1,0} %dynamic-slice.389), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.915 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %multiply.916, f32[16,1024]{1,0} %bitcast.520), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %param_9.157 = f32[64,16,1024]{2,1,0} parameter(9)
  %dynamic-slice.540 = f32[1,16,1024]{2,1,0} dynamic-slice(f32[64,16,1024]{2,1,0} %param_9.157, s32[] %select.1699, s32[] %constant_10787, s32[] %constant_10787), dynamic_slice_sizes={1,16,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %bitcast.925 = f32[16,1024]{1,0} bitcast(f32[1,16,1024]{2,1,0} %dynamic-slice.540), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.914 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %multiply.915, f32[16,1024]{1,0} %bitcast.925), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %pad.172 = f32[16,4096]{1,0} pad(f32[16,1024]{1,0} %multiply.914, f32[] %constant_10786), padding=0_0x2048_1024, metadata={op_type="pad" op_name="pmap(_multi_device_update_fn)/scan/while/body/pad[ padding_config=((0, 0, 0), (2048, 1024, 0)) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  ROOT %add.1850 = f32[16,4096]{1,0} add(f32[16,4096]{1,0} %add.1851, f32[16,4096]{1,0} %pad.172), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
}

%fused_computation.93 (param_0.1696: f32[64,16,1024], param_1.2165: f32[16,2048], param_2.1804: s32[], param_3.1527: f32[64,16,1024], param_4.704: f32[64,16,1024], param_5.422: f32[64,16,1024]) -> f32[16,1024] {
  %param_1.2165 = f32[16,2048]{1,0} parameter(1)
  %slice.852 = f32[16,1024]{1,0} slice(f32[16,2048]{1,0} %param_1.2165), slice={[0:16], [0:1024]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(16, 1024)\n                                                     start_indices=(0, 0)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=65}
  %param_4.704 = f32[64,16,1024]{2,1,0} parameter(4)
  %constant_13473 = s32[] constant(64), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_2.1804 = s32[] parameter(2)
  %subtract.610 = s32[] subtract(s32[] %constant_13473, s32[] %param_2.1804), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_13472 = s32[] constant(-1)
  %add.2741 = s32[] add(s32[] %subtract.610, s32[] %constant_13472), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_10788 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.1714 = pred[] compare(s32[] %add.2741, s32[] %constant_10788), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_13469 = s32[] constant(63)
  %add.2740 = s32[] add(s32[] %subtract.610, s32[] %constant_13469), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %select.1705 = s32[] select(pred[] %compare.1714, s32[] %add.2740, s32[] %add.2741), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %dynamic-slice.551 = f32[1,16,1024]{2,1,0} dynamic-slice(f32[64,16,1024]{2,1,0} %param_4.704, s32[] %select.1705, s32[] %constant_10788, s32[] %constant_10788), dynamic_slice_sizes={1,16,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %bitcast.935 = f32[16,1024]{1,0} bitcast(f32[1,16,1024]{2,1,0} %dynamic-slice.551), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %slice.990 = f32[16,1024]{1,0} slice(f32[16,2048]{1,0} %param_1.2165), slice={[0:16], [1024:2048]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(16, 2048)\n                                                     start_indices=(0, 1024)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=65}
  %add.2739 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %bitcast.935, f32[16,1024]{1,0} %slice.990), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %param_5.422 = f32[64,16,1024]{2,1,0} parameter(5)
  %dynamic-slice.555 = f32[1,16,1024]{2,1,0} dynamic-slice(f32[64,16,1024]{2,1,0} %param_5.422, s32[] %select.1705, s32[] %constant_10788, s32[] %constant_10788), dynamic_slice_sizes={1,16,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %bitcast.939 = f32[16,1024]{1,0} bitcast(f32[1,16,1024]{2,1,0} %dynamic-slice.555), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.928 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %add.2739, f32[16,1024]{1,0} %bitcast.939), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  %param_0.1696 = f32[64,16,1024]{2,1,0} parameter(0)
  %dynamic-slice.397 = f32[1,16,1024]{2,1,0} dynamic-slice(f32[64,16,1024]{2,1,0} %param_0.1696, s32[] %select.1705, s32[] %constant_10788, s32[] %constant_10788), dynamic_slice_sizes={1,16,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %bitcast.528 = f32[16,1024]{1,0} bitcast(f32[1,16,1024]{2,1,0} %dynamic-slice.397), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.927 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %multiply.928, f32[16,1024]{1,0} %bitcast.528), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  %add.1855 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %slice.852, f32[16,1024]{1,0} %multiply.927), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %param_3.1527 = f32[64,16,1024]{2,1,0} parameter(3)
  %dynamic-slice.547 = f32[1,16,1024]{2,1,0} dynamic-slice(f32[64,16,1024]{2,1,0} %param_3.1527, s32[] %select.1705, s32[] %constant_10788, s32[] %constant_10788), dynamic_slice_sizes={1,16,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %bitcast.931 = f32[16,1024]{1,0} bitcast(f32[1,16,1024]{2,1,0} %dynamic-slice.547), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.926 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %multiply.927, f32[16,1024]{1,0} %bitcast.931), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  ROOT %add.1854 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %add.1855, f32[16,1024]{1,0} %multiply.926), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
}

%fused_computation.97 (param_0.202: f32[64,16,2048], param_1.2136: s32[], param_2.2339: f32[16,1024], param_3.2112: f32[64,16,1024], param_4.1102: f32[16,2048]) -> (f32[16,2048], f32[16,2048]) {
  %param_0.202 = f32[64,16,2048]{2,1,0} parameter(0)
  %constant_13407 = s32[] constant(64), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_1.2136 = s32[] parameter(1)
  %subtract.581 = s32[] subtract(s32[] %constant_13407, s32[] %param_1.2136), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_13406 = s32[] constant(-1)
  %add.2677 = s32[] add(s32[] %subtract.581, s32[] %constant_13406), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_10794 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.1688 = pred[] compare(s32[] %add.2677, s32[] %constant_10794), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_13403 = s32[] constant(63)
  %add.2676 = s32[] add(s32[] %subtract.581, s32[] %constant_13403), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %select.1679 = s32[] select(pred[] %compare.1688, s32[] %add.2676, s32[] %add.2677), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %dynamic-slice.401 = f32[1,16,2048]{2,1,0} dynamic-slice(f32[64,16,2048]{2,1,0} %param_0.202, s32[] %select.1679, s32[] %constant_10794, s32[] %constant_10794), dynamic_slice_sizes={1,16,2048}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 16, 2048) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %bitcast.532 = f32[16,2048]{1,0} bitcast(f32[1,16,2048]{2,1,0} %dynamic-slice.401), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_4.1102 = f32[16,2048]{1,0} parameter(4)
  %slice.851.clone.1 = f32[16,1024]{1,0} slice(f32[16,2048]{1,0} %param_4.1102), slice={[0:16], [1024:2048]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(16, 2048)\n                                                     start_indices=(0, 1024)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %constant_10784_clone_1 = f32[] constant(0), metadata={op_type="pad" op_name="pmap(_multi_device_update_fn)/scan/while/body/pad[ padding_config=((0, 0, 0), (3072, 0, 0)) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  %pad.171.clone.1 = f32[16,2048]{1,0} pad(f32[16,1024]{1,0} %slice.851.clone.1, f32[] %constant_10784_clone_1), padding=0_0x1024_0, metadata={op_type="pad" op_name="pmap(_multi_device_update_fn)/scan/while/body/pad[ padding_config=((0, 0, 0), (1024, 0, 0)) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=54}
  %param_2.2339 = f32[16,1024]{1,0} parameter(2)
  %param_3.2112 = f32[64,16,1024]{2,1,0} parameter(3)
  %dynamic-slice.542.clone.1 = f32[1,16,1024]{2,1,0} dynamic-slice(f32[64,16,1024]{2,1,0} %param_3.2112, s32[] %select.1679, s32[] %constant_10794, s32[] %constant_10794), dynamic_slice_sizes={1,16,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %bitcast.927.clone.1 = f32[16,1024]{1,0} bitcast(f32[1,16,1024]{2,1,0} %dynamic-slice.542.clone.1), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.913.clone.1 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %param_2.2339, f32[16,1024]{1,0} %bitcast.927.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %pad.170.clone.1 = f32[16,2048]{1,0} pad(f32[16,1024]{1,0} %multiply.913.clone.1, f32[] %constant_10784_clone_1), padding=0_0x0_1024, metadata={op_type="pad" op_name="pmap(_multi_device_update_fn)/scan/while/body/pad[ padding_config=((0, 0, 0), (0, 1024, 0)) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=54}
  %add.1848.clone.1 = f32[16,2048]{1,0} add(f32[16,2048]{1,0} %pad.171.clone.1, f32[16,2048]{1,0} %pad.170.clone.1), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  ROOT %tuple.473 = (f32[16,2048]{1,0}, f32[16,2048]{1,0}) tuple(f32[16,2048]{1,0} %bitcast.532, f32[16,2048]{1,0} %add.1848.clone.1)
}

%body_computation__53.12006.clone.clone (parameter.79: (f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[64,16,2048], f32[64,16,1024], /*index=5*/f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], /*index=10*/f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[2048,4096], s32[], /*index=15*/f32[2048,4096], f32[4096], f32[16,2048], f32[64,16,1024])) -> (f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[64,16,2048], f32[64,16,1024], /*index=5*/f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], /*index=10*/f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[2048,4096], s32[], /*index=15*/f32[2048,4096], f32[4096], f32[16,2048], f32[64,16,1024]) {
  %parameter.79 = (f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) parameter(0)
  %get-tuple-element.6887 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.79), index=0
  %get-tuple-element.6888 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.79), index=1
  %get-tuple-element.6889 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.79), index=2
  %get-tuple-element.6890 = f32[64,16,2048]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.79), index=3
  %get-tuple-element.6891 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.79), index=4
  %get-tuple-element.6892 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.79), index=5
  %get-tuple-element.6893 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.79), index=6
  %get-tuple-element.6894 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.79), index=7
  %get-tuple-element.6895 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.79), index=8
  %get-tuple-element.6896 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.79), index=9
  %get-tuple-element.6897 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.79), index=10
  %get-tuple-element.6898 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.79), index=11
  %get-tuple-element.6899 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.79), index=12
  %get-tuple-element.6900 = f32[2048,4096]{1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.79), index=13
  %get-tuple-element.6910 = f32[16,2048]{1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.79), index=17
  %get-tuple-element.6904 = s32[] get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.79), index=14
  %fusion.93 = f32[16,1024]{1,0} fusion(f32[64,16,1024]{2,1,0} %get-tuple-element.6897, f32[16,2048]{1,0} %get-tuple-element.6910, s32[] %get-tuple-element.6904, f32[64,16,1024]{2,1,0} %get-tuple-element.6896, f32[64,16,1024]{2,1,0} %get-tuple-element.6887, /*index=5*/f32[64,16,1024]{2,1,0} %get-tuple-element.6898), kind=kLoop, calls=%fused_computation.93, metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %fusion.91 = f32[16,4096]{1,0} fusion(f32[64,16,1024]{2,1,0} %get-tuple-element.6891, f32[16,1024]{1,0} %fusion.93, f32[64,16,1024]{2,1,0} %get-tuple-element.6889, f32[64,16,1024]{2,1,0} %get-tuple-element.6893, f32[64,16,1024]{2,1,0} %get-tuple-element.6894, /*index=5*/f32[64,16,1024]{2,1,0} %get-tuple-element.6895, f32[64,16,1024]{2,1,0} %get-tuple-element.6892, f32[64,16,1024]{2,1,0} %get-tuple-element.6899, s32[] %get-tuple-element.6904, f32[64,16,1024]{2,1,0} %get-tuple-element.6888, /*index=10*/f32[64,16,1024]{2,1,0} %get-tuple-element.6896, f32[16,2048]{1,0} %get-tuple-element.6910, f32[64,16,1024]{2,1,0} %get-tuple-element.6887, f32[64,16,1024]{2,1,0} %get-tuple-element.6898), kind=kLoop, calls=%fused_computation.91, metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %custom-call.118 = f32[16,2048]{1,0} custom-call(f32[16,4096]{1,0} %fusion.91, f32[2048,4096]{1,0} %get-tuple-element.6900), custom_call_target="__cublas$gemm", metadata={op_type="dot_general" op_name="pmap(_multi_device_update_fn)/scan/while/body/dot_general[ dimension_numbers=(((1,), (1,)), ((), ()))\n                                                           precision=None\n                                                           preferred_element_type=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}, backend_config="{\"alpha_real\":1,\"alpha_imag\":0,\"beta\":0,\"dot_dimension_numbers\":{\"lhs_contracting_dimensions\":[\"1\"],\"rhs_contracting_dimensions\":[\"1\"],\"lhs_batch_dimensions\":[],\"rhs_batch_dimensions\":[]},\"batch_size\":\"1\",\"selected_algorithm\":\"-1\"}"
  %fusion.97 = (f32[16,2048]{1,0}, f32[16,2048]{1,0}) fusion(f32[64,16,2048]{2,1,0} %get-tuple-element.6890, s32[] %get-tuple-element.6904, f32[16,1024]{1,0} %fusion.93, f32[64,16,1024]{2,1,0} %get-tuple-element.6888, f32[16,2048]{1,0} %custom-call.118), kind=kLoop, calls=%fused_computation.97, control-predecessors={%fusion.93, %fusion.91}, metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.6911 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.79), index=18
  %fusion.88 = f32[64,16,1024]{2,1,0} fusion(f32[64,16,1024]{2,1,0} %get-tuple-element.6911, f32[16,2048]{1,0} %custom-call.118, s32[] %get-tuple-element.6904), kind=kLoop, calls=%fused_computation.88, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_9275 = s32[] constant(1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.1574 = s32[] add(s32[] %get-tuple-element.6904, s32[] %constant_9275), control-predecessors={%fusion.88, %fusion.97, %fusion.93, %fusion.91}, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.5052 = f32[16,2048]{1,0} get-tuple-element((f32[16,2048]{1,0}, f32[16,2048]{1,0}) %fusion.97), index=0
  %get-tuple-element.6905 = f32[2048,4096]{1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.79), index=15
  %custom-call.117 = f32[2048,4096]{1,0} custom-call(f32[16,2048]{1,0} %get-tuple-element.5052, f32[16,4096]{1,0} %fusion.91, f32[2048,4096]{1,0} %get-tuple-element.6905), custom_call_target="__cublas$gemm", metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}, backend_config="{\"alpha_real\":1,\"alpha_imag\":0,\"beta\":1,\"dot_dimension_numbers\":{\"lhs_contracting_dimensions\":[\"0\"],\"rhs_contracting_dimensions\":[\"0\"],\"lhs_batch_dimensions\":[],\"rhs_batch_dimensions\":[]},\"batch_size\":\"1\",\"selected_algorithm\":\"4\"}"
  %get-tuple-element.6909 = f32[4096]{0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.79), index=16
  %fusion.90 = f32[4096]{0} fusion(f32[4096]{0} %get-tuple-element.6909, f32[16,4096]{1,0} %fusion.91), kind=kLoop, calls=%fused_computation.90, metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %get-tuple-element.5053 = f32[16,2048]{1,0} get-tuple-element((f32[16,2048]{1,0}, f32[16,2048]{1,0}) %fusion.97), index=1
  ROOT %tuple.838 = (f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) tuple(f32[64,16,1024]{2,1,0} %get-tuple-element.6887, f32[64,16,1024]{2,1,0} %get-tuple-element.6888, f32[64,16,1024]{2,1,0} %get-tuple-element.6889, f32[64,16,2048]{2,1,0} %get-tuple-element.6890, f32[64,16,1024]{2,1,0} %get-tuple-element.6891, /*index=5*/f32[64,16,1024]{2,1,0} %get-tuple-element.6892, f32[64,16,1024]{2,1,0} %get-tuple-element.6893, f32[64,16,1024]{2,1,0} %get-tuple-element.6894, f32[64,16,1024]{2,1,0} %get-tuple-element.6895, f32[64,16,1024]{2,1,0} %get-tuple-element.6896, /*index=10*/f32[64,16,1024]{2,1,0} %get-tuple-element.6897, f32[64,16,1024]{2,1,0} %get-tuple-element.6898, f32[64,16,1024]{2,1,0} %get-tuple-element.6899, f32[2048,4096]{1,0} %get-tuple-element.6900, s32[] %add.1574, /*index=15*/f32[2048,4096]{1,0} %custom-call.117, f32[4096]{0} %fusion.90, f32[16,2048]{1,0} %get-tuple-element.5053, f32[64,16,1024]{2,1,0} %fusion.88)
}

%cond_computation__53.12417.clone.clone (parameter.80: (f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[64,16,2048], f32[64,16,1024], /*index=5*/f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], /*index=10*/f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[2048,4096], s32[], /*index=15*/f32[2048,4096], f32[4096], f32[16,2048], f32[64,16,1024])) -> pred[] {
  %parameter.80 = (f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) parameter(0)
  %get-tuple-element.3908 = s32[] get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %parameter.80), index=14
  %constant_9279 = s32[] constant(64), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/cond/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %compare.1230 = pred[] compare(s32[] %get-tuple-element.3908, s32[] %constant_9279), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/cond/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%primitive_computation_add__1.9819 (parameter.9820: f32[], parameter.9821: f32[]) -> f32[] {
  %parameter.9820 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.9821 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.9822 = f32[] add(f32[] %parameter.9820, f32[] %parameter.9821), metadata={op_type="add" op_name="add"}
}

%fused_computation.99 (param_0.207: f32[64,16,1024], param_1.2178: f32[16,1024], param_2.1831: s32[]) -> f32[64,16,1024] {
  %param_0.207 = f32[64,16,1024]{2,1,0} parameter(0)
  %constant_10798 = f32[] constant(1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %broadcast.1468 = f32[16,1024]{1,0} broadcast(f32[] %constant_10798), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %param_1.2178 = f32[16,1024]{1,0} parameter(1)
  %subtract.211 = f32[16,1024]{1,0} subtract(f32[16,1024]{1,0} %broadcast.1468, f32[16,1024]{1,0} %param_1.2178), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %bitcast.533 = f32[1,16,1024]{2,1,0} bitcast(f32[16,1024]{1,0} %subtract.211), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_2.1831 = s32[] parameter(2)
  %constant_10797 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.1746 = pred[] compare(s32[] %param_2.1831, s32[] %constant_10797), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_13673 = s32[] constant(64), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.2783 = s32[] add(s32[] %param_2.1831, s32[] %constant_13673), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %select.1737 = s32[] select(pred[] %compare.1746, s32[] %add.2783, s32[] %param_2.1831), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.500 = f32[64,16,1024]{2,1,0} dynamic-update-slice(f32[64,16,1024]{2,1,0} %param_0.207, f32[1,16,1024]{2,1,0} %bitcast.533, s32[] %select.1737, s32[] %constant_10797, s32[] %constant_10797), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.100 (param_0.208: f32[64,16,1024], param_1.2177: f32[16,1024], param_2.1829: s32[]) -> f32[64,16,1024] {
  %param_0.208 = f32[64,16,1024]{2,1,0} parameter(0)
  %param_1.2177 = f32[16,1024]{1,0} parameter(1)
  %bitcast.534 = f32[1,16,1024]{2,1,0} bitcast(f32[16,1024]{1,0} %param_1.2177), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_2.1829 = s32[] parameter(2)
  %constant_10799 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.1744 = pred[] compare(s32[] %param_2.1829, s32[] %constant_10799), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_13668 = s32[] constant(64), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.2780 = s32[] add(s32[] %param_2.1829, s32[] %constant_13668), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %select.1735 = s32[] select(pred[] %compare.1744, s32[] %add.2780, s32[] %param_2.1829), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.501 = f32[64,16,1024]{2,1,0} dynamic-update-slice(f32[64,16,1024]{2,1,0} %param_0.208, f32[1,16,1024]{2,1,0} %bitcast.534, s32[] %select.1735, s32[] %constant_10799, s32[] %constant_10799), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.101 (param_0.209: f32[64,16,1024], param_1.2176: f32[16,1024], param_2.1827: s32[]) -> f32[64,16,1024] {
  %param_0.209 = f32[64,16,1024]{2,1,0} parameter(0)
  %constant_10802 = f32[] constant(1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %broadcast.1469 = f32[16,1024]{1,0} broadcast(f32[] %constant_10802), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %param_1.2176 = f32[16,1024]{1,0} parameter(1)
  %subtract.212 = f32[16,1024]{1,0} subtract(f32[16,1024]{1,0} %broadcast.1469, f32[16,1024]{1,0} %param_1.2176), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  %bitcast.535 = f32[1,16,1024]{2,1,0} bitcast(f32[16,1024]{1,0} %subtract.212), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_2.1827 = s32[] parameter(2)
  %constant_10800 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.1742 = pred[] compare(s32[] %param_2.1827, s32[] %constant_10800), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_13662 = s32[] constant(64), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.2778 = s32[] add(s32[] %param_2.1827, s32[] %constant_13662), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %select.1733 = s32[] select(pred[] %compare.1742, s32[] %add.2778, s32[] %param_2.1827), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.502 = f32[64,16,1024]{2,1,0} dynamic-update-slice(f32[64,16,1024]{2,1,0} %param_0.209, f32[1,16,1024]{2,1,0} %bitcast.535, s32[] %select.1733, s32[] %constant_10800, s32[] %constant_10800), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.102 (param_0.210: f32[64,16,1024], param_1.2175: f32[16,1024], param_2.1825: s32[]) -> f32[64,16,1024] {
  %param_0.210 = f32[64,16,1024]{2,1,0} parameter(0)
  %param_1.2175 = f32[16,1024]{1,0} parameter(1)
  %bitcast.536 = f32[1,16,1024]{2,1,0} bitcast(f32[16,1024]{1,0} %param_1.2175), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_2.1825 = s32[] parameter(2)
  %constant_10803 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.1740 = pred[] compare(s32[] %param_2.1825, s32[] %constant_10803), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_13656 = s32[] constant(64), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.2776 = s32[] add(s32[] %param_2.1825, s32[] %constant_13656), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %select.1731 = s32[] select(pred[] %compare.1740, s32[] %add.2776, s32[] %param_2.1825), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.503 = f32[64,16,1024]{2,1,0} dynamic-update-slice(f32[64,16,1024]{2,1,0} %param_0.210, f32[1,16,1024]{2,1,0} %bitcast.536, s32[] %select.1731, s32[] %constant_10803, s32[] %constant_10803), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.103 (param_0.211: f32[64,16,1024], param_1.2174: f32[16,1024], param_2.1823: s32[]) -> f32[64,16,1024] {
  %param_0.211 = f32[64,16,1024]{2,1,0} parameter(0)
  %constant_10806 = f32[] constant(1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %broadcast.1470 = f32[16,1024]{1,0} broadcast(f32[] %constant_10806), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %param_1.2174 = f32[16,1024]{1,0} parameter(1)
  %subtract.213 = f32[16,1024]{1,0} subtract(f32[16,1024]{1,0} %broadcast.1470, f32[16,1024]{1,0} %param_1.2174), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %bitcast.537 = f32[1,16,1024]{2,1,0} bitcast(f32[16,1024]{1,0} %subtract.213), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_2.1823 = s32[] parameter(2)
  %constant_10805 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.1738 = pred[] compare(s32[] %param_2.1823, s32[] %constant_10805), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_13649 = s32[] constant(64), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.2773 = s32[] add(s32[] %param_2.1823, s32[] %constant_13649), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %select.1729 = s32[] select(pred[] %compare.1738, s32[] %add.2773, s32[] %param_2.1823), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.504 = f32[64,16,1024]{2,1,0} dynamic-update-slice(f32[64,16,1024]{2,1,0} %param_0.211, f32[1,16,1024]{2,1,0} %bitcast.537, s32[] %select.1729, s32[] %constant_10805, s32[] %constant_10805), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.104 (param_0.212: f32[64,16,1024], param_1.2173: f32[16,1024], param_2.1821: s32[]) -> f32[64,16,1024] {
  %param_0.212 = f32[64,16,1024]{2,1,0} parameter(0)
  %param_1.2173 = f32[16,1024]{1,0} parameter(1)
  %bitcast.538 = f32[1,16,1024]{2,1,0} bitcast(f32[16,1024]{1,0} %param_1.2173), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_2.1821 = s32[] parameter(2)
  %constant_10808 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.1736 = pred[] compare(s32[] %param_2.1821, s32[] %constant_10808), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_13643 = s32[] constant(64), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.2771 = s32[] add(s32[] %param_2.1821, s32[] %constant_13643), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %select.1727 = s32[] select(pred[] %compare.1736, s32[] %add.2771, s32[] %param_2.1821), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.505 = f32[64,16,1024]{2,1,0} dynamic-update-slice(f32[64,16,1024]{2,1,0} %param_0.212, f32[1,16,1024]{2,1,0} %bitcast.538, s32[] %select.1727, s32[] %constant_10808, s32[] %constant_10808), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.105 (param_0.213: f32[64,16,1024], param_1.2172: f32[16,1024], param_2.1819: s32[]) -> f32[64,16,1024] {
  %param_0.213 = f32[64,16,1024]{2,1,0} parameter(0)
  %constant_10810 = f32[] constant(1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %broadcast.1471 = f32[16,1024]{1,0} broadcast(f32[] %constant_10810), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %param_1.2172 = f32[16,1024]{1,0} parameter(1)
  %subtract.214 = f32[16,1024]{1,0} subtract(f32[16,1024]{1,0} %broadcast.1471, f32[16,1024]{1,0} %param_1.2172), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %bitcast.539 = f32[1,16,1024]{2,1,0} bitcast(f32[16,1024]{1,0} %subtract.214), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_2.1819 = s32[] parameter(2)
  %constant_10809 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.1734 = pred[] compare(s32[] %param_2.1819, s32[] %constant_10809), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_13637 = s32[] constant(64), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.2769 = s32[] add(s32[] %param_2.1819, s32[] %constant_13637), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %select.1725 = s32[] select(pred[] %compare.1734, s32[] %add.2769, s32[] %param_2.1819), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.506 = f32[64,16,1024]{2,1,0} dynamic-update-slice(f32[64,16,1024]{2,1,0} %param_0.213, f32[1,16,1024]{2,1,0} %bitcast.539, s32[] %select.1725, s32[] %constant_10809, s32[] %constant_10809), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.106 (param_0.214: f32[64,16,1024], param_1.2171: f32[16,1024], param_2.1817: s32[]) -> f32[64,16,1024] {
  %param_0.214 = f32[64,16,1024]{2,1,0} parameter(0)
  %param_1.2171 = f32[16,1024]{1,0} parameter(1)
  %bitcast.540 = f32[1,16,1024]{2,1,0} bitcast(f32[16,1024]{1,0} %param_1.2171), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_2.1817 = s32[] parameter(2)
  %constant_10811 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.1732 = pred[] compare(s32[] %param_2.1817, s32[] %constant_10811), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_13631 = s32[] constant(64), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.2767 = s32[] add(s32[] %param_2.1817, s32[] %constant_13631), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %select.1723 = s32[] select(pred[] %compare.1732, s32[] %add.2767, s32[] %param_2.1817), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.507 = f32[64,16,1024]{2,1,0} dynamic-update-slice(f32[64,16,1024]{2,1,0} %param_0.214, f32[1,16,1024]{2,1,0} %bitcast.540, s32[] %select.1723, s32[] %constant_10811, s32[] %constant_10811), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.107 (param_0.215: f32[64,16,1024], param_1.2170: f32[16,1024], param_2.1815: s32[]) -> f32[64,16,1024] {
  %param_0.215 = f32[64,16,1024]{2,1,0} parameter(0)
  %constant_10813 = f32[] constant(1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %broadcast.1472 = f32[16,1024]{1,0} broadcast(f32[] %constant_10813), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %param_1.2170 = f32[16,1024]{1,0} parameter(1)
  %subtract.215 = f32[16,1024]{1,0} subtract(f32[16,1024]{1,0} %broadcast.1472, f32[16,1024]{1,0} %param_1.2170), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %bitcast.541 = f32[1,16,1024]{2,1,0} bitcast(f32[16,1024]{1,0} %subtract.215), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_2.1815 = s32[] parameter(2)
  %constant_10812 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.1730 = pred[] compare(s32[] %param_2.1815, s32[] %constant_10812), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_13625 = s32[] constant(64), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.2764 = s32[] add(s32[] %param_2.1815, s32[] %constant_13625), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %select.1721 = s32[] select(pred[] %compare.1730, s32[] %add.2764, s32[] %param_2.1815), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.508 = f32[64,16,1024]{2,1,0} dynamic-update-slice(f32[64,16,1024]{2,1,0} %param_0.215, f32[1,16,1024]{2,1,0} %bitcast.541, s32[] %select.1721, s32[] %constant_10812, s32[] %constant_10812), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.108 (param_0.216: f32[64,16,2048], param_1.2169: f32[16,2048], param_2.1813: s32[]) -> f32[64,16,2048] {
  %param_0.216 = f32[64,16,2048]{2,1,0} parameter(0)
  %param_1.2169 = f32[16,2048]{1,0} parameter(1)
  %bitcast.542 = f32[1,16,2048]{2,1,0} bitcast(f32[16,2048]{1,0} %param_1.2169), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 16, 2048) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_2.1813 = s32[] parameter(2)
  %constant_10814 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.1728 = pred[] compare(s32[] %param_2.1813, s32[] %constant_10814), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_13619 = s32[] constant(64), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.2762 = s32[] add(s32[] %param_2.1813, s32[] %constant_13619), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %select.1719 = s32[] select(pred[] %compare.1728, s32[] %add.2762, s32[] %param_2.1813), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.509 = f32[64,16,2048]{2,1,0} dynamic-update-slice(f32[64,16,2048]{2,1,0} %param_0.216, f32[1,16,2048]{2,1,0} %bitcast.542, s32[] %select.1719, s32[] %constant_10814, s32[] %constant_10814), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.109 (param_0.217: f32[64,16,1024], param_1.2168: f32[16,2048], param_2.1811: s32[]) -> f32[64,16,1024] {
  %param_0.217 = f32[64,16,1024]{2,1,0} parameter(0)
  %param_1.2168 = f32[16,2048]{1,0} parameter(1)
  %slice.921 = f32[16,1024]{1,0} slice(f32[16,2048]{1,0} %param_1.2168), slice={[0:16], [0:1024]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(16, 1024)\n                                                     start_indices=(0, 0)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=54}
  %bitcast.543 = f32[1,16,1024]{2,1,0} bitcast(f32[16,1024]{1,0} %slice.921), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_2.1811 = s32[] parameter(2)
  %constant_10816 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.1726 = pred[] compare(s32[] %param_2.1811, s32[] %constant_10816), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_13613 = s32[] constant(64), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.2760 = s32[] add(s32[] %param_2.1811, s32[] %constant_13613), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %select.1717 = s32[] select(pred[] %compare.1726, s32[] %add.2760, s32[] %param_2.1811), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.510 = f32[64,16,1024]{2,1,0} dynamic-update-slice(f32[64,16,1024]{2,1,0} %param_0.217, f32[1,16,1024]{2,1,0} %bitcast.543, s32[] %select.1717, s32[] %constant_10816, s32[] %constant_10816), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.110 (param_0.218: f32[64,16,1024], param_1.2167: f32[16,1024], param_2.1809: s32[]) -> f32[64,16,1024] {
  %param_0.218 = f32[64,16,1024]{2,1,0} parameter(0)
  %param_1.2167 = f32[16,1024]{1,0} parameter(1)
  %bitcast.544 = f32[1,16,1024]{2,1,0} bitcast(f32[16,1024]{1,0} %param_1.2167), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_2.1809 = s32[] parameter(2)
  %constant_10817 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.1724 = pred[] compare(s32[] %param_2.1809, s32[] %constant_10817), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_13606 = s32[] constant(64), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.2757 = s32[] add(s32[] %param_2.1809, s32[] %constant_13606), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %select.1715 = s32[] select(pred[] %compare.1724, s32[] %add.2757, s32[] %param_2.1809), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.511 = f32[64,16,1024]{2,1,0} dynamic-update-slice(f32[64,16,1024]{2,1,0} %param_0.218, f32[1,16,1024]{2,1,0} %bitcast.544, s32[] %select.1715, s32[] %constant_10817, s32[] %constant_10817), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.111 (param_0.219: f32[64,16,1024], param_1.2166: f32[16,1024], param_2.1807: f32[16,1024], param_3.1532: s32[]) -> f32[64,16,1024] {
  %param_0.219 = f32[64,16,1024]{2,1,0} parameter(0)
  %param_1.2166 = f32[16,1024]{1,0} parameter(1)
  %param_2.1807 = f32[16,1024]{1,0} parameter(2)
  %multiply.1378 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %param_1.2166, f32[16,1024]{1,0} %param_2.1807), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  %bitcast.545 = f32[1,16,1024]{2,1,0} bitcast(f32[16,1024]{1,0} %multiply.1378), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_3.1532 = s32[] parameter(3)
  %constant_10819 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.1722 = pred[] compare(s32[] %param_3.1532, s32[] %constant_10819), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_13600 = s32[] constant(64), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.2755 = s32[] add(s32[] %param_3.1532, s32[] %constant_13600), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %select.1713 = s32[] select(pred[] %compare.1722, s32[] %add.2755, s32[] %param_3.1532), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.512 = f32[64,16,1024]{2,1,0} dynamic-update-slice(f32[64,16,1024]{2,1,0} %param_0.219, f32[1,16,1024]{2,1,0} %bitcast.545, s32[] %select.1713, s32[] %constant_10819, s32[] %constant_10819), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.117 (param_0.228: f32[1,4096]) -> f32[16,4096] {
  %param_0.228 = f32[1,4096]{1,0} parameter(0)
  %bitcast.546 = f32[4096]{0} bitcast(f32[1,4096]{1,0} %param_0.228), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  ROOT %broadcast.1274 = f32[16,4096]{1,0} broadcast(f32[4096]{0} %bitcast.546), dimensions={1}, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
}

%fused_computation.118 (param_0.230: f32[16,2048], param_1.326: f32[64,16,1024], param_2.1806: s32[]) -> f32[16,2048] {
  %param_1.326 = f32[64,16,1024]{2,1,0} parameter(1)
  %param_2.1806 = s32[] parameter(2)
  %constant_10823 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.1720 = pred[] compare(s32[] %param_2.1806, s32[] %constant_10823), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_13595 = s32[] constant(64), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.2753 = s32[] add(s32[] %param_2.1806, s32[] %constant_13595), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %select.1711 = s32[] select(pred[] %compare.1720, s32[] %add.2753, s32[] %param_2.1806), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %dynamic-slice.402 = f32[1,16,1024]{2,1,0} dynamic-slice(f32[64,16,1024]{2,1,0} %param_1.326, s32[] %select.1711, s32[] %constant_10823, s32[] %constant_10823), dynamic_slice_sizes={1,16,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %bitcast.547 = f32[16,1024]{1,0} bitcast(f32[1,16,1024]{2,1,0} %dynamic-slice.402), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_0.230 = f32[16,2048]{1,0} parameter(0)
  %slice.858 = f32[16,1024]{1,0} slice(f32[16,2048]{1,0} %param_0.230), slice={[0:16], [1024:2048]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(16, 2048)\n                                                     start_indices=(0, 1024)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=54}
  ROOT %concatenate.190 = f32[16,2048]{1,0} concatenate(f32[16,1024]{1,0} %bitcast.547, f32[16,1024]{1,0} %slice.858), dimensions={1}, metadata={op_type="concatenate" op_name="pmap(_multi_device_update_fn)/scan/while/body/concatenate[ dimension=1 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
}

%fused_computation.662 (param_0.1243: f32[16,1024], param_1.1574: f32[16,1024], param_2.966: f32[16,1024]) -> f32[16,2048] {
  %param_0.1243 = f32[16,1024]{1,0} parameter(0)
  %param_1.1574 = f32[16,1024]{1,0} parameter(1)
  %param_2.966 = f32[16,1024]{1,0} parameter(2)
  %multiply.1379 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %param_1.1574, f32[16,1024]{1,0} %param_2.966), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  ROOT %concatenate.205 = f32[16,2048]{1,0} concatenate(f32[16,1024]{1,0} %param_0.1243, f32[16,1024]{1,0} %multiply.1379), dimensions={1}, metadata={op_type="concatenate" op_name="pmap(_multi_device_update_fn)/scan/while/body/concatenate[ dimension=1 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=65}
}

%fused_computation.740 (param_0.2172: f32[16,2048], param_1.2628: f32[16,4096]) -> (f32[16,1024], f32[16,1024], f32[16,1024], f32[16,1024], f32[16,1024], /*index=5*/f32[16,1024]) {
  %param_0.2172 = f32[16,2048]{1,0} parameter(0)
  %slice.922.clone.1 = f32[16,1024]{1,0} slice(f32[16,2048]{1,0} %param_0.2172), slice={[0:16], [0:1024]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(16, 1024)\n                                                     start_indices=(0, 0)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=54}
  %constant_10821_clone_1 = f32[] constant(1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %broadcast.1474.clone.1 = f32[16,1024]{1,0} broadcast(f32[] %constant_10821_clone_1), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %param_1.2628 = f32[16,4096]{1,0} parameter(1)
  %slice.857.clone.1 = f32[16,1024]{1,0} slice(f32[16,4096]{1,0} %param_1.2628), slice={[0:16], [2048:3072]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(16, 3072)\n                                                     start_indices=(0, 2048)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  %negate.129.clone.1 = f32[16,1024]{1,0} negate(f32[16,1024]{1,0} %slice.857.clone.1), metadata={op_type="neg" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/neg" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %exponential.110.clone.1 = f32[16,1024]{1,0} exponential(f32[16,1024]{1,0} %negate.129.clone.1), metadata={op_type="exp" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/exp" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %add.1862.clone.1 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %broadcast.1474.clone.1, f32[16,1024]{1,0} %exponential.110.clone.1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %divide.114.clone.1 = f32[16,1024]{1,0} divide(f32[16,1024]{1,0} %broadcast.1474.clone.1, f32[16,1024]{1,0} %add.1862.clone.1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %multiply.930.clone.1 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %slice.922.clone.1, f32[16,1024]{1,0} %divide.114.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %slice.856.clone.1 = f32[16,1024]{1,0} slice(f32[16,4096]{1,0} %param_1.2628), slice={[0:16], [0:1024]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(16, 1024)\n                                                     start_indices=(0, 0)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  %negate.128.clone.1 = f32[16,1024]{1,0} negate(f32[16,1024]{1,0} %slice.856.clone.1), metadata={op_type="neg" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/neg" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %exponential.109.clone.1 = f32[16,1024]{1,0} exponential(f32[16,1024]{1,0} %negate.128.clone.1), metadata={op_type="exp" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/exp" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %add.1861.clone.1 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %broadcast.1474.clone.1, f32[16,1024]{1,0} %exponential.109.clone.1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %divide.113.clone.1 = f32[16,1024]{1,0} divide(f32[16,1024]{1,0} %broadcast.1474.clone.1, f32[16,1024]{1,0} %add.1861.clone.1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %slice.855.clone.1 = f32[16,1024]{1,0} slice(f32[16,4096]{1,0} %param_1.2628), slice={[0:16], [1024:2048]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(16, 2048)\n                                                     start_indices=(0, 1024)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  %tanh.72.clone.1 = f32[16,1024]{1,0} tanh(f32[16,1024]{1,0} %slice.855.clone.1), metadata={op_type="tanh" op_name="pmap(_multi_device_update_fn)/scan/while/body/tanh" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %multiply.929.clone.1 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %divide.113.clone.1, f32[16,1024]{1,0} %tanh.72.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %add.1860.clone.1 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %multiply.930.clone.1, f32[16,1024]{1,0} %multiply.929.clone.1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %tanh.81 = f32[16,1024]{1,0} tanh(f32[16,1024]{1,0} %add.1860.clone.1), metadata={op_type="tanh" op_name="pmap(_multi_device_update_fn)/scan/while/body/tanh" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  %slice.854.clone.1 = f32[16,1024]{1,0} slice(f32[16,4096]{1,0} %param_1.2628), slice={[0:16], [3072:4096]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(16, 4096)\n                                                     start_indices=(0, 3072)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  %negate.127.clone.1 = f32[16,1024]{1,0} negate(f32[16,1024]{1,0} %slice.854.clone.1), metadata={op_type="neg" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/neg" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %exponential.108.clone.1 = f32[16,1024]{1,0} exponential(f32[16,1024]{1,0} %negate.127.clone.1), metadata={op_type="exp" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/exp" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %add.1859.clone.1 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %broadcast.1474.clone.1, f32[16,1024]{1,0} %exponential.108.clone.1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %divide.112.clone.1 = f32[16,1024]{1,0} divide(f32[16,1024]{1,0} %broadcast.1474.clone.1, f32[16,1024]{1,0} %add.1859.clone.1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  ROOT %tuple.478 = (f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, /*index=5*/f32[16,1024]{1,0}) tuple(f32[16,1024]{1,0} %tanh.81, f32[16,1024]{1,0} %add.1860.clone.1, f32[16,1024]{1,0} %divide.114.clone.1, f32[16,1024]{1,0} %tanh.72.clone.1, f32[16,1024]{1,0} %divide.113.clone.1, /*index=5*/f32[16,1024]{1,0} %divide.112.clone.1)
}

%body_computation__36.499.clone.clone.clone.clone (parameter.81: (f32[64,16,1024], f32[2048,4096], f32[1,4096], s32[], f32[16,2048], /*index=5*/f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[64,16,2048], f32[64,16,1024], /*index=10*/f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], /*index=15*/f32[64,16,1024], f32[64,16,1024], f32[64,16,1024])) -> (f32[64,16,1024], f32[2048,4096], f32[1,4096], s32[], f32[16,2048], /*index=5*/f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[64,16,2048], f32[64,16,1024], /*index=10*/f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], /*index=15*/f32[64,16,1024], f32[64,16,1024], f32[64,16,1024]) {
  %parameter.81 = (f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) parameter(0)
  %get-tuple-element.5781 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %parameter.81), index=0
  %get-tuple-element.5782 = f32[2048,4096]{1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %parameter.81), index=1
  %get-tuple-element.5783 = f32[1,4096]{1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %parameter.81), index=2
  %get-tuple-element.5797 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %parameter.81), index=16
  %get-tuple-element.5785 = f32[16,2048]{1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %parameter.81), index=4
  %get-tuple-element.5784 = s32[] get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %parameter.81), index=3
  %fusion.118 = f32[16,2048]{1,0} fusion(f32[16,2048]{1,0} %get-tuple-element.5785, f32[64,16,1024]{2,1,0} %get-tuple-element.5781, s32[] %get-tuple-element.5784), kind=kLoop, calls=%fused_computation.118, metadata={op_type="concatenate" op_name="pmap(_multi_device_update_fn)/scan/while/body/concatenate[ dimension=1 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %fusion.117 = f32[16,4096]{1,0} fusion(f32[1,4096]{1,0} %get-tuple-element.5783), kind=kLoop, calls=%fused_computation.117, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %custom-call.120 = f32[16,4096]{1,0} custom-call(f32[16,2048]{1,0} %fusion.118, f32[2048,4096]{1,0} %get-tuple-element.5782, f32[16,4096]{1,0} %fusion.117), custom_call_target="__cublas$gemm", metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}, backend_config="{\"alpha_real\":1,\"alpha_imag\":0,\"beta\":1,\"dot_dimension_numbers\":{\"lhs_contracting_dimensions\":[\"1\"],\"rhs_contracting_dimensions\":[\"0\"],\"lhs_batch_dimensions\":[],\"rhs_batch_dimensions\":[]},\"batch_size\":\"1\",\"selected_algorithm\":\"0\"}"
  %fusion.740 = (f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, /*index=5*/f32[16,1024]{1,0}) fusion(f32[16,2048]{1,0} %get-tuple-element.5785, f32[16,4096]{1,0} %custom-call.120), kind=kLoop, calls=%fused_computation.740, metadata={op_type="tanh" op_name="pmap(_multi_device_update_fn)/scan/while/body/tanh" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  %get-tuple-element.5059 = f32[16,1024]{1,0} get-tuple-element((f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, /*index=5*/f32[16,1024]{1,0}) %fusion.740), index=5
  %fusion.100 = f32[64,16,1024]{2,1,0} fusion(f32[64,16,1024]{2,1,0} %get-tuple-element.5797, f32[16,1024]{1,0} %get-tuple-element.5059, s32[] %get-tuple-element.5784), kind=kLoop, calls=%fused_computation.100, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.5796 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %parameter.81), index=15
  %get-tuple-element.5054 = f32[16,1024]{1,0} get-tuple-element((f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, /*index=5*/f32[16,1024]{1,0}) %fusion.740), index=0
  %fusion.101 = f32[64,16,1024]{2,1,0} fusion(f32[64,16,1024]{2,1,0} %get-tuple-element.5796, f32[16,1024]{1,0} %get-tuple-element.5054, s32[] %get-tuple-element.5784), kind=kLoop, calls=%fused_computation.101, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.5795 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %parameter.81), index=14
  %fusion.102 = f32[64,16,1024]{2,1,0} fusion(f32[64,16,1024]{2,1,0} %get-tuple-element.5795, f32[16,1024]{1,0} %get-tuple-element.5054, s32[] %get-tuple-element.5784), kind=kLoop, calls=%fused_computation.102, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.5794 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %parameter.81), index=13
  %get-tuple-element.5057 = f32[16,1024]{1,0} get-tuple-element((f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, /*index=5*/f32[16,1024]{1,0}) %fusion.740), index=3
  %fusion.103 = f32[64,16,1024]{2,1,0} fusion(f32[64,16,1024]{2,1,0} %get-tuple-element.5794, f32[16,1024]{1,0} %get-tuple-element.5057, s32[] %get-tuple-element.5784), kind=kLoop, calls=%fused_computation.103, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.5793 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %parameter.81), index=12
  %fusion.104 = f32[64,16,1024]{2,1,0} fusion(f32[64,16,1024]{2,1,0} %get-tuple-element.5793, f32[16,1024]{1,0} %get-tuple-element.5057, s32[] %get-tuple-element.5784), kind=kLoop, calls=%fused_computation.104, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.5792 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %parameter.81), index=11
  %get-tuple-element.5058 = f32[16,1024]{1,0} get-tuple-element((f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, /*index=5*/f32[16,1024]{1,0}) %fusion.740), index=4
  %fusion.105 = f32[64,16,1024]{2,1,0} fusion(f32[64,16,1024]{2,1,0} %get-tuple-element.5792, f32[16,1024]{1,0} %get-tuple-element.5058, s32[] %get-tuple-element.5784), kind=kLoop, calls=%fused_computation.105, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.5791 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %parameter.81), index=10
  %fusion.106 = f32[64,16,1024]{2,1,0} fusion(f32[64,16,1024]{2,1,0} %get-tuple-element.5791, f32[16,1024]{1,0} %get-tuple-element.5058, s32[] %get-tuple-element.5784), kind=kLoop, calls=%fused_computation.106, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.5790 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %parameter.81), index=9
  %get-tuple-element.5056 = f32[16,1024]{1,0} get-tuple-element((f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, /*index=5*/f32[16,1024]{1,0}) %fusion.740), index=2
  %fusion.107 = f32[64,16,1024]{2,1,0} fusion(f32[64,16,1024]{2,1,0} %get-tuple-element.5790, f32[16,1024]{1,0} %get-tuple-element.5056, s32[] %get-tuple-element.5784), kind=kLoop, calls=%fused_computation.107, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.5789 = f32[64,16,2048]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %parameter.81), index=8
  %fusion.108 = f32[64,16,2048]{2,1,0} fusion(f32[64,16,2048]{2,1,0} %get-tuple-element.5789, f32[16,2048]{1,0} %fusion.118, s32[] %get-tuple-element.5784), kind=kLoop, calls=%fused_computation.108, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.5788 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %parameter.81), index=7
  %fusion.109 = f32[64,16,1024]{2,1,0} fusion(f32[64,16,1024]{2,1,0} %get-tuple-element.5788, f32[16,2048]{1,0} %get-tuple-element.5785, s32[] %get-tuple-element.5784), kind=kLoop, calls=%fused_computation.109, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.5787 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %parameter.81), index=6
  %fusion.110 = f32[64,16,1024]{2,1,0} fusion(f32[64,16,1024]{2,1,0} %get-tuple-element.5787, f32[16,1024]{1,0} %get-tuple-element.5056, s32[] %get-tuple-element.5784), kind=kLoop, calls=%fused_computation.110, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.5786 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %parameter.81), index=5
  %fusion.111 = f32[64,16,1024]{2,1,0} fusion(f32[64,16,1024]{2,1,0} %get-tuple-element.5786, f32[16,1024]{1,0} %get-tuple-element.5054, f32[16,1024]{1,0} %get-tuple-element.5059, s32[] %get-tuple-element.5784), kind=kLoop, calls=%fused_computation.111, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.5798 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %parameter.81), index=17
  %fusion.99 = f32[64,16,1024]{2,1,0} fusion(f32[64,16,1024]{2,1,0} %get-tuple-element.5798, f32[16,1024]{1,0} %get-tuple-element.5059, s32[] %get-tuple-element.5784), kind=kLoop, calls=%fused_computation.99, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_9664 = s32[] constant(1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.1598 = s32[] add(s32[] %get-tuple-element.5784, s32[] %constant_9664), control-predecessors={%fusion.99, %fusion.118, %fusion.111, %fusion.110, %fusion.109, %fusion.108, %fusion.107, %fusion.106, %fusion.105, %fusion.104, %fusion.103, %fusion.102, %fusion.101, %fusion.100}, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.5055 = f32[16,1024]{1,0} get-tuple-element((f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, /*index=5*/f32[16,1024]{1,0}) %fusion.740), index=1
  %fusion.662 = f32[16,2048]{1,0} fusion(f32[16,1024]{1,0} %get-tuple-element.5055, f32[16,1024]{1,0} %get-tuple-element.5054, f32[16,1024]{1,0} %get-tuple-element.5059), kind=kLoop, calls=%fused_computation.662, control-predecessors={%fusion.118, %fusion.740, %fusion.109}, metadata={op_type="concatenate" op_name="pmap(_multi_device_update_fn)/scan/while/body/concatenate[ dimension=1 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=65}
  ROOT %tuple.790 = (f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) tuple(f32[64,16,1024]{2,1,0} %get-tuple-element.5781, f32[2048,4096]{1,0} %get-tuple-element.5782, f32[1,4096]{1,0} %get-tuple-element.5783, s32[] %add.1598, f32[16,2048]{1,0} %fusion.662, /*index=5*/f32[64,16,1024]{2,1,0} %fusion.111, f32[64,16,1024]{2,1,0} %fusion.110, f32[64,16,1024]{2,1,0} %fusion.109, f32[64,16,2048]{2,1,0} %fusion.108, f32[64,16,1024]{2,1,0} %fusion.107, /*index=10*/f32[64,16,1024]{2,1,0} %fusion.106, f32[64,16,1024]{2,1,0} %fusion.105, f32[64,16,1024]{2,1,0} %fusion.104, f32[64,16,1024]{2,1,0} %fusion.103, f32[64,16,1024]{2,1,0} %fusion.102, /*index=15*/f32[64,16,1024]{2,1,0} %fusion.101, f32[64,16,1024]{2,1,0} %fusion.100, f32[64,16,1024]{2,1,0} %fusion.99)
}

%cond_computation__36.920.clone.clone.clone (parameter.171: (f32[64,16,1024], f32[2048,4096], f32[1,4096], s32[], f32[16,2048], /*index=5*/f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[64,16,2048], f32[64,16,1024], /*index=10*/f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], /*index=15*/f32[64,16,1024], f32[64,16,1024], f32[64,16,1024])) -> pred[] {
  %parameter.171 = (f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) parameter(0)
  %get-tuple-element.4012 = s32[] get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %parameter.171), index=3
  %constant_9668 = s32[] constant(64), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/cond/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %compare.1246 = pred[] compare(s32[] %get-tuple-element.4012, s32[] %constant_9668), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/cond/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.120 (param_0.233: f32[64,16,1024], param_1.2191: f32[16,1024], param_2.1858: s32[]) -> f32[64,16,1024] {
  %param_0.233 = f32[64,16,1024]{2,1,0} parameter(0)
  %constant_10828 = f32[] constant(1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %broadcast.1476 = f32[16,1024]{1,0} broadcast(f32[] %constant_10828), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %param_1.2191 = f32[16,1024]{1,0} parameter(1)
  %subtract.216 = f32[16,1024]{1,0} subtract(f32[16,1024]{1,0} %broadcast.1476, f32[16,1024]{1,0} %param_1.2191), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %bitcast.548 = f32[1,16,1024]{2,1,0} bitcast(f32[16,1024]{1,0} %subtract.216), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_2.1858 = s32[] parameter(2)
  %constant_10827 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.1774 = pred[] compare(s32[] %param_2.1858, s32[] %constant_10827), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_13759 = s32[] constant(64), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.2815 = s32[] add(s32[] %param_2.1858, s32[] %constant_13759), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %select.1765 = s32[] select(pred[] %compare.1774, s32[] %add.2815, s32[] %param_2.1858), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.513 = f32[64,16,1024]{2,1,0} dynamic-update-slice(f32[64,16,1024]{2,1,0} %param_0.233, f32[1,16,1024]{2,1,0} %bitcast.548, s32[] %select.1765, s32[] %constant_10827, s32[] %constant_10827), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.121 (param_0.234: f32[64,16,1024], param_1.2190: f32[16,1024], param_2.1856: s32[]) -> f32[64,16,1024] {
  %param_0.234 = f32[64,16,1024]{2,1,0} parameter(0)
  %param_1.2190 = f32[16,1024]{1,0} parameter(1)
  %bitcast.549 = f32[1,16,1024]{2,1,0} bitcast(f32[16,1024]{1,0} %param_1.2190), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_2.1856 = s32[] parameter(2)
  %constant_10831 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.1772 = pred[] compare(s32[] %param_2.1856, s32[] %constant_10831), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_13753 = s32[] constant(64), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.2813 = s32[] add(s32[] %param_2.1856, s32[] %constant_13753), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %select.1763 = s32[] select(pred[] %compare.1772, s32[] %add.2813, s32[] %param_2.1856), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.514 = f32[64,16,1024]{2,1,0} dynamic-update-slice(f32[64,16,1024]{2,1,0} %param_0.234, f32[1,16,1024]{2,1,0} %bitcast.549, s32[] %select.1763, s32[] %constant_10831, s32[] %constant_10831), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.122 (param_0.235: f32[64,16,1024], param_1.2189: f32[16,1024], param_2.1854: s32[]) -> f32[64,16,1024] {
  %param_0.235 = f32[64,16,1024]{2,1,0} parameter(0)
  %constant_10836 = f32[] constant(1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %broadcast.1477 = f32[16,1024]{1,0} broadcast(f32[] %constant_10836), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %param_1.2189 = f32[16,1024]{1,0} parameter(1)
  %subtract.217 = f32[16,1024]{1,0} subtract(f32[16,1024]{1,0} %broadcast.1477, f32[16,1024]{1,0} %param_1.2189), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  %bitcast.550 = f32[1,16,1024]{2,1,0} bitcast(f32[16,1024]{1,0} %subtract.217), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_2.1854 = s32[] parameter(2)
  %constant_10834 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.1770 = pred[] compare(s32[] %param_2.1854, s32[] %constant_10834), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_13747 = s32[] constant(64), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.2810 = s32[] add(s32[] %param_2.1854, s32[] %constant_13747), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %select.1761 = s32[] select(pred[] %compare.1770, s32[] %add.2810, s32[] %param_2.1854), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.515 = f32[64,16,1024]{2,1,0} dynamic-update-slice(f32[64,16,1024]{2,1,0} %param_0.235, f32[1,16,1024]{2,1,0} %bitcast.550, s32[] %select.1761, s32[] %constant_10834, s32[] %constant_10834), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.123 (param_0.236: f32[64,16,1024], param_1.2188: f32[16,1024], param_2.1852: s32[]) -> f32[64,16,1024] {
  %param_0.236 = f32[64,16,1024]{2,1,0} parameter(0)
  %param_1.2188 = f32[16,1024]{1,0} parameter(1)
  %bitcast.551 = f32[1,16,1024]{2,1,0} bitcast(f32[16,1024]{1,0} %param_1.2188), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_2.1852 = s32[] parameter(2)
  %constant_10839 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.1768 = pred[] compare(s32[] %param_2.1852, s32[] %constant_10839), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_13741 = s32[] constant(64), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.2808 = s32[] add(s32[] %param_2.1852, s32[] %constant_13741), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %select.1759 = s32[] select(pred[] %compare.1768, s32[] %add.2808, s32[] %param_2.1852), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.516 = f32[64,16,1024]{2,1,0} dynamic-update-slice(f32[64,16,1024]{2,1,0} %param_0.236, f32[1,16,1024]{2,1,0} %bitcast.551, s32[] %select.1759, s32[] %constant_10839, s32[] %constant_10839), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.124 (param_0.237: f32[64,16,1024], param_1.2187: f32[16,1024], param_2.1850: s32[]) -> f32[64,16,1024] {
  %param_0.237 = f32[64,16,1024]{2,1,0} parameter(0)
  %constant_10844 = f32[] constant(1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %broadcast.1478 = f32[16,1024]{1,0} broadcast(f32[] %constant_10844), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %param_1.2187 = f32[16,1024]{1,0} parameter(1)
  %subtract.218 = f32[16,1024]{1,0} subtract(f32[16,1024]{1,0} %broadcast.1478, f32[16,1024]{1,0} %param_1.2187), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %bitcast.552 = f32[1,16,1024]{2,1,0} bitcast(f32[16,1024]{1,0} %subtract.218), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_2.1850 = s32[] parameter(2)
  %constant_10842 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.1766 = pred[] compare(s32[] %param_2.1850, s32[] %constant_10842), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_13735 = s32[] constant(64), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.2806 = s32[] add(s32[] %param_2.1850, s32[] %constant_13735), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %select.1757 = s32[] select(pred[] %compare.1766, s32[] %add.2806, s32[] %param_2.1850), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.517 = f32[64,16,1024]{2,1,0} dynamic-update-slice(f32[64,16,1024]{2,1,0} %param_0.237, f32[1,16,1024]{2,1,0} %bitcast.552, s32[] %select.1757, s32[] %constant_10842, s32[] %constant_10842), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.125 (param_0.238: f32[64,16,1024], param_1.2186: f32[16,1024], param_2.1848: s32[]) -> f32[64,16,1024] {
  %param_0.238 = f32[64,16,1024]{2,1,0} parameter(0)
  %param_1.2186 = f32[16,1024]{1,0} parameter(1)
  %bitcast.553 = f32[1,16,1024]{2,1,0} bitcast(f32[16,1024]{1,0} %param_1.2186), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_2.1848 = s32[] parameter(2)
  %constant_10845 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.1764 = pred[] compare(s32[] %param_2.1848, s32[] %constant_10845), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_13728 = s32[] constant(64), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.2803 = s32[] add(s32[] %param_2.1848, s32[] %constant_13728), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %select.1755 = s32[] select(pred[] %compare.1764, s32[] %add.2803, s32[] %param_2.1848), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.518 = f32[64,16,1024]{2,1,0} dynamic-update-slice(f32[64,16,1024]{2,1,0} %param_0.238, f32[1,16,1024]{2,1,0} %bitcast.553, s32[] %select.1755, s32[] %constant_10845, s32[] %constant_10845), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.126 (param_0.239: f32[64,16,1024], param_1.2185: f32[16,1024], param_2.1846: s32[]) -> f32[64,16,1024] {
  %param_0.239 = f32[64,16,1024]{2,1,0} parameter(0)
  %constant_10851 = f32[] constant(1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %broadcast.1480 = f32[16,1024]{1,0} broadcast(f32[] %constant_10851), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %param_1.2185 = f32[16,1024]{1,0} parameter(1)
  %subtract.219 = f32[16,1024]{1,0} subtract(f32[16,1024]{1,0} %broadcast.1480, f32[16,1024]{1,0} %param_1.2185), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %bitcast.554 = f32[1,16,1024]{2,1,0} bitcast(f32[16,1024]{1,0} %subtract.219), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_2.1846 = s32[] parameter(2)
  %constant_10847 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.1762 = pred[] compare(s32[] %param_2.1846, s32[] %constant_10847), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_13722 = s32[] constant(64), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.2801 = s32[] add(s32[] %param_2.1846, s32[] %constant_13722), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %select.1753 = s32[] select(pred[] %compare.1762, s32[] %add.2801, s32[] %param_2.1846), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.519 = f32[64,16,1024]{2,1,0} dynamic-update-slice(f32[64,16,1024]{2,1,0} %param_0.239, f32[1,16,1024]{2,1,0} %bitcast.554, s32[] %select.1753, s32[] %constant_10847, s32[] %constant_10847), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.127 (param_0.240: f32[64,16,1024], param_1.2184: f32[16,1024], param_2.1844: s32[]) -> f32[64,16,1024] {
  %param_0.240 = f32[64,16,1024]{2,1,0} parameter(0)
  %param_1.2184 = f32[16,1024]{1,0} parameter(1)
  %bitcast.555 = f32[1,16,1024]{2,1,0} bitcast(f32[16,1024]{1,0} %param_1.2184), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_2.1844 = s32[] parameter(2)
  %constant_10852 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.1760 = pred[] compare(s32[] %param_2.1844, s32[] %constant_10852), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_13716 = s32[] constant(64), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.2799 = s32[] add(s32[] %param_2.1844, s32[] %constant_13716), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %select.1751 = s32[] select(pred[] %compare.1760, s32[] %add.2799, s32[] %param_2.1844), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.520 = f32[64,16,1024]{2,1,0} dynamic-update-slice(f32[64,16,1024]{2,1,0} %param_0.240, f32[1,16,1024]{2,1,0} %bitcast.555, s32[] %select.1751, s32[] %constant_10852, s32[] %constant_10852), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.128 (param_0.241: f32[64,16,1024], param_1.2183: f32[16,1024], param_2.1842: s32[]) -> f32[64,16,1024] {
  %param_0.241 = f32[64,16,1024]{2,1,0} parameter(0)
  %constant_10854 = f32[] constant(1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %broadcast.1481 = f32[16,1024]{1,0} broadcast(f32[] %constant_10854), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %param_1.2183 = f32[16,1024]{1,0} parameter(1)
  %subtract.220 = f32[16,1024]{1,0} subtract(f32[16,1024]{1,0} %broadcast.1481, f32[16,1024]{1,0} %param_1.2183), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %bitcast.556 = f32[1,16,1024]{2,1,0} bitcast(f32[16,1024]{1,0} %subtract.220), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_2.1842 = s32[] parameter(2)
  %constant_10853 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.1758 = pred[] compare(s32[] %param_2.1842, s32[] %constant_10853), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_13710 = s32[] constant(64), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.2796 = s32[] add(s32[] %param_2.1842, s32[] %constant_13710), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %select.1749 = s32[] select(pred[] %compare.1758, s32[] %add.2796, s32[] %param_2.1842), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.521 = f32[64,16,1024]{2,1,0} dynamic-update-slice(f32[64,16,1024]{2,1,0} %param_0.241, f32[1,16,1024]{2,1,0} %bitcast.556, s32[] %select.1749, s32[] %constant_10853, s32[] %constant_10853), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.129 (param_0.242: f32[64,16,2048], param_1.2182: f32[16,2048], param_2.1840: s32[]) -> f32[64,16,2048] {
  %param_0.242 = f32[64,16,2048]{2,1,0} parameter(0)
  %param_1.2182 = f32[16,2048]{1,0} parameter(1)
  %bitcast.557 = f32[1,16,2048]{2,1,0} bitcast(f32[16,2048]{1,0} %param_1.2182), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 16, 2048) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_2.1840 = s32[] parameter(2)
  %constant_10855 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.1756 = pred[] compare(s32[] %param_2.1840, s32[] %constant_10855), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_13704 = s32[] constant(64), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.2794 = s32[] add(s32[] %param_2.1840, s32[] %constant_13704), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %select.1747 = s32[] select(pred[] %compare.1756, s32[] %add.2794, s32[] %param_2.1840), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.522 = f32[64,16,2048]{2,1,0} dynamic-update-slice(f32[64,16,2048]{2,1,0} %param_0.242, f32[1,16,2048]{2,1,0} %bitcast.557, s32[] %select.1747, s32[] %constant_10855, s32[] %constant_10855), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.130 (param_0.243: f32[64,16,1024], param_1.2181: f32[16,2048], param_2.1838: s32[]) -> f32[64,16,1024] {
  %param_0.243 = f32[64,16,1024]{2,1,0} parameter(0)
  %param_1.2181 = f32[16,2048]{1,0} parameter(1)
  %slice.923 = f32[16,1024]{1,0} slice(f32[16,2048]{1,0} %param_1.2181), slice={[0:16], [0:1024]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(16, 1024)\n                                                     start_indices=(0, 0)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=54}
  %bitcast.558 = f32[1,16,1024]{2,1,0} bitcast(f32[16,1024]{1,0} %slice.923), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_2.1838 = s32[] parameter(2)
  %constant_10856 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.1754 = pred[] compare(s32[] %param_2.1838, s32[] %constant_10856), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_13698 = s32[] constant(64), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.2792 = s32[] add(s32[] %param_2.1838, s32[] %constant_13698), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %select.1745 = s32[] select(pred[] %compare.1754, s32[] %add.2792, s32[] %param_2.1838), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.523 = f32[64,16,1024]{2,1,0} dynamic-update-slice(f32[64,16,1024]{2,1,0} %param_0.243, f32[1,16,1024]{2,1,0} %bitcast.558, s32[] %select.1745, s32[] %constant_10856, s32[] %constant_10856), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.131 (param_0.244: f32[64,16,1024], param_1.2180: f32[16,1024], param_2.1836: s32[]) -> f32[64,16,1024] {
  %param_0.244 = f32[64,16,1024]{2,1,0} parameter(0)
  %param_1.2180 = f32[16,1024]{1,0} parameter(1)
  %bitcast.559 = f32[1,16,1024]{2,1,0} bitcast(f32[16,1024]{1,0} %param_1.2180), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_2.1836 = s32[] parameter(2)
  %constant_10857 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.1752 = pred[] compare(s32[] %param_2.1836, s32[] %constant_10857), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_13692 = s32[] constant(64), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.2790 = s32[] add(s32[] %param_2.1836, s32[] %constant_13692), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %select.1743 = s32[] select(pred[] %compare.1752, s32[] %add.2790, s32[] %param_2.1836), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.524 = f32[64,16,1024]{2,1,0} dynamic-update-slice(f32[64,16,1024]{2,1,0} %param_0.244, f32[1,16,1024]{2,1,0} %bitcast.559, s32[] %select.1743, s32[] %constant_10857, s32[] %constant_10857), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.132 (param_0.245: f32[64,16,1024], param_1.2179: f32[16,1024], param_2.1834: f32[16,1024], param_3.1573: s32[]) -> f32[64,16,1024] {
  %param_0.245 = f32[64,16,1024]{2,1,0} parameter(0)
  %param_1.2179 = f32[16,1024]{1,0} parameter(1)
  %param_2.1834 = f32[16,1024]{1,0} parameter(2)
  %multiply.1380 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %param_1.2179, f32[16,1024]{1,0} %param_2.1834), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  %bitcast.560 = f32[1,16,1024]{2,1,0} bitcast(f32[16,1024]{1,0} %multiply.1380), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_3.1573 = s32[] parameter(3)
  %constant_10858 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.1750 = pred[] compare(s32[] %param_3.1573, s32[] %constant_10858), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_13685 = s32[] constant(64), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.2787 = s32[] add(s32[] %param_3.1573, s32[] %constant_13685), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %select.1741 = s32[] select(pred[] %compare.1750, s32[] %add.2787, s32[] %param_3.1573), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.525 = f32[64,16,1024]{2,1,0} dynamic-update-slice(f32[64,16,1024]{2,1,0} %param_0.245, f32[1,16,1024]{2,1,0} %bitcast.560, s32[] %select.1741, s32[] %constant_10858, s32[] %constant_10858), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.138 (param_0.254: f32[1,4096]) -> f32[16,4096] {
  %param_0.254 = f32[1,4096]{1,0} parameter(0)
  %bitcast.561 = f32[4096]{0} bitcast(f32[1,4096]{1,0} %param_0.254), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  ROOT %broadcast.1275 = f32[16,4096]{1,0} broadcast(f32[4096]{0} %bitcast.561), dimensions={1}, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
}

%fused_computation.139 (param_0.256: f32[16,2048], param_1.377: f32[64,16,1024], param_2.1833: s32[]) -> f32[16,2048] {
  %param_1.377 = f32[64,16,1024]{2,1,0} parameter(1)
  %param_2.1833 = s32[] parameter(2)
  %constant_10862 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.1748 = pred[] compare(s32[] %param_2.1833, s32[] %constant_10862), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_13679 = s32[] constant(64), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.2785 = s32[] add(s32[] %param_2.1833, s32[] %constant_13679), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %select.1739 = s32[] select(pred[] %compare.1748, s32[] %add.2785, s32[] %param_2.1833), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %dynamic-slice.403 = f32[1,16,1024]{2,1,0} dynamic-slice(f32[64,16,1024]{2,1,0} %param_1.377, s32[] %select.1739, s32[] %constant_10862, s32[] %constant_10862), dynamic_slice_sizes={1,16,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %bitcast.562 = f32[16,1024]{1,0} bitcast(f32[1,16,1024]{2,1,0} %dynamic-slice.403), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_0.256 = f32[16,2048]{1,0} parameter(0)
  %slice.863 = f32[16,1024]{1,0} slice(f32[16,2048]{1,0} %param_0.256), slice={[0:16], [1024:2048]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(16, 2048)\n                                                     start_indices=(0, 1024)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=54}
  ROOT %concatenate.191 = f32[16,2048]{1,0} concatenate(f32[16,1024]{1,0} %bitcast.562, f32[16,1024]{1,0} %slice.863), dimensions={1}, metadata={op_type="concatenate" op_name="pmap(_multi_device_update_fn)/scan/while/body/concatenate[ dimension=1 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
}

%fused_computation.663 (param_0.1247: f32[16,1024], param_1.1579: f32[16,1024], param_2.986: f32[16,1024]) -> f32[16,2048] {
  %param_0.1247 = f32[16,1024]{1,0} parameter(0)
  %param_1.1579 = f32[16,1024]{1,0} parameter(1)
  %param_2.986 = f32[16,1024]{1,0} parameter(2)
  %multiply.1381 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %param_1.1579, f32[16,1024]{1,0} %param_2.986), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  ROOT %concatenate.206 = f32[16,2048]{1,0} concatenate(f32[16,1024]{1,0} %param_0.1247, f32[16,1024]{1,0} %multiply.1381), dimensions={1}, metadata={op_type="concatenate" op_name="pmap(_multi_device_update_fn)/scan/while/body/concatenate[ dimension=1 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=65}
}

%fused_computation.741 (param_0.2176: f32[16,2048], param_1.2633: f32[16,4096]) -> (f32[16,1024], f32[16,1024], f32[16,1024], f32[16,1024], f32[16,1024], /*index=5*/f32[16,1024]) {
  %param_0.2176 = f32[16,2048]{1,0} parameter(0)
  %slice.924.clone.1 = f32[16,1024]{1,0} slice(f32[16,2048]{1,0} %param_0.2176), slice={[0:16], [0:1024]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(16, 1024)\n                                                     start_indices=(0, 0)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=54}
  %constant_10860_clone_1 = f32[] constant(1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %broadcast.1483.clone.1 = f32[16,1024]{1,0} broadcast(f32[] %constant_10860_clone_1), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %param_1.2633 = f32[16,4096]{1,0} parameter(1)
  %slice.862.clone.1 = f32[16,1024]{1,0} slice(f32[16,4096]{1,0} %param_1.2633), slice={[0:16], [2048:3072]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(16, 3072)\n                                                     start_indices=(0, 2048)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  %negate.132.clone.1 = f32[16,1024]{1,0} negate(f32[16,1024]{1,0} %slice.862.clone.1), metadata={op_type="neg" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/neg" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %exponential.113.clone.1 = f32[16,1024]{1,0} exponential(f32[16,1024]{1,0} %negate.132.clone.1), metadata={op_type="exp" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/exp" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %add.1867.clone.1 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %broadcast.1483.clone.1, f32[16,1024]{1,0} %exponential.113.clone.1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %divide.117.clone.1 = f32[16,1024]{1,0} divide(f32[16,1024]{1,0} %broadcast.1483.clone.1, f32[16,1024]{1,0} %add.1867.clone.1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %multiply.932.clone.1 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %slice.924.clone.1, f32[16,1024]{1,0} %divide.117.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %slice.861.clone.1 = f32[16,1024]{1,0} slice(f32[16,4096]{1,0} %param_1.2633), slice={[0:16], [0:1024]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(16, 1024)\n                                                     start_indices=(0, 0)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  %negate.131.clone.1 = f32[16,1024]{1,0} negate(f32[16,1024]{1,0} %slice.861.clone.1), metadata={op_type="neg" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/neg" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %exponential.112.clone.1 = f32[16,1024]{1,0} exponential(f32[16,1024]{1,0} %negate.131.clone.1), metadata={op_type="exp" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/exp" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %add.1866.clone.1 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %broadcast.1483.clone.1, f32[16,1024]{1,0} %exponential.112.clone.1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %divide.116.clone.1 = f32[16,1024]{1,0} divide(f32[16,1024]{1,0} %broadcast.1483.clone.1, f32[16,1024]{1,0} %add.1866.clone.1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %slice.860.clone.1 = f32[16,1024]{1,0} slice(f32[16,4096]{1,0} %param_1.2633), slice={[0:16], [1024:2048]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(16, 2048)\n                                                     start_indices=(0, 1024)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  %tanh.73.clone.1 = f32[16,1024]{1,0} tanh(f32[16,1024]{1,0} %slice.860.clone.1), metadata={op_type="tanh" op_name="pmap(_multi_device_update_fn)/scan/while/body/tanh" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %multiply.931.clone.1 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %divide.116.clone.1, f32[16,1024]{1,0} %tanh.73.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %add.1865.clone.1 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %multiply.932.clone.1, f32[16,1024]{1,0} %multiply.931.clone.1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %tanh.82 = f32[16,1024]{1,0} tanh(f32[16,1024]{1,0} %add.1865.clone.1), metadata={op_type="tanh" op_name="pmap(_multi_device_update_fn)/scan/while/body/tanh" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  %slice.859.clone.1 = f32[16,1024]{1,0} slice(f32[16,4096]{1,0} %param_1.2633), slice={[0:16], [3072:4096]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(16, 4096)\n                                                     start_indices=(0, 3072)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  %negate.130.clone.1 = f32[16,1024]{1,0} negate(f32[16,1024]{1,0} %slice.859.clone.1), metadata={op_type="neg" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/neg" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %exponential.111.clone.1 = f32[16,1024]{1,0} exponential(f32[16,1024]{1,0} %negate.130.clone.1), metadata={op_type="exp" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/exp" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %add.1864.clone.1 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %broadcast.1483.clone.1, f32[16,1024]{1,0} %exponential.111.clone.1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %divide.115.clone.1 = f32[16,1024]{1,0} divide(f32[16,1024]{1,0} %broadcast.1483.clone.1, f32[16,1024]{1,0} %add.1864.clone.1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  ROOT %tuple.483 = (f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, /*index=5*/f32[16,1024]{1,0}) tuple(f32[16,1024]{1,0} %tanh.82, f32[16,1024]{1,0} %add.1865.clone.1, f32[16,1024]{1,0} %divide.117.clone.1, f32[16,1024]{1,0} %tanh.73.clone.1, f32[16,1024]{1,0} %divide.116.clone.1, /*index=5*/f32[16,1024]{1,0} %divide.115.clone.1)
}

%body_computation__37.1179.clone.clone.clone.clone (parameter.172: (f32[64,16,1024], f32[2048,4096], f32[1,4096], s32[], f32[16,2048], /*index=5*/f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[64,16,2048], f32[64,16,1024], /*index=10*/f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], /*index=15*/f32[64,16,1024], f32[64,16,1024], f32[64,16,1024])) -> (f32[64,16,1024], f32[2048,4096], f32[1,4096], s32[], f32[16,2048], /*index=5*/f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[64,16,2048], f32[64,16,1024], /*index=10*/f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], /*index=15*/f32[64,16,1024], f32[64,16,1024], f32[64,16,1024]) {
  %parameter.172 = (f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) parameter(0)
  %get-tuple-element.5835 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %parameter.172), index=0
  %get-tuple-element.5836 = f32[2048,4096]{1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %parameter.172), index=1
  %get-tuple-element.5837 = f32[1,4096]{1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %parameter.172), index=2
  %get-tuple-element.5851 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %parameter.172), index=16
  %get-tuple-element.5839 = f32[16,2048]{1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %parameter.172), index=4
  %get-tuple-element.5838 = s32[] get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %parameter.172), index=3
  %fusion.139 = f32[16,2048]{1,0} fusion(f32[16,2048]{1,0} %get-tuple-element.5839, f32[64,16,1024]{2,1,0} %get-tuple-element.5835, s32[] %get-tuple-element.5838), kind=kLoop, calls=%fused_computation.139, metadata={op_type="concatenate" op_name="pmap(_multi_device_update_fn)/scan/while/body/concatenate[ dimension=1 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %fusion.138 = f32[16,4096]{1,0} fusion(f32[1,4096]{1,0} %get-tuple-element.5837), kind=kLoop, calls=%fused_computation.138, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %custom-call.122 = f32[16,4096]{1,0} custom-call(f32[16,2048]{1,0} %fusion.139, f32[2048,4096]{1,0} %get-tuple-element.5836, f32[16,4096]{1,0} %fusion.138), custom_call_target="__cublas$gemm", metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}, backend_config="{\"alpha_real\":1,\"alpha_imag\":0,\"beta\":1,\"dot_dimension_numbers\":{\"lhs_contracting_dimensions\":[\"1\"],\"rhs_contracting_dimensions\":[\"0\"],\"lhs_batch_dimensions\":[],\"rhs_batch_dimensions\":[]},\"batch_size\":\"1\",\"selected_algorithm\":\"0\"}"
  %fusion.741 = (f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, /*index=5*/f32[16,1024]{1,0}) fusion(f32[16,2048]{1,0} %get-tuple-element.5839, f32[16,4096]{1,0} %custom-call.122), kind=kLoop, calls=%fused_computation.741, metadata={op_type="tanh" op_name="pmap(_multi_device_update_fn)/scan/while/body/tanh" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  %get-tuple-element.5065 = f32[16,1024]{1,0} get-tuple-element((f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, /*index=5*/f32[16,1024]{1,0}) %fusion.741), index=5
  %fusion.121 = f32[64,16,1024]{2,1,0} fusion(f32[64,16,1024]{2,1,0} %get-tuple-element.5851, f32[16,1024]{1,0} %get-tuple-element.5065, s32[] %get-tuple-element.5838), kind=kLoop, calls=%fused_computation.121, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.5850 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %parameter.172), index=15
  %get-tuple-element.5060 = f32[16,1024]{1,0} get-tuple-element((f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, /*index=5*/f32[16,1024]{1,0}) %fusion.741), index=0
  %fusion.122 = f32[64,16,1024]{2,1,0} fusion(f32[64,16,1024]{2,1,0} %get-tuple-element.5850, f32[16,1024]{1,0} %get-tuple-element.5060, s32[] %get-tuple-element.5838), kind=kLoop, calls=%fused_computation.122, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.5849 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %parameter.172), index=14
  %fusion.123 = f32[64,16,1024]{2,1,0} fusion(f32[64,16,1024]{2,1,0} %get-tuple-element.5849, f32[16,1024]{1,0} %get-tuple-element.5060, s32[] %get-tuple-element.5838), kind=kLoop, calls=%fused_computation.123, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.5848 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %parameter.172), index=13
  %get-tuple-element.5063 = f32[16,1024]{1,0} get-tuple-element((f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, /*index=5*/f32[16,1024]{1,0}) %fusion.741), index=3
  %fusion.124 = f32[64,16,1024]{2,1,0} fusion(f32[64,16,1024]{2,1,0} %get-tuple-element.5848, f32[16,1024]{1,0} %get-tuple-element.5063, s32[] %get-tuple-element.5838), kind=kLoop, calls=%fused_computation.124, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.5847 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %parameter.172), index=12
  %fusion.125 = f32[64,16,1024]{2,1,0} fusion(f32[64,16,1024]{2,1,0} %get-tuple-element.5847, f32[16,1024]{1,0} %get-tuple-element.5063, s32[] %get-tuple-element.5838), kind=kLoop, calls=%fused_computation.125, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.5846 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %parameter.172), index=11
  %get-tuple-element.5064 = f32[16,1024]{1,0} get-tuple-element((f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, /*index=5*/f32[16,1024]{1,0}) %fusion.741), index=4
  %fusion.126 = f32[64,16,1024]{2,1,0} fusion(f32[64,16,1024]{2,1,0} %get-tuple-element.5846, f32[16,1024]{1,0} %get-tuple-element.5064, s32[] %get-tuple-element.5838), kind=kLoop, calls=%fused_computation.126, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.5845 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %parameter.172), index=10
  %fusion.127 = f32[64,16,1024]{2,1,0} fusion(f32[64,16,1024]{2,1,0} %get-tuple-element.5845, f32[16,1024]{1,0} %get-tuple-element.5064, s32[] %get-tuple-element.5838), kind=kLoop, calls=%fused_computation.127, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.5844 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %parameter.172), index=9
  %get-tuple-element.5062 = f32[16,1024]{1,0} get-tuple-element((f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, /*index=5*/f32[16,1024]{1,0}) %fusion.741), index=2
  %fusion.128 = f32[64,16,1024]{2,1,0} fusion(f32[64,16,1024]{2,1,0} %get-tuple-element.5844, f32[16,1024]{1,0} %get-tuple-element.5062, s32[] %get-tuple-element.5838), kind=kLoop, calls=%fused_computation.128, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.5843 = f32[64,16,2048]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %parameter.172), index=8
  %fusion.129 = f32[64,16,2048]{2,1,0} fusion(f32[64,16,2048]{2,1,0} %get-tuple-element.5843, f32[16,2048]{1,0} %fusion.139, s32[] %get-tuple-element.5838), kind=kLoop, calls=%fused_computation.129, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.5842 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %parameter.172), index=7
  %fusion.130 = f32[64,16,1024]{2,1,0} fusion(f32[64,16,1024]{2,1,0} %get-tuple-element.5842, f32[16,2048]{1,0} %get-tuple-element.5839, s32[] %get-tuple-element.5838), kind=kLoop, calls=%fused_computation.130, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.5841 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %parameter.172), index=6
  %fusion.131 = f32[64,16,1024]{2,1,0} fusion(f32[64,16,1024]{2,1,0} %get-tuple-element.5841, f32[16,1024]{1,0} %get-tuple-element.5062, s32[] %get-tuple-element.5838), kind=kLoop, calls=%fused_computation.131, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.5840 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %parameter.172), index=5
  %fusion.132 = f32[64,16,1024]{2,1,0} fusion(f32[64,16,1024]{2,1,0} %get-tuple-element.5840, f32[16,1024]{1,0} %get-tuple-element.5060, f32[16,1024]{1,0} %get-tuple-element.5065, s32[] %get-tuple-element.5838), kind=kLoop, calls=%fused_computation.132, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.5852 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %parameter.172), index=17
  %fusion.120 = f32[64,16,1024]{2,1,0} fusion(f32[64,16,1024]{2,1,0} %get-tuple-element.5852, f32[16,1024]{1,0} %get-tuple-element.5065, s32[] %get-tuple-element.5838), kind=kLoop, calls=%fused_computation.120, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_9758 = s32[] constant(1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.1618 = s32[] add(s32[] %get-tuple-element.5838, s32[] %constant_9758), control-predecessors={%fusion.120, %fusion.139, %fusion.132, %fusion.131, %fusion.130, %fusion.129, %fusion.128, %fusion.127, %fusion.126, %fusion.125, %fusion.124, %fusion.123, %fusion.122, %fusion.121}, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.5061 = f32[16,1024]{1,0} get-tuple-element((f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, /*index=5*/f32[16,1024]{1,0}) %fusion.741), index=1
  %fusion.663 = f32[16,2048]{1,0} fusion(f32[16,1024]{1,0} %get-tuple-element.5061, f32[16,1024]{1,0} %get-tuple-element.5060, f32[16,1024]{1,0} %get-tuple-element.5065), kind=kLoop, calls=%fused_computation.663, control-predecessors={%fusion.139, %fusion.741, %fusion.130}, metadata={op_type="concatenate" op_name="pmap(_multi_device_update_fn)/scan/while/body/concatenate[ dimension=1 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=65}
  ROOT %tuple.793 = (f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) tuple(f32[64,16,1024]{2,1,0} %get-tuple-element.5835, f32[2048,4096]{1,0} %get-tuple-element.5836, f32[1,4096]{1,0} %get-tuple-element.5837, s32[] %add.1618, f32[16,2048]{1,0} %fusion.663, /*index=5*/f32[64,16,1024]{2,1,0} %fusion.132, f32[64,16,1024]{2,1,0} %fusion.131, f32[64,16,1024]{2,1,0} %fusion.130, f32[64,16,2048]{2,1,0} %fusion.129, f32[64,16,1024]{2,1,0} %fusion.128, /*index=10*/f32[64,16,1024]{2,1,0} %fusion.127, f32[64,16,1024]{2,1,0} %fusion.126, f32[64,16,1024]{2,1,0} %fusion.125, f32[64,16,1024]{2,1,0} %fusion.124, f32[64,16,1024]{2,1,0} %fusion.123, /*index=15*/f32[64,16,1024]{2,1,0} %fusion.122, f32[64,16,1024]{2,1,0} %fusion.121, f32[64,16,1024]{2,1,0} %fusion.120)
}

%cond_computation__37.1600.clone.clone.clone (parameter.175: (f32[64,16,1024], f32[2048,4096], f32[1,4096], s32[], f32[16,2048], /*index=5*/f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[64,16,2048], f32[64,16,1024], /*index=10*/f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], /*index=15*/f32[64,16,1024], f32[64,16,1024], f32[64,16,1024])) -> pred[] {
  %parameter.175 = (f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) parameter(0)
  %get-tuple-element.4134 = s32[] get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %parameter.175), index=3
  %constant_9761 = s32[] constant(64), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/cond/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %compare.1261 = pred[] compare(s32[] %get-tuple-element.4134, s32[] %constant_9761), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/cond/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.141 (param_0.259: f32[64,16,1024], param_1.2204: f32[16,1024], param_2.1885: s32[]) -> f32[64,16,1024] {
  %param_0.259 = f32[64,16,1024]{2,1,0} parameter(0)
  %constant_10865 = f32[] constant(1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %broadcast.1485 = f32[16,1024]{1,0} broadcast(f32[] %constant_10865), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %param_1.2204 = f32[16,1024]{1,0} parameter(1)
  %subtract.221 = f32[16,1024]{1,0} subtract(f32[16,1024]{1,0} %broadcast.1485, f32[16,1024]{1,0} %param_1.2204), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %bitcast.563 = f32[1,16,1024]{2,1,0} bitcast(f32[16,1024]{1,0} %subtract.221), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_2.1885 = s32[] parameter(2)
  %constant_10864 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.1802 = pred[] compare(s32[] %param_2.1885, s32[] %constant_10864), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_13842 = s32[] constant(64), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.2847 = s32[] add(s32[] %param_2.1885, s32[] %constant_13842), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %select.1793 = s32[] select(pred[] %compare.1802, s32[] %add.2847, s32[] %param_2.1885), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.526 = f32[64,16,1024]{2,1,0} dynamic-update-slice(f32[64,16,1024]{2,1,0} %param_0.259, f32[1,16,1024]{2,1,0} %bitcast.563, s32[] %select.1793, s32[] %constant_10864, s32[] %constant_10864), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.142 (param_0.260: f32[64,16,1024], param_1.2203: f32[16,1024], param_2.1883: s32[]) -> f32[64,16,1024] {
  %param_0.260 = f32[64,16,1024]{2,1,0} parameter(0)
  %param_1.2203 = f32[16,1024]{1,0} parameter(1)
  %bitcast.564 = f32[1,16,1024]{2,1,0} bitcast(f32[16,1024]{1,0} %param_1.2203), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_2.1883 = s32[] parameter(2)
  %constant_10866 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.1800 = pred[] compare(s32[] %param_2.1883, s32[] %constant_10866), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_13836 = s32[] constant(64), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.2845 = s32[] add(s32[] %param_2.1883, s32[] %constant_13836), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %select.1791 = s32[] select(pred[] %compare.1800, s32[] %add.2845, s32[] %param_2.1883), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.527 = f32[64,16,1024]{2,1,0} dynamic-update-slice(f32[64,16,1024]{2,1,0} %param_0.260, f32[1,16,1024]{2,1,0} %bitcast.564, s32[] %select.1791, s32[] %constant_10866, s32[] %constant_10866), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.143 (param_0.261: f32[64,16,1024], param_1.2202: f32[16,1024], param_2.1881: s32[]) -> f32[64,16,1024] {
  %param_0.261 = f32[64,16,1024]{2,1,0} parameter(0)
  %constant_10868 = f32[] constant(1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %broadcast.1486 = f32[16,1024]{1,0} broadcast(f32[] %constant_10868), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %param_1.2202 = f32[16,1024]{1,0} parameter(1)
  %subtract.222 = f32[16,1024]{1,0} subtract(f32[16,1024]{1,0} %broadcast.1486, f32[16,1024]{1,0} %param_1.2202), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  %bitcast.565 = f32[1,16,1024]{2,1,0} bitcast(f32[16,1024]{1,0} %subtract.222), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_2.1881 = s32[] parameter(2)
  %constant_10867 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.1798 = pred[] compare(s32[] %param_2.1881, s32[] %constant_10867), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_13830 = s32[] constant(64), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.2842 = s32[] add(s32[] %param_2.1881, s32[] %constant_13830), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %select.1789 = s32[] select(pred[] %compare.1798, s32[] %add.2842, s32[] %param_2.1881), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.528 = f32[64,16,1024]{2,1,0} dynamic-update-slice(f32[64,16,1024]{2,1,0} %param_0.261, f32[1,16,1024]{2,1,0} %bitcast.565, s32[] %select.1789, s32[] %constant_10867, s32[] %constant_10867), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.144 (param_0.262: f32[64,16,1024], param_1.2201: f32[16,1024], param_2.1879: s32[]) -> f32[64,16,1024] {
  %param_0.262 = f32[64,16,1024]{2,1,0} parameter(0)
  %param_1.2201 = f32[16,1024]{1,0} parameter(1)
  %bitcast.566 = f32[1,16,1024]{2,1,0} bitcast(f32[16,1024]{1,0} %param_1.2201), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_2.1879 = s32[] parameter(2)
  %constant_10869 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.1796 = pred[] compare(s32[] %param_2.1879, s32[] %constant_10869), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_13824 = s32[] constant(64), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.2840 = s32[] add(s32[] %param_2.1879, s32[] %constant_13824), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %select.1787 = s32[] select(pred[] %compare.1796, s32[] %add.2840, s32[] %param_2.1879), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.529 = f32[64,16,1024]{2,1,0} dynamic-update-slice(f32[64,16,1024]{2,1,0} %param_0.262, f32[1,16,1024]{2,1,0} %bitcast.566, s32[] %select.1787, s32[] %constant_10869, s32[] %constant_10869), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.145 (param_0.263: f32[64,16,1024], param_1.2200: f32[16,1024], param_2.1877: s32[]) -> f32[64,16,1024] {
  %param_0.263 = f32[64,16,1024]{2,1,0} parameter(0)
  %constant_10871 = f32[] constant(1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %broadcast.1487 = f32[16,1024]{1,0} broadcast(f32[] %constant_10871), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %param_1.2200 = f32[16,1024]{1,0} parameter(1)
  %subtract.223 = f32[16,1024]{1,0} subtract(f32[16,1024]{1,0} %broadcast.1487, f32[16,1024]{1,0} %param_1.2200), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %bitcast.567 = f32[1,16,1024]{2,1,0} bitcast(f32[16,1024]{1,0} %subtract.223), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_2.1877 = s32[] parameter(2)
  %constant_10870 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.1794 = pred[] compare(s32[] %param_2.1877, s32[] %constant_10870), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_13818 = s32[] constant(64), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.2838 = s32[] add(s32[] %param_2.1877, s32[] %constant_13818), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %select.1785 = s32[] select(pred[] %compare.1794, s32[] %add.2838, s32[] %param_2.1877), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.530 = f32[64,16,1024]{2,1,0} dynamic-update-slice(f32[64,16,1024]{2,1,0} %param_0.263, f32[1,16,1024]{2,1,0} %bitcast.567, s32[] %select.1785, s32[] %constant_10870, s32[] %constant_10870), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.146 (param_0.264: f32[64,16,1024], param_1.2199: f32[16,1024], param_2.1875: s32[]) -> f32[64,16,1024] {
  %param_0.264 = f32[64,16,1024]{2,1,0} parameter(0)
  %param_1.2199 = f32[16,1024]{1,0} parameter(1)
  %bitcast.568 = f32[1,16,1024]{2,1,0} bitcast(f32[16,1024]{1,0} %param_1.2199), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_2.1875 = s32[] parameter(2)
  %constant_10872 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.1792 = pred[] compare(s32[] %param_2.1875, s32[] %constant_10872), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_13811 = s32[] constant(64), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.2836 = s32[] add(s32[] %param_2.1875, s32[] %constant_13811), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %select.1783 = s32[] select(pred[] %compare.1792, s32[] %add.2836, s32[] %param_2.1875), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.531 = f32[64,16,1024]{2,1,0} dynamic-update-slice(f32[64,16,1024]{2,1,0} %param_0.264, f32[1,16,1024]{2,1,0} %bitcast.568, s32[] %select.1783, s32[] %constant_10872, s32[] %constant_10872), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.147 (param_0.265: f32[64,16,1024], param_1.2198: f32[16,1024], param_2.1873: s32[]) -> f32[64,16,1024] {
  %param_0.265 = f32[64,16,1024]{2,1,0} parameter(0)
  %constant_10874 = f32[] constant(1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %broadcast.1488 = f32[16,1024]{1,0} broadcast(f32[] %constant_10874), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %param_1.2198 = f32[16,1024]{1,0} parameter(1)
  %subtract.224 = f32[16,1024]{1,0} subtract(f32[16,1024]{1,0} %broadcast.1488, f32[16,1024]{1,0} %param_1.2198), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %bitcast.569 = f32[1,16,1024]{2,1,0} bitcast(f32[16,1024]{1,0} %subtract.224), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_2.1873 = s32[] parameter(2)
  %constant_10873 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.1790 = pred[] compare(s32[] %param_2.1873, s32[] %constant_10873), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_13805 = s32[] constant(64), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.2833 = s32[] add(s32[] %param_2.1873, s32[] %constant_13805), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %select.1781 = s32[] select(pred[] %compare.1790, s32[] %add.2833, s32[] %param_2.1873), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.532 = f32[64,16,1024]{2,1,0} dynamic-update-slice(f32[64,16,1024]{2,1,0} %param_0.265, f32[1,16,1024]{2,1,0} %bitcast.569, s32[] %select.1781, s32[] %constant_10873, s32[] %constant_10873), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.148 (param_0.266: f32[64,16,1024], param_1.2197: f32[16,1024], param_2.1871: s32[]) -> f32[64,16,1024] {
  %param_0.266 = f32[64,16,1024]{2,1,0} parameter(0)
  %param_1.2197 = f32[16,1024]{1,0} parameter(1)
  %bitcast.570 = f32[1,16,1024]{2,1,0} bitcast(f32[16,1024]{1,0} %param_1.2197), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_2.1871 = s32[] parameter(2)
  %constant_10875 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.1788 = pred[] compare(s32[] %param_2.1871, s32[] %constant_10875), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_13800 = s32[] constant(64), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.2831 = s32[] add(s32[] %param_2.1871, s32[] %constant_13800), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %select.1779 = s32[] select(pred[] %compare.1788, s32[] %add.2831, s32[] %param_2.1871), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.533 = f32[64,16,1024]{2,1,0} dynamic-update-slice(f32[64,16,1024]{2,1,0} %param_0.266, f32[1,16,1024]{2,1,0} %bitcast.570, s32[] %select.1779, s32[] %constant_10875, s32[] %constant_10875), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.149 (param_0.267: f32[64,16,1024], param_1.2196: f32[16,1024], param_2.1869: s32[]) -> f32[64,16,1024] {
  %param_0.267 = f32[64,16,1024]{2,1,0} parameter(0)
  %constant_10877 = f32[] constant(1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %broadcast.1489 = f32[16,1024]{1,0} broadcast(f32[] %constant_10877), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %param_1.2196 = f32[16,1024]{1,0} parameter(1)
  %subtract.225 = f32[16,1024]{1,0} subtract(f32[16,1024]{1,0} %broadcast.1489, f32[16,1024]{1,0} %param_1.2196), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %bitcast.571 = f32[1,16,1024]{2,1,0} bitcast(f32[16,1024]{1,0} %subtract.225), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_2.1869 = s32[] parameter(2)
  %constant_10876 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.1786 = pred[] compare(s32[] %param_2.1869, s32[] %constant_10876), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_13795 = s32[] constant(64), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.2829 = s32[] add(s32[] %param_2.1869, s32[] %constant_13795), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %select.1777 = s32[] select(pred[] %compare.1786, s32[] %add.2829, s32[] %param_2.1869), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.534 = f32[64,16,1024]{2,1,0} dynamic-update-slice(f32[64,16,1024]{2,1,0} %param_0.267, f32[1,16,1024]{2,1,0} %bitcast.571, s32[] %select.1777, s32[] %constant_10876, s32[] %constant_10876), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.150 (param_0.268: f32[64,16,2048], param_1.2195: f32[16,2048], param_2.1867: s32[]) -> f32[64,16,2048] {
  %param_0.268 = f32[64,16,2048]{2,1,0} parameter(0)
  %param_1.2195 = f32[16,2048]{1,0} parameter(1)
  %bitcast.572 = f32[1,16,2048]{2,1,0} bitcast(f32[16,2048]{1,0} %param_1.2195), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 16, 2048) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_2.1867 = s32[] parameter(2)
  %constant_10878 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.1784 = pred[] compare(s32[] %param_2.1867, s32[] %constant_10878), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_13788 = s32[] constant(64), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.2826 = s32[] add(s32[] %param_2.1867, s32[] %constant_13788), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %select.1775 = s32[] select(pred[] %compare.1784, s32[] %add.2826, s32[] %param_2.1867), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.535 = f32[64,16,2048]{2,1,0} dynamic-update-slice(f32[64,16,2048]{2,1,0} %param_0.268, f32[1,16,2048]{2,1,0} %bitcast.572, s32[] %select.1775, s32[] %constant_10878, s32[] %constant_10878), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.151 (param_0.269: f32[64,16,1024], param_1.2194: f32[16,2048], param_2.1865: s32[]) -> f32[64,16,1024] {
  %param_0.269 = f32[64,16,1024]{2,1,0} parameter(0)
  %param_1.2194 = f32[16,2048]{1,0} parameter(1)
  %slice.925 = f32[16,1024]{1,0} slice(f32[16,2048]{1,0} %param_1.2194), slice={[0:16], [0:1024]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(16, 1024)\n                                                     start_indices=(0, 0)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=54}
  %bitcast.573 = f32[1,16,1024]{2,1,0} bitcast(f32[16,1024]{1,0} %slice.925), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_2.1865 = s32[] parameter(2)
  %constant_10881 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.1782 = pred[] compare(s32[] %param_2.1865, s32[] %constant_10881), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_13783 = s32[] constant(64), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.2824 = s32[] add(s32[] %param_2.1865, s32[] %constant_13783), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %select.1773 = s32[] select(pred[] %compare.1782, s32[] %add.2824, s32[] %param_2.1865), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.536 = f32[64,16,1024]{2,1,0} dynamic-update-slice(f32[64,16,1024]{2,1,0} %param_0.269, f32[1,16,1024]{2,1,0} %bitcast.573, s32[] %select.1773, s32[] %constant_10881, s32[] %constant_10881), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.152 (param_0.270: f32[64,16,1024], param_1.2193: f32[16,1024], param_2.1863: s32[]) -> f32[64,16,1024] {
  %param_0.270 = f32[64,16,1024]{2,1,0} parameter(0)
  %param_1.2193 = f32[16,1024]{1,0} parameter(1)
  %bitcast.574 = f32[1,16,1024]{2,1,0} bitcast(f32[16,1024]{1,0} %param_1.2193), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_2.1863 = s32[] parameter(2)
  %constant_10882 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.1780 = pred[] compare(s32[] %param_2.1863, s32[] %constant_10882), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_13777 = s32[] constant(64), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.2822 = s32[] add(s32[] %param_2.1863, s32[] %constant_13777), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %select.1771 = s32[] select(pred[] %compare.1780, s32[] %add.2822, s32[] %param_2.1863), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.537 = f32[64,16,1024]{2,1,0} dynamic-update-slice(f32[64,16,1024]{2,1,0} %param_0.270, f32[1,16,1024]{2,1,0} %bitcast.574, s32[] %select.1771, s32[] %constant_10882, s32[] %constant_10882), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.153 (param_0.271: f32[64,16,1024], param_1.2192: f32[16,1024], param_2.1861: f32[16,1024], param_3.1614: s32[]) -> f32[64,16,1024] {
  %param_0.271 = f32[64,16,1024]{2,1,0} parameter(0)
  %param_1.2192 = f32[16,1024]{1,0} parameter(1)
  %param_2.1861 = f32[16,1024]{1,0} parameter(2)
  %multiply.1382 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %param_1.2192, f32[16,1024]{1,0} %param_2.1861), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  %bitcast.575 = f32[1,16,1024]{2,1,0} bitcast(f32[16,1024]{1,0} %multiply.1382), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_3.1614 = s32[] parameter(3)
  %constant_10883 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.1778 = pred[] compare(s32[] %param_3.1614, s32[] %constant_10883), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_13771 = s32[] constant(64), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.2819 = s32[] add(s32[] %param_3.1614, s32[] %constant_13771), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %select.1769 = s32[] select(pred[] %compare.1778, s32[] %add.2819, s32[] %param_3.1614), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.538 = f32[64,16,1024]{2,1,0} dynamic-update-slice(f32[64,16,1024]{2,1,0} %param_0.271, f32[1,16,1024]{2,1,0} %bitcast.575, s32[] %select.1769, s32[] %constant_10883, s32[] %constant_10883), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.159 (param_0.280: f32[1,4096]) -> f32[16,4096] {
  %param_0.280 = f32[1,4096]{1,0} parameter(0)
  %bitcast.576 = f32[4096]{0} bitcast(f32[1,4096]{1,0} %param_0.280), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  ROOT %broadcast.1276 = f32[16,4096]{1,0} broadcast(f32[4096]{0} %bitcast.576), dimensions={1}, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
}

%fused_computation.160 (param_0.282: f32[16,2048], param_1.428: f32[64,16,1024], param_2.1860: s32[]) -> f32[16,2048] {
  %param_1.428 = f32[64,16,1024]{2,1,0} parameter(1)
  %param_2.1860 = s32[] parameter(2)
  %constant_10887 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.1776 = pred[] compare(s32[] %param_2.1860, s32[] %constant_10887), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_13765 = s32[] constant(64), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.2817 = s32[] add(s32[] %param_2.1860, s32[] %constant_13765), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %select.1767 = s32[] select(pred[] %compare.1776, s32[] %add.2817, s32[] %param_2.1860), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %dynamic-slice.404 = f32[1,16,1024]{2,1,0} dynamic-slice(f32[64,16,1024]{2,1,0} %param_1.428, s32[] %select.1767, s32[] %constant_10887, s32[] %constant_10887), dynamic_slice_sizes={1,16,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %bitcast.577 = f32[16,1024]{1,0} bitcast(f32[1,16,1024]{2,1,0} %dynamic-slice.404), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_0.282 = f32[16,2048]{1,0} parameter(0)
  %slice.868 = f32[16,1024]{1,0} slice(f32[16,2048]{1,0} %param_0.282), slice={[0:16], [1024:2048]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(16, 2048)\n                                                     start_indices=(0, 1024)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=54}
  ROOT %concatenate.192 = f32[16,2048]{1,0} concatenate(f32[16,1024]{1,0} %bitcast.577, f32[16,1024]{1,0} %slice.868), dimensions={1}, metadata={op_type="concatenate" op_name="pmap(_multi_device_update_fn)/scan/while/body/concatenate[ dimension=1 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
}

%fused_computation.664 (param_0.1251: f32[16,1024], param_1.1584: f32[16,1024], param_2.1006: f32[16,1024]) -> f32[16,2048] {
  %param_0.1251 = f32[16,1024]{1,0} parameter(0)
  %param_1.1584 = f32[16,1024]{1,0} parameter(1)
  %param_2.1006 = f32[16,1024]{1,0} parameter(2)
  %multiply.1383 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %param_1.1584, f32[16,1024]{1,0} %param_2.1006), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  ROOT %concatenate.207 = f32[16,2048]{1,0} concatenate(f32[16,1024]{1,0} %param_0.1251, f32[16,1024]{1,0} %multiply.1383), dimensions={1}, metadata={op_type="concatenate" op_name="pmap(_multi_device_update_fn)/scan/while/body/concatenate[ dimension=1 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=65}
}

%fused_computation.742 (param_0.2180: f32[16,2048], param_1.2638: f32[16,4096]) -> (f32[16,1024], f32[16,1024], f32[16,1024], f32[16,1024], f32[16,1024], /*index=5*/f32[16,1024]) {
  %param_0.2180 = f32[16,2048]{1,0} parameter(0)
  %slice.926.clone.1 = f32[16,1024]{1,0} slice(f32[16,2048]{1,0} %param_0.2180), slice={[0:16], [0:1024]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(16, 1024)\n                                                     start_indices=(0, 0)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=54}
  %constant_10885_clone_1 = f32[] constant(1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %broadcast.1491.clone.1 = f32[16,1024]{1,0} broadcast(f32[] %constant_10885_clone_1), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %param_1.2638 = f32[16,4096]{1,0} parameter(1)
  %slice.867.clone.1 = f32[16,1024]{1,0} slice(f32[16,4096]{1,0} %param_1.2638), slice={[0:16], [2048:3072]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(16, 3072)\n                                                     start_indices=(0, 2048)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  %negate.135.clone.1 = f32[16,1024]{1,0} negate(f32[16,1024]{1,0} %slice.867.clone.1), metadata={op_type="neg" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/neg" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %exponential.116.clone.1 = f32[16,1024]{1,0} exponential(f32[16,1024]{1,0} %negate.135.clone.1), metadata={op_type="exp" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/exp" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %add.1872.clone.1 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %broadcast.1491.clone.1, f32[16,1024]{1,0} %exponential.116.clone.1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %divide.120.clone.1 = f32[16,1024]{1,0} divide(f32[16,1024]{1,0} %broadcast.1491.clone.1, f32[16,1024]{1,0} %add.1872.clone.1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %multiply.934.clone.1 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %slice.926.clone.1, f32[16,1024]{1,0} %divide.120.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %slice.866.clone.1 = f32[16,1024]{1,0} slice(f32[16,4096]{1,0} %param_1.2638), slice={[0:16], [0:1024]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(16, 1024)\n                                                     start_indices=(0, 0)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  %negate.134.clone.1 = f32[16,1024]{1,0} negate(f32[16,1024]{1,0} %slice.866.clone.1), metadata={op_type="neg" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/neg" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %exponential.115.clone.1 = f32[16,1024]{1,0} exponential(f32[16,1024]{1,0} %negate.134.clone.1), metadata={op_type="exp" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/exp" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %add.1871.clone.1 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %broadcast.1491.clone.1, f32[16,1024]{1,0} %exponential.115.clone.1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %divide.119.clone.1 = f32[16,1024]{1,0} divide(f32[16,1024]{1,0} %broadcast.1491.clone.1, f32[16,1024]{1,0} %add.1871.clone.1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %slice.865.clone.1 = f32[16,1024]{1,0} slice(f32[16,4096]{1,0} %param_1.2638), slice={[0:16], [1024:2048]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(16, 2048)\n                                                     start_indices=(0, 1024)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  %tanh.74.clone.1 = f32[16,1024]{1,0} tanh(f32[16,1024]{1,0} %slice.865.clone.1), metadata={op_type="tanh" op_name="pmap(_multi_device_update_fn)/scan/while/body/tanh" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %multiply.933.clone.1 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %divide.119.clone.1, f32[16,1024]{1,0} %tanh.74.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %add.1870.clone.1 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %multiply.934.clone.1, f32[16,1024]{1,0} %multiply.933.clone.1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %tanh.83 = f32[16,1024]{1,0} tanh(f32[16,1024]{1,0} %add.1870.clone.1), metadata={op_type="tanh" op_name="pmap(_multi_device_update_fn)/scan/while/body/tanh" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  %slice.864.clone.1 = f32[16,1024]{1,0} slice(f32[16,4096]{1,0} %param_1.2638), slice={[0:16], [3072:4096]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(16, 4096)\n                                                     start_indices=(0, 3072)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  %negate.133.clone.1 = f32[16,1024]{1,0} negate(f32[16,1024]{1,0} %slice.864.clone.1), metadata={op_type="neg" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/neg" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %exponential.114.clone.1 = f32[16,1024]{1,0} exponential(f32[16,1024]{1,0} %negate.133.clone.1), metadata={op_type="exp" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/exp" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %add.1869.clone.1 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %broadcast.1491.clone.1, f32[16,1024]{1,0} %exponential.114.clone.1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %divide.118.clone.1 = f32[16,1024]{1,0} divide(f32[16,1024]{1,0} %broadcast.1491.clone.1, f32[16,1024]{1,0} %add.1869.clone.1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  ROOT %tuple.488 = (f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, /*index=5*/f32[16,1024]{1,0}) tuple(f32[16,1024]{1,0} %tanh.83, f32[16,1024]{1,0} %add.1870.clone.1, f32[16,1024]{1,0} %divide.120.clone.1, f32[16,1024]{1,0} %tanh.74.clone.1, f32[16,1024]{1,0} %divide.119.clone.1, /*index=5*/f32[16,1024]{1,0} %divide.118.clone.1)
}

%body_computation__38.1859.clone.clone.clone.clone (parameter.176: (f32[64,16,1024], f32[2048,4096], f32[1,4096], s32[], f32[16,2048], /*index=5*/f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[64,16,2048], f32[64,16,1024], /*index=10*/f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], /*index=15*/f32[64,16,1024], f32[64,16,1024], f32[64,16,1024])) -> (f32[64,16,1024], f32[2048,4096], f32[1,4096], s32[], f32[16,2048], /*index=5*/f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[64,16,2048], f32[64,16,1024], /*index=10*/f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], /*index=15*/f32[64,16,1024], f32[64,16,1024], f32[64,16,1024]) {
  %parameter.176 = (f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) parameter(0)
  %get-tuple-element.5889 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %parameter.176), index=0
  %get-tuple-element.5890 = f32[2048,4096]{1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %parameter.176), index=1
  %get-tuple-element.5891 = f32[1,4096]{1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %parameter.176), index=2
  %get-tuple-element.5905 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %parameter.176), index=16
  %get-tuple-element.5893 = f32[16,2048]{1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %parameter.176), index=4
  %get-tuple-element.5892 = s32[] get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %parameter.176), index=3
  %fusion.160 = f32[16,2048]{1,0} fusion(f32[16,2048]{1,0} %get-tuple-element.5893, f32[64,16,1024]{2,1,0} %get-tuple-element.5889, s32[] %get-tuple-element.5892), kind=kLoop, calls=%fused_computation.160, metadata={op_type="concatenate" op_name="pmap(_multi_device_update_fn)/scan/while/body/concatenate[ dimension=1 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %fusion.159 = f32[16,4096]{1,0} fusion(f32[1,4096]{1,0} %get-tuple-element.5891), kind=kLoop, calls=%fused_computation.159, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %custom-call.124 = f32[16,4096]{1,0} custom-call(f32[16,2048]{1,0} %fusion.160, f32[2048,4096]{1,0} %get-tuple-element.5890, f32[16,4096]{1,0} %fusion.159), custom_call_target="__cublas$gemm", metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}, backend_config="{\"alpha_real\":1,\"alpha_imag\":0,\"beta\":1,\"dot_dimension_numbers\":{\"lhs_contracting_dimensions\":[\"1\"],\"rhs_contracting_dimensions\":[\"0\"],\"lhs_batch_dimensions\":[],\"rhs_batch_dimensions\":[]},\"batch_size\":\"1\",\"selected_algorithm\":\"0\"}"
  %fusion.742 = (f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, /*index=5*/f32[16,1024]{1,0}) fusion(f32[16,2048]{1,0} %get-tuple-element.5893, f32[16,4096]{1,0} %custom-call.124), kind=kLoop, calls=%fused_computation.742, metadata={op_type="tanh" op_name="pmap(_multi_device_update_fn)/scan/while/body/tanh" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  %get-tuple-element.5071 = f32[16,1024]{1,0} get-tuple-element((f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, /*index=5*/f32[16,1024]{1,0}) %fusion.742), index=5
  %fusion.142 = f32[64,16,1024]{2,1,0} fusion(f32[64,16,1024]{2,1,0} %get-tuple-element.5905, f32[16,1024]{1,0} %get-tuple-element.5071, s32[] %get-tuple-element.5892), kind=kLoop, calls=%fused_computation.142, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.5904 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %parameter.176), index=15
  %get-tuple-element.5066 = f32[16,1024]{1,0} get-tuple-element((f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, /*index=5*/f32[16,1024]{1,0}) %fusion.742), index=0
  %fusion.143 = f32[64,16,1024]{2,1,0} fusion(f32[64,16,1024]{2,1,0} %get-tuple-element.5904, f32[16,1024]{1,0} %get-tuple-element.5066, s32[] %get-tuple-element.5892), kind=kLoop, calls=%fused_computation.143, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.5903 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %parameter.176), index=14
  %fusion.144 = f32[64,16,1024]{2,1,0} fusion(f32[64,16,1024]{2,1,0} %get-tuple-element.5903, f32[16,1024]{1,0} %get-tuple-element.5066, s32[] %get-tuple-element.5892), kind=kLoop, calls=%fused_computation.144, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.5902 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %parameter.176), index=13
  %get-tuple-element.5069 = f32[16,1024]{1,0} get-tuple-element((f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, /*index=5*/f32[16,1024]{1,0}) %fusion.742), index=3
  %fusion.145 = f32[64,16,1024]{2,1,0} fusion(f32[64,16,1024]{2,1,0} %get-tuple-element.5902, f32[16,1024]{1,0} %get-tuple-element.5069, s32[] %get-tuple-element.5892), kind=kLoop, calls=%fused_computation.145, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.5901 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %parameter.176), index=12
  %fusion.146 = f32[64,16,1024]{2,1,0} fusion(f32[64,16,1024]{2,1,0} %get-tuple-element.5901, f32[16,1024]{1,0} %get-tuple-element.5069, s32[] %get-tuple-element.5892), kind=kLoop, calls=%fused_computation.146, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.5900 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %parameter.176), index=11
  %get-tuple-element.5070 = f32[16,1024]{1,0} get-tuple-element((f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, /*index=5*/f32[16,1024]{1,0}) %fusion.742), index=4
  %fusion.147 = f32[64,16,1024]{2,1,0} fusion(f32[64,16,1024]{2,1,0} %get-tuple-element.5900, f32[16,1024]{1,0} %get-tuple-element.5070, s32[] %get-tuple-element.5892), kind=kLoop, calls=%fused_computation.147, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.5899 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %parameter.176), index=10
  %fusion.148 = f32[64,16,1024]{2,1,0} fusion(f32[64,16,1024]{2,1,0} %get-tuple-element.5899, f32[16,1024]{1,0} %get-tuple-element.5070, s32[] %get-tuple-element.5892), kind=kLoop, calls=%fused_computation.148, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.5898 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %parameter.176), index=9
  %get-tuple-element.5068 = f32[16,1024]{1,0} get-tuple-element((f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, /*index=5*/f32[16,1024]{1,0}) %fusion.742), index=2
  %fusion.149 = f32[64,16,1024]{2,1,0} fusion(f32[64,16,1024]{2,1,0} %get-tuple-element.5898, f32[16,1024]{1,0} %get-tuple-element.5068, s32[] %get-tuple-element.5892), kind=kLoop, calls=%fused_computation.149, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.5897 = f32[64,16,2048]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %parameter.176), index=8
  %fusion.150 = f32[64,16,2048]{2,1,0} fusion(f32[64,16,2048]{2,1,0} %get-tuple-element.5897, f32[16,2048]{1,0} %fusion.160, s32[] %get-tuple-element.5892), kind=kLoop, calls=%fused_computation.150, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.5896 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %parameter.176), index=7
  %fusion.151 = f32[64,16,1024]{2,1,0} fusion(f32[64,16,1024]{2,1,0} %get-tuple-element.5896, f32[16,2048]{1,0} %get-tuple-element.5893, s32[] %get-tuple-element.5892), kind=kLoop, calls=%fused_computation.151, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.5895 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %parameter.176), index=6
  %fusion.152 = f32[64,16,1024]{2,1,0} fusion(f32[64,16,1024]{2,1,0} %get-tuple-element.5895, f32[16,1024]{1,0} %get-tuple-element.5068, s32[] %get-tuple-element.5892), kind=kLoop, calls=%fused_computation.152, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.5894 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %parameter.176), index=5
  %fusion.153 = f32[64,16,1024]{2,1,0} fusion(f32[64,16,1024]{2,1,0} %get-tuple-element.5894, f32[16,1024]{1,0} %get-tuple-element.5066, f32[16,1024]{1,0} %get-tuple-element.5071, s32[] %get-tuple-element.5892), kind=kLoop, calls=%fused_computation.153, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.5906 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %parameter.176), index=17
  %fusion.141 = f32[64,16,1024]{2,1,0} fusion(f32[64,16,1024]{2,1,0} %get-tuple-element.5906, f32[16,1024]{1,0} %get-tuple-element.5071, s32[] %get-tuple-element.5892), kind=kLoop, calls=%fused_computation.141, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_9834 = s32[] constant(1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.1638 = s32[] add(s32[] %get-tuple-element.5892, s32[] %constant_9834), control-predecessors={%fusion.141, %fusion.160, %fusion.153, %fusion.152, %fusion.151, %fusion.150, %fusion.149, %fusion.148, %fusion.147, %fusion.146, %fusion.145, %fusion.144, %fusion.143, %fusion.142}, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.5067 = f32[16,1024]{1,0} get-tuple-element((f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, /*index=5*/f32[16,1024]{1,0}) %fusion.742), index=1
  %fusion.664 = f32[16,2048]{1,0} fusion(f32[16,1024]{1,0} %get-tuple-element.5067, f32[16,1024]{1,0} %get-tuple-element.5066, f32[16,1024]{1,0} %get-tuple-element.5071), kind=kLoop, calls=%fused_computation.664, control-predecessors={%fusion.160, %fusion.742, %fusion.151}, metadata={op_type="concatenate" op_name="pmap(_multi_device_update_fn)/scan/while/body/concatenate[ dimension=1 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=65}
  ROOT %tuple.796 = (f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) tuple(f32[64,16,1024]{2,1,0} %get-tuple-element.5889, f32[2048,4096]{1,0} %get-tuple-element.5890, f32[1,4096]{1,0} %get-tuple-element.5891, s32[] %add.1638, f32[16,2048]{1,0} %fusion.664, /*index=5*/f32[64,16,1024]{2,1,0} %fusion.153, f32[64,16,1024]{2,1,0} %fusion.152, f32[64,16,1024]{2,1,0} %fusion.151, f32[64,16,2048]{2,1,0} %fusion.150, f32[64,16,1024]{2,1,0} %fusion.149, /*index=10*/f32[64,16,1024]{2,1,0} %fusion.148, f32[64,16,1024]{2,1,0} %fusion.147, f32[64,16,1024]{2,1,0} %fusion.146, f32[64,16,1024]{2,1,0} %fusion.145, f32[64,16,1024]{2,1,0} %fusion.144, /*index=15*/f32[64,16,1024]{2,1,0} %fusion.143, f32[64,16,1024]{2,1,0} %fusion.142, f32[64,16,1024]{2,1,0} %fusion.141)
}

%cond_computation__38.2280.clone.clone.clone (parameter.177: (f32[64,16,1024], f32[2048,4096], f32[1,4096], s32[], f32[16,2048], /*index=5*/f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[64,16,2048], f32[64,16,1024], /*index=10*/f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], /*index=15*/f32[64,16,1024], f32[64,16,1024], f32[64,16,1024])) -> pred[] {
  %parameter.177 = (f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) parameter(0)
  %get-tuple-element.4253 = s32[] get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %parameter.177), index=3
  %constant_9837 = s32[] constant(64), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/cond/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %compare.1276 = pred[] compare(s32[] %get-tuple-element.4253, s32[] %constant_9837), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/cond/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.162 (param_0.285: f32[64,16,1024], param_1.2217: f32[16,1024], param_2.1912: s32[]) -> f32[64,16,1024] {
  %param_0.285 = f32[64,16,1024]{2,1,0} parameter(0)
  %constant_10890 = f32[] constant(1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %broadcast.1493 = f32[16,1024]{1,0} broadcast(f32[] %constant_10890), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %param_1.2217 = f32[16,1024]{1,0} parameter(1)
  %subtract.226 = f32[16,1024]{1,0} subtract(f32[16,1024]{1,0} %broadcast.1493, f32[16,1024]{1,0} %param_1.2217), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %bitcast.578 = f32[1,16,1024]{2,1,0} bitcast(f32[16,1024]{1,0} %subtract.226), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_2.1912 = s32[] parameter(2)
  %constant_10889 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.1830 = pred[] compare(s32[] %param_2.1912, s32[] %constant_10889), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_13927 = s32[] constant(64), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.2879 = s32[] add(s32[] %param_2.1912, s32[] %constant_13927), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %select.1821 = s32[] select(pred[] %compare.1830, s32[] %add.2879, s32[] %param_2.1912), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.539 = f32[64,16,1024]{2,1,0} dynamic-update-slice(f32[64,16,1024]{2,1,0} %param_0.285, f32[1,16,1024]{2,1,0} %bitcast.578, s32[] %select.1821, s32[] %constant_10889, s32[] %constant_10889), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.163 (param_0.286: f32[64,16,1024], param_1.2216: f32[16,1024], param_2.1910: s32[]) -> f32[64,16,1024] {
  %param_0.286 = f32[64,16,1024]{2,1,0} parameter(0)
  %param_1.2216 = f32[16,1024]{1,0} parameter(1)
  %bitcast.579 = f32[1,16,1024]{2,1,0} bitcast(f32[16,1024]{1,0} %param_1.2216), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_2.1910 = s32[] parameter(2)
  %constant_10891 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.1828 = pred[] compare(s32[] %param_2.1910, s32[] %constant_10891), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_13921 = s32[] constant(64), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.2877 = s32[] add(s32[] %param_2.1910, s32[] %constant_13921), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %select.1819 = s32[] select(pred[] %compare.1828, s32[] %add.2877, s32[] %param_2.1910), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.540 = f32[64,16,1024]{2,1,0} dynamic-update-slice(f32[64,16,1024]{2,1,0} %param_0.286, f32[1,16,1024]{2,1,0} %bitcast.579, s32[] %select.1819, s32[] %constant_10891, s32[] %constant_10891), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.164 (param_0.287: f32[64,16,1024], param_1.2215: f32[16,1024], param_2.1908: s32[]) -> f32[64,16,1024] {
  %param_0.287 = f32[64,16,1024]{2,1,0} parameter(0)
  %constant_10893 = f32[] constant(1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %broadcast.1494 = f32[16,1024]{1,0} broadcast(f32[] %constant_10893), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %param_1.2215 = f32[16,1024]{1,0} parameter(1)
  %subtract.227 = f32[16,1024]{1,0} subtract(f32[16,1024]{1,0} %broadcast.1494, f32[16,1024]{1,0} %param_1.2215), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  %bitcast.580 = f32[1,16,1024]{2,1,0} bitcast(f32[16,1024]{1,0} %subtract.227), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_2.1908 = s32[] parameter(2)
  %constant_10892 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.1826 = pred[] compare(s32[] %param_2.1908, s32[] %constant_10892), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_13916 = s32[] constant(64), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.2875 = s32[] add(s32[] %param_2.1908, s32[] %constant_13916), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %select.1817 = s32[] select(pred[] %compare.1826, s32[] %add.2875, s32[] %param_2.1908), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.541 = f32[64,16,1024]{2,1,0} dynamic-update-slice(f32[64,16,1024]{2,1,0} %param_0.287, f32[1,16,1024]{2,1,0} %bitcast.580, s32[] %select.1817, s32[] %constant_10892, s32[] %constant_10892), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.165 (param_0.288: f32[64,16,1024], param_1.2214: f32[16,1024], param_2.1906: s32[]) -> f32[64,16,1024] {
  %param_0.288 = f32[64,16,1024]{2,1,0} parameter(0)
  %param_1.2214 = f32[16,1024]{1,0} parameter(1)
  %bitcast.581 = f32[1,16,1024]{2,1,0} bitcast(f32[16,1024]{1,0} %param_1.2214), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_2.1906 = s32[] parameter(2)
  %constant_10894 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.1824 = pred[] compare(s32[] %param_2.1906, s32[] %constant_10894), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_13909 = s32[] constant(64), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.2872 = s32[] add(s32[] %param_2.1906, s32[] %constant_13909), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %select.1815 = s32[] select(pred[] %compare.1824, s32[] %add.2872, s32[] %param_2.1906), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.542 = f32[64,16,1024]{2,1,0} dynamic-update-slice(f32[64,16,1024]{2,1,0} %param_0.288, f32[1,16,1024]{2,1,0} %bitcast.581, s32[] %select.1815, s32[] %constant_10894, s32[] %constant_10894), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.166 (param_0.289: f32[64,16,1024], param_1.2213: f32[16,1024], param_2.1904: s32[]) -> f32[64,16,1024] {
  %param_0.289 = f32[64,16,1024]{2,1,0} parameter(0)
  %constant_10896 = f32[] constant(1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %broadcast.1495 = f32[16,1024]{1,0} broadcast(f32[] %constant_10896), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %param_1.2213 = f32[16,1024]{1,0} parameter(1)
  %subtract.228 = f32[16,1024]{1,0} subtract(f32[16,1024]{1,0} %broadcast.1495, f32[16,1024]{1,0} %param_1.2213), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %bitcast.582 = f32[1,16,1024]{2,1,0} bitcast(f32[16,1024]{1,0} %subtract.228), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_2.1904 = s32[] parameter(2)
  %constant_10895 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.1822 = pred[] compare(s32[] %param_2.1904, s32[] %constant_10895), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_13903 = s32[] constant(64), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.2870 = s32[] add(s32[] %param_2.1904, s32[] %constant_13903), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %select.1813 = s32[] select(pred[] %compare.1822, s32[] %add.2870, s32[] %param_2.1904), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.543 = f32[64,16,1024]{2,1,0} dynamic-update-slice(f32[64,16,1024]{2,1,0} %param_0.289, f32[1,16,1024]{2,1,0} %bitcast.582, s32[] %select.1813, s32[] %constant_10895, s32[] %constant_10895), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.167 (param_0.290: f32[64,16,1024], param_1.2212: f32[16,1024], param_2.1902: s32[]) -> f32[64,16,1024] {
  %param_0.290 = f32[64,16,1024]{2,1,0} parameter(0)
  %param_1.2212 = f32[16,1024]{1,0} parameter(1)
  %bitcast.583 = f32[1,16,1024]{2,1,0} bitcast(f32[16,1024]{1,0} %param_1.2212), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_2.1902 = s32[] parameter(2)
  %constant_10897 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.1820 = pred[] compare(s32[] %param_2.1902, s32[] %constant_10897), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_13897 = s32[] constant(64), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.2868 = s32[] add(s32[] %param_2.1902, s32[] %constant_13897), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %select.1811 = s32[] select(pred[] %compare.1820, s32[] %add.2868, s32[] %param_2.1902), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.544 = f32[64,16,1024]{2,1,0} dynamic-update-slice(f32[64,16,1024]{2,1,0} %param_0.290, f32[1,16,1024]{2,1,0} %bitcast.583, s32[] %select.1811, s32[] %constant_10897, s32[] %constant_10897), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.168 (param_0.291: f32[64,16,1024], param_1.2211: f32[16,1024], param_2.1900: s32[]) -> f32[64,16,1024] {
  %param_0.291 = f32[64,16,1024]{2,1,0} parameter(0)
  %constant_10899 = f32[] constant(1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %broadcast.1496 = f32[16,1024]{1,0} broadcast(f32[] %constant_10899), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %param_1.2211 = f32[16,1024]{1,0} parameter(1)
  %subtract.229 = f32[16,1024]{1,0} subtract(f32[16,1024]{1,0} %broadcast.1496, f32[16,1024]{1,0} %param_1.2211), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %bitcast.584 = f32[1,16,1024]{2,1,0} bitcast(f32[16,1024]{1,0} %subtract.229), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_2.1900 = s32[] parameter(2)
  %constant_10898 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.1818 = pred[] compare(s32[] %param_2.1900, s32[] %constant_10898), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_13891 = s32[] constant(64), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.2865 = s32[] add(s32[] %param_2.1900, s32[] %constant_13891), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %select.1809 = s32[] select(pred[] %compare.1818, s32[] %add.2865, s32[] %param_2.1900), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.545 = f32[64,16,1024]{2,1,0} dynamic-update-slice(f32[64,16,1024]{2,1,0} %param_0.291, f32[1,16,1024]{2,1,0} %bitcast.584, s32[] %select.1809, s32[] %constant_10898, s32[] %constant_10898), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.169 (param_0.292: f32[64,16,1024], param_1.2210: f32[16,1024], param_2.1898: s32[]) -> f32[64,16,1024] {
  %param_0.292 = f32[64,16,1024]{2,1,0} parameter(0)
  %param_1.2210 = f32[16,1024]{1,0} parameter(1)
  %bitcast.585 = f32[1,16,1024]{2,1,0} bitcast(f32[16,1024]{1,0} %param_1.2210), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_2.1898 = s32[] parameter(2)
  %constant_10900 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.1816 = pred[] compare(s32[] %param_2.1898, s32[] %constant_10900), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_13885 = s32[] constant(64), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.2863 = s32[] add(s32[] %param_2.1898, s32[] %constant_13885), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %select.1807 = s32[] select(pred[] %compare.1816, s32[] %add.2863, s32[] %param_2.1898), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.546 = f32[64,16,1024]{2,1,0} dynamic-update-slice(f32[64,16,1024]{2,1,0} %param_0.292, f32[1,16,1024]{2,1,0} %bitcast.585, s32[] %select.1807, s32[] %constant_10900, s32[] %constant_10900), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.170 (param_0.293: f32[64,16,1024], param_1.2209: f32[16,1024], param_2.1896: s32[]) -> f32[64,16,1024] {
  %param_0.293 = f32[64,16,1024]{2,1,0} parameter(0)
  %constant_10902 = f32[] constant(1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %broadcast.1497 = f32[16,1024]{1,0} broadcast(f32[] %constant_10902), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %param_1.2209 = f32[16,1024]{1,0} parameter(1)
  %subtract.230 = f32[16,1024]{1,0} subtract(f32[16,1024]{1,0} %broadcast.1497, f32[16,1024]{1,0} %param_1.2209), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %bitcast.586 = f32[1,16,1024]{2,1,0} bitcast(f32[16,1024]{1,0} %subtract.230), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_2.1896 = s32[] parameter(2)
  %constant_10901 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.1814 = pred[] compare(s32[] %param_2.1896, s32[] %constant_10901), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_13878 = s32[] constant(64), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.2861 = s32[] add(s32[] %param_2.1896, s32[] %constant_13878), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %select.1805 = s32[] select(pred[] %compare.1814, s32[] %add.2861, s32[] %param_2.1896), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.547 = f32[64,16,1024]{2,1,0} dynamic-update-slice(f32[64,16,1024]{2,1,0} %param_0.293, f32[1,16,1024]{2,1,0} %bitcast.586, s32[] %select.1805, s32[] %constant_10901, s32[] %constant_10901), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.171 (param_0.294: f32[64,16,2048], param_1.2208: f32[16,2048], param_2.1894: s32[]) -> f32[64,16,2048] {
  %param_0.294 = f32[64,16,2048]{2,1,0} parameter(0)
  %param_1.2208 = f32[16,2048]{1,0} parameter(1)
  %bitcast.587 = f32[1,16,2048]{2,1,0} bitcast(f32[16,2048]{1,0} %param_1.2208), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 16, 2048) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_2.1894 = s32[] parameter(2)
  %constant_10903 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.1812 = pred[] compare(s32[] %param_2.1894, s32[] %constant_10903), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_13873 = s32[] constant(64), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.2859 = s32[] add(s32[] %param_2.1894, s32[] %constant_13873), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %select.1803 = s32[] select(pred[] %compare.1812, s32[] %add.2859, s32[] %param_2.1894), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.548 = f32[64,16,2048]{2,1,0} dynamic-update-slice(f32[64,16,2048]{2,1,0} %param_0.294, f32[1,16,2048]{2,1,0} %bitcast.587, s32[] %select.1803, s32[] %constant_10903, s32[] %constant_10903), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.172 (param_0.295: f32[64,16,1024], param_1.2207: f32[16,2048], param_2.1892: s32[]) -> f32[64,16,1024] {
  %param_0.295 = f32[64,16,1024]{2,1,0} parameter(0)
  %param_1.2207 = f32[16,2048]{1,0} parameter(1)
  %slice.927 = f32[16,1024]{1,0} slice(f32[16,2048]{1,0} %param_1.2207), slice={[0:16], [0:1024]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(16, 1024)\n                                                     start_indices=(0, 0)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=54}
  %bitcast.588 = f32[1,16,1024]{2,1,0} bitcast(f32[16,1024]{1,0} %slice.927), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_2.1892 = s32[] parameter(2)
  %constant_10904 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.1810 = pred[] compare(s32[] %param_2.1892, s32[] %constant_10904), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_13867 = s32[] constant(64), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.2856 = s32[] add(s32[] %param_2.1892, s32[] %constant_13867), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %select.1801 = s32[] select(pred[] %compare.1810, s32[] %add.2856, s32[] %param_2.1892), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.549 = f32[64,16,1024]{2,1,0} dynamic-update-slice(f32[64,16,1024]{2,1,0} %param_0.295, f32[1,16,1024]{2,1,0} %bitcast.588, s32[] %select.1801, s32[] %constant_10904, s32[] %constant_10904), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.173 (param_0.296: f32[64,16,1024], param_1.2206: f32[16,1024], param_2.1890: s32[]) -> f32[64,16,1024] {
  %param_0.296 = f32[64,16,1024]{2,1,0} parameter(0)
  %param_1.2206 = f32[16,1024]{1,0} parameter(1)
  %bitcast.589 = f32[1,16,1024]{2,1,0} bitcast(f32[16,1024]{1,0} %param_1.2206), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_2.1890 = s32[] parameter(2)
  %constant_10905 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.1808 = pred[] compare(s32[] %param_2.1890, s32[] %constant_10905), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_13861 = s32[] constant(64), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.2854 = s32[] add(s32[] %param_2.1890, s32[] %constant_13861), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %select.1799 = s32[] select(pred[] %compare.1808, s32[] %add.2854, s32[] %param_2.1890), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.550 = f32[64,16,1024]{2,1,0} dynamic-update-slice(f32[64,16,1024]{2,1,0} %param_0.296, f32[1,16,1024]{2,1,0} %bitcast.589, s32[] %select.1799, s32[] %constant_10905, s32[] %constant_10905), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.174 (param_0.297: f32[64,16,1024], param_1.2205: f32[16,1024], param_2.1888: f32[16,1024], param_3.1655: s32[]) -> f32[64,16,1024] {
  %param_0.297 = f32[64,16,1024]{2,1,0} parameter(0)
  %param_1.2205 = f32[16,1024]{1,0} parameter(1)
  %param_2.1888 = f32[16,1024]{1,0} parameter(2)
  %multiply.1384 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %param_1.2205, f32[16,1024]{1,0} %param_2.1888), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  %bitcast.590 = f32[1,16,1024]{2,1,0} bitcast(f32[16,1024]{1,0} %multiply.1384), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_3.1655 = s32[] parameter(3)
  %constant_10906 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.1806 = pred[] compare(s32[] %param_3.1655, s32[] %constant_10906), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_13854 = s32[] constant(64), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.2852 = s32[] add(s32[] %param_3.1655, s32[] %constant_13854), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %select.1797 = s32[] select(pred[] %compare.1806, s32[] %add.2852, s32[] %param_3.1655), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.551 = f32[64,16,1024]{2,1,0} dynamic-update-slice(f32[64,16,1024]{2,1,0} %param_0.297, f32[1,16,1024]{2,1,0} %bitcast.590, s32[] %select.1797, s32[] %constant_10906, s32[] %constant_10906), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.180 (param_0.306: f32[1,4096]) -> f32[16,4096] {
  %param_0.306 = f32[1,4096]{1,0} parameter(0)
  %bitcast.591 = f32[4096]{0} bitcast(f32[1,4096]{1,0} %param_0.306), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  ROOT %broadcast.1277 = f32[16,4096]{1,0} broadcast(f32[4096]{0} %bitcast.591), dimensions={1}, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
}

%fused_computation.181 (param_0.308: f32[16,2048], param_1.479: f32[64,16,1024], param_2.1887: s32[]) -> f32[16,2048] {
  %param_1.479 = f32[64,16,1024]{2,1,0} parameter(1)
  %param_2.1887 = s32[] parameter(2)
  %constant_10910 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.1804 = pred[] compare(s32[] %param_2.1887, s32[] %constant_10910), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_13848 = s32[] constant(64), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.2849 = s32[] add(s32[] %param_2.1887, s32[] %constant_13848), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %select.1795 = s32[] select(pred[] %compare.1804, s32[] %add.2849, s32[] %param_2.1887), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %dynamic-slice.405 = f32[1,16,1024]{2,1,0} dynamic-slice(f32[64,16,1024]{2,1,0} %param_1.479, s32[] %select.1795, s32[] %constant_10910, s32[] %constant_10910), dynamic_slice_sizes={1,16,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %bitcast.592 = f32[16,1024]{1,0} bitcast(f32[1,16,1024]{2,1,0} %dynamic-slice.405), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_0.308 = f32[16,2048]{1,0} parameter(0)
  %slice.873 = f32[16,1024]{1,0} slice(f32[16,2048]{1,0} %param_0.308), slice={[0:16], [1024:2048]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(16, 2048)\n                                                     start_indices=(0, 1024)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=54}
  ROOT %concatenate.193 = f32[16,2048]{1,0} concatenate(f32[16,1024]{1,0} %bitcast.592, f32[16,1024]{1,0} %slice.873), dimensions={1}, metadata={op_type="concatenate" op_name="pmap(_multi_device_update_fn)/scan/while/body/concatenate[ dimension=1 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
}

%fused_computation.665 (param_0.1255: f32[16,1024], param_1.1589: f32[16,1024], param_2.1026: f32[16,1024]) -> f32[16,2048] {
  %param_0.1255 = f32[16,1024]{1,0} parameter(0)
  %param_1.1589 = f32[16,1024]{1,0} parameter(1)
  %param_2.1026 = f32[16,1024]{1,0} parameter(2)
  %multiply.1385 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %param_1.1589, f32[16,1024]{1,0} %param_2.1026), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  ROOT %concatenate.208 = f32[16,2048]{1,0} concatenate(f32[16,1024]{1,0} %param_0.1255, f32[16,1024]{1,0} %multiply.1385), dimensions={1}, metadata={op_type="concatenate" op_name="pmap(_multi_device_update_fn)/scan/while/body/concatenate[ dimension=1 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=65}
}

%fused_computation.743 (param_0.2184: f32[16,2048], param_1.2643: f32[16,4096]) -> (f32[16,1024], f32[16,1024], f32[16,1024], f32[16,1024], f32[16,1024], /*index=5*/f32[16,1024]) {
  %param_0.2184 = f32[16,2048]{1,0} parameter(0)
  %slice.928.clone.1 = f32[16,1024]{1,0} slice(f32[16,2048]{1,0} %param_0.2184), slice={[0:16], [0:1024]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(16, 1024)\n                                                     start_indices=(0, 0)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=54}
  %constant_10908_clone_1 = f32[] constant(1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %broadcast.1499.clone.1 = f32[16,1024]{1,0} broadcast(f32[] %constant_10908_clone_1), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %param_1.2643 = f32[16,4096]{1,0} parameter(1)
  %slice.872.clone.1 = f32[16,1024]{1,0} slice(f32[16,4096]{1,0} %param_1.2643), slice={[0:16], [2048:3072]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(16, 3072)\n                                                     start_indices=(0, 2048)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  %negate.138.clone.1 = f32[16,1024]{1,0} negate(f32[16,1024]{1,0} %slice.872.clone.1), metadata={op_type="neg" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/neg" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %exponential.119.clone.1 = f32[16,1024]{1,0} exponential(f32[16,1024]{1,0} %negate.138.clone.1), metadata={op_type="exp" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/exp" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %add.1877.clone.1 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %broadcast.1499.clone.1, f32[16,1024]{1,0} %exponential.119.clone.1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %divide.123.clone.1 = f32[16,1024]{1,0} divide(f32[16,1024]{1,0} %broadcast.1499.clone.1, f32[16,1024]{1,0} %add.1877.clone.1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %multiply.936.clone.1 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %slice.928.clone.1, f32[16,1024]{1,0} %divide.123.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %slice.871.clone.1 = f32[16,1024]{1,0} slice(f32[16,4096]{1,0} %param_1.2643), slice={[0:16], [0:1024]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(16, 1024)\n                                                     start_indices=(0, 0)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  %negate.137.clone.1 = f32[16,1024]{1,0} negate(f32[16,1024]{1,0} %slice.871.clone.1), metadata={op_type="neg" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/neg" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %exponential.118.clone.1 = f32[16,1024]{1,0} exponential(f32[16,1024]{1,0} %negate.137.clone.1), metadata={op_type="exp" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/exp" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %add.1876.clone.1 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %broadcast.1499.clone.1, f32[16,1024]{1,0} %exponential.118.clone.1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %divide.122.clone.1 = f32[16,1024]{1,0} divide(f32[16,1024]{1,0} %broadcast.1499.clone.1, f32[16,1024]{1,0} %add.1876.clone.1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %slice.870.clone.1 = f32[16,1024]{1,0} slice(f32[16,4096]{1,0} %param_1.2643), slice={[0:16], [1024:2048]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(16, 2048)\n                                                     start_indices=(0, 1024)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  %tanh.75.clone.1 = f32[16,1024]{1,0} tanh(f32[16,1024]{1,0} %slice.870.clone.1), metadata={op_type="tanh" op_name="pmap(_multi_device_update_fn)/scan/while/body/tanh" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %multiply.935.clone.1 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %divide.122.clone.1, f32[16,1024]{1,0} %tanh.75.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %add.1875.clone.1 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %multiply.936.clone.1, f32[16,1024]{1,0} %multiply.935.clone.1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %tanh.84 = f32[16,1024]{1,0} tanh(f32[16,1024]{1,0} %add.1875.clone.1), metadata={op_type="tanh" op_name="pmap(_multi_device_update_fn)/scan/while/body/tanh" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  %slice.869.clone.1 = f32[16,1024]{1,0} slice(f32[16,4096]{1,0} %param_1.2643), slice={[0:16], [3072:4096]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(16, 4096)\n                                                     start_indices=(0, 3072)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  %negate.136.clone.1 = f32[16,1024]{1,0} negate(f32[16,1024]{1,0} %slice.869.clone.1), metadata={op_type="neg" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/neg" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %exponential.117.clone.1 = f32[16,1024]{1,0} exponential(f32[16,1024]{1,0} %negate.136.clone.1), metadata={op_type="exp" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/exp" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %add.1874.clone.1 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %broadcast.1499.clone.1, f32[16,1024]{1,0} %exponential.117.clone.1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %divide.121.clone.1 = f32[16,1024]{1,0} divide(f32[16,1024]{1,0} %broadcast.1499.clone.1, f32[16,1024]{1,0} %add.1874.clone.1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  ROOT %tuple.493 = (f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, /*index=5*/f32[16,1024]{1,0}) tuple(f32[16,1024]{1,0} %tanh.84, f32[16,1024]{1,0} %add.1875.clone.1, f32[16,1024]{1,0} %divide.123.clone.1, f32[16,1024]{1,0} %tanh.75.clone.1, f32[16,1024]{1,0} %divide.122.clone.1, /*index=5*/f32[16,1024]{1,0} %divide.121.clone.1)
}

%body_computation__39.2539.clone.clone.clone.clone (parameter.178: (f32[64,16,1024], f32[2048,4096], f32[1,4096], s32[], f32[16,2048], /*index=5*/f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[64,16,2048], f32[64,16,1024], /*index=10*/f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], /*index=15*/f32[64,16,1024], f32[64,16,1024], f32[64,16,1024])) -> (f32[64,16,1024], f32[2048,4096], f32[1,4096], s32[], f32[16,2048], /*index=5*/f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[64,16,2048], f32[64,16,1024], /*index=10*/f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], /*index=15*/f32[64,16,1024], f32[64,16,1024], f32[64,16,1024]) {
  %parameter.178 = (f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) parameter(0)
  %get-tuple-element.5943 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %parameter.178), index=0
  %get-tuple-element.5944 = f32[2048,4096]{1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %parameter.178), index=1
  %get-tuple-element.5945 = f32[1,4096]{1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %parameter.178), index=2
  %get-tuple-element.5959 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %parameter.178), index=16
  %get-tuple-element.5947 = f32[16,2048]{1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %parameter.178), index=4
  %get-tuple-element.5946 = s32[] get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %parameter.178), index=3
  %fusion.181 = f32[16,2048]{1,0} fusion(f32[16,2048]{1,0} %get-tuple-element.5947, f32[64,16,1024]{2,1,0} %get-tuple-element.5943, s32[] %get-tuple-element.5946), kind=kLoop, calls=%fused_computation.181, metadata={op_type="concatenate" op_name="pmap(_multi_device_update_fn)/scan/while/body/concatenate[ dimension=1 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %fusion.180 = f32[16,4096]{1,0} fusion(f32[1,4096]{1,0} %get-tuple-element.5945), kind=kLoop, calls=%fused_computation.180, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %custom-call.126 = f32[16,4096]{1,0} custom-call(f32[16,2048]{1,0} %fusion.181, f32[2048,4096]{1,0} %get-tuple-element.5944, f32[16,4096]{1,0} %fusion.180), custom_call_target="__cublas$gemm", metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}, backend_config="{\"alpha_real\":1,\"alpha_imag\":0,\"beta\":1,\"dot_dimension_numbers\":{\"lhs_contracting_dimensions\":[\"1\"],\"rhs_contracting_dimensions\":[\"0\"],\"lhs_batch_dimensions\":[],\"rhs_batch_dimensions\":[]},\"batch_size\":\"1\",\"selected_algorithm\":\"0\"}"
  %fusion.743 = (f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, /*index=5*/f32[16,1024]{1,0}) fusion(f32[16,2048]{1,0} %get-tuple-element.5947, f32[16,4096]{1,0} %custom-call.126), kind=kLoop, calls=%fused_computation.743, metadata={op_type="tanh" op_name="pmap(_multi_device_update_fn)/scan/while/body/tanh" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  %get-tuple-element.5077 = f32[16,1024]{1,0} get-tuple-element((f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, /*index=5*/f32[16,1024]{1,0}) %fusion.743), index=5
  %fusion.163 = f32[64,16,1024]{2,1,0} fusion(f32[64,16,1024]{2,1,0} %get-tuple-element.5959, f32[16,1024]{1,0} %get-tuple-element.5077, s32[] %get-tuple-element.5946), kind=kLoop, calls=%fused_computation.163, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.5958 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %parameter.178), index=15
  %get-tuple-element.5072 = f32[16,1024]{1,0} get-tuple-element((f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, /*index=5*/f32[16,1024]{1,0}) %fusion.743), index=0
  %fusion.164 = f32[64,16,1024]{2,1,0} fusion(f32[64,16,1024]{2,1,0} %get-tuple-element.5958, f32[16,1024]{1,0} %get-tuple-element.5072, s32[] %get-tuple-element.5946), kind=kLoop, calls=%fused_computation.164, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.5957 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %parameter.178), index=14
  %fusion.165 = f32[64,16,1024]{2,1,0} fusion(f32[64,16,1024]{2,1,0} %get-tuple-element.5957, f32[16,1024]{1,0} %get-tuple-element.5072, s32[] %get-tuple-element.5946), kind=kLoop, calls=%fused_computation.165, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.5956 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %parameter.178), index=13
  %get-tuple-element.5075 = f32[16,1024]{1,0} get-tuple-element((f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, /*index=5*/f32[16,1024]{1,0}) %fusion.743), index=3
  %fusion.166 = f32[64,16,1024]{2,1,0} fusion(f32[64,16,1024]{2,1,0} %get-tuple-element.5956, f32[16,1024]{1,0} %get-tuple-element.5075, s32[] %get-tuple-element.5946), kind=kLoop, calls=%fused_computation.166, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.5955 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %parameter.178), index=12
  %fusion.167 = f32[64,16,1024]{2,1,0} fusion(f32[64,16,1024]{2,1,0} %get-tuple-element.5955, f32[16,1024]{1,0} %get-tuple-element.5075, s32[] %get-tuple-element.5946), kind=kLoop, calls=%fused_computation.167, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.5954 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %parameter.178), index=11
  %get-tuple-element.5076 = f32[16,1024]{1,0} get-tuple-element((f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, /*index=5*/f32[16,1024]{1,0}) %fusion.743), index=4
  %fusion.168 = f32[64,16,1024]{2,1,0} fusion(f32[64,16,1024]{2,1,0} %get-tuple-element.5954, f32[16,1024]{1,0} %get-tuple-element.5076, s32[] %get-tuple-element.5946), kind=kLoop, calls=%fused_computation.168, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.5953 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %parameter.178), index=10
  %fusion.169 = f32[64,16,1024]{2,1,0} fusion(f32[64,16,1024]{2,1,0} %get-tuple-element.5953, f32[16,1024]{1,0} %get-tuple-element.5076, s32[] %get-tuple-element.5946), kind=kLoop, calls=%fused_computation.169, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.5952 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %parameter.178), index=9
  %get-tuple-element.5074 = f32[16,1024]{1,0} get-tuple-element((f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, /*index=5*/f32[16,1024]{1,0}) %fusion.743), index=2
  %fusion.170 = f32[64,16,1024]{2,1,0} fusion(f32[64,16,1024]{2,1,0} %get-tuple-element.5952, f32[16,1024]{1,0} %get-tuple-element.5074, s32[] %get-tuple-element.5946), kind=kLoop, calls=%fused_computation.170, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.5951 = f32[64,16,2048]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %parameter.178), index=8
  %fusion.171 = f32[64,16,2048]{2,1,0} fusion(f32[64,16,2048]{2,1,0} %get-tuple-element.5951, f32[16,2048]{1,0} %fusion.181, s32[] %get-tuple-element.5946), kind=kLoop, calls=%fused_computation.171, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.5950 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %parameter.178), index=7
  %fusion.172 = f32[64,16,1024]{2,1,0} fusion(f32[64,16,1024]{2,1,0} %get-tuple-element.5950, f32[16,2048]{1,0} %get-tuple-element.5947, s32[] %get-tuple-element.5946), kind=kLoop, calls=%fused_computation.172, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.5949 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %parameter.178), index=6
  %fusion.173 = f32[64,16,1024]{2,1,0} fusion(f32[64,16,1024]{2,1,0} %get-tuple-element.5949, f32[16,1024]{1,0} %get-tuple-element.5074, s32[] %get-tuple-element.5946), kind=kLoop, calls=%fused_computation.173, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.5948 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %parameter.178), index=5
  %fusion.174 = f32[64,16,1024]{2,1,0} fusion(f32[64,16,1024]{2,1,0} %get-tuple-element.5948, f32[16,1024]{1,0} %get-tuple-element.5072, f32[16,1024]{1,0} %get-tuple-element.5077, s32[] %get-tuple-element.5946), kind=kLoop, calls=%fused_computation.174, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.5960 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %parameter.178), index=17
  %fusion.162 = f32[64,16,1024]{2,1,0} fusion(f32[64,16,1024]{2,1,0} %get-tuple-element.5960, f32[16,1024]{1,0} %get-tuple-element.5077, s32[] %get-tuple-element.5946), kind=kLoop, calls=%fused_computation.162, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_9925 = s32[] constant(1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.1658 = s32[] add(s32[] %get-tuple-element.5946, s32[] %constant_9925), control-predecessors={%fusion.162, %fusion.181, %fusion.174, %fusion.173, %fusion.172, %fusion.171, %fusion.170, %fusion.169, %fusion.168, %fusion.167, %fusion.166, %fusion.165, %fusion.164, %fusion.163}, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.5073 = f32[16,1024]{1,0} get-tuple-element((f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, /*index=5*/f32[16,1024]{1,0}) %fusion.743), index=1
  %fusion.665 = f32[16,2048]{1,0} fusion(f32[16,1024]{1,0} %get-tuple-element.5073, f32[16,1024]{1,0} %get-tuple-element.5072, f32[16,1024]{1,0} %get-tuple-element.5077), kind=kLoop, calls=%fused_computation.665, control-predecessors={%fusion.181, %fusion.743, %fusion.172}, metadata={op_type="concatenate" op_name="pmap(_multi_device_update_fn)/scan/while/body/concatenate[ dimension=1 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=65}
  ROOT %tuple.799 = (f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) tuple(f32[64,16,1024]{2,1,0} %get-tuple-element.5943, f32[2048,4096]{1,0} %get-tuple-element.5944, f32[1,4096]{1,0} %get-tuple-element.5945, s32[] %add.1658, f32[16,2048]{1,0} %fusion.665, /*index=5*/f32[64,16,1024]{2,1,0} %fusion.174, f32[64,16,1024]{2,1,0} %fusion.173, f32[64,16,1024]{2,1,0} %fusion.172, f32[64,16,2048]{2,1,0} %fusion.171, f32[64,16,1024]{2,1,0} %fusion.170, /*index=10*/f32[64,16,1024]{2,1,0} %fusion.169, f32[64,16,1024]{2,1,0} %fusion.168, f32[64,16,1024]{2,1,0} %fusion.167, f32[64,16,1024]{2,1,0} %fusion.166, f32[64,16,1024]{2,1,0} %fusion.165, /*index=15*/f32[64,16,1024]{2,1,0} %fusion.164, f32[64,16,1024]{2,1,0} %fusion.163, f32[64,16,1024]{2,1,0} %fusion.162)
}

%cond_computation__39.2960.clone.clone.clone (parameter.179: (f32[64,16,1024], f32[2048,4096], f32[1,4096], s32[], f32[16,2048], /*index=5*/f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[64,16,2048], f32[64,16,1024], /*index=10*/f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], /*index=15*/f32[64,16,1024], f32[64,16,1024], f32[64,16,1024])) -> pred[] {
  %parameter.179 = (f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) parameter(0)
  %get-tuple-element.4374 = s32[] get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %parameter.179), index=3
  %constant_9928 = s32[] constant(64), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/cond/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %compare.1291 = pred[] compare(s32[] %get-tuple-element.4374, s32[] %constant_9928), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/cond/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.183 (param_0.311: f32[64,16,1024], param_1.2230: f32[16,1024], param_2.1939: s32[]) -> f32[64,16,1024] {
  %param_0.311 = f32[64,16,1024]{2,1,0} parameter(0)
  %constant_10913 = f32[] constant(1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %broadcast.1501 = f32[16,1024]{1,0} broadcast(f32[] %constant_10913), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %param_1.2230 = f32[16,1024]{1,0} parameter(1)
  %subtract.231 = f32[16,1024]{1,0} subtract(f32[16,1024]{1,0} %broadcast.1501, f32[16,1024]{1,0} %param_1.2230), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %bitcast.593 = f32[1,16,1024]{2,1,0} bitcast(f32[16,1024]{1,0} %subtract.231), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_2.1939 = s32[] parameter(2)
  %constant_10912 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.1858 = pred[] compare(s32[] %param_2.1939, s32[] %constant_10912), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_14011 = s32[] constant(64), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.2911 = s32[] add(s32[] %param_2.1939, s32[] %constant_14011), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %select.1849 = s32[] select(pred[] %compare.1858, s32[] %add.2911, s32[] %param_2.1939), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.552 = f32[64,16,1024]{2,1,0} dynamic-update-slice(f32[64,16,1024]{2,1,0} %param_0.311, f32[1,16,1024]{2,1,0} %bitcast.593, s32[] %select.1849, s32[] %constant_10912, s32[] %constant_10912), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.184 (param_0.312: f32[64,16,1024], param_1.2229: f32[16,1024], param_2.1937: s32[]) -> f32[64,16,1024] {
  %param_0.312 = f32[64,16,1024]{2,1,0} parameter(0)
  %param_1.2229 = f32[16,1024]{1,0} parameter(1)
  %bitcast.594 = f32[1,16,1024]{2,1,0} bitcast(f32[16,1024]{1,0} %param_1.2229), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_2.1937 = s32[] parameter(2)
  %constant_10914 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.1856 = pred[] compare(s32[] %param_2.1937, s32[] %constant_10914), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_14005 = s32[] constant(64), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.2909 = s32[] add(s32[] %param_2.1937, s32[] %constant_14005), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %select.1847 = s32[] select(pred[] %compare.1856, s32[] %add.2909, s32[] %param_2.1937), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.553 = f32[64,16,1024]{2,1,0} dynamic-update-slice(f32[64,16,1024]{2,1,0} %param_0.312, f32[1,16,1024]{2,1,0} %bitcast.594, s32[] %select.1847, s32[] %constant_10914, s32[] %constant_10914), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.185 (param_0.313: f32[64,16,1024], param_1.2228: f32[16,1024], param_2.1935: s32[]) -> f32[64,16,1024] {
  %param_0.313 = f32[64,16,1024]{2,1,0} parameter(0)
  %constant_10916 = f32[] constant(1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %broadcast.1503 = f32[16,1024]{1,0} broadcast(f32[] %constant_10916), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %param_1.2228 = f32[16,1024]{1,0} parameter(1)
  %subtract.232 = f32[16,1024]{1,0} subtract(f32[16,1024]{1,0} %broadcast.1503, f32[16,1024]{1,0} %param_1.2228), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  %bitcast.595 = f32[1,16,1024]{2,1,0} bitcast(f32[16,1024]{1,0} %subtract.232), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_2.1935 = s32[] parameter(2)
  %constant_10915 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.1854 = pred[] compare(s32[] %param_2.1935, s32[] %constant_10915), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_14000 = s32[] constant(64), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.2907 = s32[] add(s32[] %param_2.1935, s32[] %constant_14000), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %select.1845 = s32[] select(pred[] %compare.1854, s32[] %add.2907, s32[] %param_2.1935), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.554 = f32[64,16,1024]{2,1,0} dynamic-update-slice(f32[64,16,1024]{2,1,0} %param_0.313, f32[1,16,1024]{2,1,0} %bitcast.595, s32[] %select.1845, s32[] %constant_10915, s32[] %constant_10915), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.186 (param_0.314: f32[64,16,1024], param_1.2227: f32[16,1024], param_2.1933: s32[]) -> f32[64,16,1024] {
  %param_0.314 = f32[64,16,1024]{2,1,0} parameter(0)
  %param_1.2227 = f32[16,1024]{1,0} parameter(1)
  %bitcast.596 = f32[1,16,1024]{2,1,0} bitcast(f32[16,1024]{1,0} %param_1.2227), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_2.1933 = s32[] parameter(2)
  %constant_10917 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.1852 = pred[] compare(s32[] %param_2.1933, s32[] %constant_10917), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_13994 = s32[] constant(64), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.2905 = s32[] add(s32[] %param_2.1933, s32[] %constant_13994), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %select.1843 = s32[] select(pred[] %compare.1852, s32[] %add.2905, s32[] %param_2.1933), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.555 = f32[64,16,1024]{2,1,0} dynamic-update-slice(f32[64,16,1024]{2,1,0} %param_0.314, f32[1,16,1024]{2,1,0} %bitcast.596, s32[] %select.1843, s32[] %constant_10917, s32[] %constant_10917), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.187 (param_0.315: f32[64,16,1024], param_1.2226: f32[16,1024], param_2.1931: s32[]) -> f32[64,16,1024] {
  %param_0.315 = f32[64,16,1024]{2,1,0} parameter(0)
  %constant_10919 = f32[] constant(1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %broadcast.1504 = f32[16,1024]{1,0} broadcast(f32[] %constant_10919), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %param_1.2226 = f32[16,1024]{1,0} parameter(1)
  %subtract.233 = f32[16,1024]{1,0} subtract(f32[16,1024]{1,0} %broadcast.1504, f32[16,1024]{1,0} %param_1.2226), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %bitcast.597 = f32[1,16,1024]{2,1,0} bitcast(f32[16,1024]{1,0} %subtract.233), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_2.1931 = s32[] parameter(2)
  %constant_10918 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.1850 = pred[] compare(s32[] %param_2.1931, s32[] %constant_10918), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_13988 = s32[] constant(64), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.2902 = s32[] add(s32[] %param_2.1931, s32[] %constant_13988), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %select.1841 = s32[] select(pred[] %compare.1850, s32[] %add.2902, s32[] %param_2.1931), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.556 = f32[64,16,1024]{2,1,0} dynamic-update-slice(f32[64,16,1024]{2,1,0} %param_0.315, f32[1,16,1024]{2,1,0} %bitcast.597, s32[] %select.1841, s32[] %constant_10918, s32[] %constant_10918), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.188 (param_0.316: f32[64,16,1024], param_1.2225: f32[16,1024], param_2.1929: s32[]) -> f32[64,16,1024] {
  %param_0.316 = f32[64,16,1024]{2,1,0} parameter(0)
  %param_1.2225 = f32[16,1024]{1,0} parameter(1)
  %bitcast.598 = f32[1,16,1024]{2,1,0} bitcast(f32[16,1024]{1,0} %param_1.2225), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_2.1929 = s32[] parameter(2)
  %constant_10920 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.1848 = pred[] compare(s32[] %param_2.1929, s32[] %constant_10920), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_13982 = s32[] constant(64), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.2900 = s32[] add(s32[] %param_2.1929, s32[] %constant_13982), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %select.1839 = s32[] select(pred[] %compare.1848, s32[] %add.2900, s32[] %param_2.1929), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.557 = f32[64,16,1024]{2,1,0} dynamic-update-slice(f32[64,16,1024]{2,1,0} %param_0.316, f32[1,16,1024]{2,1,0} %bitcast.598, s32[] %select.1839, s32[] %constant_10920, s32[] %constant_10920), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.189 (param_0.317: f32[64,16,1024], param_1.2224: f32[16,1024], param_2.1927: s32[]) -> f32[64,16,1024] {
  %param_0.317 = f32[64,16,1024]{2,1,0} parameter(0)
  %constant_10922 = f32[] constant(1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %broadcast.1505 = f32[16,1024]{1,0} broadcast(f32[] %constant_10922), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %param_1.2224 = f32[16,1024]{1,0} parameter(1)
  %subtract.234 = f32[16,1024]{1,0} subtract(f32[16,1024]{1,0} %broadcast.1505, f32[16,1024]{1,0} %param_1.2224), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %bitcast.599 = f32[1,16,1024]{2,1,0} bitcast(f32[16,1024]{1,0} %subtract.234), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_2.1927 = s32[] parameter(2)
  %constant_10921 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.1846 = pred[] compare(s32[] %param_2.1927, s32[] %constant_10921), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_13976 = s32[] constant(64), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.2898 = s32[] add(s32[] %param_2.1927, s32[] %constant_13976), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %select.1837 = s32[] select(pred[] %compare.1846, s32[] %add.2898, s32[] %param_2.1927), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.558 = f32[64,16,1024]{2,1,0} dynamic-update-slice(f32[64,16,1024]{2,1,0} %param_0.317, f32[1,16,1024]{2,1,0} %bitcast.599, s32[] %select.1837, s32[] %constant_10921, s32[] %constant_10921), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.190 (param_0.318: f32[64,16,1024], param_1.2223: f32[16,1024], param_2.1925: s32[]) -> f32[64,16,1024] {
  %param_0.318 = f32[64,16,1024]{2,1,0} parameter(0)
  %param_1.2223 = f32[16,1024]{1,0} parameter(1)
  %bitcast.600 = f32[1,16,1024]{2,1,0} bitcast(f32[16,1024]{1,0} %param_1.2223), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_2.1925 = s32[] parameter(2)
  %constant_10923 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.1844 = pred[] compare(s32[] %param_2.1925, s32[] %constant_10923), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_13970 = s32[] constant(64), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.2895 = s32[] add(s32[] %param_2.1925, s32[] %constant_13970), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %select.1835 = s32[] select(pred[] %compare.1844, s32[] %add.2895, s32[] %param_2.1925), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.559 = f32[64,16,1024]{2,1,0} dynamic-update-slice(f32[64,16,1024]{2,1,0} %param_0.318, f32[1,16,1024]{2,1,0} %bitcast.600, s32[] %select.1835, s32[] %constant_10923, s32[] %constant_10923), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.191 (param_0.319: f32[64,16,1024], param_1.2222: f32[16,1024], param_2.1923: s32[]) -> f32[64,16,1024] {
  %param_0.319 = f32[64,16,1024]{2,1,0} parameter(0)
  %constant_10925 = f32[] constant(1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %broadcast.1506 = f32[16,1024]{1,0} broadcast(f32[] %constant_10925), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %param_1.2222 = f32[16,1024]{1,0} parameter(1)
  %subtract.235 = f32[16,1024]{1,0} subtract(f32[16,1024]{1,0} %broadcast.1506, f32[16,1024]{1,0} %param_1.2222), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %bitcast.601 = f32[1,16,1024]{2,1,0} bitcast(f32[16,1024]{1,0} %subtract.235), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_2.1923 = s32[] parameter(2)
  %constant_10924 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.1842 = pred[] compare(s32[] %param_2.1923, s32[] %constant_10924), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_13964 = s32[] constant(64), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.2893 = s32[] add(s32[] %param_2.1923, s32[] %constant_13964), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %select.1833 = s32[] select(pred[] %compare.1842, s32[] %add.2893, s32[] %param_2.1923), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.560 = f32[64,16,1024]{2,1,0} dynamic-update-slice(f32[64,16,1024]{2,1,0} %param_0.319, f32[1,16,1024]{2,1,0} %bitcast.601, s32[] %select.1833, s32[] %constant_10924, s32[] %constant_10924), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.192 (param_0.320: f32[64,16,2048], param_1.2221: f32[16,2048], param_2.1921: s32[]) -> f32[64,16,2048] {
  %param_0.320 = f32[64,16,2048]{2,1,0} parameter(0)
  %param_1.2221 = f32[16,2048]{1,0} parameter(1)
  %bitcast.602 = f32[1,16,2048]{2,1,0} bitcast(f32[16,2048]{1,0} %param_1.2221), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 16, 2048) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_2.1921 = s32[] parameter(2)
  %constant_10926 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.1840 = pred[] compare(s32[] %param_2.1921, s32[] %constant_10926), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_13959 = s32[] constant(64), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.2891 = s32[] add(s32[] %param_2.1921, s32[] %constant_13959), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %select.1831 = s32[] select(pred[] %compare.1840, s32[] %add.2891, s32[] %param_2.1921), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.561 = f32[64,16,2048]{2,1,0} dynamic-update-slice(f32[64,16,2048]{2,1,0} %param_0.320, f32[1,16,2048]{2,1,0} %bitcast.602, s32[] %select.1831, s32[] %constant_10926, s32[] %constant_10926), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.193 (param_0.321: f32[64,16,1024], param_1.2220: f32[16,2048], param_2.1919: s32[]) -> f32[64,16,1024] {
  %param_0.321 = f32[64,16,1024]{2,1,0} parameter(0)
  %param_1.2220 = f32[16,2048]{1,0} parameter(1)
  %slice.929 = f32[16,1024]{1,0} slice(f32[16,2048]{1,0} %param_1.2220), slice={[0:16], [0:1024]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(16, 1024)\n                                                     start_indices=(0, 0)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=54}
  %bitcast.603 = f32[1,16,1024]{2,1,0} bitcast(f32[16,1024]{1,0} %slice.929), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_2.1919 = s32[] parameter(2)
  %constant_10927 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.1838 = pred[] compare(s32[] %param_2.1919, s32[] %constant_10927), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_13953 = s32[] constant(64), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.2888 = s32[] add(s32[] %param_2.1919, s32[] %constant_13953), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %select.1829 = s32[] select(pred[] %compare.1838, s32[] %add.2888, s32[] %param_2.1919), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.562 = f32[64,16,1024]{2,1,0} dynamic-update-slice(f32[64,16,1024]{2,1,0} %param_0.321, f32[1,16,1024]{2,1,0} %bitcast.603, s32[] %select.1829, s32[] %constant_10927, s32[] %constant_10927), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.194 (param_0.322: f32[64,16,1024], param_1.2219: f32[16,1024], param_2.1917: s32[]) -> f32[64,16,1024] {
  %param_0.322 = f32[64,16,1024]{2,1,0} parameter(0)
  %param_1.2219 = f32[16,1024]{1,0} parameter(1)
  %bitcast.604 = f32[1,16,1024]{2,1,0} bitcast(f32[16,1024]{1,0} %param_1.2219), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_2.1917 = s32[] parameter(2)
  %constant_10928 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.1836 = pred[] compare(s32[] %param_2.1917, s32[] %constant_10928), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_13946 = s32[] constant(64), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.2886 = s32[] add(s32[] %param_2.1917, s32[] %constant_13946), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %select.1827 = s32[] select(pred[] %compare.1836, s32[] %add.2886, s32[] %param_2.1917), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.563 = f32[64,16,1024]{2,1,0} dynamic-update-slice(f32[64,16,1024]{2,1,0} %param_0.322, f32[1,16,1024]{2,1,0} %bitcast.604, s32[] %select.1827, s32[] %constant_10928, s32[] %constant_10928), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.195 (param_0.323: f32[64,16,1024], param_1.2218: f32[16,1024], param_2.1915: f32[16,1024], param_3.1696: s32[]) -> f32[64,16,1024] {
  %param_0.323 = f32[64,16,1024]{2,1,0} parameter(0)
  %param_1.2218 = f32[16,1024]{1,0} parameter(1)
  %param_2.1915 = f32[16,1024]{1,0} parameter(2)
  %multiply.1386 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %param_1.2218, f32[16,1024]{1,0} %param_2.1915), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  %bitcast.605 = f32[1,16,1024]{2,1,0} bitcast(f32[16,1024]{1,0} %multiply.1386), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_3.1696 = s32[] parameter(3)
  %constant_10929 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.1834 = pred[] compare(s32[] %param_3.1696, s32[] %constant_10929), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_13940 = s32[] constant(64), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.2884 = s32[] add(s32[] %param_3.1696, s32[] %constant_13940), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %select.1825 = s32[] select(pred[] %compare.1834, s32[] %add.2884, s32[] %param_3.1696), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.564 = f32[64,16,1024]{2,1,0} dynamic-update-slice(f32[64,16,1024]{2,1,0} %param_0.323, f32[1,16,1024]{2,1,0} %bitcast.605, s32[] %select.1825, s32[] %constant_10929, s32[] %constant_10929), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.201 (param_0.332: f32[1,4096]) -> f32[16,4096] {
  %param_0.332 = f32[1,4096]{1,0} parameter(0)
  %bitcast.606 = f32[4096]{0} bitcast(f32[1,4096]{1,0} %param_0.332), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  ROOT %broadcast.1278 = f32[16,4096]{1,0} broadcast(f32[4096]{0} %bitcast.606), dimensions={1}, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
}

%fused_computation.202 (param_0.334: f32[16,2048], param_1.530: f32[64,16,1024], param_2.1914: s32[]) -> f32[16,2048] {
  %param_1.530 = f32[64,16,1024]{2,1,0} parameter(1)
  %param_2.1914 = s32[] parameter(2)
  %constant_10941 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.1832 = pred[] compare(s32[] %param_2.1914, s32[] %constant_10941), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_13934 = s32[] constant(64), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.2882 = s32[] add(s32[] %param_2.1914, s32[] %constant_13934), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %select.1823 = s32[] select(pred[] %compare.1832, s32[] %add.2882, s32[] %param_2.1914), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %dynamic-slice.406 = f32[1,16,1024]{2,1,0} dynamic-slice(f32[64,16,1024]{2,1,0} %param_1.530, s32[] %select.1823, s32[] %constant_10941, s32[] %constant_10941), dynamic_slice_sizes={1,16,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %bitcast.607 = f32[16,1024]{1,0} bitcast(f32[1,16,1024]{2,1,0} %dynamic-slice.406), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_0.334 = f32[16,2048]{1,0} parameter(0)
  %slice.878 = f32[16,1024]{1,0} slice(f32[16,2048]{1,0} %param_0.334), slice={[0:16], [1024:2048]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(16, 2048)\n                                                     start_indices=(0, 1024)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=54}
  ROOT %concatenate.194 = f32[16,2048]{1,0} concatenate(f32[16,1024]{1,0} %bitcast.607, f32[16,1024]{1,0} %slice.878), dimensions={1}, metadata={op_type="concatenate" op_name="pmap(_multi_device_update_fn)/scan/while/body/concatenate[ dimension=1 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
}

%fused_computation.666 (param_0.1259: f32[16,1024], param_1.1594: f32[16,1024], param_2.1046: f32[16,1024]) -> f32[16,2048] {
  %param_0.1259 = f32[16,1024]{1,0} parameter(0)
  %param_1.1594 = f32[16,1024]{1,0} parameter(1)
  %param_2.1046 = f32[16,1024]{1,0} parameter(2)
  %multiply.1387 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %param_1.1594, f32[16,1024]{1,0} %param_2.1046), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  ROOT %concatenate.209 = f32[16,2048]{1,0} concatenate(f32[16,1024]{1,0} %param_0.1259, f32[16,1024]{1,0} %multiply.1387), dimensions={1}, metadata={op_type="concatenate" op_name="pmap(_multi_device_update_fn)/scan/while/body/concatenate[ dimension=1 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=65}
}

%fused_computation.744 (param_0.2188: f32[16,2048], param_1.2648: f32[16,4096]) -> (f32[16,1024], f32[16,1024], f32[16,1024], f32[16,1024], f32[16,1024], /*index=5*/f32[16,1024]) {
  %param_0.2188 = f32[16,2048]{1,0} parameter(0)
  %slice.930.clone.1 = f32[16,1024]{1,0} slice(f32[16,2048]{1,0} %param_0.2188), slice={[0:16], [0:1024]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(16, 1024)\n                                                     start_indices=(0, 0)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=54}
  %constant_10931_clone_1 = f32[] constant(1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %broadcast.1508.clone.1 = f32[16,1024]{1,0} broadcast(f32[] %constant_10931_clone_1), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %param_1.2648 = f32[16,4096]{1,0} parameter(1)
  %slice.877.clone.1 = f32[16,1024]{1,0} slice(f32[16,4096]{1,0} %param_1.2648), slice={[0:16], [2048:3072]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(16, 3072)\n                                                     start_indices=(0, 2048)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  %negate.141.clone.1 = f32[16,1024]{1,0} negate(f32[16,1024]{1,0} %slice.877.clone.1), metadata={op_type="neg" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/neg" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %exponential.122.clone.1 = f32[16,1024]{1,0} exponential(f32[16,1024]{1,0} %negate.141.clone.1), metadata={op_type="exp" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/exp" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %add.1882.clone.1 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %broadcast.1508.clone.1, f32[16,1024]{1,0} %exponential.122.clone.1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %divide.126.clone.1 = f32[16,1024]{1,0} divide(f32[16,1024]{1,0} %broadcast.1508.clone.1, f32[16,1024]{1,0} %add.1882.clone.1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %multiply.938.clone.1 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %slice.930.clone.1, f32[16,1024]{1,0} %divide.126.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %slice.876.clone.1 = f32[16,1024]{1,0} slice(f32[16,4096]{1,0} %param_1.2648), slice={[0:16], [0:1024]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(16, 1024)\n                                                     start_indices=(0, 0)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  %negate.140.clone.1 = f32[16,1024]{1,0} negate(f32[16,1024]{1,0} %slice.876.clone.1), metadata={op_type="neg" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/neg" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %exponential.121.clone.1 = f32[16,1024]{1,0} exponential(f32[16,1024]{1,0} %negate.140.clone.1), metadata={op_type="exp" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/exp" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %add.1881.clone.1 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %broadcast.1508.clone.1, f32[16,1024]{1,0} %exponential.121.clone.1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %divide.125.clone.1 = f32[16,1024]{1,0} divide(f32[16,1024]{1,0} %broadcast.1508.clone.1, f32[16,1024]{1,0} %add.1881.clone.1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %slice.875.clone.1 = f32[16,1024]{1,0} slice(f32[16,4096]{1,0} %param_1.2648), slice={[0:16], [1024:2048]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(16, 2048)\n                                                     start_indices=(0, 1024)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  %tanh.76.clone.1 = f32[16,1024]{1,0} tanh(f32[16,1024]{1,0} %slice.875.clone.1), metadata={op_type="tanh" op_name="pmap(_multi_device_update_fn)/scan/while/body/tanh" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %multiply.937.clone.1 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %divide.125.clone.1, f32[16,1024]{1,0} %tanh.76.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %add.1880.clone.1 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %multiply.938.clone.1, f32[16,1024]{1,0} %multiply.937.clone.1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %tanh.85 = f32[16,1024]{1,0} tanh(f32[16,1024]{1,0} %add.1880.clone.1), metadata={op_type="tanh" op_name="pmap(_multi_device_update_fn)/scan/while/body/tanh" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  %slice.874.clone.1 = f32[16,1024]{1,0} slice(f32[16,4096]{1,0} %param_1.2648), slice={[0:16], [3072:4096]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(16, 4096)\n                                                     start_indices=(0, 3072)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  %negate.139.clone.1 = f32[16,1024]{1,0} negate(f32[16,1024]{1,0} %slice.874.clone.1), metadata={op_type="neg" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/neg" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %exponential.120.clone.1 = f32[16,1024]{1,0} exponential(f32[16,1024]{1,0} %negate.139.clone.1), metadata={op_type="exp" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/exp" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %add.1879.clone.1 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %broadcast.1508.clone.1, f32[16,1024]{1,0} %exponential.120.clone.1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %divide.124.clone.1 = f32[16,1024]{1,0} divide(f32[16,1024]{1,0} %broadcast.1508.clone.1, f32[16,1024]{1,0} %add.1879.clone.1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  ROOT %tuple.499 = (f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, /*index=5*/f32[16,1024]{1,0}) tuple(f32[16,1024]{1,0} %tanh.85, f32[16,1024]{1,0} %add.1880.clone.1, f32[16,1024]{1,0} %divide.126.clone.1, f32[16,1024]{1,0} %tanh.76.clone.1, f32[16,1024]{1,0} %divide.125.clone.1, /*index=5*/f32[16,1024]{1,0} %divide.124.clone.1)
}

%body_computation__40.3389.clone.clone.clone.clone (parameter.180: (f32[64,16,1024], f32[2048,4096], f32[1,4096], s32[], f32[16,2048], /*index=5*/f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[64,16,2048], f32[64,16,1024], /*index=10*/f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], /*index=15*/f32[64,16,1024], f32[64,16,1024], f32[64,16,1024])) -> (f32[64,16,1024], f32[2048,4096], f32[1,4096], s32[], f32[16,2048], /*index=5*/f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[64,16,2048], f32[64,16,1024], /*index=10*/f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], /*index=15*/f32[64,16,1024], f32[64,16,1024], f32[64,16,1024]) {
  %parameter.180 = (f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) parameter(0)
  %get-tuple-element.5727 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %parameter.180), index=0
  %get-tuple-element.5728 = f32[2048,4096]{1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %parameter.180), index=1
  %get-tuple-element.5729 = f32[1,4096]{1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %parameter.180), index=2
  %get-tuple-element.5743 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %parameter.180), index=16
  %get-tuple-element.5731 = f32[16,2048]{1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %parameter.180), index=4
  %get-tuple-element.5730 = s32[] get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %parameter.180), index=3
  %fusion.202 = f32[16,2048]{1,0} fusion(f32[16,2048]{1,0} %get-tuple-element.5731, f32[64,16,1024]{2,1,0} %get-tuple-element.5727, s32[] %get-tuple-element.5730), kind=kLoop, calls=%fused_computation.202, metadata={op_type="concatenate" op_name="pmap(_multi_device_update_fn)/scan/while/body/concatenate[ dimension=1 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %fusion.201 = f32[16,4096]{1,0} fusion(f32[1,4096]{1,0} %get-tuple-element.5729), kind=kLoop, calls=%fused_computation.201, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %custom-call.128 = f32[16,4096]{1,0} custom-call(f32[16,2048]{1,0} %fusion.202, f32[2048,4096]{1,0} %get-tuple-element.5728, f32[16,4096]{1,0} %fusion.201), custom_call_target="__cublas$gemm", metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}, backend_config="{\"alpha_real\":1,\"alpha_imag\":0,\"beta\":1,\"dot_dimension_numbers\":{\"lhs_contracting_dimensions\":[\"1\"],\"rhs_contracting_dimensions\":[\"0\"],\"lhs_batch_dimensions\":[],\"rhs_batch_dimensions\":[]},\"batch_size\":\"1\",\"selected_algorithm\":\"0\"}"
  %fusion.744 = (f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, /*index=5*/f32[16,1024]{1,0}) fusion(f32[16,2048]{1,0} %get-tuple-element.5731, f32[16,4096]{1,0} %custom-call.128), kind=kLoop, calls=%fused_computation.744, metadata={op_type="tanh" op_name="pmap(_multi_device_update_fn)/scan/while/body/tanh" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  %get-tuple-element.5083 = f32[16,1024]{1,0} get-tuple-element((f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, /*index=5*/f32[16,1024]{1,0}) %fusion.744), index=5
  %fusion.184 = f32[64,16,1024]{2,1,0} fusion(f32[64,16,1024]{2,1,0} %get-tuple-element.5743, f32[16,1024]{1,0} %get-tuple-element.5083, s32[] %get-tuple-element.5730), kind=kLoop, calls=%fused_computation.184, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.5742 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %parameter.180), index=15
  %get-tuple-element.5078 = f32[16,1024]{1,0} get-tuple-element((f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, /*index=5*/f32[16,1024]{1,0}) %fusion.744), index=0
  %fusion.185 = f32[64,16,1024]{2,1,0} fusion(f32[64,16,1024]{2,1,0} %get-tuple-element.5742, f32[16,1024]{1,0} %get-tuple-element.5078, s32[] %get-tuple-element.5730), kind=kLoop, calls=%fused_computation.185, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.5741 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %parameter.180), index=14
  %fusion.186 = f32[64,16,1024]{2,1,0} fusion(f32[64,16,1024]{2,1,0} %get-tuple-element.5741, f32[16,1024]{1,0} %get-tuple-element.5078, s32[] %get-tuple-element.5730), kind=kLoop, calls=%fused_computation.186, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.5740 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %parameter.180), index=13
  %get-tuple-element.5081 = f32[16,1024]{1,0} get-tuple-element((f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, /*index=5*/f32[16,1024]{1,0}) %fusion.744), index=3
  %fusion.187 = f32[64,16,1024]{2,1,0} fusion(f32[64,16,1024]{2,1,0} %get-tuple-element.5740, f32[16,1024]{1,0} %get-tuple-element.5081, s32[] %get-tuple-element.5730), kind=kLoop, calls=%fused_computation.187, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.5739 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %parameter.180), index=12
  %fusion.188 = f32[64,16,1024]{2,1,0} fusion(f32[64,16,1024]{2,1,0} %get-tuple-element.5739, f32[16,1024]{1,0} %get-tuple-element.5081, s32[] %get-tuple-element.5730), kind=kLoop, calls=%fused_computation.188, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.5738 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %parameter.180), index=11
  %get-tuple-element.5082 = f32[16,1024]{1,0} get-tuple-element((f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, /*index=5*/f32[16,1024]{1,0}) %fusion.744), index=4
  %fusion.189 = f32[64,16,1024]{2,1,0} fusion(f32[64,16,1024]{2,1,0} %get-tuple-element.5738, f32[16,1024]{1,0} %get-tuple-element.5082, s32[] %get-tuple-element.5730), kind=kLoop, calls=%fused_computation.189, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.5737 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %parameter.180), index=10
  %fusion.190 = f32[64,16,1024]{2,1,0} fusion(f32[64,16,1024]{2,1,0} %get-tuple-element.5737, f32[16,1024]{1,0} %get-tuple-element.5082, s32[] %get-tuple-element.5730), kind=kLoop, calls=%fused_computation.190, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.5736 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %parameter.180), index=9
  %get-tuple-element.5080 = f32[16,1024]{1,0} get-tuple-element((f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, /*index=5*/f32[16,1024]{1,0}) %fusion.744), index=2
  %fusion.191 = f32[64,16,1024]{2,1,0} fusion(f32[64,16,1024]{2,1,0} %get-tuple-element.5736, f32[16,1024]{1,0} %get-tuple-element.5080, s32[] %get-tuple-element.5730), kind=kLoop, calls=%fused_computation.191, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.5735 = f32[64,16,2048]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %parameter.180), index=8
  %fusion.192 = f32[64,16,2048]{2,1,0} fusion(f32[64,16,2048]{2,1,0} %get-tuple-element.5735, f32[16,2048]{1,0} %fusion.202, s32[] %get-tuple-element.5730), kind=kLoop, calls=%fused_computation.192, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.5734 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %parameter.180), index=7
  %fusion.193 = f32[64,16,1024]{2,1,0} fusion(f32[64,16,1024]{2,1,0} %get-tuple-element.5734, f32[16,2048]{1,0} %get-tuple-element.5731, s32[] %get-tuple-element.5730), kind=kLoop, calls=%fused_computation.193, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.5733 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %parameter.180), index=6
  %fusion.194 = f32[64,16,1024]{2,1,0} fusion(f32[64,16,1024]{2,1,0} %get-tuple-element.5733, f32[16,1024]{1,0} %get-tuple-element.5080, s32[] %get-tuple-element.5730), kind=kLoop, calls=%fused_computation.194, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.5732 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %parameter.180), index=5
  %fusion.195 = f32[64,16,1024]{2,1,0} fusion(f32[64,16,1024]{2,1,0} %get-tuple-element.5732, f32[16,1024]{1,0} %get-tuple-element.5078, f32[16,1024]{1,0} %get-tuple-element.5083, s32[] %get-tuple-element.5730), kind=kLoop, calls=%fused_computation.195, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.5744 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %parameter.180), index=17
  %fusion.183 = f32[64,16,1024]{2,1,0} fusion(f32[64,16,1024]{2,1,0} %get-tuple-element.5744, f32[16,1024]{1,0} %get-tuple-element.5083, s32[] %get-tuple-element.5730), kind=kLoop, calls=%fused_computation.183, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_10045 = s32[] constant(1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.1678 = s32[] add(s32[] %get-tuple-element.5730, s32[] %constant_10045), control-predecessors={%fusion.183, %fusion.202, %fusion.195, %fusion.194, %fusion.193, %fusion.192, %fusion.191, %fusion.190, %fusion.189, %fusion.188, %fusion.187, %fusion.186, %fusion.185, %fusion.184}, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.5079 = f32[16,1024]{1,0} get-tuple-element((f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, /*index=5*/f32[16,1024]{1,0}) %fusion.744), index=1
  %fusion.666 = f32[16,2048]{1,0} fusion(f32[16,1024]{1,0} %get-tuple-element.5079, f32[16,1024]{1,0} %get-tuple-element.5078, f32[16,1024]{1,0} %get-tuple-element.5083), kind=kLoop, calls=%fused_computation.666, control-predecessors={%fusion.202, %fusion.744, %fusion.193}, metadata={op_type="concatenate" op_name="pmap(_multi_device_update_fn)/scan/while/body/concatenate[ dimension=1 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=65}
  ROOT %tuple.787 = (f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) tuple(f32[64,16,1024]{2,1,0} %get-tuple-element.5727, f32[2048,4096]{1,0} %get-tuple-element.5728, f32[1,4096]{1,0} %get-tuple-element.5729, s32[] %add.1678, f32[16,2048]{1,0} %fusion.666, /*index=5*/f32[64,16,1024]{2,1,0} %fusion.195, f32[64,16,1024]{2,1,0} %fusion.194, f32[64,16,1024]{2,1,0} %fusion.193, f32[64,16,2048]{2,1,0} %fusion.192, f32[64,16,1024]{2,1,0} %fusion.191, /*index=10*/f32[64,16,1024]{2,1,0} %fusion.190, f32[64,16,1024]{2,1,0} %fusion.189, f32[64,16,1024]{2,1,0} %fusion.188, f32[64,16,1024]{2,1,0} %fusion.187, f32[64,16,1024]{2,1,0} %fusion.186, /*index=15*/f32[64,16,1024]{2,1,0} %fusion.185, f32[64,16,1024]{2,1,0} %fusion.184, f32[64,16,1024]{2,1,0} %fusion.183)
}

%cond_computation__40.3810.clone.clone.clone (parameter.181: (f32[64,16,1024], f32[2048,4096], f32[1,4096], s32[], f32[16,2048], /*index=5*/f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[64,16,2048], f32[64,16,1024], /*index=10*/f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], /*index=15*/f32[64,16,1024], f32[64,16,1024], f32[64,16,1024])) -> pred[] {
  %parameter.181 = (f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) parameter(0)
  %get-tuple-element.4492 = s32[] get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %parameter.181), index=3
  %constant_10051 = s32[] constant(64), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/cond/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %compare.1308 = pred[] compare(s32[] %get-tuple-element.4492, s32[] %constant_10051), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/cond/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.204 (param_0.337: f32[64,16,1024], param_1.2243: f32[16,1024], param_2.1966: s32[]) -> f32[64,16,1024] {
  %param_0.337 = f32[64,16,1024]{2,1,0} parameter(0)
  %constant_10946 = f32[] constant(1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %broadcast.1510 = f32[16,1024]{1,0} broadcast(f32[] %constant_10946), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %param_1.2243 = f32[16,1024]{1,0} parameter(1)
  %subtract.236 = f32[16,1024]{1,0} subtract(f32[16,1024]{1,0} %broadcast.1510, f32[16,1024]{1,0} %param_1.2243), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %bitcast.608 = f32[1,16,1024]{2,1,0} bitcast(f32[16,1024]{1,0} %subtract.236), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_2.1966 = s32[] parameter(2)
  %constant_10945 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.1887 = pred[] compare(s32[] %param_2.1966, s32[] %constant_10945), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_14096 = s32[] constant(64), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.2944 = s32[] add(s32[] %param_2.1966, s32[] %constant_14096), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %select.1877 = s32[] select(pred[] %compare.1887, s32[] %add.2944, s32[] %param_2.1966), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.565 = f32[64,16,1024]{2,1,0} dynamic-update-slice(f32[64,16,1024]{2,1,0} %param_0.337, f32[1,16,1024]{2,1,0} %bitcast.608, s32[] %select.1877, s32[] %constant_10945, s32[] %constant_10945), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.205 (param_0.338: f32[64,16,1024], param_1.2242: f32[16,1024], param_2.1964: s32[]) -> f32[64,16,1024] {
  %param_0.338 = f32[64,16,1024]{2,1,0} parameter(0)
  %param_1.2242 = f32[16,1024]{1,0} parameter(1)
  %bitcast.609 = f32[1,16,1024]{2,1,0} bitcast(f32[16,1024]{1,0} %param_1.2242), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_2.1964 = s32[] parameter(2)
  %constant_10947 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.1884 = pred[] compare(s32[] %param_2.1964, s32[] %constant_10947), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_14090 = s32[] constant(64), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.2941 = s32[] add(s32[] %param_2.1964, s32[] %constant_14090), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %select.1875 = s32[] select(pred[] %compare.1884, s32[] %add.2941, s32[] %param_2.1964), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.566 = f32[64,16,1024]{2,1,0} dynamic-update-slice(f32[64,16,1024]{2,1,0} %param_0.338, f32[1,16,1024]{2,1,0} %bitcast.609, s32[] %select.1875, s32[] %constant_10947, s32[] %constant_10947), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.206 (param_0.339: f32[64,16,1024], param_1.2241: f32[16,1024], param_2.1962: s32[]) -> f32[64,16,1024] {
  %param_0.339 = f32[64,16,1024]{2,1,0} parameter(0)
  %constant_10949 = f32[] constant(1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %broadcast.1511 = f32[16,1024]{1,0} broadcast(f32[] %constant_10949), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %param_1.2241 = f32[16,1024]{1,0} parameter(1)
  %subtract.237 = f32[16,1024]{1,0} subtract(f32[16,1024]{1,0} %broadcast.1511, f32[16,1024]{1,0} %param_1.2241), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  %bitcast.610 = f32[1,16,1024]{2,1,0} bitcast(f32[16,1024]{1,0} %subtract.237), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_2.1962 = s32[] parameter(2)
  %constant_10948 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.1882 = pred[] compare(s32[] %param_2.1962, s32[] %constant_10948), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_14085 = s32[] constant(64), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.2939 = s32[] add(s32[] %param_2.1962, s32[] %constant_14085), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %select.1873 = s32[] select(pred[] %compare.1882, s32[] %add.2939, s32[] %param_2.1962), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.567 = f32[64,16,1024]{2,1,0} dynamic-update-slice(f32[64,16,1024]{2,1,0} %param_0.339, f32[1,16,1024]{2,1,0} %bitcast.610, s32[] %select.1873, s32[] %constant_10948, s32[] %constant_10948), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.207 (param_0.340: f32[64,16,1024], param_1.2240: f32[16,1024], param_2.1960: s32[]) -> f32[64,16,1024] {
  %param_0.340 = f32[64,16,1024]{2,1,0} parameter(0)
  %param_1.2240 = f32[16,1024]{1,0} parameter(1)
  %bitcast.611 = f32[1,16,1024]{2,1,0} bitcast(f32[16,1024]{1,0} %param_1.2240), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_2.1960 = s32[] parameter(2)
  %constant_10950 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.1880 = pred[] compare(s32[] %param_2.1960, s32[] %constant_10950), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_14079 = s32[] constant(64), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.2937 = s32[] add(s32[] %param_2.1960, s32[] %constant_14079), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %select.1871 = s32[] select(pred[] %compare.1880, s32[] %add.2937, s32[] %param_2.1960), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.568 = f32[64,16,1024]{2,1,0} dynamic-update-slice(f32[64,16,1024]{2,1,0} %param_0.340, f32[1,16,1024]{2,1,0} %bitcast.611, s32[] %select.1871, s32[] %constant_10950, s32[] %constant_10950), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.208 (param_0.341: f32[64,16,1024], param_1.2239: f32[16,1024], param_2.1958: s32[]) -> f32[64,16,1024] {
  %param_0.341 = f32[64,16,1024]{2,1,0} parameter(0)
  %constant_10952 = f32[] constant(1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %broadcast.1512 = f32[16,1024]{1,0} broadcast(f32[] %constant_10952), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %param_1.2239 = f32[16,1024]{1,0} parameter(1)
  %subtract.238 = f32[16,1024]{1,0} subtract(f32[16,1024]{1,0} %broadcast.1512, f32[16,1024]{1,0} %param_1.2239), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %bitcast.612 = f32[1,16,1024]{2,1,0} bitcast(f32[16,1024]{1,0} %subtract.238), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_2.1958 = s32[] parameter(2)
  %constant_10951 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.1878 = pred[] compare(s32[] %param_2.1958, s32[] %constant_10951), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_14072 = s32[] constant(64), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.2934 = s32[] add(s32[] %param_2.1958, s32[] %constant_14072), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %select.1869 = s32[] select(pred[] %compare.1878, s32[] %add.2934, s32[] %param_2.1958), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.569 = f32[64,16,1024]{2,1,0} dynamic-update-slice(f32[64,16,1024]{2,1,0} %param_0.341, f32[1,16,1024]{2,1,0} %bitcast.612, s32[] %select.1869, s32[] %constant_10951, s32[] %constant_10951), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.209 (param_0.342: f32[64,16,1024], param_1.2238: f32[16,1024], param_2.1956: s32[]) -> f32[64,16,1024] {
  %param_0.342 = f32[64,16,1024]{2,1,0} parameter(0)
  %param_1.2238 = f32[16,1024]{1,0} parameter(1)
  %bitcast.613 = f32[1,16,1024]{2,1,0} bitcast(f32[16,1024]{1,0} %param_1.2238), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_2.1956 = s32[] parameter(2)
  %constant_10953 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.1876 = pred[] compare(s32[] %param_2.1956, s32[] %constant_10953), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_14066 = s32[] constant(64), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.2932 = s32[] add(s32[] %param_2.1956, s32[] %constant_14066), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %select.1867 = s32[] select(pred[] %compare.1876, s32[] %add.2932, s32[] %param_2.1956), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.570 = f32[64,16,1024]{2,1,0} dynamic-update-slice(f32[64,16,1024]{2,1,0} %param_0.342, f32[1,16,1024]{2,1,0} %bitcast.613, s32[] %select.1867, s32[] %constant_10953, s32[] %constant_10953), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.210 (param_0.343: f32[64,16,1024], param_1.2237: f32[16,1024], param_2.1954: s32[]) -> f32[64,16,1024] {
  %param_0.343 = f32[64,16,1024]{2,1,0} parameter(0)
  %constant_10955 = f32[] constant(1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %broadcast.1513 = f32[16,1024]{1,0} broadcast(f32[] %constant_10955), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %param_1.2237 = f32[16,1024]{1,0} parameter(1)
  %subtract.239 = f32[16,1024]{1,0} subtract(f32[16,1024]{1,0} %broadcast.1513, f32[16,1024]{1,0} %param_1.2237), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %bitcast.614 = f32[1,16,1024]{2,1,0} bitcast(f32[16,1024]{1,0} %subtract.239), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_2.1954 = s32[] parameter(2)
  %constant_10954 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.1874 = pred[] compare(s32[] %param_2.1954, s32[] %constant_10954), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_14060 = s32[] constant(64), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.2930 = s32[] add(s32[] %param_2.1954, s32[] %constant_14060), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %select.1865 = s32[] select(pred[] %compare.1874, s32[] %add.2930, s32[] %param_2.1954), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.571 = f32[64,16,1024]{2,1,0} dynamic-update-slice(f32[64,16,1024]{2,1,0} %param_0.343, f32[1,16,1024]{2,1,0} %bitcast.614, s32[] %select.1865, s32[] %constant_10954, s32[] %constant_10954), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.211 (param_0.344: f32[64,16,1024], param_1.2236: f32[16,1024], param_2.1952: s32[]) -> f32[64,16,1024] {
  %param_0.344 = f32[64,16,1024]{2,1,0} parameter(0)
  %param_1.2236 = f32[16,1024]{1,0} parameter(1)
  %bitcast.615 = f32[1,16,1024]{2,1,0} bitcast(f32[16,1024]{1,0} %param_1.2236), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_2.1952 = s32[] parameter(2)
  %constant_10956 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.1872 = pred[] compare(s32[] %param_2.1952, s32[] %constant_10956), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_14053 = s32[] constant(64), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.2928 = s32[] add(s32[] %param_2.1952, s32[] %constant_14053), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %select.1863 = s32[] select(pred[] %compare.1872, s32[] %add.2928, s32[] %param_2.1952), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.572 = f32[64,16,1024]{2,1,0} dynamic-update-slice(f32[64,16,1024]{2,1,0} %param_0.344, f32[1,16,1024]{2,1,0} %bitcast.615, s32[] %select.1863, s32[] %constant_10956, s32[] %constant_10956), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.212 (param_0.345: f32[64,16,1024], param_1.2235: f32[16,1024], param_2.1950: s32[]) -> f32[64,16,1024] {
  %param_0.345 = f32[64,16,1024]{2,1,0} parameter(0)
  %constant_10958 = f32[] constant(1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %broadcast.1514 = f32[16,1024]{1,0} broadcast(f32[] %constant_10958), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %param_1.2235 = f32[16,1024]{1,0} parameter(1)
  %subtract.240 = f32[16,1024]{1,0} subtract(f32[16,1024]{1,0} %broadcast.1514, f32[16,1024]{1,0} %param_1.2235), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %bitcast.616 = f32[1,16,1024]{2,1,0} bitcast(f32[16,1024]{1,0} %subtract.240), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_2.1950 = s32[] parameter(2)
  %constant_10957 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.1870 = pred[] compare(s32[] %param_2.1950, s32[] %constant_10957), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_14047 = s32[] constant(64), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.2925 = s32[] add(s32[] %param_2.1950, s32[] %constant_14047), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %select.1861 = s32[] select(pred[] %compare.1870, s32[] %add.2925, s32[] %param_2.1950), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.573 = f32[64,16,1024]{2,1,0} dynamic-update-slice(f32[64,16,1024]{2,1,0} %param_0.345, f32[1,16,1024]{2,1,0} %bitcast.616, s32[] %select.1861, s32[] %constant_10957, s32[] %constant_10957), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.213 (param_0.346: f32[64,16,2048], param_1.2234: f32[16,2048], param_2.1948: s32[]) -> f32[64,16,2048] {
  %param_0.346 = f32[64,16,2048]{2,1,0} parameter(0)
  %param_1.2234 = f32[16,2048]{1,0} parameter(1)
  %bitcast.617 = f32[1,16,2048]{2,1,0} bitcast(f32[16,2048]{1,0} %param_1.2234), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 16, 2048) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_2.1948 = s32[] parameter(2)
  %constant_10959 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.1868 = pred[] compare(s32[] %param_2.1948, s32[] %constant_10959), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_14042 = s32[] constant(64), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.2923 = s32[] add(s32[] %param_2.1948, s32[] %constant_14042), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %select.1859 = s32[] select(pred[] %compare.1868, s32[] %add.2923, s32[] %param_2.1948), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.574 = f32[64,16,2048]{2,1,0} dynamic-update-slice(f32[64,16,2048]{2,1,0} %param_0.346, f32[1,16,2048]{2,1,0} %bitcast.617, s32[] %select.1859, s32[] %constant_10959, s32[] %constant_10959), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.214 (param_0.347: f32[64,16,1024], param_1.2233: f32[16,2048], param_2.1946: s32[]) -> f32[64,16,1024] {
  %param_0.347 = f32[64,16,1024]{2,1,0} parameter(0)
  %param_1.2233 = f32[16,2048]{1,0} parameter(1)
  %slice.931 = f32[16,1024]{1,0} slice(f32[16,2048]{1,0} %param_1.2233), slice={[0:16], [0:1024]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(16, 1024)\n                                                     start_indices=(0, 0)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=54}
  %bitcast.618 = f32[1,16,1024]{2,1,0} bitcast(f32[16,1024]{1,0} %slice.931), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_2.1946 = s32[] parameter(2)
  %constant_10960 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.1866 = pred[] compare(s32[] %param_2.1946, s32[] %constant_10960), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_14035 = s32[] constant(64), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.2921 = s32[] add(s32[] %param_2.1946, s32[] %constant_14035), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %select.1857 = s32[] select(pred[] %compare.1866, s32[] %add.2921, s32[] %param_2.1946), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.575 = f32[64,16,1024]{2,1,0} dynamic-update-slice(f32[64,16,1024]{2,1,0} %param_0.347, f32[1,16,1024]{2,1,0} %bitcast.618, s32[] %select.1857, s32[] %constant_10960, s32[] %constant_10960), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.215 (param_0.348: f32[64,16,1024], param_1.2232: f32[16,1024], param_2.1944: s32[]) -> f32[64,16,1024] {
  %param_0.348 = f32[64,16,1024]{2,1,0} parameter(0)
  %param_1.2232 = f32[16,1024]{1,0} parameter(1)
  %bitcast.619 = f32[1,16,1024]{2,1,0} bitcast(f32[16,1024]{1,0} %param_1.2232), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_2.1944 = s32[] parameter(2)
  %constant_10961 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.1864 = pred[] compare(s32[] %param_2.1944, s32[] %constant_10961), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_14029 = s32[] constant(64), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.2918 = s32[] add(s32[] %param_2.1944, s32[] %constant_14029), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %select.1855 = s32[] select(pred[] %compare.1864, s32[] %add.2918, s32[] %param_2.1944), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.576 = f32[64,16,1024]{2,1,0} dynamic-update-slice(f32[64,16,1024]{2,1,0} %param_0.348, f32[1,16,1024]{2,1,0} %bitcast.619, s32[] %select.1855, s32[] %constant_10961, s32[] %constant_10961), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.216 (param_0.349: f32[64,16,1024], param_1.2231: f32[16,1024], param_2.1942: f32[16,1024], param_3.1737: s32[]) -> f32[64,16,1024] {
  %param_0.349 = f32[64,16,1024]{2,1,0} parameter(0)
  %param_1.2231 = f32[16,1024]{1,0} parameter(1)
  %param_2.1942 = f32[16,1024]{1,0} parameter(2)
  %multiply.1388 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %param_1.2231, f32[16,1024]{1,0} %param_2.1942), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  %bitcast.620 = f32[1,16,1024]{2,1,0} bitcast(f32[16,1024]{1,0} %multiply.1388), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_3.1737 = s32[] parameter(3)
  %constant_10962 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.1862 = pred[] compare(s32[] %param_3.1737, s32[] %constant_10962), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_14023 = s32[] constant(64), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.2916 = s32[] add(s32[] %param_3.1737, s32[] %constant_14023), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %select.1853 = s32[] select(pred[] %compare.1862, s32[] %add.2916, s32[] %param_3.1737), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.577 = f32[64,16,1024]{2,1,0} dynamic-update-slice(f32[64,16,1024]{2,1,0} %param_0.349, f32[1,16,1024]{2,1,0} %bitcast.620, s32[] %select.1853, s32[] %constant_10962, s32[] %constant_10962), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.222 (param_0.358: f32[1,4096]) -> f32[16,4096] {
  %param_0.358 = f32[1,4096]{1,0} parameter(0)
  %bitcast.621 = f32[4096]{0} bitcast(f32[1,4096]{1,0} %param_0.358), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  ROOT %broadcast.1279 = f32[16,4096]{1,0} broadcast(f32[4096]{0} %bitcast.621), dimensions={1}, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
}

%fused_computation.223 (param_0.360: f32[16,2048], param_1.581: f32[64,16,1024], param_2.1941: s32[]) -> f32[16,2048] {
  %param_1.581 = f32[64,16,1024]{2,1,0} parameter(1)
  %param_2.1941 = s32[] parameter(2)
  %constant_10966 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.1860 = pred[] compare(s32[] %param_2.1941, s32[] %constant_10966), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_14017 = s32[] constant(64), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.2914 = s32[] add(s32[] %param_2.1941, s32[] %constant_14017), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %select.1851 = s32[] select(pred[] %compare.1860, s32[] %add.2914, s32[] %param_2.1941), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %dynamic-slice.407 = f32[1,16,1024]{2,1,0} dynamic-slice(f32[64,16,1024]{2,1,0} %param_1.581, s32[] %select.1851, s32[] %constant_10966, s32[] %constant_10966), dynamic_slice_sizes={1,16,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %bitcast.622 = f32[16,1024]{1,0} bitcast(f32[1,16,1024]{2,1,0} %dynamic-slice.407), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_0.360 = f32[16,2048]{1,0} parameter(0)
  %slice.883 = f32[16,1024]{1,0} slice(f32[16,2048]{1,0} %param_0.360), slice={[0:16], [1024:2048]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(16, 2048)\n                                                     start_indices=(0, 1024)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=54}
  ROOT %concatenate.195 = f32[16,2048]{1,0} concatenate(f32[16,1024]{1,0} %bitcast.622, f32[16,1024]{1,0} %slice.883), dimensions={1}, metadata={op_type="concatenate" op_name="pmap(_multi_device_update_fn)/scan/while/body/concatenate[ dimension=1 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
}

%fused_computation.667 (param_0.1263: f32[16,1024], param_1.1599: f32[16,1024], param_2.1066: f32[16,1024]) -> f32[16,2048] {
  %param_0.1263 = f32[16,1024]{1,0} parameter(0)
  %param_1.1599 = f32[16,1024]{1,0} parameter(1)
  %param_2.1066 = f32[16,1024]{1,0} parameter(2)
  %multiply.1389 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %param_1.1599, f32[16,1024]{1,0} %param_2.1066), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  ROOT %concatenate.210 = f32[16,2048]{1,0} concatenate(f32[16,1024]{1,0} %param_0.1263, f32[16,1024]{1,0} %multiply.1389), dimensions={1}, metadata={op_type="concatenate" op_name="pmap(_multi_device_update_fn)/scan/while/body/concatenate[ dimension=1 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=65}
}

%fused_computation.745 (param_0.2192: f32[16,2048], param_1.2653: f32[16,4096]) -> (f32[16,1024], f32[16,1024], f32[16,1024], f32[16,1024], f32[16,1024], /*index=5*/f32[16,1024]) {
  %param_0.2192 = f32[16,2048]{1,0} parameter(0)
  %slice.932.clone.1 = f32[16,1024]{1,0} slice(f32[16,2048]{1,0} %param_0.2192), slice={[0:16], [0:1024]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(16, 1024)\n                                                     start_indices=(0, 0)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=54}
  %constant_10964_clone_1 = f32[] constant(1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %broadcast.1516.clone.1 = f32[16,1024]{1,0} broadcast(f32[] %constant_10964_clone_1), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %param_1.2653 = f32[16,4096]{1,0} parameter(1)
  %slice.882.clone.1 = f32[16,1024]{1,0} slice(f32[16,4096]{1,0} %param_1.2653), slice={[0:16], [2048:3072]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(16, 3072)\n                                                     start_indices=(0, 2048)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  %negate.144.clone.1 = f32[16,1024]{1,0} negate(f32[16,1024]{1,0} %slice.882.clone.1), metadata={op_type="neg" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/neg" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %exponential.125.clone.1 = f32[16,1024]{1,0} exponential(f32[16,1024]{1,0} %negate.144.clone.1), metadata={op_type="exp" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/exp" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %add.1888.clone.1 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %broadcast.1516.clone.1, f32[16,1024]{1,0} %exponential.125.clone.1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %divide.129.clone.1 = f32[16,1024]{1,0} divide(f32[16,1024]{1,0} %broadcast.1516.clone.1, f32[16,1024]{1,0} %add.1888.clone.1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %multiply.940.clone.1 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %slice.932.clone.1, f32[16,1024]{1,0} %divide.129.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %slice.881.clone.1 = f32[16,1024]{1,0} slice(f32[16,4096]{1,0} %param_1.2653), slice={[0:16], [0:1024]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(16, 1024)\n                                                     start_indices=(0, 0)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  %negate.143.clone.1 = f32[16,1024]{1,0} negate(f32[16,1024]{1,0} %slice.881.clone.1), metadata={op_type="neg" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/neg" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %exponential.124.clone.1 = f32[16,1024]{1,0} exponential(f32[16,1024]{1,0} %negate.143.clone.1), metadata={op_type="exp" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/exp" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %add.1886.clone.1 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %broadcast.1516.clone.1, f32[16,1024]{1,0} %exponential.124.clone.1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %divide.128.clone.1 = f32[16,1024]{1,0} divide(f32[16,1024]{1,0} %broadcast.1516.clone.1, f32[16,1024]{1,0} %add.1886.clone.1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %slice.880.clone.1 = f32[16,1024]{1,0} slice(f32[16,4096]{1,0} %param_1.2653), slice={[0:16], [1024:2048]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(16, 2048)\n                                                     start_indices=(0, 1024)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  %tanh.77.clone.1 = f32[16,1024]{1,0} tanh(f32[16,1024]{1,0} %slice.880.clone.1), metadata={op_type="tanh" op_name="pmap(_multi_device_update_fn)/scan/while/body/tanh" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %multiply.939.clone.1 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %divide.128.clone.1, f32[16,1024]{1,0} %tanh.77.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %add.1885.clone.1 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %multiply.940.clone.1, f32[16,1024]{1,0} %multiply.939.clone.1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %tanh.86 = f32[16,1024]{1,0} tanh(f32[16,1024]{1,0} %add.1885.clone.1), metadata={op_type="tanh" op_name="pmap(_multi_device_update_fn)/scan/while/body/tanh" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  %slice.879.clone.1 = f32[16,1024]{1,0} slice(f32[16,4096]{1,0} %param_1.2653), slice={[0:16], [3072:4096]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(16, 4096)\n                                                     start_indices=(0, 3072)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  %negate.142.clone.1 = f32[16,1024]{1,0} negate(f32[16,1024]{1,0} %slice.879.clone.1), metadata={op_type="neg" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/neg" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %exponential.123.clone.1 = f32[16,1024]{1,0} exponential(f32[16,1024]{1,0} %negate.142.clone.1), metadata={op_type="exp" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/exp" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %add.1884.clone.1 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %broadcast.1516.clone.1, f32[16,1024]{1,0} %exponential.123.clone.1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %divide.127.clone.1 = f32[16,1024]{1,0} divide(f32[16,1024]{1,0} %broadcast.1516.clone.1, f32[16,1024]{1,0} %add.1884.clone.1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  ROOT %tuple.504 = (f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, /*index=5*/f32[16,1024]{1,0}) tuple(f32[16,1024]{1,0} %tanh.86, f32[16,1024]{1,0} %add.1885.clone.1, f32[16,1024]{1,0} %divide.129.clone.1, f32[16,1024]{1,0} %tanh.77.clone.1, f32[16,1024]{1,0} %divide.128.clone.1, /*index=5*/f32[16,1024]{1,0} %divide.127.clone.1)
}

%body_computation__41.4909.clone.clone.clone.clone (parameter.182: (f32[64,16,1024], f32[2048,4096], f32[1,4096], s32[], f32[16,2048], /*index=5*/f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[64,16,2048], f32[64,16,1024], /*index=10*/f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], /*index=15*/f32[64,16,1024], f32[64,16,1024], f32[64,16,1024])) -> (f32[64,16,1024], f32[2048,4096], f32[1,4096], s32[], f32[16,2048], /*index=5*/f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[64,16,2048], f32[64,16,1024], /*index=10*/f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], /*index=15*/f32[64,16,1024], f32[64,16,1024], f32[64,16,1024]) {
  %parameter.182 = (f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) parameter(0)
  %get-tuple-element.5997 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %parameter.182), index=0
  %get-tuple-element.5998 = f32[2048,4096]{1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %parameter.182), index=1
  %get-tuple-element.5999 = f32[1,4096]{1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %parameter.182), index=2
  %get-tuple-element.6035 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %parameter.182), index=16
  %get-tuple-element.6001 = f32[16,2048]{1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %parameter.182), index=4
  %get-tuple-element.6000 = s32[] get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %parameter.182), index=3
  %fusion.223 = f32[16,2048]{1,0} fusion(f32[16,2048]{1,0} %get-tuple-element.6001, f32[64,16,1024]{2,1,0} %get-tuple-element.5997, s32[] %get-tuple-element.6000), kind=kLoop, calls=%fused_computation.223, metadata={op_type="concatenate" op_name="pmap(_multi_device_update_fn)/scan/while/body/concatenate[ dimension=1 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %fusion.222 = f32[16,4096]{1,0} fusion(f32[1,4096]{1,0} %get-tuple-element.5999), kind=kLoop, calls=%fused_computation.222, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %custom-call.130 = f32[16,4096]{1,0} custom-call(f32[16,2048]{1,0} %fusion.223, f32[2048,4096]{1,0} %get-tuple-element.5998, f32[16,4096]{1,0} %fusion.222), custom_call_target="__cublas$gemm", metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}, backend_config="{\"alpha_real\":1,\"alpha_imag\":0,\"beta\":1,\"dot_dimension_numbers\":{\"lhs_contracting_dimensions\":[\"1\"],\"rhs_contracting_dimensions\":[\"0\"],\"lhs_batch_dimensions\":[],\"rhs_batch_dimensions\":[]},\"batch_size\":\"1\",\"selected_algorithm\":\"0\"}"
  %fusion.745 = (f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, /*index=5*/f32[16,1024]{1,0}) fusion(f32[16,2048]{1,0} %get-tuple-element.6001, f32[16,4096]{1,0} %custom-call.130), kind=kLoop, calls=%fused_computation.745, metadata={op_type="tanh" op_name="pmap(_multi_device_update_fn)/scan/while/body/tanh" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  %get-tuple-element.5089 = f32[16,1024]{1,0} get-tuple-element((f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, /*index=5*/f32[16,1024]{1,0}) %fusion.745), index=5
  %fusion.205 = f32[64,16,1024]{2,1,0} fusion(f32[64,16,1024]{2,1,0} %get-tuple-element.6035, f32[16,1024]{1,0} %get-tuple-element.5089, s32[] %get-tuple-element.6000), kind=kLoop, calls=%fused_computation.205, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.6034 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %parameter.182), index=15
  %get-tuple-element.5084 = f32[16,1024]{1,0} get-tuple-element((f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, /*index=5*/f32[16,1024]{1,0}) %fusion.745), index=0
  %fusion.206 = f32[64,16,1024]{2,1,0} fusion(f32[64,16,1024]{2,1,0} %get-tuple-element.6034, f32[16,1024]{1,0} %get-tuple-element.5084, s32[] %get-tuple-element.6000), kind=kLoop, calls=%fused_computation.206, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.6011 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %parameter.182), index=14
  %fusion.207 = f32[64,16,1024]{2,1,0} fusion(f32[64,16,1024]{2,1,0} %get-tuple-element.6011, f32[16,1024]{1,0} %get-tuple-element.5084, s32[] %get-tuple-element.6000), kind=kLoop, calls=%fused_computation.207, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.6010 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %parameter.182), index=13
  %get-tuple-element.5087 = f32[16,1024]{1,0} get-tuple-element((f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, /*index=5*/f32[16,1024]{1,0}) %fusion.745), index=3
  %fusion.208 = f32[64,16,1024]{2,1,0} fusion(f32[64,16,1024]{2,1,0} %get-tuple-element.6010, f32[16,1024]{1,0} %get-tuple-element.5087, s32[] %get-tuple-element.6000), kind=kLoop, calls=%fused_computation.208, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.6009 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %parameter.182), index=12
  %fusion.209 = f32[64,16,1024]{2,1,0} fusion(f32[64,16,1024]{2,1,0} %get-tuple-element.6009, f32[16,1024]{1,0} %get-tuple-element.5087, s32[] %get-tuple-element.6000), kind=kLoop, calls=%fused_computation.209, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.6008 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %parameter.182), index=11
  %get-tuple-element.5088 = f32[16,1024]{1,0} get-tuple-element((f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, /*index=5*/f32[16,1024]{1,0}) %fusion.745), index=4
  %fusion.210 = f32[64,16,1024]{2,1,0} fusion(f32[64,16,1024]{2,1,0} %get-tuple-element.6008, f32[16,1024]{1,0} %get-tuple-element.5088, s32[] %get-tuple-element.6000), kind=kLoop, calls=%fused_computation.210, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.6007 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %parameter.182), index=10
  %fusion.211 = f32[64,16,1024]{2,1,0} fusion(f32[64,16,1024]{2,1,0} %get-tuple-element.6007, f32[16,1024]{1,0} %get-tuple-element.5088, s32[] %get-tuple-element.6000), kind=kLoop, calls=%fused_computation.211, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.6006 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %parameter.182), index=9
  %get-tuple-element.5086 = f32[16,1024]{1,0} get-tuple-element((f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, /*index=5*/f32[16,1024]{1,0}) %fusion.745), index=2
  %fusion.212 = f32[64,16,1024]{2,1,0} fusion(f32[64,16,1024]{2,1,0} %get-tuple-element.6006, f32[16,1024]{1,0} %get-tuple-element.5086, s32[] %get-tuple-element.6000), kind=kLoop, calls=%fused_computation.212, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.6005 = f32[64,16,2048]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %parameter.182), index=8
  %fusion.213 = f32[64,16,2048]{2,1,0} fusion(f32[64,16,2048]{2,1,0} %get-tuple-element.6005, f32[16,2048]{1,0} %fusion.223, s32[] %get-tuple-element.6000), kind=kLoop, calls=%fused_computation.213, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.6004 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %parameter.182), index=7
  %fusion.214 = f32[64,16,1024]{2,1,0} fusion(f32[64,16,1024]{2,1,0} %get-tuple-element.6004, f32[16,2048]{1,0} %get-tuple-element.6001, s32[] %get-tuple-element.6000), kind=kLoop, calls=%fused_computation.214, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.6003 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %parameter.182), index=6
  %fusion.215 = f32[64,16,1024]{2,1,0} fusion(f32[64,16,1024]{2,1,0} %get-tuple-element.6003, f32[16,1024]{1,0} %get-tuple-element.5086, s32[] %get-tuple-element.6000), kind=kLoop, calls=%fused_computation.215, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.6002 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %parameter.182), index=5
  %fusion.216 = f32[64,16,1024]{2,1,0} fusion(f32[64,16,1024]{2,1,0} %get-tuple-element.6002, f32[16,1024]{1,0} %get-tuple-element.5084, f32[16,1024]{1,0} %get-tuple-element.5089, s32[] %get-tuple-element.6000), kind=kLoop, calls=%fused_computation.216, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.6036 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %parameter.182), index=17
  %fusion.204 = f32[64,16,1024]{2,1,0} fusion(f32[64,16,1024]{2,1,0} %get-tuple-element.6036, f32[16,1024]{1,0} %get-tuple-element.5089, s32[] %get-tuple-element.6000), kind=kLoop, calls=%fused_computation.204, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_10194 = s32[] constant(1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.1698 = s32[] add(s32[] %get-tuple-element.6000, s32[] %constant_10194), control-predecessors={%fusion.204, %fusion.223, %fusion.216, %fusion.215, %fusion.214, %fusion.213, %fusion.212, %fusion.211, %fusion.210, %fusion.209, %fusion.208, %fusion.207, %fusion.206, %fusion.205}, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.5085 = f32[16,1024]{1,0} get-tuple-element((f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, /*index=5*/f32[16,1024]{1,0}) %fusion.745), index=1
  %fusion.667 = f32[16,2048]{1,0} fusion(f32[16,1024]{1,0} %get-tuple-element.5085, f32[16,1024]{1,0} %get-tuple-element.5084, f32[16,1024]{1,0} %get-tuple-element.5089), kind=kLoop, calls=%fused_computation.667, control-predecessors={%fusion.223, %fusion.745, %fusion.214}, metadata={op_type="concatenate" op_name="pmap(_multi_device_update_fn)/scan/while/body/concatenate[ dimension=1 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=65}
  ROOT %tuple.802 = (f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) tuple(f32[64,16,1024]{2,1,0} %get-tuple-element.5997, f32[2048,4096]{1,0} %get-tuple-element.5998, f32[1,4096]{1,0} %get-tuple-element.5999, s32[] %add.1698, f32[16,2048]{1,0} %fusion.667, /*index=5*/f32[64,16,1024]{2,1,0} %fusion.216, f32[64,16,1024]{2,1,0} %fusion.215, f32[64,16,1024]{2,1,0} %fusion.214, f32[64,16,2048]{2,1,0} %fusion.213, f32[64,16,1024]{2,1,0} %fusion.212, /*index=10*/f32[64,16,1024]{2,1,0} %fusion.211, f32[64,16,1024]{2,1,0} %fusion.210, f32[64,16,1024]{2,1,0} %fusion.209, f32[64,16,1024]{2,1,0} %fusion.208, f32[64,16,1024]{2,1,0} %fusion.207, /*index=15*/f32[64,16,1024]{2,1,0} %fusion.206, f32[64,16,1024]{2,1,0} %fusion.205, f32[64,16,1024]{2,1,0} %fusion.204)
}

%cond_computation__41.5330.clone.clone.clone (parameter.183: (f32[64,16,1024], f32[2048,4096], f32[1,4096], s32[], f32[16,2048], /*index=5*/f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[64,16,2048], f32[64,16,1024], /*index=10*/f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], /*index=15*/f32[64,16,1024], f32[64,16,1024], f32[64,16,1024])) -> pred[] {
  %parameter.183 = (f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) parameter(0)
  %get-tuple-element.4610 = s32[] get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %parameter.183), index=3
  %constant_10201 = s32[] constant(64), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/cond/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %compare.1325 = pred[] compare(s32[] %get-tuple-element.4610, s32[] %constant_10201), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/cond/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.225 (param_0.363: f32[64,16,1024], param_1.2256: f32[16,1024], param_2.1993: s32[]) -> f32[64,16,1024] {
  %param_0.363 = f32[64,16,1024]{2,1,0} parameter(0)
  %constant_10969 = f32[] constant(1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %broadcast.1518 = f32[16,1024]{1,0} broadcast(f32[] %constant_10969), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %param_1.2256 = f32[16,1024]{1,0} parameter(1)
  %subtract.241 = f32[16,1024]{1,0} subtract(f32[16,1024]{1,0} %broadcast.1518, f32[16,1024]{1,0} %param_1.2256), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %bitcast.623 = f32[1,16,1024]{2,1,0} bitcast(f32[16,1024]{1,0} %subtract.241), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_2.1993 = s32[] parameter(2)
  %constant_10968 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.1917 = pred[] compare(s32[] %param_2.1993, s32[] %constant_10968), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_14179 = s32[] constant(64), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.2974 = s32[] add(s32[] %param_2.1993, s32[] %constant_14179), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %select.1908 = s32[] select(pred[] %compare.1917, s32[] %add.2974, s32[] %param_2.1993), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.578 = f32[64,16,1024]{2,1,0} dynamic-update-slice(f32[64,16,1024]{2,1,0} %param_0.363, f32[1,16,1024]{2,1,0} %bitcast.623, s32[] %select.1908, s32[] %constant_10968, s32[] %constant_10968), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.226 (param_0.364: f32[64,16,1024], param_1.2255: f32[16,1024], param_2.1991: s32[]) -> f32[64,16,1024] {
  %param_0.364 = f32[64,16,1024]{2,1,0} parameter(0)
  %param_1.2255 = f32[16,1024]{1,0} parameter(1)
  %bitcast.624 = f32[1,16,1024]{2,1,0} bitcast(f32[16,1024]{1,0} %param_1.2255), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_2.1991 = s32[] parameter(2)
  %constant_10970 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.1915 = pred[] compare(s32[] %param_2.1991, s32[] %constant_10970), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_14173 = s32[] constant(64), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.2972 = s32[] add(s32[] %param_2.1991, s32[] %constant_14173), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %select.1906 = s32[] select(pred[] %compare.1915, s32[] %add.2972, s32[] %param_2.1991), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.579 = f32[64,16,1024]{2,1,0} dynamic-update-slice(f32[64,16,1024]{2,1,0} %param_0.364, f32[1,16,1024]{2,1,0} %bitcast.624, s32[] %select.1906, s32[] %constant_10970, s32[] %constant_10970), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.227 (param_0.365: f32[64,16,1024], param_1.2254: f32[16,1024], param_2.1989: s32[]) -> f32[64,16,1024] {
  %param_0.365 = f32[64,16,1024]{2,1,0} parameter(0)
  %constant_10972 = f32[] constant(1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %broadcast.1519 = f32[16,1024]{1,0} broadcast(f32[] %constant_10972), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %param_1.2254 = f32[16,1024]{1,0} parameter(1)
  %subtract.242 = f32[16,1024]{1,0} subtract(f32[16,1024]{1,0} %broadcast.1519, f32[16,1024]{1,0} %param_1.2254), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  %bitcast.625 = f32[1,16,1024]{2,1,0} bitcast(f32[16,1024]{1,0} %subtract.242), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_2.1989 = s32[] parameter(2)
  %constant_10971 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.1913 = pred[] compare(s32[] %param_2.1989, s32[] %constant_10971), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_14168 = s32[] constant(64), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.2970 = s32[] add(s32[] %param_2.1989, s32[] %constant_14168), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %select.1903 = s32[] select(pred[] %compare.1913, s32[] %add.2970, s32[] %param_2.1989), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.580 = f32[64,16,1024]{2,1,0} dynamic-update-slice(f32[64,16,1024]{2,1,0} %param_0.365, f32[1,16,1024]{2,1,0} %bitcast.625, s32[] %select.1903, s32[] %constant_10971, s32[] %constant_10971), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.228 (param_0.366: f32[64,16,1024], param_1.2253: f32[16,1024], param_2.1987: s32[]) -> f32[64,16,1024] {
  %param_0.366 = f32[64,16,1024]{2,1,0} parameter(0)
  %param_1.2253 = f32[16,1024]{1,0} parameter(1)
  %bitcast.626 = f32[1,16,1024]{2,1,0} bitcast(f32[16,1024]{1,0} %param_1.2253), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_2.1987 = s32[] parameter(2)
  %constant_10973 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.1911 = pred[] compare(s32[] %param_2.1987, s32[] %constant_10973), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_14161 = s32[] constant(64), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.2968 = s32[] add(s32[] %param_2.1987, s32[] %constant_14161), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %select.1901 = s32[] select(pred[] %compare.1911, s32[] %add.2968, s32[] %param_2.1987), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.581 = f32[64,16,1024]{2,1,0} dynamic-update-slice(f32[64,16,1024]{2,1,0} %param_0.366, f32[1,16,1024]{2,1,0} %bitcast.626, s32[] %select.1901, s32[] %constant_10973, s32[] %constant_10973), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.229 (param_0.367: f32[64,16,1024], param_1.2252: f32[16,1024], param_2.1985: s32[]) -> f32[64,16,1024] {
  %param_0.367 = f32[64,16,1024]{2,1,0} parameter(0)
  %constant_10975 = f32[] constant(1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %broadcast.1520 = f32[16,1024]{1,0} broadcast(f32[] %constant_10975), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %param_1.2252 = f32[16,1024]{1,0} parameter(1)
  %subtract.243 = f32[16,1024]{1,0} subtract(f32[16,1024]{1,0} %broadcast.1520, f32[16,1024]{1,0} %param_1.2252), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %bitcast.627 = f32[1,16,1024]{2,1,0} bitcast(f32[16,1024]{1,0} %subtract.243), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_2.1985 = s32[] parameter(2)
  %constant_10974 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.1909 = pred[] compare(s32[] %param_2.1985, s32[] %constant_10974), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_14155 = s32[] constant(64), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.2966 = s32[] add(s32[] %param_2.1985, s32[] %constant_14155), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %select.1899 = s32[] select(pred[] %compare.1909, s32[] %add.2966, s32[] %param_2.1985), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.582 = f32[64,16,1024]{2,1,0} dynamic-update-slice(f32[64,16,1024]{2,1,0} %param_0.367, f32[1,16,1024]{2,1,0} %bitcast.627, s32[] %select.1899, s32[] %constant_10974, s32[] %constant_10974), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.230 (param_0.368: f32[64,16,1024], param_1.2251: f32[16,1024], param_2.1983: s32[]) -> f32[64,16,1024] {
  %param_0.368 = f32[64,16,1024]{2,1,0} parameter(0)
  %param_1.2251 = f32[16,1024]{1,0} parameter(1)
  %bitcast.628 = f32[1,16,1024]{2,1,0} bitcast(f32[16,1024]{1,0} %param_1.2251), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_2.1983 = s32[] parameter(2)
  %constant_10976 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.1907 = pred[] compare(s32[] %param_2.1983, s32[] %constant_10976), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_14149 = s32[] constant(64), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.2964 = s32[] add(s32[] %param_2.1983, s32[] %constant_14149), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %select.1897 = s32[] select(pred[] %compare.1907, s32[] %add.2964, s32[] %param_2.1983), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.583 = f32[64,16,1024]{2,1,0} dynamic-update-slice(f32[64,16,1024]{2,1,0} %param_0.368, f32[1,16,1024]{2,1,0} %bitcast.628, s32[] %select.1897, s32[] %constant_10976, s32[] %constant_10976), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.231 (param_0.369: f32[64,16,1024], param_1.2250: f32[16,1024], param_2.1981: s32[]) -> f32[64,16,1024] {
  %param_0.369 = f32[64,16,1024]{2,1,0} parameter(0)
  %constant_10978 = f32[] constant(1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %broadcast.1521 = f32[16,1024]{1,0} broadcast(f32[] %constant_10978), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %param_1.2250 = f32[16,1024]{1,0} parameter(1)
  %subtract.244 = f32[16,1024]{1,0} subtract(f32[16,1024]{1,0} %broadcast.1521, f32[16,1024]{1,0} %param_1.2250), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %bitcast.629 = f32[1,16,1024]{2,1,0} bitcast(f32[16,1024]{1,0} %subtract.244), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_2.1981 = s32[] parameter(2)
  %constant_10977 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.1905 = pred[] compare(s32[] %param_2.1981, s32[] %constant_10977), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_14143 = s32[] constant(64), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.2962 = s32[] add(s32[] %param_2.1981, s32[] %constant_14143), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %select.1894 = s32[] select(pred[] %compare.1905, s32[] %add.2962, s32[] %param_2.1981), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.584 = f32[64,16,1024]{2,1,0} dynamic-update-slice(f32[64,16,1024]{2,1,0} %param_0.369, f32[1,16,1024]{2,1,0} %bitcast.629, s32[] %select.1894, s32[] %constant_10977, s32[] %constant_10977), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.232 (param_0.370: f32[64,16,1024], param_1.2249: f32[16,1024], param_2.1979: s32[]) -> f32[64,16,1024] {
  %param_0.370 = f32[64,16,1024]{2,1,0} parameter(0)
  %param_1.2249 = f32[16,1024]{1,0} parameter(1)
  %bitcast.630 = f32[1,16,1024]{2,1,0} bitcast(f32[16,1024]{1,0} %param_1.2249), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_2.1979 = s32[] parameter(2)
  %constant_10979 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.1903 = pred[] compare(s32[] %param_2.1979, s32[] %constant_10979), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_14137 = s32[] constant(64), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.2960 = s32[] add(s32[] %param_2.1979, s32[] %constant_14137), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %select.1892 = s32[] select(pred[] %compare.1903, s32[] %add.2960, s32[] %param_2.1979), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.585 = f32[64,16,1024]{2,1,0} dynamic-update-slice(f32[64,16,1024]{2,1,0} %param_0.370, f32[1,16,1024]{2,1,0} %bitcast.630, s32[] %select.1892, s32[] %constant_10979, s32[] %constant_10979), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.233 (param_0.371: f32[64,16,1024], param_1.2248: f32[16,1024], param_2.1977: s32[]) -> f32[64,16,1024] {
  %param_0.371 = f32[64,16,1024]{2,1,0} parameter(0)
  %constant_10984 = f32[] constant(1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %broadcast.1522 = f32[16,1024]{1,0} broadcast(f32[] %constant_10984), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %param_1.2248 = f32[16,1024]{1,0} parameter(1)
  %subtract.245 = f32[16,1024]{1,0} subtract(f32[16,1024]{1,0} %broadcast.1522, f32[16,1024]{1,0} %param_1.2248), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %bitcast.631 = f32[1,16,1024]{2,1,0} bitcast(f32[16,1024]{1,0} %subtract.245), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_2.1977 = s32[] parameter(2)
  %constant_10982 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.1901 = pred[] compare(s32[] %param_2.1977, s32[] %constant_10982), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_14131 = s32[] constant(64), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.2958 = s32[] add(s32[] %param_2.1977, s32[] %constant_14131), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %select.1890 = s32[] select(pred[] %compare.1901, s32[] %add.2958, s32[] %param_2.1977), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.586 = f32[64,16,1024]{2,1,0} dynamic-update-slice(f32[64,16,1024]{2,1,0} %param_0.371, f32[1,16,1024]{2,1,0} %bitcast.631, s32[] %select.1890, s32[] %constant_10982, s32[] %constant_10982), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.234 (param_0.372: f32[64,16,2048], param_1.2247: f32[16,2048], param_2.1975: s32[]) -> f32[64,16,2048] {
  %param_0.372 = f32[64,16,2048]{2,1,0} parameter(0)
  %param_1.2247 = f32[16,2048]{1,0} parameter(1)
  %bitcast.632 = f32[1,16,2048]{2,1,0} bitcast(f32[16,2048]{1,0} %param_1.2247), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 16, 2048) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_2.1975 = s32[] parameter(2)
  %constant_10986 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.1898 = pred[] compare(s32[] %param_2.1975, s32[] %constant_10986), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_14126 = s32[] constant(64), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.2956 = s32[] add(s32[] %param_2.1975, s32[] %constant_14126), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %select.1887 = s32[] select(pred[] %compare.1898, s32[] %add.2956, s32[] %param_2.1975), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.587 = f32[64,16,2048]{2,1,0} dynamic-update-slice(f32[64,16,2048]{2,1,0} %param_0.372, f32[1,16,2048]{2,1,0} %bitcast.632, s32[] %select.1887, s32[] %constant_10986, s32[] %constant_10986), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.235 (param_0.373: f32[64,16,1024], param_1.2246: f32[16,2048], param_2.1973: s32[]) -> f32[64,16,1024] {
  %param_0.373 = f32[64,16,1024]{2,1,0} parameter(0)
  %param_1.2246 = f32[16,2048]{1,0} parameter(1)
  %slice.933 = f32[16,1024]{1,0} slice(f32[16,2048]{1,0} %param_1.2246), slice={[0:16], [0:1024]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(16, 1024)\n                                                     start_indices=(0, 0)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=54}
  %bitcast.633 = f32[1,16,1024]{2,1,0} bitcast(f32[16,1024]{1,0} %slice.933), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_2.1973 = s32[] parameter(2)
  %constant_10988 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.1896 = pred[] compare(s32[] %param_2.1973, s32[] %constant_10988), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_14120 = s32[] constant(64), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.2953 = s32[] add(s32[] %param_2.1973, s32[] %constant_14120), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %select.1885 = s32[] select(pred[] %compare.1896, s32[] %add.2953, s32[] %param_2.1973), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.588 = f32[64,16,1024]{2,1,0} dynamic-update-slice(f32[64,16,1024]{2,1,0} %param_0.373, f32[1,16,1024]{2,1,0} %bitcast.633, s32[] %select.1885, s32[] %constant_10988, s32[] %constant_10988), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.236 (param_0.374: f32[64,16,1024], param_1.2245: f32[16,1024], param_2.1971: s32[]) -> f32[64,16,1024] {
  %param_0.374 = f32[64,16,1024]{2,1,0} parameter(0)
  %param_1.2245 = f32[16,1024]{1,0} parameter(1)
  %bitcast.634 = f32[1,16,1024]{2,1,0} bitcast(f32[16,1024]{1,0} %param_1.2245), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_2.1971 = s32[] parameter(2)
  %constant_10989 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.1894 = pred[] compare(s32[] %param_2.1971, s32[] %constant_10989), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_14114 = s32[] constant(64), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.2951 = s32[] add(s32[] %param_2.1971, s32[] %constant_14114), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %select.1883 = s32[] select(pred[] %compare.1894, s32[] %add.2951, s32[] %param_2.1971), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.589 = f32[64,16,1024]{2,1,0} dynamic-update-slice(f32[64,16,1024]{2,1,0} %param_0.374, f32[1,16,1024]{2,1,0} %bitcast.634, s32[] %select.1883, s32[] %constant_10989, s32[] %constant_10989), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.237 (param_0.375: f32[64,16,1024], param_1.2244: f32[16,1024], param_2.1969: f32[16,1024], param_3.1778: s32[]) -> f32[64,16,1024] {
  %param_0.375 = f32[64,16,1024]{2,1,0} parameter(0)
  %param_1.2244 = f32[16,1024]{1,0} parameter(1)
  %param_2.1969 = f32[16,1024]{1,0} parameter(2)
  %multiply.1390 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %param_1.2244, f32[16,1024]{1,0} %param_2.1969), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  %bitcast.635 = f32[1,16,1024]{2,1,0} bitcast(f32[16,1024]{1,0} %multiply.1390), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_3.1778 = s32[] parameter(3)
  %constant_10992 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.1892 = pred[] compare(s32[] %param_3.1778, s32[] %constant_10992), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_14108 = s32[] constant(64), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.2948 = s32[] add(s32[] %param_3.1778, s32[] %constant_14108), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %select.1881 = s32[] select(pred[] %compare.1892, s32[] %add.2948, s32[] %param_3.1778), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.590 = f32[64,16,1024]{2,1,0} dynamic-update-slice(f32[64,16,1024]{2,1,0} %param_0.375, f32[1,16,1024]{2,1,0} %bitcast.635, s32[] %select.1881, s32[] %constant_10992, s32[] %constant_10992), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.243 (param_0.384: f32[1,4096]) -> f32[16,4096] {
  %param_0.384 = f32[1,4096]{1,0} parameter(0)
  %bitcast.636 = f32[4096]{0} bitcast(f32[1,4096]{1,0} %param_0.384), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  ROOT %broadcast.1280 = f32[16,4096]{1,0} broadcast(f32[4096]{0} %bitcast.636), dimensions={1}, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
}

%fused_computation.244 (param_0.386: f32[16,2048], param_1.632: f32[64,16,1024], param_2.1968: s32[]) -> f32[16,2048] {
  %param_1.632 = f32[64,16,1024]{2,1,0} parameter(1)
  %param_2.1968 = s32[] parameter(2)
  %constant_11003 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.1889 = pred[] compare(s32[] %param_2.1968, s32[] %constant_11003), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_14102 = s32[] constant(64), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.2946 = s32[] add(s32[] %param_2.1968, s32[] %constant_14102), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %select.1879 = s32[] select(pred[] %compare.1889, s32[] %add.2946, s32[] %param_2.1968), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %dynamic-slice.408 = f32[1,16,1024]{2,1,0} dynamic-slice(f32[64,16,1024]{2,1,0} %param_1.632, s32[] %select.1879, s32[] %constant_11003, s32[] %constant_11003), dynamic_slice_sizes={1,16,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %bitcast.637 = f32[16,1024]{1,0} bitcast(f32[1,16,1024]{2,1,0} %dynamic-slice.408), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_0.386 = f32[16,2048]{1,0} parameter(0)
  %slice.888 = f32[16,1024]{1,0} slice(f32[16,2048]{1,0} %param_0.386), slice={[0:16], [1024:2048]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(16, 2048)\n                                                     start_indices=(0, 1024)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=54}
  ROOT %concatenate.196 = f32[16,2048]{1,0} concatenate(f32[16,1024]{1,0} %bitcast.637, f32[16,1024]{1,0} %slice.888), dimensions={1}, metadata={op_type="concatenate" op_name="pmap(_multi_device_update_fn)/scan/while/body/concatenate[ dimension=1 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
}

%fused_computation.668 (param_0.1267: f32[16,1024], param_1.1604: f32[16,1024], param_2.1086: f32[16,1024]) -> f32[16,2048] {
  %param_0.1267 = f32[16,1024]{1,0} parameter(0)
  %param_1.1604 = f32[16,1024]{1,0} parameter(1)
  %param_2.1086 = f32[16,1024]{1,0} parameter(2)
  %multiply.1391 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %param_1.1604, f32[16,1024]{1,0} %param_2.1086), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  ROOT %concatenate.211 = f32[16,2048]{1,0} concatenate(f32[16,1024]{1,0} %param_0.1267, f32[16,1024]{1,0} %multiply.1391), dimensions={1}, metadata={op_type="concatenate" op_name="pmap(_multi_device_update_fn)/scan/while/body/concatenate[ dimension=1 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=65}
}

%fused_computation.746 (param_0.2196: f32[16,2048], param_1.2658: f32[16,4096]) -> (f32[16,1024], f32[16,1024], f32[16,1024], f32[16,1024], f32[16,1024], /*index=5*/f32[16,1024]) {
  %param_0.2196 = f32[16,2048]{1,0} parameter(0)
  %slice.934.clone.1 = f32[16,1024]{1,0} slice(f32[16,2048]{1,0} %param_0.2196), slice={[0:16], [0:1024]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(16, 1024)\n                                                     start_indices=(0, 0)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=54}
  %constant_10997_clone_1 = f32[] constant(1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %broadcast.1524.clone.1 = f32[16,1024]{1,0} broadcast(f32[] %constant_10997_clone_1), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %param_1.2658 = f32[16,4096]{1,0} parameter(1)
  %slice.887.clone.1 = f32[16,1024]{1,0} slice(f32[16,4096]{1,0} %param_1.2658), slice={[0:16], [2048:3072]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(16, 3072)\n                                                     start_indices=(0, 2048)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  %negate.147.clone.1 = f32[16,1024]{1,0} negate(f32[16,1024]{1,0} %slice.887.clone.1), metadata={op_type="neg" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/neg" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %exponential.128.clone.1 = f32[16,1024]{1,0} exponential(f32[16,1024]{1,0} %negate.147.clone.1), metadata={op_type="exp" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/exp" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %add.1893.clone.1 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %broadcast.1524.clone.1, f32[16,1024]{1,0} %exponential.128.clone.1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %divide.132.clone.1 = f32[16,1024]{1,0} divide(f32[16,1024]{1,0} %broadcast.1524.clone.1, f32[16,1024]{1,0} %add.1893.clone.1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %multiply.942.clone.1 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %slice.934.clone.1, f32[16,1024]{1,0} %divide.132.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %slice.886.clone.1 = f32[16,1024]{1,0} slice(f32[16,4096]{1,0} %param_1.2658), slice={[0:16], [0:1024]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(16, 1024)\n                                                     start_indices=(0, 0)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  %negate.146.clone.1 = f32[16,1024]{1,0} negate(f32[16,1024]{1,0} %slice.886.clone.1), metadata={op_type="neg" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/neg" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %exponential.127.clone.1 = f32[16,1024]{1,0} exponential(f32[16,1024]{1,0} %negate.146.clone.1), metadata={op_type="exp" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/exp" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %add.1892.clone.1 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %broadcast.1524.clone.1, f32[16,1024]{1,0} %exponential.127.clone.1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %divide.131.clone.1 = f32[16,1024]{1,0} divide(f32[16,1024]{1,0} %broadcast.1524.clone.1, f32[16,1024]{1,0} %add.1892.clone.1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %slice.885.clone.1 = f32[16,1024]{1,0} slice(f32[16,4096]{1,0} %param_1.2658), slice={[0:16], [1024:2048]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(16, 2048)\n                                                     start_indices=(0, 1024)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  %tanh.78.clone.1 = f32[16,1024]{1,0} tanh(f32[16,1024]{1,0} %slice.885.clone.1), metadata={op_type="tanh" op_name="pmap(_multi_device_update_fn)/scan/while/body/tanh" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %multiply.941.clone.1 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %divide.131.clone.1, f32[16,1024]{1,0} %tanh.78.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %add.1891.clone.1 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %multiply.942.clone.1, f32[16,1024]{1,0} %multiply.941.clone.1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %tanh.87 = f32[16,1024]{1,0} tanh(f32[16,1024]{1,0} %add.1891.clone.1), metadata={op_type="tanh" op_name="pmap(_multi_device_update_fn)/scan/while/body/tanh" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  %slice.884.clone.1 = f32[16,1024]{1,0} slice(f32[16,4096]{1,0} %param_1.2658), slice={[0:16], [3072:4096]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(16, 4096)\n                                                     start_indices=(0, 3072)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  %negate.145.clone.1 = f32[16,1024]{1,0} negate(f32[16,1024]{1,0} %slice.884.clone.1), metadata={op_type="neg" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/neg" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %exponential.126.clone.1 = f32[16,1024]{1,0} exponential(f32[16,1024]{1,0} %negate.145.clone.1), metadata={op_type="exp" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/exp" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %add.1890.clone.1 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %broadcast.1524.clone.1, f32[16,1024]{1,0} %exponential.126.clone.1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %divide.130.clone.1 = f32[16,1024]{1,0} divide(f32[16,1024]{1,0} %broadcast.1524.clone.1, f32[16,1024]{1,0} %add.1890.clone.1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  ROOT %tuple.509 = (f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, /*index=5*/f32[16,1024]{1,0}) tuple(f32[16,1024]{1,0} %tanh.87, f32[16,1024]{1,0} %add.1891.clone.1, f32[16,1024]{1,0} %divide.132.clone.1, f32[16,1024]{1,0} %tanh.78.clone.1, f32[16,1024]{1,0} %divide.131.clone.1, /*index=5*/f32[16,1024]{1,0} %divide.130.clone.1)
}

%body_computation__42.5589.clone.clone.clone.clone (parameter.184: (f32[64,16,1024], f32[2048,4096], f32[1,4096], s32[], f32[16,2048], /*index=5*/f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[64,16,2048], f32[64,16,1024], /*index=10*/f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], /*index=15*/f32[64,16,1024], f32[64,16,1024], f32[64,16,1024])) -> (f32[64,16,1024], f32[2048,4096], f32[1,4096], s32[], f32[16,2048], /*index=5*/f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[64,16,2048], f32[64,16,1024], /*index=10*/f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], /*index=15*/f32[64,16,1024], f32[64,16,1024], f32[64,16,1024]) {
  %parameter.184 = (f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) parameter(0)
  %get-tuple-element.6136 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %parameter.184), index=0
  %get-tuple-element.6137 = f32[2048,4096]{1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %parameter.184), index=1
  %get-tuple-element.6138 = f32[1,4096]{1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %parameter.184), index=2
  %get-tuple-element.6154 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %parameter.184), index=16
  %get-tuple-element.6140 = f32[16,2048]{1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %parameter.184), index=4
  %get-tuple-element.6139 = s32[] get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %parameter.184), index=3
  %fusion.244 = f32[16,2048]{1,0} fusion(f32[16,2048]{1,0} %get-tuple-element.6140, f32[64,16,1024]{2,1,0} %get-tuple-element.6136, s32[] %get-tuple-element.6139), kind=kLoop, calls=%fused_computation.244, metadata={op_type="concatenate" op_name="pmap(_multi_device_update_fn)/scan/while/body/concatenate[ dimension=1 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %fusion.243 = f32[16,4096]{1,0} fusion(f32[1,4096]{1,0} %get-tuple-element.6138), kind=kLoop, calls=%fused_computation.243, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %custom-call.132 = f32[16,4096]{1,0} custom-call(f32[16,2048]{1,0} %fusion.244, f32[2048,4096]{1,0} %get-tuple-element.6137, f32[16,4096]{1,0} %fusion.243), custom_call_target="__cublas$gemm", metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}, backend_config="{\"alpha_real\":1,\"alpha_imag\":0,\"beta\":1,\"dot_dimension_numbers\":{\"lhs_contracting_dimensions\":[\"1\"],\"rhs_contracting_dimensions\":[\"0\"],\"lhs_batch_dimensions\":[],\"rhs_batch_dimensions\":[]},\"batch_size\":\"1\",\"selected_algorithm\":\"0\"}"
  %fusion.746 = (f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, /*index=5*/f32[16,1024]{1,0}) fusion(f32[16,2048]{1,0} %get-tuple-element.6140, f32[16,4096]{1,0} %custom-call.132), kind=kLoop, calls=%fused_computation.746, metadata={op_type="tanh" op_name="pmap(_multi_device_update_fn)/scan/while/body/tanh" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  %get-tuple-element.5095 = f32[16,1024]{1,0} get-tuple-element((f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, /*index=5*/f32[16,1024]{1,0}) %fusion.746), index=5
  %fusion.226 = f32[64,16,1024]{2,1,0} fusion(f32[64,16,1024]{2,1,0} %get-tuple-element.6154, f32[16,1024]{1,0} %get-tuple-element.5095, s32[] %get-tuple-element.6139), kind=kLoop, calls=%fused_computation.226, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.6153 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %parameter.184), index=15
  %get-tuple-element.5090 = f32[16,1024]{1,0} get-tuple-element((f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, /*index=5*/f32[16,1024]{1,0}) %fusion.746), index=0
  %fusion.227 = f32[64,16,1024]{2,1,0} fusion(f32[64,16,1024]{2,1,0} %get-tuple-element.6153, f32[16,1024]{1,0} %get-tuple-element.5090, s32[] %get-tuple-element.6139), kind=kLoop, calls=%fused_computation.227, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.6152 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %parameter.184), index=14
  %fusion.228 = f32[64,16,1024]{2,1,0} fusion(f32[64,16,1024]{2,1,0} %get-tuple-element.6152, f32[16,1024]{1,0} %get-tuple-element.5090, s32[] %get-tuple-element.6139), kind=kLoop, calls=%fused_computation.228, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.6149 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %parameter.184), index=13
  %get-tuple-element.5093 = f32[16,1024]{1,0} get-tuple-element((f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, /*index=5*/f32[16,1024]{1,0}) %fusion.746), index=3
  %fusion.229 = f32[64,16,1024]{2,1,0} fusion(f32[64,16,1024]{2,1,0} %get-tuple-element.6149, f32[16,1024]{1,0} %get-tuple-element.5093, s32[] %get-tuple-element.6139), kind=kLoop, calls=%fused_computation.229, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.6148 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %parameter.184), index=12
  %fusion.230 = f32[64,16,1024]{2,1,0} fusion(f32[64,16,1024]{2,1,0} %get-tuple-element.6148, f32[16,1024]{1,0} %get-tuple-element.5093, s32[] %get-tuple-element.6139), kind=kLoop, calls=%fused_computation.230, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.6147 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %parameter.184), index=11
  %get-tuple-element.5094 = f32[16,1024]{1,0} get-tuple-element((f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, /*index=5*/f32[16,1024]{1,0}) %fusion.746), index=4
  %fusion.231 = f32[64,16,1024]{2,1,0} fusion(f32[64,16,1024]{2,1,0} %get-tuple-element.6147, f32[16,1024]{1,0} %get-tuple-element.5094, s32[] %get-tuple-element.6139), kind=kLoop, calls=%fused_computation.231, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.6146 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %parameter.184), index=10
  %fusion.232 = f32[64,16,1024]{2,1,0} fusion(f32[64,16,1024]{2,1,0} %get-tuple-element.6146, f32[16,1024]{1,0} %get-tuple-element.5094, s32[] %get-tuple-element.6139), kind=kLoop, calls=%fused_computation.232, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.6145 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %parameter.184), index=9
  %get-tuple-element.5092 = f32[16,1024]{1,0} get-tuple-element((f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, /*index=5*/f32[16,1024]{1,0}) %fusion.746), index=2
  %fusion.233 = f32[64,16,1024]{2,1,0} fusion(f32[64,16,1024]{2,1,0} %get-tuple-element.6145, f32[16,1024]{1,0} %get-tuple-element.5092, s32[] %get-tuple-element.6139), kind=kLoop, calls=%fused_computation.233, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.6144 = f32[64,16,2048]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %parameter.184), index=8
  %fusion.234 = f32[64,16,2048]{2,1,0} fusion(f32[64,16,2048]{2,1,0} %get-tuple-element.6144, f32[16,2048]{1,0} %fusion.244, s32[] %get-tuple-element.6139), kind=kLoop, calls=%fused_computation.234, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.6143 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %parameter.184), index=7
  %fusion.235 = f32[64,16,1024]{2,1,0} fusion(f32[64,16,1024]{2,1,0} %get-tuple-element.6143, f32[16,2048]{1,0} %get-tuple-element.6140, s32[] %get-tuple-element.6139), kind=kLoop, calls=%fused_computation.235, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.6142 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %parameter.184), index=6
  %fusion.236 = f32[64,16,1024]{2,1,0} fusion(f32[64,16,1024]{2,1,0} %get-tuple-element.6142, f32[16,1024]{1,0} %get-tuple-element.5092, s32[] %get-tuple-element.6139), kind=kLoop, calls=%fused_computation.236, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.6141 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %parameter.184), index=5
  %fusion.237 = f32[64,16,1024]{2,1,0} fusion(f32[64,16,1024]{2,1,0} %get-tuple-element.6141, f32[16,1024]{1,0} %get-tuple-element.5090, f32[16,1024]{1,0} %get-tuple-element.5095, s32[] %get-tuple-element.6139), kind=kLoop, calls=%fused_computation.237, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.6155 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %parameter.184), index=17
  %fusion.225 = f32[64,16,1024]{2,1,0} fusion(f32[64,16,1024]{2,1,0} %get-tuple-element.6155, f32[16,1024]{1,0} %get-tuple-element.5095, s32[] %get-tuple-element.6139), kind=kLoop, calls=%fused_computation.225, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_10308 = s32[] constant(1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.1718 = s32[] add(s32[] %get-tuple-element.6139, s32[] %constant_10308), control-predecessors={%fusion.225, %fusion.244, %fusion.237, %fusion.236, %fusion.235, %fusion.234, %fusion.233, %fusion.232, %fusion.231, %fusion.230, %fusion.229, %fusion.228, %fusion.227, %fusion.226}, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.5091 = f32[16,1024]{1,0} get-tuple-element((f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, /*index=5*/f32[16,1024]{1,0}) %fusion.746), index=1
  %fusion.668 = f32[16,2048]{1,0} fusion(f32[16,1024]{1,0} %get-tuple-element.5091, f32[16,1024]{1,0} %get-tuple-element.5090, f32[16,1024]{1,0} %get-tuple-element.5095), kind=kLoop, calls=%fused_computation.668, control-predecessors={%fusion.244, %fusion.746, %fusion.235}, metadata={op_type="concatenate" op_name="pmap(_multi_device_update_fn)/scan/while/body/concatenate[ dimension=1 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=65}
  ROOT %tuple.805 = (f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) tuple(f32[64,16,1024]{2,1,0} %get-tuple-element.6136, f32[2048,4096]{1,0} %get-tuple-element.6137, f32[1,4096]{1,0} %get-tuple-element.6138, s32[] %add.1718, f32[16,2048]{1,0} %fusion.668, /*index=5*/f32[64,16,1024]{2,1,0} %fusion.237, f32[64,16,1024]{2,1,0} %fusion.236, f32[64,16,1024]{2,1,0} %fusion.235, f32[64,16,2048]{2,1,0} %fusion.234, f32[64,16,1024]{2,1,0} %fusion.233, /*index=10*/f32[64,16,1024]{2,1,0} %fusion.232, f32[64,16,1024]{2,1,0} %fusion.231, f32[64,16,1024]{2,1,0} %fusion.230, f32[64,16,1024]{2,1,0} %fusion.229, f32[64,16,1024]{2,1,0} %fusion.228, /*index=15*/f32[64,16,1024]{2,1,0} %fusion.227, f32[64,16,1024]{2,1,0} %fusion.226, f32[64,16,1024]{2,1,0} %fusion.225)
}

%cond_computation__42.6010.clone.clone.clone (parameter.185: (f32[64,16,1024], f32[2048,4096], f32[1,4096], s32[], f32[16,2048], /*index=5*/f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[64,16,2048], f32[64,16,1024], /*index=10*/f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], /*index=15*/f32[64,16,1024], f32[64,16,1024], f32[64,16,1024])) -> pred[] {
  %parameter.185 = (f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) parameter(0)
  %get-tuple-element.4731 = s32[] get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %parameter.185), index=3
  %constant_10311 = s32[] constant(64), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/cond/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %compare.1342 = pred[] compare(s32[] %get-tuple-element.4731, s32[] %constant_10311), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/cond/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.246 (param_0.389: f32[64,16,1024], param_1.2269: f32[16,1024], param_2.2020: s32[]) -> f32[64,16,1024] {
  %param_0.389 = f32[64,16,1024]{2,1,0} parameter(0)
  %constant_11007 = f32[] constant(1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %broadcast.1527 = f32[16,1024]{1,0} broadcast(f32[] %constant_11007), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %param_1.2269 = f32[16,1024]{1,0} parameter(1)
  %subtract.246 = f32[16,1024]{1,0} subtract(f32[16,1024]{1,0} %broadcast.1527, f32[16,1024]{1,0} %param_1.2269), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %bitcast.638 = f32[1,16,1024]{2,1,0} bitcast(f32[16,1024]{1,0} %subtract.246), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_2.2020 = s32[] parameter(2)
  %constant_11006 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.1945 = pred[] compare(s32[] %param_2.2020, s32[] %constant_11006), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_14265 = s32[] constant(64), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.3002 = s32[] add(s32[] %param_2.2020, s32[] %constant_14265), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %select.1936 = s32[] select(pred[] %compare.1945, s32[] %add.3002, s32[] %param_2.2020), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.591 = f32[64,16,1024]{2,1,0} dynamic-update-slice(f32[64,16,1024]{2,1,0} %param_0.389, f32[1,16,1024]{2,1,0} %bitcast.638, s32[] %select.1936, s32[] %constant_11006, s32[] %constant_11006), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.247 (param_0.390: f32[64,16,1024], param_1.2268: f32[16,1024], param_2.2018: s32[]) -> f32[64,16,1024] {
  %param_0.390 = f32[64,16,1024]{2,1,0} parameter(0)
  %param_1.2268 = f32[16,1024]{1,0} parameter(1)
  %bitcast.639 = f32[1,16,1024]{2,1,0} bitcast(f32[16,1024]{1,0} %param_1.2268), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_2.2018 = s32[] parameter(2)
  %constant_11009 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.1943 = pred[] compare(s32[] %param_2.2018, s32[] %constant_11009), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_14258 = s32[] constant(64), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.3000 = s32[] add(s32[] %param_2.2018, s32[] %constant_14258), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %select.1934 = s32[] select(pred[] %compare.1943, s32[] %add.3000, s32[] %param_2.2018), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.592 = f32[64,16,1024]{2,1,0} dynamic-update-slice(f32[64,16,1024]{2,1,0} %param_0.390, f32[1,16,1024]{2,1,0} %bitcast.639, s32[] %select.1934, s32[] %constant_11009, s32[] %constant_11009), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.248 (param_0.391: f32[64,16,1024], param_1.2267: f32[16,1024], param_2.2016: s32[]) -> f32[64,16,1024] {
  %param_0.391 = f32[64,16,1024]{2,1,0} parameter(0)
  %constant_11012 = f32[] constant(1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %broadcast.1528 = f32[16,1024]{1,0} broadcast(f32[] %constant_11012), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %param_1.2267 = f32[16,1024]{1,0} parameter(1)
  %subtract.247 = f32[16,1024]{1,0} subtract(f32[16,1024]{1,0} %broadcast.1528, f32[16,1024]{1,0} %param_1.2267), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  %bitcast.640 = f32[1,16,1024]{2,1,0} bitcast(f32[16,1024]{1,0} %subtract.247), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_2.2016 = s32[] parameter(2)
  %constant_11011 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.1941 = pred[] compare(s32[] %param_2.2016, s32[] %constant_11011), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_14252 = s32[] constant(64), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.2998 = s32[] add(s32[] %param_2.2016, s32[] %constant_14252), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %select.1932 = s32[] select(pred[] %compare.1941, s32[] %add.2998, s32[] %param_2.2016), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.593 = f32[64,16,1024]{2,1,0} dynamic-update-slice(f32[64,16,1024]{2,1,0} %param_0.391, f32[1,16,1024]{2,1,0} %bitcast.640, s32[] %select.1932, s32[] %constant_11011, s32[] %constant_11011), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.249 (param_0.392: f32[64,16,1024], param_1.2266: f32[16,1024], param_2.2014: s32[]) -> f32[64,16,1024] {
  %param_0.392 = f32[64,16,1024]{2,1,0} parameter(0)
  %param_1.2266 = f32[16,1024]{1,0} parameter(1)
  %bitcast.641 = f32[1,16,1024]{2,1,0} bitcast(f32[16,1024]{1,0} %param_1.2266), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_2.2014 = s32[] parameter(2)
  %constant_11015 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.1939 = pred[] compare(s32[] %param_2.2014, s32[] %constant_11015), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_14247 = s32[] constant(64), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.2996 = s32[] add(s32[] %param_2.2014, s32[] %constant_14247), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %select.1930 = s32[] select(pred[] %compare.1939, s32[] %add.2996, s32[] %param_2.2014), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.594 = f32[64,16,1024]{2,1,0} dynamic-update-slice(f32[64,16,1024]{2,1,0} %param_0.392, f32[1,16,1024]{2,1,0} %bitcast.641, s32[] %select.1930, s32[] %constant_11015, s32[] %constant_11015), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.250 (param_0.393: f32[64,16,1024], param_1.2265: f32[16,1024], param_2.2012: s32[]) -> f32[64,16,1024] {
  %param_0.393 = f32[64,16,1024]{2,1,0} parameter(0)
  %constant_11020 = f32[] constant(1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %broadcast.1529 = f32[16,1024]{1,0} broadcast(f32[] %constant_11020), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %param_1.2265 = f32[16,1024]{1,0} parameter(1)
  %subtract.248 = f32[16,1024]{1,0} subtract(f32[16,1024]{1,0} %broadcast.1529, f32[16,1024]{1,0} %param_1.2265), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %bitcast.642 = f32[1,16,1024]{2,1,0} bitcast(f32[16,1024]{1,0} %subtract.248), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_2.2012 = s32[] parameter(2)
  %constant_11018 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.1937 = pred[] compare(s32[] %param_2.2012, s32[] %constant_11018), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_14241 = s32[] constant(64), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.2994 = s32[] add(s32[] %param_2.2012, s32[] %constant_14241), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %select.1928 = s32[] select(pred[] %compare.1937, s32[] %add.2994, s32[] %param_2.2012), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.595 = f32[64,16,1024]{2,1,0} dynamic-update-slice(f32[64,16,1024]{2,1,0} %param_0.393, f32[1,16,1024]{2,1,0} %bitcast.642, s32[] %select.1928, s32[] %constant_11018, s32[] %constant_11018), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.251 (param_0.394: f32[64,16,1024], param_1.2264: f32[16,1024], param_2.2010: s32[]) -> f32[64,16,1024] {
  %param_0.394 = f32[64,16,1024]{2,1,0} parameter(0)
  %param_1.2264 = f32[16,1024]{1,0} parameter(1)
  %bitcast.643 = f32[1,16,1024]{2,1,0} bitcast(f32[16,1024]{1,0} %param_1.2264), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_2.2010 = s32[] parameter(2)
  %constant_11023 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.1935 = pred[] compare(s32[] %param_2.2010, s32[] %constant_11023), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_14234 = s32[] constant(64), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.2992 = s32[] add(s32[] %param_2.2010, s32[] %constant_14234), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %select.1926 = s32[] select(pred[] %compare.1935, s32[] %add.2992, s32[] %param_2.2010), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.596 = f32[64,16,1024]{2,1,0} dynamic-update-slice(f32[64,16,1024]{2,1,0} %param_0.394, f32[1,16,1024]{2,1,0} %bitcast.643, s32[] %select.1926, s32[] %constant_11023, s32[] %constant_11023), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.252 (param_0.395: f32[64,16,1024], param_1.2263: f32[16,1024], param_2.2008: s32[]) -> f32[64,16,1024] {
  %param_0.395 = f32[64,16,1024]{2,1,0} parameter(0)
  %constant_11028 = f32[] constant(1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %broadcast.1530 = f32[16,1024]{1,0} broadcast(f32[] %constant_11028), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %param_1.2263 = f32[16,1024]{1,0} parameter(1)
  %subtract.249 = f32[16,1024]{1,0} subtract(f32[16,1024]{1,0} %broadcast.1530, f32[16,1024]{1,0} %param_1.2263), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %bitcast.644 = f32[1,16,1024]{2,1,0} bitcast(f32[16,1024]{1,0} %subtract.249), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_2.2008 = s32[] parameter(2)
  %constant_11026 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.1933 = pred[] compare(s32[] %param_2.2008, s32[] %constant_11026), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_14228 = s32[] constant(64), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.2990 = s32[] add(s32[] %param_2.2008, s32[] %constant_14228), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %select.1924 = s32[] select(pred[] %compare.1933, s32[] %add.2990, s32[] %param_2.2008), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.597 = f32[64,16,1024]{2,1,0} dynamic-update-slice(f32[64,16,1024]{2,1,0} %param_0.395, f32[1,16,1024]{2,1,0} %bitcast.644, s32[] %select.1924, s32[] %constant_11026, s32[] %constant_11026), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.253 (param_0.396: f32[64,16,1024], param_1.2262: f32[16,1024], param_2.2006: s32[]) -> f32[64,16,1024] {
  %param_0.396 = f32[64,16,1024]{2,1,0} parameter(0)
  %param_1.2262 = f32[16,1024]{1,0} parameter(1)
  %bitcast.645 = f32[1,16,1024]{2,1,0} bitcast(f32[16,1024]{1,0} %param_1.2262), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_2.2006 = s32[] parameter(2)
  %constant_11029 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.1931 = pred[] compare(s32[] %param_2.2006, s32[] %constant_11029), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_14222 = s32[] constant(64), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.2988 = s32[] add(s32[] %param_2.2006, s32[] %constant_14222), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %select.1922 = s32[] select(pred[] %compare.1931, s32[] %add.2988, s32[] %param_2.2006), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.598 = f32[64,16,1024]{2,1,0} dynamic-update-slice(f32[64,16,1024]{2,1,0} %param_0.396, f32[1,16,1024]{2,1,0} %bitcast.645, s32[] %select.1922, s32[] %constant_11029, s32[] %constant_11029), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.254 (param_0.397: f32[64,16,1024], param_1.2261: f32[16,1024], param_2.2004: s32[]) -> f32[64,16,1024] {
  %param_0.397 = f32[64,16,1024]{2,1,0} parameter(0)
  %constant_11032 = f32[] constant(1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %broadcast.1531 = f32[16,1024]{1,0} broadcast(f32[] %constant_11032), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %param_1.2261 = f32[16,1024]{1,0} parameter(1)
  %subtract.250 = f32[16,1024]{1,0} subtract(f32[16,1024]{1,0} %broadcast.1531, f32[16,1024]{1,0} %param_1.2261), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %bitcast.646 = f32[1,16,1024]{2,1,0} bitcast(f32[16,1024]{1,0} %subtract.250), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_2.2004 = s32[] parameter(2)
  %constant_11030 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.1929 = pred[] compare(s32[] %param_2.2004, s32[] %constant_11030), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_14216 = s32[] constant(64), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.2986 = s32[] add(s32[] %param_2.2004, s32[] %constant_14216), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %select.1920 = s32[] select(pred[] %compare.1929, s32[] %add.2986, s32[] %param_2.2004), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.599 = f32[64,16,1024]{2,1,0} dynamic-update-slice(f32[64,16,1024]{2,1,0} %param_0.397, f32[1,16,1024]{2,1,0} %bitcast.646, s32[] %select.1920, s32[] %constant_11030, s32[] %constant_11030), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.255 (param_0.398: f32[64,16,2048], param_1.2260: f32[16,2048], param_2.2002: s32[]) -> f32[64,16,2048] {
  %param_0.398 = f32[64,16,2048]{2,1,0} parameter(0)
  %param_1.2260 = f32[16,2048]{1,0} parameter(1)
  %bitcast.647 = f32[1,16,2048]{2,1,0} bitcast(f32[16,2048]{1,0} %param_1.2260), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 16, 2048) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_2.2002 = s32[] parameter(2)
  %constant_11034 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.1927 = pred[] compare(s32[] %param_2.2002, s32[] %constant_11034), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_14210 = s32[] constant(64), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.2984 = s32[] add(s32[] %param_2.2002, s32[] %constant_14210), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %select.1918 = s32[] select(pred[] %compare.1927, s32[] %add.2984, s32[] %param_2.2002), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.600 = f32[64,16,2048]{2,1,0} dynamic-update-slice(f32[64,16,2048]{2,1,0} %param_0.398, f32[1,16,2048]{2,1,0} %bitcast.647, s32[] %select.1918, s32[] %constant_11034, s32[] %constant_11034), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.256 (param_0.399: f32[64,16,1024], param_1.2259: f32[16,2048], param_2.2000: s32[]) -> f32[64,16,1024] {
  %param_0.399 = f32[64,16,1024]{2,1,0} parameter(0)
  %param_1.2259 = f32[16,2048]{1,0} parameter(1)
  %slice.935 = f32[16,1024]{1,0} slice(f32[16,2048]{1,0} %param_1.2259), slice={[0:16], [0:1024]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(16, 1024)\n                                                     start_indices=(0, 0)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=54}
  %bitcast.648 = f32[1,16,1024]{2,1,0} bitcast(f32[16,1024]{1,0} %slice.935), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_2.2000 = s32[] parameter(2)
  %constant_11035 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.1925 = pred[] compare(s32[] %param_2.2000, s32[] %constant_11035), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_14204 = s32[] constant(64), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.2982 = s32[] add(s32[] %param_2.2000, s32[] %constant_14204), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %select.1916 = s32[] select(pred[] %compare.1925, s32[] %add.2982, s32[] %param_2.2000), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.601 = f32[64,16,1024]{2,1,0} dynamic-update-slice(f32[64,16,1024]{2,1,0} %param_0.399, f32[1,16,1024]{2,1,0} %bitcast.648, s32[] %select.1916, s32[] %constant_11035, s32[] %constant_11035), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.257 (param_0.400: f32[64,16,1024], param_1.2258: f32[16,1024], param_2.1998: s32[]) -> f32[64,16,1024] {
  %param_0.400 = f32[64,16,1024]{2,1,0} parameter(0)
  %param_1.2258 = f32[16,1024]{1,0} parameter(1)
  %bitcast.649 = f32[1,16,1024]{2,1,0} bitcast(f32[16,1024]{1,0} %param_1.2258), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_2.1998 = s32[] parameter(2)
  %constant_11038 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.1923 = pred[] compare(s32[] %param_2.1998, s32[] %constant_11038), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_14198 = s32[] constant(64), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.2980 = s32[] add(s32[] %param_2.1998, s32[] %constant_14198), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %select.1914 = s32[] select(pred[] %compare.1923, s32[] %add.2980, s32[] %param_2.1998), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.602 = f32[64,16,1024]{2,1,0} dynamic-update-slice(f32[64,16,1024]{2,1,0} %param_0.400, f32[1,16,1024]{2,1,0} %bitcast.649, s32[] %select.1914, s32[] %constant_11038, s32[] %constant_11038), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.258 (param_0.401: f32[64,16,1024], param_1.2257: f32[16,1024], param_2.1996: f32[16,1024], param_3.1819: s32[]) -> f32[64,16,1024] {
  %param_0.401 = f32[64,16,1024]{2,1,0} parameter(0)
  %param_1.2257 = f32[16,1024]{1,0} parameter(1)
  %param_2.1996 = f32[16,1024]{1,0} parameter(2)
  %multiply.1392 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %param_1.2257, f32[16,1024]{1,0} %param_2.1996), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  %bitcast.650 = f32[1,16,1024]{2,1,0} bitcast(f32[16,1024]{1,0} %multiply.1392), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_3.1819 = s32[] parameter(3)
  %constant_11041 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.1921 = pred[] compare(s32[] %param_3.1819, s32[] %constant_11041), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_14192 = s32[] constant(64), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.2978 = s32[] add(s32[] %param_3.1819, s32[] %constant_14192), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %select.1912 = s32[] select(pred[] %compare.1921, s32[] %add.2978, s32[] %param_3.1819), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.603 = f32[64,16,1024]{2,1,0} dynamic-update-slice(f32[64,16,1024]{2,1,0} %param_0.401, f32[1,16,1024]{2,1,0} %bitcast.650, s32[] %select.1912, s32[] %constant_11041, s32[] %constant_11041), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.264 (param_0.410: f32[1,4096]) -> f32[16,4096] {
  %param_0.410 = f32[1,4096]{1,0} parameter(0)
  %bitcast.651 = f32[4096]{0} bitcast(f32[1,4096]{1,0} %param_0.410), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  ROOT %broadcast.1282 = f32[16,4096]{1,0} broadcast(f32[4096]{0} %bitcast.651), dimensions={1}, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
}

%fused_computation.265 (param_0.412: f32[16,2048], param_1.683: f32[64,16,1024], param_2.1995: s32[]) -> f32[16,2048] {
  %param_1.683 = f32[64,16,1024]{2,1,0} parameter(1)
  %param_2.1995 = s32[] parameter(2)
  %constant_11051 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.1919 = pred[] compare(s32[] %param_2.1995, s32[] %constant_11051), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_14186 = s32[] constant(64), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.2976 = s32[] add(s32[] %param_2.1995, s32[] %constant_14186), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %select.1910 = s32[] select(pred[] %compare.1919, s32[] %add.2976, s32[] %param_2.1995), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %dynamic-slice.409 = f32[1,16,1024]{2,1,0} dynamic-slice(f32[64,16,1024]{2,1,0} %param_1.683, s32[] %select.1910, s32[] %constant_11051, s32[] %constant_11051), dynamic_slice_sizes={1,16,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %bitcast.652 = f32[16,1024]{1,0} bitcast(f32[1,16,1024]{2,1,0} %dynamic-slice.409), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_0.412 = f32[16,2048]{1,0} parameter(0)
  %slice.893 = f32[16,1024]{1,0} slice(f32[16,2048]{1,0} %param_0.412), slice={[0:16], [1024:2048]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(16, 2048)\n                                                     start_indices=(0, 1024)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=54}
  ROOT %concatenate.197 = f32[16,2048]{1,0} concatenate(f32[16,1024]{1,0} %bitcast.652, f32[16,1024]{1,0} %slice.893), dimensions={1}, metadata={op_type="concatenate" op_name="pmap(_multi_device_update_fn)/scan/while/body/concatenate[ dimension=1 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
}

%fused_computation.669 (param_0.1271: f32[16,1024], param_1.1609: f32[16,1024], param_2.1106: f32[16,1024]) -> f32[16,2048] {
  %param_0.1271 = f32[16,1024]{1,0} parameter(0)
  %param_1.1609 = f32[16,1024]{1,0} parameter(1)
  %param_2.1106 = f32[16,1024]{1,0} parameter(2)
  %multiply.1393 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %param_1.1609, f32[16,1024]{1,0} %param_2.1106), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  ROOT %concatenate.212 = f32[16,2048]{1,0} concatenate(f32[16,1024]{1,0} %param_0.1271, f32[16,1024]{1,0} %multiply.1393), dimensions={1}, metadata={op_type="concatenate" op_name="pmap(_multi_device_update_fn)/scan/while/body/concatenate[ dimension=1 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=65}
}

%fused_computation.747 (param_0.2200: f32[16,2048], param_1.2663: f32[16,4096]) -> (f32[16,1024], f32[16,1024], f32[16,1024], f32[16,1024], f32[16,1024], /*index=5*/f32[16,1024]) {
  %param_0.2200 = f32[16,2048]{1,0} parameter(0)
  %slice.936.clone.1 = f32[16,1024]{1,0} slice(f32[16,2048]{1,0} %param_0.2200), slice={[0:16], [0:1024]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(16, 1024)\n                                                     start_indices=(0, 0)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=54}
  %constant_11046_clone_1 = f32[] constant(1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %broadcast.1533.clone.1 = f32[16,1024]{1,0} broadcast(f32[] %constant_11046_clone_1), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %param_1.2663 = f32[16,4096]{1,0} parameter(1)
  %slice.892.clone.1 = f32[16,1024]{1,0} slice(f32[16,4096]{1,0} %param_1.2663), slice={[0:16], [2048:3072]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(16, 3072)\n                                                     start_indices=(0, 2048)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  %negate.150.clone.1 = f32[16,1024]{1,0} negate(f32[16,1024]{1,0} %slice.892.clone.1), metadata={op_type="neg" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/neg" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %exponential.131.clone.1 = f32[16,1024]{1,0} exponential(f32[16,1024]{1,0} %negate.150.clone.1), metadata={op_type="exp" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/exp" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %add.1899.clone.1 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %broadcast.1533.clone.1, f32[16,1024]{1,0} %exponential.131.clone.1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %divide.135.clone.1 = f32[16,1024]{1,0} divide(f32[16,1024]{1,0} %broadcast.1533.clone.1, f32[16,1024]{1,0} %add.1899.clone.1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %multiply.944.clone.1 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %slice.936.clone.1, f32[16,1024]{1,0} %divide.135.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %slice.891.clone.1 = f32[16,1024]{1,0} slice(f32[16,4096]{1,0} %param_1.2663), slice={[0:16], [0:1024]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(16, 1024)\n                                                     start_indices=(0, 0)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  %negate.149.clone.1 = f32[16,1024]{1,0} negate(f32[16,1024]{1,0} %slice.891.clone.1), metadata={op_type="neg" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/neg" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %exponential.130.clone.1 = f32[16,1024]{1,0} exponential(f32[16,1024]{1,0} %negate.149.clone.1), metadata={op_type="exp" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/exp" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %add.1898.clone.1 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %broadcast.1533.clone.1, f32[16,1024]{1,0} %exponential.130.clone.1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %divide.134.clone.1 = f32[16,1024]{1,0} divide(f32[16,1024]{1,0} %broadcast.1533.clone.1, f32[16,1024]{1,0} %add.1898.clone.1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %slice.890.clone.1 = f32[16,1024]{1,0} slice(f32[16,4096]{1,0} %param_1.2663), slice={[0:16], [1024:2048]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(16, 2048)\n                                                     start_indices=(0, 1024)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  %tanh.79.clone.1 = f32[16,1024]{1,0} tanh(f32[16,1024]{1,0} %slice.890.clone.1), metadata={op_type="tanh" op_name="pmap(_multi_device_update_fn)/scan/while/body/tanh" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %multiply.943.clone.1 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %divide.134.clone.1, f32[16,1024]{1,0} %tanh.79.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %add.1897.clone.1 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %multiply.944.clone.1, f32[16,1024]{1,0} %multiply.943.clone.1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %tanh.88 = f32[16,1024]{1,0} tanh(f32[16,1024]{1,0} %add.1897.clone.1), metadata={op_type="tanh" op_name="pmap(_multi_device_update_fn)/scan/while/body/tanh" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  %slice.889.clone.1 = f32[16,1024]{1,0} slice(f32[16,4096]{1,0} %param_1.2663), slice={[0:16], [3072:4096]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(16, 4096)\n                                                     start_indices=(0, 3072)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  %negate.148.clone.1 = f32[16,1024]{1,0} negate(f32[16,1024]{1,0} %slice.889.clone.1), metadata={op_type="neg" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/neg" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %exponential.129.clone.1 = f32[16,1024]{1,0} exponential(f32[16,1024]{1,0} %negate.148.clone.1), metadata={op_type="exp" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/exp" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %add.1896.clone.1 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %broadcast.1533.clone.1, f32[16,1024]{1,0} %exponential.129.clone.1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %divide.133.clone.1 = f32[16,1024]{1,0} divide(f32[16,1024]{1,0} %broadcast.1533.clone.1, f32[16,1024]{1,0} %add.1896.clone.1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  ROOT %tuple.514 = (f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, /*index=5*/f32[16,1024]{1,0}) tuple(f32[16,1024]{1,0} %tanh.88, f32[16,1024]{1,0} %add.1897.clone.1, f32[16,1024]{1,0} %divide.135.clone.1, f32[16,1024]{1,0} %tanh.79.clone.1, f32[16,1024]{1,0} %divide.134.clone.1, /*index=5*/f32[16,1024]{1,0} %divide.133.clone.1)
}

%body_computation__43.6269.clone.clone.clone.clone (parameter.186: (f32[64,16,1024], f32[2048,4096], f32[1,4096], s32[], f32[16,2048], /*index=5*/f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[64,16,2048], f32[64,16,1024], /*index=10*/f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], /*index=15*/f32[64,16,1024], f32[64,16,1024], f32[64,16,1024])) -> (f32[64,16,1024], f32[2048,4096], f32[1,4096], s32[], f32[16,2048], /*index=5*/f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[64,16,2048], f32[64,16,1024], /*index=10*/f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], /*index=15*/f32[64,16,1024], f32[64,16,1024], f32[64,16,1024]) {
  %parameter.186 = (f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) parameter(0)
  %get-tuple-element.6198 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %parameter.186), index=0
  %get-tuple-element.6199 = f32[2048,4096]{1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %parameter.186), index=1
  %get-tuple-element.6200 = f32[1,4096]{1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %parameter.186), index=2
  %get-tuple-element.6214 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %parameter.186), index=16
  %get-tuple-element.6202 = f32[16,2048]{1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %parameter.186), index=4
  %get-tuple-element.6201 = s32[] get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %parameter.186), index=3
  %fusion.265 = f32[16,2048]{1,0} fusion(f32[16,2048]{1,0} %get-tuple-element.6202, f32[64,16,1024]{2,1,0} %get-tuple-element.6198, s32[] %get-tuple-element.6201), kind=kLoop, calls=%fused_computation.265, metadata={op_type="concatenate" op_name="pmap(_multi_device_update_fn)/scan/while/body/concatenate[ dimension=1 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %fusion.264 = f32[16,4096]{1,0} fusion(f32[1,4096]{1,0} %get-tuple-element.6200), kind=kLoop, calls=%fused_computation.264, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %custom-call.134 = f32[16,4096]{1,0} custom-call(f32[16,2048]{1,0} %fusion.265, f32[2048,4096]{1,0} %get-tuple-element.6199, f32[16,4096]{1,0} %fusion.264), custom_call_target="__cublas$gemm", metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}, backend_config="{\"alpha_real\":1,\"alpha_imag\":0,\"beta\":1,\"dot_dimension_numbers\":{\"lhs_contracting_dimensions\":[\"1\"],\"rhs_contracting_dimensions\":[\"0\"],\"lhs_batch_dimensions\":[],\"rhs_batch_dimensions\":[]},\"batch_size\":\"1\",\"selected_algorithm\":\"0\"}"
  %fusion.747 = (f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, /*index=5*/f32[16,1024]{1,0}) fusion(f32[16,2048]{1,0} %get-tuple-element.6202, f32[16,4096]{1,0} %custom-call.134), kind=kLoop, calls=%fused_computation.747, metadata={op_type="tanh" op_name="pmap(_multi_device_update_fn)/scan/while/body/tanh" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  %get-tuple-element.5101 = f32[16,1024]{1,0} get-tuple-element((f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, /*index=5*/f32[16,1024]{1,0}) %fusion.747), index=5
  %fusion.247 = f32[64,16,1024]{2,1,0} fusion(f32[64,16,1024]{2,1,0} %get-tuple-element.6214, f32[16,1024]{1,0} %get-tuple-element.5101, s32[] %get-tuple-element.6201), kind=kLoop, calls=%fused_computation.247, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.6213 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %parameter.186), index=15
  %get-tuple-element.5096 = f32[16,1024]{1,0} get-tuple-element((f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, /*index=5*/f32[16,1024]{1,0}) %fusion.747), index=0
  %fusion.248 = f32[64,16,1024]{2,1,0} fusion(f32[64,16,1024]{2,1,0} %get-tuple-element.6213, f32[16,1024]{1,0} %get-tuple-element.5096, s32[] %get-tuple-element.6201), kind=kLoop, calls=%fused_computation.248, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.6212 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %parameter.186), index=14
  %fusion.249 = f32[64,16,1024]{2,1,0} fusion(f32[64,16,1024]{2,1,0} %get-tuple-element.6212, f32[16,1024]{1,0} %get-tuple-element.5096, s32[] %get-tuple-element.6201), kind=kLoop, calls=%fused_computation.249, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.6211 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %parameter.186), index=13
  %get-tuple-element.5099 = f32[16,1024]{1,0} get-tuple-element((f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, /*index=5*/f32[16,1024]{1,0}) %fusion.747), index=3
  %fusion.250 = f32[64,16,1024]{2,1,0} fusion(f32[64,16,1024]{2,1,0} %get-tuple-element.6211, f32[16,1024]{1,0} %get-tuple-element.5099, s32[] %get-tuple-element.6201), kind=kLoop, calls=%fused_computation.250, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.6210 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %parameter.186), index=12
  %fusion.251 = f32[64,16,1024]{2,1,0} fusion(f32[64,16,1024]{2,1,0} %get-tuple-element.6210, f32[16,1024]{1,0} %get-tuple-element.5099, s32[] %get-tuple-element.6201), kind=kLoop, calls=%fused_computation.251, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.6209 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %parameter.186), index=11
  %get-tuple-element.5100 = f32[16,1024]{1,0} get-tuple-element((f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, /*index=5*/f32[16,1024]{1,0}) %fusion.747), index=4
  %fusion.252 = f32[64,16,1024]{2,1,0} fusion(f32[64,16,1024]{2,1,0} %get-tuple-element.6209, f32[16,1024]{1,0} %get-tuple-element.5100, s32[] %get-tuple-element.6201), kind=kLoop, calls=%fused_computation.252, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.6208 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %parameter.186), index=10
  %fusion.253 = f32[64,16,1024]{2,1,0} fusion(f32[64,16,1024]{2,1,0} %get-tuple-element.6208, f32[16,1024]{1,0} %get-tuple-element.5100, s32[] %get-tuple-element.6201), kind=kLoop, calls=%fused_computation.253, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.6207 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %parameter.186), index=9
  %get-tuple-element.5098 = f32[16,1024]{1,0} get-tuple-element((f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, /*index=5*/f32[16,1024]{1,0}) %fusion.747), index=2
  %fusion.254 = f32[64,16,1024]{2,1,0} fusion(f32[64,16,1024]{2,1,0} %get-tuple-element.6207, f32[16,1024]{1,0} %get-tuple-element.5098, s32[] %get-tuple-element.6201), kind=kLoop, calls=%fused_computation.254, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.6206 = f32[64,16,2048]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %parameter.186), index=8
  %fusion.255 = f32[64,16,2048]{2,1,0} fusion(f32[64,16,2048]{2,1,0} %get-tuple-element.6206, f32[16,2048]{1,0} %fusion.265, s32[] %get-tuple-element.6201), kind=kLoop, calls=%fused_computation.255, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.6205 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %parameter.186), index=7
  %fusion.256 = f32[64,16,1024]{2,1,0} fusion(f32[64,16,1024]{2,1,0} %get-tuple-element.6205, f32[16,2048]{1,0} %get-tuple-element.6202, s32[] %get-tuple-element.6201), kind=kLoop, calls=%fused_computation.256, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.6204 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %parameter.186), index=6
  %fusion.257 = f32[64,16,1024]{2,1,0} fusion(f32[64,16,1024]{2,1,0} %get-tuple-element.6204, f32[16,1024]{1,0} %get-tuple-element.5098, s32[] %get-tuple-element.6201), kind=kLoop, calls=%fused_computation.257, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.6203 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %parameter.186), index=5
  %fusion.258 = f32[64,16,1024]{2,1,0} fusion(f32[64,16,1024]{2,1,0} %get-tuple-element.6203, f32[16,1024]{1,0} %get-tuple-element.5096, f32[16,1024]{1,0} %get-tuple-element.5101, s32[] %get-tuple-element.6201), kind=kLoop, calls=%fused_computation.258, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.6215 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %parameter.186), index=17
  %fusion.246 = f32[64,16,1024]{2,1,0} fusion(f32[64,16,1024]{2,1,0} %get-tuple-element.6215, f32[16,1024]{1,0} %get-tuple-element.5101, s32[] %get-tuple-element.6201), kind=kLoop, calls=%fused_computation.246, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_10398 = s32[] constant(1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.1738 = s32[] add(s32[] %get-tuple-element.6201, s32[] %constant_10398), control-predecessors={%fusion.246, %fusion.265, %fusion.258, %fusion.257, %fusion.256, %fusion.255, %fusion.254, %fusion.253, %fusion.252, %fusion.251, %fusion.250, %fusion.249, %fusion.248, %fusion.247}, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.5097 = f32[16,1024]{1,0} get-tuple-element((f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, /*index=5*/f32[16,1024]{1,0}) %fusion.747), index=1
  %fusion.669 = f32[16,2048]{1,0} fusion(f32[16,1024]{1,0} %get-tuple-element.5097, f32[16,1024]{1,0} %get-tuple-element.5096, f32[16,1024]{1,0} %get-tuple-element.5101), kind=kLoop, calls=%fused_computation.669, control-predecessors={%fusion.265, %fusion.747, %fusion.256}, metadata={op_type="concatenate" op_name="pmap(_multi_device_update_fn)/scan/while/body/concatenate[ dimension=1 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=65}
  ROOT %tuple.808 = (f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) tuple(f32[64,16,1024]{2,1,0} %get-tuple-element.6198, f32[2048,4096]{1,0} %get-tuple-element.6199, f32[1,4096]{1,0} %get-tuple-element.6200, s32[] %add.1738, f32[16,2048]{1,0} %fusion.669, /*index=5*/f32[64,16,1024]{2,1,0} %fusion.258, f32[64,16,1024]{2,1,0} %fusion.257, f32[64,16,1024]{2,1,0} %fusion.256, f32[64,16,2048]{2,1,0} %fusion.255, f32[64,16,1024]{2,1,0} %fusion.254, /*index=10*/f32[64,16,1024]{2,1,0} %fusion.253, f32[64,16,1024]{2,1,0} %fusion.252, f32[64,16,1024]{2,1,0} %fusion.251, f32[64,16,1024]{2,1,0} %fusion.250, f32[64,16,1024]{2,1,0} %fusion.249, /*index=15*/f32[64,16,1024]{2,1,0} %fusion.248, f32[64,16,1024]{2,1,0} %fusion.247, f32[64,16,1024]{2,1,0} %fusion.246)
}

%cond_computation__43.6690.clone.clone.clone (parameter.187: (f32[64,16,1024], f32[2048,4096], f32[1,4096], s32[], f32[16,2048], /*index=5*/f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[64,16,2048], f32[64,16,1024], /*index=10*/f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], /*index=15*/f32[64,16,1024], f32[64,16,1024], f32[64,16,1024])) -> pred[] {
  %parameter.187 = (f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) parameter(0)
  %get-tuple-element.4854 = s32[] get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %parameter.187), index=3
  %constant_10401 = s32[] constant(64), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/cond/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %compare.1360 = pred[] compare(s32[] %get-tuple-element.4854, s32[] %constant_10401), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/cond/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.267 (param_0.415: f32[64,16,1024], param_1.2282: f32[16,1024], param_2.2047: s32[]) -> f32[64,16,1024] {
  %param_0.415 = f32[64,16,1024]{2,1,0} parameter(0)
  %constant_11055 = f32[] constant(1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %broadcast.1535 = f32[16,1024]{1,0} broadcast(f32[] %constant_11055), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %param_1.2282 = f32[16,1024]{1,0} parameter(1)
  %subtract.251 = f32[16,1024]{1,0} subtract(f32[16,1024]{1,0} %broadcast.1535, f32[16,1024]{1,0} %param_1.2282), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %bitcast.653 = f32[1,16,1024]{2,1,0} bitcast(f32[16,1024]{1,0} %subtract.251), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_2.2047 = s32[] parameter(2)
  %constant_11053 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.1973 = pred[] compare(s32[] %param_2.2047, s32[] %constant_11053), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_14348 = s32[] constant(64), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.3030 = s32[] add(s32[] %param_2.2047, s32[] %constant_14348), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %select.1964 = s32[] select(pred[] %compare.1973, s32[] %add.3030, s32[] %param_2.2047), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.604 = f32[64,16,1024]{2,1,0} dynamic-update-slice(f32[64,16,1024]{2,1,0} %param_0.415, f32[1,16,1024]{2,1,0} %bitcast.653, s32[] %select.1964, s32[] %constant_11053, s32[] %constant_11053), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.268 (param_0.416: f32[64,16,1024], param_1.2281: f32[16,1024], param_2.2045: s32[]) -> f32[64,16,1024] {
  %param_0.416 = f32[64,16,1024]{2,1,0} parameter(0)
  %param_1.2281 = f32[16,1024]{1,0} parameter(1)
  %bitcast.654 = f32[1,16,1024]{2,1,0} bitcast(f32[16,1024]{1,0} %param_1.2281), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_2.2045 = s32[] parameter(2)
  %constant_11057 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.1971 = pred[] compare(s32[] %param_2.2045, s32[] %constant_11057), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_14342 = s32[] constant(64), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.3028 = s32[] add(s32[] %param_2.2045, s32[] %constant_14342), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %select.1962 = s32[] select(pred[] %compare.1971, s32[] %add.3028, s32[] %param_2.2045), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.605 = f32[64,16,1024]{2,1,0} dynamic-update-slice(f32[64,16,1024]{2,1,0} %param_0.416, f32[1,16,1024]{2,1,0} %bitcast.654, s32[] %select.1962, s32[] %constant_11057, s32[] %constant_11057), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.269 (param_0.417: f32[64,16,1024], param_1.2280: f32[16,1024], param_2.2043: s32[]) -> f32[64,16,1024] {
  %param_0.417 = f32[64,16,1024]{2,1,0} parameter(0)
  %constant_11061 = f32[] constant(1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %broadcast.1536 = f32[16,1024]{1,0} broadcast(f32[] %constant_11061), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %param_1.2280 = f32[16,1024]{1,0} parameter(1)
  %subtract.252 = f32[16,1024]{1,0} subtract(f32[16,1024]{1,0} %broadcast.1536, f32[16,1024]{1,0} %param_1.2280), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  %bitcast.655 = f32[1,16,1024]{2,1,0} bitcast(f32[16,1024]{1,0} %subtract.252), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_2.2043 = s32[] parameter(2)
  %constant_11058 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.1969 = pred[] compare(s32[] %param_2.2043, s32[] %constant_11058), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_14336 = s32[] constant(64), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.3026 = s32[] add(s32[] %param_2.2043, s32[] %constant_14336), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %select.1960 = s32[] select(pred[] %compare.1969, s32[] %add.3026, s32[] %param_2.2043), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.606 = f32[64,16,1024]{2,1,0} dynamic-update-slice(f32[64,16,1024]{2,1,0} %param_0.417, f32[1,16,1024]{2,1,0} %bitcast.655, s32[] %select.1960, s32[] %constant_11058, s32[] %constant_11058), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.270 (param_0.418: f32[64,16,1024], param_1.2279: f32[16,1024], param_2.2041: s32[]) -> f32[64,16,1024] {
  %param_0.418 = f32[64,16,1024]{2,1,0} parameter(0)
  %param_1.2279 = f32[16,1024]{1,0} parameter(1)
  %bitcast.656 = f32[1,16,1024]{2,1,0} bitcast(f32[16,1024]{1,0} %param_1.2279), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_2.2041 = s32[] parameter(2)
  %constant_11064 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.1967 = pred[] compare(s32[] %param_2.2041, s32[] %constant_11064), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_14331 = s32[] constant(64), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.3024 = s32[] add(s32[] %param_2.2041, s32[] %constant_14331), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %select.1958 = s32[] select(pred[] %compare.1967, s32[] %add.3024, s32[] %param_2.2041), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.607 = f32[64,16,1024]{2,1,0} dynamic-update-slice(f32[64,16,1024]{2,1,0} %param_0.418, f32[1,16,1024]{2,1,0} %bitcast.656, s32[] %select.1958, s32[] %constant_11064, s32[] %constant_11064), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.271 (param_0.419: f32[64,16,1024], param_1.2278: f32[16,1024], param_2.2039: s32[]) -> f32[64,16,1024] {
  %param_0.419 = f32[64,16,1024]{2,1,0} parameter(0)
  %constant_11069 = f32[] constant(1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %broadcast.1537 = f32[16,1024]{1,0} broadcast(f32[] %constant_11069), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %param_1.2278 = f32[16,1024]{1,0} parameter(1)
  %subtract.253 = f32[16,1024]{1,0} subtract(f32[16,1024]{1,0} %broadcast.1537, f32[16,1024]{1,0} %param_1.2278), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %bitcast.657 = f32[1,16,1024]{2,1,0} bitcast(f32[16,1024]{1,0} %subtract.253), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_2.2039 = s32[] parameter(2)
  %constant_11066 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.1965 = pred[] compare(s32[] %param_2.2039, s32[] %constant_11066), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_14325 = s32[] constant(64), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.3022 = s32[] add(s32[] %param_2.2039, s32[] %constant_14325), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %select.1956 = s32[] select(pred[] %compare.1965, s32[] %add.3022, s32[] %param_2.2039), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.608 = f32[64,16,1024]{2,1,0} dynamic-update-slice(f32[64,16,1024]{2,1,0} %param_0.419, f32[1,16,1024]{2,1,0} %bitcast.657, s32[] %select.1956, s32[] %constant_11066, s32[] %constant_11066), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.272 (param_0.420: f32[64,16,1024], param_1.2277: f32[16,1024], param_2.2037: s32[]) -> f32[64,16,1024] {
  %param_0.420 = f32[64,16,1024]{2,1,0} parameter(0)
  %param_1.2277 = f32[16,1024]{1,0} parameter(1)
  %bitcast.658 = f32[1,16,1024]{2,1,0} bitcast(f32[16,1024]{1,0} %param_1.2277), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_2.2037 = s32[] parameter(2)
  %constant_11072 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.1963 = pred[] compare(s32[] %param_2.2037, s32[] %constant_11072), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_14319 = s32[] constant(64), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.3020 = s32[] add(s32[] %param_2.2037, s32[] %constant_14319), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %select.1954 = s32[] select(pred[] %compare.1963, s32[] %add.3020, s32[] %param_2.2037), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.609 = f32[64,16,1024]{2,1,0} dynamic-update-slice(f32[64,16,1024]{2,1,0} %param_0.420, f32[1,16,1024]{2,1,0} %bitcast.658, s32[] %select.1954, s32[] %constant_11072, s32[] %constant_11072), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.273 (param_0.421: f32[64,16,1024], param_1.2276: f32[16,1024], param_2.2035: s32[]) -> f32[64,16,1024] {
  %param_0.421 = f32[64,16,1024]{2,1,0} parameter(0)
  %constant_11075 = f32[] constant(1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %broadcast.1538 = f32[16,1024]{1,0} broadcast(f32[] %constant_11075), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %param_1.2276 = f32[16,1024]{1,0} parameter(1)
  %subtract.254 = f32[16,1024]{1,0} subtract(f32[16,1024]{1,0} %broadcast.1538, f32[16,1024]{1,0} %param_1.2276), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %bitcast.659 = f32[1,16,1024]{2,1,0} bitcast(f32[16,1024]{1,0} %subtract.254), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_2.2035 = s32[] parameter(2)
  %constant_11074 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.1961 = pred[] compare(s32[] %param_2.2035, s32[] %constant_11074), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_14313 = s32[] constant(64), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.3018 = s32[] add(s32[] %param_2.2035, s32[] %constant_14313), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %select.1952 = s32[] select(pred[] %compare.1961, s32[] %add.3018, s32[] %param_2.2035), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.610 = f32[64,16,1024]{2,1,0} dynamic-update-slice(f32[64,16,1024]{2,1,0} %param_0.421, f32[1,16,1024]{2,1,0} %bitcast.659, s32[] %select.1952, s32[] %constant_11074, s32[] %constant_11074), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.274 (param_0.422: f32[64,16,1024], param_1.2275: f32[16,1024], param_2.2033: s32[]) -> f32[64,16,1024] {
  %param_0.422 = f32[64,16,1024]{2,1,0} parameter(0)
  %param_1.2275 = f32[16,1024]{1,0} parameter(1)
  %bitcast.660 = f32[1,16,1024]{2,1,0} bitcast(f32[16,1024]{1,0} %param_1.2275), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_2.2033 = s32[] parameter(2)
  %constant_11076 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.1959 = pred[] compare(s32[] %param_2.2033, s32[] %constant_11076), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_14307 = s32[] constant(64), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.3016 = s32[] add(s32[] %param_2.2033, s32[] %constant_14307), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %select.1950 = s32[] select(pred[] %compare.1959, s32[] %add.3016, s32[] %param_2.2033), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.611 = f32[64,16,1024]{2,1,0} dynamic-update-slice(f32[64,16,1024]{2,1,0} %param_0.422, f32[1,16,1024]{2,1,0} %bitcast.660, s32[] %select.1950, s32[] %constant_11076, s32[] %constant_11076), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.275 (param_0.423: f32[64,16,1024], param_1.2274: f32[16,1024], param_2.2031: s32[]) -> f32[64,16,1024] {
  %param_0.423 = f32[64,16,1024]{2,1,0} parameter(0)
  %constant_11080 = f32[] constant(1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %broadcast.1539 = f32[16,1024]{1,0} broadcast(f32[] %constant_11080), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %param_1.2274 = f32[16,1024]{1,0} parameter(1)
  %subtract.255 = f32[16,1024]{1,0} subtract(f32[16,1024]{1,0} %broadcast.1539, f32[16,1024]{1,0} %param_1.2274), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %bitcast.661 = f32[1,16,1024]{2,1,0} bitcast(f32[16,1024]{1,0} %subtract.255), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_2.2031 = s32[] parameter(2)
  %constant_11078 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.1957 = pred[] compare(s32[] %param_2.2031, s32[] %constant_11078), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_14301 = s32[] constant(64), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.3014 = s32[] add(s32[] %param_2.2031, s32[] %constant_14301), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %select.1948 = s32[] select(pred[] %compare.1957, s32[] %add.3014, s32[] %param_2.2031), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.612 = f32[64,16,1024]{2,1,0} dynamic-update-slice(f32[64,16,1024]{2,1,0} %param_0.423, f32[1,16,1024]{2,1,0} %bitcast.661, s32[] %select.1948, s32[] %constant_11078, s32[] %constant_11078), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.276 (param_0.424: f32[64,16,2048], param_1.2273: f32[16,2048], param_2.2029: s32[]) -> f32[64,16,2048] {
  %param_0.424 = f32[64,16,2048]{2,1,0} parameter(0)
  %param_1.2273 = f32[16,2048]{1,0} parameter(1)
  %bitcast.662 = f32[1,16,2048]{2,1,0} bitcast(f32[16,2048]{1,0} %param_1.2273), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 16, 2048) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_2.2029 = s32[] parameter(2)
  %constant_11081 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.1955 = pred[] compare(s32[] %param_2.2029, s32[] %constant_11081), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_14295 = s32[] constant(64), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.3012 = s32[] add(s32[] %param_2.2029, s32[] %constant_14295), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %select.1946 = s32[] select(pred[] %compare.1955, s32[] %add.3012, s32[] %param_2.2029), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.613 = f32[64,16,2048]{2,1,0} dynamic-update-slice(f32[64,16,2048]{2,1,0} %param_0.424, f32[1,16,2048]{2,1,0} %bitcast.662, s32[] %select.1946, s32[] %constant_11081, s32[] %constant_11081), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.277 (param_0.425: f32[64,16,1024], param_1.2272: f32[16,2048], param_2.2027: s32[]) -> f32[64,16,1024] {
  %param_0.425 = f32[64,16,1024]{2,1,0} parameter(0)
  %param_1.2272 = f32[16,2048]{1,0} parameter(1)
  %slice.937 = f32[16,1024]{1,0} slice(f32[16,2048]{1,0} %param_1.2272), slice={[0:16], [0:1024]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(16, 1024)\n                                                     start_indices=(0, 0)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=54}
  %bitcast.663 = f32[1,16,1024]{2,1,0} bitcast(f32[16,1024]{1,0} %slice.937), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_2.2027 = s32[] parameter(2)
  %constant_11084 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.1953 = pred[] compare(s32[] %param_2.2027, s32[] %constant_11084), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_14290 = s32[] constant(64), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.3010 = s32[] add(s32[] %param_2.2027, s32[] %constant_14290), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %select.1944 = s32[] select(pred[] %compare.1953, s32[] %add.3010, s32[] %param_2.2027), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.614 = f32[64,16,1024]{2,1,0} dynamic-update-slice(f32[64,16,1024]{2,1,0} %param_0.425, f32[1,16,1024]{2,1,0} %bitcast.663, s32[] %select.1944, s32[] %constant_11084, s32[] %constant_11084), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.278 (param_0.426: f32[64,16,1024], param_1.2271: f32[16,1024], param_2.2025: s32[]) -> f32[64,16,1024] {
  %param_0.426 = f32[64,16,1024]{2,1,0} parameter(0)
  %param_1.2271 = f32[16,1024]{1,0} parameter(1)
  %bitcast.664 = f32[1,16,1024]{2,1,0} bitcast(f32[16,1024]{1,0} %param_1.2271), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_2.2025 = s32[] parameter(2)
  %constant_11087 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.1951 = pred[] compare(s32[] %param_2.2025, s32[] %constant_11087), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_14284 = s32[] constant(64), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.3008 = s32[] add(s32[] %param_2.2025, s32[] %constant_14284), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %select.1942 = s32[] select(pred[] %compare.1951, s32[] %add.3008, s32[] %param_2.2025), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.615 = f32[64,16,1024]{2,1,0} dynamic-update-slice(f32[64,16,1024]{2,1,0} %param_0.426, f32[1,16,1024]{2,1,0} %bitcast.664, s32[] %select.1942, s32[] %constant_11087, s32[] %constant_11087), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.279 (param_0.427: f32[64,16,1024], param_1.2270: f32[16,1024], param_2.2023: f32[16,1024], param_3.1860: s32[]) -> f32[64,16,1024] {
  %param_0.427 = f32[64,16,1024]{2,1,0} parameter(0)
  %param_1.2270 = f32[16,1024]{1,0} parameter(1)
  %param_2.2023 = f32[16,1024]{1,0} parameter(2)
  %multiply.1394 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %param_1.2270, f32[16,1024]{1,0} %param_2.2023), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  %bitcast.665 = f32[1,16,1024]{2,1,0} bitcast(f32[16,1024]{1,0} %multiply.1394), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_3.1860 = s32[] parameter(3)
  %constant_11089 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.1949 = pred[] compare(s32[] %param_3.1860, s32[] %constant_11089), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_14278 = s32[] constant(64), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.3006 = s32[] add(s32[] %param_3.1860, s32[] %constant_14278), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %select.1940 = s32[] select(pred[] %compare.1949, s32[] %add.3006, s32[] %param_3.1860), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.616 = f32[64,16,1024]{2,1,0} dynamic-update-slice(f32[64,16,1024]{2,1,0} %param_0.427, f32[1,16,1024]{2,1,0} %bitcast.665, s32[] %select.1940, s32[] %constant_11089, s32[] %constant_11089), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.285 (param_0.436: f32[1,4096]) -> f32[16,4096] {
  %param_0.436 = f32[1,4096]{1,0} parameter(0)
  %bitcast.666 = f32[4096]{0} bitcast(f32[1,4096]{1,0} %param_0.436), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  ROOT %broadcast.1283 = f32[16,4096]{1,0} broadcast(f32[4096]{0} %bitcast.666), dimensions={1}, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
}

%fused_computation.286 (param_0.438: f32[16,2048], param_1.734: f32[64,16,1024], param_2.2022: s32[]) -> f32[16,2048] {
  %param_1.734 = f32[64,16,1024]{2,1,0} parameter(1)
  %param_2.2022 = s32[] parameter(2)
  %constant_11098 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.1947 = pred[] compare(s32[] %param_2.2022, s32[] %constant_11098), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_14271 = s32[] constant(64), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.3004 = s32[] add(s32[] %param_2.2022, s32[] %constant_14271), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %select.1938 = s32[] select(pred[] %compare.1947, s32[] %add.3004, s32[] %param_2.2022), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %dynamic-slice.410 = f32[1,16,1024]{2,1,0} dynamic-slice(f32[64,16,1024]{2,1,0} %param_1.734, s32[] %select.1938, s32[] %constant_11098, s32[] %constant_11098), dynamic_slice_sizes={1,16,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %bitcast.667 = f32[16,1024]{1,0} bitcast(f32[1,16,1024]{2,1,0} %dynamic-slice.410), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_0.438 = f32[16,2048]{1,0} parameter(0)
  %slice.898 = f32[16,1024]{1,0} slice(f32[16,2048]{1,0} %param_0.438), slice={[0:16], [1024:2048]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(16, 2048)\n                                                     start_indices=(0, 1024)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=54}
  ROOT %concatenate.198 = f32[16,2048]{1,0} concatenate(f32[16,1024]{1,0} %bitcast.667, f32[16,1024]{1,0} %slice.898), dimensions={1}, metadata={op_type="concatenate" op_name="pmap(_multi_device_update_fn)/scan/while/body/concatenate[ dimension=1 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
}

%fused_computation.670 (param_0.1275: f32[16,1024], param_1.1614: f32[16,1024], param_2.1126: f32[16,1024]) -> f32[16,2048] {
  %param_0.1275 = f32[16,1024]{1,0} parameter(0)
  %param_1.1614 = f32[16,1024]{1,0} parameter(1)
  %param_2.1126 = f32[16,1024]{1,0} parameter(2)
  %multiply.1395 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %param_1.1614, f32[16,1024]{1,0} %param_2.1126), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  ROOT %concatenate.213 = f32[16,2048]{1,0} concatenate(f32[16,1024]{1,0} %param_0.1275, f32[16,1024]{1,0} %multiply.1395), dimensions={1}, metadata={op_type="concatenate" op_name="pmap(_multi_device_update_fn)/scan/while/body/concatenate[ dimension=1 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=65}
}

%fused_computation.748 (param_0.2204: f32[16,2048], param_1.2668: f32[16,4096]) -> (f32[16,1024], f32[16,1024], f32[16,1024], f32[16,1024], f32[16,1024], /*index=5*/f32[16,1024]) {
  %param_0.2204 = f32[16,2048]{1,0} parameter(0)
  %slice.938.clone.1 = f32[16,1024]{1,0} slice(f32[16,2048]{1,0} %param_0.2204), slice={[0:16], [0:1024]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(16, 1024)\n                                                     start_indices=(0, 0)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=54}
  %constant_11095_clone_1 = f32[] constant(1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %broadcast.1541.clone.1 = f32[16,1024]{1,0} broadcast(f32[] %constant_11095_clone_1), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %param_1.2668 = f32[16,4096]{1,0} parameter(1)
  %slice.897.clone.1 = f32[16,1024]{1,0} slice(f32[16,4096]{1,0} %param_1.2668), slice={[0:16], [2048:3072]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(16, 3072)\n                                                     start_indices=(0, 2048)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  %negate.153.clone.1 = f32[16,1024]{1,0} negate(f32[16,1024]{1,0} %slice.897.clone.1), metadata={op_type="neg" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/neg" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %exponential.134.clone.1 = f32[16,1024]{1,0} exponential(f32[16,1024]{1,0} %negate.153.clone.1), metadata={op_type="exp" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/exp" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %add.1905.clone.1 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %broadcast.1541.clone.1, f32[16,1024]{1,0} %exponential.134.clone.1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %divide.138.clone.1 = f32[16,1024]{1,0} divide(f32[16,1024]{1,0} %broadcast.1541.clone.1, f32[16,1024]{1,0} %add.1905.clone.1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %multiply.946.clone.1 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %slice.938.clone.1, f32[16,1024]{1,0} %divide.138.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %slice.896.clone.1 = f32[16,1024]{1,0} slice(f32[16,4096]{1,0} %param_1.2668), slice={[0:16], [0:1024]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(16, 1024)\n                                                     start_indices=(0, 0)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  %negate.152.clone.1 = f32[16,1024]{1,0} negate(f32[16,1024]{1,0} %slice.896.clone.1), metadata={op_type="neg" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/neg" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %exponential.133.clone.1 = f32[16,1024]{1,0} exponential(f32[16,1024]{1,0} %negate.152.clone.1), metadata={op_type="exp" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/exp" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %add.1904.clone.1 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %broadcast.1541.clone.1, f32[16,1024]{1,0} %exponential.133.clone.1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %divide.137.clone.1 = f32[16,1024]{1,0} divide(f32[16,1024]{1,0} %broadcast.1541.clone.1, f32[16,1024]{1,0} %add.1904.clone.1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %slice.895.clone.1 = f32[16,1024]{1,0} slice(f32[16,4096]{1,0} %param_1.2668), slice={[0:16], [1024:2048]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(16, 2048)\n                                                     start_indices=(0, 1024)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  %tanh.80.clone.1 = f32[16,1024]{1,0} tanh(f32[16,1024]{1,0} %slice.895.clone.1), metadata={op_type="tanh" op_name="pmap(_multi_device_update_fn)/scan/while/body/tanh" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %multiply.945.clone.1 = f32[16,1024]{1,0} multiply(f32[16,1024]{1,0} %divide.137.clone.1, f32[16,1024]{1,0} %tanh.80.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %add.1903.clone.1 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %multiply.946.clone.1, f32[16,1024]{1,0} %multiply.945.clone.1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %tanh.89 = f32[16,1024]{1,0} tanh(f32[16,1024]{1,0} %add.1903.clone.1), metadata={op_type="tanh" op_name="pmap(_multi_device_update_fn)/scan/while/body/tanh" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  %slice.894.clone.1 = f32[16,1024]{1,0} slice(f32[16,4096]{1,0} %param_1.2668), slice={[0:16], [3072:4096]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(16, 4096)\n                                                     start_indices=(0, 3072)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  %negate.151.clone.1 = f32[16,1024]{1,0} negate(f32[16,1024]{1,0} %slice.894.clone.1), metadata={op_type="neg" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/neg" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %exponential.132.clone.1 = f32[16,1024]{1,0} exponential(f32[16,1024]{1,0} %negate.151.clone.1), metadata={op_type="exp" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/exp" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %add.1901.clone.1 = f32[16,1024]{1,0} add(f32[16,1024]{1,0} %broadcast.1541.clone.1, f32[16,1024]{1,0} %exponential.132.clone.1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %divide.136.clone.1 = f32[16,1024]{1,0} divide(f32[16,1024]{1,0} %broadcast.1541.clone.1, f32[16,1024]{1,0} %add.1901.clone.1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  ROOT %tuple.519 = (f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, /*index=5*/f32[16,1024]{1,0}) tuple(f32[16,1024]{1,0} %tanh.89, f32[16,1024]{1,0} %add.1903.clone.1, f32[16,1024]{1,0} %divide.138.clone.1, f32[16,1024]{1,0} %tanh.80.clone.1, f32[16,1024]{1,0} %divide.137.clone.1, /*index=5*/f32[16,1024]{1,0} %divide.136.clone.1)
}

%body_computation__44.6949.clone.clone.clone.clone (parameter.188: (f32[64,16,1024], f32[2048,4096], f32[1,4096], s32[], f32[16,2048], /*index=5*/f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[64,16,2048], f32[64,16,1024], /*index=10*/f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], /*index=15*/f32[64,16,1024], f32[64,16,1024], f32[64,16,1024])) -> (f32[64,16,1024], f32[2048,4096], f32[1,4096], s32[], f32[16,2048], /*index=5*/f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[64,16,2048], f32[64,16,1024], /*index=10*/f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], /*index=15*/f32[64,16,1024], f32[64,16,1024], f32[64,16,1024]) {
  %parameter.188 = (f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) parameter(0)
  %get-tuple-element.6258 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %parameter.188), index=0
  %get-tuple-element.6259 = f32[2048,4096]{1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %parameter.188), index=1
  %get-tuple-element.6260 = f32[1,4096]{1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %parameter.188), index=2
  %get-tuple-element.6296 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %parameter.188), index=16
  %get-tuple-element.6262 = f32[16,2048]{1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %parameter.188), index=4
  %get-tuple-element.6261 = s32[] get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %parameter.188), index=3
  %fusion.286 = f32[16,2048]{1,0} fusion(f32[16,2048]{1,0} %get-tuple-element.6262, f32[64,16,1024]{2,1,0} %get-tuple-element.6258, s32[] %get-tuple-element.6261), kind=kLoop, calls=%fused_computation.286, metadata={op_type="concatenate" op_name="pmap(_multi_device_update_fn)/scan/while/body/concatenate[ dimension=1 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %fusion.285 = f32[16,4096]{1,0} fusion(f32[1,4096]{1,0} %get-tuple-element.6260), kind=kLoop, calls=%fused_computation.285, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %custom-call.136 = f32[16,4096]{1,0} custom-call(f32[16,2048]{1,0} %fusion.286, f32[2048,4096]{1,0} %get-tuple-element.6259, f32[16,4096]{1,0} %fusion.285), custom_call_target="__cublas$gemm", metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}, backend_config="{\"alpha_real\":1,\"alpha_imag\":0,\"beta\":1,\"dot_dimension_numbers\":{\"lhs_contracting_dimensions\":[\"1\"],\"rhs_contracting_dimensions\":[\"0\"],\"lhs_batch_dimensions\":[],\"rhs_batch_dimensions\":[]},\"batch_size\":\"1\",\"selected_algorithm\":\"0\"}"
  %fusion.748 = (f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, /*index=5*/f32[16,1024]{1,0}) fusion(f32[16,2048]{1,0} %get-tuple-element.6262, f32[16,4096]{1,0} %custom-call.136), kind=kLoop, calls=%fused_computation.748, metadata={op_type="tanh" op_name="pmap(_multi_device_update_fn)/scan/while/body/tanh" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  %get-tuple-element.5107 = f32[16,1024]{1,0} get-tuple-element((f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, /*index=5*/f32[16,1024]{1,0}) %fusion.748), index=5
  %fusion.268 = f32[64,16,1024]{2,1,0} fusion(f32[64,16,1024]{2,1,0} %get-tuple-element.6296, f32[16,1024]{1,0} %get-tuple-element.5107, s32[] %get-tuple-element.6261), kind=kLoop, calls=%fused_computation.268, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.6295 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %parameter.188), index=15
  %get-tuple-element.5102 = f32[16,1024]{1,0} get-tuple-element((f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, /*index=5*/f32[16,1024]{1,0}) %fusion.748), index=0
  %fusion.269 = f32[64,16,1024]{2,1,0} fusion(f32[64,16,1024]{2,1,0} %get-tuple-element.6295, f32[16,1024]{1,0} %get-tuple-element.5102, s32[] %get-tuple-element.6261), kind=kLoop, calls=%fused_computation.269, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.6294 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %parameter.188), index=14
  %fusion.270 = f32[64,16,1024]{2,1,0} fusion(f32[64,16,1024]{2,1,0} %get-tuple-element.6294, f32[16,1024]{1,0} %get-tuple-element.5102, s32[] %get-tuple-element.6261), kind=kLoop, calls=%fused_computation.270, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.6293 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %parameter.188), index=13
  %get-tuple-element.5105 = f32[16,1024]{1,0} get-tuple-element((f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, /*index=5*/f32[16,1024]{1,0}) %fusion.748), index=3
  %fusion.271 = f32[64,16,1024]{2,1,0} fusion(f32[64,16,1024]{2,1,0} %get-tuple-element.6293, f32[16,1024]{1,0} %get-tuple-element.5105, s32[] %get-tuple-element.6261), kind=kLoop, calls=%fused_computation.271, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.6270 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %parameter.188), index=12
  %fusion.272 = f32[64,16,1024]{2,1,0} fusion(f32[64,16,1024]{2,1,0} %get-tuple-element.6270, f32[16,1024]{1,0} %get-tuple-element.5105, s32[] %get-tuple-element.6261), kind=kLoop, calls=%fused_computation.272, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.6269 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %parameter.188), index=11
  %get-tuple-element.5106 = f32[16,1024]{1,0} get-tuple-element((f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, /*index=5*/f32[16,1024]{1,0}) %fusion.748), index=4
  %fusion.273 = f32[64,16,1024]{2,1,0} fusion(f32[64,16,1024]{2,1,0} %get-tuple-element.6269, f32[16,1024]{1,0} %get-tuple-element.5106, s32[] %get-tuple-element.6261), kind=kLoop, calls=%fused_computation.273, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.6268 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %parameter.188), index=10
  %fusion.274 = f32[64,16,1024]{2,1,0} fusion(f32[64,16,1024]{2,1,0} %get-tuple-element.6268, f32[16,1024]{1,0} %get-tuple-element.5106, s32[] %get-tuple-element.6261), kind=kLoop, calls=%fused_computation.274, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.6267 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %parameter.188), index=9
  %get-tuple-element.5104 = f32[16,1024]{1,0} get-tuple-element((f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, /*index=5*/f32[16,1024]{1,0}) %fusion.748), index=2
  %fusion.275 = f32[64,16,1024]{2,1,0} fusion(f32[64,16,1024]{2,1,0} %get-tuple-element.6267, f32[16,1024]{1,0} %get-tuple-element.5104, s32[] %get-tuple-element.6261), kind=kLoop, calls=%fused_computation.275, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.6266 = f32[64,16,2048]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %parameter.188), index=8
  %fusion.276 = f32[64,16,2048]{2,1,0} fusion(f32[64,16,2048]{2,1,0} %get-tuple-element.6266, f32[16,2048]{1,0} %fusion.286, s32[] %get-tuple-element.6261), kind=kLoop, calls=%fused_computation.276, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.6265 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %parameter.188), index=7
  %fusion.277 = f32[64,16,1024]{2,1,0} fusion(f32[64,16,1024]{2,1,0} %get-tuple-element.6265, f32[16,2048]{1,0} %get-tuple-element.6262, s32[] %get-tuple-element.6261), kind=kLoop, calls=%fused_computation.277, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.6264 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %parameter.188), index=6
  %fusion.278 = f32[64,16,1024]{2,1,0} fusion(f32[64,16,1024]{2,1,0} %get-tuple-element.6264, f32[16,1024]{1,0} %get-tuple-element.5104, s32[] %get-tuple-element.6261), kind=kLoop, calls=%fused_computation.278, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.6263 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %parameter.188), index=5
  %fusion.279 = f32[64,16,1024]{2,1,0} fusion(f32[64,16,1024]{2,1,0} %get-tuple-element.6263, f32[16,1024]{1,0} %get-tuple-element.5102, f32[16,1024]{1,0} %get-tuple-element.5107, s32[] %get-tuple-element.6261), kind=kLoop, calls=%fused_computation.279, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.6297 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %parameter.188), index=17
  %fusion.267 = f32[64,16,1024]{2,1,0} fusion(f32[64,16,1024]{2,1,0} %get-tuple-element.6297, f32[16,1024]{1,0} %get-tuple-element.5107, s32[] %get-tuple-element.6261), kind=kLoop, calls=%fused_computation.267, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant_10495 = s32[] constant(1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.1758 = s32[] add(s32[] %get-tuple-element.6261, s32[] %constant_10495), control-predecessors={%fusion.267, %fusion.286, %fusion.279, %fusion.278, %fusion.277, %fusion.276, %fusion.275, %fusion.274, %fusion.273, %fusion.272, %fusion.271, %fusion.270, %fusion.269, %fusion.268}, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.5103 = f32[16,1024]{1,0} get-tuple-element((f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, f32[16,1024]{1,0}, /*index=5*/f32[16,1024]{1,0}) %fusion.748), index=1
  %fusion.670 = f32[16,2048]{1,0} fusion(f32[16,1024]{1,0} %get-tuple-element.5103, f32[16,1024]{1,0} %get-tuple-element.5102, f32[16,1024]{1,0} %get-tuple-element.5107), kind=kLoop, calls=%fused_computation.670, control-predecessors={%fusion.286, %fusion.748, %fusion.277}, metadata={op_type="concatenate" op_name="pmap(_multi_device_update_fn)/scan/while/body/concatenate[ dimension=1 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=65}
  ROOT %tuple.811 = (f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) tuple(f32[64,16,1024]{2,1,0} %get-tuple-element.6258, f32[2048,4096]{1,0} %get-tuple-element.6259, f32[1,4096]{1,0} %get-tuple-element.6260, s32[] %add.1758, f32[16,2048]{1,0} %fusion.670, /*index=5*/f32[64,16,1024]{2,1,0} %fusion.279, f32[64,16,1024]{2,1,0} %fusion.278, f32[64,16,1024]{2,1,0} %fusion.277, f32[64,16,2048]{2,1,0} %fusion.276, f32[64,16,1024]{2,1,0} %fusion.275, /*index=10*/f32[64,16,1024]{2,1,0} %fusion.274, f32[64,16,1024]{2,1,0} %fusion.273, f32[64,16,1024]{2,1,0} %fusion.272, f32[64,16,1024]{2,1,0} %fusion.271, f32[64,16,1024]{2,1,0} %fusion.270, /*index=15*/f32[64,16,1024]{2,1,0} %fusion.269, f32[64,16,1024]{2,1,0} %fusion.268, f32[64,16,1024]{2,1,0} %fusion.267)
}

%cond_computation__44.7370.clone.clone.clone (parameter.189: (f32[64,16,1024], f32[2048,4096], f32[1,4096], s32[], f32[16,2048], /*index=5*/f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[64,16,2048], f32[64,16,1024], /*index=10*/f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], f32[64,16,1024], /*index=15*/f32[64,16,1024], f32[64,16,1024], f32[64,16,1024])) -> pred[] {
  %parameter.189 = (f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) parameter(0)
  %get-tuple-element.4994 = s32[] get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %parameter.189), index=3
  %constant_10500 = s32[] constant(64), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/cond/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %compare.1377 = pred[] compare(s32[] %get-tuple-element.4994, s32[] %constant_10500), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/cond/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%primitive_computation_add__1.7651 (parameter.7652: f32[], parameter.7653: f32[]) -> f32[] {
  %parameter.7652 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.7653 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.7654 = f32[] add(f32[] %parameter.7652, f32[] %parameter.7653), metadata={op_type="add" op_name="add"}
}

%fused_computation.290 (param_0.1908: f32[16,64], param_1.2366: s32[16,64], param_2.2118: f32[16,64], param_3.1949: f32[16,64], param_4.1007: f32[256], param_5.471: f32[1024,256], param_6.426: f32[16,64]) -> f32[16,64] {
  %param_1.2366 = s32[16,64]{1,0} parameter(1)
  %broadcast.1824 = s32[16,64,256]{2,1,0} broadcast(s32[16,64]{1,0} %param_1.2366), dimensions={0,1}, metadata={op_type="eq" op_name="pmap(_multi_device_update_fn)/eq" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/core.py" source_line=776}
  %iota.66 = s32[16,64,256]{2,1,0} iota(), iota_dimension=2, metadata={op_type="eq" op_name="pmap(_multi_device_update_fn)/eq" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/core.py" source_line=776}
  %compare.1975 = pred[16,64,256]{2,1,0} compare(s32[16,64,256]{2,1,0} %broadcast.1824, s32[16,64,256]{2,1,0} %iota.66), direction=EQ, metadata={op_type="eq" op_name="pmap(_multi_device_update_fn)/eq" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/core.py" source_line=776}
  %param_5.471 = f32[1024,256]{1,0} parameter(5)
  %bitcast.1003 = f32[16,64,256]{2,1,0} bitcast(f32[1024,256]{1,0} %param_5.471), metadata={op_type="dot_general" op_name="pmap(_multi_device_update_fn)/dot_general[ dimension_numbers=(((2,), (0,)), ((), ()))\n                                           precision=None\n                                           preferred_element_type=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/core.py" source_line=96}
  %param_4.1007 = f32[256]{0} parameter(4)
  %broadcast.1924 = f32[16,64,256]{2,1,0} broadcast(f32[256]{0} %param_4.1007), dimensions={2}, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/core.py" source_line=96}
  %add.3044 = f32[16,64,256]{2,1,0} add(f32[16,64,256]{2,1,0} %bitcast.1003, f32[16,64,256]{2,1,0} %broadcast.1924), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/core.py" source_line=96}
  %param_3.1949 = f32[16,64]{1,0} parameter(3)
  %bitcast.1002 = f32[16,64,1]{1,0,2} bitcast(f32[16,64]{1,0} %param_3.1949), metadata={op_type="log" op_name="pmap(_multi_device_update_fn)/log" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=94}
  %param_2.2118 = f32[16,64]{1,0} parameter(2)
  %bitcast.1001 = f32[16,64,1]{1,0,2} bitcast(f32[16,64]{1,0} %param_2.2118), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/broadcast_in_dim[ broadcast_dimensions=(0, 1)\n                                                shape=(16, 64, 1) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=94}
  %is-finite.14 = pred[16,64,1]{1,0,2} is-finite(f32[16,64,1]{1,0,2} %bitcast.1001), metadata={op_type="is_finite" op_name="pmap(_multi_device_update_fn)/is_finite" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=94}
  %constant_11107 = f32[] constant(0)
  %broadcast.1923 = f32[16,64,1]{1,0,2} broadcast(f32[] %constant_11107), dimensions={}, metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/broadcast_in_dim[ broadcast_dimensions=(  )\n                                                shape=(16, 64, 1) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=94}
  %select.1987 = f32[16,64,1]{1,0,2} select(pred[16,64,1]{1,0,2} %is-finite.14, f32[16,64,1]{1,0,2} %bitcast.1001, f32[16,64,1]{1,0,2} %broadcast.1923), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=94}
  %add.3043 = f32[16,64,1]{1,0,2} add(f32[16,64,1]{1,0,2} %bitcast.1002, f32[16,64,1]{1,0,2} %select.1987), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=94}
  %bitcast.1000 = f32[16,64]{1,0} bitcast(f32[16,64,1]{1,0,2} %add.3043), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/core.py" source_line=794}
  %broadcast.1921 = f32[16,64,256]{2,1,0} broadcast(f32[16,64]{1,0} %bitcast.1000), dimensions={0,1}, metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/core.py" source_line=794}
  %subtract.620 = f32[16,64,256]{2,1,0} subtract(f32[16,64,256]{2,1,0} %add.3044, f32[16,64,256]{2,1,0} %broadcast.1921), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/core.py" source_line=794}
  %param_0.1908 = f32[16,64]{1,0} parameter(0)
  %bitcast.670 = f32[16,64,1]{1,0,2} bitcast(f32[16,64]{1,0} %param_0.1908), metadata={op_type="log" op_name="pmap(_multi_device_update_fn)/log" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=94}
  %param_6.426 = f32[16,64]{1,0} parameter(6)
  %bitcast.1015 = f32[16,64,1]{1,0,2} bitcast(f32[16,64]{1,0} %param_6.426), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/broadcast_in_dim[ broadcast_dimensions=(0, 1)\n                                                shape=(16, 64, 1) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=94}
  %is-finite.20 = pred[16,64,1]{1,0,2} is-finite(f32[16,64,1]{1,0,2} %bitcast.1015), metadata={op_type="is_finite" op_name="pmap(_multi_device_update_fn)/is_finite" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=94}
  %select.1994 = f32[16,64,1]{1,0,2} select(pred[16,64,1]{1,0,2} %is-finite.20, f32[16,64,1]{1,0,2} %bitcast.1015, f32[16,64,1]{1,0,2} %broadcast.1923), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=94}
  %add.1939 = f32[16,64,1]{1,0,2} add(f32[16,64,1]{1,0,2} %bitcast.670, f32[16,64,1]{1,0,2} %select.1994), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=94}
  %bitcast.669 = f32[16,64]{1,0} bitcast(f32[16,64,1]{1,0,2} %add.1939), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/core.py" source_line=794}
  %broadcast.1285 = f32[16,64,256]{2,1,0} broadcast(f32[16,64]{1,0} %bitcast.669), dimensions={0,1}, metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/core.py" source_line=794}
  %subtract.256 = f32[16,64,256]{2,1,0} subtract(f32[16,64,256]{2,1,0} %subtract.620, f32[16,64,256]{2,1,0} %broadcast.1285), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/core.py" source_line=794}
  %broadcast.1544 = f32[16,64,256]{2,1,0} broadcast(f32[] %constant_11107), dimensions={}
  %select.1384 = f32[16,64,256]{2,1,0} select(pred[16,64,256]{2,1,0} %compare.1975, f32[16,64,256]{2,1,0} %subtract.256, f32[16,64,256]{2,1,0} %broadcast.1544), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/metrics.py" source_line=581}
  ROOT %reduce.183 = f32[16,64]{1,0} reduce(f32[16,64,256]{2,1,0} %select.1384, f32[] %constant_11107), dimensions={2}, to_apply=%primitive_computation_add__1.7651, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(2,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/metrics.py" source_line=581}
}

%fused_computation.291 (param_0.450: f32[], param_1.749: f32[], param_2.513: f32[], param_3.458: f32[], param_4.127: f32[], param_5.61: f32[], param_6.59: f32[], param_7.59: f32[], param_8.68: f32[], param_9.68: f32[], param_10.86: f32[], param_11.113: f32[], param_12.68: f32[], param_13.41: f32[], param_14.14: f32[], param_15.5: f32[], param_16.5: f32[], param_17.5: f32[], param_18.5: f32[], param_19.5: f32[], param_20.5: f32[], param_21.5: f32[], param_22.5: f32[], param_23.5: f32[], param_24.5: f32[], param_25.5: f32[], param_26.5: f32[], param_27.5: f32[], param_28.3: f32[], param_29.1: f32[]) -> f32[] {
  %param_28.3 = f32[] parameter(28)
  %param_29.1 = f32[] parameter(29)
  %add.1971 = f32[] add(f32[] %param_28.3, f32[] %param_29.1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %param_27.5 = f32[] parameter(27)
  %add.1970 = f32[] add(f32[] %add.1971, f32[] %param_27.5), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %param_26.5 = f32[] parameter(26)
  %add.1969 = f32[] add(f32[] %add.1970, f32[] %param_26.5), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %param_25.5 = f32[] parameter(25)
  %add.1968 = f32[] add(f32[] %add.1969, f32[] %param_25.5), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %param_24.5 = f32[] parameter(24)
  %add.1967 = f32[] add(f32[] %add.1968, f32[] %param_24.5), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %param_23.5 = f32[] parameter(23)
  %add.1966 = f32[] add(f32[] %add.1967, f32[] %param_23.5), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %param_22.5 = f32[] parameter(22)
  %add.1965 = f32[] add(f32[] %add.1966, f32[] %param_22.5), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %param_21.5 = f32[] parameter(21)
  %add.1964 = f32[] add(f32[] %add.1965, f32[] %param_21.5), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %param_20.5 = f32[] parameter(20)
  %add.1963 = f32[] add(f32[] %add.1964, f32[] %param_20.5), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %param_19.5 = f32[] parameter(19)
  %add.1962 = f32[] add(f32[] %add.1963, f32[] %param_19.5), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %param_18.5 = f32[] parameter(18)
  %add.1961 = f32[] add(f32[] %add.1962, f32[] %param_18.5), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %param_17.5 = f32[] parameter(17)
  %add.1960 = f32[] add(f32[] %add.1961, f32[] %param_17.5), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %param_16.5 = f32[] parameter(16)
  %add.1958 = f32[] add(f32[] %add.1960, f32[] %param_16.5), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %param_15.5 = f32[] parameter(15)
  %add.1957 = f32[] add(f32[] %add.1958, f32[] %param_15.5), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %param_14.14 = f32[] parameter(14)
  %add.1956 = f32[] add(f32[] %add.1957, f32[] %param_14.14), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %param_13.41 = f32[] parameter(13)
  %add.1955 = f32[] add(f32[] %add.1956, f32[] %param_13.41), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %param_12.68 = f32[] parameter(12)
  %add.1954 = f32[] add(f32[] %add.1955, f32[] %param_12.68), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %param_11.113 = f32[] parameter(11)
  %add.1953 = f32[] add(f32[] %add.1954, f32[] %param_11.113), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %param_10.86 = f32[] parameter(10)
  %add.1952 = f32[] add(f32[] %add.1953, f32[] %param_10.86), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %param_9.68 = f32[] parameter(9)
  %add.1951 = f32[] add(f32[] %add.1952, f32[] %param_9.68), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %param_8.68 = f32[] parameter(8)
  %add.1949 = f32[] add(f32[] %add.1951, f32[] %param_8.68), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %param_7.59 = f32[] parameter(7)
  %add.1948 = f32[] add(f32[] %add.1949, f32[] %param_7.59), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %param_6.59 = f32[] parameter(6)
  %add.1947 = f32[] add(f32[] %add.1948, f32[] %param_6.59), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %param_5.61 = f32[] parameter(5)
  %add.1946 = f32[] add(f32[] %add.1947, f32[] %param_5.61), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %param_4.127 = f32[] parameter(4)
  %add.1945 = f32[] add(f32[] %add.1946, f32[] %param_4.127), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %param_3.458 = f32[] parameter(3)
  %add.1944 = f32[] add(f32[] %add.1945, f32[] %param_3.458), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %param_2.513 = f32[] parameter(2)
  %add.1943 = f32[] add(f32[] %add.1944, f32[] %param_2.513), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %param_1.749 = f32[] parameter(1)
  %add.1941 = f32[] add(f32[] %add.1943, f32[] %param_1.749), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %param_0.450 = f32[] parameter(0)
  %add.1940 = f32[] add(f32[] %add.1941, f32[] %param_0.450), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  ROOT %sqrt.1 = f32[] sqrt(f32[] %add.1940), metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
}

%scalar_add_computation (scalar_lhs: f32[], scalar_rhs: f32[]) -> f32[] {
  %scalar_lhs = f32[] parameter(0)
  %scalar_rhs = f32[] parameter(1)
  ROOT %add.25 = f32[] add(f32[] %scalar_lhs, f32[] %scalar_rhs)
}

%primitive_computation_add__1.15973 (parameter.15974: f32[], parameter.15975: f32[]) -> f32[] {
  %parameter.15974 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.15975 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.15976 = f32[] add(f32[] %parameter.15974, f32[] %parameter.15975), metadata={op_type="add" op_name="add"}
}

%fused_computation.292 (param_0.2163: f32[1024,256], param_1.2687: f32[256], param_2.2442: f32[1024]) -> (f32[], f32[]) {
  %param_0.2163 = f32[1024,256]{1,0} parameter(0)
  %constant_14910 = f32[] constant(0.125)
  %broadcast.2304 = f32[1024,256]{1,0} broadcast(f32[] %constant_14910), dimensions={}
  %multiply.1927 = f32[1024,256]{1,0} multiply(f32[1024,256]{1,0} %param_0.2163, f32[1024,256]{1,0} %broadcast.2304), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=200}
  %multiply.1925 = f32[1024,256]{1,0} multiply(f32[1024,256]{1,0} %multiply.1927, f32[1024,256]{1,0} %multiply.1927), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=126}
  %bitcast.671 = f32[262144]{0} bitcast(f32[1024,256]{1,0} %multiply.1925)
  %constant_11195 = f32[] constant(0)
  %reduce.184 = f32[] reduce(f32[262144]{0} %bitcast.671, f32[] %constant_11195), dimensions={0}, to_apply=%scalar_add_computation, metadata={op_type="dot_general" op_name="pmap(_multi_device_update_fn)/dot_general[ dimension_numbers=(((0,), (0,)), ((), ()))\n                                           precision=None\n                                           preferred_element_type=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %param_2.2442 = f32[1024]{0} parameter(2)
  %broadcast.2310.clone.1 = f32[1024]{0} broadcast(f32[] %constant_14910), dimensions={}
  %multiply.1933.clone.1 = f32[1024]{0} multiply(f32[1024]{0} %param_2.2442, f32[1024]{0} %broadcast.2310.clone.1)
  %broadcast.2309.clone.1 = f32[1024,256]{1,0} broadcast(f32[1024]{0} %multiply.1933.clone.1), dimensions={0}
  %multiply.1932.clone.1 = f32[1024,256]{1,0} multiply(f32[1024,256]{1,0} %param_0.2163, f32[1024,256]{1,0} %broadcast.2309.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  %param_1.2687 = f32[256]{0} parameter(1)
  %broadcast.2308.clone.1 = f32[1024,256]{1,0} broadcast(f32[256]{0} %param_1.2687), dimensions={1}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  %multiply.1931.clone.1 = f32[1024,256]{1,0} multiply(f32[1024,256]{1,0} %multiply.1932.clone.1, f32[1024,256]{1,0} %broadcast.2308.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  %multiply.963.clone.1 = f32[1024,256]{1,0} multiply(f32[1024,256]{1,0} %multiply.1931.clone.1, f32[1024,256]{1,0} %multiply.1931.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %bitcast.687.clone.1 = f32[262144]{0} bitcast(f32[1024,256]{1,0} %multiply.963.clone.1)
  %reduce.202.clone.1 = f32[] reduce(f32[262144]{0} %bitcast.687.clone.1, f32[] %constant_11195), dimensions={0}, to_apply=%primitive_computation_add__1.15973, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0, 1) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  ROOT %tuple.527 = (f32[], f32[]) tuple(f32[] %reduce.184, f32[] %reduce.202.clone.1)
}

%primitive_computation_add__1.15769 (parameter.15770: f32[], parameter.15771: f32[]) -> f32[] {
  %parameter.15770 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.15771 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.15772 = f32[] add(f32[] %parameter.15770, f32[] %parameter.15771), metadata={op_type="add" op_name="add"}
}

%fused_computation.293 (param_0.2149: f32[2048,4096], param_1.2702: f32[4096], param_2.2461: f32[2048]) -> (f32[], f32[]) {
  %param_0.2149 = f32[2048,4096]{1,0} parameter(0)
  %constant_14892 = f32[] constant(0.125)
  %broadcast.2286 = f32[2048,4096]{1,0} broadcast(f32[] %constant_14892), dimensions={}
  %multiply.1902 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %param_0.2149, f32[2048,4096]{1,0} %broadcast.2286), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=200}
  %multiply.1901 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %multiply.1902, f32[2048,4096]{1,0} %multiply.1902), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=126}
  %bitcast.672 = f32[8388608]{0} bitcast(f32[2048,4096]{1,0} %multiply.1901)
  %constant_11190 = f32[] constant(0)
  %reduce.185 = f32[] reduce(f32[8388608]{0} %bitcast.672, f32[] %constant_11190), dimensions={0}, to_apply=%scalar_add_computation, metadata={op_type="dot_general" op_name="pmap(_multi_device_update_fn)/dot_general[ dimension_numbers=(((0,), (0,)), ((), ()))\n                                           precision=None\n                                           preferred_element_type=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %param_2.2461 = f32[2048]{0} parameter(2)
  %broadcast.2292.clone.1 = f32[2048]{0} broadcast(f32[] %constant_14892), dimensions={}
  %multiply.1908.clone.1 = f32[2048]{0} multiply(f32[2048]{0} %param_2.2461, f32[2048]{0} %broadcast.2292.clone.1)
  %broadcast.2291.clone.1 = f32[2048,4096]{1,0} broadcast(f32[2048]{0} %multiply.1908.clone.1), dimensions={0}
  %multiply.1907.clone.1 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %param_0.2149, f32[2048,4096]{1,0} %broadcast.2291.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  %param_1.2702 = f32[4096]{0} parameter(1)
  %broadcast.2290.clone.1 = f32[2048,4096]{1,0} broadcast(f32[4096]{0} %param_1.2702), dimensions={1}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  %multiply.1906.clone.1 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %multiply.1907.clone.1, f32[2048,4096]{1,0} %broadcast.2290.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  %multiply.990.clone.1 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %multiply.1906.clone.1, f32[2048,4096]{1,0} %multiply.1906.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %bitcast.690.clone.1 = f32[8388608]{0} bitcast(f32[2048,4096]{1,0} %multiply.990.clone.1)
  %reduce.206.clone.1 = f32[] reduce(f32[8388608]{0} %bitcast.690.clone.1, f32[] %constant_11190), dimensions={0}, to_apply=%primitive_computation_add__1.15769, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0, 1) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  ROOT %tuple.535 = (f32[], f32[]) tuple(f32[] %reduce.185, f32[] %reduce.206.clone.1)
}

%primitive_computation_add__1.15565 (parameter.15566: f32[], parameter.15567: f32[]) -> f32[] {
  %parameter.15566 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.15567 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.15568 = f32[] add(f32[] %parameter.15566, f32[] %parameter.15567), metadata={op_type="add" op_name="add"}
}

%fused_computation.294 (param_0.2135: f32[2048,4096], param_1.2717: f32[4096], param_2.2480: f32[2048]) -> (f32[], f32[]) {
  %param_0.2135 = f32[2048,4096]{1,0} parameter(0)
  %constant_14873 = f32[] constant(0.125)
  %broadcast.2268 = f32[2048,4096]{1,0} broadcast(f32[] %constant_14873), dimensions={}
  %multiply.1878 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %param_0.2135, f32[2048,4096]{1,0} %broadcast.2268), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=200}
  %multiply.1877 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %multiply.1878, f32[2048,4096]{1,0} %multiply.1878), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=126}
  %bitcast.673 = f32[8388608]{0} bitcast(f32[2048,4096]{1,0} %multiply.1877)
  %constant_11184 = f32[] constant(0)
  %reduce.186 = f32[] reduce(f32[8388608]{0} %bitcast.673, f32[] %constant_11184), dimensions={0}, to_apply=%scalar_add_computation, metadata={op_type="dot_general" op_name="pmap(_multi_device_update_fn)/dot_general[ dimension_numbers=(((0,), (0,)), ((), ()))\n                                           precision=None\n                                           preferred_element_type=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %param_2.2480 = f32[2048]{0} parameter(2)
  %broadcast.2274.clone.1 = f32[2048]{0} broadcast(f32[] %constant_14873), dimensions={}
  %multiply.1884.clone.1 = f32[2048]{0} multiply(f32[2048]{0} %param_2.2480, f32[2048]{0} %broadcast.2274.clone.1)
  %broadcast.2273.clone.1 = f32[2048,4096]{1,0} broadcast(f32[2048]{0} %multiply.1884.clone.1), dimensions={0}
  %multiply.1883.clone.1 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %param_0.2135, f32[2048,4096]{1,0} %broadcast.2273.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  %param_1.2717 = f32[4096]{0} parameter(1)
  %broadcast.2272.clone.1 = f32[2048,4096]{1,0} broadcast(f32[4096]{0} %param_1.2717), dimensions={1}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  %multiply.1882.clone.1 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %multiply.1883.clone.1, f32[2048,4096]{1,0} %broadcast.2272.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  %multiply.1017.clone.1 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %multiply.1882.clone.1, f32[2048,4096]{1,0} %multiply.1882.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %bitcast.692.clone.1 = f32[8388608]{0} bitcast(f32[2048,4096]{1,0} %multiply.1017.clone.1)
  %reduce.210.clone.1 = f32[] reduce(f32[8388608]{0} %bitcast.692.clone.1, f32[] %constant_11184), dimensions={0}, to_apply=%primitive_computation_add__1.15565, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0, 1) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  ROOT %tuple.543 = (f32[], f32[]) tuple(f32[] %reduce.186, f32[] %reduce.210.clone.1)
}

%primitive_computation_add__1.15361 (parameter.15362: f32[], parameter.15363: f32[]) -> f32[] {
  %parameter.15362 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.15363 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.15364 = f32[] add(f32[] %parameter.15362, f32[] %parameter.15363), metadata={op_type="add" op_name="add"}
}

%fused_computation.295 (param_0.2121: f32[2048,4096], param_1.2732: f32[4096], param_2.2499: f32[2048]) -> (f32[], f32[]) {
  %param_0.2121 = f32[2048,4096]{1,0} parameter(0)
  %constant_14855 = f32[] constant(0.125)
  %broadcast.2249 = f32[2048,4096]{1,0} broadcast(f32[] %constant_14855), dimensions={}
  %multiply.1854 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %param_0.2121, f32[2048,4096]{1,0} %broadcast.2249), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=200}
  %multiply.1853 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %multiply.1854, f32[2048,4096]{1,0} %multiply.1854), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=126}
  %bitcast.674 = f32[8388608]{0} bitcast(f32[2048,4096]{1,0} %multiply.1853)
  %constant_11176 = f32[] constant(0)
  %reduce.187 = f32[] reduce(f32[8388608]{0} %bitcast.674, f32[] %constant_11176), dimensions={0}, to_apply=%scalar_add_computation, metadata={op_type="dot_general" op_name="pmap(_multi_device_update_fn)/dot_general[ dimension_numbers=(((0,), (0,)), ((), ()))\n                                           precision=None\n                                           preferred_element_type=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %param_2.2499 = f32[2048]{0} parameter(2)
  %broadcast.2256.clone.1 = f32[2048]{0} broadcast(f32[] %constant_14855), dimensions={}
  %multiply.1860.clone.1 = f32[2048]{0} multiply(f32[2048]{0} %param_2.2499, f32[2048]{0} %broadcast.2256.clone.1)
  %broadcast.2255.clone.1 = f32[2048,4096]{1,0} broadcast(f32[2048]{0} %multiply.1860.clone.1), dimensions={0}
  %multiply.1859.clone.1 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %param_0.2121, f32[2048,4096]{1,0} %broadcast.2255.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  %param_1.2732 = f32[4096]{0} parameter(1)
  %broadcast.2254.clone.1 = f32[2048,4096]{1,0} broadcast(f32[4096]{0} %param_1.2732), dimensions={1}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  %multiply.1858.clone.1 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %multiply.1859.clone.1, f32[2048,4096]{1,0} %broadcast.2254.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  %multiply.1044.clone.1 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %multiply.1858.clone.1, f32[2048,4096]{1,0} %multiply.1858.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %bitcast.694.clone.1 = f32[8388608]{0} bitcast(f32[2048,4096]{1,0} %multiply.1044.clone.1)
  %reduce.214.clone.1 = f32[] reduce(f32[8388608]{0} %bitcast.694.clone.1, f32[] %constant_11176), dimensions={0}, to_apply=%primitive_computation_add__1.15361, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0, 1) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  ROOT %tuple.551 = (f32[], f32[]) tuple(f32[] %reduce.187, f32[] %reduce.214.clone.1)
}

%primitive_computation_add__1.15157 (parameter.15158: f32[], parameter.15159: f32[]) -> f32[] {
  %parameter.15158 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.15159 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.15160 = f32[] add(f32[] %parameter.15158, f32[] %parameter.15159), metadata={op_type="add" op_name="add"}
}

%fused_computation.296 (param_0.2107: f32[2048,4096], param_1.2747: f32[4096], param_2.2518: f32[2048]) -> (f32[], f32[]) {
  %param_0.2107 = f32[2048,4096]{1,0} parameter(0)
  %constant_14837 = f32[] constant(0.125)
  %broadcast.2231 = f32[2048,4096]{1,0} broadcast(f32[] %constant_14837), dimensions={}
  %multiply.1830 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %param_0.2107, f32[2048,4096]{1,0} %broadcast.2231), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=200}
  %multiply.1829 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %multiply.1830, f32[2048,4096]{1,0} %multiply.1830), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=126}
  %bitcast.675 = f32[8388608]{0} bitcast(f32[2048,4096]{1,0} %multiply.1829)
  %constant_11170 = f32[] constant(0)
  %reduce.188 = f32[] reduce(f32[8388608]{0} %bitcast.675, f32[] %constant_11170), dimensions={0}, to_apply=%scalar_add_computation, metadata={op_type="dot_general" op_name="pmap(_multi_device_update_fn)/dot_general[ dimension_numbers=(((0,), (0,)), ((), ()))\n                                           precision=None\n                                           preferred_element_type=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %param_2.2518 = f32[2048]{0} parameter(2)
  %broadcast.2237.clone.1 = f32[2048]{0} broadcast(f32[] %constant_14837), dimensions={}
  %multiply.1836.clone.1 = f32[2048]{0} multiply(f32[2048]{0} %param_2.2518, f32[2048]{0} %broadcast.2237.clone.1)
  %broadcast.2236.clone.1 = f32[2048,4096]{1,0} broadcast(f32[2048]{0} %multiply.1836.clone.1), dimensions={0}
  %multiply.1835.clone.1 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %param_0.2107, f32[2048,4096]{1,0} %broadcast.2236.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  %param_1.2747 = f32[4096]{0} parameter(1)
  %broadcast.2235.clone.1 = f32[2048,4096]{1,0} broadcast(f32[4096]{0} %param_1.2747), dimensions={1}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  %multiply.1834.clone.1 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %multiply.1835.clone.1, f32[2048,4096]{1,0} %broadcast.2235.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  %multiply.1071.clone.1 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %multiply.1834.clone.1, f32[2048,4096]{1,0} %multiply.1834.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %bitcast.696.clone.1 = f32[8388608]{0} bitcast(f32[2048,4096]{1,0} %multiply.1071.clone.1)
  %reduce.218.clone.1 = f32[] reduce(f32[8388608]{0} %bitcast.696.clone.1, f32[] %constant_11170), dimensions={0}, to_apply=%primitive_computation_add__1.15157, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0, 1) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  ROOT %tuple.559 = (f32[], f32[]) tuple(f32[] %reduce.188, f32[] %reduce.218.clone.1)
}

%primitive_computation_add__1.14953 (parameter.14954: f32[], parameter.14955: f32[]) -> f32[] {
  %parameter.14954 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.14955 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.14956 = f32[] add(f32[] %parameter.14954, f32[] %parameter.14955), metadata={op_type="add" op_name="add"}
}

%fused_computation.297 (param_0.2093: f32[1024,1024], param_1.2762: f32[1024], param_2.2537: f32[1024]) -> (f32[], f32[]) {
  %param_0.2093 = f32[1024,1024]{1,0} parameter(0)
  %constant_14818 = f32[] constant(0.125)
  %broadcast.2212 = f32[1024,1024]{1,0} broadcast(f32[] %constant_14818), dimensions={}
  %multiply.1806 = f32[1024,1024]{1,0} multiply(f32[1024,1024]{1,0} %param_0.2093, f32[1024,1024]{1,0} %broadcast.2212), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=200}
  %multiply.1805 = f32[1024,1024]{1,0} multiply(f32[1024,1024]{1,0} %multiply.1806, f32[1024,1024]{1,0} %multiply.1806), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=126}
  %bitcast.676 = f32[1048576]{0} bitcast(f32[1024,1024]{1,0} %multiply.1805)
  %constant_11166 = f32[] constant(0)
  %reduce.189 = f32[] reduce(f32[1048576]{0} %bitcast.676, f32[] %constant_11166), dimensions={0}, to_apply=%scalar_add_computation, metadata={op_type="dot_general" op_name="pmap(_multi_device_update_fn)/dot_general[ dimension_numbers=(((0,), (0,)), ((), ()))\n                                           precision=None\n                                           preferred_element_type=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %param_2.2537 = f32[1024]{0} parameter(2)
  %broadcast.2218.clone.1 = f32[1024]{0} broadcast(f32[] %constant_14818), dimensions={}
  %multiply.1812.clone.1 = f32[1024]{0} multiply(f32[1024]{0} %param_2.2537, f32[1024]{0} %broadcast.2218.clone.1)
  %broadcast.2217.clone.1 = f32[1024,1024]{1,0} broadcast(f32[1024]{0} %multiply.1812.clone.1), dimensions={0}
  %multiply.1811.clone.1 = f32[1024,1024]{1,0} multiply(f32[1024,1024]{1,0} %param_0.2093, f32[1024,1024]{1,0} %broadcast.2217.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  %param_1.2762 = f32[1024]{0} parameter(1)
  %broadcast.2216.clone.1 = f32[1024,1024]{1,0} broadcast(f32[1024]{0} %param_1.2762), dimensions={1}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  %multiply.1810.clone.1 = f32[1024,1024]{1,0} multiply(f32[1024,1024]{1,0} %multiply.1811.clone.1, f32[1024,1024]{1,0} %broadcast.2216.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  %multiply.1098.clone.1 = f32[1024,1024]{1,0} multiply(f32[1024,1024]{1,0} %multiply.1810.clone.1, f32[1024,1024]{1,0} %multiply.1810.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %bitcast.699.clone.1 = f32[1048576]{0} bitcast(f32[1024,1024]{1,0} %multiply.1098.clone.1)
  %reduce.223.clone.1 = f32[] reduce(f32[1048576]{0} %bitcast.699.clone.1, f32[] %constant_11166), dimensions={0}, to_apply=%primitive_computation_add__1.14953, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0, 1) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  ROOT %tuple.568 = (f32[], f32[]) tuple(f32[] %reduce.189, f32[] %reduce.223.clone.1)
}

%primitive_computation_add__1.14749 (parameter.14750: f32[], parameter.14751: f32[]) -> f32[] {
  %parameter.14750 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.14751 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.14752 = f32[] add(f32[] %parameter.14750, f32[] %parameter.14751), metadata={op_type="add" op_name="add"}
}

%fused_computation.298 (param_0.2079: f32[1024,1024], param_1.2777: f32[1024], param_2.2556: f32[1024]) -> (f32[], f32[]) {
  %param_0.2079 = f32[1024,1024]{1,0} parameter(0)
  %constant_14801 = f32[] constant(0.125)
  %broadcast.2193 = f32[1024,1024]{1,0} broadcast(f32[] %constant_14801), dimensions={}
  %multiply.1782 = f32[1024,1024]{1,0} multiply(f32[1024,1024]{1,0} %param_0.2079, f32[1024,1024]{1,0} %broadcast.2193), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=200}
  %multiply.1781 = f32[1024,1024]{1,0} multiply(f32[1024,1024]{1,0} %multiply.1782, f32[1024,1024]{1,0} %multiply.1782), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=126}
  %bitcast.677 = f32[1048576]{0} bitcast(f32[1024,1024]{1,0} %multiply.1781)
  %constant_11158 = f32[] constant(0)
  %reduce.190 = f32[] reduce(f32[1048576]{0} %bitcast.677, f32[] %constant_11158), dimensions={0}, to_apply=%scalar_add_computation, metadata={op_type="dot_general" op_name="pmap(_multi_device_update_fn)/dot_general[ dimension_numbers=(((0,), (0,)), ((), ()))\n                                           precision=None\n                                           preferred_element_type=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %param_2.2556 = f32[1024]{0} parameter(2)
  %broadcast.2199.clone.1 = f32[1024]{0} broadcast(f32[] %constant_14801), dimensions={}
  %multiply.1788.clone.1 = f32[1024]{0} multiply(f32[1024]{0} %param_2.2556, f32[1024]{0} %broadcast.2199.clone.1)
  %broadcast.2198.clone.1 = f32[1024,1024]{1,0} broadcast(f32[1024]{0} %multiply.1788.clone.1), dimensions={0}
  %multiply.1787.clone.1 = f32[1024,1024]{1,0} multiply(f32[1024,1024]{1,0} %param_0.2079, f32[1024,1024]{1,0} %broadcast.2198.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  %param_1.2777 = f32[1024]{0} parameter(1)
  %broadcast.2197.clone.1 = f32[1024,1024]{1,0} broadcast(f32[1024]{0} %param_1.2777), dimensions={1}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  %multiply.1786.clone.1 = f32[1024,1024]{1,0} multiply(f32[1024,1024]{1,0} %multiply.1787.clone.1, f32[1024,1024]{1,0} %broadcast.2197.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  %multiply.1125.clone.1 = f32[1024,1024]{1,0} multiply(f32[1024,1024]{1,0} %multiply.1786.clone.1, f32[1024,1024]{1,0} %multiply.1786.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %bitcast.702.clone.1 = f32[1048576]{0} bitcast(f32[1024,1024]{1,0} %multiply.1125.clone.1)
  %reduce.227.clone.1 = f32[] reduce(f32[1048576]{0} %bitcast.702.clone.1, f32[] %constant_11158), dimensions={0}, to_apply=%primitive_computation_add__1.14749, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0, 1) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  ROOT %tuple.576 = (f32[], f32[]) tuple(f32[] %reduce.190, f32[] %reduce.227.clone.1)
}

%primitive_computation_add__1.14545 (parameter.14546: f32[], parameter.14547: f32[]) -> f32[] {
  %parameter.14546 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.14547 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.14548 = f32[] add(f32[] %parameter.14546, f32[] %parameter.14547), metadata={op_type="add" op_name="add"}
}

%fused_computation.299 (param_0.2065: f32[1024,1024], param_1.2792: f32[1024], param_2.2575: f32[1024]) -> (f32[], f32[]) {
  %param_0.2065 = f32[1024,1024]{1,0} parameter(0)
  %constant_14782 = f32[] constant(0.125)
  %broadcast.2174 = f32[1024,1024]{1,0} broadcast(f32[] %constant_14782), dimensions={}
  %multiply.1758 = f32[1024,1024]{1,0} multiply(f32[1024,1024]{1,0} %param_0.2065, f32[1024,1024]{1,0} %broadcast.2174), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=200}
  %multiply.1757 = f32[1024,1024]{1,0} multiply(f32[1024,1024]{1,0} %multiply.1758, f32[1024,1024]{1,0} %multiply.1758), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=126}
  %bitcast.678 = f32[1048576]{0} bitcast(f32[1024,1024]{1,0} %multiply.1757)
  %constant_11150 = f32[] constant(0)
  %reduce.191 = f32[] reduce(f32[1048576]{0} %bitcast.678, f32[] %constant_11150), dimensions={0}, to_apply=%scalar_add_computation, metadata={op_type="dot_general" op_name="pmap(_multi_device_update_fn)/dot_general[ dimension_numbers=(((0,), (0,)), ((), ()))\n                                           precision=None\n                                           preferred_element_type=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %param_2.2575 = f32[1024]{0} parameter(2)
  %broadcast.2180.clone.1 = f32[1024]{0} broadcast(f32[] %constant_14782), dimensions={}
  %multiply.1764.clone.1 = f32[1024]{0} multiply(f32[1024]{0} %param_2.2575, f32[1024]{0} %broadcast.2180.clone.1)
  %broadcast.2179.clone.1 = f32[1024,1024]{1,0} broadcast(f32[1024]{0} %multiply.1764.clone.1), dimensions={0}
  %multiply.1763.clone.1 = f32[1024,1024]{1,0} multiply(f32[1024,1024]{1,0} %param_0.2065, f32[1024,1024]{1,0} %broadcast.2179.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  %param_1.2792 = f32[1024]{0} parameter(1)
  %broadcast.2178.clone.1 = f32[1024,1024]{1,0} broadcast(f32[1024]{0} %param_1.2792), dimensions={1}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  %multiply.1762.clone.1 = f32[1024,1024]{1,0} multiply(f32[1024,1024]{1,0} %multiply.1763.clone.1, f32[1024,1024]{1,0} %broadcast.2178.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  %multiply.1152.clone.1 = f32[1024,1024]{1,0} multiply(f32[1024,1024]{1,0} %multiply.1762.clone.1, f32[1024,1024]{1,0} %multiply.1762.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %bitcast.706.clone.1 = f32[1048576]{0} bitcast(f32[1024,1024]{1,0} %multiply.1152.clone.1)
  %reduce.231.clone.1 = f32[] reduce(f32[1048576]{0} %bitcast.706.clone.1, f32[] %constant_11150), dimensions={0}, to_apply=%primitive_computation_add__1.14545, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0, 1) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  ROOT %tuple.585 = (f32[], f32[]) tuple(f32[] %reduce.191, f32[] %reduce.231.clone.1)
}

%primitive_computation_add__1.14341 (parameter.14342: f32[], parameter.14343: f32[]) -> f32[] {
  %parameter.14342 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.14343 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.14344 = f32[] add(f32[] %parameter.14342, f32[] %parameter.14343), metadata={op_type="add" op_name="add"}
}

%fused_computation.300 (param_0.2051: f32[1024,1024], param_1.2807: f32[1024], param_2.2594: f32[1024]) -> (f32[], f32[]) {
  %param_0.2051 = f32[1024,1024]{1,0} parameter(0)
  %constant_14763 = f32[] constant(0.125)
  %broadcast.2155 = f32[1024,1024]{1,0} broadcast(f32[] %constant_14763), dimensions={}
  %multiply.1734 = f32[1024,1024]{1,0} multiply(f32[1024,1024]{1,0} %param_0.2051, f32[1024,1024]{1,0} %broadcast.2155), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=200}
  %multiply.1733 = f32[1024,1024]{1,0} multiply(f32[1024,1024]{1,0} %multiply.1734, f32[1024,1024]{1,0} %multiply.1734), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=126}
  %bitcast.679 = f32[1048576]{0} bitcast(f32[1024,1024]{1,0} %multiply.1733)
  %constant_11145 = f32[] constant(0)
  %reduce.192 = f32[] reduce(f32[1048576]{0} %bitcast.679, f32[] %constant_11145), dimensions={0}, to_apply=%scalar_add_computation, metadata={op_type="dot_general" op_name="pmap(_multi_device_update_fn)/dot_general[ dimension_numbers=(((0,), (0,)), ((), ()))\n                                           precision=None\n                                           preferred_element_type=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %param_2.2594 = f32[1024]{0} parameter(2)
  %broadcast.2162.clone.1 = f32[1024]{0} broadcast(f32[] %constant_14763), dimensions={}
  %multiply.1740.clone.1 = f32[1024]{0} multiply(f32[1024]{0} %param_2.2594, f32[1024]{0} %broadcast.2162.clone.1)
  %broadcast.2161.clone.1 = f32[1024,1024]{1,0} broadcast(f32[1024]{0} %multiply.1740.clone.1), dimensions={0}
  %multiply.1739.clone.1 = f32[1024,1024]{1,0} multiply(f32[1024,1024]{1,0} %param_0.2051, f32[1024,1024]{1,0} %broadcast.2161.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  %param_1.2807 = f32[1024]{0} parameter(1)
  %broadcast.2160.clone.1 = f32[1024,1024]{1,0} broadcast(f32[1024]{0} %param_1.2807), dimensions={1}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  %multiply.1738.clone.1 = f32[1024,1024]{1,0} multiply(f32[1024,1024]{1,0} %multiply.1739.clone.1, f32[1024,1024]{1,0} %broadcast.2160.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  %multiply.1179.clone.1 = f32[1024,1024]{1,0} multiply(f32[1024,1024]{1,0} %multiply.1738.clone.1, f32[1024,1024]{1,0} %multiply.1738.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %bitcast.709.clone.1 = f32[1048576]{0} bitcast(f32[1024,1024]{1,0} %multiply.1179.clone.1)
  %reduce.235.clone.1 = f32[] reduce(f32[1048576]{0} %bitcast.709.clone.1, f32[] %constant_11145), dimensions={0}, to_apply=%primitive_computation_add__1.14341, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0, 1) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  ROOT %tuple.593 = (f32[], f32[]) tuple(f32[] %reduce.192, f32[] %reduce.235.clone.1)
}

%primitive_computation_add__1.14137 (parameter.14138: f32[], parameter.14139: f32[]) -> f32[] {
  %parameter.14138 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.14139 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.14140 = f32[] add(f32[] %parameter.14138, f32[] %parameter.14139), metadata={op_type="add" op_name="add"}
}

%fused_computation.301 (param_0.2037: f32[2048,4096], param_1.2822: f32[4096], param_2.2613: f32[2048]) -> (f32[], f32[]) {
  %param_0.2037 = f32[2048,4096]{1,0} parameter(0)
  %constant_14745 = f32[] constant(0.125)
  %broadcast.2137 = f32[2048,4096]{1,0} broadcast(f32[] %constant_14745), dimensions={}
  %multiply.1710 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %param_0.2037, f32[2048,4096]{1,0} %broadcast.2137), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=200}
  %multiply.1709 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %multiply.1710, f32[2048,4096]{1,0} %multiply.1710), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=126}
  %bitcast.680 = f32[8388608]{0} bitcast(f32[2048,4096]{1,0} %multiply.1709)
  %constant_11141 = f32[] constant(0)
  %reduce.193 = f32[] reduce(f32[8388608]{0} %bitcast.680, f32[] %constant_11141), dimensions={0}, to_apply=%scalar_add_computation, metadata={op_type="dot_general" op_name="pmap(_multi_device_update_fn)/dot_general[ dimension_numbers=(((0,), (0,)), ((), ()))\n                                           precision=None\n                                           preferred_element_type=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %param_2.2613 = f32[2048]{0} parameter(2)
  %broadcast.2143.clone.1 = f32[2048]{0} broadcast(f32[] %constant_14745), dimensions={}
  %multiply.1716.clone.1 = f32[2048]{0} multiply(f32[2048]{0} %param_2.2613, f32[2048]{0} %broadcast.2143.clone.1)
  %broadcast.2142.clone.1 = f32[2048,4096]{1,0} broadcast(f32[2048]{0} %multiply.1716.clone.1), dimensions={0}
  %multiply.1715.clone.1 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %param_0.2037, f32[2048,4096]{1,0} %broadcast.2142.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  %param_1.2822 = f32[4096]{0} parameter(1)
  %broadcast.2141.clone.1 = f32[2048,4096]{1,0} broadcast(f32[4096]{0} %param_1.2822), dimensions={1}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  %multiply.1714.clone.1 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %multiply.1715.clone.1, f32[2048,4096]{1,0} %broadcast.2141.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  %multiply.1206.clone.1 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %multiply.1714.clone.1, f32[2048,4096]{1,0} %multiply.1714.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %bitcast.712.clone.1 = f32[8388608]{0} bitcast(f32[2048,4096]{1,0} %multiply.1206.clone.1)
  %reduce.239.clone.1 = f32[] reduce(f32[8388608]{0} %bitcast.712.clone.1, f32[] %constant_11141), dimensions={0}, to_apply=%primitive_computation_add__1.14137, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0, 1) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  ROOT %tuple.602 = (f32[], f32[]) tuple(f32[] %reduce.193, f32[] %reduce.239.clone.1)
}

%primitive_computation_add__1.14011 (parameter.14012: f32[], parameter.14013: f32[]) -> f32[] {
  %parameter.14012 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.14013 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.14014 = f32[] add(f32[] %parameter.14012, f32[] %parameter.14013), metadata={op_type="add" op_name="add"}
}

%fused_computation.302 (param_0.2021: f32[256,1024], param_1.2832: f32[1024], param_2.2625: f32[256]) -> (f32[], f32[]) {
  %param_0.2021 = f32[256,1024]{1,0} parameter(0)
  %constant_14717 = f32[] constant(0.125)
  %broadcast.2114 = f32[256,1024]{1,0} broadcast(f32[] %constant_14717), dimensions={}
  %multiply.1682 = f32[256,1024]{1,0} multiply(f32[256,1024]{1,0} %param_0.2021, f32[256,1024]{1,0} %broadcast.2114), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=200}
  %multiply.1681 = f32[256,1024]{1,0} multiply(f32[256,1024]{1,0} %multiply.1682, f32[256,1024]{1,0} %multiply.1682), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=126}
  %bitcast.681 = f32[262144]{0} bitcast(f32[256,1024]{1,0} %multiply.1681)
  %constant_11138 = f32[] constant(0)
  %reduce.194 = f32[] reduce(f32[262144]{0} %bitcast.681, f32[] %constant_11138), dimensions={0}, to_apply=%scalar_add_computation, metadata={op_type="dot_general" op_name="pmap(_multi_device_update_fn)/dot_general[ dimension_numbers=(((0,), (0,)), ((), ()))\n                                           precision=None\n                                           preferred_element_type=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %param_2.2625 = f32[256]{0} parameter(2)
  %broadcast.2124.clone.1 = f32[256]{0} broadcast(f32[] %constant_14717), dimensions={}
  %multiply.1692.clone.1 = f32[256]{0} multiply(f32[256]{0} %param_2.2625, f32[256]{0} %broadcast.2124.clone.1)
  %broadcast.2123.clone.1 = f32[256,1024]{1,0} broadcast(f32[256]{0} %multiply.1692.clone.1), dimensions={0}
  %multiply.1691.clone.1 = f32[256,1024]{1,0} multiply(f32[256,1024]{1,0} %param_0.2021, f32[256,1024]{1,0} %broadcast.2123.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  %param_1.2832 = f32[1024]{0} parameter(1)
  %broadcast.2122.clone.1 = f32[256,1024]{1,0} broadcast(f32[1024]{0} %param_1.2832), dimensions={1}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  %multiply.1690.clone.1 = f32[256,1024]{1,0} multiply(f32[256,1024]{1,0} %multiply.1691.clone.1, f32[256,1024]{1,0} %broadcast.2122.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  %multiply.1223.clone.1 = f32[256,1024]{1,0} multiply(f32[256,1024]{1,0} %multiply.1690.clone.1, f32[256,1024]{1,0} %multiply.1690.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %bitcast.714.clone.1 = f32[262144]{0} bitcast(f32[256,1024]{1,0} %multiply.1223.clone.1)
  %reduce.241.clone.1 = f32[] reduce(f32[262144]{0} %bitcast.714.clone.1, f32[] %constant_11138), dimensions={0}, to_apply=%primitive_computation_add__1.14011, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0, 1) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  ROOT %tuple.606 = (f32[], f32[]) tuple(f32[] %reduce.194, f32[] %reduce.241.clone.1)
}

%primitive_computation_add__1.13807 (parameter.13808: f32[], parameter.13809: f32[]) -> f32[] {
  %parameter.13808 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.13809 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.13810 = f32[] add(f32[] %parameter.13808, f32[] %parameter.13809), metadata={op_type="add" op_name="add"}
}

%fused_computation.303 (param_0.2007: f32[2048,4096], param_1.2847: f32[4096], param_2.2644: f32[2048]) -> (f32[], f32[]) {
  %param_0.2007 = f32[2048,4096]{1,0} parameter(0)
  %constant_14699 = f32[] constant(0.125)
  %broadcast.2095 = f32[2048,4096]{1,0} broadcast(f32[] %constant_14699), dimensions={}
  %multiply.1658 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %param_0.2007, f32[2048,4096]{1,0} %broadcast.2095), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=200}
  %multiply.1657 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %multiply.1658, f32[2048,4096]{1,0} %multiply.1658), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=126}
  %bitcast.682 = f32[8388608]{0} bitcast(f32[2048,4096]{1,0} %multiply.1657)
  %constant_11130 = f32[] constant(0)
  %reduce.195 = f32[] reduce(f32[8388608]{0} %bitcast.682, f32[] %constant_11130), dimensions={0}, to_apply=%scalar_add_computation, metadata={op_type="dot_general" op_name="pmap(_multi_device_update_fn)/dot_general[ dimension_numbers=(((0,), (0,)), ((), ()))\n                                           precision=None\n                                           preferred_element_type=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %param_2.2644 = f32[2048]{0} parameter(2)
  %broadcast.2101.clone.1 = f32[2048]{0} broadcast(f32[] %constant_14699), dimensions={}
  %multiply.1664.clone.1 = f32[2048]{0} multiply(f32[2048]{0} %param_2.2644, f32[2048]{0} %broadcast.2101.clone.1)
  %broadcast.2100.clone.1 = f32[2048,4096]{1,0} broadcast(f32[2048]{0} %multiply.1664.clone.1), dimensions={0}
  %multiply.1663.clone.1 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %param_0.2007, f32[2048,4096]{1,0} %broadcast.2100.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  %param_1.2847 = f32[4096]{0} parameter(1)
  %broadcast.2099.clone.1 = f32[2048,4096]{1,0} broadcast(f32[4096]{0} %param_1.2847), dimensions={1}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  %multiply.1662.clone.1 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %multiply.1663.clone.1, f32[2048,4096]{1,0} %broadcast.2099.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  %multiply.1252.clone.1 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %multiply.1662.clone.1, f32[2048,4096]{1,0} %multiply.1662.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %bitcast.716.clone.1 = f32[8388608]{0} bitcast(f32[2048,4096]{1,0} %multiply.1252.clone.1)
  %reduce.245.clone.1 = f32[] reduce(f32[8388608]{0} %bitcast.716.clone.1, f32[] %constant_11130), dimensions={0}, to_apply=%primitive_computation_add__1.13807, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0, 1) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  ROOT %tuple.614 = (f32[], f32[]) tuple(f32[] %reduce.195, f32[] %reduce.245.clone.1)
}

%primitive_computation_add__1.13603 (parameter.13604: f32[], parameter.13605: f32[]) -> f32[] {
  %parameter.13604 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.13605 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.13606 = f32[] add(f32[] %parameter.13604, f32[] %parameter.13605), metadata={op_type="add" op_name="add"}
}

%fused_computation.304 (param_0.1993: f32[2048,4096], param_1.2862: f32[4096], param_2.2663: f32[2048]) -> (f32[], f32[]) {
  %param_0.1993 = f32[2048,4096]{1,0} parameter(0)
  %constant_14681 = f32[] constant(0.125)
  %broadcast.2076 = f32[2048,4096]{1,0} broadcast(f32[] %constant_14681), dimensions={}
  %multiply.1634 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %param_0.1993, f32[2048,4096]{1,0} %broadcast.2076), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=200}
  %multiply.1633 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %multiply.1634, f32[2048,4096]{1,0} %multiply.1634), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=126}
  %bitcast.683 = f32[8388608]{0} bitcast(f32[2048,4096]{1,0} %multiply.1633)
  %constant_11124 = f32[] constant(0)
  %reduce.196 = f32[] reduce(f32[8388608]{0} %bitcast.683, f32[] %constant_11124), dimensions={0}, to_apply=%scalar_add_computation, metadata={op_type="dot_general" op_name="pmap(_multi_device_update_fn)/dot_general[ dimension_numbers=(((0,), (0,)), ((), ()))\n                                           precision=None\n                                           preferred_element_type=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %param_2.2663 = f32[2048]{0} parameter(2)
  %broadcast.2082.clone.1 = f32[2048]{0} broadcast(f32[] %constant_14681), dimensions={}
  %multiply.1640.clone.1 = f32[2048]{0} multiply(f32[2048]{0} %param_2.2663, f32[2048]{0} %broadcast.2082.clone.1)
  %broadcast.2081.clone.1 = f32[2048,4096]{1,0} broadcast(f32[2048]{0} %multiply.1640.clone.1), dimensions={0}
  %multiply.1639.clone.1 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %param_0.1993, f32[2048,4096]{1,0} %broadcast.2081.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  %param_1.2862 = f32[4096]{0} parameter(1)
  %broadcast.2080.clone.1 = f32[2048,4096]{1,0} broadcast(f32[4096]{0} %param_1.2862), dimensions={1}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  %multiply.1638.clone.1 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %multiply.1639.clone.1, f32[2048,4096]{1,0} %broadcast.2080.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  %multiply.1281.clone.1 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %multiply.1638.clone.1, f32[2048,4096]{1,0} %multiply.1638.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %bitcast.718.clone.1 = f32[8388608]{0} bitcast(f32[2048,4096]{1,0} %multiply.1281.clone.1)
  %reduce.249.clone.1 = f32[] reduce(f32[8388608]{0} %bitcast.718.clone.1, f32[] %constant_11124), dimensions={0}, to_apply=%primitive_computation_add__1.13603, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0, 1) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  ROOT %tuple.622 = (f32[], f32[]) tuple(f32[] %reduce.196, f32[] %reduce.249.clone.1)
}

%primitive_computation_add__1.13399 (parameter.13400: f32[], parameter.13401: f32[]) -> f32[] {
  %parameter.13400 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.13401 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.13402 = f32[] add(f32[] %parameter.13400, f32[] %parameter.13401), metadata={op_type="add" op_name="add"}
}

%fused_computation.305 (param_0.1979: f32[2048,4096], param_1.2877: f32[4096], param_2.2682: f32[2048]) -> (f32[], f32[]) {
  %param_0.1979 = f32[2048,4096]{1,0} parameter(0)
  %constant_14662 = f32[] constant(0.125)
  %broadcast.2057 = f32[2048,4096]{1,0} broadcast(f32[] %constant_14662), dimensions={}
  %multiply.1610 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %param_0.1979, f32[2048,4096]{1,0} %broadcast.2057), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=200}
  %multiply.1609 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %multiply.1610, f32[2048,4096]{1,0} %multiply.1610), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=126}
  %bitcast.684 = f32[8388608]{0} bitcast(f32[2048,4096]{1,0} %multiply.1609)
  %constant_11120 = f32[] constant(0)
  %reduce.197 = f32[] reduce(f32[8388608]{0} %bitcast.684, f32[] %constant_11120), dimensions={0}, to_apply=%scalar_add_computation, metadata={op_type="dot_general" op_name="pmap(_multi_device_update_fn)/dot_general[ dimension_numbers=(((0,), (0,)), ((), ()))\n                                           precision=None\n                                           preferred_element_type=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %param_2.2682 = f32[2048]{0} parameter(2)
  %broadcast.2063.clone.1 = f32[2048]{0} broadcast(f32[] %constant_14662), dimensions={}
  %multiply.1616.clone.1 = f32[2048]{0} multiply(f32[2048]{0} %param_2.2682, f32[2048]{0} %broadcast.2063.clone.1)
  %broadcast.2062.clone.1 = f32[2048,4096]{1,0} broadcast(f32[2048]{0} %multiply.1616.clone.1), dimensions={0}
  %multiply.1615.clone.1 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %param_0.1979, f32[2048,4096]{1,0} %broadcast.2062.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  %param_1.2877 = f32[4096]{0} parameter(1)
  %broadcast.2061.clone.1 = f32[2048,4096]{1,0} broadcast(f32[4096]{0} %param_1.2877), dimensions={1}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  %multiply.1614.clone.1 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %multiply.1615.clone.1, f32[2048,4096]{1,0} %broadcast.2061.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  %multiply.1308.clone.1 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %multiply.1614.clone.1, f32[2048,4096]{1,0} %multiply.1614.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %bitcast.720.clone.1 = f32[8388608]{0} bitcast(f32[2048,4096]{1,0} %multiply.1308.clone.1)
  %reduce.253.clone.1 = f32[] reduce(f32[8388608]{0} %bitcast.720.clone.1, f32[] %constant_11120), dimensions={0}, to_apply=%primitive_computation_add__1.13399, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0, 1) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  ROOT %tuple.630 = (f32[], f32[]) tuple(f32[] %reduce.197, f32[] %reduce.253.clone.1)
}

%primitive_computation_add__1.13195 (parameter.13196: f32[], parameter.13197: f32[]) -> f32[] {
  %parameter.13196 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.13197 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.13198 = f32[] add(f32[] %parameter.13196, f32[] %parameter.13197), metadata={op_type="add" op_name="add"}
}

%fused_computation.306 (param_0.1947: f32[2048,4096], param_1.2892: f32[4096], param_2.2701: f32[2048]) -> (f32[], f32[]) {
  %param_0.1947 = f32[2048,4096]{1,0} parameter(0)
  %constant_14535 = f32[] constant(0.125)
  %broadcast.2001 = f32[2048,4096]{1,0} broadcast(f32[] %constant_14535), dimensions={}
  %multiply.1550 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %param_0.1947, f32[2048,4096]{1,0} %broadcast.2001), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=200}
  %multiply.1549 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %multiply.1550, f32[2048,4096]{1,0} %multiply.1550), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=126}
  %bitcast.685 = f32[8388608]{0} bitcast(f32[2048,4096]{1,0} %multiply.1549)
  %constant_11110 = f32[] constant(0)
  %reduce.198 = f32[] reduce(f32[8388608]{0} %bitcast.685, f32[] %constant_11110), dimensions={0}, to_apply=%scalar_add_computation, metadata={op_type="dot_general" op_name="pmap(_multi_device_update_fn)/dot_general[ dimension_numbers=(((0,), (0,)), ((), ()))\n                                           precision=None\n                                           preferred_element_type=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %param_2.2701 = f32[2048]{0} parameter(2)
  %broadcast.2045.clone.1 = f32[2048]{0} broadcast(f32[] %constant_14535), dimensions={}
  %multiply.1592.clone.1 = f32[2048]{0} multiply(f32[2048]{0} %param_2.2701, f32[2048]{0} %broadcast.2045.clone.1)
  %broadcast.2043.clone.1 = f32[2048,4096]{1,0} broadcast(f32[2048]{0} %multiply.1592.clone.1), dimensions={0}
  %multiply.1591.clone.1 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %param_0.1947, f32[2048,4096]{1,0} %broadcast.2043.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  %param_1.2892 = f32[4096]{0} parameter(1)
  %broadcast.2042.clone.1 = f32[2048,4096]{1,0} broadcast(f32[4096]{0} %param_1.2892), dimensions={1}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  %multiply.1590.clone.1 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %multiply.1591.clone.1, f32[2048,4096]{1,0} %broadcast.2042.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  %multiply.1335.clone.1 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %multiply.1590.clone.1, f32[2048,4096]{1,0} %multiply.1590.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %bitcast.722.clone.1 = f32[8388608]{0} bitcast(f32[2048,4096]{1,0} %multiply.1335.clone.1)
  %reduce.257.clone.1 = f32[] reduce(f32[8388608]{0} %bitcast.722.clone.1, f32[] %constant_11110), dimensions={0}, to_apply=%primitive_computation_add__1.13195, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0, 1) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  ROOT %tuple.638 = (f32[], f32[]) tuple(f32[] %reduce.198, f32[] %reduce.257.clone.1)
}

%primitive_computation_add__1.13069 (parameter.13070: f32[], parameter.13071: f32[]) -> f32[] {
  %parameter.13070 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.13071 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.13072 = f32[] add(f32[] %parameter.13070, f32[] %parameter.13071), metadata={op_type="add" op_name="add"}
}

%fused_computation.307 (param_0.1933: f32[32000,1024], param_1.2900: f32[1024], param_2.2712: f32[32000]) -> (f32[], f32[]) {
  %param_0.1933 = f32[32000,1024]{1,0} parameter(0)
  %constant_14517 = f32[] constant(0.125)
  %broadcast.1982 = f32[32000,1024]{1,0} broadcast(f32[] %constant_14517), dimensions={}
  %multiply.1526 = f32[32000,1024]{1,0} multiply(f32[32000,1024]{1,0} %param_0.1933, f32[32000,1024]{1,0} %broadcast.1982), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=200}
  %multiply.1525 = f32[32000,1024]{1,0} multiply(f32[32000,1024]{1,0} %multiply.1526, f32[32000,1024]{1,0} %multiply.1526), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=126}
  %bitcast.686 = f32[32768000]{0} bitcast(f32[32000,1024]{1,0} %multiply.1525)
  %constant_11112 = f32[] constant(0)
  %reduce.199 = f32[] reduce(f32[32768000]{0} %bitcast.686, f32[] %constant_11112), dimensions={0}, to_apply=%scalar_add_computation, metadata={op_type="dot_general" op_name="pmap(_multi_device_update_fn)/dot_general[ dimension_numbers=(((0,), (0,)), ((), ()))\n                                           precision=None\n                                           preferred_element_type=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %param_2.2712 = f32[32000]{0} parameter(2)
  %broadcast.1988.clone.1 = f32[32000]{0} broadcast(f32[] %constant_14517), dimensions={}
  %multiply.1532.clone.1 = f32[32000]{0} multiply(f32[32000]{0} %param_2.2712, f32[32000]{0} %broadcast.1988.clone.1)
  %broadcast.1987.clone.1 = f32[32000,1024]{1,0} broadcast(f32[32000]{0} %multiply.1532.clone.1), dimensions={0}
  %multiply.1531.clone.1 = f32[32000,1024]{1,0} multiply(f32[32000,1024]{1,0} %param_0.1933, f32[32000,1024]{1,0} %broadcast.1987.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  %param_1.2900 = f32[1024]{0} parameter(1)
  %broadcast.1986.clone.1 = f32[32000,1024]{1,0} broadcast(f32[1024]{0} %param_1.2900), dimensions={1}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  %multiply.1530.clone.1 = f32[32000,1024]{1,0} multiply(f32[32000,1024]{1,0} %multiply.1531.clone.1, f32[32000,1024]{1,0} %broadcast.1986.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  %multiply.1354.clone.1 = f32[32000,1024]{1,0} multiply(f32[32000,1024]{1,0} %multiply.1530.clone.1, f32[32000,1024]{1,0} %multiply.1530.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %bitcast.724.clone.1 = f32[32768000]{0} bitcast(f32[32000,1024]{1,0} %multiply.1354.clone.1)
  %reduce.259.clone.1 = f32[] reduce(f32[32768000]{0} %bitcast.724.clone.1, f32[] %constant_11112), dimensions={0}, to_apply=%primitive_computation_add__1.13069, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0, 1) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  ROOT %tuple.716 = (f32[], f32[]) tuple(f32[] %reduce.199, f32[] %reduce.259.clone.1)
}

%fused_computation.308 (param_0.484: f32[256], param_1.1664: f32[], param_2.1159: f32[], param_3.914: f32[], param_4.317: f32[], param_5.219: f32[], param_6.168: f32[256], param_7.142: f32[]) -> f32[256] {
  %param_7.142 = f32[] parameter(7)
  %broadcast.1289 = f32[256]{0} broadcast(f32[] %param_7.142), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  %param_6.168 = f32[256]{0} parameter(6)
  %multiply.951 = f32[256]{0} multiply(f32[256]{0} %broadcast.1289, f32[256]{0} %param_6.168), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  %param_3.914 = f32[] parameter(3)
  %param_4.317 = f32[] parameter(4)
  %param_5.219 = f32[] parameter(5)
  %maximum.4 = f32[] maximum(f32[] %param_4.317, f32[] %param_5.219), metadata={op_type="max" op_name="pmap(_multi_device_update_fn)/max" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=122}
  %multiply.950 = f32[] multiply(f32[] %param_3.914, f32[] %maximum.4), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=122}
  %broadcast.1288 = f32[256]{0} broadcast(f32[] %multiply.950), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=152}
  %param_0.484 = f32[256]{0} parameter(0)
  %constant_11202 = f32[] constant(1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/metrics.py" source_line=617}
  %param_1.1664 = f32[] parameter(1)
  %param_2.1159 = f32[] parameter(2)
  %divide.140 = f32[] divide(f32[] %param_1.1664, f32[] %param_2.1159), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %maximum.3 = f32[] maximum(f32[] %constant_11202, f32[] %divide.140), metadata={op_type="max" op_name="pmap(_multi_device_update_fn)/max" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %broadcast.1286 = f32[256]{0} broadcast(f32[] %maximum.3), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=150}
  %divide.139 = f32[256]{0} divide(f32[256]{0} %param_0.484, f32[256]{0} %broadcast.1286), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=150}
  %multiply.949 = f32[256]{0} multiply(f32[256]{0} %broadcast.1288, f32[256]{0} %divide.139), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=152}
  ROOT %subtract.257 = f32[256]{0} subtract(f32[256]{0} %multiply.951, f32[256]{0} %multiply.949), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
}

%fused_computation.309 (param_0.486: f32[]) -> f32[] {
  %param_0.486 = f32[] parameter(0)
  %constant_11210 = f32[] constant(0.00390625)
  %multiply.952 = f32[] multiply(f32[] %param_0.486, f32[] %constant_11210), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  ROOT %sqrt.2 = f32[] sqrt(f32[] %multiply.952), metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
}

%fused_computation.313 (param_0.493: f32[], param_1.2672: f32[], param_2.2423: f32[], param_3.2232: f32[], param_4.1159: f32[], param_5.545: f32[], param_6.500: f32[], param_7.479: f32[], param_8.353: f32[], param_9.221: f32[], param_10.185: f32[], param_11.179: f32[], param_12.197: f32[], param_13.242: f32[], param_14.224: f32[], param_15.161: f32[], param_16.80: f32[], param_17.26: f32[], param_18.8: f32[], param_19.8: f32[], param_20.8: f32[], param_21.8: f32[], param_22.8: f32[], param_23.8: f32[], param_24.8: f32[], param_25.8: f32[], param_26.8: f32[], param_27.8: f32[], param_28.5: f32[], param_29.2: f32[]) -> (f32[], f32[], f32[], f32[], f32[], /*index=5*/f32[], f32[], f32[], f32[], f32[], /*index=10*/f32[], f32[], f32[], f32[], f32[], /*index=15*/f32[], f32[], f32[], f32[], f32[], /*index=20*/f32[], f32[], f32[], f32[], f32[], /*index=25*/f32[], f32[], f32[], f32[], f32[], /*index=30*/f32[]) {
  %param_0.493 = f32[] parameter(0)
  %constant_11204 = f32[] constant(0.00390625)
  %multiply.957 = f32[] multiply(f32[] %param_0.493, f32[] %constant_11204), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %sqrt.3 = f32[] sqrt(f32[] %multiply.957), metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %param_28.5 = f32[] parameter(28)
  %param_29.2 = f32[] parameter(29)
  %add.1938.clone.1 = f32[] add(f32[] %param_28.5, f32[] %param_29.2), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %param_27.8 = f32[] parameter(27)
  %add.1937.clone.1 = f32[] add(f32[] %add.1938.clone.1, f32[] %param_27.8), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %param_26.8 = f32[] parameter(26)
  %add.1936.clone.1 = f32[] add(f32[] %add.1937.clone.1, f32[] %param_26.8), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %param_25.8 = f32[] parameter(25)
  %add.1935.clone.1 = f32[] add(f32[] %add.1936.clone.1, f32[] %param_25.8), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %param_24.8 = f32[] parameter(24)
  %add.1934.clone.1 = f32[] add(f32[] %add.1935.clone.1, f32[] %param_24.8), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %param_23.8 = f32[] parameter(23)
  %add.1932.clone.1 = f32[] add(f32[] %add.1934.clone.1, f32[] %param_23.8), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %param_22.8 = f32[] parameter(22)
  %add.1931.clone.1 = f32[] add(f32[] %add.1932.clone.1, f32[] %param_22.8), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %param_21.8 = f32[] parameter(21)
  %add.1930.clone.1 = f32[] add(f32[] %add.1931.clone.1, f32[] %param_21.8), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %param_20.8 = f32[] parameter(20)
  %add.1929.clone.1 = f32[] add(f32[] %add.1930.clone.1, f32[] %param_20.8), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %param_19.8 = f32[] parameter(19)
  %add.1928.clone.1 = f32[] add(f32[] %add.1929.clone.1, f32[] %param_19.8), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %param_18.8 = f32[] parameter(18)
  %add.1927.clone.1 = f32[] add(f32[] %add.1928.clone.1, f32[] %param_18.8), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %param_17.26 = f32[] parameter(17)
  %add.1926.clone.1 = f32[] add(f32[] %add.1927.clone.1, f32[] %param_17.26), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %param_16.80 = f32[] parameter(16)
  %add.1925.clone.1 = f32[] add(f32[] %add.1926.clone.1, f32[] %param_16.80), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %param_15.161 = f32[] parameter(15)
  %add.1924.clone.1 = f32[] add(f32[] %add.1925.clone.1, f32[] %param_15.161), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %param_14.224 = f32[] parameter(14)
  %add.1923.clone.1 = f32[] add(f32[] %add.1924.clone.1, f32[] %param_14.224), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %param_13.242 = f32[] parameter(13)
  %add.1922.clone.1 = f32[] add(f32[] %add.1923.clone.1, f32[] %param_13.242), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %param_12.197 = f32[] parameter(12)
  %add.1921.clone.1 = f32[] add(f32[] %add.1922.clone.1, f32[] %param_12.197), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %param_11.179 = f32[] parameter(11)
  %add.1919.clone.1 = f32[] add(f32[] %add.1921.clone.1, f32[] %param_11.179), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %param_10.185 = f32[] parameter(10)
  %add.1918.clone.1 = f32[] add(f32[] %add.1919.clone.1, f32[] %param_10.185), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %param_9.221 = f32[] parameter(9)
  %add.1917.clone.1 = f32[] add(f32[] %add.1918.clone.1, f32[] %param_9.221), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %param_8.353 = f32[] parameter(8)
  %add.1916.clone.1 = f32[] add(f32[] %add.1917.clone.1, f32[] %param_8.353), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %param_7.479 = f32[] parameter(7)
  %add.1915.clone.1 = f32[] add(f32[] %add.1916.clone.1, f32[] %param_7.479), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %param_6.500 = f32[] parameter(6)
  %add.1914.clone.1 = f32[] add(f32[] %add.1915.clone.1, f32[] %param_6.500), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %param_5.545 = f32[] parameter(5)
  %add.1912.clone.1 = f32[] add(f32[] %add.1914.clone.1, f32[] %param_5.545), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %param_4.1159 = f32[] parameter(4)
  %add.1911.clone.1 = f32[] add(f32[] %add.1912.clone.1, f32[] %param_4.1159), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %param_3.2232 = f32[] parameter(3)
  %add.1910.clone.1 = f32[] add(f32[] %add.1911.clone.1, f32[] %param_3.2232), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %param_2.2423 = f32[] parameter(2)
  %add.1909.clone.1 = f32[] add(f32[] %add.1910.clone.1, f32[] %param_2.2423), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %param_1.2672 = f32[] parameter(1)
  %add.1908.clone.1 = f32[] add(f32[] %add.1909.clone.1, f32[] %param_1.2672), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %add.1907.clone.1 = f32[] add(f32[] %add.1908.clone.1, f32[] %param_0.493), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %sqrt.0.clone.1 = f32[] sqrt(f32[] %add.1907.clone.1), metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %constant_11225_clone_1 = f32[] constant(3.81469727e-06)
  %multiply.974.clone.1 = f32[] multiply(f32[] %param_1.2672, f32[] %constant_11225_clone_1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %sqrt.5.clone.1 = f32[] sqrt(f32[] %multiply.974.clone.1), metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %constant_11250_clone_1 = f32[] constant(0.000244140625)
  %multiply.984.clone.1 = f32[] multiply(f32[] %param_2.2423, f32[] %constant_11250_clone_1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %sqrt.7.clone.1 = f32[] sqrt(f32[] %multiply.984.clone.1), metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %constant_11268_clone_1 = f32[] constant(1.1920929e-07)
  %multiply.1001.clone.1 = f32[] multiply(f32[] %param_3.2232, f32[] %constant_11268_clone_1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %sqrt.9.clone.1 = f32[] sqrt(f32[] %multiply.1001.clone.1), metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %multiply.1011.clone.1 = f32[] multiply(f32[] %param_4.1159, f32[] %constant_11250_clone_1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %sqrt.11.clone.1 = f32[] sqrt(f32[] %multiply.1011.clone.1), metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %multiply.1028.clone.1 = f32[] multiply(f32[] %param_5.545, f32[] %constant_11268_clone_1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %sqrt.13.clone.1 = f32[] sqrt(f32[] %multiply.1028.clone.1), metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %multiply.1038.clone.1 = f32[] multiply(f32[] %param_6.500, f32[] %constant_11250_clone_1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %sqrt.15.clone.1 = f32[] sqrt(f32[] %multiply.1038.clone.1), metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %multiply.1055.clone.1 = f32[] multiply(f32[] %param_7.479, f32[] %constant_11268_clone_1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %sqrt.17.clone.1 = f32[] sqrt(f32[] %multiply.1055.clone.1), metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %multiply.1065.clone.1 = f32[] multiply(f32[] %param_8.353, f32[] %constant_11250_clone_1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %sqrt.19.clone.1 = f32[] sqrt(f32[] %multiply.1065.clone.1), metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %multiply.1082.clone.1 = f32[] multiply(f32[] %param_9.221, f32[] %constant_11268_clone_1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %sqrt.21.clone.1 = f32[] sqrt(f32[] %multiply.1082.clone.1), metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %constant_11367_clone_1 = f32[] constant(0.0009765625)
  %multiply.1092.clone.1 = f32[] multiply(f32[] %param_10.185, f32[] %constant_11367_clone_1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %sqrt.23.clone.1 = f32[] sqrt(f32[] %multiply.1092.clone.1), metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %constant_11377_clone_1 = f32[] constant(9.53674316e-07)
  %multiply.1109.clone.1 = f32[] multiply(f32[] %param_11.179, f32[] %constant_11377_clone_1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %sqrt.25.clone.1 = f32[] sqrt(f32[] %multiply.1109.clone.1), metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %multiply.1119.clone.1 = f32[] multiply(f32[] %param_12.197, f32[] %constant_11367_clone_1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %sqrt.27.clone.1 = f32[] sqrt(f32[] %multiply.1119.clone.1), metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %multiply.1136.clone.1 = f32[] multiply(f32[] %param_13.242, f32[] %constant_11377_clone_1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %sqrt.29.clone.1 = f32[] sqrt(f32[] %multiply.1136.clone.1), metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %multiply.1146.clone.1 = f32[] multiply(f32[] %param_14.224, f32[] %constant_11367_clone_1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %sqrt.31.clone.1 = f32[] sqrt(f32[] %multiply.1146.clone.1), metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %multiply.1163.clone.1 = f32[] multiply(f32[] %param_15.161, f32[] %constant_11377_clone_1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %sqrt.33.clone.1 = f32[] sqrt(f32[] %multiply.1163.clone.1), metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %multiply.1173.clone.1 = f32[] multiply(f32[] %param_16.80, f32[] %constant_11367_clone_1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %sqrt.35.clone.1 = f32[] sqrt(f32[] %multiply.1173.clone.1), metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %multiply.1190.clone.1 = f32[] multiply(f32[] %param_17.26, f32[] %constant_11377_clone_1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %sqrt.37.clone.1 = f32[] sqrt(f32[] %multiply.1190.clone.1), metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %multiply.1200.clone.1 = f32[] multiply(f32[] %param_18.8, f32[] %constant_11250_clone_1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %sqrt.39.clone.1 = f32[] sqrt(f32[] %multiply.1200.clone.1), metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %multiply.1217.clone.1 = f32[] multiply(f32[] %param_19.8, f32[] %constant_11268_clone_1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %sqrt.41.clone.1 = f32[] sqrt(f32[] %multiply.1217.clone.1), metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %multiply.1235.clone.1 = f32[] multiply(f32[] %param_20.8, f32[] %constant_11225_clone_1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %sqrt.43.clone.1 = f32[] sqrt(f32[] %multiply.1235.clone.1), metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %multiply.1245.clone.1 = f32[] multiply(f32[] %param_21.8, f32[] %constant_11250_clone_1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %sqrt.45.clone.1 = f32[] sqrt(f32[] %multiply.1245.clone.1), metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %multiply.1264.clone.1 = f32[] multiply(f32[] %param_22.8, f32[] %constant_11268_clone_1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %sqrt.47.clone.1 = f32[] sqrt(f32[] %multiply.1264.clone.1), metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %multiply.1274.clone.1 = f32[] multiply(f32[] %param_23.8, f32[] %constant_11250_clone_1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %sqrt.49.clone.1 = f32[] sqrt(f32[] %multiply.1274.clone.1), metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %multiply.1292.clone.1 = f32[] multiply(f32[] %param_24.8, f32[] %constant_11268_clone_1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %sqrt.51.clone.1 = f32[] sqrt(f32[] %multiply.1292.clone.1), metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %multiply.1302.clone.1 = f32[] multiply(f32[] %param_25.8, f32[] %constant_11250_clone_1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %sqrt.53.clone.1 = f32[] sqrt(f32[] %multiply.1302.clone.1), metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %multiply.1319.clone.1 = f32[] multiply(f32[] %param_26.8, f32[] %constant_11268_clone_1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %sqrt.55.clone.1 = f32[] sqrt(f32[] %multiply.1319.clone.1), metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %multiply.1329.clone.1 = f32[] multiply(f32[] %param_27.8, f32[] %constant_11250_clone_1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %sqrt.57.clone.1 = f32[] sqrt(f32[] %multiply.1329.clone.1), metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %multiply.1348.clone.1 = f32[] multiply(f32[] %param_29.2, f32[] %constant_11268_clone_1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %sqrt.59.clone.1 = f32[] sqrt(f32[] %multiply.1348.clone.1), metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %constant_11701_clone_1 = f32[] constant(3.05175796e-08)
  %multiply.1375.clone.1 = f32[] multiply(f32[] %param_28.5, f32[] %constant_11701_clone_1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %sqrt.61.clone.1 = f32[] sqrt(f32[] %multiply.1375.clone.1), metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  ROOT %tuple.660 = (f32[], f32[], f32[], f32[], f32[], /*index=5*/f32[], f32[], f32[], f32[], f32[], /*index=10*/f32[], f32[], f32[], f32[], f32[], /*index=15*/f32[], f32[], f32[], f32[], f32[], /*index=20*/f32[], f32[], f32[], f32[], f32[], /*index=25*/f32[], f32[], f32[], f32[], f32[], /*index=30*/f32[]) tuple(f32[] %sqrt.3, f32[] %sqrt.0.clone.1, f32[] %sqrt.5.clone.1, f32[] %sqrt.7.clone.1, f32[] %sqrt.9.clone.1, /*index=5*/f32[] %sqrt.11.clone.1, f32[] %sqrt.13.clone.1, f32[] %sqrt.15.clone.1, f32[] %sqrt.17.clone.1, f32[] %sqrt.19.clone.1, /*index=10*/f32[] %sqrt.21.clone.1, f32[] %sqrt.23.clone.1, f32[] %sqrt.25.clone.1, f32[] %sqrt.27.clone.1, f32[] %sqrt.29.clone.1, /*index=15*/f32[] %sqrt.31.clone.1, f32[] %sqrt.33.clone.1, f32[] %sqrt.35.clone.1, f32[] %sqrt.37.clone.1, f32[] %sqrt.39.clone.1, /*index=20*/f32[] %sqrt.41.clone.1, f32[] %sqrt.43.clone.1, f32[] %sqrt.45.clone.1, f32[] %sqrt.47.clone.1, f32[] %sqrt.49.clone.1, /*index=25*/f32[] %sqrt.51.clone.1, f32[] %sqrt.53.clone.1, f32[] %sqrt.55.clone.1, f32[] %sqrt.57.clone.1, f32[] %sqrt.59.clone.1, /*index=30*/f32[] %sqrt.61.clone.1)
}

%primitive_computation_add__1.16025 (parameter.16026: f32[], parameter.16027: f32[]) -> f32[] {
  %parameter.16026 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.16027 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.16028 = f32[] add(f32[] %parameter.16026, f32[] %parameter.16027), metadata={op_type="add" op_name="add"}
}

%fused_computation.314 (param_0.1340: f32[256]) -> f32[] {
  %param_0.1340 = f32[256]{0} parameter(0)
  %multiply.958 = f32[256]{0} multiply(f32[256]{0} %param_0.1340, f32[256]{0} %param_0.1340), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %constant_11207 = f32[] constant(0)
  ROOT %reduce.201 = f32[] reduce(f32[256]{0} %multiply.958, f32[] %constant_11207), dimensions={0}, to_apply=%primitive_computation_add__1.16025, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
}

%fused_computation.315 (param_0.2168: f32[], param_1.2623: f32[], param_2.2312: f32[], param_3.2067: f32[], param_4.1057: f32[], param_5.506: f32[1024,256], param_6.452: f32[], param_7.431: f32[256], param_8.323: f32[1024,256], param_9.209: f32[1024]) -> f32[1024,256] {
  %param_6.452 = f32[] parameter(6)
  %broadcast.1296 = f32[1024,256]{1,0} broadcast(f32[] %param_6.452), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  %param_5.506 = f32[1024,256]{1,0} parameter(5)
  %multiply.961 = f32[1024,256]{1,0} multiply(f32[1024,256]{1,0} %broadcast.1296, f32[1024,256]{1,0} %param_5.506), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  %param_2.2312 = f32[] parameter(2)
  %param_3.2067 = f32[] parameter(3)
  %param_4.1057 = f32[] parameter(4)
  %maximum.6 = f32[] maximum(f32[] %param_3.2067, f32[] %param_4.1057), metadata={op_type="max" op_name="pmap(_multi_device_update_fn)/max" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=122}
  %multiply.960 = f32[] multiply(f32[] %param_2.2312, f32[] %maximum.6), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=122}
  %broadcast.1294 = f32[1024,256]{1,0} broadcast(f32[] %multiply.960), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=152}
  %param_8.323 = f32[1024,256]{1,0} parameter(8)
  %param_9.209 = f32[1024]{0} parameter(9)
  %constant_14917 = f32[] constant(0.125)
  %broadcast.2316 = f32[1024]{0} broadcast(f32[] %constant_14917), dimensions={}
  %multiply.1939 = f32[1024]{0} multiply(f32[1024]{0} %param_9.209, f32[1024]{0} %broadcast.2316)
  %broadcast.2315 = f32[1024,256]{1,0} broadcast(f32[1024]{0} %multiply.1939), dimensions={0}
  %multiply.1938 = f32[1024,256]{1,0} multiply(f32[1024,256]{1,0} %param_8.323, f32[1024,256]{1,0} %broadcast.2315), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  %param_7.431 = f32[256]{0} parameter(7)
  %broadcast.2314 = f32[1024,256]{1,0} broadcast(f32[256]{0} %param_7.431), dimensions={1}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  %multiply.1937 = f32[1024,256]{1,0} multiply(f32[1024,256]{1,0} %multiply.1938, f32[1024,256]{1,0} %broadcast.2314), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  %constant_11222 = f32[] constant(1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/metrics.py" source_line=617}
  %param_0.2168 = f32[] parameter(0)
  %param_1.2623 = f32[] parameter(1)
  %divide.142 = f32[] divide(f32[] %param_0.2168, f32[] %param_1.2623), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %maximum.5 = f32[] maximum(f32[] %constant_11222, f32[] %divide.142), metadata={op_type="max" op_name="pmap(_multi_device_update_fn)/max" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %broadcast.1292 = f32[1024,256]{1,0} broadcast(f32[] %maximum.5), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=150}
  %divide.141 = f32[1024,256]{1,0} divide(f32[1024,256]{1,0} %multiply.1937, f32[1024,256]{1,0} %broadcast.1292), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=150}
  %multiply.959 = f32[1024,256]{1,0} multiply(f32[1024,256]{1,0} %broadcast.1294, f32[1024,256]{1,0} %divide.141), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=152}
  ROOT %subtract.258 = f32[1024,256]{1,0} subtract(f32[1024,256]{1,0} %multiply.961, f32[1024,256]{1,0} %multiply.959), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
}

%fused_computation.316 (param_0.499: f32[]) -> f32[] {
  %param_0.499 = f32[] parameter(0)
  %constant_11230 = f32[] constant(3.81469727e-06)
  %multiply.962 = f32[] multiply(f32[] %param_0.499, f32[] %constant_11230), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  ROOT %sqrt.4 = f32[] sqrt(f32[] %multiply.962), metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
}

%fused_computation.319 (param_0.2210: f32[], param_1.2682: f32[256], param_2.2436: f32[], param_3.2255: f32[256], param_4.1399: f32[256], param_5.572: f32[]) -> (f32[256], f32[256], f32[256]) {
  %param_2.2436 = f32[] parameter(2)
  %broadcast.1572.clone.1 = f32[256]{0} broadcast(f32[] %param_2.2436), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=131}
  %param_3.2255 = f32[256]{0} parameter(3)
  %multiply.968.clone.1 = f32[256]{0} multiply(f32[256]{0} %broadcast.1572.clone.1, f32[256]{0} %param_3.2255), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
  %param_1.2682 = f32[256]{0} parameter(1)
  %constant_11242_clone_1 = f32[] constant(1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/metrics.py" source_line=617}
  %subtract.296.clone.1 = f32[] subtract(f32[] %constant_11242_clone_1, f32[] %param_2.2436), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=124}
  %constant_11241_clone_1 = f32[] constant(0.0009765625)
  %multiply.1428.clone.1 = f32[] multiply(f32[] %subtract.296.clone.1, f32[] %constant_11241_clone_1)
  %broadcast.1573.clone.1 = f32[256]{0} broadcast(f32[] %multiply.1428.clone.1), dimensions={}
  %multiply.967.clone.1 = f32[256]{0} multiply(f32[256]{0} %param_1.2682, f32[256]{0} %broadcast.1573.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
  %add.1975.clone.1 = f32[256]{0} add(f32[256]{0} %multiply.968.clone.1, f32[256]{0} %multiply.967.clone.1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
  %param_0.2210 = f32[] parameter(0)
  %broadcast.1570 = f32[256]{0} broadcast(f32[] %param_0.2210), dimensions={}, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  %add.1974 = f32[256]{0} add(f32[256]{0} %add.1975.clone.1, f32[256]{0} %broadcast.1570), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
  %constant_11239 = f32[] constant(-0.5), metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
  %broadcast.1569 = f32[256]{0} broadcast(f32[] %constant_11239), dimensions={}, metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
  %power.1 = f32[256]{0} power(f32[256]{0} %add.1974, f32[256]{0} %broadcast.1569), metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
  %param_5.572 = f32[] parameter(5)
  %constant_11507_clone_1 = f32[] constant(0.00390625)
  %multiply.1230.clone.1 = f32[] multiply(f32[] %param_5.572, f32[] %constant_11507_clone_1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=135}
  %broadcast.1374.clone.1 = f32[256]{0} broadcast(f32[] %multiply.1230.clone.1), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  %param_4.1399 = f32[256]{0} parameter(4)
  %add.2043.clone.1 = f32[256]{0} add(f32[256]{0} %param_4.1399, f32[256]{0} %broadcast.1570), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  %divide.191.clone.1 = f32[256]{0} divide(f32[256]{0} %broadcast.1374.clone.1, f32[256]{0} %add.2043.clone.1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  %constant_11509_clone_1 = f32[] constant(0.5), metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  %broadcast.1373.clone.1 = f32[256]{0} broadcast(f32[] %constant_11509_clone_1), dimensions={}, metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  %power.31.clone.1 = f32[256]{0} power(f32[256]{0} %divide.191.clone.1, f32[256]{0} %broadcast.1373.clone.1), metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  ROOT %tuple.670 = (f32[256]{0}, f32[256]{0}, f32[256]{0}) tuple(f32[256]{0} %power.1, f32[256]{0} %add.1975.clone.1, f32[256]{0} %power.31.clone.1)
}

%fused_computation.324 (param_0.515: f32[16,64,256]) -> f32[256,1024] {
  %param_0.515 = f32[16,64,256]{2,1,0} parameter(0)
  %transpose.92 = f32[256,16,64]{0,2,1} transpose(f32[16,64,256]{2,1,0} %param_0.515), dimensions={2,0,1}
  ROOT %bitcast.688 = f32[256,1024]{0,1} bitcast(f32[256,16,64]{0,2,1} %transpose.92)
}

%primitive_computation_add__1.15847 (parameter.15848: f32[], parameter.15849: f32[]) -> f32[] {
  %parameter.15848 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.15849 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.15850 = f32[] add(f32[] %parameter.15848, f32[] %parameter.15849), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.15643 (parameter.15644: f32[], parameter.15645: f32[]) -> f32[] {
  %parameter.15644 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.15645 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.15646 = f32[] add(f32[] %parameter.15644, f32[] %parameter.15645), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.15439 (parameter.15440: f32[], parameter.15441: f32[]) -> f32[] {
  %parameter.15440 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.15441 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.15442 = f32[] add(f32[] %parameter.15440, f32[] %parameter.15441), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.15235 (parameter.15236: f32[], parameter.15237: f32[]) -> f32[] {
  %parameter.15236 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.15237 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.15238 = f32[] add(f32[] %parameter.15236, f32[] %parameter.15237), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.14215 (parameter.14216: f32[], parameter.14217: f32[]) -> f32[] {
  %parameter.14216 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.14217 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.14218 = f32[] add(f32[] %parameter.14216, f32[] %parameter.14217), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.13885 (parameter.13886: f32[], parameter.13887: f32[]) -> f32[] {
  %parameter.13886 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.13887 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.13888 = f32[] add(f32[] %parameter.13886, f32[] %parameter.13887), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.13681 (parameter.13682: f32[], parameter.13683: f32[]) -> f32[] {
  %parameter.13682 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.13683 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.13684 = f32[] add(f32[] %parameter.13682, f32[] %parameter.13683), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.13477 (parameter.13478: f32[], parameter.13479: f32[]) -> f32[] {
  %parameter.13478 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.13479 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.13480 = f32[] add(f32[] %parameter.13478, f32[] %parameter.13479), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.13273 (parameter.13274: f32[], parameter.13275: f32[]) -> f32[] {
  %parameter.13274 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.13275 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.13276 = f32[] add(f32[] %parameter.13274, f32[] %parameter.13275), metadata={op_type="add" op_name="add"}
}

%fused_computation.329 (param_0.2213: f32[], param_1.2692: f32[4096], param_2.2449: f32[], param_3.2266: f32[4096], param_4.1403: f32[4096], param_5.577: f32[4096], param_6.525: f32[4096], param_7.505: f32[4096], param_8.390: f32[4096], param_9.255: f32[4096], param_10.230: f32[4096], param_11.231: f32[4096], param_12.250: f32[4096], param_13.292: f32[4096], param_14.279: f32[4096], param_15.221: f32[4096], param_16.133: f32[4096], param_17.68: f32[4096], param_18.59: f32[4096], param_19.68: f32[4096]) -> (f32[], f32[4096], f32[4096], f32[], f32[], /*index=5*/f32[4096], f32[4096], f32[], f32[], f32[4096], /*index=10*/f32[4096], f32[], f32[], f32[4096], f32[4096], /*index=15*/f32[], f32[], f32[4096], f32[4096], f32[], /*index=20*/f32[], f32[4096], f32[4096], f32[], f32[], /*index=25*/f32[4096], f32[4096], f32[], f32[], f32[4096], /*index=30*/f32[4096], f32[], f32[], f32[4096], f32[4096], /*index=35*/f32[]) {
  %param_1.2692 = f32[4096]{0} parameter(1)
  %constant_11259_clone_1 = f32[] constant(0.125)
  %broadcast.1575.clone.1 = f32[4096]{0} broadcast(f32[] %constant_11259_clone_1), dimensions={}
  %multiply.1429.clone.1 = f32[4096]{0} multiply(f32[4096]{0} %param_1.2692, f32[4096]{0} %broadcast.1575.clone.1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=200}
  %param_2.2449 = f32[] parameter(2)
  %broadcast.1580.clone.1 = f32[4096]{0} broadcast(f32[] %param_2.2449), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
  %param_3.2266 = f32[4096]{0} parameter(3)
  %multiply.983.clone.1 = f32[4096]{0} multiply(f32[4096]{0} %broadcast.1580.clone.1, f32[4096]{0} %param_3.2266), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=143}
  %constant_11264_clone_1 = f32[] constant(1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/metrics.py" source_line=617}
  %subtract.297.clone.1 = f32[] subtract(f32[] %constant_11264_clone_1, f32[] %param_2.2449), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=124}
  %broadcast.1578.clone.1 = f32[4096]{0} broadcast(f32[] %subtract.297.clone.1), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=143}
  %multiply.1430.clone.1 = f32[4096]{0} multiply(f32[4096]{0} %multiply.1429.clone.1, f32[4096]{0} %multiply.1429.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=126}
  %multiply.982.clone.1 = f32[4096]{0} multiply(f32[4096]{0} %broadcast.1578.clone.1, f32[4096]{0} %multiply.1430.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=143}
  %add.1980.clone.1 = f32[4096]{0} add(f32[4096]{0} %multiply.983.clone.1, f32[4096]{0} %multiply.982.clone.1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=143}
  %param_0.2213 = f32[] parameter(0)
  %broadcast.1576.clone.1 = f32[4096]{0} broadcast(f32[] %param_0.2213), dimensions={}, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
  %add.1978.clone.1 = f32[4096]{0} add(f32[4096]{0} %add.1980.clone.1, f32[4096]{0} %broadcast.1576.clone.1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=145}
  %constant_11260_clone_1 = f32[] constant(-0.5), metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
  %broadcast.1577.clone.1 = f32[4096]{0} broadcast(f32[] %constant_11260_clone_1), dimensions={}, metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
  %power.3.clone.1 = f32[4096]{0} power(f32[4096]{0} %add.1978.clone.1, f32[4096]{0} %broadcast.1577.clone.1), metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=145}
  %multiply.981.clone.1 = f32[4096]{0} multiply(f32[4096]{0} %multiply.1429.clone.1, f32[4096]{0} %power.3.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=145}
  %multiply.980 = f32[4096]{0} multiply(f32[4096]{0} %multiply.981.clone.1, f32[4096]{0} %multiply.981.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %constant_11258 = f32[] constant(0)
  %reduce.204 = f32[] reduce(f32[4096]{0} %multiply.980, f32[] %constant_11258), dimensions={0}, to_apply=%primitive_computation_add__1.15847, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %reduce.279.clone.1 = f32[] reduce(f32[4096]{0} %multiply.1430.clone.1, f32[] %constant_11258), dimensions={0}, to_apply=%scalar_add_computation, metadata={op_type="dot_general" op_name="pmap(_multi_device_update_fn)/dot_general[ dimension_numbers=(((0,), (0,)), ((), ()))\n                                           precision=None\n                                           preferred_element_type=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %param_4.1403 = f32[4096]{0} parameter(4)
  %multiply.1432.clone.1.clone.1 = f32[4096]{0} multiply(f32[4096]{0} %param_4.1403, f32[4096]{0} %broadcast.1575.clone.1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=200}
  %param_5.577 = f32[4096]{0} parameter(5)
  %multiply.1010.clone.1.clone.1 = f32[4096]{0} multiply(f32[4096]{0} %broadcast.1580.clone.1, f32[4096]{0} %param_5.577), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=143}
  %multiply.1433.clone.1.clone.1 = f32[4096]{0} multiply(f32[4096]{0} %multiply.1432.clone.1.clone.1, f32[4096]{0} %multiply.1432.clone.1.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=126}
  %multiply.1009.clone.1.clone.1 = f32[4096]{0} multiply(f32[4096]{0} %broadcast.1578.clone.1, f32[4096]{0} %multiply.1433.clone.1.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=143}
  %add.1987.clone.1.clone.1 = f32[4096]{0} add(f32[4096]{0} %multiply.1010.clone.1.clone.1, f32[4096]{0} %multiply.1009.clone.1.clone.1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=143}
  %add.1985.clone.1.clone.1 = f32[4096]{0} add(f32[4096]{0} %add.1987.clone.1.clone.1, f32[4096]{0} %broadcast.1576.clone.1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=145}
  %power.6.clone.1.clone.1 = f32[4096]{0} power(f32[4096]{0} %add.1985.clone.1.clone.1, f32[4096]{0} %broadcast.1577.clone.1), metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=145}
  %multiply.1008.clone.1.clone.1 = f32[4096]{0} multiply(f32[4096]{0} %multiply.1432.clone.1.clone.1, f32[4096]{0} %power.6.clone.1.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=145}
  %multiply.1007.clone.1 = f32[4096]{0} multiply(f32[4096]{0} %multiply.1008.clone.1.clone.1, f32[4096]{0} %multiply.1008.clone.1.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %reduce.208.clone.1 = f32[] reduce(f32[4096]{0} %multiply.1007.clone.1, f32[] %constant_11258), dimensions={0}, to_apply=%primitive_computation_add__1.15643, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %reduce.278.clone.1.clone.1 = f32[] reduce(f32[4096]{0} %multiply.1433.clone.1.clone.1, f32[] %constant_11258), dimensions={0}, to_apply=%scalar_add_computation, metadata={op_type="dot_general" op_name="pmap(_multi_device_update_fn)/dot_general[ dimension_numbers=(((0,), (0,)), ((), ()))\n                                           precision=None\n                                           preferred_element_type=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %param_6.525 = f32[4096]{0} parameter(6)
  %multiply.1435.clone.1.clone.1 = f32[4096]{0} multiply(f32[4096]{0} %param_6.525, f32[4096]{0} %broadcast.1575.clone.1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=200}
  %param_7.505 = f32[4096]{0} parameter(7)
  %multiply.1037.clone.1.clone.1 = f32[4096]{0} multiply(f32[4096]{0} %broadcast.1580.clone.1, f32[4096]{0} %param_7.505), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=143}
  %multiply.1436.clone.1.clone.1 = f32[4096]{0} multiply(f32[4096]{0} %multiply.1435.clone.1.clone.1, f32[4096]{0} %multiply.1435.clone.1.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=126}
  %multiply.1036.clone.1.clone.1 = f32[4096]{0} multiply(f32[4096]{0} %broadcast.1578.clone.1, f32[4096]{0} %multiply.1436.clone.1.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=143}
  %add.1993.clone.1.clone.1 = f32[4096]{0} add(f32[4096]{0} %multiply.1037.clone.1.clone.1, f32[4096]{0} %multiply.1036.clone.1.clone.1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=143}
  %add.1992.clone.1.clone.1 = f32[4096]{0} add(f32[4096]{0} %add.1993.clone.1.clone.1, f32[4096]{0} %broadcast.1576.clone.1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=145}
  %power.9.clone.1.clone.1 = f32[4096]{0} power(f32[4096]{0} %add.1992.clone.1.clone.1, f32[4096]{0} %broadcast.1577.clone.1), metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=145}
  %multiply.1035.clone.1.clone.1 = f32[4096]{0} multiply(f32[4096]{0} %multiply.1435.clone.1.clone.1, f32[4096]{0} %power.9.clone.1.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=145}
  %multiply.1034.clone.1 = f32[4096]{0} multiply(f32[4096]{0} %multiply.1035.clone.1.clone.1, f32[4096]{0} %multiply.1035.clone.1.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %reduce.212.clone.1 = f32[] reduce(f32[4096]{0} %multiply.1034.clone.1, f32[] %constant_11258), dimensions={0}, to_apply=%primitive_computation_add__1.15439, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %reduce.277.clone.1.clone.1 = f32[] reduce(f32[4096]{0} %multiply.1436.clone.1.clone.1, f32[] %constant_11258), dimensions={0}, to_apply=%scalar_add_computation, metadata={op_type="dot_general" op_name="pmap(_multi_device_update_fn)/dot_general[ dimension_numbers=(((0,), (0,)), ((), ()))\n                                           precision=None\n                                           preferred_element_type=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %param_8.390 = f32[4096]{0} parameter(8)
  %multiply.1438.clone.1.clone.1 = f32[4096]{0} multiply(f32[4096]{0} %param_8.390, f32[4096]{0} %broadcast.1575.clone.1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=200}
  %param_9.255 = f32[4096]{0} parameter(9)
  %multiply.1064.clone.1.clone.1 = f32[4096]{0} multiply(f32[4096]{0} %broadcast.1580.clone.1, f32[4096]{0} %param_9.255), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=143}
  %multiply.1439.clone.1.clone.1 = f32[4096]{0} multiply(f32[4096]{0} %multiply.1438.clone.1.clone.1, f32[4096]{0} %multiply.1438.clone.1.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=126}
  %multiply.1063.clone.1.clone.1 = f32[4096]{0} multiply(f32[4096]{0} %broadcast.1578.clone.1, f32[4096]{0} %multiply.1439.clone.1.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=143}
  %add.2000.clone.1.clone.1 = f32[4096]{0} add(f32[4096]{0} %multiply.1064.clone.1.clone.1, f32[4096]{0} %multiply.1063.clone.1.clone.1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=143}
  %add.1999.clone.1.clone.1 = f32[4096]{0} add(f32[4096]{0} %add.2000.clone.1.clone.1, f32[4096]{0} %broadcast.1576.clone.1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=145}
  %power.12.clone.1.clone.1 = f32[4096]{0} power(f32[4096]{0} %add.1999.clone.1.clone.1, f32[4096]{0} %broadcast.1577.clone.1), metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=145}
  %multiply.1062.clone.1.clone.1 = f32[4096]{0} multiply(f32[4096]{0} %multiply.1438.clone.1.clone.1, f32[4096]{0} %power.12.clone.1.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=145}
  %multiply.1061.clone.1 = f32[4096]{0} multiply(f32[4096]{0} %multiply.1062.clone.1.clone.1, f32[4096]{0} %multiply.1062.clone.1.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %reduce.216.clone.1 = f32[] reduce(f32[4096]{0} %multiply.1061.clone.1, f32[] %constant_11258), dimensions={0}, to_apply=%primitive_computation_add__1.15235, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %reduce.276.clone.1.clone.1 = f32[] reduce(f32[4096]{0} %multiply.1439.clone.1.clone.1, f32[] %constant_11258), dimensions={0}, to_apply=%scalar_add_computation, metadata={op_type="dot_general" op_name="pmap(_multi_device_update_fn)/dot_general[ dimension_numbers=(((0,), (0,)), ((), ()))\n                                           precision=None\n                                           preferred_element_type=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %param_10.230 = f32[4096]{0} parameter(10)
  %multiply.1461.clone.1.clone.1 = f32[4096]{0} multiply(f32[4096]{0} %param_10.230, f32[4096]{0} %broadcast.1575.clone.1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=200}
  %param_11.231 = f32[4096]{0} parameter(11)
  %multiply.1199.clone.1.clone.1 = f32[4096]{0} multiply(f32[4096]{0} %broadcast.1580.clone.1, f32[4096]{0} %param_11.231), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=143}
  %multiply.1462.clone.1.clone.1 = f32[4096]{0} multiply(f32[4096]{0} %multiply.1461.clone.1.clone.1, f32[4096]{0} %multiply.1461.clone.1.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=126}
  %multiply.1198.clone.1.clone.1 = f32[4096]{0} multiply(f32[4096]{0} %broadcast.1578.clone.1, f32[4096]{0} %multiply.1462.clone.1.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=143}
  %add.2035.clone.1.clone.1 = f32[4096]{0} add(f32[4096]{0} %multiply.1199.clone.1.clone.1, f32[4096]{0} %multiply.1198.clone.1.clone.1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=143}
  %add.2034.clone.1.clone.1 = f32[4096]{0} add(f32[4096]{0} %add.2035.clone.1.clone.1, f32[4096]{0} %broadcast.1576.clone.1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=145}
  %power.27.clone.1.clone.1 = f32[4096]{0} power(f32[4096]{0} %add.2034.clone.1.clone.1, f32[4096]{0} %broadcast.1577.clone.1), metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=145}
  %multiply.1197.clone.1.clone.1 = f32[4096]{0} multiply(f32[4096]{0} %multiply.1461.clone.1.clone.1, f32[4096]{0} %power.27.clone.1.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=145}
  %multiply.1196.clone.1 = f32[4096]{0} multiply(f32[4096]{0} %multiply.1197.clone.1.clone.1, f32[4096]{0} %multiply.1197.clone.1.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %reduce.237.clone.1 = f32[] reduce(f32[4096]{0} %multiply.1196.clone.1, f32[] %constant_11258), dimensions={0}, to_apply=%primitive_computation_add__1.14215, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %reduce.271.clone.1.clone.1 = f32[] reduce(f32[4096]{0} %multiply.1462.clone.1.clone.1, f32[] %constant_11258), dimensions={0}, to_apply=%scalar_add_computation, metadata={op_type="dot_general" op_name="pmap(_multi_device_update_fn)/dot_general[ dimension_numbers=(((0,), (0,)), ((), ()))\n                                           precision=None\n                                           preferred_element_type=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %param_12.250 = f32[4096]{0} parameter(12)
  %multiply.1465.clone.1.clone.1 = f32[4096]{0} multiply(f32[4096]{0} %param_12.250, f32[4096]{0} %broadcast.1575.clone.1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=200}
  %param_13.292 = f32[4096]{0} parameter(13)
  %multiply.1244.clone.1.clone.1 = f32[4096]{0} multiply(f32[4096]{0} %broadcast.1580.clone.1, f32[4096]{0} %param_13.292), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=143}
  %multiply.1466.clone.1.clone.1 = f32[4096]{0} multiply(f32[4096]{0} %multiply.1465.clone.1.clone.1, f32[4096]{0} %multiply.1465.clone.1.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=126}
  %multiply.1243.clone.1.clone.1 = f32[4096]{0} multiply(f32[4096]{0} %broadcast.1578.clone.1, f32[4096]{0} %multiply.1466.clone.1.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=143}
  %add.2047.clone.1.clone.1 = f32[4096]{0} add(f32[4096]{0} %multiply.1244.clone.1.clone.1, f32[4096]{0} %multiply.1243.clone.1.clone.1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=143}
  %add.2046.clone.1.clone.1 = f32[4096]{0} add(f32[4096]{0} %add.2047.clone.1.clone.1, f32[4096]{0} %broadcast.1576.clone.1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=145}
  %power.32.clone.1.clone.1 = f32[4096]{0} power(f32[4096]{0} %add.2046.clone.1.clone.1, f32[4096]{0} %broadcast.1577.clone.1), metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=145}
  %multiply.1242.clone.1.clone.1 = f32[4096]{0} multiply(f32[4096]{0} %multiply.1465.clone.1.clone.1, f32[4096]{0} %power.32.clone.1.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=145}
  %multiply.1241.clone.1 = f32[4096]{0} multiply(f32[4096]{0} %multiply.1242.clone.1.clone.1, f32[4096]{0} %multiply.1242.clone.1.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %reduce.243.clone.1 = f32[] reduce(f32[4096]{0} %multiply.1241.clone.1, f32[] %constant_11258), dimensions={0}, to_apply=%primitive_computation_add__1.13885, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %reduce.270.clone.1.clone.1 = f32[] reduce(f32[4096]{0} %multiply.1466.clone.1.clone.1, f32[] %constant_11258), dimensions={0}, to_apply=%scalar_add_computation, metadata={op_type="dot_general" op_name="pmap(_multi_device_update_fn)/dot_general[ dimension_numbers=(((0,), (0,)), ((), ()))\n                                           precision=None\n                                           preferred_element_type=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %param_14.279 = f32[4096]{0} parameter(14)
  %multiply.1468.clone.1.clone.1 = f32[4096]{0} multiply(f32[4096]{0} %param_14.279, f32[4096]{0} %broadcast.1575.clone.1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=200}
  %param_15.221 = f32[4096]{0} parameter(15)
  %multiply.1273.clone.1.clone.1 = f32[4096]{0} multiply(f32[4096]{0} %broadcast.1580.clone.1, f32[4096]{0} %param_15.221), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=143}
  %multiply.1469.clone.1.clone.1 = f32[4096]{0} multiply(f32[4096]{0} %multiply.1468.clone.1.clone.1, f32[4096]{0} %multiply.1468.clone.1.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=126}
  %multiply.1272.clone.1.clone.1 = f32[4096]{0} multiply(f32[4096]{0} %broadcast.1578.clone.1, f32[4096]{0} %multiply.1469.clone.1.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=143}
  %add.2054.clone.1.clone.1 = f32[4096]{0} add(f32[4096]{0} %multiply.1273.clone.1.clone.1, f32[4096]{0} %multiply.1272.clone.1.clone.1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=143}
  %add.2053.clone.1.clone.1 = f32[4096]{0} add(f32[4096]{0} %add.2054.clone.1.clone.1, f32[4096]{0} %broadcast.1576.clone.1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=145}
  %power.35.clone.1.clone.1 = f32[4096]{0} power(f32[4096]{0} %add.2053.clone.1.clone.1, f32[4096]{0} %broadcast.1577.clone.1), metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=145}
  %multiply.1271.clone.1.clone.1 = f32[4096]{0} multiply(f32[4096]{0} %multiply.1468.clone.1.clone.1, f32[4096]{0} %power.35.clone.1.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=145}
  %multiply.1270.clone.1 = f32[4096]{0} multiply(f32[4096]{0} %multiply.1271.clone.1.clone.1, f32[4096]{0} %multiply.1271.clone.1.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %reduce.247.clone.1 = f32[] reduce(f32[4096]{0} %multiply.1270.clone.1, f32[] %constant_11258), dimensions={0}, to_apply=%primitive_computation_add__1.13681, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %reduce.269.clone.1.clone.1 = f32[] reduce(f32[4096]{0} %multiply.1469.clone.1.clone.1, f32[] %constant_11258), dimensions={0}, to_apply=%scalar_add_computation, metadata={op_type="dot_general" op_name="pmap(_multi_device_update_fn)/dot_general[ dimension_numbers=(((0,), (0,)), ((), ()))\n                                           precision=None\n                                           preferred_element_type=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %param_16.133 = f32[4096]{0} parameter(16)
  %multiply.1471.clone.1.clone.1 = f32[4096]{0} multiply(f32[4096]{0} %param_16.133, f32[4096]{0} %broadcast.1575.clone.1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=200}
  %param_17.68 = f32[4096]{0} parameter(17)
  %multiply.1301.clone.1.clone.1 = f32[4096]{0} multiply(f32[4096]{0} %broadcast.1580.clone.1, f32[4096]{0} %param_17.68), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=143}
  %multiply.1472.clone.1.clone.1 = f32[4096]{0} multiply(f32[4096]{0} %multiply.1471.clone.1.clone.1, f32[4096]{0} %multiply.1471.clone.1.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=126}
  %multiply.1300.clone.1.clone.1 = f32[4096]{0} multiply(f32[4096]{0} %broadcast.1578.clone.1, f32[4096]{0} %multiply.1472.clone.1.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=143}
  %add.2061.clone.1.clone.1 = f32[4096]{0} add(f32[4096]{0} %multiply.1301.clone.1.clone.1, f32[4096]{0} %multiply.1300.clone.1.clone.1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=143}
  %add.2060.clone.1.clone.1 = f32[4096]{0} add(f32[4096]{0} %add.2061.clone.1.clone.1, f32[4096]{0} %broadcast.1576.clone.1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=145}
  %power.38.clone.1.clone.1 = f32[4096]{0} power(f32[4096]{0} %add.2060.clone.1.clone.1, f32[4096]{0} %broadcast.1577.clone.1), metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=145}
  %multiply.1299.clone.1.clone.1 = f32[4096]{0} multiply(f32[4096]{0} %multiply.1471.clone.1.clone.1, f32[4096]{0} %power.38.clone.1.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=145}
  %multiply.1298.clone.1 = f32[4096]{0} multiply(f32[4096]{0} %multiply.1299.clone.1.clone.1, f32[4096]{0} %multiply.1299.clone.1.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %reduce.251.clone.1 = f32[] reduce(f32[4096]{0} %multiply.1298.clone.1, f32[] %constant_11258), dimensions={0}, to_apply=%primitive_computation_add__1.13477, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %reduce.268.clone.1.clone.1 = f32[] reduce(f32[4096]{0} %multiply.1472.clone.1.clone.1, f32[] %constant_11258), dimensions={0}, to_apply=%scalar_add_computation, metadata={op_type="dot_general" op_name="pmap(_multi_device_update_fn)/dot_general[ dimension_numbers=(((0,), (0,)), ((), ()))\n                                           precision=None\n                                           preferred_element_type=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %param_18.59 = f32[4096]{0} parameter(18)
  %multiply.1474.clone.1.clone.1 = f32[4096]{0} multiply(f32[4096]{0} %param_18.59, f32[4096]{0} %broadcast.1575.clone.1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=200}
  %param_19.68 = f32[4096]{0} parameter(19)
  %multiply.1328.clone.1.clone.1 = f32[4096]{0} multiply(f32[4096]{0} %broadcast.1580.clone.1, f32[4096]{0} %param_19.68), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=143}
  %multiply.1475.clone.1.clone.1 = f32[4096]{0} multiply(f32[4096]{0} %multiply.1474.clone.1.clone.1, f32[4096]{0} %multiply.1474.clone.1.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=126}
  %multiply.1327.clone.1.clone.1 = f32[4096]{0} multiply(f32[4096]{0} %broadcast.1578.clone.1, f32[4096]{0} %multiply.1475.clone.1.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=143}
  %add.2068.clone.1.clone.1 = f32[4096]{0} add(f32[4096]{0} %multiply.1328.clone.1.clone.1, f32[4096]{0} %multiply.1327.clone.1.clone.1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=143}
  %add.2067.clone.1.clone.1 = f32[4096]{0} add(f32[4096]{0} %add.2068.clone.1.clone.1, f32[4096]{0} %broadcast.1576.clone.1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=145}
  %power.41.clone.1.clone.1 = f32[4096]{0} power(f32[4096]{0} %add.2067.clone.1.clone.1, f32[4096]{0} %broadcast.1577.clone.1), metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=145}
  %multiply.1326.clone.1.clone.1 = f32[4096]{0} multiply(f32[4096]{0} %multiply.1474.clone.1.clone.1, f32[4096]{0} %power.41.clone.1.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=145}
  %multiply.1325.clone.1 = f32[4096]{0} multiply(f32[4096]{0} %multiply.1326.clone.1.clone.1, f32[4096]{0} %multiply.1326.clone.1.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %reduce.255.clone.1 = f32[] reduce(f32[4096]{0} %multiply.1325.clone.1, f32[] %constant_11258), dimensions={0}, to_apply=%primitive_computation_add__1.13273, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %reduce.267.clone.1.clone.1 = f32[] reduce(f32[4096]{0} %multiply.1475.clone.1.clone.1, f32[] %constant_11258), dimensions={0}, to_apply=%scalar_add_computation, metadata={op_type="dot_general" op_name="pmap(_multi_device_update_fn)/dot_general[ dimension_numbers=(((0,), (0,)), ((), ()))\n                                           precision=None\n                                           preferred_element_type=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  ROOT %tuple.678 = (f32[], f32[4096]{0}, f32[4096]{0}, f32[], f32[], /*index=5*/f32[4096]{0}, f32[4096]{0}, f32[], f32[], f32[4096]{0}, /*index=10*/f32[4096]{0}, f32[], f32[], f32[4096]{0}, f32[4096]{0}, /*index=15*/f32[], f32[], f32[4096]{0}, f32[4096]{0}, f32[], /*index=20*/f32[], f32[4096]{0}, f32[4096]{0}, f32[], f32[], /*index=25*/f32[4096]{0}, f32[4096]{0}, f32[], f32[], f32[4096]{0}, /*index=30*/f32[4096]{0}, f32[], f32[], f32[4096]{0}, f32[4096]{0}, /*index=35*/f32[]) tuple(f32[] %reduce.204, f32[4096]{0} %multiply.981.clone.1, f32[4096]{0} %add.1980.clone.1, f32[] %reduce.279.clone.1, f32[] %reduce.208.clone.1, /*index=5*/f32[4096]{0} %multiply.1008.clone.1.clone.1, f32[4096]{0} %add.1987.clone.1.clone.1, f32[] %reduce.278.clone.1.clone.1, f32[] %reduce.212.clone.1, f32[4096]{0} %multiply.1035.clone.1.clone.1, /*index=10*/f32[4096]{0} %add.1993.clone.1.clone.1, f32[] %reduce.277.clone.1.clone.1, f32[] %reduce.216.clone.1, f32[4096]{0} %multiply.1062.clone.1.clone.1, f32[4096]{0} %add.2000.clone.1.clone.1, /*index=15*/f32[] %reduce.276.clone.1.clone.1, f32[] %reduce.237.clone.1, f32[4096]{0} %multiply.1197.clone.1.clone.1, f32[4096]{0} %add.2035.clone.1.clone.1, f32[] %reduce.271.clone.1.clone.1, /*index=20*/f32[] %reduce.243.clone.1, f32[4096]{0} %multiply.1242.clone.1.clone.1, f32[4096]{0} %add.2047.clone.1.clone.1, f32[] %reduce.270.clone.1.clone.1, f32[] %reduce.247.clone.1, /*index=25*/f32[4096]{0} %multiply.1271.clone.1.clone.1, f32[4096]{0} %add.2054.clone.1.clone.1, f32[] %reduce.269.clone.1.clone.1, f32[] %reduce.251.clone.1, f32[4096]{0} %multiply.1299.clone.1.clone.1, /*index=30*/f32[4096]{0} %add.2061.clone.1.clone.1, f32[] %reduce.268.clone.1.clone.1, f32[] %reduce.255.clone.1, f32[4096]{0} %multiply.1326.clone.1.clone.1, f32[4096]{0} %add.2068.clone.1.clone.1, /*index=35*/f32[] %reduce.267.clone.1.clone.1)
}

%primitive_computation_add__1.15209 (parameter.15210: f32[], parameter.15211: f32[]) -> f32[] {
  %parameter.15210 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.15211 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.15212 = f32[] add(f32[] %parameter.15210, f32[] %parameter.15211), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.14189 (parameter.14190: f32[], parameter.14191: f32[]) -> f32[] {
  %parameter.14190 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.14191 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.14192 = f32[] add(f32[] %parameter.14190, f32[] %parameter.14191), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.13859 (parameter.13860: f32[], parameter.13861: f32[]) -> f32[] {
  %parameter.13860 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.13861 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.13862 = f32[] add(f32[] %parameter.13860, f32[] %parameter.13861), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.13655 (parameter.13656: f32[], parameter.13657: f32[]) -> f32[] {
  %parameter.13656 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.13657 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.13658 = f32[] add(f32[] %parameter.13656, f32[] %parameter.13657), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.15413 (parameter.15414: f32[], parameter.15415: f32[]) -> f32[] {
  %parameter.15414 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.15415 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.15416 = f32[] add(f32[] %parameter.15414, f32[] %parameter.15415), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.13451 (parameter.13452: f32[], parameter.13453: f32[]) -> f32[] {
  %parameter.13452 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.13453 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.13454 = f32[] add(f32[] %parameter.13452, f32[] %parameter.13453), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.15617 (parameter.15618: f32[], parameter.15619: f32[]) -> f32[] {
  %parameter.15618 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.15619 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.15620 = f32[] add(f32[] %parameter.15618, f32[] %parameter.15619), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.13247 (parameter.13248: f32[], parameter.13249: f32[]) -> f32[] {
  %parameter.13248 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.13249 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.13250 = f32[] add(f32[] %parameter.13248, f32[] %parameter.13249), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.15821 (parameter.15822: f32[], parameter.15823: f32[]) -> f32[] {
  %parameter.15822 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.15823 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.15824 = f32[] add(f32[] %parameter.15822, f32[] %parameter.15823), metadata={op_type="add" op_name="add"}
}

%fused_computation.387 (param_0.1383: f32[4096], param_1.2943: f32[4096], param_2.2786: f32[4096], param_3.2648: f32[4096], param_4.1456: f32[4096], param_5.624: f32[4096], param_6.590: f32[4096], param_7.571: f32[4096], param_8.463: f32[4096]) -> (f32[], f32[], f32[], f32[], f32[], /*index=5*/f32[], f32[], f32[], f32[]) {
  %param_0.1383 = f32[4096]{0} parameter(0)
  %multiply.1066 = f32[4096]{0} multiply(f32[4096]{0} %param_0.1383, f32[4096]{0} %param_0.1383), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %constant_11333 = f32[] constant(0)
  %reduce.217 = f32[] reduce(f32[4096]{0} %multiply.1066, f32[] %constant_11333), dimensions={0}, to_apply=%primitive_computation_add__1.15209, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %param_1.2943 = f32[4096]{0} parameter(1)
  %multiply.1201.clone.1 = f32[4096]{0} multiply(f32[4096]{0} %param_1.2943, f32[4096]{0} %param_1.2943), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %reduce.238.clone.1 = f32[] reduce(f32[4096]{0} %multiply.1201.clone.1, f32[] %constant_11333), dimensions={0}, to_apply=%primitive_computation_add__1.14189, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %param_2.2786 = f32[4096]{0} parameter(2)
  %multiply.1247.clone.1 = f32[4096]{0} multiply(f32[4096]{0} %param_2.2786, f32[4096]{0} %param_2.2786), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %reduce.244.clone.1 = f32[] reduce(f32[4096]{0} %multiply.1247.clone.1, f32[] %constant_11333), dimensions={0}, to_apply=%primitive_computation_add__1.13859, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %param_3.2648 = f32[4096]{0} parameter(3)
  %multiply.1275.clone.1 = f32[4096]{0} multiply(f32[4096]{0} %param_3.2648, f32[4096]{0} %param_3.2648), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %reduce.248.clone.1 = f32[] reduce(f32[4096]{0} %multiply.1275.clone.1, f32[] %constant_11333), dimensions={0}, to_apply=%primitive_computation_add__1.13655, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %param_4.1456 = f32[4096]{0} parameter(4)
  %multiply.1039.clone.1 = f32[4096]{0} multiply(f32[4096]{0} %param_4.1456, f32[4096]{0} %param_4.1456), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %reduce.213.clone.1 = f32[] reduce(f32[4096]{0} %multiply.1039.clone.1, f32[] %constant_11333), dimensions={0}, to_apply=%primitive_computation_add__1.15413, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %param_5.624 = f32[4096]{0} parameter(5)
  %multiply.1303.clone.1 = f32[4096]{0} multiply(f32[4096]{0} %param_5.624, f32[4096]{0} %param_5.624), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %reduce.252.clone.1 = f32[] reduce(f32[4096]{0} %multiply.1303.clone.1, f32[] %constant_11333), dimensions={0}, to_apply=%primitive_computation_add__1.13451, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %param_6.590 = f32[4096]{0} parameter(6)
  %multiply.1012.clone.1 = f32[4096]{0} multiply(f32[4096]{0} %param_6.590, f32[4096]{0} %param_6.590), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %reduce.209.clone.1 = f32[] reduce(f32[4096]{0} %multiply.1012.clone.1, f32[] %constant_11333), dimensions={0}, to_apply=%primitive_computation_add__1.15617, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %param_7.571 = f32[4096]{0} parameter(7)
  %multiply.1330.clone.1 = f32[4096]{0} multiply(f32[4096]{0} %param_7.571, f32[4096]{0} %param_7.571), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %reduce.256.clone.1 = f32[] reduce(f32[4096]{0} %multiply.1330.clone.1, f32[] %constant_11333), dimensions={0}, to_apply=%primitive_computation_add__1.13247, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %param_8.463 = f32[4096]{0} parameter(8)
  %multiply.985.clone.1 = f32[4096]{0} multiply(f32[4096]{0} %param_8.463, f32[4096]{0} %param_8.463), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %reduce.205.clone.1 = f32[] reduce(f32[4096]{0} %multiply.985.clone.1, f32[] %constant_11333), dimensions={0}, to_apply=%primitive_computation_add__1.15821, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  ROOT %tuple.758 = (f32[], f32[], f32[], f32[], f32[], /*index=5*/f32[], f32[], f32[], f32[]) tuple(f32[] %reduce.217, f32[] %reduce.238.clone.1, f32[] %reduce.244.clone.1, f32[] %reduce.248.clone.1, f32[] %reduce.213.clone.1, /*index=5*/f32[] %reduce.252.clone.1, f32[] %reduce.209.clone.1, f32[] %reduce.256.clone.1, f32[] %reduce.205.clone.1)
}

%primitive_computation_add__1.9795 (parameter.9796: f32[], parameter.9797: f32[]) -> f32[] {
  %parameter.9796 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.9797 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.9798 = f32[] add(f32[] %parameter.9796, f32[] %parameter.9797), metadata={op_type="add" op_name="add"}
}

%fused_computation.404 (param_0.1399: f32[64,16,1024]) -> f32[1024] {
  %param_0.1399 = f32[64,16,1024]{2,1,0} parameter(0)
  %bitcast.698 = f32[1024,1024]{1,0} bitcast(f32[64,16,1024]{2,1,0} %param_0.1399)
  %constant_11375 = f32[] constant(0)
  ROOT %reduce.221 = f32[1024]{0} reduce(f32[1024,1024]{1,0} %bitcast.698, f32[] %constant_11375), dimensions={0}, to_apply=%primitive_computation_add__1.9795, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0, 1) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/core.py" source_line=96}
}

%fused_computation.411 (param_0.2240: f32[], param_1.2757: f32[1024], param_2.2531: f32[], param_3.2380: f32[1024], param_4.1411: f32[1024], param_5.589: f32[1024], param_6.548: f32[1024], param_7.531: f32[1024], param_8.423: f32[1024], param_9.281: f32[1024], param_10.259: f32[1024], param_11.252: f32[1024], param_12.276: f32[1024], param_13.305: f32[], param_14.292: f32[1024], param_15.232: f32[], param_16.146: f32[1024], param_17.79: f32[], param_18.72: f32[1024], param_19.76: f32[], param_20.62: f32[1024], param_21.48: f32[], param_22.40: f32[1024], param_23.31: f32[1024]) -> (f32[1024], f32[1024], f32[1024], f32[1024], f32[1024], /*index=5*/f32[1024], f32[1024], f32[1024], f32[1024], f32[1024], /*index=10*/f32[1024], f32[1024], f32[1024], f32[1024], f32[1024], /*index=15*/f32[1024], f32[1024]) {
  %param_2.2531 = f32[] parameter(2)
  %broadcast.1654.clone.1 = f32[1024]{0} broadcast(f32[] %param_2.2531), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
  %param_3.2380 = f32[1024]{0} parameter(3)
  %multiply.1103.clone.1 = f32[1024]{0} multiply(f32[1024]{0} %broadcast.1654.clone.1, f32[1024]{0} %param_3.2380), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
  %param_1.2757 = f32[1024]{0} parameter(1)
  %constant_11388_clone_1 = f32[] constant(1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/metrics.py" source_line=617}
  %subtract.303.clone.1 = f32[] subtract(f32[] %constant_11388_clone_1, f32[] %param_2.2531), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=124}
  %constant_11387_clone_1 = f32[] constant(0.0009765625)
  %multiply.1445.clone.1 = f32[] multiply(f32[] %subtract.303.clone.1, f32[] %constant_11387_clone_1)
  %broadcast.1653.clone.1 = f32[1024]{0} broadcast(f32[] %multiply.1445.clone.1), dimensions={}
  %multiply.1102.clone.1 = f32[1024]{0} multiply(f32[1024]{0} %param_1.2757, f32[1024]{0} %broadcast.1653.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
  %add.2010.clone.1 = f32[1024]{0} add(f32[1024]{0} %multiply.1103.clone.1, f32[1024]{0} %multiply.1102.clone.1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
  %param_0.2240 = f32[] parameter(0)
  %broadcast.1651 = f32[1024]{0} broadcast(f32[] %param_0.2240), dimensions={}, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
  %add.2008 = f32[1024]{0} add(f32[1024]{0} %add.2010.clone.1, f32[1024]{0} %broadcast.1651), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
  %constant_11386 = f32[] constant(-0.5), metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
  %broadcast.1652 = f32[1024]{0} broadcast(f32[] %constant_11386), dimensions={}, metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
  %power.16 = f32[1024]{0} power(f32[1024]{0} %add.2008, f32[1024]{0} %broadcast.1652), metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
  %param_5.589 = f32[1024]{0} parameter(5)
  %multiply.1130.clone.1.clone.1 = f32[1024]{0} multiply(f32[1024]{0} %broadcast.1654.clone.1, f32[1024]{0} %param_5.589), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
  %param_4.1411 = f32[1024]{0} parameter(4)
  %multiply.1129.clone.1.clone.1 = f32[1024]{0} multiply(f32[1024]{0} %param_4.1411, f32[1024]{0} %broadcast.1653.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
  %add.2016.clone.1.clone.1 = f32[1024]{0} add(f32[1024]{0} %multiply.1130.clone.1.clone.1, f32[1024]{0} %multiply.1129.clone.1.clone.1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
  %add.2015.clone.1 = f32[1024]{0} add(f32[1024]{0} %add.2016.clone.1.clone.1, f32[1024]{0} %broadcast.1651), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
  %power.19.clone.1 = f32[1024]{0} power(f32[1024]{0} %add.2015.clone.1, f32[1024]{0} %broadcast.1652), metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
  %param_7.531 = f32[1024]{0} parameter(7)
  %multiply.1157.clone.1.clone.1 = f32[1024]{0} multiply(f32[1024]{0} %broadcast.1654.clone.1, f32[1024]{0} %param_7.531), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
  %param_6.548 = f32[1024]{0} parameter(6)
  %multiply.1156.clone.1.clone.1 = f32[1024]{0} multiply(f32[1024]{0} %param_6.548, f32[1024]{0} %broadcast.1653.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
  %add.2023.clone.1.clone.1 = f32[1024]{0} add(f32[1024]{0} %multiply.1157.clone.1.clone.1, f32[1024]{0} %multiply.1156.clone.1.clone.1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
  %add.2022.clone.1 = f32[1024]{0} add(f32[1024]{0} %add.2023.clone.1.clone.1, f32[1024]{0} %broadcast.1651), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
  %power.22.clone.1 = f32[1024]{0} power(f32[1024]{0} %add.2022.clone.1, f32[1024]{0} %broadcast.1652), metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
  %param_9.281 = f32[1024]{0} parameter(9)
  %multiply.1184.clone.1.clone.1 = f32[1024]{0} multiply(f32[1024]{0} %broadcast.1654.clone.1, f32[1024]{0} %param_9.281), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
  %param_8.423 = f32[1024]{0} parameter(8)
  %multiply.1183.clone.1.clone.1 = f32[1024]{0} multiply(f32[1024]{0} %param_8.423, f32[1024]{0} %broadcast.1653.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
  %add.2030.clone.1.clone.1 = f32[1024]{0} add(f32[1024]{0} %multiply.1184.clone.1.clone.1, f32[1024]{0} %multiply.1183.clone.1.clone.1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
  %add.2029.clone.1 = f32[1024]{0} add(f32[1024]{0} %add.2030.clone.1.clone.1, f32[1024]{0} %broadcast.1651), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
  %power.25.clone.1 = f32[1024]{0} power(f32[1024]{0} %add.2029.clone.1, f32[1024]{0} %broadcast.1652), metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
  %param_11.252 = f32[1024]{0} parameter(11)
  %multiply.1228.clone.1.clone.1 = f32[1024]{0} multiply(f32[1024]{0} %broadcast.1654.clone.1, f32[1024]{0} %param_11.252), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
  %param_10.259 = f32[1024]{0} parameter(10)
  %constant_14721_clone_1_clone_1 = f32[] constant(0.00390625)
  %multiply.1684.clone.1.clone.1 = f32[] multiply(f32[] %subtract.303.clone.1, f32[] %constant_14721_clone_1_clone_1)
  %broadcast.2116.clone.1.clone.1 = f32[1024]{0} broadcast(f32[] %multiply.1684.clone.1.clone.1), dimensions={}
  %multiply.1227.clone.1.clone.1 = f32[1024]{0} multiply(f32[1024]{0} %param_10.259, f32[1024]{0} %broadcast.2116.clone.1.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
  %add.2042.clone.1.clone.1 = f32[1024]{0} add(f32[1024]{0} %multiply.1228.clone.1.clone.1, f32[1024]{0} %multiply.1227.clone.1.clone.1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
  %add.2041.clone.1 = f32[1024]{0} add(f32[1024]{0} %add.2042.clone.1.clone.1, f32[1024]{0} %broadcast.1651), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
  %power.30.clone.1 = f32[1024]{0} power(f32[1024]{0} %add.2041.clone.1, f32[1024]{0} %broadcast.1652), metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
  %param_23.31 = f32[1024]{0} parameter(23)
  %multiply.1360.clone.1 = f32[1024]{0} multiply(f32[1024]{0} %broadcast.1654.clone.1, f32[1024]{0} %param_23.31), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
  %param_22.40 = f32[1024]{0} parameter(22)
  %constant_11722_clone_1 = f32[] constant(3.125e-05)
  %multiply.1359.clone.1 = f32[] multiply(f32[] %subtract.303.clone.1, f32[] %constant_11722_clone_1)
  %broadcast.1415.clone.1 = f32[1024]{0} broadcast(f32[] %multiply.1359.clone.1), dimensions={}
  %multiply.1358.clone.1 = f32[1024]{0} multiply(f32[1024]{0} %param_22.40, f32[1024]{0} %broadcast.1415.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
  %add.2075.clone.1 = f32[1024]{0} add(f32[1024]{0} %multiply.1360.clone.1, f32[1024]{0} %multiply.1358.clone.1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
  %add.2074.clone.1 = f32[1024]{0} add(f32[1024]{0} %add.2075.clone.1, f32[1024]{0} %broadcast.1651), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
  %power.44.clone.1 = f32[1024]{0} power(f32[1024]{0} %add.2074.clone.1, f32[1024]{0} %broadcast.1652), metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
  %param_13.305 = f32[] parameter(13)
  %multiply.969.clone.1 = f32[] multiply(f32[] %param_13.305, f32[] %constant_11387_clone_1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=135}
  %broadcast.1299.clone.1 = f32[1024]{0} broadcast(f32[] %multiply.969.clone.1), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  %param_12.276 = f32[1024]{0} parameter(12)
  %add.1976.clone.1 = f32[1024]{0} add(f32[1024]{0} %param_12.276, f32[1024]{0} %broadcast.1651), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  %divide.143.clone.1 = f32[1024]{0} divide(f32[1024]{0} %broadcast.1299.clone.1, f32[1024]{0} %add.1976.clone.1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  %constant_11237_clone_1 = f32[] constant(0.5), metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  %broadcast.1566.clone.1 = f32[1024]{0} broadcast(f32[] %constant_11237_clone_1), dimensions={}, metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  %power.2.clone.1 = f32[1024]{0} power(f32[1024]{0} %divide.143.clone.1, f32[1024]{0} %broadcast.1566.clone.1), metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  %param_15.232 = f32[] parameter(15)
  %multiply.1104.clone.1 = f32[] multiply(f32[] %param_15.232, f32[] %constant_11387_clone_1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=135}
  %broadcast.1336.clone.1 = f32[1024]{0} broadcast(f32[] %multiply.1104.clone.1), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  %param_14.292 = f32[1024]{0} parameter(14)
  %add.2011.clone.1 = f32[1024]{0} add(f32[1024]{0} %param_14.292, f32[1024]{0} %broadcast.1651), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  %divide.168.clone.1 = f32[1024]{0} divide(f32[1024]{0} %broadcast.1336.clone.1, f32[1024]{0} %add.2011.clone.1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  %power.17.clone.1 = f32[1024]{0} power(f32[1024]{0} %divide.168.clone.1, f32[1024]{0} %broadcast.1566.clone.1), metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  %param_17.79 = f32[] parameter(17)
  %multiply.1131.clone.1 = f32[] multiply(f32[] %param_17.79, f32[] %constant_11387_clone_1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=135}
  %broadcast.1344.clone.1 = f32[1024]{0} broadcast(f32[] %multiply.1131.clone.1), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  %param_16.146 = f32[1024]{0} parameter(16)
  %add.2018.clone.1 = f32[1024]{0} add(f32[1024]{0} %param_16.146, f32[1024]{0} %broadcast.1651), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  %divide.173.clone.1 = f32[1024]{0} divide(f32[1024]{0} %broadcast.1344.clone.1, f32[1024]{0} %add.2018.clone.1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  %power.20.clone.1 = f32[1024]{0} power(f32[1024]{0} %divide.173.clone.1, f32[1024]{0} %broadcast.1566.clone.1), metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  %param_19.76 = f32[] parameter(19)
  %multiply.1158.clone.1 = f32[] multiply(f32[] %param_19.76, f32[] %constant_11387_clone_1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=135}
  %broadcast.1351.clone.1 = f32[1024]{0} broadcast(f32[] %multiply.1158.clone.1), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  %param_18.72 = f32[1024]{0} parameter(18)
  %add.2024.clone.1 = f32[1024]{0} add(f32[1024]{0} %param_18.72, f32[1024]{0} %broadcast.1651), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  %divide.178.clone.1 = f32[1024]{0} divide(f32[1024]{0} %broadcast.1351.clone.1, f32[1024]{0} %add.2024.clone.1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  %power.23.clone.1 = f32[1024]{0} power(f32[1024]{0} %divide.178.clone.1, f32[1024]{0} %broadcast.1566.clone.1), metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  %param_21.48 = f32[] parameter(21)
  %multiply.1185.clone.1 = f32[] multiply(f32[] %param_21.48, f32[] %constant_11387_clone_1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=135}
  %broadcast.1358.clone.1 = f32[1024]{0} broadcast(f32[] %multiply.1185.clone.1), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  %param_20.62 = f32[1024]{0} parameter(20)
  %add.2031.clone.1 = f32[1024]{0} add(f32[1024]{0} %param_20.62, f32[1024]{0} %broadcast.1651), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  %divide.183.clone.1 = f32[1024]{0} divide(f32[1024]{0} %broadcast.1358.clone.1, f32[1024]{0} %add.2031.clone.1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  %power.26.clone.1 = f32[1024]{0} power(f32[1024]{0} %divide.183.clone.1, f32[1024]{0} %broadcast.1566.clone.1), metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  ROOT %tuple.700 = (f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, /*index=5*/f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, /*index=10*/f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, /*index=15*/f32[1024]{0}, f32[1024]{0}) tuple(f32[1024]{0} %power.16, f32[1024]{0} %add.2010.clone.1, f32[1024]{0} %power.19.clone.1, f32[1024]{0} %add.2016.clone.1.clone.1, f32[1024]{0} %power.22.clone.1, /*index=5*/f32[1024]{0} %add.2023.clone.1.clone.1, f32[1024]{0} %power.25.clone.1, f32[1024]{0} %add.2030.clone.1.clone.1, f32[1024]{0} %power.30.clone.1, f32[1024]{0} %add.2042.clone.1.clone.1, /*index=10*/f32[1024]{0} %power.44.clone.1, f32[1024]{0} %power.2.clone.1, f32[1024]{0} %power.17.clone.1, f32[1024]{0} %power.20.clone.1, f32[1024]{0} %power.23.clone.1, /*index=15*/f32[1024]{0} %power.26.clone.1, f32[1024]{0} %add.2075.clone.1)
}

%fused_computation.454 (param_0.771: f32[16,64,1024]) -> f32[1024,1024] {
  %param_0.771 = f32[16,64,1024]{2,1,0} parameter(0)
  %transpose.95 = f32[1024,16,64]{0,2,1} transpose(f32[16,64,1024]{2,1,0} %param_0.771), dimensions={2,0,1}
  ROOT %bitcast.707 = f32[1024,1024]{0,1} bitcast(f32[1024,16,64]{0,2,1} %transpose.95)
}

%primitive_computation_add__1.14471 (parameter.14472: f32[], parameter.14473: f32[]) -> f32[] {
  %parameter.14472 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.14473 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.14474 = f32[] add(f32[] %parameter.14472, f32[] %parameter.14473), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.14267 (parameter.14268: f32[], parameter.14269: f32[]) -> f32[] {
  %parameter.14268 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.14269 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.14270 = f32[] add(f32[] %parameter.14268, f32[] %parameter.14269), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.14675 (parameter.14676: f32[], parameter.14677: f32[]) -> f32[] {
  %parameter.14676 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.14677 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.14678 = f32[] add(f32[] %parameter.14676, f32[] %parameter.14677), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.14879 (parameter.14880: f32[], parameter.14881: f32[]) -> f32[] {
  %parameter.14880 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.14881 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.14882 = f32[] add(f32[] %parameter.14880, f32[] %parameter.14881), metadata={op_type="add" op_name="add"}
}

%fused_computation.456 (param_0.1423: f32[1024,1024], param_1.2949: f32[1024,1024], param_2.2791: f32[1024,1024], param_3.2652: f32[1024,1024]) -> (f32[], f32[], f32[], f32[]) {
  %param_0.1423 = f32[1024,1024]{1,0} parameter(0)
  %multiply.1164 = f32[1024,1024]{1,0} multiply(f32[1024,1024]{1,0} %param_0.1423, f32[1024,1024]{1,0} %param_0.1423), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %bitcast.708 = f32[1048576]{0} bitcast(f32[1024,1024]{1,0} %multiply.1164)
  %constant_11427 = f32[] constant(0)
  %reduce.232 = f32[] reduce(f32[1048576]{0} %bitcast.708, f32[] %constant_11427), dimensions={0}, to_apply=%primitive_computation_add__1.14471, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0, 1) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %param_1.2949 = f32[1024,1024]{1,0} parameter(1)
  %multiply.1191.clone.1 = f32[1024,1024]{1,0} multiply(f32[1024,1024]{1,0} %param_1.2949, f32[1024,1024]{1,0} %param_1.2949), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %bitcast.711.clone.1 = f32[1048576]{0} bitcast(f32[1024,1024]{1,0} %multiply.1191.clone.1)
  %reduce.236.clone.1 = f32[] reduce(f32[1048576]{0} %bitcast.711.clone.1, f32[] %constant_11427), dimensions={0}, to_apply=%primitive_computation_add__1.14267, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0, 1) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %param_2.2791 = f32[1024,1024]{1,0} parameter(2)
  %multiply.1137.clone.1 = f32[1024,1024]{1,0} multiply(f32[1024,1024]{1,0} %param_2.2791, f32[1024,1024]{1,0} %param_2.2791), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %bitcast.705.clone.1 = f32[1048576]{0} bitcast(f32[1024,1024]{1,0} %multiply.1137.clone.1)
  %reduce.228.clone.1 = f32[] reduce(f32[1048576]{0} %bitcast.705.clone.1, f32[] %constant_11427), dimensions={0}, to_apply=%primitive_computation_add__1.14675, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0, 1) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %param_3.2652 = f32[1024,1024]{1,0} parameter(3)
  %multiply.1110.clone.1 = f32[1024,1024]{1,0} multiply(f32[1024,1024]{1,0} %param_3.2652, f32[1024,1024]{1,0} %param_3.2652), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %bitcast.701.clone.1 = f32[1048576]{0} bitcast(f32[1024,1024]{1,0} %multiply.1110.clone.1)
  %reduce.224.clone.1 = f32[] reduce(f32[1048576]{0} %bitcast.701.clone.1, f32[] %constant_11427), dimensions={0}, to_apply=%primitive_computation_add__1.14879, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0, 1) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  ROOT %tuple.762 = (f32[], f32[], f32[], f32[]) tuple(f32[] %reduce.232, f32[] %reduce.236.clone.1, f32[] %reduce.228.clone.1, f32[] %reduce.224.clone.1)
}

%fused_computation.457 (param_0.777: f32[1024], param_1.1767: f32[], param_2.1308: f32[], param_3.1082: f32[], param_4.420: f32[], param_5.235: f32[], param_6.184: f32[1024], param_7.173: f32[], param_8.357: f32[1024], param_9.229: f32[], param_10.197: f32[], param_11.205: f32[1024], param_12.217: f32[1024], param_13.266: f32[], param_14.246: f32[], param_15.195: f32[1024], param_16.100: f32[1024], param_17.42: f32[], param_18.26: f32[], param_19.42: f32[1024]) -> (f32[1024], f32[1024], f32[1024], f32[1024]) {
  %param_7.173 = f32[] parameter(7)
  %broadcast.1692 = f32[1024]{0} broadcast(f32[] %param_7.173), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  %param_6.184 = f32[1024]{0} parameter(6)
  %multiply.1167 = f32[1024]{0} multiply(f32[1024]{0} %broadcast.1692, f32[1024]{0} %param_6.184), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  %param_3.1082 = f32[] parameter(3)
  %param_4.420 = f32[] parameter(4)
  %param_5.235 = f32[] parameter(5)
  %maximum.36 = f32[] maximum(f32[] %param_4.420, f32[] %param_5.235), metadata={op_type="max" op_name="pmap(_multi_device_update_fn)/max" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=122}
  %multiply.1166 = f32[] multiply(f32[] %param_3.1082, f32[] %maximum.36), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=122}
  %broadcast.1353 = f32[1024]{0} broadcast(f32[] %multiply.1166), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=152}
  %param_0.777 = f32[1024]{0} parameter(0)
  %constant_11439 = f32[] constant(1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/metrics.py" source_line=617}
  %param_1.1767 = f32[] parameter(1)
  %param_2.1308 = f32[] parameter(2)
  %divide.180 = f32[] divide(f32[] %param_1.1767, f32[] %param_2.1308), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %maximum.35 = f32[] maximum(f32[] %constant_11439, f32[] %divide.180), metadata={op_type="max" op_name="pmap(_multi_device_update_fn)/max" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %broadcast.1352 = f32[1024]{0} broadcast(f32[] %maximum.35), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=150}
  %divide.179 = f32[1024]{0} divide(f32[1024]{0} %param_0.777, f32[1024]{0} %broadcast.1352), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=150}
  %multiply.1165 = f32[1024]{0} multiply(f32[1024]{0} %broadcast.1353, f32[1024]{0} %divide.179), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=152}
  %subtract.273 = f32[1024]{0} subtract(f32[1024]{0} %multiply.1167, f32[1024]{0} %multiply.1165), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  %param_11.205 = f32[1024]{0} parameter(11)
  %multiply.1086.clone.1 = f32[1024]{0} multiply(f32[1024]{0} %broadcast.1692, f32[1024]{0} %param_11.205), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  %param_10.197 = f32[] parameter(10)
  %maximum.24.clone.1 = f32[] maximum(f32[] %param_10.197, f32[] %param_5.235), metadata={op_type="max" op_name="pmap(_multi_device_update_fn)/max" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=122}
  %multiply.1085.clone.1 = f32[] multiply(f32[] %param_3.1082, f32[] %maximum.24.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=122}
  %broadcast.1331.clone.1 = f32[1024]{0} broadcast(f32[] %multiply.1085.clone.1), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=152}
  %param_8.357 = f32[1024]{0} parameter(8)
  %param_9.229 = f32[] parameter(9)
  %divide.165.clone.1 = f32[] divide(f32[] %param_9.229, f32[] %param_2.1308), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %maximum.23.clone.1 = f32[] maximum(f32[] %constant_11439, f32[] %divide.165.clone.1), metadata={op_type="max" op_name="pmap(_multi_device_update_fn)/max" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %broadcast.1330.clone.1 = f32[1024]{0} broadcast(f32[] %maximum.23.clone.1), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=150}
  %divide.164.clone.1 = f32[1024]{0} divide(f32[1024]{0} %param_8.357, f32[1024]{0} %broadcast.1330.clone.1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=150}
  %multiply.1084.clone.1 = f32[1024]{0} multiply(f32[1024]{0} %broadcast.1331.clone.1, f32[1024]{0} %divide.164.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=152}
  %subtract.267.clone.1 = f32[1024]{0} subtract(f32[1024]{0} %multiply.1086.clone.1, f32[1024]{0} %multiply.1084.clone.1), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  %param_15.195 = f32[1024]{0} parameter(15)
  %multiply.1113.clone.1 = f32[1024]{0} multiply(f32[1024]{0} %broadcast.1692, f32[1024]{0} %param_15.195), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  %param_14.246 = f32[] parameter(14)
  %maximum.28.clone.1 = f32[] maximum(f32[] %param_14.246, f32[] %param_5.235), metadata={op_type="max" op_name="pmap(_multi_device_update_fn)/max" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=122}
  %multiply.1112.clone.1 = f32[] multiply(f32[] %param_3.1082, f32[] %maximum.28.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=122}
  %broadcast.1338.clone.1 = f32[1024]{0} broadcast(f32[] %multiply.1112.clone.1), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=152}
  %param_12.217 = f32[1024]{0} parameter(12)
  %param_13.266 = f32[] parameter(13)
  %divide.170.clone.1 = f32[] divide(f32[] %param_13.266, f32[] %param_2.1308), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %maximum.27.clone.1 = f32[] maximum(f32[] %constant_11439, f32[] %divide.170.clone.1), metadata={op_type="max" op_name="pmap(_multi_device_update_fn)/max" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %broadcast.1337.clone.1 = f32[1024]{0} broadcast(f32[] %maximum.27.clone.1), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=150}
  %divide.169.clone.1 = f32[1024]{0} divide(f32[1024]{0} %param_12.217, f32[1024]{0} %broadcast.1337.clone.1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=150}
  %multiply.1111.clone.1 = f32[1024]{0} multiply(f32[1024]{0} %broadcast.1338.clone.1, f32[1024]{0} %divide.169.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=152}
  %subtract.269.clone.1 = f32[1024]{0} subtract(f32[1024]{0} %multiply.1113.clone.1, f32[1024]{0} %multiply.1111.clone.1), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  %param_19.42 = f32[1024]{0} parameter(19)
  %multiply.1140.clone.1 = f32[1024]{0} multiply(f32[1024]{0} %broadcast.1692, f32[1024]{0} %param_19.42), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  %param_18.26 = f32[] parameter(18)
  %maximum.32.clone.1 = f32[] maximum(f32[] %param_18.26, f32[] %param_5.235), metadata={op_type="max" op_name="pmap(_multi_device_update_fn)/max" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=122}
  %multiply.1139.clone.1 = f32[] multiply(f32[] %param_3.1082, f32[] %maximum.32.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=122}
  %broadcast.1346.clone.1 = f32[1024]{0} broadcast(f32[] %multiply.1139.clone.1), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=152}
  %param_16.100 = f32[1024]{0} parameter(16)
  %param_17.42 = f32[] parameter(17)
  %divide.175.clone.1 = f32[] divide(f32[] %param_17.42, f32[] %param_2.1308), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %maximum.31.clone.1 = f32[] maximum(f32[] %constant_11439, f32[] %divide.175.clone.1), metadata={op_type="max" op_name="pmap(_multi_device_update_fn)/max" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %broadcast.1345.clone.1 = f32[1024]{0} broadcast(f32[] %maximum.31.clone.1), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=150}
  %divide.174.clone.1 = f32[1024]{0} divide(f32[1024]{0} %param_16.100, f32[1024]{0} %broadcast.1345.clone.1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=150}
  %multiply.1138.clone.1 = f32[1024]{0} multiply(f32[1024]{0} %broadcast.1346.clone.1, f32[1024]{0} %divide.174.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=152}
  %subtract.271.clone.1 = f32[1024]{0} subtract(f32[1024]{0} %multiply.1140.clone.1, f32[1024]{0} %multiply.1138.clone.1), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  ROOT %tuple.659 = (f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}) tuple(f32[1024]{0} %subtract.273, f32[1024]{0} %subtract.267.clone.1, f32[1024]{0} %subtract.269.clone.1, f32[1024]{0} %subtract.271.clone.1)
}

%primitive_computation_add__1.14393 (parameter.14394: f32[], parameter.14395: f32[]) -> f32[] {
  %parameter.14394 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.14395 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.14396 = f32[] add(f32[] %parameter.14394, f32[] %parameter.14395), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.14597 (parameter.14598: f32[], parameter.14599: f32[]) -> f32[] {
  %parameter.14598 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.14599 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.14600 = f32[] add(f32[] %parameter.14598, f32[] %parameter.14599), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.14801 (parameter.14802: f32[], parameter.14803: f32[]) -> f32[] {
  %parameter.14802 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.14803 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.14804 = f32[] add(f32[] %parameter.14802, f32[] %parameter.14803), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.15005 (parameter.15006: f32[], parameter.15007: f32[]) -> f32[] {
  %parameter.15006 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.15007 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.15008 = f32[] add(f32[] %parameter.15006, f32[] %parameter.15007), metadata={op_type="add" op_name="add"}
}

%fused_computation.463 (param_0.1427: f32[1024], param_1.2941: f32[1024], param_2.2783: f32[1024], param_3.2645: f32[1024]) -> (f32[], f32[], f32[], f32[]) {
  %param_0.1427 = f32[1024]{0} parameter(0)
  %multiply.1174 = f32[1024]{0} multiply(f32[1024]{0} %param_0.1427, f32[1024]{0} %param_0.1427), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %constant_11441 = f32[] constant(0)
  %reduce.234 = f32[] reduce(f32[1024]{0} %multiply.1174, f32[] %constant_11441), dimensions={0}, to_apply=%primitive_computation_add__1.14393, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %param_1.2941 = f32[1024]{0} parameter(1)
  %multiply.1147.clone.1 = f32[1024]{0} multiply(f32[1024]{0} %param_1.2941, f32[1024]{0} %param_1.2941), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %reduce.230.clone.1 = f32[] reduce(f32[1024]{0} %multiply.1147.clone.1, f32[] %constant_11441), dimensions={0}, to_apply=%primitive_computation_add__1.14597, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %param_2.2783 = f32[1024]{0} parameter(2)
  %multiply.1120.clone.1 = f32[1024]{0} multiply(f32[1024]{0} %param_2.2783, f32[1024]{0} %param_2.2783), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %reduce.226.clone.1 = f32[] reduce(f32[1024]{0} %multiply.1120.clone.1, f32[] %constant_11441), dimensions={0}, to_apply=%primitive_computation_add__1.14801, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %param_3.2645 = f32[1024]{0} parameter(3)
  %multiply.1093.clone.1 = f32[1024]{0} multiply(f32[1024]{0} %param_3.2645, f32[1024]{0} %param_3.2645), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %reduce.222.clone.1 = f32[] reduce(f32[1024]{0} %multiply.1093.clone.1, f32[] %constant_11441), dimensions={0}, to_apply=%primitive_computation_add__1.15005, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  ROOT %tuple.750 = (f32[], f32[], f32[], f32[]) tuple(f32[] %reduce.234, f32[] %reduce.230.clone.1, f32[] %reduce.226.clone.1, f32[] %reduce.222.clone.1)
}

%fused_computation.464 (param_0.2056: f32[], param_1.2511: f32[], param_2.2232: f32[], param_3.2043: f32[], param_4.1049: f32[], param_5.498: f32[1024,1024], param_6.444: f32[], param_7.415: f32[1024], param_8.299: f32[1024,1024], param_9.185: f32[1024], param_10.193: f32[], param_11.196: f32[1024], param_12.212: f32[1024,1024], param_13.262: f32[1024], param_14.242: f32[], param_15.186: f32[1024,1024], param_16.95: f32[], param_17.38: f32[1024], param_18.22: f32[1024,1024], param_19.33: f32[1024], param_20.27: f32[], param_21.28: f32[1024,1024], param_22.22: f32[], param_23.25: f32[1024], param_24.23: f32[1024,1024], param_25.28: f32[1024], param_26.26: f32[], param_27.33: f32[1024,1024]) -> (f32[1024,1024], f32[1024,1024], f32[1024,1024], f32[1024,1024]) {
  %param_6.444 = f32[] parameter(6)
  %broadcast.1699 = f32[1024,1024]{1,0} broadcast(f32[] %param_6.444), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  %param_5.498 = f32[1024,1024]{1,0} parameter(5)
  %multiply.1177 = f32[1024,1024]{1,0} multiply(f32[1024,1024]{1,0} %broadcast.1699, f32[1024,1024]{1,0} %param_5.498), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  %param_2.2232 = f32[] parameter(2)
  %param_3.2043 = f32[] parameter(3)
  %param_4.1049 = f32[] parameter(4)
  %maximum.38 = f32[] maximum(f32[] %param_3.2043, f32[] %param_4.1049), metadata={op_type="max" op_name="pmap(_multi_device_update_fn)/max" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=122}
  %multiply.1176 = f32[] multiply(f32[] %param_2.2232, f32[] %maximum.38), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=122}
  %broadcast.1355 = f32[1024,1024]{1,0} broadcast(f32[] %multiply.1176), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=152}
  %param_8.299 = f32[1024,1024]{1,0} parameter(8)
  %param_9.185 = f32[1024]{0} parameter(9)
  %constant_14771 = f32[] constant(0.125)
  %broadcast.2168 = f32[1024]{0} broadcast(f32[] %constant_14771), dimensions={}
  %multiply.1746 = f32[1024]{0} multiply(f32[1024]{0} %param_9.185, f32[1024]{0} %broadcast.2168)
  %broadcast.2167 = f32[1024,1024]{1,0} broadcast(f32[1024]{0} %multiply.1746), dimensions={0}
  %multiply.1745 = f32[1024,1024]{1,0} multiply(f32[1024,1024]{1,0} %param_8.299, f32[1024,1024]{1,0} %broadcast.2167), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  %param_7.415 = f32[1024]{0} parameter(7)
  %broadcast.2166 = f32[1024,1024]{1,0} broadcast(f32[1024]{0} %param_7.415), dimensions={1}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  %multiply.1744 = f32[1024,1024]{1,0} multiply(f32[1024,1024]{1,0} %multiply.1745, f32[1024,1024]{1,0} %broadcast.2166), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  %constant_11459 = f32[] constant(1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/metrics.py" source_line=617}
  %param_0.2056 = f32[] parameter(0)
  %param_1.2511 = f32[] parameter(1)
  %divide.182 = f32[] divide(f32[] %param_0.2056, f32[] %param_1.2511), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %maximum.37 = f32[] maximum(f32[] %constant_11459, f32[] %divide.182), metadata={op_type="max" op_name="pmap(_multi_device_update_fn)/max" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %broadcast.1354 = f32[1024,1024]{1,0} broadcast(f32[] %maximum.37), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=150}
  %divide.181 = f32[1024,1024]{1,0} divide(f32[1024,1024]{1,0} %multiply.1744, f32[1024,1024]{1,0} %broadcast.1354), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=150}
  %multiply.1175 = f32[1024,1024]{1,0} multiply(f32[1024,1024]{1,0} %broadcast.1355, f32[1024,1024]{1,0} %divide.181), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=152}
  %subtract.274 = f32[1024,1024]{1,0} subtract(f32[1024,1024]{1,0} %multiply.1177, f32[1024,1024]{1,0} %multiply.1175), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  %param_15.186 = f32[1024,1024]{1,0} parameter(15)
  %multiply.1096.clone.1 = f32[1024,1024]{1,0} multiply(f32[1024,1024]{1,0} %broadcast.1699, f32[1024,1024]{1,0} %param_15.186), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  %param_14.242 = f32[] parameter(14)
  %maximum.26.clone.1 = f32[] maximum(f32[] %param_14.242, f32[] %param_4.1049), metadata={op_type="max" op_name="pmap(_multi_device_update_fn)/max" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=122}
  %multiply.1095.clone.1 = f32[] multiply(f32[] %param_2.2232, f32[] %maximum.26.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=122}
  %broadcast.1333.clone.1 = f32[1024,1024]{1,0} broadcast(f32[] %multiply.1095.clone.1), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=152}
  %param_12.212 = f32[1024,1024]{1,0} parameter(12)
  %param_13.262 = f32[1024]{0} parameter(13)
  %multiply.1818.clone.1 = f32[1024]{0} multiply(f32[1024]{0} %param_13.262, f32[1024]{0} %broadcast.2168)
  %broadcast.2223.clone.1 = f32[1024,1024]{1,0} broadcast(f32[1024]{0} %multiply.1818.clone.1), dimensions={0}
  %multiply.1817.clone.1 = f32[1024,1024]{1,0} multiply(f32[1024,1024]{1,0} %param_12.212, f32[1024,1024]{1,0} %broadcast.2223.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  %param_11.196 = f32[1024]{0} parameter(11)
  %broadcast.2222.clone.1 = f32[1024,1024]{1,0} broadcast(f32[1024]{0} %param_11.196), dimensions={1}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  %multiply.1816.clone.1 = f32[1024,1024]{1,0} multiply(f32[1024,1024]{1,0} %multiply.1817.clone.1, f32[1024,1024]{1,0} %broadcast.2222.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  %param_10.193 = f32[] parameter(10)
  %divide.167.clone.1 = f32[] divide(f32[] %param_10.193, f32[] %param_1.2511), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %maximum.25.clone.1 = f32[] maximum(f32[] %constant_11459, f32[] %divide.167.clone.1), metadata={op_type="max" op_name="pmap(_multi_device_update_fn)/max" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %broadcast.1332.clone.1 = f32[1024,1024]{1,0} broadcast(f32[] %maximum.25.clone.1), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=150}
  %divide.166.clone.1 = f32[1024,1024]{1,0} divide(f32[1024,1024]{1,0} %multiply.1816.clone.1, f32[1024,1024]{1,0} %broadcast.1332.clone.1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=150}
  %multiply.1094.clone.1 = f32[1024,1024]{1,0} multiply(f32[1024,1024]{1,0} %broadcast.1333.clone.1, f32[1024,1024]{1,0} %divide.166.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=152}
  %subtract.268.clone.1 = f32[1024,1024]{1,0} subtract(f32[1024,1024]{1,0} %multiply.1096.clone.1, f32[1024,1024]{1,0} %multiply.1094.clone.1), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  %param_21.28 = f32[1024,1024]{1,0} parameter(21)
  %multiply.1123.clone.1 = f32[1024,1024]{1,0} multiply(f32[1024,1024]{1,0} %broadcast.1699, f32[1024,1024]{1,0} %param_21.28), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  %param_20.27 = f32[] parameter(20)
  %maximum.30.clone.1 = f32[] maximum(f32[] %param_20.27, f32[] %param_4.1049), metadata={op_type="max" op_name="pmap(_multi_device_update_fn)/max" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=122}
  %multiply.1122.clone.1 = f32[] multiply(f32[] %param_2.2232, f32[] %maximum.30.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=122}
  %broadcast.1340.clone.1 = f32[1024,1024]{1,0} broadcast(f32[] %multiply.1122.clone.1), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=152}
  %param_18.22 = f32[1024,1024]{1,0} parameter(18)
  %param_19.33 = f32[1024]{0} parameter(19)
  %multiply.1794.clone.1 = f32[1024]{0} multiply(f32[1024]{0} %param_19.33, f32[1024]{0} %broadcast.2168)
  %broadcast.2204.clone.1 = f32[1024,1024]{1,0} broadcast(f32[1024]{0} %multiply.1794.clone.1), dimensions={0}
  %multiply.1793.clone.1 = f32[1024,1024]{1,0} multiply(f32[1024,1024]{1,0} %param_18.22, f32[1024,1024]{1,0} %broadcast.2204.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  %param_17.38 = f32[1024]{0} parameter(17)
  %broadcast.2203.clone.1 = f32[1024,1024]{1,0} broadcast(f32[1024]{0} %param_17.38), dimensions={1}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  %multiply.1792.clone.1 = f32[1024,1024]{1,0} multiply(f32[1024,1024]{1,0} %multiply.1793.clone.1, f32[1024,1024]{1,0} %broadcast.2203.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  %param_16.95 = f32[] parameter(16)
  %divide.172.clone.1 = f32[] divide(f32[] %param_16.95, f32[] %param_1.2511), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %maximum.29.clone.1 = f32[] maximum(f32[] %constant_11459, f32[] %divide.172.clone.1), metadata={op_type="max" op_name="pmap(_multi_device_update_fn)/max" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %broadcast.1339.clone.1 = f32[1024,1024]{1,0} broadcast(f32[] %maximum.29.clone.1), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=150}
  %divide.171.clone.1 = f32[1024,1024]{1,0} divide(f32[1024,1024]{1,0} %multiply.1792.clone.1, f32[1024,1024]{1,0} %broadcast.1339.clone.1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=150}
  %multiply.1121.clone.1 = f32[1024,1024]{1,0} multiply(f32[1024,1024]{1,0} %broadcast.1340.clone.1, f32[1024,1024]{1,0} %divide.171.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=152}
  %subtract.270.clone.1 = f32[1024,1024]{1,0} subtract(f32[1024,1024]{1,0} %multiply.1123.clone.1, f32[1024,1024]{1,0} %multiply.1121.clone.1), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  %param_27.33 = f32[1024,1024]{1,0} parameter(27)
  %multiply.1150.clone.1 = f32[1024,1024]{1,0} multiply(f32[1024,1024]{1,0} %broadcast.1699, f32[1024,1024]{1,0} %param_27.33), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  %param_26.26 = f32[] parameter(26)
  %maximum.34.clone.1 = f32[] maximum(f32[] %param_26.26, f32[] %param_4.1049), metadata={op_type="max" op_name="pmap(_multi_device_update_fn)/max" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=122}
  %multiply.1149.clone.1 = f32[] multiply(f32[] %param_2.2232, f32[] %maximum.34.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=122}
  %broadcast.1348.clone.1 = f32[1024,1024]{1,0} broadcast(f32[] %multiply.1149.clone.1), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=152}
  %param_24.23 = f32[1024,1024]{1,0} parameter(24)
  %param_25.28 = f32[1024]{0} parameter(25)
  %multiply.1770.clone.1 = f32[1024]{0} multiply(f32[1024]{0} %param_25.28, f32[1024]{0} %broadcast.2168)
  %broadcast.2186.clone.1 = f32[1024,1024]{1,0} broadcast(f32[1024]{0} %multiply.1770.clone.1), dimensions={0}
  %multiply.1769.clone.1 = f32[1024,1024]{1,0} multiply(f32[1024,1024]{1,0} %param_24.23, f32[1024,1024]{1,0} %broadcast.2186.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  %param_23.25 = f32[1024]{0} parameter(23)
  %broadcast.2185.clone.1 = f32[1024,1024]{1,0} broadcast(f32[1024]{0} %param_23.25), dimensions={1}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  %multiply.1768.clone.1 = f32[1024,1024]{1,0} multiply(f32[1024,1024]{1,0} %multiply.1769.clone.1, f32[1024,1024]{1,0} %broadcast.2185.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  %param_22.22 = f32[] parameter(22)
  %divide.177.clone.1 = f32[] divide(f32[] %param_22.22, f32[] %param_1.2511), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %maximum.33.clone.1 = f32[] maximum(f32[] %constant_11459, f32[] %divide.177.clone.1), metadata={op_type="max" op_name="pmap(_multi_device_update_fn)/max" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %broadcast.1347.clone.1 = f32[1024,1024]{1,0} broadcast(f32[] %maximum.33.clone.1), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=150}
  %divide.176.clone.1 = f32[1024,1024]{1,0} divide(f32[1024,1024]{1,0} %multiply.1768.clone.1, f32[1024,1024]{1,0} %broadcast.1347.clone.1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=150}
  %multiply.1148.clone.1 = f32[1024,1024]{1,0} multiply(f32[1024,1024]{1,0} %broadcast.1348.clone.1, f32[1024,1024]{1,0} %divide.176.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=152}
  %subtract.272.clone.1 = f32[1024,1024]{1,0} subtract(f32[1024,1024]{1,0} %multiply.1150.clone.1, f32[1024,1024]{1,0} %multiply.1148.clone.1), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  ROOT %tuple.656 = (f32[1024,1024]{1,0}, f32[1024,1024]{1,0}, f32[1024,1024]{1,0}, f32[1024,1024]{1,0}) tuple(f32[1024,1024]{1,0} %subtract.274, f32[1024,1024]{1,0} %subtract.268.clone.1, f32[1024,1024]{1,0} %subtract.270.clone.1, f32[1024,1024]{1,0} %subtract.272.clone.1)
}

%fused_computation.473 (param_0.808: f32[16,64,1024]) -> f32[1024,1024] {
  %param_0.808 = f32[16,64,1024]{2,1,0} parameter(0)
  %transpose.96 = f32[1024,16,64]{0,2,1} transpose(f32[16,64,1024]{2,1,0} %param_0.808), dimensions={2,0,1}
  ROOT %bitcast.710 = f32[1024,1024]{0,1} bitcast(f32[1024,16,64]{0,2,1} %transpose.96)
}

%primitive_computation_add__1.14063 (parameter.14064: f32[], parameter.14065: f32[]) -> f32[] {
  %parameter.14064 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.14065 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.14066 = f32[] add(f32[] %parameter.14064, f32[] %parameter.14065), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.15083 (parameter.15084: f32[], parameter.15085: f32[]) -> f32[] {
  %parameter.15084 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.15085 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.15086 = f32[] add(f32[] %parameter.15084, f32[] %parameter.15085), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.13733 (parameter.13734: f32[], parameter.13735: f32[]) -> f32[] {
  %parameter.13734 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.13735 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.13736 = f32[] add(f32[] %parameter.13734, f32[] %parameter.13735), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.15287 (parameter.15288: f32[], parameter.15289: f32[]) -> f32[] {
  %parameter.15288 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.15289 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.15290 = f32[] add(f32[] %parameter.15288, f32[] %parameter.15289), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.13529 (parameter.13530: f32[], parameter.13531: f32[]) -> f32[] {
  %parameter.13530 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.13531 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.13532 = f32[] add(f32[] %parameter.13530, f32[] %parameter.13531), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.15491 (parameter.15492: f32[], parameter.15493: f32[]) -> f32[] {
  %parameter.15492 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.15493 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.15494 = f32[] add(f32[] %parameter.15492, f32[] %parameter.15493), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.13325 (parameter.13326: f32[], parameter.13327: f32[]) -> f32[] {
  %parameter.13326 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.13327 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.13328 = f32[] add(f32[] %parameter.13326, f32[] %parameter.13327), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.15695 (parameter.15696: f32[], parameter.15697: f32[]) -> f32[] {
  %parameter.15696 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.15697 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.15698 = f32[] add(f32[] %parameter.15696, f32[] %parameter.15697), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.13121 (parameter.13122: f32[], parameter.13123: f32[]) -> f32[] {
  %parameter.13122 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.13123 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.13124 = f32[] add(f32[] %parameter.13122, f32[] %parameter.13123), metadata={op_type="add" op_name="add"}
}

%fused_computation.493 (param_0.1446: f32[2048,4096], param_1.2952: f32[2048,4096], param_2.2795: f32[2048,4096], param_3.2656: f32[2048,4096], param_4.1461: f32[2048,4096], param_5.628: f32[2048,4096], param_6.594: f32[2048,4096], param_7.575: f32[2048,4096], param_8.467: f32[2048,4096]) -> (f32[], f32[], f32[], f32[], f32[], /*index=5*/f32[], f32[], f32[], f32[]) {
  %param_0.1446 = f32[2048,4096]{1,0} parameter(0)
  %multiply.1218 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %param_0.1446, f32[2048,4096]{1,0} %param_0.1446), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %bitcast.713 = f32[8388608]{0} bitcast(f32[2048,4096]{1,0} %multiply.1218)
  %constant_11484 = f32[] constant(0)
  %reduce.240 = f32[] reduce(f32[8388608]{0} %bitcast.713, f32[] %constant_11484), dimensions={0}, to_apply=%primitive_computation_add__1.14063, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0, 1) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %param_1.2952 = f32[2048,4096]{1,0} parameter(1)
  %multiply.1083.clone.1 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %param_1.2952, f32[2048,4096]{1,0} %param_1.2952), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %bitcast.697.clone.1 = f32[8388608]{0} bitcast(f32[2048,4096]{1,0} %multiply.1083.clone.1)
  %reduce.219.clone.1 = f32[] reduce(f32[8388608]{0} %bitcast.697.clone.1, f32[] %constant_11484), dimensions={0}, to_apply=%primitive_computation_add__1.15083, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0, 1) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %param_2.2795 = f32[2048,4096]{1,0} parameter(2)
  %multiply.1265.clone.1 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %param_2.2795, f32[2048,4096]{1,0} %param_2.2795), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %bitcast.717.clone.1 = f32[8388608]{0} bitcast(f32[2048,4096]{1,0} %multiply.1265.clone.1)
  %reduce.246.clone.1 = f32[] reduce(f32[8388608]{0} %bitcast.717.clone.1, f32[] %constant_11484), dimensions={0}, to_apply=%primitive_computation_add__1.13733, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0, 1) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %param_3.2656 = f32[2048,4096]{1,0} parameter(3)
  %multiply.1056.clone.1 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %param_3.2656, f32[2048,4096]{1,0} %param_3.2656), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %bitcast.695.clone.1 = f32[8388608]{0} bitcast(f32[2048,4096]{1,0} %multiply.1056.clone.1)
  %reduce.215.clone.1 = f32[] reduce(f32[8388608]{0} %bitcast.695.clone.1, f32[] %constant_11484), dimensions={0}, to_apply=%primitive_computation_add__1.15287, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0, 1) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %param_4.1461 = f32[2048,4096]{1,0} parameter(4)
  %multiply.1293.clone.1 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %param_4.1461, f32[2048,4096]{1,0} %param_4.1461), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %bitcast.719.clone.1 = f32[8388608]{0} bitcast(f32[2048,4096]{1,0} %multiply.1293.clone.1)
  %reduce.250.clone.1 = f32[] reduce(f32[8388608]{0} %bitcast.719.clone.1, f32[] %constant_11484), dimensions={0}, to_apply=%primitive_computation_add__1.13529, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0, 1) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %param_5.628 = f32[2048,4096]{1,0} parameter(5)
  %multiply.1029.clone.1 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %param_5.628, f32[2048,4096]{1,0} %param_5.628), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %bitcast.693.clone.1 = f32[8388608]{0} bitcast(f32[2048,4096]{1,0} %multiply.1029.clone.1)
  %reduce.211.clone.1 = f32[] reduce(f32[8388608]{0} %bitcast.693.clone.1, f32[] %constant_11484), dimensions={0}, to_apply=%primitive_computation_add__1.15491, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0, 1) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %param_6.594 = f32[2048,4096]{1,0} parameter(6)
  %multiply.1320.clone.1 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %param_6.594, f32[2048,4096]{1,0} %param_6.594), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %bitcast.721.clone.1 = f32[8388608]{0} bitcast(f32[2048,4096]{1,0} %multiply.1320.clone.1)
  %reduce.254.clone.1 = f32[] reduce(f32[8388608]{0} %bitcast.721.clone.1, f32[] %constant_11484), dimensions={0}, to_apply=%primitive_computation_add__1.13325, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0, 1) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %param_7.575 = f32[2048,4096]{1,0} parameter(7)
  %multiply.1002.clone.1 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %param_7.575, f32[2048,4096]{1,0} %param_7.575), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %bitcast.691.clone.1 = f32[8388608]{0} bitcast(f32[2048,4096]{1,0} %multiply.1002.clone.1)
  %reduce.207.clone.1 = f32[] reduce(f32[8388608]{0} %bitcast.691.clone.1, f32[] %constant_11484), dimensions={0}, to_apply=%primitive_computation_add__1.15695, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0, 1) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %param_8.467 = f32[2048,4096]{1,0} parameter(8)
  %multiply.1349.clone.1 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %param_8.467, f32[2048,4096]{1,0} %param_8.467), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %bitcast.723.clone.1 = f32[8388608]{0} bitcast(f32[2048,4096]{1,0} %multiply.1349.clone.1)
  %reduce.258.clone.1 = f32[] reduce(f32[8388608]{0} %bitcast.723.clone.1, f32[] %constant_11484), dimensions={0}, to_apply=%primitive_computation_add__1.13121, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0, 1) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  ROOT %tuple.770 = (f32[], f32[], f32[], f32[], f32[], /*index=5*/f32[], f32[], f32[], f32[]) tuple(f32[] %reduce.240, f32[] %reduce.219.clone.1, f32[] %reduce.246.clone.1, f32[] %reduce.215.clone.1, f32[] %reduce.250.clone.1, /*index=5*/f32[] %reduce.211.clone.1, f32[] %reduce.254.clone.1, f32[] %reduce.207.clone.1, f32[] %reduce.258.clone.1)
}

%fused_computation.494 (param_0.2028: f32[], param_1.2483: f32[], param_2.2212: f32[], param_3.2037: f32[], param_4.1047: f32[], param_5.496: f32[256,1024], param_6.442: f32[], param_7.411: f32[1024], param_8.293: f32[256,1024], param_9.179: f32[256]) -> f32[256,1024] {
  %param_6.442 = f32[] parameter(6)
  %broadcast.1369 = f32[256,1024]{1,0} broadcast(f32[] %param_6.442), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  %param_5.496 = f32[256,1024]{1,0} parameter(5)
  %multiply.1221 = f32[256,1024]{1,0} multiply(f32[256,1024]{1,0} %broadcast.1369, f32[256,1024]{1,0} %param_5.496), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  %param_2.2212 = f32[] parameter(2)
  %param_3.2037 = f32[] parameter(3)
  %param_4.1047 = f32[] parameter(4)
  %maximum.44 = f32[] maximum(f32[] %param_3.2037, f32[] %param_4.1047), metadata={op_type="max" op_name="pmap(_multi_device_update_fn)/max" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=122}
  %multiply.1220 = f32[] multiply(f32[] %param_2.2212, f32[] %maximum.44), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=122}
  %broadcast.1368 = f32[256,1024]{1,0} broadcast(f32[] %multiply.1220), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=152}
  %param_8.293 = f32[256,1024]{1,0} parameter(8)
  %param_9.179 = f32[256]{0} parameter(9)
  %constant_14735 = f32[] constant(0.125)
  %broadcast.2130 = f32[256]{0} broadcast(f32[] %constant_14735), dimensions={}
  %multiply.1698 = f32[256]{0} multiply(f32[256]{0} %param_9.179, f32[256]{0} %broadcast.2130)
  %broadcast.2129 = f32[256,1024]{1,0} broadcast(f32[256]{0} %multiply.1698), dimensions={0}
  %multiply.1697 = f32[256,1024]{1,0} multiply(f32[256,1024]{1,0} %param_8.293, f32[256,1024]{1,0} %broadcast.2129), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  %param_7.411 = f32[1024]{0} parameter(7)
  %broadcast.2128 = f32[256,1024]{1,0} broadcast(f32[1024]{0} %param_7.411), dimensions={1}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  %multiply.1696 = f32[256,1024]{1,0} multiply(f32[256,1024]{1,0} %multiply.1697, f32[256,1024]{1,0} %broadcast.2128), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  %constant_11494 = f32[] constant(1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/metrics.py" source_line=617}
  %param_0.2028 = f32[] parameter(0)
  %param_1.2483 = f32[] parameter(1)
  %divide.190 = f32[] divide(f32[] %param_0.2028, f32[] %param_1.2483), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %maximum.43 = f32[] maximum(f32[] %constant_11494, f32[] %divide.190), metadata={op_type="max" op_name="pmap(_multi_device_update_fn)/max" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %broadcast.1367 = f32[256,1024]{1,0} broadcast(f32[] %maximum.43), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=150}
  %divide.189 = f32[256,1024]{1,0} divide(f32[256,1024]{1,0} %multiply.1696, f32[256,1024]{1,0} %broadcast.1367), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=150}
  %multiply.1219 = f32[256,1024]{1,0} multiply(f32[256,1024]{1,0} %broadcast.1368, f32[256,1024]{1,0} %divide.189), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=152}
  ROOT %subtract.277 = f32[256,1024]{1,0} subtract(f32[256,1024]{1,0} %multiply.1221, f32[256,1024]{1,0} %multiply.1219), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
}

%fused_computation.495 (param_0.851: f32[]) -> f32[] {
  %param_0.851 = f32[] parameter(0)
  %constant_11500 = f32[] constant(3.81469727e-06)
  %multiply.1222 = f32[] multiply(f32[] %param_0.851, f32[] %constant_11500), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  ROOT %sqrt.42 = f32[] sqrt(f32[] %multiply.1222), metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
}

%scatter_add_reducer__5.12499 (parameter.12500: f32[], parameter.12501: f32[]) -> f32[] {
  %parameter.12500 = f32[] parameter(0)
  %parameter.12501 = f32[] parameter(1)
  ROOT %add.12502 = f32[] add(f32[] %parameter.12500, f32[] %parameter.12501)
}

%fused_computation.504 (param_0.1875: f32[64,16,1024], param_1.2330: s32[16,64]) -> f32[256,1024] {
  %constant_11523 = f32[] constant(0)
  %broadcast.1376 = f32[256,1024]{1,0} broadcast(f32[] %constant_11523), dimensions={}, metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/broadcast_in_dim[ broadcast_dimensions=(  )\n                                                shape=(256, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/core.py" source_line=182}
  %param_1.2330 = s32[16,64]{1,0} parameter(1)
  %constant_14408 = s32[] constant(0), metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %pad.180 = s32[16,65]{1,0} pad(s32[16,64]{1,0} %param_1.2330, s32[] %constant_14408), padding=0_0x1_0, metadata={op_type="pad" op_name="pmap(_multi_device_update_fn)/jit(_pad)/pad[ padding_config=((0, 0, 0), (1, 0, 0)) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/attention.py" source_line=741}
  %slice.994 = s32[16,64]{1,0} slice(s32[16,65]{1,0} %pad.180), slice={[0:16], [0:64]}
  %copy.45 = s32[16,64]{0,1} copy(s32[16,64]{1,0} %slice.994)
  %bitcast.967 = s32[16,64,1]{2,0,1} bitcast(s32[16,64]{0,1} %copy.45), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/broadcast_in_dim[ broadcast_dimensions=(0, 1)\n                                                shape=(16, 64, 1) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/core.py" source_line=182}
  %param_0.1875 = f32[64,16,1024]{2,1,0} parameter(0)
  %transpose.97 = f32[16,64,1024]{2,0,1} transpose(f32[64,16,1024]{2,1,0} %param_0.1875), dimensions={1,0,2}, metadata={op_type="transpose" op_name="pmap(_multi_device_update_fn)/transpose[ permutation=(1, 0, 2) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/combinators.py" source_line=342}
  ROOT %scatter.0 = f32[256,1024]{1,0} scatter(f32[256,1024]{1,0} %broadcast.1376, s32[16,64,1]{2,0,1} %bitcast.967, f32[16,64,1024]{2,0,1} %transpose.97), update_window_dims={2}, inserted_window_dims={0}, scatter_dims_to_operand_dims={0}, index_vector_dim=2, to_apply=%scatter_add_reducer__5.12499, metadata={op_type="scatter-add" op_name="pmap(_multi_device_update_fn)/scatter-add[ dimension_numbers=ScatterDimensionNumbers(update_window_dims=(2,), inserted_window_dims=(0,), scatter_dims_to_operand_dims=(0,))\n                                           indices_are_sorted=False\n                                           unique_indices=False\n                                           update_consts=(  ) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/core.py" source_line=182}
}

%fused_computation.505 (param_0.1456: f32[1024,1024], param_1.1800: f32[64,16,1024]) -> f32[64,16,1024] {
  %param_1.1800 = f32[64,16,1024]{2,1,0} parameter(1)
  %transpose.112 = f32[16,64,1024]{2,0,1} transpose(f32[64,16,1024]{2,1,0} %param_1.1800), dimensions={1,0,2}, metadata={op_type="transpose" op_name="pmap(_multi_device_update_fn)/transpose[ permutation=(1, 0, 2) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/combinators.py" source_line=342}
  %param_0.1456 = f32[1024,1024]{1,0} parameter(0)
  %reshape.1920 = f32[16,64,1024]{2,0,1} reshape(f32[1024,1024]{1,0} %param_0.1456), metadata={op_type="dot_general" op_name="pmap(_multi_device_update_fn)/dot_general[ dimension_numbers=(((2,), (1,)), ((), ()))\n                                           precision=None\n                                           preferred_element_type=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/core.py" source_line=96}
  %add.2045 = f32[16,64,1024]{2,0,1} add(f32[16,64,1024]{2,0,1} %transpose.112, f32[16,64,1024]{2,0,1} %reshape.1920), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=238}
  ROOT %transpose.98 = f32[64,16,1024]{2,1,0} transpose(f32[16,64,1024]{2,0,1} %add.2045), dimensions={1,0,2}, metadata={op_type="transpose" op_name="pmap(_multi_device_update_fn)/transpose[ permutation=(1, 0, 2) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/combinators.py" source_line=342}
}

%primitive_computation_add__1.13937 (parameter.13938: f32[], parameter.13939: f32[]) -> f32[] {
  %parameter.13938 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.13939 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.13940 = f32[] add(f32[] %parameter.13938, f32[] %parameter.13939), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.15899 (parameter.15900: f32[], parameter.15901: f32[]) -> f32[] {
  %parameter.15900 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.15901 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.15902 = f32[] add(f32[] %parameter.15900, f32[] %parameter.15901), metadata={op_type="add" op_name="add"}
}

%fused_computation.507 (param_0.1450: f32[256,1024], param_1.2946: f32[1024,256]) -> (f32[], f32[]) {
  %param_0.1450 = f32[256,1024]{1,0} parameter(0)
  %multiply.1236 = f32[256,1024]{1,0} multiply(f32[256,1024]{1,0} %param_0.1450, f32[256,1024]{1,0} %param_0.1450), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %bitcast.715 = f32[262144]{0} bitcast(f32[256,1024]{1,0} %multiply.1236)
  %constant_11498 = f32[] constant(0)
  %reduce.242 = f32[] reduce(f32[262144]{0} %bitcast.715, f32[] %constant_11498), dimensions={0}, to_apply=%primitive_computation_add__1.13937, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0, 1) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %param_1.2946 = f32[1024,256]{1,0} parameter(1)
  %multiply.975.clone.1 = f32[1024,256]{1,0} multiply(f32[1024,256]{1,0} %param_1.2946, f32[1024,256]{1,0} %param_1.2946), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %bitcast.689.clone.1 = f32[262144]{0} bitcast(f32[1024,256]{1,0} %multiply.975.clone.1)
  %reduce.203.clone.1 = f32[] reduce(f32[262144]{0} %bitcast.689.clone.1, f32[] %constant_11498), dimensions={0}, to_apply=%primitive_computation_add__1.15899, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0, 1) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  ROOT %tuple.759 = (f32[], f32[]) tuple(f32[] %reduce.242, f32[] %reduce.203.clone.1)
}

%fused_computation.551 (param_0.1984: f32[], param_1.2439: f32[], param_2.2180: f32[], param_3.2022: f32[], param_4.1042: f32[], param_5.493: f32[2048,4096], param_6.439: f32[], param_7.405: f32[4096], param_8.284: f32[2048,4096], param_9.170: f32[2048]) -> f32[2048,4096] {
  %param_6.439 = f32[] parameter(6)
  %broadcast.1784 = f32[2048,4096]{1,0} broadcast(f32[] %param_6.439), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  %param_5.493 = f32[2048,4096]{1,0} parameter(5)
  %multiply.1306 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %broadcast.1784, f32[2048,4096]{1,0} %param_5.493), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  %param_2.2180 = f32[] parameter(2)
  %param_3.2022 = f32[] parameter(3)
  %param_4.1042 = f32[] parameter(4)
  %maximum.56 = f32[] maximum(f32[] %param_3.2022, f32[] %param_4.1042), metadata={op_type="max" op_name="pmap(_multi_device_update_fn)/max" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=122}
  %multiply.1305 = f32[] multiply(f32[] %param_2.2180, f32[] %maximum.56), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=122}
  %broadcast.1395 = f32[2048,4096]{1,0} broadcast(f32[] %multiply.1305), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=152}
  %param_8.284 = f32[2048,4096]{1,0} parameter(8)
  %param_9.170 = f32[2048]{0} parameter(9)
  %constant_14669 = f32[] constant(0.125)
  %broadcast.2070 = f32[2048]{0} broadcast(f32[] %constant_14669), dimensions={}
  %multiply.1622 = f32[2048]{0} multiply(f32[2048]{0} %param_9.170, f32[2048]{0} %broadcast.2070)
  %broadcast.2069 = f32[2048,4096]{1,0} broadcast(f32[2048]{0} %multiply.1622), dimensions={0}
  %multiply.1621 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %param_8.284, f32[2048,4096]{1,0} %broadcast.2069), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  %param_7.405 = f32[4096]{0} parameter(7)
  %broadcast.2068 = f32[2048,4096]{1,0} broadcast(f32[4096]{0} %param_7.405), dimensions={1}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  %multiply.1620 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %multiply.1621, f32[2048,4096]{1,0} %broadcast.2068), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  %constant_11624 = f32[] constant(1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/metrics.py" source_line=617}
  %param_0.1984 = f32[] parameter(0)
  %param_1.2439 = f32[] parameter(1)
  %divide.205 = f32[] divide(f32[] %param_0.1984, f32[] %param_1.2439), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %maximum.55 = f32[] maximum(f32[] %constant_11624, f32[] %divide.205), metadata={op_type="max" op_name="pmap(_multi_device_update_fn)/max" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %broadcast.1394 = f32[2048,4096]{1,0} broadcast(f32[] %maximum.55), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=150}
  %divide.204 = f32[2048,4096]{1,0} divide(f32[2048,4096]{1,0} %multiply.1620, f32[2048,4096]{1,0} %broadcast.1394), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=150}
  %multiply.1304 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %broadcast.1395, f32[2048,4096]{1,0} %divide.204), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=152}
  ROOT %subtract.283 = f32[2048,4096]{1,0} subtract(f32[2048,4096]{1,0} %multiply.1306, f32[2048,4096]{1,0} %multiply.1304), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
}

%fused_computation.552 (param_0.962: f32[]) -> f32[] {
  %param_0.962 = f32[] parameter(0)
  %constant_11632 = f32[] constant(1.1920929e-07)
  %multiply.1307 = f32[] multiply(f32[] %param_0.962, f32[] %constant_11632), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  ROOT %sqrt.54 = f32[] sqrt(f32[] %multiply.1307), metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
}

%fused_computation.562 (param_0.982: f32[4096], param_1.1831: f32[], param_2.1409: f32[], param_3.1190: f32[], param_4.487: f32[], param_5.246: f32[], param_6.195: f32[4096], param_7.194: f32[], param_8.355: f32[4096], param_9.225: f32[], param_10.191: f32[], param_11.192: f32[4096], param_12.207: f32[4096], param_13.254: f32[], param_14.235: f32[], param_15.178: f32[4096], param_16.90: f32[4096], param_17.34: f32[], param_18.17: f32[], param_19.25: f32[4096], param_20.20: f32[4096], param_21.20: f32[], param_22.17: f32[], param_23.21: f32[4096], param_24.18: f32[4096], param_25.20: f32[], param_26.19: f32[], param_27.25: f32[4096], param_28.15: f32[4096], param_29.10: f32[], param_30.64: f32[], param_31.16: f32[4096], param_32.11: f32[4096], param_33.11: f32[], param_34.8: f32[], param_35.12: f32[4096], param_36.9: f32[4096], param_37.11: f32[], param_38.10: f32[], param_39.16: f32[4096]) -> (f32[4096], f32[4096], f32[4096], f32[4096], f32[4096], /*index=5*/f32[4096], f32[4096], f32[4096], f32[4096]) {
  %param_7.194 = f32[] parameter(7)
  %broadcast.1794 = f32[4096]{0} broadcast(f32[] %param_7.194), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  %param_6.195 = f32[4096]{0} parameter(6)
  %multiply.1323 = f32[4096]{0} multiply(f32[4096]{0} %broadcast.1794, f32[4096]{0} %param_6.195), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  %param_3.1190 = f32[] parameter(3)
  %param_4.487 = f32[] parameter(4)
  %param_5.246 = f32[] parameter(5)
  %maximum.58 = f32[] maximum(f32[] %param_4.487, f32[] %param_5.246), metadata={op_type="max" op_name="pmap(_multi_device_update_fn)/max" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=122}
  %multiply.1322 = f32[] multiply(f32[] %param_3.1190, f32[] %maximum.58), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=122}
  %broadcast.1400 = f32[4096]{0} broadcast(f32[] %multiply.1322), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=152}
  %param_0.982 = f32[4096]{0} parameter(0)
  %constant_11645 = f32[] constant(1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/metrics.py" source_line=617}
  %param_1.1831 = f32[] parameter(1)
  %param_2.1409 = f32[] parameter(2)
  %divide.208 = f32[] divide(f32[] %param_1.1831, f32[] %param_2.1409), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %maximum.57 = f32[] maximum(f32[] %constant_11645, f32[] %divide.208), metadata={op_type="max" op_name="pmap(_multi_device_update_fn)/max" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %broadcast.1399 = f32[4096]{0} broadcast(f32[] %maximum.57), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=150}
  %divide.207 = f32[4096]{0} divide(f32[4096]{0} %param_0.982, f32[4096]{0} %broadcast.1399), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=150}
  %multiply.1321 = f32[4096]{0} multiply(f32[4096]{0} %broadcast.1400, f32[4096]{0} %divide.207), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=152}
  %subtract.284 = f32[4096]{0} subtract(f32[4096]{0} %multiply.1323, f32[4096]{0} %multiply.1321), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  %param_11.192 = f32[4096]{0} parameter(11)
  %multiply.978.clone.1 = f32[4096]{0} multiply(f32[4096]{0} %broadcast.1794, f32[4096]{0} %param_11.192), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  %param_10.191 = f32[] parameter(10)
  %maximum.8.clone.1 = f32[] maximum(f32[] %param_10.191, f32[] %param_5.246), metadata={op_type="max" op_name="pmap(_multi_device_update_fn)/max" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=122}
  %multiply.977.clone.1 = f32[] multiply(f32[] %param_3.1190, f32[] %maximum.8.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=122}
  %broadcast.1302.clone.1 = f32[4096]{0} broadcast(f32[] %multiply.977.clone.1), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=152}
  %param_8.355 = f32[4096]{0} parameter(8)
  %param_9.225 = f32[] parameter(9)
  %divide.145.clone.1 = f32[] divide(f32[] %param_9.225, f32[] %param_2.1409), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %maximum.7.clone.1 = f32[] maximum(f32[] %constant_11645, f32[] %divide.145.clone.1), metadata={op_type="max" op_name="pmap(_multi_device_update_fn)/max" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %broadcast.1301.clone.1 = f32[4096]{0} broadcast(f32[] %maximum.7.clone.1), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=150}
  %divide.144.clone.1 = f32[4096]{0} divide(f32[4096]{0} %param_8.355, f32[4096]{0} %broadcast.1301.clone.1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=150}
  %multiply.976.clone.1 = f32[4096]{0} multiply(f32[4096]{0} %broadcast.1302.clone.1, f32[4096]{0} %divide.144.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=152}
  %subtract.259.clone.1 = f32[4096]{0} subtract(f32[4096]{0} %multiply.978.clone.1, f32[4096]{0} %multiply.976.clone.1), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  %param_15.178 = f32[4096]{0} parameter(15)
  %multiply.1005.clone.1 = f32[4096]{0} multiply(f32[4096]{0} %broadcast.1794, f32[4096]{0} %param_15.178), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  %param_14.235 = f32[] parameter(14)
  %maximum.12.clone.1 = f32[] maximum(f32[] %param_14.235, f32[] %param_5.246), metadata={op_type="max" op_name="pmap(_multi_device_update_fn)/max" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=122}
  %multiply.1004.clone.1 = f32[] multiply(f32[] %param_3.1190, f32[] %maximum.12.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=122}
  %broadcast.1309.clone.1 = f32[4096]{0} broadcast(f32[] %multiply.1004.clone.1), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=152}
  %param_12.207 = f32[4096]{0} parameter(12)
  %param_13.254 = f32[] parameter(13)
  %divide.150.clone.1 = f32[] divide(f32[] %param_13.254, f32[] %param_2.1409), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %maximum.11.clone.1 = f32[] maximum(f32[] %constant_11645, f32[] %divide.150.clone.1), metadata={op_type="max" op_name="pmap(_multi_device_update_fn)/max" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %broadcast.1308.clone.1 = f32[4096]{0} broadcast(f32[] %maximum.11.clone.1), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=150}
  %divide.149.clone.1 = f32[4096]{0} divide(f32[4096]{0} %param_12.207, f32[4096]{0} %broadcast.1308.clone.1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=150}
  %multiply.1003.clone.1 = f32[4096]{0} multiply(f32[4096]{0} %broadcast.1309.clone.1, f32[4096]{0} %divide.149.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=152}
  %subtract.261.clone.1 = f32[4096]{0} subtract(f32[4096]{0} %multiply.1005.clone.1, f32[4096]{0} %multiply.1003.clone.1), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  %param_19.25 = f32[4096]{0} parameter(19)
  %multiply.1032.clone.1 = f32[4096]{0} multiply(f32[4096]{0} %broadcast.1794, f32[4096]{0} %param_19.25), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  %param_18.17 = f32[] parameter(18)
  %maximum.16.clone.1 = f32[] maximum(f32[] %param_18.17, f32[] %param_5.246), metadata={op_type="max" op_name="pmap(_multi_device_update_fn)/max" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=122}
  %multiply.1031.clone.1 = f32[] multiply(f32[] %param_3.1190, f32[] %maximum.16.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=122}
  %broadcast.1316.clone.1 = f32[4096]{0} broadcast(f32[] %multiply.1031.clone.1), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=152}
  %param_16.90 = f32[4096]{0} parameter(16)
  %param_17.34 = f32[] parameter(17)
  %divide.155.clone.1 = f32[] divide(f32[] %param_17.34, f32[] %param_2.1409), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %maximum.15.clone.1 = f32[] maximum(f32[] %constant_11645, f32[] %divide.155.clone.1), metadata={op_type="max" op_name="pmap(_multi_device_update_fn)/max" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %broadcast.1315.clone.1 = f32[4096]{0} broadcast(f32[] %maximum.15.clone.1), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=150}
  %divide.154.clone.1 = f32[4096]{0} divide(f32[4096]{0} %param_16.90, f32[4096]{0} %broadcast.1315.clone.1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=150}
  %multiply.1030.clone.1 = f32[4096]{0} multiply(f32[4096]{0} %broadcast.1316.clone.1, f32[4096]{0} %divide.154.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=152}
  %subtract.263.clone.1 = f32[4096]{0} subtract(f32[4096]{0} %multiply.1032.clone.1, f32[4096]{0} %multiply.1030.clone.1), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  %param_23.21 = f32[4096]{0} parameter(23)
  %multiply.1059.clone.1 = f32[4096]{0} multiply(f32[4096]{0} %broadcast.1794, f32[4096]{0} %param_23.21), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  %param_22.17 = f32[] parameter(22)
  %maximum.20.clone.1 = f32[] maximum(f32[] %param_22.17, f32[] %param_5.246), metadata={op_type="max" op_name="pmap(_multi_device_update_fn)/max" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=122}
  %multiply.1058.clone.1 = f32[] multiply(f32[] %param_3.1190, f32[] %maximum.20.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=122}
  %broadcast.1324.clone.1 = f32[4096]{0} broadcast(f32[] %multiply.1058.clone.1), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=152}
  %param_20.20 = f32[4096]{0} parameter(20)
  %param_21.20 = f32[] parameter(21)
  %divide.160.clone.1 = f32[] divide(f32[] %param_21.20, f32[] %param_2.1409), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %maximum.19.clone.1 = f32[] maximum(f32[] %constant_11645, f32[] %divide.160.clone.1), metadata={op_type="max" op_name="pmap(_multi_device_update_fn)/max" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %broadcast.1323.clone.1 = f32[4096]{0} broadcast(f32[] %maximum.19.clone.1), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=150}
  %divide.159.clone.1 = f32[4096]{0} divide(f32[4096]{0} %param_20.20, f32[4096]{0} %broadcast.1323.clone.1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=150}
  %multiply.1057.clone.1 = f32[4096]{0} multiply(f32[4096]{0} %broadcast.1324.clone.1, f32[4096]{0} %divide.159.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=152}
  %subtract.265.clone.1 = f32[4096]{0} subtract(f32[4096]{0} %multiply.1059.clone.1, f32[4096]{0} %multiply.1057.clone.1), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  %param_27.25 = f32[4096]{0} parameter(27)
  %multiply.1194.clone.1 = f32[4096]{0} multiply(f32[4096]{0} %broadcast.1794, f32[4096]{0} %param_27.25), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  %param_26.19 = f32[] parameter(26)
  %maximum.40.clone.1 = f32[] maximum(f32[] %param_26.19, f32[] %param_5.246), metadata={op_type="max" op_name="pmap(_multi_device_update_fn)/max" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=122}
  %multiply.1193.clone.1 = f32[] multiply(f32[] %param_3.1190, f32[] %maximum.40.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=122}
  %broadcast.1360.clone.1 = f32[4096]{0} broadcast(f32[] %multiply.1193.clone.1), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=152}
  %param_24.18 = f32[4096]{0} parameter(24)
  %param_25.20 = f32[] parameter(25)
  %divide.185.clone.1 = f32[] divide(f32[] %param_25.20, f32[] %param_2.1409), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %maximum.39.clone.1 = f32[] maximum(f32[] %constant_11645, f32[] %divide.185.clone.1), metadata={op_type="max" op_name="pmap(_multi_device_update_fn)/max" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %broadcast.1359.clone.1 = f32[4096]{0} broadcast(f32[] %maximum.39.clone.1), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=150}
  %divide.184.clone.1 = f32[4096]{0} divide(f32[4096]{0} %param_24.18, f32[4096]{0} %broadcast.1359.clone.1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=150}
  %multiply.1192.clone.1 = f32[4096]{0} multiply(f32[4096]{0} %broadcast.1360.clone.1, f32[4096]{0} %divide.184.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=152}
  %subtract.275.clone.1 = f32[4096]{0} subtract(f32[4096]{0} %multiply.1194.clone.1, f32[4096]{0} %multiply.1192.clone.1), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  %param_31.16 = f32[4096]{0} parameter(31)
  %multiply.1239.clone.1 = f32[4096]{0} multiply(f32[4096]{0} %broadcast.1794, f32[4096]{0} %param_31.16), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  %param_30.64 = f32[] parameter(30)
  %maximum.46.clone.1 = f32[] maximum(f32[] %param_30.64, f32[] %param_5.246), metadata={op_type="max" op_name="pmap(_multi_device_update_fn)/max" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=122}
  %multiply.1238.clone.1 = f32[] multiply(f32[] %param_3.1190, f32[] %maximum.46.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=122}
  %broadcast.1378.clone.1 = f32[4096]{0} broadcast(f32[] %multiply.1238.clone.1), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=152}
  %param_28.15 = f32[4096]{0} parameter(28)
  %param_29.10 = f32[] parameter(29)
  %divide.193.clone.1 = f32[] divide(f32[] %param_29.10, f32[] %param_2.1409), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %maximum.45.clone.1 = f32[] maximum(f32[] %constant_11645, f32[] %divide.193.clone.1), metadata={op_type="max" op_name="pmap(_multi_device_update_fn)/max" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %broadcast.1377.clone.1 = f32[4096]{0} broadcast(f32[] %maximum.45.clone.1), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=150}
  %divide.192.clone.1 = f32[4096]{0} divide(f32[4096]{0} %param_28.15, f32[4096]{0} %broadcast.1377.clone.1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=150}
  %multiply.1237.clone.1 = f32[4096]{0} multiply(f32[4096]{0} %broadcast.1378.clone.1, f32[4096]{0} %divide.192.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=152}
  %subtract.278.clone.1 = f32[4096]{0} subtract(f32[4096]{0} %multiply.1239.clone.1, f32[4096]{0} %multiply.1237.clone.1), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  %param_35.12 = f32[4096]{0} parameter(35)
  %multiply.1268.clone.1 = f32[4096]{0} multiply(f32[4096]{0} %broadcast.1794, f32[4096]{0} %param_35.12), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  %param_34.8 = f32[] parameter(34)
  %maximum.50.clone.1 = f32[] maximum(f32[] %param_34.8, f32[] %param_5.246), metadata={op_type="max" op_name="pmap(_multi_device_update_fn)/max" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=122}
  %multiply.1267.clone.1 = f32[] multiply(f32[] %param_3.1190, f32[] %maximum.50.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=122}
  %broadcast.1385.clone.1 = f32[4096]{0} broadcast(f32[] %multiply.1267.clone.1), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=152}
  %param_32.11 = f32[4096]{0} parameter(32)
  %param_33.11 = f32[] parameter(33)
  %divide.198.clone.1 = f32[] divide(f32[] %param_33.11, f32[] %param_2.1409), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %maximum.49.clone.1 = f32[] maximum(f32[] %constant_11645, f32[] %divide.198.clone.1), metadata={op_type="max" op_name="pmap(_multi_device_update_fn)/max" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %broadcast.1384.clone.1 = f32[4096]{0} broadcast(f32[] %maximum.49.clone.1), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=150}
  %divide.197.clone.1 = f32[4096]{0} divide(f32[4096]{0} %param_32.11, f32[4096]{0} %broadcast.1384.clone.1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=150}
  %multiply.1266.clone.1 = f32[4096]{0} multiply(f32[4096]{0} %broadcast.1385.clone.1, f32[4096]{0} %divide.197.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=152}
  %subtract.280.clone.1 = f32[4096]{0} subtract(f32[4096]{0} %multiply.1268.clone.1, f32[4096]{0} %multiply.1266.clone.1), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  %param_39.16 = f32[4096]{0} parameter(39)
  %multiply.1296.clone.1 = f32[4096]{0} multiply(f32[4096]{0} %broadcast.1794, f32[4096]{0} %param_39.16), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  %param_38.10 = f32[] parameter(38)
  %maximum.54.clone.1 = f32[] maximum(f32[] %param_38.10, f32[] %param_5.246), metadata={op_type="max" op_name="pmap(_multi_device_update_fn)/max" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=122}
  %multiply.1295.clone.1 = f32[] multiply(f32[] %param_3.1190, f32[] %maximum.54.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=122}
  %broadcast.1393.clone.1 = f32[4096]{0} broadcast(f32[] %multiply.1295.clone.1), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=152}
  %param_36.9 = f32[4096]{0} parameter(36)
  %param_37.11 = f32[] parameter(37)
  %divide.203.clone.1 = f32[] divide(f32[] %param_37.11, f32[] %param_2.1409), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %maximum.53.clone.1 = f32[] maximum(f32[] %constant_11645, f32[] %divide.203.clone.1), metadata={op_type="max" op_name="pmap(_multi_device_update_fn)/max" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %broadcast.1392.clone.1 = f32[4096]{0} broadcast(f32[] %maximum.53.clone.1), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=150}
  %divide.202.clone.1 = f32[4096]{0} divide(f32[4096]{0} %param_36.9, f32[4096]{0} %broadcast.1392.clone.1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=150}
  %multiply.1294.clone.1 = f32[4096]{0} multiply(f32[4096]{0} %broadcast.1393.clone.1, f32[4096]{0} %divide.202.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=152}
  %subtract.282.clone.1 = f32[4096]{0} subtract(f32[4096]{0} %multiply.1296.clone.1, f32[4096]{0} %multiply.1294.clone.1), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  ROOT %tuple.653 = (f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, /*index=5*/f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}) tuple(f32[4096]{0} %subtract.284, f32[4096]{0} %subtract.259.clone.1, f32[4096]{0} %subtract.261.clone.1, f32[4096]{0} %subtract.263.clone.1, f32[4096]{0} %subtract.265.clone.1, /*index=5*/f32[4096]{0} %subtract.275.clone.1, f32[4096]{0} %subtract.278.clone.1, f32[4096]{0} %subtract.280.clone.1, f32[4096]{0} %subtract.282.clone.1)
}

%fused_computation.569 (param_0.1970: f32[], param_1.2425: f32[], param_2.2170: f32[], param_3.2019: f32[], param_4.1041: f32[], param_5.492: f32[2048,4096], param_6.438: f32[], param_7.403: f32[4096], param_8.281: f32[2048,4096], param_9.167: f32[2048], param_10.187: f32[], param_11.183: f32[4096], param_12.202: f32[2048,4096], param_13.250: f32[2048], param_14.231: f32[], param_15.169: f32[2048,4096], param_16.85: f32[], param_17.30: f32[4096], param_18.13: f32[2048,4096], param_19.16: f32[2048], param_20.15: f32[], param_21.16: f32[2048,4096], param_22.13: f32[], param_23.12: f32[4096], param_24.13: f32[2048,4096], param_25.16: f32[2048], param_26.15: f32[], param_27.16: f32[2048,4096], param_28.10: f32[], param_29.6: f32[4096], param_30.60: f32[2048,4096], param_31.7: f32[2048], param_32.6: f32[], param_33.7: f32[2048,4096], param_34.4: f32[], param_35.3: f32[4096], param_36.4: f32[2048,4096], param_37.7: f32[2048], param_38.6: f32[], param_39.7: f32[2048,4096], param_40.4: f32[], param_41.3: f32[4096], param_42.4: f32[2048,4096], param_43.7: f32[2048], param_44.6: f32[], param_45.7: f32[2048,4096], param_46.4: f32[], param_47.3: f32[4096], param_48.4: f32[2048,4096], param_49.7: f32[2048], param_50.6: f32[], param_51.7: f32[2048,4096]) -> (f32[2048,4096], f32[2048,4096], f32[2048,4096], f32[2048,4096], f32[2048,4096], /*index=5*/f32[2048,4096], f32[2048,4096], f32[2048,4096]) {
  %param_6.438 = f32[] parameter(6)
  %broadcast.1801 = f32[2048,4096]{1,0} broadcast(f32[] %param_6.438), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  %param_5.492 = f32[2048,4096]{1,0} parameter(5)
  %multiply.1333 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %broadcast.1801, f32[2048,4096]{1,0} %param_5.492), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  %param_2.2170 = f32[] parameter(2)
  %param_3.2019 = f32[] parameter(3)
  %param_4.1041 = f32[] parameter(4)
  %maximum.60 = f32[] maximum(f32[] %param_3.2019, f32[] %param_4.1041), metadata={op_type="max" op_name="pmap(_multi_device_update_fn)/max" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=122}
  %multiply.1332 = f32[] multiply(f32[] %param_2.2170, f32[] %maximum.60), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=122}
  %broadcast.1402 = f32[2048,4096]{1,0} broadcast(f32[] %multiply.1332), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=152}
  %param_8.281 = f32[2048,4096]{1,0} parameter(8)
  %param_9.167 = f32[2048]{0} parameter(9)
  %constant_14651 = f32[] constant(0.125)
  %broadcast.2051 = f32[2048]{0} broadcast(f32[] %constant_14651), dimensions={}
  %multiply.1598 = f32[2048]{0} multiply(f32[2048]{0} %param_9.167, f32[2048]{0} %broadcast.2051)
  %broadcast.2050 = f32[2048,4096]{1,0} broadcast(f32[2048]{0} %multiply.1598), dimensions={0}
  %multiply.1597 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %param_8.281, f32[2048,4096]{1,0} %broadcast.2050), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  %param_7.403 = f32[4096]{0} parameter(7)
  %broadcast.2049 = f32[2048,4096]{1,0} broadcast(f32[4096]{0} %param_7.403), dimensions={1}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  %multiply.1596 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %multiply.1597, f32[2048,4096]{1,0} %broadcast.2049), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  %constant_11662 = f32[] constant(1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/metrics.py" source_line=617}
  %param_0.1970 = f32[] parameter(0)
  %param_1.2425 = f32[] parameter(1)
  %divide.210 = f32[] divide(f32[] %param_0.1970, f32[] %param_1.2425), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %maximum.59 = f32[] maximum(f32[] %constant_11662, f32[] %divide.210), metadata={op_type="max" op_name="pmap(_multi_device_update_fn)/max" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %broadcast.1401 = f32[2048,4096]{1,0} broadcast(f32[] %maximum.59), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=150}
  %divide.209 = f32[2048,4096]{1,0} divide(f32[2048,4096]{1,0} %multiply.1596, f32[2048,4096]{1,0} %broadcast.1401), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=150}
  %multiply.1331 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %broadcast.1402, f32[2048,4096]{1,0} %divide.209), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=152}
  %subtract.285 = f32[2048,4096]{1,0} subtract(f32[2048,4096]{1,0} %multiply.1333, f32[2048,4096]{1,0} %multiply.1331), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  %param_15.169 = f32[2048,4096]{1,0} parameter(15)
  %multiply.988.clone.1 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %broadcast.1801, f32[2048,4096]{1,0} %param_15.169), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  %param_14.231 = f32[] parameter(14)
  %maximum.10.clone.1 = f32[] maximum(f32[] %param_14.231, f32[] %param_4.1041), metadata={op_type="max" op_name="pmap(_multi_device_update_fn)/max" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=122}
  %multiply.987.clone.1 = f32[] multiply(f32[] %param_2.2170, f32[] %maximum.10.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=122}
  %broadcast.1304.clone.1 = f32[2048,4096]{1,0} broadcast(f32[] %multiply.987.clone.1), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=152}
  %param_12.202 = f32[2048,4096]{1,0} parameter(12)
  %param_13.250 = f32[2048]{0} parameter(13)
  %multiply.1914.clone.1 = f32[2048]{0} multiply(f32[2048]{0} %param_13.250, f32[2048]{0} %broadcast.2051)
  %broadcast.2297.clone.1 = f32[2048,4096]{1,0} broadcast(f32[2048]{0} %multiply.1914.clone.1), dimensions={0}
  %multiply.1913.clone.1 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %param_12.202, f32[2048,4096]{1,0} %broadcast.2297.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  %param_11.183 = f32[4096]{0} parameter(11)
  %broadcast.2296.clone.1 = f32[2048,4096]{1,0} broadcast(f32[4096]{0} %param_11.183), dimensions={1}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  %multiply.1912.clone.1 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %multiply.1913.clone.1, f32[2048,4096]{1,0} %broadcast.2296.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  %param_10.187 = f32[] parameter(10)
  %divide.147.clone.1 = f32[] divide(f32[] %param_10.187, f32[] %param_1.2425), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %maximum.9.clone.1 = f32[] maximum(f32[] %constant_11662, f32[] %divide.147.clone.1), metadata={op_type="max" op_name="pmap(_multi_device_update_fn)/max" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %broadcast.1303.clone.1 = f32[2048,4096]{1,0} broadcast(f32[] %maximum.9.clone.1), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=150}
  %divide.146.clone.1 = f32[2048,4096]{1,0} divide(f32[2048,4096]{1,0} %multiply.1912.clone.1, f32[2048,4096]{1,0} %broadcast.1303.clone.1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=150}
  %multiply.986.clone.1 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %broadcast.1304.clone.1, f32[2048,4096]{1,0} %divide.146.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=152}
  %subtract.260.clone.1 = f32[2048,4096]{1,0} subtract(f32[2048,4096]{1,0} %multiply.988.clone.1, f32[2048,4096]{1,0} %multiply.986.clone.1), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  %param_21.16 = f32[2048,4096]{1,0} parameter(21)
  %multiply.1015.clone.1 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %broadcast.1801, f32[2048,4096]{1,0} %param_21.16), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  %param_20.15 = f32[] parameter(20)
  %maximum.14.clone.1 = f32[] maximum(f32[] %param_20.15, f32[] %param_4.1041), metadata={op_type="max" op_name="pmap(_multi_device_update_fn)/max" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=122}
  %multiply.1014.clone.1 = f32[] multiply(f32[] %param_2.2170, f32[] %maximum.14.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=122}
  %broadcast.1311.clone.1 = f32[2048,4096]{1,0} broadcast(f32[] %multiply.1014.clone.1), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=152}
  %param_18.13 = f32[2048,4096]{1,0} parameter(18)
  %param_19.16 = f32[2048]{0} parameter(19)
  %multiply.1890.clone.1 = f32[2048]{0} multiply(f32[2048]{0} %param_19.16, f32[2048]{0} %broadcast.2051)
  %broadcast.2279.clone.1 = f32[2048,4096]{1,0} broadcast(f32[2048]{0} %multiply.1890.clone.1), dimensions={0}
  %multiply.1889.clone.1 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %param_18.13, f32[2048,4096]{1,0} %broadcast.2279.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  %param_17.30 = f32[4096]{0} parameter(17)
  %broadcast.2278.clone.1 = f32[2048,4096]{1,0} broadcast(f32[4096]{0} %param_17.30), dimensions={1}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  %multiply.1888.clone.1 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %multiply.1889.clone.1, f32[2048,4096]{1,0} %broadcast.2278.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  %param_16.85 = f32[] parameter(16)
  %divide.152.clone.1 = f32[] divide(f32[] %param_16.85, f32[] %param_1.2425), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %maximum.13.clone.1 = f32[] maximum(f32[] %constant_11662, f32[] %divide.152.clone.1), metadata={op_type="max" op_name="pmap(_multi_device_update_fn)/max" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %broadcast.1310.clone.1 = f32[2048,4096]{1,0} broadcast(f32[] %maximum.13.clone.1), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=150}
  %divide.151.clone.1 = f32[2048,4096]{1,0} divide(f32[2048,4096]{1,0} %multiply.1888.clone.1, f32[2048,4096]{1,0} %broadcast.1310.clone.1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=150}
  %multiply.1013.clone.1 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %broadcast.1311.clone.1, f32[2048,4096]{1,0} %divide.151.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=152}
  %subtract.262.clone.1 = f32[2048,4096]{1,0} subtract(f32[2048,4096]{1,0} %multiply.1015.clone.1, f32[2048,4096]{1,0} %multiply.1013.clone.1), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  %param_27.16 = f32[2048,4096]{1,0} parameter(27)
  %multiply.1042.clone.1 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %broadcast.1801, f32[2048,4096]{1,0} %param_27.16), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  %param_26.15 = f32[] parameter(26)
  %maximum.18.clone.1 = f32[] maximum(f32[] %param_26.15, f32[] %param_4.1041), metadata={op_type="max" op_name="pmap(_multi_device_update_fn)/max" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=122}
  %multiply.1041.clone.1 = f32[] multiply(f32[] %param_2.2170, f32[] %maximum.18.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=122}
  %broadcast.1319.clone.1 = f32[2048,4096]{1,0} broadcast(f32[] %multiply.1041.clone.1), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=152}
  %param_24.13 = f32[2048,4096]{1,0} parameter(24)
  %param_25.16 = f32[2048]{0} parameter(25)
  %multiply.1866.clone.1 = f32[2048]{0} multiply(f32[2048]{0} %param_25.16, f32[2048]{0} %broadcast.2051)
  %broadcast.2261.clone.1 = f32[2048,4096]{1,0} broadcast(f32[2048]{0} %multiply.1866.clone.1), dimensions={0}
  %multiply.1865.clone.1 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %param_24.13, f32[2048,4096]{1,0} %broadcast.2261.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  %param_23.12 = f32[4096]{0} parameter(23)
  %broadcast.2260.clone.1 = f32[2048,4096]{1,0} broadcast(f32[4096]{0} %param_23.12), dimensions={1}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  %multiply.1864.clone.1 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %multiply.1865.clone.1, f32[2048,4096]{1,0} %broadcast.2260.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  %param_22.13 = f32[] parameter(22)
  %divide.157.clone.1 = f32[] divide(f32[] %param_22.13, f32[] %param_1.2425), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %maximum.17.clone.1 = f32[] maximum(f32[] %constant_11662, f32[] %divide.157.clone.1), metadata={op_type="max" op_name="pmap(_multi_device_update_fn)/max" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %broadcast.1317.clone.1 = f32[2048,4096]{1,0} broadcast(f32[] %maximum.17.clone.1), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=150}
  %divide.156.clone.1 = f32[2048,4096]{1,0} divide(f32[2048,4096]{1,0} %multiply.1864.clone.1, f32[2048,4096]{1,0} %broadcast.1317.clone.1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=150}
  %multiply.1040.clone.1 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %broadcast.1319.clone.1, f32[2048,4096]{1,0} %divide.156.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=152}
  %subtract.264.clone.1 = f32[2048,4096]{1,0} subtract(f32[2048,4096]{1,0} %multiply.1042.clone.1, f32[2048,4096]{1,0} %multiply.1040.clone.1), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  %param_33.7 = f32[2048,4096]{1,0} parameter(33)
  %multiply.1069.clone.1 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %broadcast.1801, f32[2048,4096]{1,0} %param_33.7), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  %param_32.6 = f32[] parameter(32)
  %maximum.22.clone.1 = f32[] maximum(f32[] %param_32.6, f32[] %param_4.1041), metadata={op_type="max" op_name="pmap(_multi_device_update_fn)/max" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=122}
  %multiply.1068.clone.1 = f32[] multiply(f32[] %param_2.2170, f32[] %maximum.22.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=122}
  %broadcast.1326.clone.1 = f32[2048,4096]{1,0} broadcast(f32[] %multiply.1068.clone.1), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=152}
  %param_30.60 = f32[2048,4096]{1,0} parameter(30)
  %param_31.7 = f32[2048]{0} parameter(31)
  %multiply.1842.clone.1 = f32[2048]{0} multiply(f32[2048]{0} %param_31.7, f32[2048]{0} %broadcast.2051)
  %broadcast.2242.clone.1 = f32[2048,4096]{1,0} broadcast(f32[2048]{0} %multiply.1842.clone.1), dimensions={0}
  %multiply.1841.clone.1 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %param_30.60, f32[2048,4096]{1,0} %broadcast.2242.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  %param_29.6 = f32[4096]{0} parameter(29)
  %broadcast.2241.clone.1 = f32[2048,4096]{1,0} broadcast(f32[4096]{0} %param_29.6), dimensions={1}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  %multiply.1840.clone.1 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %multiply.1841.clone.1, f32[2048,4096]{1,0} %broadcast.2241.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  %param_28.10 = f32[] parameter(28)
  %divide.162.clone.1 = f32[] divide(f32[] %param_28.10, f32[] %param_1.2425), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %maximum.21.clone.1 = f32[] maximum(f32[] %constant_11662, f32[] %divide.162.clone.1), metadata={op_type="max" op_name="pmap(_multi_device_update_fn)/max" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %broadcast.1325.clone.1 = f32[2048,4096]{1,0} broadcast(f32[] %maximum.21.clone.1), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=150}
  %divide.161.clone.1 = f32[2048,4096]{1,0} divide(f32[2048,4096]{1,0} %multiply.1840.clone.1, f32[2048,4096]{1,0} %broadcast.1325.clone.1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=150}
  %multiply.1067.clone.1 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %broadcast.1326.clone.1, f32[2048,4096]{1,0} %divide.161.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=152}
  %subtract.266.clone.1 = f32[2048,4096]{1,0} subtract(f32[2048,4096]{1,0} %multiply.1069.clone.1, f32[2048,4096]{1,0} %multiply.1067.clone.1), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  %param_39.7 = f32[2048,4096]{1,0} parameter(39)
  %multiply.1204.clone.1 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %broadcast.1801, f32[2048,4096]{1,0} %param_39.7), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  %param_38.6 = f32[] parameter(38)
  %maximum.42.clone.1 = f32[] maximum(f32[] %param_38.6, f32[] %param_4.1041), metadata={op_type="max" op_name="pmap(_multi_device_update_fn)/max" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=122}
  %multiply.1203.clone.1 = f32[] multiply(f32[] %param_2.2170, f32[] %maximum.42.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=122}
  %broadcast.1362.clone.1 = f32[2048,4096]{1,0} broadcast(f32[] %multiply.1203.clone.1), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=152}
  %param_36.4 = f32[2048,4096]{1,0} parameter(36)
  %param_37.7 = f32[2048]{0} parameter(37)
  %multiply.1722.clone.1 = f32[2048]{0} multiply(f32[2048]{0} %param_37.7, f32[2048]{0} %broadcast.2051)
  %broadcast.2148.clone.1 = f32[2048,4096]{1,0} broadcast(f32[2048]{0} %multiply.1722.clone.1), dimensions={0}
  %multiply.1721.clone.1 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %param_36.4, f32[2048,4096]{1,0} %broadcast.2148.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  %param_35.3 = f32[4096]{0} parameter(35)
  %broadcast.2147.clone.1 = f32[2048,4096]{1,0} broadcast(f32[4096]{0} %param_35.3), dimensions={1}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  %multiply.1720.clone.1 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %multiply.1721.clone.1, f32[2048,4096]{1,0} %broadcast.2147.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  %param_34.4 = f32[] parameter(34)
  %divide.187.clone.1 = f32[] divide(f32[] %param_34.4, f32[] %param_1.2425), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %maximum.41.clone.1 = f32[] maximum(f32[] %constant_11662, f32[] %divide.187.clone.1), metadata={op_type="max" op_name="pmap(_multi_device_update_fn)/max" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %broadcast.1361.clone.1 = f32[2048,4096]{1,0} broadcast(f32[] %maximum.41.clone.1), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=150}
  %divide.186.clone.1 = f32[2048,4096]{1,0} divide(f32[2048,4096]{1,0} %multiply.1720.clone.1, f32[2048,4096]{1,0} %broadcast.1361.clone.1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=150}
  %multiply.1202.clone.1 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %broadcast.1362.clone.1, f32[2048,4096]{1,0} %divide.186.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=152}
  %subtract.276.clone.1 = f32[2048,4096]{1,0} subtract(f32[2048,4096]{1,0} %multiply.1204.clone.1, f32[2048,4096]{1,0} %multiply.1202.clone.1), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  %param_45.7 = f32[2048,4096]{1,0} parameter(45)
  %multiply.1250.clone.1 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %broadcast.1801, f32[2048,4096]{1,0} %param_45.7), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  %param_44.6 = f32[] parameter(44)
  %maximum.48.clone.1 = f32[] maximum(f32[] %param_44.6, f32[] %param_4.1041), metadata={op_type="max" op_name="pmap(_multi_device_update_fn)/max" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=122}
  %multiply.1249.clone.1 = f32[] multiply(f32[] %param_2.2170, f32[] %maximum.48.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=122}
  %broadcast.1380.clone.1 = f32[2048,4096]{1,0} broadcast(f32[] %multiply.1249.clone.1), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=152}
  %param_42.4 = f32[2048,4096]{1,0} parameter(42)
  %param_43.7 = f32[2048]{0} parameter(43)
  %multiply.1670.clone.1 = f32[2048]{0} multiply(f32[2048]{0} %param_43.7, f32[2048]{0} %broadcast.2051)
  %broadcast.2106.clone.1 = f32[2048,4096]{1,0} broadcast(f32[2048]{0} %multiply.1670.clone.1), dimensions={0}
  %multiply.1669.clone.1 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %param_42.4, f32[2048,4096]{1,0} %broadcast.2106.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  %param_41.3 = f32[4096]{0} parameter(41)
  %broadcast.2105.clone.1 = f32[2048,4096]{1,0} broadcast(f32[4096]{0} %param_41.3), dimensions={1}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  %multiply.1668.clone.1 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %multiply.1669.clone.1, f32[2048,4096]{1,0} %broadcast.2105.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  %param_40.4 = f32[] parameter(40)
  %divide.195.clone.1 = f32[] divide(f32[] %param_40.4, f32[] %param_1.2425), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %maximum.47.clone.1 = f32[] maximum(f32[] %constant_11662, f32[] %divide.195.clone.1), metadata={op_type="max" op_name="pmap(_multi_device_update_fn)/max" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %broadcast.1379.clone.1 = f32[2048,4096]{1,0} broadcast(f32[] %maximum.47.clone.1), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=150}
  %divide.194.clone.1 = f32[2048,4096]{1,0} divide(f32[2048,4096]{1,0} %multiply.1668.clone.1, f32[2048,4096]{1,0} %broadcast.1379.clone.1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=150}
  %multiply.1248.clone.1 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %broadcast.1380.clone.1, f32[2048,4096]{1,0} %divide.194.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=152}
  %subtract.279.clone.1 = f32[2048,4096]{1,0} subtract(f32[2048,4096]{1,0} %multiply.1250.clone.1, f32[2048,4096]{1,0} %multiply.1248.clone.1), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  %param_51.7 = f32[2048,4096]{1,0} parameter(51)
  %multiply.1279.clone.1 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %broadcast.1801, f32[2048,4096]{1,0} %param_51.7), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  %param_50.6 = f32[] parameter(50)
  %maximum.52.clone.1 = f32[] maximum(f32[] %param_50.6, f32[] %param_4.1041), metadata={op_type="max" op_name="pmap(_multi_device_update_fn)/max" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=122}
  %multiply.1278.clone.1 = f32[] multiply(f32[] %param_2.2170, f32[] %maximum.52.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=122}
  %broadcast.1388.clone.1 = f32[2048,4096]{1,0} broadcast(f32[] %multiply.1278.clone.1), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=152}
  %param_48.4 = f32[2048,4096]{1,0} parameter(48)
  %param_49.7 = f32[2048]{0} parameter(49)
  %multiply.1646.clone.1 = f32[2048]{0} multiply(f32[2048]{0} %param_49.7, f32[2048]{0} %broadcast.2051)
  %broadcast.2087.clone.1 = f32[2048,4096]{1,0} broadcast(f32[2048]{0} %multiply.1646.clone.1), dimensions={0}
  %multiply.1645.clone.1 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %param_48.4, f32[2048,4096]{1,0} %broadcast.2087.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  %param_47.3 = f32[4096]{0} parameter(47)
  %broadcast.2086.clone.1 = f32[2048,4096]{1,0} broadcast(f32[4096]{0} %param_47.3), dimensions={1}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  %multiply.1644.clone.1 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %multiply.1645.clone.1, f32[2048,4096]{1,0} %broadcast.2086.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  %param_46.4 = f32[] parameter(46)
  %divide.200.clone.1 = f32[] divide(f32[] %param_46.4, f32[] %param_1.2425), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %maximum.51.clone.1 = f32[] maximum(f32[] %constant_11662, f32[] %divide.200.clone.1), metadata={op_type="max" op_name="pmap(_multi_device_update_fn)/max" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %broadcast.1386.clone.1 = f32[2048,4096]{1,0} broadcast(f32[] %maximum.51.clone.1), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=150}
  %divide.199.clone.1 = f32[2048,4096]{1,0} divide(f32[2048,4096]{1,0} %multiply.1644.clone.1, f32[2048,4096]{1,0} %broadcast.1386.clone.1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=150}
  %multiply.1277.clone.1 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %broadcast.1388.clone.1, f32[2048,4096]{1,0} %divide.199.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=152}
  %subtract.281.clone.1 = f32[2048,4096]{1,0} subtract(f32[2048,4096]{1,0} %multiply.1279.clone.1, f32[2048,4096]{1,0} %multiply.1277.clone.1), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  ROOT %tuple.645 = (f32[2048,4096]{1,0}, f32[2048,4096]{1,0}, f32[2048,4096]{1,0}, f32[2048,4096]{1,0}, f32[2048,4096]{1,0}, /*index=5*/f32[2048,4096]{1,0}, f32[2048,4096]{1,0}, f32[2048,4096]{1,0}) tuple(f32[2048,4096]{1,0} %subtract.285, f32[2048,4096]{1,0} %subtract.260.clone.1, f32[2048,4096]{1,0} %subtract.262.clone.1, f32[2048,4096]{1,0} %subtract.264.clone.1, f32[2048,4096]{1,0} %subtract.266.clone.1, /*index=5*/f32[2048,4096]{1,0} %subtract.276.clone.1, f32[2048,4096]{1,0} %subtract.279.clone.1, f32[2048,4096]{1,0} %subtract.281.clone.1)
}

%fused_computation.573 (param_0.2291: f32[], param_1.2887: f32[4096], param_2.2695: f32[], param_3.2596: f32[4096], param_4.1396: f32[4096], param_5.566: f32[4096], param_6.511: f32[4096], param_7.487: f32[4096], param_8.368: f32[4096], param_9.237: f32[4096], param_10.208: f32[4096], param_11.213: f32[4096], param_12.228: f32[4096], param_13.274: f32[4096], param_14.257: f32[4096], param_15.203: f32[4096], param_16.111: f32[4096], param_17.50: f32[4096], param_18.37: f32[4096], param_19.50: f32[4096]) -> (f32[4096], f32[4096], f32[4096], f32[4096], f32[4096], /*index=5*/f32[4096], f32[4096], f32[4096], f32[4096], f32[4096], /*index=10*/f32[4096], f32[4096], f32[4096], f32[4096], f32[4096], /*index=15*/f32[4096], f32[4096], f32[4096]) {
  %param_2.2695 = f32[] parameter(2)
  %broadcast.1808.clone.1 = f32[4096]{0} broadcast(f32[] %param_2.2695), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
  %param_3.2596 = f32[4096]{0} parameter(3)
  %multiply.1340.clone.1 = f32[4096]{0} multiply(f32[4096]{0} %broadcast.1808.clone.1, f32[4096]{0} %param_3.2596), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
  %param_1.2887 = f32[4096]{0} parameter(1)
  %constant_14540_clone_1 = f32[] constant(1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/metrics.py" source_line=617}
  %subtract.624.clone.1 = f32[] subtract(f32[] %constant_14540_clone_1, f32[] %param_2.2695), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=124}
  %constant_14539_clone_1 = f32[] constant(0.00048828125)
  %multiply.1552.clone.1 = f32[] multiply(f32[] %subtract.624.clone.1, f32[] %constant_14539_clone_1)
  %broadcast.2003.clone.1 = f32[4096]{0} broadcast(f32[] %multiply.1552.clone.1), dimensions={}
  %multiply.1339.clone.1 = f32[4096]{0} multiply(f32[4096]{0} %param_1.2887, f32[4096]{0} %broadcast.2003.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
  %add.2070.clone.1 = f32[4096]{0} add(f32[4096]{0} %multiply.1340.clone.1, f32[4096]{0} %multiply.1339.clone.1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
  %param_0.2291 = f32[] parameter(0)
  %broadcast.1806 = f32[4096]{0} broadcast(f32[] %param_0.2291), dimensions={}, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
  %add.2069 = f32[4096]{0} add(f32[4096]{0} %add.2070.clone.1, f32[4096]{0} %broadcast.1806), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
  %constant_11684 = f32[] constant(-0.5), metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
  %broadcast.1807 = f32[4096]{0} broadcast(f32[] %constant_11684), dimensions={}, metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
  %power.42 = f32[4096]{0} power(f32[4096]{0} %add.2069, f32[4096]{0} %broadcast.1807), metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
  %param_5.566 = f32[4096]{0} parameter(5)
  %multiply.995.clone.1.clone.1 = f32[4096]{0} multiply(f32[4096]{0} %broadcast.1808.clone.1, f32[4096]{0} %param_5.566), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
  %param_4.1396 = f32[4096]{0} parameter(4)
  %multiply.994.clone.1.clone.1 = f32[4096]{0} multiply(f32[4096]{0} %param_4.1396, f32[4096]{0} %broadcast.2003.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
  %add.1982.clone.1.clone.1 = f32[4096]{0} add(f32[4096]{0} %multiply.995.clone.1.clone.1, f32[4096]{0} %multiply.994.clone.1.clone.1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
  %add.1981.clone.1 = f32[4096]{0} add(f32[4096]{0} %add.1982.clone.1.clone.1, f32[4096]{0} %broadcast.1806), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
  %power.4.clone.1 = f32[4096]{0} power(f32[4096]{0} %add.1981.clone.1, f32[4096]{0} %broadcast.1807), metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
  %param_7.487 = f32[4096]{0} parameter(7)
  %multiply.1022.clone.1.clone.1 = f32[4096]{0} multiply(f32[4096]{0} %broadcast.1808.clone.1, f32[4096]{0} %param_7.487), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
  %param_6.511 = f32[4096]{0} parameter(6)
  %multiply.1021.clone.1.clone.1 = f32[4096]{0} multiply(f32[4096]{0} %param_6.511, f32[4096]{0} %broadcast.2003.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
  %add.1989.clone.1.clone.1 = f32[4096]{0} add(f32[4096]{0} %multiply.1022.clone.1.clone.1, f32[4096]{0} %multiply.1021.clone.1.clone.1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
  %add.1988.clone.1 = f32[4096]{0} add(f32[4096]{0} %add.1989.clone.1.clone.1, f32[4096]{0} %broadcast.1806), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
  %power.7.clone.1 = f32[4096]{0} power(f32[4096]{0} %add.1988.clone.1, f32[4096]{0} %broadcast.1807), metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
  %param_9.237 = f32[4096]{0} parameter(9)
  %multiply.1049.clone.1.clone.1 = f32[4096]{0} multiply(f32[4096]{0} %broadcast.1808.clone.1, f32[4096]{0} %param_9.237), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
  %param_8.368 = f32[4096]{0} parameter(8)
  %multiply.1048.clone.1.clone.1 = f32[4096]{0} multiply(f32[4096]{0} %param_8.368, f32[4096]{0} %broadcast.2003.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
  %add.1996.clone.1.clone.1 = f32[4096]{0} add(f32[4096]{0} %multiply.1049.clone.1.clone.1, f32[4096]{0} %multiply.1048.clone.1.clone.1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
  %add.1995.clone.1 = f32[4096]{0} add(f32[4096]{0} %add.1996.clone.1.clone.1, f32[4096]{0} %broadcast.1806), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
  %power.10.clone.1 = f32[4096]{0} power(f32[4096]{0} %add.1995.clone.1, f32[4096]{0} %broadcast.1807), metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
  %param_11.213 = f32[4096]{0} parameter(11)
  %multiply.1076.clone.1.clone.1 = f32[4096]{0} multiply(f32[4096]{0} %broadcast.1808.clone.1, f32[4096]{0} %param_11.213), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
  %param_10.208 = f32[4096]{0} parameter(10)
  %multiply.1075.clone.1.clone.1 = f32[4096]{0} multiply(f32[4096]{0} %param_10.208, f32[4096]{0} %broadcast.2003.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
  %add.2003.clone.1.clone.1 = f32[4096]{0} add(f32[4096]{0} %multiply.1076.clone.1.clone.1, f32[4096]{0} %multiply.1075.clone.1.clone.1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
  %add.2001.clone.1 = f32[4096]{0} add(f32[4096]{0} %add.2003.clone.1.clone.1, f32[4096]{0} %broadcast.1806), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
  %power.13.clone.1 = f32[4096]{0} power(f32[4096]{0} %add.2001.clone.1, f32[4096]{0} %broadcast.1807), metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
  %param_13.274 = f32[4096]{0} parameter(13)
  %multiply.1211.clone.1.clone.1 = f32[4096]{0} multiply(f32[4096]{0} %broadcast.1808.clone.1, f32[4096]{0} %param_13.274), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
  %param_12.228 = f32[4096]{0} parameter(12)
  %multiply.1210.clone.1.clone.1 = f32[4096]{0} multiply(f32[4096]{0} %param_12.228, f32[4096]{0} %broadcast.2003.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
  %add.2037.clone.1.clone.1 = f32[4096]{0} add(f32[4096]{0} %multiply.1211.clone.1.clone.1, f32[4096]{0} %multiply.1210.clone.1.clone.1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
  %add.2036.clone.1 = f32[4096]{0} add(f32[4096]{0} %add.2037.clone.1.clone.1, f32[4096]{0} %broadcast.1806), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
  %power.28.clone.1 = f32[4096]{0} power(f32[4096]{0} %add.2036.clone.1, f32[4096]{0} %broadcast.1807), metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
  %param_15.203 = f32[4096]{0} parameter(15)
  %multiply.1257.clone.1.clone.1 = f32[4096]{0} multiply(f32[4096]{0} %broadcast.1808.clone.1, f32[4096]{0} %param_15.203), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
  %param_14.257 = f32[4096]{0} parameter(14)
  %multiply.1256.clone.1.clone.1 = f32[4096]{0} multiply(f32[4096]{0} %param_14.257, f32[4096]{0} %broadcast.2003.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
  %add.2050.clone.1.clone.1 = f32[4096]{0} add(f32[4096]{0} %multiply.1257.clone.1.clone.1, f32[4096]{0} %multiply.1256.clone.1.clone.1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
  %add.2049.clone.1 = f32[4096]{0} add(f32[4096]{0} %add.2050.clone.1.clone.1, f32[4096]{0} %broadcast.1806), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
  %power.33.clone.1 = f32[4096]{0} power(f32[4096]{0} %add.2049.clone.1, f32[4096]{0} %broadcast.1807), metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
  %param_17.50 = f32[4096]{0} parameter(17)
  %multiply.1286.clone.1.clone.1 = f32[4096]{0} multiply(f32[4096]{0} %broadcast.1808.clone.1, f32[4096]{0} %param_17.50), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
  %param_16.111 = f32[4096]{0} parameter(16)
  %multiply.1285.clone.1.clone.1 = f32[4096]{0} multiply(f32[4096]{0} %param_16.111, f32[4096]{0} %broadcast.2003.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
  %add.2057.clone.1.clone.1 = f32[4096]{0} add(f32[4096]{0} %multiply.1286.clone.1.clone.1, f32[4096]{0} %multiply.1285.clone.1.clone.1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
  %add.2056.clone.1 = f32[4096]{0} add(f32[4096]{0} %add.2057.clone.1.clone.1, f32[4096]{0} %broadcast.1806), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
  %power.36.clone.1 = f32[4096]{0} power(f32[4096]{0} %add.2056.clone.1, f32[4096]{0} %broadcast.1807), metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
  %param_19.50 = f32[4096]{0} parameter(19)
  %multiply.1313.clone.1.clone.1 = f32[4096]{0} multiply(f32[4096]{0} %broadcast.1808.clone.1, f32[4096]{0} %param_19.50), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
  %param_18.37 = f32[4096]{0} parameter(18)
  %multiply.1312.clone.1.clone.1 = f32[4096]{0} multiply(f32[4096]{0} %param_18.37, f32[4096]{0} %broadcast.2003.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
  %add.2064.clone.1.clone.1 = f32[4096]{0} add(f32[4096]{0} %multiply.1313.clone.1.clone.1, f32[4096]{0} %multiply.1312.clone.1.clone.1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
  %add.2062.clone.1 = f32[4096]{0} add(f32[4096]{0} %add.2064.clone.1.clone.1, f32[4096]{0} %broadcast.1806), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
  %power.39.clone.1 = f32[4096]{0} power(f32[4096]{0} %add.2062.clone.1, f32[4096]{0} %broadcast.1807), metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
  ROOT %tuple.669 = (f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, /*index=5*/f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, /*index=10*/f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, /*index=15*/f32[4096]{0}, f32[4096]{0}, f32[4096]{0}) tuple(f32[4096]{0} %power.42, f32[4096]{0} %add.2070.clone.1, f32[4096]{0} %power.4.clone.1, f32[4096]{0} %add.1982.clone.1.clone.1, f32[4096]{0} %power.7.clone.1, /*index=5*/f32[4096]{0} %add.1989.clone.1.clone.1, f32[4096]{0} %power.10.clone.1, f32[4096]{0} %add.1996.clone.1.clone.1, f32[4096]{0} %power.13.clone.1, f32[4096]{0} %add.2003.clone.1.clone.1, /*index=10*/f32[4096]{0} %power.28.clone.1, f32[4096]{0} %add.2037.clone.1.clone.1, f32[4096]{0} %power.33.clone.1, f32[4096]{0} %add.2050.clone.1.clone.1, f32[4096]{0} %power.36.clone.1, /*index=15*/f32[4096]{0} %add.2057.clone.1.clone.1, f32[4096]{0} %power.39.clone.1, f32[4096]{0} %add.2064.clone.1.clone.1)
}

%fused_computation.576 (param_0.1495: f32[2048], param_1.1839: f32[], param_2.1423: f32[], param_3.2608: f32[2048], param_4.1417: f32[], param_5.594: f32[2048], param_6.554: f32[], param_7.536: f32[2048], param_8.429: f32[], param_9.286: f32[2048], param_10.265: f32[], param_11.257: f32[2048], param_12.275: f32[], param_13.304: f32[2048], param_14.291: f32[], param_15.231: f32[2048], param_16.145: f32[], param_17.78: f32[2048], param_18.71: f32[]) -> (f32[2048], f32[2048], f32[2048], f32[2048], f32[2048], /*index=5*/f32[2048], f32[2048], f32[2048], f32[2048]) {
  %param_1.1839 = f32[] parameter(1)
  %constant_11678 = f32[] constant(0.00048828125)
  %multiply.1342 = f32[] multiply(f32[] %param_1.1839, f32[] %constant_11678), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=135}
  %broadcast.1406 = f32[2048]{0} broadcast(f32[] %multiply.1342), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  %param_0.1495 = f32[2048]{0} parameter(0)
  %param_2.1423 = f32[] parameter(2)
  %broadcast.1803 = f32[2048]{0} broadcast(f32[] %param_2.1423), dimensions={}, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  %add.2072 = f32[2048]{0} add(f32[2048]{0} %param_0.1495, f32[2048]{0} %broadcast.1803), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  %divide.211 = f32[2048]{0} divide(f32[2048]{0} %broadcast.1406, f32[2048]{0} %add.2072), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  %constant_11679 = f32[] constant(0.5), metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  %broadcast.1804 = f32[2048]{0} broadcast(f32[] %constant_11679), dimensions={}, metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  %power.43 = f32[2048]{0} power(f32[2048]{0} %divide.211, f32[2048]{0} %broadcast.1804), metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  %param_4.1417 = f32[] parameter(4)
  %multiply.996.clone.1 = f32[] multiply(f32[] %param_4.1417, f32[] %constant_11678), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=135}
  %broadcast.1307.clone.1 = f32[2048]{0} broadcast(f32[] %multiply.996.clone.1), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  %param_3.2608 = f32[2048]{0} parameter(3)
  %add.1983.clone.1 = f32[2048]{0} add(f32[2048]{0} %param_3.2608, f32[2048]{0} %broadcast.1803), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  %divide.148.clone.1 = f32[2048]{0} divide(f32[2048]{0} %broadcast.1307.clone.1, f32[2048]{0} %add.1983.clone.1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  %power.5.clone.1 = f32[2048]{0} power(f32[2048]{0} %divide.148.clone.1, f32[2048]{0} %broadcast.1804), metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  %param_6.554 = f32[] parameter(6)
  %multiply.1023.clone.1 = f32[] multiply(f32[] %param_6.554, f32[] %constant_11678), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=135}
  %broadcast.1314.clone.1 = f32[2048]{0} broadcast(f32[] %multiply.1023.clone.1), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  %param_5.594 = f32[2048]{0} parameter(5)
  %add.1990.clone.1 = f32[2048]{0} add(f32[2048]{0} %param_5.594, f32[2048]{0} %broadcast.1803), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  %divide.153.clone.1 = f32[2048]{0} divide(f32[2048]{0} %broadcast.1314.clone.1, f32[2048]{0} %add.1990.clone.1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  %power.8.clone.1 = f32[2048]{0} power(f32[2048]{0} %divide.153.clone.1, f32[2048]{0} %broadcast.1804), metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  %param_8.429 = f32[] parameter(8)
  %multiply.1050.clone.1 = f32[] multiply(f32[] %param_8.429, f32[] %constant_11678), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=135}
  %broadcast.1322.clone.1 = f32[2048]{0} broadcast(f32[] %multiply.1050.clone.1), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  %param_7.536 = f32[2048]{0} parameter(7)
  %add.1997.clone.1 = f32[2048]{0} add(f32[2048]{0} %param_7.536, f32[2048]{0} %broadcast.1803), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  %divide.158.clone.1 = f32[2048]{0} divide(f32[2048]{0} %broadcast.1322.clone.1, f32[2048]{0} %add.1997.clone.1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  %power.11.clone.1 = f32[2048]{0} power(f32[2048]{0} %divide.158.clone.1, f32[2048]{0} %broadcast.1804), metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  %param_10.265 = f32[] parameter(10)
  %multiply.1077.clone.1 = f32[] multiply(f32[] %param_10.265, f32[] %constant_11678), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=135}
  %broadcast.1329.clone.1 = f32[2048]{0} broadcast(f32[] %multiply.1077.clone.1), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  %param_9.286 = f32[2048]{0} parameter(9)
  %add.2004.clone.1 = f32[2048]{0} add(f32[2048]{0} %param_9.286, f32[2048]{0} %broadcast.1803), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  %divide.163.clone.1 = f32[2048]{0} divide(f32[2048]{0} %broadcast.1329.clone.1, f32[2048]{0} %add.2004.clone.1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  %power.14.clone.1 = f32[2048]{0} power(f32[2048]{0} %divide.163.clone.1, f32[2048]{0} %broadcast.1804), metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  %param_12.275 = f32[] parameter(12)
  %multiply.1212.clone.1 = f32[] multiply(f32[] %param_12.275, f32[] %constant_11678), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=135}
  %broadcast.1366.clone.1 = f32[2048]{0} broadcast(f32[] %multiply.1212.clone.1), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  %param_11.257 = f32[2048]{0} parameter(11)
  %add.2038.clone.1 = f32[2048]{0} add(f32[2048]{0} %param_11.257, f32[2048]{0} %broadcast.1803), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  %divide.188.clone.1 = f32[2048]{0} divide(f32[2048]{0} %broadcast.1366.clone.1, f32[2048]{0} %add.2038.clone.1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  %power.29.clone.1 = f32[2048]{0} power(f32[2048]{0} %divide.188.clone.1, f32[2048]{0} %broadcast.1804), metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  %param_14.291 = f32[] parameter(14)
  %multiply.1258.clone.1 = f32[] multiply(f32[] %param_14.291, f32[] %constant_11678), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=135}
  %broadcast.1383.clone.1 = f32[2048]{0} broadcast(f32[] %multiply.1258.clone.1), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  %param_13.304 = f32[2048]{0} parameter(13)
  %add.2051.clone.1 = f32[2048]{0} add(f32[2048]{0} %param_13.304, f32[2048]{0} %broadcast.1803), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  %divide.196.clone.1 = f32[2048]{0} divide(f32[2048]{0} %broadcast.1383.clone.1, f32[2048]{0} %add.2051.clone.1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  %power.34.clone.1 = f32[2048]{0} power(f32[2048]{0} %divide.196.clone.1, f32[2048]{0} %broadcast.1804), metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  %param_16.145 = f32[] parameter(16)
  %multiply.1287.clone.1 = f32[] multiply(f32[] %param_16.145, f32[] %constant_11678), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=135}
  %broadcast.1391.clone.1 = f32[2048]{0} broadcast(f32[] %multiply.1287.clone.1), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  %param_15.231 = f32[2048]{0} parameter(15)
  %add.2058.clone.1 = f32[2048]{0} add(f32[2048]{0} %param_15.231, f32[2048]{0} %broadcast.1803), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  %divide.201.clone.1 = f32[2048]{0} divide(f32[2048]{0} %broadcast.1391.clone.1, f32[2048]{0} %add.2058.clone.1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  %power.37.clone.1 = f32[2048]{0} power(f32[2048]{0} %divide.201.clone.1, f32[2048]{0} %broadcast.1804), metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  %param_18.71 = f32[] parameter(18)
  %multiply.1314.clone.1 = f32[] multiply(f32[] %param_18.71, f32[] %constant_11678), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=135}
  %broadcast.1398.clone.1 = f32[2048]{0} broadcast(f32[] %multiply.1314.clone.1), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  %param_17.78 = f32[2048]{0} parameter(17)
  %add.2065.clone.1 = f32[2048]{0} add(f32[2048]{0} %param_17.78, f32[2048]{0} %broadcast.1803), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  %divide.206.clone.1 = f32[2048]{0} divide(f32[2048]{0} %broadcast.1398.clone.1, f32[2048]{0} %add.2065.clone.1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  %power.40.clone.1 = f32[2048]{0} power(f32[2048]{0} %divide.206.clone.1, f32[2048]{0} %broadcast.1804), metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  ROOT %tuple.699 = (f32[2048]{0}, f32[2048]{0}, f32[2048]{0}, f32[2048]{0}, f32[2048]{0}, /*index=5*/f32[2048]{0}, f32[2048]{0}, f32[2048]{0}, f32[2048]{0}) tuple(f32[2048]{0} %power.43, f32[2048]{0} %power.5.clone.1, f32[2048]{0} %power.8.clone.1, f32[2048]{0} %power.11.clone.1, f32[2048]{0} %power.14.clone.1, /*index=5*/f32[2048]{0} %power.29.clone.1, f32[2048]{0} %power.34.clone.1, f32[2048]{0} %power.37.clone.1, f32[2048]{0} %power.40.clone.1)
}

%fused_computation.582 (param_0.1938: f32[], param_1.2393: f32[], param_2.2142: f32[], param_3.1962: f32[], param_4.1022: f32[], param_5.491: f32[32000,1024], param_6.437: f32[], param_7.401: f32[1024], param_8.278: f32[32000,1024], param_9.164: f32[32000]) -> f32[32000,1024] {
  %param_6.437 = f32[] parameter(6)
  %broadcast.1411 = f32[32000,1024]{1,0} broadcast(f32[] %param_6.437), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  %param_5.491 = f32[32000,1024]{1,0} parameter(5)
  %multiply.1352 = f32[32000,1024]{1,0} multiply(f32[32000,1024]{1,0} %broadcast.1411, f32[32000,1024]{1,0} %param_5.491), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  %param_2.2142 = f32[] parameter(2)
  %param_3.1962 = f32[] parameter(3)
  %param_4.1022 = f32[] parameter(4)
  %maximum.62 = f32[] maximum(f32[] %param_3.1962, f32[] %param_4.1022), metadata={op_type="max" op_name="pmap(_multi_device_update_fn)/max" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=122}
  %multiply.1351 = f32[] multiply(f32[] %param_2.2142, f32[] %maximum.62), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=122}
  %broadcast.1409 = f32[32000,1024]{1,0} broadcast(f32[] %multiply.1351), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=152}
  %param_8.278 = f32[32000,1024]{1,0} parameter(8)
  %param_9.164 = f32[32000]{0} parameter(9)
  %constant_14524 = f32[] constant(0.125)
  %broadcast.1994 = f32[32000]{0} broadcast(f32[] %constant_14524), dimensions={}
  %multiply.1538 = f32[32000]{0} multiply(f32[32000]{0} %param_9.164, f32[32000]{0} %broadcast.1994)
  %broadcast.1993 = f32[32000,1024]{1,0} broadcast(f32[32000]{0} %multiply.1538), dimensions={0}
  %multiply.1537 = f32[32000,1024]{1,0} multiply(f32[32000,1024]{1,0} %param_8.278, f32[32000,1024]{1,0} %broadcast.1993), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  %param_7.401 = f32[1024]{0} parameter(7)
  %broadcast.1992 = f32[32000,1024]{1,0} broadcast(f32[1024]{0} %param_7.401), dimensions={1}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  %multiply.1536 = f32[32000,1024]{1,0} multiply(f32[32000,1024]{1,0} %multiply.1537, f32[32000,1024]{1,0} %broadcast.1992), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  %constant_11693 = f32[] constant(1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/metrics.py" source_line=617}
  %param_0.1938 = f32[] parameter(0)
  %param_1.2393 = f32[] parameter(1)
  %divide.213 = f32[] divide(f32[] %param_0.1938, f32[] %param_1.2393), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %maximum.61 = f32[] maximum(f32[] %constant_11693, f32[] %divide.213), metadata={op_type="max" op_name="pmap(_multi_device_update_fn)/max" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %broadcast.1408 = f32[32000,1024]{1,0} broadcast(f32[] %maximum.61), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=150}
  %divide.212 = f32[32000,1024]{1,0} divide(f32[32000,1024]{1,0} %multiply.1536, f32[32000,1024]{1,0} %broadcast.1408), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=150}
  %multiply.1350 = f32[32000,1024]{1,0} multiply(f32[32000,1024]{1,0} %broadcast.1409, f32[32000,1024]{1,0} %divide.212), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=152}
  ROOT %subtract.286 = f32[32000,1024]{1,0} subtract(f32[32000,1024]{1,0} %multiply.1352, f32[32000,1024]{1,0} %multiply.1350), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
}

%fused_computation.583 (param_0.1023: f32[]) -> f32[] {
  %param_0.1023 = f32[] parameter(0)
  %constant_11703 = f32[] constant(3.05175796e-08)
  %multiply.1353 = f32[] multiply(f32[] %param_0.1023, f32[] %constant_11703), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  ROOT %sqrt.60 = f32[] sqrt(f32[] %multiply.1353), metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
}

%fused_computation.588 (param_0.1504: f32[32000], param_1.1847: f32[], param_2.1431: f32[]) -> f32[32000] {
  %param_2.1431 = f32[] parameter(2)
  %constant_11711 = f32[] constant(3.125e-05)
  %multiply.1361 = f32[] multiply(f32[] %param_2.1431, f32[] %constant_11711), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=135}
  %broadcast.1418 = f32[32000]{0} broadcast(f32[] %multiply.1361), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  %param_0.1504 = f32[32000]{0} parameter(0)
  %param_1.1847 = f32[] parameter(1)
  %broadcast.1417 = f32[32000]{0} broadcast(f32[] %param_1.1847), dimensions={}, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  %add.2076 = f32[32000]{0} add(f32[32000]{0} %param_0.1504, f32[32000]{0} %broadcast.1417), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  %divide.214 = f32[32000]{0} divide(f32[32000]{0} %broadcast.1418, f32[32000]{0} %add.2076), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  %constant_11708 = f32[] constant(0.5), metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  %broadcast.1416 = f32[32000]{0} broadcast(f32[] %constant_11708), dimensions={}, metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  ROOT %power.45 = f32[32000]{0} power(f32[32000]{0} %divide.214, f32[32000]{0} %broadcast.1416), metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
}

%fused_computation.591 (param_0.1506: f32[], param_1.1851: s32[], param_2.2706: f32[], param_3.2612: s32[]) -> (f32[], f32[]) {
  %constant_11725 = f32[] constant(1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/metrics.py" source_line=617}
  %param_1.1851 = s32[] parameter(1)
  %convert.42 = f32[] convert(s32[] %param_1.1851), metadata={op_type="convert_element_type" op_name="pmap(_multi_device_update_fn)/convert_element_type[ new_dtype=float32\n                                                    weak_type=False ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=84}
  %add.2079 = f32[] add(f32[] %convert.42, f32[] %constant_11725), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=84}
  %param_0.1506 = f32[] parameter(0)
  %negate.154 = f32[] negate(f32[] %param_0.1506), metadata={op_type="neg" op_name="pmap(_multi_device_update_fn)/neg" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=85}
  %power.46 = f32[] power(f32[] %add.2079, f32[] %negate.154), metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=85}
  %subtract.287 = f32[] subtract(f32[] %constant_11725, f32[] %power.46), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=85}
  %param_3.2612 = s32[] parameter(3)
  %constant_10591_clone_1 = s32[] constant(1), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=113}
  %compare.1405.clone.1 = pred[] compare(s32[] %param_3.2612, s32[] %constant_10591_clone_1), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=113}
  %param_2.2706 = f32[] parameter(2)
  %subtract.294.clone.1 = s32[] subtract(s32[] %param_3.2612, s32[] %param_1.1851), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=115}
  %convert.45.clone.1 = f32[] convert(s32[] %subtract.294.clone.1), metadata={op_type="convert_element_type" op_name="pmap(_multi_device_update_fn)/convert_element_type[ new_dtype=float32\n                                                    weak_type=True ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=115}
  %constant_11699_clone_1 = f32[] constant(0)
  %maximum.65.clone.1 = f32[] maximum(f32[] %convert.45.clone.1, f32[] %constant_11699_clone_1), metadata={op_type="max" op_name="pmap(_multi_device_update_fn)/max" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=115}
  %multiply.1377.clone.1 = f32[] multiply(f32[] %param_2.2706, f32[] %maximum.65.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=115}
  %convert.44.clone.1 = f32[] convert(s32[] %param_3.2612), metadata={op_type="convert_element_type" op_name="pmap(_multi_device_update_fn)/convert_element_type[ new_dtype=float32\n                                                    weak_type=True ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=116}
  %maximum.64.clone.1 = f32[] maximum(f32[] %convert.44.clone.1, f32[] %constant_11699_clone_1), metadata={op_type="max" op_name="pmap(_multi_device_update_fn)/max" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=116}
  %divide.219.clone.1 = f32[] divide(f32[] %multiply.1377.clone.1, f32[] %maximum.64.clone.1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=115}
  %select.1395.clone.1 = f32[] select(pred[] %compare.1405.clone.1, f32[] %param_2.2706, f32[] %divide.219.clone.1), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/jit(_where)/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=112}
  %subtract.293.clone.1 = f32[] subtract(f32[] %constant_11725, f32[] %select.1395.clone.1), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  ROOT %tuple.715 = (f32[], f32[]) tuple(f32[] %subtract.287, f32[] %subtract.293.clone.1)
}

%scatter_add_reducer__4.11958 (parameter.11959: f32[], parameter.11960: f32[]) -> f32[] {
  %parameter.11959 = f32[] parameter(0)
  %parameter.11960 = f32[] parameter(1)
  ROOT %add.11961 = f32[] add(f32[] %parameter.11959, f32[] %parameter.11960)
}

%fused_computation.592 (param_0.1829: f32[64,16,1024], param_1.2286: s32[16,64]) -> f32[32000,1024] {
  %constant_11728 = f32[] constant(0)
  %broadcast.1422 = f32[32000,1024]{1,0} broadcast(f32[] %constant_11728), dimensions={}, metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/broadcast_in_dim[ broadcast_dimensions=(  )\n                                                shape=(32000, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/core.py" source_line=182}
  %param_1.2286 = s32[16,64]{1,0} parameter(1)
  %copy.41 = s32[16,64]{0,1} copy(s32[16,64]{1,0} %param_1.2286)
  %bitcast.943 = s32[16,64,1]{2,0,1} bitcast(s32[16,64]{0,1} %copy.41), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/broadcast_in_dim[ broadcast_dimensions=(0, 1)\n                                                shape=(16, 64, 1) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/core.py" source_line=182}
  %param_0.1829 = f32[64,16,1024]{2,1,0} parameter(0)
  %transpose.99 = f32[16,64,1024]{2,0,1} transpose(f32[64,16,1024]{2,1,0} %param_0.1829), dimensions={1,0,2}, metadata={op_type="transpose" op_name="pmap(_multi_device_update_fn)/transpose[ permutation=(1, 0, 2) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/combinators.py" source_line=342}
  ROOT %scatter.1 = f32[32000,1024]{1,0} scatter(f32[32000,1024]{1,0} %broadcast.1422, s32[16,64,1]{2,0,1} %bitcast.943, f32[16,64,1024]{2,0,1} %transpose.99), update_window_dims={2}, inserted_window_dims={0}, scatter_dims_to_operand_dims={0}, index_vector_dim=2, to_apply=%scatter_add_reducer__4.11958, metadata={op_type="scatter-add" op_name="pmap(_multi_device_update_fn)/scatter-add[ dimension_numbers=ScatterDimensionNumbers(update_window_dims=(2,), inserted_window_dims=(0,), scatter_dims_to_operand_dims=(0,))\n                                           indices_are_sorted=False\n                                           unique_indices=False\n                                           update_consts=(  ) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/core.py" source_line=182}
}

%fused_computation.593 (param_0.1042: f32[1024,1024]) -> f32[64,16,1024] {
  %param_0.1042 = f32[1024,1024]{1,0} parameter(0)
  %reshape.1921 = f32[16,64,1024]{2,0,1} reshape(f32[1024,1024]{1,0} %param_0.1042), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=238}
  ROOT %transpose.100 = f32[64,16,1024]{2,1,0} transpose(f32[16,64,1024]{2,0,1} %reshape.1921), dimensions={1,0,2}, metadata={op_type="transpose" op_name="pmap(_multi_device_update_fn)/transpose[ permutation=(1, 0, 2) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/combinators.py" source_line=342}
}

%fused_computation.594 (param_0.1046: f32[16,1,64,64]) -> f32[16,64,64] {
  %param_0.1046 = f32[16,1,64,64]{3,2,0,1} parameter(0)
  %bitcast.726 = f32[16,64,1,64]{3,1,0,2} bitcast(f32[16,1,64,64]{3,2,0,1} %param_0.1046), metadata={op_type="transpose" op_name="pmap(_multi_device_update_fn)/transpose[ permutation=(0, 2, 1, 3) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/attention.py" source_line=281}
  %transpose.101 = f32[16,1,64,64]{2,3,0,1} transpose(f32[16,64,1,64]{3,1,0,2} %bitcast.726), dimensions={0,2,3,1}
  %bitcast.725 = f32[16,64,64]{1,2,0} bitcast(f32[16,1,64,64]{2,3,0,1} %transpose.101)
  ROOT %copy.28 = f32[16,64,64]{2,1,0} copy(f32[16,64,64]{1,2,0} %bitcast.725)
}

%fused_computation.595 (param_0.1924: f32[16,1,64,64], param_1.2379: f32[16,64], param_2.2132: f32[16,64], param_3.1959: s32[16,64], param_4.1021: f32[16,1,64,64], param_5.490: pred[16,1,64,64], param_6.436: f32[16,64,64]) -> f32[16,1,64,64] {
  %param_3.1959 = s32[16,64]{1,0} parameter(3)
  %constant_14401 = s32[] constant(0), metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %broadcast.1871 = s32[16,64]{1,0} broadcast(s32[] %constant_14401), dimensions={}, metadata={op_type="ne" op_name="pmap(_multi_device_update_fn)/ne" source_file="/usr/local/lib/python3.8/dist-packages/trax/models/rnn.py" source_line=205}
  %compare.1992 = pred[16,64]{1,0} compare(s32[16,64]{1,0} %param_3.1959, s32[16,64]{1,0} %broadcast.1871), direction=NE, metadata={op_type="ne" op_name="pmap(_multi_device_update_fn)/ne" source_file="/usr/local/lib/python3.8/dist-packages/trax/models/rnn.py" source_line=205}
  %convert.49 = f32[16,64]{1,0} convert(pred[16,64]{1,0} %compare.1992), metadata={op_type="convert_element_type" op_name="pmap(_multi_device_update_fn)/convert_element_type[ new_dtype=float32\n                                                    weak_type=False ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/models/rnn.py" source_line=209}
  %constant_11730 = f32[] constant(0)
  %broadcast.1870 = f32[16,64]{1,0} broadcast(f32[] %constant_11730), dimensions={}, metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/jit(jvp(_where))/broadcast_in_dim[ broadcast_dimensions=(  )\n                                                                 shape=(16, 1, 64, 64) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/attention.py" source_line=283}
  %compare.1990 = pred[16,64]{1,0} compare(f32[16,64]{1,0} %convert.49, f32[16,64]{1,0} %broadcast.1870), direction=NE, metadata={op_type="ne" op_name="pmap(_multi_device_update_fn)/jit(jvp(_where))/ne" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/attention.py" source_line=283}
  %broadcast.1869 = pred[16,1,64,64]{3,2,0,1} broadcast(pred[16,64]{1,0} %compare.1990), dimensions={0,3}, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/models/rnn.py" source_line=209}
  %param_5.490 = pred[16,1,64,64]{3,2,0,1} parameter(5)
  %param_6.436 = f32[16,64,64]{2,1,0} parameter(6)
  %bitcast.1023 = f32[16,1,64,64]{3,2,0,1} bitcast(f32[16,64,64]{2,1,0} %param_6.436), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/broadcast_in_dim[ broadcast_dimensions=(0, 2, 3)\n                                                shape=(16, 1, 64, 64) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/attention.py" source_line=293}
  %broadcast.1976 = f32[16,1,64,64]{3,2,0,1} broadcast(f32[] %constant_11730), dimensions={}, metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/broadcast_in_dim[ broadcast_dimensions=(  )\n                                                shape=(16, 1, 64, 64) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/attention.py" source_line=292}
  %select.2004 = f32[16,1,64,64]{3,2,0,1} select(pred[16,1,64,64]{3,2,0,1} %param_5.490, f32[16,1,64,64]{3,2,0,1} %bitcast.1023, f32[16,1,64,64]{3,2,0,1} %broadcast.1976), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/jit(transpose(jvp(_where)))/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/attention.py" source_line=290}
  %constant_14505 = f32[] constant(1.25)
  %broadcast.1974 = f32[16,1,64,64]{3,2,0,1} broadcast(f32[] %constant_14505), dimensions={}
  %multiply.1514 = f32[16,1,64,64]{3,2,0,1} multiply(f32[16,1,64,64]{3,2,0,1} %select.2004, f32[16,1,64,64]{3,2,0,1} %broadcast.1974), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/attention.py" source_line=291}
  %param_4.1021 = f32[16,1,64,64]{3,2,0,1} parameter(4)
  %multiply.1513 = f32[16,1,64,64]{3,2,0,1} multiply(f32[16,1,64,64]{3,2,0,1} %multiply.1514, f32[16,1,64,64]{3,2,0,1} %param_4.1021), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/attention.py" source_line=287}
  %param_1.2379 = f32[16,64]{1,0} parameter(1)
  %bitcast.728 = f32[16,1,64]{2,0,1} bitcast(f32[16,64]{1,0} %param_1.2379), metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(3,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/attention.py" source_line=287}
  %param_2.2132 = f32[16,64]{1,0} parameter(2)
  %bitcast.794 = f32[16,1,64]{2,0,1} bitcast(f32[16,64]{1,0} %param_2.2132), metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(3,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=94}
  %divide.215 = f32[16,1,64]{2,0,1} divide(f32[16,1,64]{2,0,1} %bitcast.728, f32[16,1,64]{2,0,1} %bitcast.794), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=94}
  %bitcast.727 = f32[16,64]{1,0} bitcast(f32[16,1,64]{2,0,1} %divide.215), metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(1, 3) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=94}
  %broadcast.1424 = f32[16,1,64,64]{3,2,0,1} broadcast(f32[16,64]{1,0} %bitcast.727), dimensions={0,2}, metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/broadcast_in_dim[ broadcast_dimensions=(0, 1, 2)\n                                                shape=(16, 1, 64, 64) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=94}
  %param_0.1924 = f32[16,1,64,64]{3,2,0,1} parameter(0)
  %multiply.1367 = f32[16,1,64,64]{3,2,0,1} multiply(f32[16,1,64,64]{3,2,0,1} %broadcast.1424, f32[16,1,64,64]{3,2,0,1} %param_0.1924), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=94}
  %add.2080 = f32[16,1,64,64]{3,2,0,1} add(f32[16,1,64,64]{3,2,0,1} %multiply.1513, f32[16,1,64,64]{3,2,0,1} %multiply.1367), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=238}
  %select.1386 = f32[16,1,64,64]{3,2,0,1} select(pred[16,1,64,64]{3,2,0,1} %broadcast.1869, f32[16,1,64,64]{3,2,0,1} %add.2080, f32[16,1,64,64]{3,2,0,1} %broadcast.1976), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/jit(transpose(jvp(_where)))/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/attention.py" source_line=283}
  %constant_10583 = f32[] constant(0.03125)
  %broadcast.1423 = f32[16,1,64,64]{3,2,0,1} broadcast(f32[] %constant_10583), dimensions={}
  ROOT %multiply.1366 = f32[16,1,64,64]{3,2,0,1} multiply(f32[16,1,64,64]{3,2,0,1} %select.1386, f32[16,1,64,64]{3,2,0,1} %broadcast.1423), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/attention.py" source_line=281}
}

%primitive_computation_add__1.9854 (parameter.9855: f32[], parameter.9856: f32[]) -> f32[] {
  %parameter.9855 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.9856 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.9857 = f32[] add(f32[] %parameter.9855, f32[] %parameter.9856), metadata={op_type="add" op_name="add"}
}

%fused_computation.596 (param_0.1922: f32[16,1,64,64], param_1.2377: pred[16,1,64,64], param_2.2130: f32[16,64,64]) -> f32[16,64] {
  %param_1.2377 = pred[16,1,64,64]{3,2,0,1} parameter(1)
  %param_2.2130 = f32[16,64,64]{2,1,0} parameter(2)
  %bitcast.1021 = f32[16,1,64,64]{3,2,0,1} bitcast(f32[16,64,64]{2,1,0} %param_2.2130), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/broadcast_in_dim[ broadcast_dimensions=(0, 2, 3)\n                                                shape=(16, 1, 64, 64) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/attention.py" source_line=293}
  %constant_11731 = f32[] constant(0)
  %broadcast.1969 = f32[16,1,64,64]{3,2,0,1} broadcast(f32[] %constant_11731), dimensions={}, metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/broadcast_in_dim[ broadcast_dimensions=(  )\n                                                shape=(16, 1, 64, 64) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/attention.py" source_line=292}
  %select.2001 = f32[16,1,64,64]{3,2,0,1} select(pred[16,1,64,64]{3,2,0,1} %param_1.2377, f32[16,1,64,64]{3,2,0,1} %bitcast.1021, f32[16,1,64,64]{3,2,0,1} %broadcast.1969), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/jit(transpose(jvp(_where)))/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/attention.py" source_line=290}
  %constant_14499 = f32[] constant(1.25)
  %broadcast.1968 = f32[16,1,64,64]{3,2,0,1} broadcast(f32[] %constant_14499), dimensions={}
  %multiply.1510 = f32[16,1,64,64]{3,2,0,1} multiply(f32[16,1,64,64]{3,2,0,1} %select.2001, f32[16,1,64,64]{3,2,0,1} %broadcast.1968), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/attention.py" source_line=291}
  %param_0.1922 = f32[16,1,64,64]{3,2,0,1} parameter(0)
  %multiply.1509 = f32[16,1,64,64]{3,2,0,1} multiply(f32[16,1,64,64]{3,2,0,1} %multiply.1510, f32[16,1,64,64]{3,2,0,1} %param_0.1922), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/attention.py" source_line=287}
  %negate.155 = f32[16,1,64,64]{3,2,0,1} negate(f32[16,1,64,64]{3,2,0,1} %multiply.1509), metadata={op_type="neg" op_name="pmap(_multi_device_update_fn)/neg" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/attention.py" source_line=287}
  %bitcast.729 = f32[16,64,64]{2,1,0} bitcast(f32[16,1,64,64]{3,2,0,1} %negate.155)
  ROOT %reduce.260 = f32[16,64]{1,0} reduce(f32[16,64,64]{2,1,0} %bitcast.729, f32[] %constant_11731), dimensions={2}, to_apply=%primitive_computation_add__1.9854
}

%fused_computation.598 (param_0.1056: f32[16,64,1024]) -> f32[16,1024,64] {
  %param_0.1056 = f32[16,64,1024]{2,1,0} parameter(0)
  %bitcast.732 = f32[16,1,64,1024]{3,2,0,1} bitcast(f32[16,64,1024]{2,1,0} %param_0.1056), metadata={op_type="transpose" op_name="pmap(_multi_device_update_fn)/transpose[ permutation=(0, 2, 1, 3) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/attention.py" source_line=360}
  %transpose.102 = f32[16,1,1024,64]{2,3,0,1} transpose(f32[16,1,64,1024]{3,2,0,1} %bitcast.732), dimensions={0,1,3,2}
  %bitcast.731 = f32[16,1024,64]{1,2,0} bitcast(f32[16,1,1024,64]{2,3,0,1} %transpose.102)
  ROOT %copy.29 = f32[16,1024,64]{2,1,0} copy(f32[16,1024,64]{1,2,0} %bitcast.731)
}

%fused_computation.599 (param_0.1919: f32[16,1024,64]) -> (f32[1024,1024], f32[1024,1024]) {
  %param_0.1919 = f32[16,1024,64]{2,1,0} parameter(0)
  %bitcast.1019 = f32[16,1,1024,64]{3,2,0,1} bitcast(f32[16,1024,64]{2,1,0} %param_0.1919), metadata={op_type="dot_general" op_name="pmap(_multi_device_update_fn)/dot_general[ dimension_numbers=(((1,), (1,)), ((0,), (0,)))\n                                           precision=None\n                                           preferred_element_type=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/attention.py" source_line=293}
  %transpose.119 = f32[16,64,1,1024]{1,3,0,2} transpose(f32[16,1,1024,64]{3,2,0,1} %bitcast.1019), dimensions={0,3,1,2}, metadata={op_type="transpose" op_name="pmap(_multi_device_update_fn)/transpose[ permutation=(0, 2, 1, 3) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/attention.py" source_line=360}
  %copy.30 = f32[16,64,1,1024]{3,1,0,2} copy(f32[16,64,1,1024]{1,3,0,2} %transpose.119), metadata={op_type="transpose" op_name="pmap(_multi_device_update_fn)/transpose[ permutation=(0, 2, 1, 3) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/attention.py" source_line=360}
  %bitcast.733 = f32[1024,1024]{1,0} bitcast(f32[16,64,1,1024]{3,1,0,2} %copy.30)
  %bitcast.704.clone.1 = f32[16,64,1024]{1,2,0} bitcast(f32[16,64,1,1024]{1,3,0,2} %transpose.119), metadata={op_type="reshape" op_name="pmap(_multi_device_update_fn)/reshape[ dimensions=None\n                                       new_sizes=(16, 64, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/attention.py" source_line=359}
  %transpose.94.clone.1 = f32[1024,16,64]{2,0,1} transpose(f32[16,64,1024]{1,2,0} %bitcast.704.clone.1), dimensions={2,0,1}
  %copy.27.clone.1 = f32[1024,16,64]{2,1,0} copy(f32[1024,16,64]{2,0,1} %transpose.94.clone.1)
  %bitcast.703.clone.1 = f32[1024,1024]{1,0} bitcast(f32[1024,16,64]{2,1,0} %copy.27.clone.1)
  ROOT %tuple.717 = (f32[1024,1024]{1,0}, f32[1024,1024]{1,0}) tuple(f32[1024,1024]{1,0} %bitcast.733, f32[1024,1024]{1,0} %bitcast.703.clone.1)
}

%fused_computation.601 (param_0.1063: f32[1024,1024]) -> f32[16,1024,64] {
  %param_0.1063 = f32[1024,1024]{1,0} parameter(0)
  %reshape.1922 = f32[16,64,1,1024]{1,3,0,2} reshape(f32[1024,1024]{1,0} %param_0.1063), metadata={op_type="transpose" op_name="pmap(_multi_device_update_fn)/transpose[ permutation=(0, 2, 1, 3) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/attention.py" source_line=293}
  %transpose.104 = f32[16,1,1024,64]{3,2,0,1} transpose(f32[16,64,1,1024]{1,3,0,2} %reshape.1922), dimensions={0,2,3,1}
  ROOT %bitcast.735 = f32[16,1024,64]{2,1,0} bitcast(f32[16,1,1024,64]{3,2,0,1} %transpose.104)
}

%fused_computation.602 (param_0.1508: f32[64,16,1024]) -> (f32[1024,1024], f32[1024,1024]) {
  %param_0.1508 = f32[64,16,1024]{2,1,0} parameter(0)
  %transpose.113 = f32[16,64,1024]{2,0,1} transpose(f32[64,16,1024]{2,1,0} %param_0.1508), dimensions={1,0,2}, metadata={op_type="transpose" op_name="pmap(_multi_device_update_fn)/transpose[ permutation=(1, 0, 2) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/combinators.py" source_line=342}
  %copy.31 = f32[16,64,1024]{2,1,0} copy(f32[16,64,1024]{2,0,1} %transpose.113), metadata={op_type="transpose" op_name="pmap(_multi_device_update_fn)/transpose[ permutation=(1, 0, 2) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/combinators.py" source_line=342}
  %bitcast.736 = f32[1024,1024]{1,0} bitcast(f32[16,64,1024]{2,1,0} %copy.31)
  %transpose.93.clone.1 = f32[1024,16,64]{0,1,2} transpose(f32[64,16,1024]{2,1,0} %param_0.1508), dimensions={2,1,0}
  %copy.26.clone.1 = f32[1024,16,64]{2,1,0} copy(f32[1024,16,64]{0,1,2} %transpose.93.clone.1)
  %bitcast.700.clone.1 = f32[1024,1024]{1,0} bitcast(f32[1024,16,64]{2,1,0} %copy.26.clone.1)
  ROOT %tuple.718 = (f32[1024,1024]{1,0}, f32[1024,1024]{1,0}) tuple(f32[1024,1024]{1,0} %bitcast.736, f32[1024,1024]{1,0} %bitcast.700.clone.1)
}

%fused_computation.603 (param_0.1067: f32[1024,1024]) -> f32[64,16,1024] {
  %param_0.1067 = f32[1024,1024]{1,0} parameter(0)
  %reshape.1923 = f32[16,64,1024]{2,0,1} reshape(f32[1024,1024]{1,0} %param_0.1067), metadata={op_type="dot_general" op_name="pmap(_multi_device_update_fn)/dot_general[ dimension_numbers=(((2,), (1,)), ((), ()))\n                                           precision=None\n                                           preferred_element_type=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/core.py" source_line=96}
  ROOT %transpose.105 = f32[64,16,1024]{2,1,0} transpose(f32[16,64,1024]{2,0,1} %reshape.1923), dimensions={1,0,2}, metadata={op_type="transpose" op_name="pmap(_multi_device_update_fn)/transpose[ permutation=(1, 0, 2) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/combinators.py" source_line=342}
}

%fused_computation.604 (param_0.1913: f32[16,64,256], param_1.2373: f32[16,64], param_2.2125: f32[16,64], param_3.1956: f32[16,64,256], param_4.1019: f32[16,64], param_5.487: f32[16,64], param_6.432: f32[16,64], param_7.397: f32[], param_8.275: s32[16,64]) -> f32[16,64,256] {
  %param_8.275 = s32[16,64]{1,0} parameter(8)
  %broadcast.1963 = s32[16,64,256]{2,1,0} broadcast(s32[16,64]{1,0} %param_8.275), dimensions={0,1}, metadata={op_type="eq" op_name="pmap(_multi_device_update_fn)/eq" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/core.py" source_line=776}
  %iota.76 = s32[16,64,256]{2,1,0} iota(), iota_dimension=2, metadata={op_type="eq" op_name="pmap(_multi_device_update_fn)/eq" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/core.py" source_line=776}
  %compare.2010 = pred[16,64,256]{2,1,0} compare(s32[16,64,256]{2,1,0} %broadcast.1963, s32[16,64,256]{2,1,0} %iota.76), direction=EQ, metadata={op_type="eq" op_name="pmap(_multi_device_update_fn)/eq" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/core.py" source_line=776}
  %constant_14493 = f32[] constant(1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/metrics.py" source_line=617}
  %param_7.397 = f32[] parameter(7)
  %constant_14491 = f32[] constant(0.125)
  %multiply.1506 = f32[] multiply(f32[] %param_7.397, f32[] %constant_14491), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/metrics.py" source_line=108}
  %divide.232 = f32[] divide(f32[] %constant_14493, f32[] %multiply.1506), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/metrics.py" source_line=617}
  %broadcast.1962 = f32[16,64]{1,0} broadcast(f32[] %divide.232), dimensions={}, metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/broadcast_in_dim[ broadcast_dimensions=(  )\n                                                shape=(16, 64) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/metrics.py" source_line=617}
  %param_6.432 = f32[16,64]{1,0} parameter(6)
  %multiply.1505 = f32[16,64]{1,0} multiply(f32[16,64]{1,0} %broadcast.1962, f32[16,64]{1,0} %param_6.432), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/metrics.py" source_line=617}
  %constant_14490 = f32[] constant(-1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/metrics.py" source_line=581}
  %broadcast.1960 = f32[16,64]{1,0} broadcast(f32[] %constant_14490), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/metrics.py" source_line=581}
  %multiply.1504 = f32[16,64]{1,0} multiply(f32[16,64]{1,0} %multiply.1505, f32[16,64]{1,0} %broadcast.1960), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/metrics.py" source_line=581}
  %broadcast.1959 = f32[16,64,256]{2,1,0} broadcast(f32[16,64]{1,0} %multiply.1504), dimensions={0,1}, metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/broadcast_in_dim[ broadcast_dimensions=(0, 1)\n                                                shape=(16, 64, 256) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/metrics.py" source_line=581}
  %constant_14489 = f32[] constant(0)
  %broadcast.1958 = f32[16,64,256]{2,1,0} broadcast(f32[] %constant_14489), dimensions={}
  %select.1999 = f32[16,64,256]{2,1,0} select(pred[16,64,256]{2,1,0} %compare.2010, f32[16,64,256]{2,1,0} %broadcast.1959, f32[16,64,256]{2,1,0} %broadcast.1958), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/metrics.py" source_line=581}
  %param_4.1019 = f32[16,64]{1,0} parameter(4)
  %param_5.487 = f32[16,64]{1,0} parameter(5)
  %divide.231 = f32[16,64]{1,0} divide(f32[16,64]{1,0} %param_4.1019, f32[16,64]{1,0} %param_5.487), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=94}
  %broadcast.1957 = f32[16,64,256]{2,1,0} broadcast(f32[16,64]{1,0} %divide.231), dimensions={0,1}, metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/broadcast_in_dim[ broadcast_dimensions=(0, 1)\n                                                shape=(16, 64, 256) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=94}
  %param_3.1956 = f32[16,64,256]{2,1,0} parameter(3)
  %multiply.1503 = f32[16,64,256]{2,1,0} multiply(f32[16,64,256]{2,1,0} %broadcast.1957, f32[16,64,256]{2,1,0} %param_3.1956), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=94}
  %add.3052 = f32[16,64,256]{2,1,0} add(f32[16,64,256]{2,1,0} %select.1999, f32[16,64,256]{2,1,0} %multiply.1503), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=238}
  %param_1.2373 = f32[16,64]{1,0} parameter(1)
  %param_2.2125 = f32[16,64]{1,0} parameter(2)
  %divide.216 = f32[16,64]{1,0} divide(f32[16,64]{1,0} %param_1.2373, f32[16,64]{1,0} %param_2.2125), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=94}
  %broadcast.1425 = f32[16,64,256]{2,1,0} broadcast(f32[16,64]{1,0} %divide.216), dimensions={0,1}, metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/broadcast_in_dim[ broadcast_dimensions=(0, 1)\n                                                shape=(16, 64, 256) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=94}
  %param_0.1913 = f32[16,64,256]{2,1,0} parameter(0)
  %multiply.1370 = f32[16,64,256]{2,1,0} multiply(f32[16,64,256]{2,1,0} %broadcast.1425, f32[16,64,256]{2,1,0} %param_0.1913), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=94}
  ROOT %add.2081 = f32[16,64,256]{2,1,0} add(f32[16,64,256]{2,1,0} %add.3052, f32[16,64,256]{2,1,0} %multiply.1370), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=238}
}

%primitive_computation_add__1.7712 (parameter.7713: f32[], parameter.7714: f32[]) -> f32[] {
  %parameter.7713 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.7714 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.7715 = f32[] add(f32[] %parameter.7713, f32[] %parameter.7714), metadata={op_type="add" op_name="add"}
}

%fused_computation.605 (param_0.1911: f32[16,64,256], param_1.2371: f32[16,64], param_2.2123: f32[16,64], param_3.1953: f32[16,64], param_4.1014: f32[], param_5.482: s32[16,64]) -> f32[16,64] {
  %param_5.482 = s32[16,64]{1,0} parameter(5)
  %broadcast.1948 = s32[16,64,256]{2,1,0} broadcast(s32[16,64]{1,0} %param_5.482), dimensions={0,1}, metadata={op_type="eq" op_name="pmap(_multi_device_update_fn)/eq" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/core.py" source_line=776}
  %iota.74 = s32[16,64,256]{2,1,0} iota(), iota_dimension=2, metadata={op_type="eq" op_name="pmap(_multi_device_update_fn)/eq" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/core.py" source_line=776}
  %compare.2008 = pred[16,64,256]{2,1,0} compare(s32[16,64,256]{2,1,0} %broadcast.1948, s32[16,64,256]{2,1,0} %iota.74), direction=EQ, metadata={op_type="eq" op_name="pmap(_multi_device_update_fn)/eq" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/core.py" source_line=776}
  %constant_14482 = f32[] constant(1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/metrics.py" source_line=617}
  %param_4.1014 = f32[] parameter(4)
  %constant_14480 = f32[] constant(0.125)
  %multiply.1498 = f32[] multiply(f32[] %param_4.1014, f32[] %constant_14480), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/metrics.py" source_line=108}
  %divide.228 = f32[] divide(f32[] %constant_14482, f32[] %multiply.1498), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/metrics.py" source_line=617}
  %broadcast.1947 = f32[16,64]{1,0} broadcast(f32[] %divide.228), dimensions={}, metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/broadcast_in_dim[ broadcast_dimensions=(  )\n                                                shape=(16, 64) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/metrics.py" source_line=617}
  %param_3.1953 = f32[16,64]{1,0} parameter(3)
  %multiply.1497 = f32[16,64]{1,0} multiply(f32[16,64]{1,0} %broadcast.1947, f32[16,64]{1,0} %param_3.1953), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/metrics.py" source_line=617}
  %constant_14479 = f32[] constant(-1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/metrics.py" source_line=581}
  %broadcast.1946 = f32[16,64]{1,0} broadcast(f32[] %constant_14479), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/metrics.py" source_line=581}
  %multiply.1496 = f32[16,64]{1,0} multiply(f32[16,64]{1,0} %multiply.1497, f32[16,64]{1,0} %broadcast.1946), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/metrics.py" source_line=581}
  %broadcast.1945 = f32[16,64,256]{2,1,0} broadcast(f32[16,64]{1,0} %multiply.1496), dimensions={0,1}, metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/broadcast_in_dim[ broadcast_dimensions=(0, 1)\n                                                shape=(16, 64, 256) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/metrics.py" source_line=581}
  %constant_11739 = f32[] constant(0)
  %broadcast.1944 = f32[16,64,256]{2,1,0} broadcast(f32[] %constant_11739), dimensions={}
  %select.1997 = f32[16,64,256]{2,1,0} select(pred[16,64,256]{2,1,0} %compare.2008, f32[16,64,256]{2,1,0} %broadcast.1945, f32[16,64,256]{2,1,0} %broadcast.1944), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/metrics.py" source_line=581}
  %param_1.2371 = f32[16,64]{1,0} parameter(1)
  %param_2.2123 = f32[16,64]{1,0} parameter(2)
  %divide.227 = f32[16,64]{1,0} divide(f32[16,64]{1,0} %param_1.2371, f32[16,64]{1,0} %param_2.2123), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=94}
  %broadcast.1943 = f32[16,64,256]{2,1,0} broadcast(f32[16,64]{1,0} %divide.227), dimensions={0,1}, metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/broadcast_in_dim[ broadcast_dimensions=(0, 1)\n                                                shape=(16, 64, 256) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=94}
  %param_0.1911 = f32[16,64,256]{2,1,0} parameter(0)
  %multiply.1495 = f32[16,64,256]{2,1,0} multiply(f32[16,64,256]{2,1,0} %broadcast.1943, f32[16,64,256]{2,1,0} %param_0.1911), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=94}
  %add.3050 = f32[16,64,256]{2,1,0} add(f32[16,64,256]{2,1,0} %select.1997, f32[16,64,256]{2,1,0} %multiply.1495), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=238}
  %negate.156 = f32[16,64,256]{2,1,0} negate(f32[16,64,256]{2,1,0} %add.3050), metadata={op_type="neg" op_name="pmap(_multi_device_update_fn)/neg" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/core.py" source_line=794}
  ROOT %reduce.261 = f32[16,64]{1,0} reduce(f32[16,64,256]{2,1,0} %negate.156, f32[] %constant_11739), dimensions={2}, to_apply=%primitive_computation_add__1.7712, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(2,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/core.py" source_line=794}
}

%fused_computation.613 (param_0.1087: f32[64,16,1024]) -> f32[1024,1024] {
  %param_0.1087 = f32[64,16,1024]{2,1,0} parameter(0)
  %transpose.106 = f32[16,64,1024]{2,0,1} transpose(f32[64,16,1024]{2,1,0} %param_0.1087), dimensions={1,0,2}, metadata={op_type="transpose" op_name="pmap(_multi_device_update_fn)/transpose[ permutation=(1, 0, 2) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/combinators.py" source_line=342}
  %copy.32 = f32[16,64,1024]{2,1,0} copy(f32[16,64,1024]{2,0,1} %transpose.106), metadata={op_type="transpose" op_name="pmap(_multi_device_update_fn)/transpose[ permutation=(1, 0, 2) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/combinators.py" source_line=342}
  ROOT %bitcast.744 = f32[1024,1024]{1,0} bitcast(f32[16,64,1024]{2,1,0} %copy.32)
}

%fused_computation.614 (param_0.1513: f32[1024], param_1.1856: f32[1024,1024], param_2.1440: f32[64,16,1024]) -> f32[64,16,1024] {
  %param_2.1440 = f32[64,16,1024]{2,1,0} parameter(2)
  %transpose.114 = f32[16,64,1024]{2,0,1} transpose(f32[64,16,1024]{2,1,0} %param_2.1440), dimensions={1,0,2}, metadata={op_type="transpose" op_name="pmap(_multi_device_update_fn)/transpose[ permutation=(1, 0, 2) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/combinators.py" source_line=342}
  %param_1.1856 = f32[1024,1024]{1,0} parameter(1)
  %reshape.1924 = f32[16,64,1024]{2,0,1} reshape(f32[1024,1024]{1,0} %param_1.1856), metadata={op_type="dot_general" op_name="pmap(_multi_device_update_fn)/dot_general[ dimension_numbers=(((2,), (0,)), ((), ()))\n                                           precision=None\n                                           preferred_element_type=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/core.py" source_line=96}
  %param_0.1513 = f32[1024]{0} parameter(0)
  %broadcast.1431 = f32[16,64,1024]{2,0,1} broadcast(f32[1024]{0} %param_0.1513), dimensions={2}, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/core.py" source_line=96}
  %add.2087 = f32[16,64,1024]{2,0,1} add(f32[16,64,1024]{2,0,1} %reshape.1924, f32[16,64,1024]{2,0,1} %broadcast.1431), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/core.py" source_line=96}
  %add.2085 = f32[16,64,1024]{2,0,1} add(f32[16,64,1024]{2,0,1} %transpose.114, f32[16,64,1024]{2,0,1} %add.2087), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/combinators.py" source_line=843}
  ROOT %transpose.107 = f32[64,16,1024]{2,1,0} transpose(f32[16,64,1024]{2,0,1} %add.2085), dimensions={1,0,2}, metadata={op_type="transpose" op_name="pmap(_multi_device_update_fn)/transpose[ permutation=(1, 0, 2) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/combinators.py" source_line=342}
}

%fused_computation.615 (param_0.1091: f32[1024], param_1.1497: f32[1024,1024]) -> f32[16,64,1024] {
  %param_1.1497 = f32[1024,1024]{1,0} parameter(1)
  %bitcast.745 = f32[16,64,1024]{2,1,0} bitcast(f32[1024,1024]{1,0} %param_1.1497), metadata={op_type="dot_general" op_name="pmap(_multi_device_update_fn)/dot_general[ dimension_numbers=(((2,), (0,)), ((), ()))\n                                           precision=None\n                                           preferred_element_type=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/core.py" source_line=96}
  %param_0.1091 = f32[1024]{0} parameter(0)
  %broadcast.1432 = f32[16,64,1024]{2,1,0} broadcast(f32[1024]{0} %param_0.1091), dimensions={2}, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/core.py" source_line=96}
  ROOT %add.2088 = f32[16,64,1024]{2,1,0} add(f32[16,64,1024]{2,1,0} %bitcast.745, f32[16,64,1024]{2,1,0} %broadcast.1432), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/core.py" source_line=96}
}

%fused_computation.616 (param_0.1093: pred[16,1,64,64], param_1.1857: f32[16,1,64,64]) -> f32[16,64,64] {
  %param_0.1093 = pred[16,1,64,64]{3,2,0,1} parameter(0)
  %param_1.1857 = f32[16,1,64,64]{3,2,0,1} parameter(1)
  %constant_11748 = f32[] constant(1.25)
  %broadcast.1818 = f32[16,1,64,64]{3,2,0,1} broadcast(f32[] %constant_11748), dimensions={}
  %multiply.1372 = f32[16,1,64,64]{3,2,0,1} multiply(f32[16,1,64,64]{3,2,0,1} %param_1.1857, f32[16,1,64,64]{3,2,0,1} %broadcast.1818), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/attention.py" source_line=291}
  %constant_11749 = f32[] constant(0)
  %broadcast.1820 = f32[16,1,64,64]{3,2,0,1} broadcast(f32[] %constant_11749), dimensions={}, metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/broadcast_in_dim[ broadcast_dimensions=(  )\n                                                shape=(16, 1, 64, 64) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/attention.py" source_line=292}
  %select.1390 = f32[16,1,64,64]{3,2,0,1} select(pred[16,1,64,64]{3,2,0,1} %param_0.1093, f32[16,1,64,64]{3,2,0,1} %multiply.1372, f32[16,1,64,64]{3,2,0,1} %broadcast.1820), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/jit(jvp(_where))/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/attention.py" source_line=290}
  ROOT %bitcast.746 = f32[16,64,64]{2,1,0} bitcast(f32[16,1,64,64]{3,2,0,1} %select.1390), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/squeeze[ dimensions=(1,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/attention.py" source_line=293}
}

%fused_computation.617 (param_0.1886: f32[16,1,64], param_1.2344: f32[16,64,64], param_2.2088: s32[16,64], param_3.1921: f32[16,64]) -> f32[16,1,64,64] {
  %param_2.2088 = s32[16,64]{1,0} parameter(2)
  %constant_14433 = s32[] constant(0), metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %broadcast.1895 = s32[16,64]{1,0} broadcast(s32[] %constant_14433), dimensions={}, metadata={op_type="ne" op_name="pmap(_multi_device_update_fn)/ne" source_file="/usr/local/lib/python3.8/dist-packages/trax/models/rnn.py" source_line=205}
  %compare.2005 = pred[16,64]{1,0} compare(s32[16,64]{1,0} %param_2.2088, s32[16,64]{1,0} %broadcast.1895), direction=NE, metadata={op_type="ne" op_name="pmap(_multi_device_update_fn)/ne" source_file="/usr/local/lib/python3.8/dist-packages/trax/models/rnn.py" source_line=205}
  %convert.55 = f32[16,64]{1,0} convert(pred[16,64]{1,0} %compare.2005), metadata={op_type="convert_element_type" op_name="pmap(_multi_device_update_fn)/convert_element_type[ new_dtype=float32\n                                                    weak_type=False ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/models/rnn.py" source_line=209}
  %constant_14432 = f32[] constant(0)
  %broadcast.1894 = f32[16,64]{1,0} broadcast(f32[] %constant_14432), dimensions={}, metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/jit(jvp(_where))/broadcast_in_dim[ broadcast_dimensions=(  )\n                                                                 shape=(16, 1, 64, 64) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/attention.py" source_line=283}
  %compare.2004 = pred[16,64]{1,0} compare(f32[16,64]{1,0} %convert.55, f32[16,64]{1,0} %broadcast.1894), direction=NE, metadata={op_type="ne" op_name="pmap(_multi_device_update_fn)/jit(jvp(_where))/ne" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/attention.py" source_line=283}
  %broadcast.1893 = pred[16,1,64,64]{3,2,0,1} broadcast(pred[16,64]{1,0} %compare.2004), dimensions={0,3}, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/models/rnn.py" source_line=209}
  %param_1.2344 = f32[16,64,64]{2,1,0} parameter(1)
  %bitcast.973 = f32[16,1,64,64]{3,2,0,1} bitcast(f32[16,64,64]{2,1,0} %param_1.2344), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/attention.py" source_line=281}
  %constant_14431 = f32[] constant(-1e+09), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/broadcast_in_dim[ broadcast_dimensions=(  )\n                                                shape=(16, 1, 64, 64) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/attention.py" source_line=285}
  %broadcast.1892 = f32[16,1,64,64]{3,2,0,1} broadcast(f32[] %constant_14431), dimensions={}, metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/broadcast_in_dim[ broadcast_dimensions=(  )\n                                                shape=(16, 1, 64, 64) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/attention.py" source_line=285}
  %select.1974 = f32[16,1,64,64]{3,2,0,1} select(pred[16,1,64,64]{3,2,0,1} %broadcast.1893, f32[16,1,64,64]{3,2,0,1} %bitcast.973, f32[16,1,64,64]{3,2,0,1} %broadcast.1892), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/jit(jvp(_where))/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/attention.py" source_line=283}
  %param_0.1886 = f32[16,1,64]{2,0,1} parameter(0)
  %bitcast.748 = f32[16,1,64,1]{2,0,3,1} bitcast(f32[16,1,64]{2,0,1} %param_0.1886), metadata={op_type="log" op_name="pmap(_multi_device_update_fn)/log" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=94}
  %param_3.1921 = f32[16,64]{1,0} parameter(3)
  %bitcast.977 = f32[16,1,64,1]{2,0,3,1} bitcast(f32[16,64]{1,0} %param_3.1921), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/broadcast_in_dim[ broadcast_dimensions=(0, 1, 2)\n                                                shape=(16, 1, 64, 1) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=94}
  %is-finite.6 = pred[16,1,64,1]{2,0,3,1} is-finite(f32[16,1,64,1]{2,0,3,1} %bitcast.977), metadata={op_type="is_finite" op_name="pmap(_multi_device_update_fn)/is_finite" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=94}
  %broadcast.1899 = f32[16,1,64,1]{2,0,3,1} broadcast(f32[] %constant_14432), dimensions={}, metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/broadcast_in_dim[ broadcast_dimensions=(  )\n                                                shape=(16, 1, 64, 1) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=94}
  %select.1978 = f32[16,1,64,1]{2,0,3,1} select(pred[16,1,64,1]{2,0,3,1} %is-finite.6, f32[16,1,64,1]{2,0,3,1} %bitcast.977, f32[16,1,64,1]{2,0,3,1} %broadcast.1899), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=94}
  %add.2089 = f32[16,1,64,1]{2,0,3,1} add(f32[16,1,64,1]{2,0,3,1} %bitcast.748, f32[16,1,64,1]{2,0,3,1} %select.1978), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=94}
  %bitcast.747 = f32[16,64]{1,0} bitcast(f32[16,1,64,1]{2,0,3,1} %add.2089)
  %broadcast.1434 = f32[16,1,64,64]{3,2,0,1} broadcast(f32[16,64]{1,0} %bitcast.747), dimensions={0,2}, metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/attention.py" source_line=287}
  %subtract.291 = f32[16,1,64,64]{3,2,0,1} subtract(f32[16,1,64,64]{3,2,0,1} %select.1974, f32[16,1,64,64]{3,2,0,1} %broadcast.1434), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/attention.py" source_line=287}
  ROOT %exponential.137 = f32[16,1,64,64]{3,2,0,1} exponential(f32[16,1,64,64]{3,2,0,1} %subtract.291), metadata={op_type="exp" op_name="pmap(_multi_device_update_fn)/exp" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/attention.py" source_line=287}
}

%primitive_computation_add__1.4493 (parameter.4494: f32[], parameter.4495: f32[]) -> f32[] {
  %parameter.4494 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.4495 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.4496 = f32[] add(f32[] %parameter.4494, f32[] %parameter.4495), metadata={op_type="add" op_name="add"}
}

%fused_computation.618 (param_0.1516: f32[16,1,64,64]) -> f32[16,64] {
  %param_0.1516 = f32[16,1,64,64]{3,2,0,1} parameter(0)
  %bitcast.749 = f32[16,64,64]{2,1,0} bitcast(f32[16,1,64,64]{3,2,0,1} %param_0.1516)
  %constant_11751 = f32[] constant(0)
  ROOT %reduce.262 = f32[16,64]{1,0} reduce(f32[16,64,64]{2,1,0} %bitcast.749, f32[] %constant_11751), dimensions={2}, to_apply=%primitive_computation_add__1.4493
}

%fused_computation.619 (param_0.1884: f32[16,64,64], param_1.2343: s32[16,64], param_2.2087: f32[16,64]) -> f32[16,1,64,64] {
  %param_1.2343 = s32[16,64]{1,0} parameter(1)
  %constant_14416 = s32[] constant(0), metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %broadcast.1879 = s32[16,64]{1,0} broadcast(s32[] %constant_14416), dimensions={}, metadata={op_type="ne" op_name="pmap(_multi_device_update_fn)/ne" source_file="/usr/local/lib/python3.8/dist-packages/trax/models/rnn.py" source_line=205}
  %compare.1996 = pred[16,64]{1,0} compare(s32[16,64]{1,0} %param_1.2343, s32[16,64]{1,0} %broadcast.1879), direction=NE, metadata={op_type="ne" op_name="pmap(_multi_device_update_fn)/ne" source_file="/usr/local/lib/python3.8/dist-packages/trax/models/rnn.py" source_line=205}
  %convert.51 = f32[16,64]{1,0} convert(pred[16,64]{1,0} %compare.1996), metadata={op_type="convert_element_type" op_name="pmap(_multi_device_update_fn)/convert_element_type[ new_dtype=float32\n                                                    weak_type=False ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/models/rnn.py" source_line=209}
  %constant_14415 = f32[] constant(0)
  %broadcast.1878 = f32[16,64]{1,0} broadcast(f32[] %constant_14415), dimensions={}, metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/jit(jvp(_where))/broadcast_in_dim[ broadcast_dimensions=(  )\n                                                                 shape=(16, 1, 64, 64) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/attention.py" source_line=283}
  %compare.1995 = pred[16,64]{1,0} compare(f32[16,64]{1,0} %convert.51, f32[16,64]{1,0} %broadcast.1878), direction=NE, metadata={op_type="ne" op_name="pmap(_multi_device_update_fn)/jit(jvp(_where))/ne" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/attention.py" source_line=283}
  %broadcast.1877 = pred[16,1,64,64]{3,2,0,1} broadcast(pred[16,64]{1,0} %compare.1995), dimensions={0,3}, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/models/rnn.py" source_line=209}
  %param_0.1884 = f32[16,64,64]{2,1,0} parameter(0)
  %bitcast.969 = f32[16,1,64,64]{3,2,0,1} bitcast(f32[16,64,64]{2,1,0} %param_0.1884), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/attention.py" source_line=281}
  %constant_14414 = f32[] constant(-1e+09), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/broadcast_in_dim[ broadcast_dimensions=(  )\n                                                shape=(16, 1, 64, 64) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/attention.py" source_line=285}
  %broadcast.1876 = f32[16,1,64,64]{3,2,0,1} broadcast(f32[] %constant_14414), dimensions={}, metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/broadcast_in_dim[ broadcast_dimensions=(  )\n                                                shape=(16, 1, 64, 64) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/attention.py" source_line=285}
  %select.1970 = f32[16,1,64,64]{3,2,0,1} select(pred[16,1,64,64]{3,2,0,1} %broadcast.1877, f32[16,1,64,64]{3,2,0,1} %bitcast.969, f32[16,1,64,64]{3,2,0,1} %broadcast.1876), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/jit(jvp(_where))/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/attention.py" source_line=283}
  %param_2.2087 = f32[16,64]{1,0} parameter(2)
  %bitcast.975 = f32[16,1,64,1]{2,0,3,1} bitcast(f32[16,64]{1,0} %param_2.2087), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/broadcast_in_dim[ broadcast_dimensions=(0, 1, 2)\n                                                shape=(16, 1, 64, 1) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=94}
  %is-finite.4 = pred[16,1,64,1]{2,0,3,1} is-finite(f32[16,1,64,1]{2,0,3,1} %bitcast.975), metadata={op_type="is_finite" op_name="pmap(_multi_device_update_fn)/is_finite" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=94}
  %broadcast.1897 = f32[16,1,64,1]{2,0,3,1} broadcast(f32[] %constant_14415), dimensions={}, metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/broadcast_in_dim[ broadcast_dimensions=(  )\n                                                shape=(16, 1, 64, 1) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=94}
  %select.1976 = f32[16,1,64,1]{2,0,3,1} select(pred[16,1,64,1]{2,0,3,1} %is-finite.4, f32[16,1,64,1]{2,0,3,1} %bitcast.975, f32[16,1,64,1]{2,0,3,1} %broadcast.1897), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=94}
  %bitcast.750 = f32[16,64]{1,0} bitcast(f32[16,1,64,1]{2,0,3,1} %select.1976)
  %broadcast.1435 = f32[16,1,64,64]{3,2,0,1} broadcast(f32[16,64]{1,0} %bitcast.750), dimensions={0,2}, metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=94}
  %subtract.292 = f32[16,1,64,64]{3,2,0,1} subtract(f32[16,1,64,64]{3,2,0,1} %select.1970, f32[16,1,64,64]{3,2,0,1} %broadcast.1435), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=94}
  ROOT %exponential.138 = f32[16,1,64,64]{3,2,0,1} exponential(f32[16,1,64,64]{3,2,0,1} %subtract.292), metadata={op_type="exp" op_name="pmap(_multi_device_update_fn)/exp" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=94}
}

%primitive_computation_max.4465 (parameter.4466: f32[], parameter.4467: f32[]) -> f32[] {
  %parameter.4466 = f32[] parameter(0), metadata={op_type="max" op_name="max"}
  %parameter.4467 = f32[] parameter(1), metadata={op_type="max" op_name="max"}
  ROOT %maximum.4468 = f32[] maximum(f32[] %parameter.4466, f32[] %parameter.4467), metadata={op_type="max" op_name="max"}
}

%fused_computation.621 (param_0.1880: f32[16,64,64], param_1.2340: s32[16,64]) -> f32[16,64] {
  %param_1.2340 = s32[16,64]{1,0} parameter(1)
  %constant_14425 = s32[] constant(0), metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %broadcast.1887 = s32[16,64]{1,0} broadcast(s32[] %constant_14425), dimensions={}, metadata={op_type="ne" op_name="pmap(_multi_device_update_fn)/ne" source_file="/usr/local/lib/python3.8/dist-packages/trax/models/rnn.py" source_line=205}
  %compare.2001 = pred[16,64]{1,0} compare(s32[16,64]{1,0} %param_1.2340, s32[16,64]{1,0} %broadcast.1887), direction=NE, metadata={op_type="ne" op_name="pmap(_multi_device_update_fn)/ne" source_file="/usr/local/lib/python3.8/dist-packages/trax/models/rnn.py" source_line=205}
  %convert.53 = f32[16,64]{1,0} convert(pred[16,64]{1,0} %compare.2001), metadata={op_type="convert_element_type" op_name="pmap(_multi_device_update_fn)/convert_element_type[ new_dtype=float32\n                                                    weak_type=False ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/models/rnn.py" source_line=209}
  %constant_14423 = f32[] constant(0)
  %broadcast.1886 = f32[16,64]{1,0} broadcast(f32[] %constant_14423), dimensions={}, metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/jit(jvp(_where))/broadcast_in_dim[ broadcast_dimensions=(  )\n                                                                 shape=(16, 1, 64, 64) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/attention.py" source_line=283}
  %compare.1999 = pred[16,64]{1,0} compare(f32[16,64]{1,0} %convert.53, f32[16,64]{1,0} %broadcast.1886), direction=NE, metadata={op_type="ne" op_name="pmap(_multi_device_update_fn)/jit(jvp(_where))/ne" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/attention.py" source_line=283}
  %broadcast.1885 = pred[16,1,64,64]{3,2,0,1} broadcast(pred[16,64]{1,0} %compare.1999), dimensions={0,3}, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/models/rnn.py" source_line=209}
  %param_0.1880 = f32[16,64,64]{2,1,0} parameter(0)
  %bitcast.971 = f32[16,1,64,64]{3,2,0,1} bitcast(f32[16,64,64]{2,1,0} %param_0.1880), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/attention.py" source_line=281}
  %constant_14422 = f32[] constant(-1e+09), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/broadcast_in_dim[ broadcast_dimensions=(  )\n                                                shape=(16, 1, 64, 64) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/attention.py" source_line=285}
  %broadcast.1884 = f32[16,1,64,64]{3,2,0,1} broadcast(f32[] %constant_14422), dimensions={}, metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/broadcast_in_dim[ broadcast_dimensions=(  )\n                                                shape=(16, 1, 64, 64) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/attention.py" source_line=285}
  %select.1972 = f32[16,1,64,64]{3,2,0,1} select(pred[16,1,64,64]{3,2,0,1} %broadcast.1885, f32[16,1,64,64]{3,2,0,1} %bitcast.971, f32[16,1,64,64]{3,2,0,1} %broadcast.1884), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/jit(jvp(_where))/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/attention.py" source_line=283}
  %bitcast.752 = f32[16,64,64]{2,1,0} bitcast(f32[16,1,64,64]{3,2,0,1} %select.1972)
  %constant_11754 = f32[] constant(-inf), metadata={op_type="reduce_max" op_name="pmap(_multi_device_update_fn)/reduce_max[ axes=(3,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=94}
  ROOT %reduce.263 = f32[16,64]{1,0} reduce(f32[16,64,64]{2,1,0} %bitcast.752, f32[] %constant_11754), dimensions={2}, to_apply=%primitive_computation_max.4465
}

%fused_computation.623 (param_0.1109: f32[16,64,1024]) -> f32[16,1024,64] {
  %param_0.1109 = f32[16,64,1024]{2,1,0} parameter(0)
  %bitcast.755 = f32[16,1,64,1024]{3,2,0,1} bitcast(f32[16,64,1024]{2,1,0} %param_0.1109), metadata={op_type="transpose" op_name="pmap(_multi_device_update_fn)/transpose[ permutation=(0, 2, 1, 3) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/attention.py" source_line=360}
  %transpose.108 = f32[16,1024,1,64]{1,3,0,2} transpose(f32[16,1,64,1024]{3,2,0,1} %bitcast.755), dimensions={0,3,1,2}
  %copy.33 = f32[16,1024,1,64]{3,1,0,2} copy(f32[16,1024,1,64]{1,3,0,2} %transpose.108)
  ROOT %bitcast.754 = f32[16,1024,64]{2,1,0} bitcast(f32[16,1024,1,64]{3,1,0,2} %copy.33)
}

%fused_computation.624 (param_0.1111: f32[1024], param_1.1519: f32[1024,1024]) -> f32[16,64,1024] {
  %param_1.1519 = f32[1024,1024]{1,0} parameter(1)
  %bitcast.756 = f32[16,64,1024]{2,1,0} bitcast(f32[1024,1024]{1,0} %param_1.1519), metadata={op_type="dot_general" op_name="pmap(_multi_device_update_fn)/dot_general[ dimension_numbers=(((2,), (0,)), ((), ()))\n                                           precision=None\n                                           preferred_element_type=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/core.py" source_line=96}
  %param_0.1111 = f32[1024]{0} parameter(0)
  %broadcast.1438 = f32[16,64,1024]{2,1,0} broadcast(f32[1024]{0} %param_0.1111), dimensions={2}, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/core.py" source_line=96}
  ROOT %add.2090 = f32[16,64,1024]{2,1,0} add(f32[16,64,1024]{2,1,0} %bitcast.756, f32[16,64,1024]{2,1,0} %broadcast.1438), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/core.py" source_line=96}
}

%fused_computation.625 (param_0.1114: f32[64,16,1024]) -> f32[1024,1024] {
  %param_0.1114 = f32[64,16,1024]{2,1,0} parameter(0)
  %transpose.109 = f32[16,64,1024]{2,0,1} transpose(f32[64,16,1024]{2,1,0} %param_0.1114), dimensions={1,0,2}, metadata={op_type="transpose" op_name="pmap(_multi_device_update_fn)/transpose[ permutation=(1, 0, 2) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/combinators.py" source_line=342}
  %copy.34 = f32[16,64,1024]{2,1,0} copy(f32[16,64,1024]{2,0,1} %transpose.109), metadata={op_type="transpose" op_name="pmap(_multi_device_update_fn)/transpose[ permutation=(1, 0, 2) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/combinators.py" source_line=342}
  ROOT %bitcast.757 = f32[1024,1024]{1,0} bitcast(f32[16,64,1024]{2,1,0} %copy.34)
}

%fused_computation.626 (param_0.1116: f32[32000,1024], param_1.2284: s32[16,64]) -> f32[64,16,1024] {
  %param_0.1116 = f32[32000,1024]{1,0} parameter(0)
  %param_1.2284 = s32[16,64]{1,0} parameter(1)
  %copy.39 = s32[16,64]{0,1} copy(s32[16,64]{1,0} %param_1.2284)
  %bitcast.941 = s32[16,64,1]{2,0,1} bitcast(s32[16,64]{0,1} %copy.39), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/broadcast_in_dim[ broadcast_dimensions=(0, 1)\n                                                shape=(16, 64, 1) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/core.py" source_line=182}
  %gather.4 = f32[16,64,1024]{2,0,1} gather(f32[32000,1024]{1,0} %param_0.1116, s32[16,64,1]{2,0,1} %bitcast.941), offset_dims={2}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=2, slice_sizes={1,1024}, metadata={op_type="gather" op_name="pmap(_multi_device_update_fn)/gather[ dimension_numbers=GatherDimensionNumbers(offset_dims=(2,), collapsed_slice_dims=(0,), start_index_map=(0,))\n                                      indices_are_sorted=False\n                                      slice_sizes=(1, 1024)\n                                      unique_indices=False ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/core.py" source_line=182}
  ROOT %transpose.110 = f32[64,16,1024]{2,1,0} transpose(f32[16,64,1024]{2,0,1} %gather.4), dimensions={1,0,2}, metadata={op_type="transpose" op_name="pmap(_multi_device_update_fn)/transpose[ permutation=(1, 0, 2) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/combinators.py" source_line=342}
}

%fused_computation.627 (param_0.1118: f32[1024], param_1.1523: f32[1024,1024]) -> f32[16,64,1024] {
  %param_1.1523 = f32[1024,1024]{1,0} parameter(1)
  %bitcast.758 = f32[16,64,1024]{2,1,0} bitcast(f32[1024,1024]{1,0} %param_1.1523), metadata={op_type="dot_general" op_name="pmap(_multi_device_update_fn)/dot_general[ dimension_numbers=(((2,), (0,)), ((), ()))\n                                           precision=None\n                                           preferred_element_type=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/core.py" source_line=96}
  %param_0.1118 = f32[1024]{0} parameter(0)
  %broadcast.1439 = f32[16,64,1024]{2,1,0} broadcast(f32[1024]{0} %param_0.1118), dimensions={2}, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/core.py" source_line=96}
  ROOT %add.2091 = f32[16,64,1024]{2,1,0} add(f32[16,64,1024]{2,1,0} %bitcast.758, f32[16,64,1024]{2,1,0} %broadcast.1439), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/core.py" source_line=96}
}

%fused_computation.628 (param_0.1519: f32[64,16,1024]) -> f32[1024,1024] {
  %param_0.1519 = f32[64,16,1024]{2,1,0} parameter(0)
  %transpose.115 = f32[16,64,1024]{2,0,1} transpose(f32[64,16,1024]{2,1,0} %param_0.1519), dimensions={1,0,2}, metadata={op_type="transpose" op_name="pmap(_multi_device_update_fn)/transpose[ permutation=(1, 0, 2) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/combinators.py" source_line=342}
  %copy.35 = f32[16,64,1024]{2,1,0} copy(f32[16,64,1024]{2,0,1} %transpose.115), metadata={op_type="transpose" op_name="pmap(_multi_device_update_fn)/transpose[ permutation=(1, 0, 2) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/combinators.py" source_line=342}
  ROOT %bitcast.759 = f32[1024,1024]{1,0} bitcast(f32[16,64,1024]{2,1,0} %copy.35)
}

%fused_computation.630 (param_0.1521: u32[32768], param_1.1858: u32[32768]) -> pred[16,1,64,64] {
  %constant_11765 = f32[] constant(0)
  %broadcast.1447 = f32[65536]{0} broadcast(f32[] %constant_11765), dimensions={}, metadata={op_type="max" op_name="pmap(_multi_device_update_fn)/jit(_bernoulli)/jit(_uniform)/max" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=86}
  %param_0.1521 = u32[32768]{0} parameter(0)
  %param_1.1858 = u32[32768]{0} parameter(1)
  %concatenate.199 = u32[65536]{0} concatenate(u32[32768]{0} %param_0.1521, u32[32768]{0} %param_1.1858), dimensions={0}, metadata={op_type="concatenate" op_name="pmap(_multi_device_update_fn)/jit(_bernoulli)/jit(_uniform)/jit(_random_bits)/jit(threefry_2x32)/concatenate[ dimension=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=86}
  %constant_10589 = u32[] constant(9), metadata={op_type="shift_right_logical" op_name="pmap(_multi_device_update_fn)/jit(_bernoulli)/jit(_uniform)/shift_right_logical" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=86}
  %broadcast.1446 = u32[65536]{0} broadcast(u32[] %constant_10589), dimensions={}, metadata={op_type="shift_right_logical" op_name="pmap(_multi_device_update_fn)/jit(_bernoulli)/jit(_uniform)/shift_right_logical" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=86}
  %shift-right-logical.19 = u32[65536]{0} shift-right-logical(u32[65536]{0} %concatenate.199, u32[65536]{0} %broadcast.1446), metadata={op_type="shift_right_logical" op_name="pmap(_multi_device_update_fn)/jit(_bernoulli)/jit(_uniform)/shift_right_logical" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=86}
  %constant_10587 = u32[] constant(1065353216), metadata={op_type="or" op_name="pmap(_multi_device_update_fn)/jit(_bernoulli)/jit(_uniform)/or" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=86}
  %broadcast.1445 = u32[65536]{0} broadcast(u32[] %constant_10587), dimensions={}, metadata={op_type="or" op_name="pmap(_multi_device_update_fn)/jit(_bernoulli)/jit(_uniform)/or" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=86}
  %or.3 = u32[65536]{0} or(u32[65536]{0} %shift-right-logical.19, u32[65536]{0} %broadcast.1445), metadata={op_type="or" op_name="pmap(_multi_device_update_fn)/jit(_bernoulli)/jit(_uniform)/or" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=86}
  %bitcast-convert.3 = f32[65536]{0} bitcast-convert(u32[65536]{0} %or.3), metadata={op_type="bitcast_convert_type" op_name="pmap(_multi_device_update_fn)/jit(_bernoulli)/jit(_uniform)/bitcast_convert_type[ new_dtype=float32 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=86}
  %constant_11762 = f32[] constant(-1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/metrics.py" source_line=581}
  %broadcast.1444 = f32[65536]{0} broadcast(f32[] %constant_11762), dimensions={}
  %add.2092 = f32[65536]{0} add(f32[65536]{0} %bitcast-convert.3, f32[65536]{0} %broadcast.1444), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/jit(_bernoulli)/jit(_uniform)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=86}
  %maximum.63 = f32[65536]{0} maximum(f32[65536]{0} %broadcast.1447, f32[65536]{0} %add.2092), metadata={op_type="max" op_name="pmap(_multi_device_update_fn)/jit(_bernoulli)/jit(_uniform)/max" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=86}
  %constant_10586 = f32[] constant(0.8), metadata={op_type="xla_call" op_name="pmap(_multi_device_update_fn)/xla_call[ backend=None\n                                        device=None\n                                        donated_invars=(False, False)\n                                        inline=False\n                                        name=_bernoulli ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=86}
  %broadcast.1443 = f32[65536]{0} broadcast(f32[] %constant_10586), dimensions={}, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/jit(_bernoulli)/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=86}
  %compare.1402 = pred[65536]{0} compare(f32[65536]{0} %maximum.63, f32[65536]{0} %broadcast.1443), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/jit(_bernoulli)/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=86}
  ROOT %bitcast.760 = pred[16,1,64,64]{3,2,0,1} bitcast(pred[65536]{0} %compare.1402), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/jit(_bernoulli)/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=86}
}

%fused_computation.632 (param_0.1868: u32[3], param_1.2317: u32[3]) -> (u32[32768], u32[32768]) {
  %param_0.1868 = u32[3]{0} parameter(0)
  %param_1.2317 = u32[3]{0} parameter(1)
  %concatenate.234 = u32[6]{0} concatenate(u32[3]{0} %param_0.1868, u32[3]{0} %param_1.2317), dimensions={0}, metadata={op_type="concatenate" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/concatenate[ dimension=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %bitcast.963 = u32[3,2]{1,0} bitcast(u32[6]{0} %concatenate.234), metadata={op_type="reshape" op_name="pmap(_multi_device_update_fn)/jit(_split)/reshape[ dimensions=None\n                                                   new_sizes=(3, 2) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %slice.901 = u32[1,1]{1,0} slice(u32[3,2]{1,0} %bitcast.963), slice={[1:2], [0:1]}
  %bitcast.763 = u32[] bitcast(u32[1,1]{1,0} %slice.901), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/jit(_bernoulli)/jit(_uniform)/jit(_random_bits)/jit(threefry_2x32)/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=86}
  %broadcast.1449 = u32[32768]{0} broadcast(u32[] %bitcast.763), dimensions={}, metadata={op_type="threefry2x32" op_name="pmap(_multi_device_update_fn)/jit(_bernoulli)/jit(_uniform)/jit(_random_bits)/jit(threefry_2x32)/threefry2x32" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=86}
  %slice.900.clone.1 = u32[1,2]{1,0} slice(u32[3,2]{1,0} %bitcast.963), slice={[1:2], [0:2]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/slice[ limit_indices=(2, 2)\n                                     start_indices=(1, 0)\n                                     strides=(1, 1) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/combinators.py" source_line=86}
  %bitcast.762.clone.1 = u32[2]{0} bitcast(u32[1,2]{1,0} %slice.900.clone.1), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/combinators.py" source_line=86}
  %slice.899.clone.1 = u32[1]{0} slice(u32[2]{0} %bitcast.762.clone.1), slice={[1:2]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/jit(_bernoulli)/jit(_uniform)/jit(_random_bits)/jit(threefry_2x32)/slice[ limit_indices=(2,)\n                                                                                                        start_indices=(1,)\n                                                                                                        strides=(1,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=86}
  %bitcast.761.clone.1 = u32[] bitcast(u32[1]{0} %slice.899.clone.1), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/jit(_bernoulli)/jit(_uniform)/jit(_random_bits)/jit(threefry_2x32)/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=86}
  %broadcast.1448.clone.1 = u32[32768]{0} broadcast(u32[] %bitcast.761.clone.1), dimensions={}, metadata={op_type="threefry2x32" op_name="pmap(_multi_device_update_fn)/jit(_bernoulli)/jit(_uniform)/jit(_random_bits)/jit(threefry_2x32)/threefry2x32" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=86}
  ROOT %tuple.722 = (u32[32768]{0}, u32[32768]{0}) tuple(u32[32768]{0} %broadcast.1449, u32[32768]{0} %broadcast.1448.clone.1)
}

%fused_computation.635 (param_0.1862: u32[3], param_1.2313: u32[3]) -> (u32[3], u32[3]) {
  %param_0.1862 = u32[3]{0} parameter(0)
  %param_1.2313 = u32[3]{0} parameter(1)
  %concatenate.230 = u32[6]{0} concatenate(u32[3]{0} %param_0.1862, u32[3]{0} %param_1.2313), dimensions={0}, metadata={op_type="concatenate" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/concatenate[ dimension=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %bitcast.959 = u32[3,2]{1,0} bitcast(u32[6]{0} %concatenate.230), metadata={op_type="reshape" op_name="pmap(_multi_device_update_fn)/jit(_split)/reshape[ dimensions=None\n                                                   new_sizes=(3, 2) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %slice.904 = u32[1,1]{1,0} slice(u32[3,2]{1,0} %bitcast.959), slice={[1:2], [0:1]}
  %bitcast.767 = u32[] bitcast(u32[1,1]{1,0} %slice.904), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %broadcast.1451 = u32[3]{0} broadcast(u32[] %bitcast.767), dimensions={}, metadata={op_type="threefry2x32" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/threefry2x32" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %slice.903.clone.1 = u32[1,2]{1,0} slice(u32[3,2]{1,0} %bitcast.959), slice={[1:2], [0:2]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/slice[ limit_indices=(2, 2)\n                                     start_indices=(1, 0)\n                                     strides=(1, 1) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/combinators.py" source_line=86}
  %bitcast.766.clone.1 = u32[2]{0} bitcast(u32[1,2]{1,0} %slice.903.clone.1), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/combinators.py" source_line=86}
  %slice.902.clone.1 = u32[1]{0} slice(u32[2]{0} %bitcast.766.clone.1), slice={[1:2]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/slice[ limit_indices=(2,)\n                                                                    start_indices=(1,)\n                                                                    strides=(1,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %bitcast.765.clone.1 = u32[] bitcast(u32[1]{0} %slice.902.clone.1), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %broadcast.1450.clone.1 = u32[3]{0} broadcast(u32[] %bitcast.765.clone.1), dimensions={}, metadata={op_type="threefry2x32" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/threefry2x32" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  ROOT %tuple.723 = (u32[3]{0}, u32[3]{0}) tuple(u32[3]{0} %broadcast.1451, u32[3]{0} %broadcast.1450.clone.1)
}

%fused_computation.638 (param_0.1856: u32[2], param_1.2309: u32[2]) -> (u32[3], u32[3]) {
  %param_0.1856 = u32[2]{0} parameter(0)
  %param_1.2309 = u32[2]{0} parameter(1)
  %concatenate.226 = u32[4]{0} concatenate(u32[2]{0} %param_0.1856, u32[2]{0} %param_1.2309), dimensions={0}, metadata={op_type="concatenate" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/concatenate[ dimension=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %bitcast.955 = u32[2,2]{1,0} bitcast(u32[4]{0} %concatenate.226), metadata={op_type="reshape" op_name="pmap(_multi_device_update_fn)/jit(_split)/reshape[ dimensions=None\n                                                   new_sizes=(2, 2) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %slice.907 = u32[1,1]{1,0} slice(u32[2,2]{1,0} %bitcast.955), slice={[1:2], [0:1]}
  %bitcast.771 = u32[] bitcast(u32[1,1]{1,0} %slice.907), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %broadcast.1453 = u32[3]{0} broadcast(u32[] %bitcast.771), dimensions={}, metadata={op_type="threefry2x32" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/threefry2x32" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %slice.906.clone.1 = u32[1,2]{1,0} slice(u32[2,2]{1,0} %bitcast.955), slice={[1:2], [0:2]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/slice[ limit_indices=(2, 2)\n                                     start_indices=(1, 0)\n                                     strides=(1, 1) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/combinators.py" source_line=209}
  %bitcast.770.clone.1 = u32[2]{0} bitcast(u32[1,2]{1,0} %slice.906.clone.1), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/combinators.py" source_line=209}
  %slice.905.clone.1 = u32[1]{0} slice(u32[2]{0} %bitcast.770.clone.1), slice={[1:2]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/slice[ limit_indices=(2,)\n                                                                    start_indices=(1,)\n                                                                    strides=(1,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %bitcast.769.clone.1 = u32[] bitcast(u32[1]{0} %slice.905.clone.1), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %broadcast.1452.clone.1 = u32[3]{0} broadcast(u32[] %bitcast.769.clone.1), dimensions={}, metadata={op_type="threefry2x32" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/threefry2x32" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  ROOT %tuple.724 = (u32[3]{0}, u32[3]{0}) tuple(u32[3]{0} %broadcast.1453, u32[3]{0} %broadcast.1452.clone.1)
}

%fused_computation.641 (param_0.1850: u32[2], param_1.2305: u32[2]) -> (u32[2], u32[2]) {
  %param_0.1850 = u32[2]{0} parameter(0)
  %param_1.2305 = u32[2]{0} parameter(1)
  %concatenate.221 = u32[4]{0} concatenate(u32[2]{0} %param_0.1850, u32[2]{0} %param_1.2305), dimensions={0}, metadata={op_type="concatenate" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/concatenate[ dimension=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %bitcast.951 = u32[2,2]{1,0} bitcast(u32[4]{0} %concatenate.221), metadata={op_type="reshape" op_name="pmap(_multi_device_update_fn)/jit(_split)/reshape[ dimensions=None\n                                                   new_sizes=(2, 2) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %slice.910 = u32[1,1]{1,0} slice(u32[2,2]{1,0} %bitcast.951), slice={[1:2], [0:1]}
  %bitcast.775 = u32[] bitcast(u32[1,1]{1,0} %slice.910), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %broadcast.1455 = u32[2]{0} broadcast(u32[] %bitcast.775), dimensions={}, metadata={op_type="threefry2x32" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/threefry2x32" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %slice.909.clone.1 = u32[1,2]{1,0} slice(u32[2,2]{1,0} %bitcast.951), slice={[1:2], [0:2]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/slice[ limit_indices=(2, 2)\n                                     start_indices=(1, 0)\n                                     strides=(1, 1) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/combinators.py" source_line=86}
  %bitcast.774.clone.1 = u32[2]{0} bitcast(u32[1,2]{1,0} %slice.909.clone.1), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/combinators.py" source_line=86}
  %slice.908.clone.1 = u32[1]{0} slice(u32[2]{0} %bitcast.774.clone.1), slice={[1:2]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/slice[ limit_indices=(2,)\n                                                                    start_indices=(1,)\n                                                                    strides=(1,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %bitcast.773.clone.1 = u32[] bitcast(u32[1]{0} %slice.908.clone.1), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %broadcast.1454.clone.1 = u32[2]{0} broadcast(u32[] %bitcast.773.clone.1), dimensions={}, metadata={op_type="threefry2x32" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/threefry2x32" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  ROOT %tuple.725 = (u32[2]{0}, u32[2]{0}) tuple(u32[2]{0} %broadcast.1455, u32[2]{0} %broadcast.1454.clone.1)
}

%fused_computation.644 (param_0.1173: u32[2]) -> (u32[2], u32[2]) {
  %param_0.1173 = u32[2]{0} parameter(0)
  %slice.912 = u32[1]{0} slice(u32[2]{0} %param_0.1173), slice={[0:1]}
  %bitcast.778 = u32[] bitcast(u32[1]{0} %slice.912), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %broadcast.1458 = u32[2]{0} broadcast(u32[] %bitcast.778), dimensions={}, metadata={op_type="threefry2x32" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/threefry2x32" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %slice.911.clone.1 = u32[1]{0} slice(u32[2]{0} %param_0.1173), slice={[1:2]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/slice[ limit_indices=(2,)\n                                                                    start_indices=(1,)\n                                                                    strides=(1,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %bitcast.777.clone.1 = u32[] bitcast(u32[1]{0} %slice.911.clone.1), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %broadcast.1457.clone.1 = u32[2]{0} broadcast(u32[] %bitcast.777.clone.1), dimensions={}, metadata={op_type="threefry2x32" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/threefry2x32" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  ROOT %tuple.726 = (u32[2]{0}, u32[2]{0}) tuple(u32[2]{0} %broadcast.1458, u32[2]{0} %broadcast.1457.clone.1)
}

%fused_computation.646 (param_0.1844: u32[11], param_1.2301: u32[11]) -> (u32[2], u32[2]) {
  %param_0.1844 = u32[11]{0} parameter(0)
  %param_1.2301 = u32[11]{0} parameter(1)
  %concatenate.217 = u32[22]{0} concatenate(u32[11]{0} %param_0.1844, u32[11]{0} %param_1.2301), dimensions={0}, metadata={op_type="concatenate" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/concatenate[ dimension=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %bitcast.947 = u32[11,2]{1,0} bitcast(u32[22]{0} %concatenate.217), metadata={op_type="reshape" op_name="pmap(_multi_device_update_fn)/jit(_split)/reshape[ dimensions=None\n                                                   new_sizes=(11, 2) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %slice.915 = u32[1,1]{1,0} slice(u32[11,2]{1,0} %bitcast.947), slice={[3:4], [0:1]}
  %bitcast.781 = u32[] bitcast(u32[1,1]{1,0} %slice.915), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %broadcast.1460 = u32[2]{0} broadcast(u32[] %bitcast.781), dimensions={}, metadata={op_type="threefry2x32" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/threefry2x32" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %slice.914.clone.1 = u32[1,2]{1,0} slice(u32[11,2]{1,0} %bitcast.947), slice={[3:4], [0:2]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/slice[ limit_indices=(4, 2)\n                                     start_indices=(3, 0)\n                                     strides=(1, 1) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/combinators.py" source_line=86}
  %bitcast.780.clone.1 = u32[2]{0} bitcast(u32[1,2]{1,0} %slice.914.clone.1), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/combinators.py" source_line=86}
  %slice.913.clone.1 = u32[1]{0} slice(u32[2]{0} %bitcast.780.clone.1), slice={[1:2]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/slice[ limit_indices=(2,)\n                                                                    start_indices=(1,)\n                                                                    strides=(1,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %bitcast.779.clone.1 = u32[] bitcast(u32[1]{0} %slice.913.clone.1), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %broadcast.1459.clone.1 = u32[2]{0} broadcast(u32[] %bitcast.779.clone.1), dimensions={}, metadata={op_type="threefry2x32" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/threefry2x32" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  ROOT %tuple.727 = (u32[2]{0}, u32[2]{0}) tuple(u32[2]{0} %broadcast.1460, u32[2]{0} %broadcast.1459.clone.1)
}

%fused_computation.649 (param_0.1189: u32[2]) -> (u32[11], u32[11]) {
  %param_0.1189 = u32[2]{0} parameter(0)
  %slice.917 = u32[1]{0} slice(u32[2]{0} %param_0.1189), slice={[0:1]}
  %bitcast.784 = u32[] bitcast(u32[1]{0} %slice.917), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %broadcast.1462 = u32[11]{0} broadcast(u32[] %bitcast.784), dimensions={}, metadata={op_type="threefry2x32" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/threefry2x32" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %slice.916.clone.1 = u32[1]{0} slice(u32[2]{0} %param_0.1189), slice={[1:2]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/slice[ limit_indices=(2,)\n                                                                    start_indices=(1,)\n                                                                    strides=(1,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %bitcast.783.clone.1 = u32[] bitcast(u32[1]{0} %slice.916.clone.1), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %broadcast.1461.clone.1 = u32[11]{0} broadcast(u32[] %bitcast.783.clone.1), dimensions={}, metadata={op_type="threefry2x32" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/threefry2x32" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  ROOT %tuple.728 = (u32[11]{0}, u32[11]{0}) tuple(u32[11]{0} %broadcast.1462, u32[11]{0} %broadcast.1461.clone.1)
}

%fused_computation.650 (param_0.1192: u32[2]) -> (u32[2], u32[2]) {
  %param_0.1192 = u32[2]{0} parameter(0)
  %slice.918 = u32[1]{0} slice(u32[2]{0} %param_0.1192), slice={[1:2]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/slice[ limit_indices=(2,)\n                                                                    start_indices=(1,)\n                                                                    strides=(1,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %bitcast.785 = u32[] bitcast(u32[1]{0} %slice.918), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %broadcast.1463 = u32[2]{0} broadcast(u32[] %bitcast.785), dimensions={}, metadata={op_type="threefry2x32" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/threefry2x32" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %slice.919.clone.1 = u32[1]{0} slice(u32[2]{0} %param_0.1192), slice={[0:1]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/slice[ limit_indices=(1,)\n                                                                    start_indices=(0,)\n                                                                    strides=(1,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %bitcast.786.clone.1 = u32[] bitcast(u32[1]{0} %slice.919.clone.1), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %broadcast.1464.clone.1 = u32[2]{0} broadcast(u32[] %bitcast.786.clone.1), dimensions={}, metadata={op_type="threefry2x32" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/threefry2x32" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  ROOT %tuple.729 = (u32[2]{0}, u32[2]{0}) tuple(u32[2]{0} %broadcast.1463, u32[2]{0} %broadcast.1464.clone.1)
}

%fused_computation.652 (param_0.1197: f32[256,1024], param_1.2326: s32[16,64]) -> f32[64,16,1024] {
  %param_0.1197 = f32[256,1024]{1,0} parameter(0)
  %param_1.2326 = s32[16,64]{1,0} parameter(1)
  %constant_14405 = s32[] constant(0), metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %pad.178 = s32[16,65]{1,0} pad(s32[16,64]{1,0} %param_1.2326, s32[] %constant_14405), padding=0_0x1_0, metadata={op_type="pad" op_name="pmap(_multi_device_update_fn)/jit(_pad)/pad[ padding_config=((0, 0, 0), (1, 0, 0)) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/attention.py" source_line=741}
  %slice.992 = s32[16,64]{1,0} slice(s32[16,65]{1,0} %pad.178), slice={[0:16], [0:64]}
  %copy.43 = s32[16,64]{0,1} copy(s32[16,64]{1,0} %slice.992)
  %bitcast.965 = s32[16,64,1]{2,0,1} bitcast(s32[16,64]{0,1} %copy.43), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/broadcast_in_dim[ broadcast_dimensions=(0, 1)\n                                                shape=(16, 64, 1) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/core.py" source_line=182}
  %gather.5 = f32[16,64,1024]{2,0,1} gather(f32[256,1024]{1,0} %param_0.1197, s32[16,64,1]{2,0,1} %bitcast.965), offset_dims={2}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=2, slice_sizes={1,1024}, metadata={op_type="gather" op_name="pmap(_multi_device_update_fn)/gather[ dimension_numbers=GatherDimensionNumbers(offset_dims=(2,), collapsed_slice_dims=(0,), start_index_map=(0,))\n                                      indices_are_sorted=False\n                                      slice_sizes=(1, 1024)\n                                      unique_indices=False ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/core.py" source_line=182}
  ROOT %transpose.111 = f32[64,16,1024]{2,1,0} transpose(f32[16,64,1024]{2,0,1} %gather.5), dimensions={1,0,2}, metadata={op_type="transpose" op_name="pmap(_multi_device_update_fn)/transpose[ permutation=(1, 0, 2) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/combinators.py" source_line=342}
}

%primitive_computation_add__1.7693 (parameter.7694: f32[], parameter.7695: f32[]) -> f32[] {
  %parameter.7694 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.7695 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.7696 = f32[] add(f32[] %parameter.7694, f32[] %parameter.7695), metadata={op_type="add" op_name="add"}
}

%fused_computation.654 (param_0.1836: f32[16,64], param_1.2295: f32[], param_2.2061: s32[16,64]) -> f32[16,64] {
  %param_2.2061 = s32[16,64]{1,0} parameter(2)
  %broadcast.1843 = s32[16,64,256]{2,1,0} broadcast(s32[16,64]{1,0} %param_2.2061), dimensions={0,1}, metadata={op_type="eq" op_name="pmap(_multi_device_update_fn)/eq" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/core.py" source_line=776}
  %iota.70 = s32[16,64,256]{2,1,0} iota(), iota_dimension=2, metadata={op_type="eq" op_name="pmap(_multi_device_update_fn)/eq" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/core.py" source_line=776}
  %compare.1980 = pred[16,64,256]{2,1,0} compare(s32[16,64,256]{2,1,0} %broadcast.1843, s32[16,64,256]{2,1,0} %iota.70), direction=EQ, metadata={op_type="eq" op_name="pmap(_multi_device_update_fn)/eq" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/core.py" source_line=776}
  %constant_14365 = f32[] constant(1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/metrics.py" source_line=617}
  %param_1.2295 = f32[] parameter(1)
  %constant_14364 = f32[] constant(0.125)
  %multiply.1484 = f32[] multiply(f32[] %param_1.2295, f32[] %constant_14364), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/metrics.py" source_line=108}
  %divide.222 = f32[] divide(f32[] %constant_14365, f32[] %multiply.1484), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/metrics.py" source_line=617}
  %broadcast.1841 = f32[16,64]{1,0} broadcast(f32[] %divide.222), dimensions={}, metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/broadcast_in_dim[ broadcast_dimensions=(  )\n                                                shape=(16, 64) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/metrics.py" source_line=617}
  %param_0.1836 = f32[16,64]{1,0} parameter(0)
  %multiply.1483 = f32[16,64]{1,0} multiply(f32[16,64]{1,0} %broadcast.1841, f32[16,64]{1,0} %param_0.1836), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/metrics.py" source_line=617}
  %constant_14363 = f32[] constant(-1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/metrics.py" source_line=581}
  %broadcast.1839 = f32[16,64]{1,0} broadcast(f32[] %constant_14363), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/metrics.py" source_line=581}
  %multiply.1482 = f32[16,64]{1,0} multiply(f32[16,64]{1,0} %multiply.1483, f32[16,64]{1,0} %broadcast.1839), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/metrics.py" source_line=581}
  %broadcast.1837 = f32[16,64,256]{2,1,0} broadcast(f32[16,64]{1,0} %multiply.1482), dimensions={0,1}, metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/broadcast_in_dim[ broadcast_dimensions=(0, 1)\n                                                shape=(16, 64, 256) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/metrics.py" source_line=581}
  %constant_11742 = f32[] constant(0)
  %broadcast.1835 = f32[16,64,256]{2,1,0} broadcast(f32[] %constant_11742), dimensions={}
  %select.1966 = f32[16,64,256]{2,1,0} select(pred[16,64,256]{2,1,0} %compare.1980, f32[16,64,256]{2,1,0} %broadcast.1837, f32[16,64,256]{2,1,0} %broadcast.1835), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/metrics.py" source_line=581}
  %negate.157 = f32[16,64,256]{2,1,0} negate(f32[16,64,256]{2,1,0} %select.1966), metadata={op_type="neg" op_name="pmap(_multi_device_update_fn)/neg" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/core.py" source_line=794}
  ROOT %reduce.264 = f32[16,64]{1,0} reduce(f32[16,64,256]{2,1,0} %negate.157, f32[] %constant_11742), dimensions={2}, to_apply=%primitive_computation_add__1.7693, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(2,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/core.py" source_line=794}
}

%primitive_computation_add__1.7667 (parameter.7668: f32[], parameter.7669: f32[]) -> f32[] {
  %parameter.7668 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.7669 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.7670 = f32[] add(f32[] %parameter.7668, f32[] %parameter.7669), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.7661 (parameter.7662: f32[], parameter.7663: f32[]) -> f32[] {
  %parameter.7662 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.7663 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.7664 = f32[] add(f32[] %parameter.7662, f32[] %parameter.7663), metadata={op_type="add" op_name="add"}
}

%fused_computation.656 (param_0.1538: f32[16,64], param_1.2911: f32[16,64]) -> (f32[], f32[]) {
  %param_0.1538 = f32[16,64]{1,0} parameter(0)
  %bitcast.788 = f32[1024]{0} bitcast(f32[16,64]{1,0} %param_0.1538)
  %constant_11776 = f32[] constant(0)
  %reduce.265 = f32[] reduce(f32[1024]{0} %bitcast.788, f32[] %constant_11776), dimensions={0}, to_apply=%primitive_computation_add__1.7667, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0, 1) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/metrics.py" source_line=102}
  %param_1.2911 = f32[16,64]{1,0} parameter(1)
  %constant_11103_clone_1 = f32[] constant(-1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/metrics.py" source_line=581}
  %broadcast.1543.clone.1 = f32[16,64]{1,0} broadcast(f32[] %constant_11103_clone_1), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/metrics.py" source_line=581}
  %multiply.948.clone.1 = f32[16,64]{1,0} multiply(f32[16,64]{1,0} %param_1.2911, f32[16,64]{1,0} %broadcast.1543.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/metrics.py" source_line=581}
  %multiply.947.clone.1 = f32[16,64]{1,0} multiply(f32[16,64]{1,0} %multiply.948.clone.1, f32[16,64]{1,0} %param_0.1538), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/metrics.py" source_line=617}
  %bitcast.668.clone.1 = f32[1024]{0} bitcast(f32[16,64]{1,0} %multiply.947.clone.1)
  %reduce.182.clone.1 = f32[] reduce(f32[1024]{0} %bitcast.668.clone.1, f32[] %constant_11776), dimensions={0}, to_apply=%primitive_computation_add__1.7661, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0, 1) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/metrics.py" source_line=617}
  ROOT %tuple.719 = (f32[], f32[]) tuple(f32[] %reduce.265, f32[] %reduce.182.clone.1)
}

%primitive_computation_add__1.12995 (parameter.12996: f32[], parameter.12997: f32[]) -> f32[] {
  %parameter.12996 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.12997 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.12998 = f32[] add(f32[] %parameter.12996, f32[] %parameter.12997), metadata={op_type="add" op_name="add"}
}

%fused_computation.660 (param_0.1502: f32[32000,1024]) -> f32[] {
  %param_0.1502 = f32[32000,1024]{1,0} parameter(0)
  %multiply.1376 = f32[32000,1024]{1,0} multiply(f32[32000,1024]{1,0} %param_0.1502, f32[32000,1024]{1,0} %param_0.1502), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %bitcast.790 = f32[32768000]{0} bitcast(f32[32000,1024]{1,0} %multiply.1376)
  %constant_11702 = f32[] constant(0)
  ROOT %reduce.266 = f32[] reduce(f32[32768000]{0} %bitcast.790, f32[] %constant_11702), dimensions={0}, to_apply=%primitive_computation_add__1.12995, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0, 1) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
}

%fused_computation.671 (param_0.1279: f32[], param_1.1619: f32[]) -> f32[] {
  %param_0.1279 = f32[] parameter(0)
  %param_1.1619 = f32[] parameter(1)
  %constant_11101 = f32[] constant(0.125)
  %multiply.1396 = f32[] multiply(f32[] %param_1.1619, f32[] %constant_11101), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/metrics.py" source_line=108}
  ROOT %divide.220 = f32[] divide(f32[] %param_0.1279, f32[] %multiply.1396), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/metrics.py" source_line=617}
}

%primitive_computation_add__1.7730 (parameter.7731: f32[], parameter.7732: f32[]) -> f32[] {
  %parameter.7731 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.7732 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.7733 = f32[] add(f32[] %parameter.7731, f32[] %parameter.7732), metadata={op_type="add" op_name="add"}
}

%fused_computation.686 (param_0.1348: f32[16,64,256]) -> f32[256] {
  %param_0.1348 = f32[16,64,256]{2,1,0} parameter(0)
  %bitcast.791 = f32[1024,256]{1,0} bitcast(f32[16,64,256]{2,1,0} %param_0.1348)
  %constant_11219 = f32[] constant(0)
  ROOT %reduce.281 = f32[256]{0} reduce(f32[1024,256]{1,0} %bitcast.791, f32[] %constant_11219), dimensions={0}, to_apply=%primitive_computation_add__1.7730, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0, 1) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/core.py" source_line=96}
}

%primitive_computation_add__1.9891 (parameter.9892: f32[], parameter.9893: f32[]) -> f32[] {
  %parameter.9892 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.9893 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.9894 = f32[] add(f32[] %parameter.9892, f32[] %parameter.9893), metadata={op_type="add" op_name="add"}
}

%fused_computation.687 (param_0.1422: f32[16,64,1024]) -> f32[1024] {
  %param_0.1422 = f32[16,64,1024]{2,1,0} parameter(0)
  %bitcast.792 = f32[1024,1024]{1,0} bitcast(f32[16,64,1024]{2,1,0} %param_0.1422)
  %constant_11424 = f32[] constant(0)
  ROOT %reduce.282 = f32[1024]{0} reduce(f32[1024,1024]{1,0} %bitcast.792, f32[] %constant_11424), dimensions={0}, to_apply=%primitive_computation_add__1.9891, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0, 1) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/core.py" source_line=96}
}

%primitive_computation_add__1.11968 (parameter.11969: f32[], parameter.11970: f32[]) -> f32[] {
  %parameter.11969 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.11970 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.11971 = f32[] add(f32[] %parameter.11969, f32[] %parameter.11970), metadata={op_type="add" op_name="add"}
}

%fused_computation.688 (param_0.1435: f32[16,64,1024]) -> f32[1024] {
  %param_0.1435 = f32[16,64,1024]{2,1,0} parameter(0)
  %bitcast.793 = f32[1024,1024]{1,0} bitcast(f32[16,64,1024]{2,1,0} %param_0.1435)
  %constant_11458 = f32[] constant(0)
  ROOT %reduce.283 = f32[1024]{0} reduce(f32[1024,1024]{1,0} %bitcast.793, f32[] %constant_11458), dimensions={0}, to_apply=%primitive_computation_add__1.11968, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0, 1) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/core.py" source_line=96}
}

%fused_computation.689 (param_0.1515: f32[16,64]) -> f32[16,1,64] {
  %param_0.1515 = f32[16,64]{1,0} parameter(0)
  %bitcast.795 = f32[16,1,64]{2,0,1} bitcast(f32[16,64]{1,0} %param_0.1515), metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(3,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=94}
  ROOT %log.3 = f32[16,1,64]{2,0,1} log(f32[16,1,64]{2,0,1} %bitcast.795), metadata={op_type="log" op_name="pmap(_multi_device_update_fn)/log" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=94}
}

%primitive_computation_max.7466 (parameter.7467: f32[], parameter.7468: f32[]) -> f32[] {
  %parameter.7467 = f32[] parameter(0), metadata={op_type="max" op_name="max"}
  %parameter.7468 = f32[] parameter(1), metadata={op_type="max" op_name="max"}
  ROOT %maximum.7469 = f32[] maximum(f32[] %parameter.7467, f32[] %parameter.7468), metadata={op_type="max" op_name="max"}
}

%fused_computation.706 (param_0.2337: f32[256], param_1.2933: f32[1024,256]) -> f32[16,64] {
  %param_1.2933 = f32[1024,256]{1,0} parameter(1)
  %bitcast.979 = f32[16,64,256]{2,1,0} bitcast(f32[1024,256]{1,0} %param_1.2933), metadata={op_type="dot_general" op_name="pmap(_multi_device_update_fn)/dot_general[ dimension_numbers=(((2,), (0,)), ((), ()))\n                                           precision=None\n                                           preferred_element_type=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/core.py" source_line=96}
  %param_0.2337 = f32[256]{0} parameter(0)
  %broadcast.1901 = f32[16,64,256]{2,1,0} broadcast(f32[256]{0} %param_0.2337), dimensions={2}, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/core.py" source_line=96}
  %add.3032 = f32[16,64,256]{2,1,0} add(f32[16,64,256]{2,1,0} %bitcast.979, f32[16,64,256]{2,1,0} %broadcast.1901), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/core.py" source_line=96}
  %constant_14964 = f32[] constant(-inf), metadata={op_type="reduce_max" op_name="pmap(_multi_device_update_fn)/reduce_max[ axes=(3,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=94}
  ROOT %reduce.284 = f32[16,64]{1,0} reduce(f32[16,64,256]{2,1,0} %add.3032, f32[] %constant_14964), dimensions={2}, to_apply=%primitive_computation_max.7466, metadata={op_type="reduce_max" op_name="pmap(_multi_device_update_fn)/reduce_max[ axes=(2,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=94}
}

%primitive_computation_max.7571 (parameter.7572: f32[], parameter.7573: f32[]) -> f32[] {
  %parameter.7572 = f32[] parameter(0), metadata={op_type="max" op_name="max"}
  %parameter.7573 = f32[] parameter(1), metadata={op_type="max" op_name="max"}
  ROOT %maximum.7574 = f32[] maximum(f32[] %parameter.7572, f32[] %parameter.7573), metadata={op_type="max" op_name="max"}
}

%fused_computation.707 (param_0.2335: f32[16,64], param_1.2931: f32[16,64], param_2.2767: f32[256], param_3.2630: f32[1024,256]) -> f32[16,64] {
  %param_3.2630 = f32[1024,256]{1,0} parameter(3)
  %bitcast.995 = f32[16,64,256]{2,1,0} bitcast(f32[1024,256]{1,0} %param_3.2630), metadata={op_type="dot_general" op_name="pmap(_multi_device_update_fn)/dot_general[ dimension_numbers=(((2,), (0,)), ((), ()))\n                                           precision=None\n                                           preferred_element_type=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/core.py" source_line=96}
  %param_2.2767 = f32[256]{0} parameter(2)
  %broadcast.1916 = f32[16,64,256]{2,1,0} broadcast(f32[256]{0} %param_2.2767), dimensions={2}, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/core.py" source_line=96}
  %add.3040 = f32[16,64,256]{2,1,0} add(f32[16,64,256]{2,1,0} %bitcast.995, f32[16,64,256]{2,1,0} %broadcast.1916), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/core.py" source_line=96}
  %param_1.2931 = f32[16,64]{1,0} parameter(1)
  %bitcast.994 = f32[16,64,1]{1,0,2} bitcast(f32[16,64]{1,0} %param_1.2931), metadata={op_type="log" op_name="pmap(_multi_device_update_fn)/log" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=94}
  %param_0.2335 = f32[16,64]{1,0} parameter(0)
  %bitcast.993 = f32[16,64,1]{1,0,2} bitcast(f32[16,64]{1,0} %param_0.2335), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/broadcast_in_dim[ broadcast_dimensions=(0, 1)\n                                                shape=(16, 64, 1) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=94}
  %is-finite.12 = pred[16,64,1]{1,0,2} is-finite(f32[16,64,1]{1,0,2} %bitcast.993), metadata={op_type="is_finite" op_name="pmap(_multi_device_update_fn)/is_finite" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=94}
  %constant_14455 = f32[] constant(0)
  %broadcast.1915 = f32[16,64,1]{1,0,2} broadcast(f32[] %constant_14455), dimensions={}, metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/broadcast_in_dim[ broadcast_dimensions=(  )\n                                                shape=(16, 64, 1) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=94}
  %select.1985 = f32[16,64,1]{1,0,2} select(pred[16,64,1]{1,0,2} %is-finite.12, f32[16,64,1]{1,0,2} %bitcast.993, f32[16,64,1]{1,0,2} %broadcast.1915), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=94}
  %add.3039 = f32[16,64,1]{1,0,2} add(f32[16,64,1]{1,0,2} %bitcast.994, f32[16,64,1]{1,0,2} %select.1985), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=94}
  %bitcast.992 = f32[16,64]{1,0} bitcast(f32[16,64,1]{1,0,2} %add.3039), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/core.py" source_line=794}
  %broadcast.1914 = f32[16,64,256]{2,1,0} broadcast(f32[16,64]{1,0} %bitcast.992), dimensions={0,1}, metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/core.py" source_line=794}
  %subtract.618 = f32[16,64,256]{2,1,0} subtract(f32[16,64,256]{2,1,0} %add.3040, f32[16,64,256]{2,1,0} %broadcast.1914), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/core.py" source_line=794}
  %constant_14961 = f32[] constant(-inf), metadata={op_type="reduce_max" op_name="pmap(_multi_device_update_fn)/reduce_max[ axes=(3,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=94}
  ROOT %reduce.285 = f32[16,64]{1,0} reduce(f32[16,64,256]{2,1,0} %subtract.618, f32[] %constant_14961), dimensions={2}, to_apply=%primitive_computation_max.7571, metadata={op_type="reduce_max" op_name="pmap(_multi_device_update_fn)/reduce_max[ axes=(2,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=94}
}

%primitive_computation_add__1.13011 (parameter.13012: f32[], parameter.13013: f32[]) -> f32[] {
  %parameter.13012 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.13013 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.13014 = f32[] add(f32[] %parameter.13012, f32[] %parameter.13013), metadata={op_type="add" op_name="add"}
}

%fused_computation.708 (param_0.2321: f32[32000,1024]) -> f32[32000] {
  %param_0.2321 = f32[32000,1024]{1,0} parameter(0)
  %constant_14510 = f32[] constant(0.125)
  %broadcast.1978 = f32[32000,1024]{1,0} broadcast(f32[] %constant_14510), dimensions={}
  %multiply.1518 = f32[32000,1024]{1,0} multiply(f32[32000,1024]{1,0} %param_0.2321, f32[32000,1024]{1,0} %broadcast.1978), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=200}
  %multiply.1517 = f32[32000,1024]{1,0} multiply(f32[32000,1024]{1,0} %multiply.1518, f32[32000,1024]{1,0} %multiply.1518), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=126}
  %constant_14945 = f32[] constant(0)
  ROOT %reduce.286 = f32[32000]{0} reduce(f32[32000,1024]{1,0} %multiply.1517, f32[] %constant_14945), dimensions={1}, to_apply=%primitive_computation_add__1.13011, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(1,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=131}
}

%primitive_computation_add__1.13025 (parameter.13026: f32[], parameter.13027: f32[]) -> f32[] {
  %parameter.13026 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.13027 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.13028 = f32[] add(f32[] %parameter.13026, f32[] %parameter.13027), metadata={op_type="add" op_name="add"}
}

%fused_computation.709 (param_0.2322: f32[32000,1024]) -> f32[1024] {
  %param_0.2322 = f32[32000,1024]{1,0} parameter(0)
  %constant_14514 = f32[] constant(0.125)
  %broadcast.1980 = f32[32000,1024]{1,0} broadcast(f32[] %constant_14514), dimensions={}
  %multiply.1522 = f32[32000,1024]{1,0} multiply(f32[32000,1024]{1,0} %param_0.2322, f32[32000,1024]{1,0} %broadcast.1980), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=200}
  %multiply.1521 = f32[32000,1024]{1,0} multiply(f32[32000,1024]{1,0} %multiply.1522, f32[32000,1024]{1,0} %multiply.1522), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=126}
  %constant_14946 = f32[] constant(0)
  ROOT %reduce.287 = f32[1024]{0} reduce(f32[32000,1024]{1,0} %multiply.1521, f32[] %constant_14946), dimensions={0}, to_apply=%primitive_computation_add__1.13025, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
}

%primitive_computation_add__1.13137 (parameter.13138: f32[], parameter.13139: f32[]) -> f32[] {
  %parameter.13138 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.13139 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.13140 = f32[] add(f32[] %parameter.13138, f32[] %parameter.13139), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.15711 (parameter.15712: f32[], parameter.15713: f32[]) -> f32[] {
  %parameter.15712 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.15713 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.15714 = f32[] add(f32[] %parameter.15712, f32[] %parameter.15713), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.13341 (parameter.13342: f32[], parameter.13343: f32[]) -> f32[] {
  %parameter.13342 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.13343 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.13344 = f32[] add(f32[] %parameter.13342, f32[] %parameter.13343), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.14079 (parameter.14080: f32[], parameter.14081: f32[]) -> f32[] {
  %parameter.14080 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.14081 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.14082 = f32[] add(f32[] %parameter.14080, f32[] %parameter.14081), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.15507 (parameter.15508: f32[], parameter.15509: f32[]) -> f32[] {
  %parameter.15508 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.15509 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.15510 = f32[] add(f32[] %parameter.15508, f32[] %parameter.15509), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.15303 (parameter.15304: f32[], parameter.15305: f32[]) -> f32[] {
  %parameter.15304 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.15305 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.15306 = f32[] add(f32[] %parameter.15304, f32[] %parameter.15305), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.13749 (parameter.13750: f32[], parameter.13751: f32[]) -> f32[] {
  %parameter.13750 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.13751 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.13752 = f32[] add(f32[] %parameter.13750, f32[] %parameter.13751), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.15099 (parameter.15100: f32[], parameter.15101: f32[]) -> f32[] {
  %parameter.15100 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.15101 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.15102 = f32[] add(f32[] %parameter.15100, f32[] %parameter.15101), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.13545 (parameter.13546: f32[], parameter.13547: f32[]) -> f32[] {
  %parameter.13546 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.13547 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.13548 = f32[] add(f32[] %parameter.13546, f32[] %parameter.13547), metadata={op_type="add" op_name="add"}
}

%fused_computation.710 (param_0.2310: f32[2048,4096], param_1.2961: f32[2048,4096], param_2.2813: f32[2048,4096], param_3.2674: f32[2048,4096], param_4.1473: f32[2048,4096], param_5.634: f32[2048,4096], param_6.600: f32[2048,4096], param_7.581: f32[2048,4096], param_8.473: f32[2048,4096]) -> (f32[2048], f32[2048], f32[2048], f32[2048], f32[2048], /*index=5*/f32[2048], f32[2048], f32[2048], f32[2048]) {
  %param_0.2310 = f32[2048,4096]{1,0} parameter(0)
  %constant_14528 = f32[] constant(0.125)
  %broadcast.1996 = f32[2048,4096]{1,0} broadcast(f32[] %constant_14528), dimensions={}
  %multiply.1542 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %param_0.2310, f32[2048,4096]{1,0} %broadcast.1996), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=200}
  %multiply.1541 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %multiply.1542, f32[2048,4096]{1,0} %multiply.1542), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=126}
  %constant_14932 = f32[] constant(0)
  %reduce.288 = f32[2048]{0} reduce(f32[2048,4096]{1,0} %multiply.1541, f32[] %constant_14932), dimensions={1}, to_apply=%primitive_computation_add__1.13137, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(1,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=131}
  %param_1.2961 = f32[2048,4096]{1,0} parameter(1)
  %multiply.1894.clone.1 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %param_1.2961, f32[2048,4096]{1,0} %broadcast.1996), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=200}
  %multiply.1893.clone.1 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %multiply.1894.clone.1, f32[2048,4096]{1,0} %multiply.1894.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=126}
  %reduce.314.clone.1 = f32[2048]{0} reduce(f32[2048,4096]{1,0} %multiply.1893.clone.1, f32[] %constant_14932), dimensions={1}, to_apply=%primitive_computation_add__1.15711, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(1,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=131}
  %param_2.2813 = f32[2048,4096]{1,0} parameter(2)
  %multiply.1602.clone.1 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %param_2.2813, f32[2048,4096]{1,0} %broadcast.1996), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=200}
  %multiply.1601.clone.1 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %multiply.1602.clone.1, f32[2048,4096]{1,0} %multiply.1602.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=126}
  %reduce.290.clone.1 = f32[2048]{0} reduce(f32[2048,4096]{1,0} %multiply.1601.clone.1, f32[] %constant_14932), dimensions={1}, to_apply=%primitive_computation_add__1.13341, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(1,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=131}
  %param_3.2674 = f32[2048,4096]{1,0} parameter(3)
  %multiply.1702.clone.1 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %param_3.2674, f32[2048,4096]{1,0} %broadcast.1996), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=200}
  %multiply.1701.clone.1 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %multiply.1702.clone.1, f32[2048,4096]{1,0} %multiply.1702.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=126}
  %reduce.298.clone.1 = f32[2048]{0} reduce(f32[2048,4096]{1,0} %multiply.1701.clone.1, f32[] %constant_14932), dimensions={1}, to_apply=%primitive_computation_add__1.14079, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(1,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=131}
  %param_4.1473 = f32[2048,4096]{1,0} parameter(4)
  %multiply.1870.clone.1 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %param_4.1473, f32[2048,4096]{1,0} %broadcast.1996), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=200}
  %multiply.1869.clone.1 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %multiply.1870.clone.1, f32[2048,4096]{1,0} %multiply.1870.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=126}
  %reduce.312.clone.1 = f32[2048]{0} reduce(f32[2048,4096]{1,0} %multiply.1869.clone.1, f32[] %constant_14932), dimensions={1}, to_apply=%primitive_computation_add__1.15507, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(1,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=131}
  %param_5.634 = f32[2048,4096]{1,0} parameter(5)
  %multiply.1846.clone.1 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %param_5.634, f32[2048,4096]{1,0} %broadcast.1996), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=200}
  %multiply.1845.clone.1 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %multiply.1846.clone.1, f32[2048,4096]{1,0} %multiply.1846.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=126}
  %reduce.310.clone.1 = f32[2048]{0} reduce(f32[2048,4096]{1,0} %multiply.1845.clone.1, f32[] %constant_14932), dimensions={1}, to_apply=%primitive_computation_add__1.15303, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(1,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=131}
  %param_6.600 = f32[2048,4096]{1,0} parameter(6)
  %multiply.1650.clone.1 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %param_6.600, f32[2048,4096]{1,0} %broadcast.1996), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=200}
  %multiply.1649.clone.1 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %multiply.1650.clone.1, f32[2048,4096]{1,0} %multiply.1650.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=126}
  %reduce.294.clone.1 = f32[2048]{0} reduce(f32[2048,4096]{1,0} %multiply.1649.clone.1, f32[] %constant_14932), dimensions={1}, to_apply=%primitive_computation_add__1.13749, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(1,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=131}
  %param_7.581 = f32[2048,4096]{1,0} parameter(7)
  %multiply.1822.clone.1 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %param_7.581, f32[2048,4096]{1,0} %broadcast.1996), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=200}
  %multiply.1821.clone.1 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %multiply.1822.clone.1, f32[2048,4096]{1,0} %multiply.1822.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=126}
  %reduce.308.clone.1 = f32[2048]{0} reduce(f32[2048,4096]{1,0} %multiply.1821.clone.1, f32[] %constant_14932), dimensions={1}, to_apply=%primitive_computation_add__1.15099, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(1,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=131}
  %param_8.473 = f32[2048,4096]{1,0} parameter(8)
  %multiply.1626.clone.1 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %param_8.473, f32[2048,4096]{1,0} %broadcast.1996), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=200}
  %multiply.1625.clone.1 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %multiply.1626.clone.1, f32[2048,4096]{1,0} %multiply.1626.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=126}
  %reduce.292.clone.1 = f32[2048]{0} reduce(f32[2048,4096]{1,0} %multiply.1625.clone.1, f32[] %constant_14932), dimensions={1}, to_apply=%primitive_computation_add__1.13545, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(1,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=131}
  ROOT %tuple.784 = (f32[2048]{0}, f32[2048]{0}, f32[2048]{0}, f32[2048]{0}, f32[2048]{0}, /*index=5*/f32[2048]{0}, f32[2048]{0}, f32[2048]{0}, f32[2048]{0}) tuple(f32[2048]{0} %reduce.288, f32[2048]{0} %reduce.314.clone.1, f32[2048]{0} %reduce.290.clone.1, f32[2048]{0} %reduce.298.clone.1, f32[2048]{0} %reduce.312.clone.1, /*index=5*/f32[2048]{0} %reduce.310.clone.1, f32[2048]{0} %reduce.294.clone.1, f32[2048]{0} %reduce.308.clone.1, f32[2048]{0} %reduce.292.clone.1)
}

%primitive_computation_add__1.13151 (parameter.13152: f32[], parameter.13153: f32[]) -> f32[] {
  %parameter.13152 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.13153 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.13154 = f32[] add(f32[] %parameter.13152, f32[] %parameter.13153), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.15725 (parameter.15726: f32[], parameter.15727: f32[]) -> f32[] {
  %parameter.15726 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.15727 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.15728 = f32[] add(f32[] %parameter.15726, f32[] %parameter.15727), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.15521 (parameter.15522: f32[], parameter.15523: f32[]) -> f32[] {
  %parameter.15522 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.15523 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.15524 = f32[] add(f32[] %parameter.15522, f32[] %parameter.15523), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.15317 (parameter.15318: f32[], parameter.15319: f32[]) -> f32[] {
  %parameter.15318 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.15319 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.15320 = f32[] add(f32[] %parameter.15318, f32[] %parameter.15319), metadata={op_type="add" op_name="add"}
}

%fused_computation.711 (param_0.2319: f32[2048,4096], param_1.2955: f32[2048,4096], param_2.2801: f32[2048,4096], param_3.2662: f32[2048,4096]) -> (f32[4096], f32[4096], f32[4096], f32[4096]) {
  %param_0.2319 = f32[2048,4096]{1,0} parameter(0)
  %constant_14531 = f32[] constant(0.125)
  %broadcast.1999 = f32[2048,4096]{1,0} broadcast(f32[] %constant_14531), dimensions={}
  %multiply.1546 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %param_0.2319, f32[2048,4096]{1,0} %broadcast.1999), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=200}
  %multiply.1545 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %multiply.1546, f32[2048,4096]{1,0} %multiply.1546), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=126}
  %constant_14943 = f32[] constant(0)
  %reduce.289 = f32[4096]{0} reduce(f32[2048,4096]{1,0} %multiply.1545, f32[] %constant_14943), dimensions={0}, to_apply=%primitive_computation_add__1.13151, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
  %param_1.2955 = f32[2048,4096]{1,0} parameter(1)
  %multiply.1898.clone.1 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %param_1.2955, f32[2048,4096]{1,0} %broadcast.1999), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=200}
  %multiply.1897.clone.1 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %multiply.1898.clone.1, f32[2048,4096]{1,0} %multiply.1898.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=126}
  %reduce.315.clone.1 = f32[4096]{0} reduce(f32[2048,4096]{1,0} %multiply.1897.clone.1, f32[] %constant_14943), dimensions={0}, to_apply=%primitive_computation_add__1.15725, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
  %param_2.2801 = f32[2048,4096]{1,0} parameter(2)
  %multiply.1874.clone.1 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %param_2.2801, f32[2048,4096]{1,0} %broadcast.1999), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=200}
  %multiply.1873.clone.1 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %multiply.1874.clone.1, f32[2048,4096]{1,0} %multiply.1874.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=126}
  %reduce.313.clone.1 = f32[4096]{0} reduce(f32[2048,4096]{1,0} %multiply.1873.clone.1, f32[] %constant_14943), dimensions={0}, to_apply=%primitive_computation_add__1.15521, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
  %param_3.2662 = f32[2048,4096]{1,0} parameter(3)
  %multiply.1850.clone.1 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %param_3.2662, f32[2048,4096]{1,0} %broadcast.1999), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=200}
  %multiply.1849.clone.1 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %multiply.1850.clone.1, f32[2048,4096]{1,0} %multiply.1850.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=126}
  %reduce.311.clone.1 = f32[4096]{0} reduce(f32[2048,4096]{1,0} %multiply.1849.clone.1, f32[] %constant_14943), dimensions={0}, to_apply=%primitive_computation_add__1.15317, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
  ROOT %tuple.773 = (f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}) tuple(f32[4096]{0} %reduce.289, f32[4096]{0} %reduce.315.clone.1, f32[4096]{0} %reduce.313.clone.1, f32[4096]{0} %reduce.311.clone.1)
}

%primitive_computation_add__1.13355 (parameter.13356: f32[], parameter.13357: f32[]) -> f32[] {
  %parameter.13356 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.13357 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.13358 = f32[] add(f32[] %parameter.13356, f32[] %parameter.13357), metadata={op_type="add" op_name="add"}
}

%fused_computation.713 (param_0.2311: f32[2048,4096]) -> f32[4096] {
  %param_0.2311 = f32[2048,4096]{1,0} parameter(0)
  %constant_14658 = f32[] constant(0.125)
  %broadcast.2055 = f32[2048,4096]{1,0} broadcast(f32[] %constant_14658), dimensions={}
  %multiply.1606 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %param_0.2311, f32[2048,4096]{1,0} %broadcast.2055), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=200}
  %multiply.1605 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %multiply.1606, f32[2048,4096]{1,0} %multiply.1606), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=126}
  %constant_14933 = f32[] constant(0)
  ROOT %reduce.291 = f32[4096]{0} reduce(f32[2048,4096]{1,0} %multiply.1605, f32[] %constant_14933), dimensions={0}, to_apply=%primitive_computation_add__1.13355, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
}

%primitive_computation_add__1.13953 (parameter.13954: f32[], parameter.13955: f32[]) -> f32[] {
  %parameter.13954 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.13955 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.13956 = f32[] add(f32[] %parameter.13954, f32[] %parameter.13955), metadata={op_type="add" op_name="add"}
}

%fused_computation.718 (param_0.2299: f32[256,1024]) -> f32[256] {
  %param_0.2299 = f32[256,1024]{1,0} parameter(0)
  %constant_14709 = f32[] constant(0.125)
  %broadcast.2109 = f32[256,1024]{1,0} broadcast(f32[] %constant_14709), dimensions={}
  %multiply.1674 = f32[256,1024]{1,0} multiply(f32[256,1024]{1,0} %param_0.2299, f32[256,1024]{1,0} %broadcast.2109), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=200}
  %multiply.1673 = f32[256,1024]{1,0} multiply(f32[256,1024]{1,0} %multiply.1674, f32[256,1024]{1,0} %multiply.1674), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=126}
  %constant_14919 = f32[] constant(0)
  ROOT %reduce.296 = f32[256]{0} reduce(f32[256,1024]{1,0} %multiply.1673, f32[] %constant_14919), dimensions={1}, to_apply=%primitive_computation_add__1.13953, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(1,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=131}
}

%primitive_computation_add__1.13967 (parameter.13968: f32[], parameter.13969: f32[]) -> f32[] {
  %parameter.13968 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.13969 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.13970 = f32[] add(f32[] %parameter.13968, f32[] %parameter.13969), metadata={op_type="add" op_name="add"}
}

%fused_computation.719 (param_0.2329: f32[256,1024]) -> f32[1024] {
  %param_0.2329 = f32[256,1024]{1,0} parameter(0)
  %constant_14713 = f32[] constant(0.125)
  %broadcast.2111 = f32[256,1024]{1,0} broadcast(f32[] %constant_14713), dimensions={}
  %multiply.1678 = f32[256,1024]{1,0} multiply(f32[256,1024]{1,0} %param_0.2329, f32[256,1024]{1,0} %broadcast.2111), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=200}
  %multiply.1677 = f32[256,1024]{1,0} multiply(f32[256,1024]{1,0} %multiply.1678, f32[256,1024]{1,0} %multiply.1678), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=126}
  %constant_14954 = f32[] constant(0)
  ROOT %reduce.297 = f32[1024]{0} reduce(f32[256,1024]{1,0} %multiply.1677, f32[] %constant_14954), dimensions={0}, to_apply=%primitive_computation_add__1.13967, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
}

%primitive_computation_add__1.14487 (parameter.14488: f32[], parameter.14489: f32[]) -> f32[] {
  %parameter.14488 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.14489 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.14490 = f32[] add(f32[] %parameter.14488, f32[] %parameter.14489), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.14895 (parameter.14896: f32[], parameter.14897: f32[]) -> f32[] {
  %parameter.14896 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.14897 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.14898 = f32[] add(f32[] %parameter.14896, f32[] %parameter.14897), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.14283 (parameter.14284: f32[], parameter.14285: f32[]) -> f32[] {
  %parameter.14284 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.14285 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.14286 = f32[] add(f32[] %parameter.14284, f32[] %parameter.14285), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.14691 (parameter.14692: f32[], parameter.14693: f32[]) -> f32[] {
  %parameter.14692 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.14693 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.14694 = f32[] add(f32[] %parameter.14692, f32[] %parameter.14693), metadata={op_type="add" op_name="add"}
}

%fused_computation.724 (param_0.2328: f32[1024,1024], param_1.2936: f32[1024,1024], param_2.2774: f32[1024,1024], param_3.2636: f32[1024,1024]) -> (f32[1024], f32[1024], f32[1024], f32[1024]) {
  %param_0.2328 = f32[1024,1024]{1,0} parameter(0)
  %constant_14775 = f32[] constant(0.125)
  %broadcast.2170 = f32[1024,1024]{1,0} broadcast(f32[] %constant_14775), dimensions={}
  %multiply.1750 = f32[1024,1024]{1,0} multiply(f32[1024,1024]{1,0} %param_0.2328, f32[1024,1024]{1,0} %broadcast.2170), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=200}
  %multiply.1749 = f32[1024,1024]{1,0} multiply(f32[1024,1024]{1,0} %multiply.1750, f32[1024,1024]{1,0} %multiply.1750), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=126}
  %constant_14953 = f32[] constant(0)
  %reduce.302 = f32[1024]{0} reduce(f32[1024,1024]{1,0} %multiply.1749, f32[] %constant_14953), dimensions={1}, to_apply=%primitive_computation_add__1.14487, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(1,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=131}
  %param_1.2936 = f32[1024,1024]{1,0} parameter(1)
  %multiply.1798.clone.1 = f32[1024,1024]{1,0} multiply(f32[1024,1024]{1,0} %param_1.2936, f32[1024,1024]{1,0} %broadcast.2170), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=200}
  %multiply.1797.clone.1 = f32[1024,1024]{1,0} multiply(f32[1024,1024]{1,0} %multiply.1798.clone.1, f32[1024,1024]{1,0} %multiply.1798.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=126}
  %reduce.306.clone.1 = f32[1024]{0} reduce(f32[1024,1024]{1,0} %multiply.1797.clone.1, f32[] %constant_14953), dimensions={1}, to_apply=%primitive_computation_add__1.14895, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(1,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=131}
  %param_2.2774 = f32[1024,1024]{1,0} parameter(2)
  %multiply.1726.clone.1 = f32[1024,1024]{1,0} multiply(f32[1024,1024]{1,0} %param_2.2774, f32[1024,1024]{1,0} %broadcast.2170), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=200}
  %multiply.1725.clone.1 = f32[1024,1024]{1,0} multiply(f32[1024,1024]{1,0} %multiply.1726.clone.1, f32[1024,1024]{1,0} %multiply.1726.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=126}
  %reduce.300.clone.1 = f32[1024]{0} reduce(f32[1024,1024]{1,0} %multiply.1725.clone.1, f32[] %constant_14953), dimensions={1}, to_apply=%primitive_computation_add__1.14283, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(1,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=131}
  %param_3.2636 = f32[1024,1024]{1,0} parameter(3)
  %multiply.1774.clone.1 = f32[1024,1024]{1,0} multiply(f32[1024,1024]{1,0} %param_3.2636, f32[1024,1024]{1,0} %broadcast.2170), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=200}
  %multiply.1773.clone.1 = f32[1024,1024]{1,0} multiply(f32[1024,1024]{1,0} %multiply.1774.clone.1, f32[1024,1024]{1,0} %multiply.1774.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=126}
  %reduce.304.clone.1 = f32[1024]{0} reduce(f32[1024,1024]{1,0} %multiply.1773.clone.1, f32[] %constant_14953), dimensions={1}, to_apply=%primitive_computation_add__1.14691, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(1,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=131}
  ROOT %tuple.744 = (f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}) tuple(f32[1024]{0} %reduce.302, f32[1024]{0} %reduce.306.clone.1, f32[1024]{0} %reduce.300.clone.1, f32[1024]{0} %reduce.304.clone.1)
}

%primitive_computation_add__1.14909 (parameter.14910: f32[], parameter.14911: f32[]) -> f32[] {
  %parameter.14910 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.14911 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.14912 = f32[] add(f32[] %parameter.14910, f32[] %parameter.14911), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.14705 (parameter.14706: f32[], parameter.14707: f32[]) -> f32[] {
  %parameter.14706 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.14707 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.14708 = f32[] add(f32[] %parameter.14706, f32[] %parameter.14707), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.14501 (parameter.14502: f32[], parameter.14503: f32[]) -> f32[] {
  %parameter.14502 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.14503 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.14504 = f32[] add(f32[] %parameter.14502, f32[] %parameter.14503), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.14297 (parameter.14298: f32[], parameter.14299: f32[]) -> f32[] {
  %parameter.14298 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.14299 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.14300 = f32[] add(f32[] %parameter.14298, f32[] %parameter.14299), metadata={op_type="add" op_name="add"}
}

%fused_computation.729 (param_0.2333: f32[1024,1024], param_1.2939: f32[1024,1024], param_2.2780: f32[1024,1024], param_3.2642: f32[1024,1024]) -> (f32[1024], f32[1024], f32[1024], f32[1024]) {
  %param_0.2333 = f32[1024,1024]{1,0} parameter(0)
  %constant_14815 = f32[] constant(0.125)
  %broadcast.2210 = f32[1024,1024]{1,0} broadcast(f32[] %constant_14815), dimensions={}
  %multiply.1802 = f32[1024,1024]{1,0} multiply(f32[1024,1024]{1,0} %param_0.2333, f32[1024,1024]{1,0} %broadcast.2210), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=200}
  %multiply.1801 = f32[1024,1024]{1,0} multiply(f32[1024,1024]{1,0} %multiply.1802, f32[1024,1024]{1,0} %multiply.1802), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=126}
  %constant_14959 = f32[] constant(0)
  %reduce.307 = f32[1024]{0} reduce(f32[1024,1024]{1,0} %multiply.1801, f32[] %constant_14959), dimensions={0}, to_apply=%primitive_computation_add__1.14909, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
  %param_1.2939 = f32[1024,1024]{1,0} parameter(1)
  %multiply.1778.clone.1 = f32[1024,1024]{1,0} multiply(f32[1024,1024]{1,0} %param_1.2939, f32[1024,1024]{1,0} %broadcast.2210), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=200}
  %multiply.1777.clone.1 = f32[1024,1024]{1,0} multiply(f32[1024,1024]{1,0} %multiply.1778.clone.1, f32[1024,1024]{1,0} %multiply.1778.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=126}
  %reduce.305.clone.1 = f32[1024]{0} reduce(f32[1024,1024]{1,0} %multiply.1777.clone.1, f32[] %constant_14959), dimensions={0}, to_apply=%primitive_computation_add__1.14705, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
  %param_2.2780 = f32[1024,1024]{1,0} parameter(2)
  %multiply.1754.clone.1 = f32[1024,1024]{1,0} multiply(f32[1024,1024]{1,0} %param_2.2780, f32[1024,1024]{1,0} %broadcast.2210), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=200}
  %multiply.1753.clone.1 = f32[1024,1024]{1,0} multiply(f32[1024,1024]{1,0} %multiply.1754.clone.1, f32[1024,1024]{1,0} %multiply.1754.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=126}
  %reduce.303.clone.1 = f32[1024]{0} reduce(f32[1024,1024]{1,0} %multiply.1753.clone.1, f32[] %constant_14959), dimensions={0}, to_apply=%primitive_computation_add__1.14501, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
  %param_3.2642 = f32[1024,1024]{1,0} parameter(3)
  %multiply.1730.clone.1 = f32[1024,1024]{1,0} multiply(f32[1024,1024]{1,0} %param_3.2642, f32[1024,1024]{1,0} %broadcast.2210), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=200}
  %multiply.1729.clone.1 = f32[1024,1024]{1,0} multiply(f32[1024,1024]{1,0} %multiply.1730.clone.1, f32[1024,1024]{1,0} %multiply.1730.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=126}
  %reduce.301.clone.1 = f32[1024]{0} reduce(f32[1024,1024]{1,0} %multiply.1729.clone.1, f32[] %constant_14959), dimensions={0}, to_apply=%primitive_computation_add__1.14297, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
  ROOT %tuple.747 = (f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}) tuple(f32[1024]{0} %reduce.307, f32[1024]{0} %reduce.305.clone.1, f32[1024]{0} %reduce.303.clone.1, f32[1024]{0} %reduce.301.clone.1)
}

%primitive_computation_add__1.15113 (parameter.15114: f32[], parameter.15115: f32[]) -> f32[] {
  %parameter.15114 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.15115 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.15116 = f32[] add(f32[] %parameter.15114, f32[] %parameter.15115), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.14093 (parameter.14094: f32[], parameter.14095: f32[]) -> f32[] {
  %parameter.14094 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.14095 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.14096 = f32[] add(f32[] %parameter.14094, f32[] %parameter.14095), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.13763 (parameter.13764: f32[], parameter.13765: f32[]) -> f32[] {
  %parameter.13764 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.13765 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.13766 = f32[] add(f32[] %parameter.13764, f32[] %parameter.13765), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.13559 (parameter.13560: f32[], parameter.13561: f32[]) -> f32[] {
  %parameter.13560 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.13561 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.13562 = f32[] add(f32[] %parameter.13560, f32[] %parameter.13561), metadata={op_type="add" op_name="add"}
}

%fused_computation.731 (param_0.2315: f32[2048,4096], param_1.2958: f32[2048,4096], param_2.2807: f32[2048,4096], param_3.2668: f32[2048,4096]) -> (f32[4096], f32[4096], f32[4096], f32[4096]) {
  %param_0.2315 = f32[2048,4096]{1,0} parameter(0)
  %constant_14833 = f32[] constant(0.125)
  %broadcast.2229 = f32[2048,4096]{1,0} broadcast(f32[] %constant_14833), dimensions={}
  %multiply.1826 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %param_0.2315, f32[2048,4096]{1,0} %broadcast.2229), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=200}
  %multiply.1825 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %multiply.1826, f32[2048,4096]{1,0} %multiply.1826), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=126}
  %constant_14938 = f32[] constant(0)
  %reduce.309 = f32[4096]{0} reduce(f32[2048,4096]{1,0} %multiply.1825, f32[] %constant_14938), dimensions={0}, to_apply=%primitive_computation_add__1.15113, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
  %param_1.2958 = f32[2048,4096]{1,0} parameter(1)
  %multiply.1706.clone.1 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %param_1.2958, f32[2048,4096]{1,0} %broadcast.2229), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=200}
  %multiply.1705.clone.1 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %multiply.1706.clone.1, f32[2048,4096]{1,0} %multiply.1706.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=126}
  %reduce.299.clone.1 = f32[4096]{0} reduce(f32[2048,4096]{1,0} %multiply.1705.clone.1, f32[] %constant_14938), dimensions={0}, to_apply=%primitive_computation_add__1.14093, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
  %param_2.2807 = f32[2048,4096]{1,0} parameter(2)
  %multiply.1654.clone.1 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %param_2.2807, f32[2048,4096]{1,0} %broadcast.2229), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=200}
  %multiply.1653.clone.1 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %multiply.1654.clone.1, f32[2048,4096]{1,0} %multiply.1654.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=126}
  %reduce.295.clone.1 = f32[4096]{0} reduce(f32[2048,4096]{1,0} %multiply.1653.clone.1, f32[] %constant_14938), dimensions={0}, to_apply=%primitive_computation_add__1.13763, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
  %param_3.2668 = f32[2048,4096]{1,0} parameter(3)
  %multiply.1630.clone.1 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %param_3.2668, f32[2048,4096]{1,0} %broadcast.2229), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=200}
  %multiply.1629.clone.1 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %multiply.1630.clone.1, f32[2048,4096]{1,0} %multiply.1630.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=126}
  %reduce.293.clone.1 = f32[4096]{0} reduce(f32[2048,4096]{1,0} %multiply.1629.clone.1, f32[] %constant_14938), dimensions={0}, to_apply=%primitive_computation_add__1.13559, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
  ROOT %tuple.776 = (f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}) tuple(f32[4096]{0} %reduce.309, f32[4096]{0} %reduce.299.clone.1, f32[4096]{0} %reduce.295.clone.1, f32[4096]{0} %reduce.293.clone.1)
}

%primitive_computation_add__1.15915 (parameter.15916: f32[], parameter.15917: f32[]) -> f32[] {
  %parameter.15916 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.15917 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.15918 = f32[] add(f32[] %parameter.15916, f32[] %parameter.15917), metadata={op_type="add" op_name="add"}
}

%fused_computation.738 (param_0.2326: f32[1024,256]) -> f32[1024] {
  %param_0.2326 = f32[1024,256]{1,0} parameter(0)
  %constant_14903 = f32[] constant(0.125)
  %broadcast.2300 = f32[1024,256]{1,0} broadcast(f32[] %constant_14903), dimensions={}
  %multiply.1918 = f32[1024,256]{1,0} multiply(f32[1024,256]{1,0} %param_0.2326, f32[1024,256]{1,0} %broadcast.2300), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=200}
  %multiply.1917 = f32[1024,256]{1,0} multiply(f32[1024,256]{1,0} %multiply.1918, f32[1024,256]{1,0} %multiply.1918), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=126}
  %constant_14950 = f32[] constant(0)
  ROOT %reduce.316 = f32[1024]{0} reduce(f32[1024,256]{1,0} %multiply.1917, f32[] %constant_14950), dimensions={1}, to_apply=%primitive_computation_add__1.15915, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(1,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=131}
}

%primitive_computation_add__1.15929 (parameter.15930: f32[], parameter.15931: f32[]) -> f32[] {
  %parameter.15930 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.15931 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.15932 = f32[] add(f32[] %parameter.15930, f32[] %parameter.15931), metadata={op_type="add" op_name="add"}
}

%fused_computation.739 (param_0.2300: f32[1024,256]) -> f32[256] {
  %param_0.2300 = f32[1024,256]{1,0} parameter(0)
  %constant_14906 = f32[] constant(0.125)
  %broadcast.2302 = f32[1024,256]{1,0} broadcast(f32[] %constant_14906), dimensions={}
  %multiply.1922 = f32[1024,256]{1,0} multiply(f32[1024,256]{1,0} %param_0.2300, f32[1024,256]{1,0} %broadcast.2302), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=200}
  %multiply.1921 = f32[1024,256]{1,0} multiply(f32[1024,256]{1,0} %multiply.1922, f32[1024,256]{1,0} %multiply.1922), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=126}
  %constant_14921 = f32[] constant(0)
  ROOT %reduce.317 = f32[256]{0} reduce(f32[1024,256]{1,0} %multiply.1921, f32[] %constant_14921), dimensions={0}, to_apply=%primitive_computation_add__1.15929, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
}

%primitive_computation_add__1.14513 (parameter.14514: f32[], parameter.14515: f32[]) -> f32[] {
  %parameter.14514 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.14515 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.14516 = f32[] add(f32[] %parameter.14514, f32[] %parameter.14515), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.14921 (parameter.14922: f32[], parameter.14923: f32[]) -> f32[] {
  %parameter.14922 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.14923 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.14924 = f32[] add(f32[] %parameter.14922, f32[] %parameter.14923), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.15941 (parameter.15942: f32[], parameter.15943: f32[]) -> f32[] {
  %parameter.15942 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.15943 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.15944 = f32[] add(f32[] %parameter.15942, f32[] %parameter.15943), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.14309 (parameter.14310: f32[], parameter.14311: f32[]) -> f32[] {
  %parameter.14310 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.14311 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.14312 = f32[] add(f32[] %parameter.14310, f32[] %parameter.14311), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.14717 (parameter.14718: f32[], parameter.14719: f32[]) -> f32[] {
  %parameter.14718 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.14719 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.14720 = f32[] add(f32[] %parameter.14718, f32[] %parameter.14719), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.14419 (parameter.14420: f32[], parameter.14421: f32[]) -> f32[] {
  %parameter.14420 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.14421 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.14422 = f32[] add(f32[] %parameter.14420, f32[] %parameter.14421), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.14623 (parameter.14624: f32[], parameter.14625: f32[]) -> f32[] {
  %parameter.14624 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.14625 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.14626 = f32[] add(f32[] %parameter.14624, f32[] %parameter.14625), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.14827 (parameter.14828: f32[], parameter.14829: f32[]) -> f32[] {
  %parameter.14828 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.14829 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.14830 = f32[] add(f32[] %parameter.14828, f32[] %parameter.14829), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.15031 (parameter.15032: f32[], parameter.15033: f32[]) -> f32[] {
  %parameter.15032 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.15033 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.15034 = f32[] add(f32[] %parameter.15032, f32[] %parameter.15033), metadata={op_type="add" op_name="add"}
}

%fused_computation.756 (param_0.2323: f32[1024], param_1.2929: f32[], param_2.2765: f32[1024], param_3.2628: f32[1024], param_4.1445: f32[1024], param_5.621: f32[1024], param_6.587: f32[1024], param_7.568: f32[1024], param_8.460: f32[1024], param_9.304: f32[1024], param_10.285: f32[1024], param_11.271: f32[1024], param_12.296: f32[], param_13.318: f32[1024], param_14.307: f32[1024], param_15.245: f32[1024], param_16.165: f32[1024], param_17.95: f32[1024], param_18.91: f32[1024], param_19.92: f32[1024]) -> (f32[], f32[1024], f32[], f32[1024], f32[], /*index=5*/f32[1024], f32[], f32[1024], f32[], f32[1024], /*index=10*/f32[], f32[1024], f32[1024], f32[], f32[], /*index=15*/f32[1024], f32[1024], f32[], f32[], f32[1024], /*index=20*/f32[1024], f32[], f32[], f32[1024], f32[1024], /*index=25*/f32[]) {
  %param_1.2929 = f32[] parameter(1)
  %broadcast.1686.clone.1 = f32[1024]{0} broadcast(f32[] %param_1.2929), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
  %param_2.2765 = f32[1024]{0} parameter(2)
  %multiply.1160.clone.1 = f32[1024]{0} multiply(f32[1024]{0} %broadcast.1686.clone.1, f32[1024]{0} %param_2.2765), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=131}
  %param_0.2323 = f32[1024]{0} parameter(0)
  %constant_11434_clone_1 = f32[] constant(1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/metrics.py" source_line=617}
  %subtract.308.clone.1 = f32[] subtract(f32[] %constant_11434_clone_1, f32[] %param_1.2929), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=124}
  %constant_11433_clone_1 = f32[] constant(0.0009765625)
  %multiply.1454.clone.1 = f32[] multiply(f32[] %subtract.308.clone.1, f32[] %constant_11433_clone_1)
  %broadcast.1685.clone.1 = f32[1024]{0} broadcast(f32[] %multiply.1454.clone.1), dimensions={}
  %multiply.1159.clone.1 = f32[1024]{0} multiply(f32[1024]{0} %param_0.2323, f32[1024]{0} %broadcast.1685.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=131}
  %add.2026.clone.1 = f32[1024]{0} add(f32[1024]{0} %multiply.1160.clone.1, f32[1024]{0} %multiply.1159.clone.1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=131}
  %constant_11149_clone_1_clone_1_clone_1 = f32[] constant(0)
  %reduce.325 = f32[] reduce(f32[1024]{0} %add.2026.clone.1, f32[] %constant_11149_clone_1_clone_1_clone_1), dimensions={0}, to_apply=%primitive_computation_add__1.14513, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=135}
  %param_4.1445 = f32[1024]{0} parameter(4)
  %multiply.1106.clone.1.clone.1 = f32[1024]{0} multiply(f32[1024]{0} %broadcast.1686.clone.1, f32[1024]{0} %param_4.1445), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=131}
  %param_3.2628 = f32[1024]{0} parameter(3)
  %multiply.1105.clone.1.clone.1 = f32[1024]{0} multiply(f32[1024]{0} %param_3.2628, f32[1024]{0} %broadcast.1685.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=131}
  %add.2012.clone.1.clone.1 = f32[1024]{0} add(f32[1024]{0} %multiply.1106.clone.1.clone.1, f32[1024]{0} %multiply.1105.clone.1.clone.1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=131}
  %reduce.323.clone.1 = f32[] reduce(f32[1024]{0} %add.2012.clone.1.clone.1, f32[] %constant_11149_clone_1_clone_1_clone_1), dimensions={0}, to_apply=%primitive_computation_add__1.14921, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=135}
  %param_6.587 = f32[1024]{0} parameter(6)
  %multiply.971.clone.1.clone.1 = f32[1024]{0} multiply(f32[1024]{0} %broadcast.1686.clone.1, f32[1024]{0} %param_6.587), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=131}
  %param_5.621 = f32[1024]{0} parameter(5)
  %constant_14727_clone_1_clone_1 = f32[] constant(0.00390625)
  %multiply.1686.clone.1.clone.1 = f32[] multiply(f32[] %subtract.308.clone.1, f32[] %constant_14727_clone_1_clone_1)
  %broadcast.2118.clone.1.clone.1 = f32[1024]{0} broadcast(f32[] %multiply.1686.clone.1.clone.1), dimensions={}
  %multiply.970.clone.1.clone.1 = f32[1024]{0} multiply(f32[1024]{0} %param_5.621, f32[1024]{0} %broadcast.2118.clone.1.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=131}
  %add.1977.clone.1.clone.1 = f32[1024]{0} add(f32[1024]{0} %multiply.971.clone.1.clone.1, f32[1024]{0} %multiply.970.clone.1.clone.1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=131}
  %reduce.318.clone.1 = f32[] reduce(f32[1024]{0} %add.1977.clone.1.clone.1, f32[] %constant_11149_clone_1_clone_1_clone_1), dimensions={0}, to_apply=%primitive_computation_add__1.15941, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=135}
  %param_8.460 = f32[1024]{0} parameter(8)
  %multiply.1187.clone.1.clone.1 = f32[1024]{0} multiply(f32[1024]{0} %broadcast.1686.clone.1, f32[1024]{0} %param_8.460), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=131}
  %param_7.568 = f32[1024]{0} parameter(7)
  %multiply.1186.clone.1.clone.1 = f32[1024]{0} multiply(f32[1024]{0} %param_7.568, f32[1024]{0} %broadcast.1685.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=131}
  %add.2033.clone.1.clone.1 = f32[1024]{0} add(f32[1024]{0} %multiply.1187.clone.1.clone.1, f32[1024]{0} %multiply.1186.clone.1.clone.1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=131}
  %reduce.326.clone.1 = f32[] reduce(f32[1024]{0} %add.2033.clone.1.clone.1, f32[] %constant_11149_clone_1_clone_1_clone_1), dimensions={0}, to_apply=%primitive_computation_add__1.14309, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=135}
  %param_10.285 = f32[1024]{0} parameter(10)
  %multiply.1133.clone.1.clone.1 = f32[1024]{0} multiply(f32[1024]{0} %broadcast.1686.clone.1, f32[1024]{0} %param_10.285), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=131}
  %param_9.304 = f32[1024]{0} parameter(9)
  %multiply.1132.clone.1.clone.1 = f32[1024]{0} multiply(f32[1024]{0} %param_9.304, f32[1024]{0} %broadcast.1685.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=131}
  %add.2019.clone.1.clone.1 = f32[1024]{0} add(f32[1024]{0} %multiply.1133.clone.1.clone.1, f32[1024]{0} %multiply.1132.clone.1.clone.1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=131}
  %reduce.324.clone.1 = f32[] reduce(f32[1024]{0} %add.2019.clone.1.clone.1, f32[] %constant_11149_clone_1_clone_1_clone_1), dimensions={0}, to_apply=%primitive_computation_add__1.14717, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=135}
  %param_18.91 = f32[1024]{0} parameter(18)
  %constant_11147_clone_1_clone_1_clone_1 = f32[] constant(0.125)
  %broadcast.1639.clone.1.clone.1 = f32[1024]{0} broadcast(f32[] %constant_11147_clone_1_clone_1_clone_1), dimensions={}
  %multiply.1441.clone.1.clone.1 = f32[1024]{0} multiply(f32[1024]{0} %param_18.91, f32[1024]{0} %broadcast.1639.clone.1.clone.1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=200}
  %param_19.92 = f32[1024]{0} parameter(19)
  %multiply.1091.clone.1.clone.1 = f32[1024]{0} multiply(f32[1024]{0} %broadcast.1686.clone.1, f32[1024]{0} %param_19.92), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=143}
  %broadcast.1642.clone.1.clone.1 = f32[1024]{0} broadcast(f32[] %subtract.308.clone.1), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=143}
  %multiply.1442.clone.1.clone.1 = f32[1024]{0} multiply(f32[1024]{0} %multiply.1441.clone.1.clone.1, f32[1024]{0} %multiply.1441.clone.1.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=126}
  %multiply.1090.clone.1.clone.1 = f32[1024]{0} multiply(f32[1024]{0} %broadcast.1642.clone.1.clone.1, f32[1024]{0} %multiply.1442.clone.1.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=143}
  %add.2007.clone.1.clone.1 = f32[1024]{0} add(f32[1024]{0} %multiply.1091.clone.1.clone.1, f32[1024]{0} %multiply.1090.clone.1.clone.1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=143}
  %param_12.296 = f32[] parameter(12)
  %broadcast.1640.clone.1.clone.1 = f32[1024]{0} broadcast(f32[] %param_12.296), dimensions={}, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
  %add.2006.clone.1.clone.1 = f32[1024]{0} add(f32[1024]{0} %add.2007.clone.1.clone.1, f32[1024]{0} %broadcast.1640.clone.1.clone.1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=145}
  %constant_11453_clone_1_clone_1_clone_1 = f32[] constant(-0.5), metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
  %broadcast.1641.clone.1.clone.1 = f32[1024]{0} broadcast(f32[] %constant_11453_clone_1_clone_1_clone_1), dimensions={}, metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
  %power.15.clone.1.clone.1 = f32[1024]{0} power(f32[1024]{0} %add.2006.clone.1.clone.1, f32[1024]{0} %broadcast.1641.clone.1.clone.1), metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=145}
  %multiply.1089.clone.1.clone.1 = f32[1024]{0} multiply(f32[1024]{0} %multiply.1441.clone.1.clone.1, f32[1024]{0} %power.15.clone.1.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=145}
  %multiply.1088.clone.1 = f32[1024]{0} multiply(f32[1024]{0} %multiply.1089.clone.1.clone.1, f32[1024]{0} %multiply.1089.clone.1.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %reduce.220.clone.1 = f32[] reduce(f32[1024]{0} %multiply.1088.clone.1, f32[] %constant_11149_clone_1_clone_1_clone_1), dimensions={0}, to_apply=%primitive_computation_add__1.15031, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %reduce.275.clone.1.clone.1 = f32[] reduce(f32[1024]{0} %multiply.1442.clone.1.clone.1, f32[] %constant_11149_clone_1_clone_1_clone_1), dimensions={0}, to_apply=%scalar_add_computation, metadata={op_type="dot_general" op_name="pmap(_multi_device_update_fn)/dot_general[ dimension_numbers=(((0,), (0,)), ((), ()))\n                                           precision=None\n                                           preferred_element_type=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %param_16.165 = f32[1024]{0} parameter(16)
  %multiply.1446.clone.1.clone.1.clone.1 = f32[1024]{0} multiply(f32[1024]{0} %param_16.165, f32[1024]{0} %broadcast.1639.clone.1.clone.1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=200}
  %param_17.95 = f32[1024]{0} parameter(17)
  %multiply.1118.clone.1.clone.1.clone.1 = f32[1024]{0} multiply(f32[1024]{0} %broadcast.1686.clone.1, f32[1024]{0} %param_17.95), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=143}
  %multiply.1447.clone.1.clone.1.clone.1 = f32[1024]{0} multiply(f32[1024]{0} %multiply.1446.clone.1.clone.1.clone.1, f32[1024]{0} %multiply.1446.clone.1.clone.1.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=126}
  %multiply.1117.clone.1.clone.1.clone.1 = f32[1024]{0} multiply(f32[1024]{0} %broadcast.1642.clone.1.clone.1, f32[1024]{0} %multiply.1447.clone.1.clone.1.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=143}
  %add.2014.clone.1.clone.1.clone.1 = f32[1024]{0} add(f32[1024]{0} %multiply.1118.clone.1.clone.1.clone.1, f32[1024]{0} %multiply.1117.clone.1.clone.1.clone.1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=143}
  %add.2013.clone.1.clone.1.clone.1 = f32[1024]{0} add(f32[1024]{0} %add.2014.clone.1.clone.1.clone.1, f32[1024]{0} %broadcast.1640.clone.1.clone.1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=145}
  %power.18.clone.1.clone.1.clone.1 = f32[1024]{0} power(f32[1024]{0} %add.2013.clone.1.clone.1.clone.1, f32[1024]{0} %broadcast.1641.clone.1.clone.1), metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=145}
  %multiply.1116.clone.1.clone.1.clone.1 = f32[1024]{0} multiply(f32[1024]{0} %multiply.1446.clone.1.clone.1.clone.1, f32[1024]{0} %power.18.clone.1.clone.1.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=145}
  %multiply.1115.clone.1.clone.1 = f32[1024]{0} multiply(f32[1024]{0} %multiply.1116.clone.1.clone.1.clone.1, f32[1024]{0} %multiply.1116.clone.1.clone.1.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %reduce.225.clone.1.clone.1 = f32[] reduce(f32[1024]{0} %multiply.1115.clone.1.clone.1, f32[] %constant_11149_clone_1_clone_1_clone_1), dimensions={0}, to_apply=%primitive_computation_add__1.14827, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %reduce.274.clone.1.clone.1.clone.1 = f32[] reduce(f32[1024]{0} %multiply.1447.clone.1.clone.1.clone.1, f32[] %constant_11149_clone_1_clone_1_clone_1), dimensions={0}, to_apply=%scalar_add_computation, metadata={op_type="dot_general" op_name="pmap(_multi_device_update_fn)/dot_general[ dimension_numbers=(((0,), (0,)), ((), ()))\n                                           precision=None\n                                           preferred_element_type=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %param_14.307 = f32[1024]{0} parameter(14)
  %multiply.1451.clone.1.clone.1.clone.1 = f32[1024]{0} multiply(f32[1024]{0} %param_14.307, f32[1024]{0} %broadcast.1639.clone.1.clone.1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=200}
  %param_15.245 = f32[1024]{0} parameter(15)
  %multiply.1145.clone.1.clone.1.clone.1 = f32[1024]{0} multiply(f32[1024]{0} %broadcast.1686.clone.1, f32[1024]{0} %param_15.245), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=143}
  %multiply.1452.clone.1.clone.1.clone.1 = f32[1024]{0} multiply(f32[1024]{0} %multiply.1451.clone.1.clone.1.clone.1, f32[1024]{0} %multiply.1451.clone.1.clone.1.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=126}
  %multiply.1144.clone.1.clone.1.clone.1 = f32[1024]{0} multiply(f32[1024]{0} %broadcast.1642.clone.1.clone.1, f32[1024]{0} %multiply.1452.clone.1.clone.1.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=143}
  %add.2021.clone.1.clone.1.clone.1 = f32[1024]{0} add(f32[1024]{0} %multiply.1145.clone.1.clone.1.clone.1, f32[1024]{0} %multiply.1144.clone.1.clone.1.clone.1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=143}
  %add.2020.clone.1.clone.1.clone.1 = f32[1024]{0} add(f32[1024]{0} %add.2021.clone.1.clone.1.clone.1, f32[1024]{0} %broadcast.1640.clone.1.clone.1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=145}
  %power.21.clone.1.clone.1.clone.1 = f32[1024]{0} power(f32[1024]{0} %add.2020.clone.1.clone.1.clone.1, f32[1024]{0} %broadcast.1641.clone.1.clone.1), metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=145}
  %multiply.1143.clone.1.clone.1.clone.1 = f32[1024]{0} multiply(f32[1024]{0} %multiply.1451.clone.1.clone.1.clone.1, f32[1024]{0} %power.21.clone.1.clone.1.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=145}
  %multiply.1142.clone.1.clone.1 = f32[1024]{0} multiply(f32[1024]{0} %multiply.1143.clone.1.clone.1.clone.1, f32[1024]{0} %multiply.1143.clone.1.clone.1.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %reduce.229.clone.1.clone.1 = f32[] reduce(f32[1024]{0} %multiply.1142.clone.1.clone.1, f32[] %constant_11149_clone_1_clone_1_clone_1), dimensions={0}, to_apply=%primitive_computation_add__1.14623, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %reduce.273.clone.1.clone.1.clone.1 = f32[] reduce(f32[1024]{0} %multiply.1452.clone.1.clone.1.clone.1, f32[] %constant_11149_clone_1_clone_1_clone_1), dimensions={0}, to_apply=%scalar_add_computation, metadata={op_type="dot_general" op_name="pmap(_multi_device_update_fn)/dot_general[ dimension_numbers=(((0,), (0,)), ((), ()))\n                                           precision=None\n                                           preferred_element_type=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %param_11.271 = f32[1024]{0} parameter(11)
  %multiply.1456.clone.1.clone.1.clone.1 = f32[1024]{0} multiply(f32[1024]{0} %param_11.271, f32[1024]{0} %broadcast.1639.clone.1.clone.1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=200}
  %param_13.318 = f32[1024]{0} parameter(13)
  %multiply.1172.clone.1.clone.1.clone.1 = f32[1024]{0} multiply(f32[1024]{0} %broadcast.1686.clone.1, f32[1024]{0} %param_13.318), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=143}
  %multiply.1457.clone.1.clone.1.clone.1 = f32[1024]{0} multiply(f32[1024]{0} %multiply.1456.clone.1.clone.1.clone.1, f32[1024]{0} %multiply.1456.clone.1.clone.1.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=126}
  %multiply.1171.clone.1.clone.1.clone.1 = f32[1024]{0} multiply(f32[1024]{0} %broadcast.1642.clone.1.clone.1, f32[1024]{0} %multiply.1457.clone.1.clone.1.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=143}
  %add.2028.clone.1.clone.1.clone.1 = f32[1024]{0} add(f32[1024]{0} %multiply.1172.clone.1.clone.1.clone.1, f32[1024]{0} %multiply.1171.clone.1.clone.1.clone.1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=143}
  %add.2027.clone.1.clone.1.clone.1 = f32[1024]{0} add(f32[1024]{0} %add.2028.clone.1.clone.1.clone.1, f32[1024]{0} %broadcast.1640.clone.1.clone.1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=145}
  %power.24.clone.1.clone.1.clone.1 = f32[1024]{0} power(f32[1024]{0} %add.2027.clone.1.clone.1.clone.1, f32[1024]{0} %broadcast.1641.clone.1.clone.1), metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=145}
  %multiply.1170.clone.1.clone.1.clone.1 = f32[1024]{0} multiply(f32[1024]{0} %multiply.1456.clone.1.clone.1.clone.1, f32[1024]{0} %power.24.clone.1.clone.1.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=145}
  %multiply.1169.clone.1.clone.1 = f32[1024]{0} multiply(f32[1024]{0} %multiply.1170.clone.1.clone.1.clone.1, f32[1024]{0} %multiply.1170.clone.1.clone.1.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %reduce.233.clone.1.clone.1 = f32[] reduce(f32[1024]{0} %multiply.1169.clone.1.clone.1, f32[] %constant_11149_clone_1_clone_1_clone_1), dimensions={0}, to_apply=%primitive_computation_add__1.14419, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %reduce.272.clone.1.clone.1.clone.1 = f32[] reduce(f32[1024]{0} %multiply.1457.clone.1.clone.1.clone.1, f32[] %constant_11149_clone_1_clone_1_clone_1), dimensions={0}, to_apply=%scalar_add_computation, metadata={op_type="dot_general" op_name="pmap(_multi_device_update_fn)/dot_general[ dimension_numbers=(((0,), (0,)), ((), ()))\n                                           precision=None\n                                           preferred_element_type=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  ROOT %tuple.705 = (f32[], f32[1024]{0}, f32[], f32[1024]{0}, f32[], /*index=5*/f32[1024]{0}, f32[], f32[1024]{0}, f32[], f32[1024]{0}, /*index=10*/f32[], f32[1024]{0}, f32[1024]{0}, f32[], f32[], /*index=15*/f32[1024]{0}, f32[1024]{0}, f32[], f32[], f32[1024]{0}, /*index=20*/f32[1024]{0}, f32[], f32[], f32[1024]{0}, f32[1024]{0}, /*index=25*/f32[]) tuple(f32[] %reduce.325, f32[1024]{0} %add.2026.clone.1, f32[] %reduce.323.clone.1, f32[1024]{0} %add.2012.clone.1.clone.1, f32[] %reduce.318.clone.1, /*index=5*/f32[1024]{0} %add.1977.clone.1.clone.1, f32[] %reduce.326.clone.1, f32[1024]{0} %add.2033.clone.1.clone.1, f32[] %reduce.324.clone.1, f32[1024]{0} %add.2019.clone.1.clone.1, /*index=10*/f32[] %reduce.220.clone.1, f32[1024]{0} %multiply.1089.clone.1.clone.1, f32[1024]{0} %add.2007.clone.1.clone.1, f32[] %reduce.275.clone.1.clone.1, f32[] %reduce.225.clone.1.clone.1, /*index=15*/f32[1024]{0} %multiply.1116.clone.1.clone.1.clone.1, f32[1024]{0} %add.2014.clone.1.clone.1.clone.1, f32[] %reduce.274.clone.1.clone.1.clone.1, f32[] %reduce.229.clone.1.clone.1, f32[1024]{0} %multiply.1143.clone.1.clone.1.clone.1, /*index=20*/f32[1024]{0} %add.2021.clone.1.clone.1.clone.1, f32[] %reduce.273.clone.1.clone.1.clone.1, f32[] %reduce.233.clone.1.clone.1, f32[1024]{0} %multiply.1170.clone.1.clone.1.clone.1, f32[1024]{0} %add.2028.clone.1.clone.1.clone.1, /*index=25*/f32[] %reduce.272.clone.1.clone.1.clone.1)
}

%primitive_computation_add__1.13979 (parameter.13980: f32[], parameter.13981: f32[]) -> f32[] {
  %parameter.13980 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.13981 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.13982 = f32[] add(f32[] %parameter.13980, f32[] %parameter.13981), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.16051 (parameter.16052: f32[], parameter.16053: f32[]) -> f32[] {
  %parameter.16052 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.16053 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.16054 = f32[] add(f32[] %parameter.16052, f32[] %parameter.16053), metadata={op_type="add" op_name="add"}
}

%fused_computation.759 (param_0.2298: f32[256], param_1.2926: f32[], param_2.2762: f32[256], param_3.2626: f32[256], param_4.1443: f32[], param_5.619: f32[256]) -> (f32[], f32[256], f32[], f32[256], f32[256], /*index=5*/f32[]) {
  %param_1.2926 = f32[] parameter(1)
  %broadcast.1732.clone.1 = f32[256]{0} broadcast(f32[] %param_1.2926), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=131}
  %param_2.2762 = f32[256]{0} parameter(2)
  %multiply.1232.clone.1 = f32[256]{0} multiply(f32[256]{0} %broadcast.1732.clone.1, f32[256]{0} %param_2.2762), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=131}
  %param_0.2298 = f32[256]{0} parameter(0)
  %constant_11515_clone_1 = f32[] constant(1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/metrics.py" source_line=617}
  %subtract.314.clone.1 = f32[] subtract(f32[] %constant_11515_clone_1, f32[] %param_1.2926), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=124}
  %constant_11512_clone_1 = f32[] constant(0.0009765625)
  %multiply.1464.clone.1 = f32[] multiply(f32[] %subtract.314.clone.1, f32[] %constant_11512_clone_1)
  %broadcast.1733.clone.1 = f32[256]{0} broadcast(f32[] %multiply.1464.clone.1), dimensions={}
  %multiply.1231.clone.1 = f32[256]{0} multiply(f32[256]{0} %param_0.2298, f32[256]{0} %broadcast.1733.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=131}
  %add.2044.clone.1 = f32[256]{0} add(f32[256]{0} %multiply.1232.clone.1, f32[256]{0} %multiply.1231.clone.1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=131}
  %constant_11199_clone_1_clone_1 = f32[] constant(0)
  %reduce.328 = f32[] reduce(f32[256]{0} %add.2044.clone.1, f32[] %constant_11199_clone_1_clone_1), dimensions={0}, to_apply=%primitive_computation_add__1.13979, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=135}
  %param_3.2626 = f32[256]{0} parameter(3)
  %constant_11196_clone_1_clone_1 = f32[] constant(0.125)
  %broadcast.1561.clone.1.clone.1 = f32[256]{0} broadcast(f32[] %constant_11196_clone_1_clone_1), dimensions={}
  %multiply.1425.clone.1.clone.1 = f32[256]{0} multiply(f32[256]{0} %param_3.2626, f32[256]{0} %broadcast.1561.clone.1.clone.1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=200}
  %param_5.619 = f32[256]{0} parameter(5)
  %multiply.956.clone.1.clone.1 = f32[256]{0} multiply(f32[256]{0} %broadcast.1732.clone.1, f32[256]{0} %param_5.619), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=143}
  %broadcast.1291.clone.1.clone.1 = f32[256]{0} broadcast(f32[] %subtract.314.clone.1), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=143}
  %multiply.1426.clone.1.clone.1 = f32[256]{0} multiply(f32[256]{0} %multiply.1425.clone.1.clone.1, f32[256]{0} %multiply.1425.clone.1.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=126}
  %multiply.955.clone.1.clone.1 = f32[256]{0} multiply(f32[256]{0} %broadcast.1291.clone.1.clone.1, f32[256]{0} %multiply.1426.clone.1.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=143}
  %add.1973.clone.1.clone.1 = f32[256]{0} add(f32[256]{0} %multiply.956.clone.1.clone.1, f32[256]{0} %multiply.955.clone.1.clone.1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=143}
  %param_4.1443 = f32[] parameter(4)
  %broadcast.1562.clone.1.clone.1 = f32[256]{0} broadcast(f32[] %param_4.1443), dimensions={}, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  %add.1972.clone.1.clone.1 = f32[256]{0} add(f32[256]{0} %add.1973.clone.1.clone.1, f32[256]{0} %broadcast.1562.clone.1.clone.1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=145}
  %constant_11214_clone_1_clone_1 = f32[] constant(-0.5), metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
  %broadcast.1560.clone.1.clone.1 = f32[256]{0} broadcast(f32[] %constant_11214_clone_1_clone_1), dimensions={}, metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
  %power.0.clone.1.clone.1 = f32[256]{0} power(f32[256]{0} %add.1972.clone.1.clone.1, f32[256]{0} %broadcast.1560.clone.1.clone.1), metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=145}
  %multiply.954.clone.1.clone.1 = f32[256]{0} multiply(f32[256]{0} %multiply.1425.clone.1.clone.1, f32[256]{0} %power.0.clone.1.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=145}
  %multiply.953.clone.1 = f32[256]{0} multiply(f32[256]{0} %multiply.954.clone.1.clone.1, f32[256]{0} %multiply.954.clone.1.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %reduce.200.clone.1 = f32[] reduce(f32[256]{0} %multiply.953.clone.1, f32[] %constant_11199_clone_1_clone_1), dimensions={0}, to_apply=%primitive_computation_add__1.16051, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %reduce.280.clone.1.clone.1 = f32[] reduce(f32[256]{0} %multiply.1426.clone.1.clone.1, f32[] %constant_11199_clone_1_clone_1), dimensions={0}, to_apply=%scalar_add_computation, metadata={op_type="dot_general" op_name="pmap(_multi_device_update_fn)/dot_general[ dimension_numbers=(((0,), (0,)), ((), ()))\n                                           precision=None\n                                           preferred_element_type=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  ROOT %tuple.714 = (f32[], f32[256]{0}, f32[], f32[256]{0}, f32[256]{0}, /*index=5*/f32[]) tuple(f32[] %reduce.328, f32[256]{0} %add.2044.clone.1, f32[] %reduce.200.clone.1, f32[256]{0} %multiply.954.clone.1.clone.1, f32[256]{0} %add.1973.clone.1.clone.1, /*index=5*/f32[] %reduce.280.clone.1.clone.1)
}

%primitive_computation_add__1.13163 (parameter.13164: f32[], parameter.13165: f32[]) -> f32[] {
  %parameter.13164 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.13165 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.13166 = f32[] add(f32[] %parameter.13164, f32[] %parameter.13165), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.15737 (parameter.15738: f32[], parameter.15739: f32[]) -> f32[] {
  %parameter.15738 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.15739 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.15740 = f32[] add(f32[] %parameter.15738, f32[] %parameter.15739), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.13367 (parameter.13368: f32[], parameter.13369: f32[]) -> f32[] {
  %parameter.13368 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.13369 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.13370 = f32[] add(f32[] %parameter.13368, f32[] %parameter.13369), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.14105 (parameter.14106: f32[], parameter.14107: f32[]) -> f32[] {
  %parameter.14106 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.14107 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.14108 = f32[] add(f32[] %parameter.14106, f32[] %parameter.14107), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.15533 (parameter.15534: f32[], parameter.15535: f32[]) -> f32[] {
  %parameter.15534 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.15535 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.15536 = f32[] add(f32[] %parameter.15534, f32[] %parameter.15535), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.15329 (parameter.15330: f32[], parameter.15331: f32[]) -> f32[] {
  %parameter.15330 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.15331 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.15332 = f32[] add(f32[] %parameter.15330, f32[] %parameter.15331), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.13775 (parameter.13776: f32[], parameter.13777: f32[]) -> f32[] {
  %parameter.13776 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.13777 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.13778 = f32[] add(f32[] %parameter.13776, f32[] %parameter.13777), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.15125 (parameter.15126: f32[], parameter.15127: f32[]) -> f32[] {
  %parameter.15126 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.15127 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.15128 = f32[] add(f32[] %parameter.15126, f32[] %parameter.15127), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.13571 (parameter.13572: f32[], parameter.13573: f32[]) -> f32[] {
  %parameter.13572 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.13573 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.13574 = f32[] add(f32[] %parameter.13572, f32[] %parameter.13573), metadata={op_type="add" op_name="add"}
}

%fused_computation.763 (param_0.2301: f32[2048], param_1.2927: f32[], param_2.2763: f32[2048], param_3.2627: f32[2048], param_4.1444: f32[2048], param_5.620: f32[2048], param_6.586: f32[2048], param_7.567: f32[2048], param_8.459: f32[2048], param_9.303: f32[2048], param_10.284: f32[2048], param_11.270: f32[2048], param_12.295: f32[2048], param_13.317: f32[2048], param_14.306: f32[2048], param_15.244: f32[2048], param_16.164: f32[2048], param_17.94: f32[2048], param_18.90: f32[2048]) -> (f32[], f32[2048], f32[], f32[2048], f32[], /*index=5*/f32[2048], f32[], f32[2048], f32[], f32[2048], /*index=10*/f32[], f32[2048], f32[], f32[2048], f32[], /*index=15*/f32[2048], f32[], f32[2048]) {
  %param_1.2927 = f32[] parameter(1)
  %broadcast.1805.clone.1 = f32[2048]{0} broadcast(f32[] %param_1.2927), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=131}
  %param_2.2763 = f32[2048]{0} parameter(2)
  %multiply.1344.clone.1 = f32[2048]{0} multiply(f32[2048]{0} %broadcast.1805.clone.1, f32[2048]{0} %param_2.2763), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=131}
  %param_0.2301 = f32[2048]{0} parameter(0)
  %constant_14595_clone_1 = f32[] constant(1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/metrics.py" source_line=617}
  %subtract.642.clone.1 = f32[] subtract(f32[] %constant_14595_clone_1, f32[] %param_1.2927), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=124}
  %constant_14594_clone_1 = f32[] constant(0.000244140625)
  %multiply.1570.clone.1 = f32[] multiply(f32[] %subtract.642.clone.1, f32[] %constant_14594_clone_1)
  %broadcast.2022.clone.1 = f32[2048]{0} broadcast(f32[] %multiply.1570.clone.1), dimensions={}
  %multiply.1343.clone.1 = f32[2048]{0} multiply(f32[2048]{0} %param_0.2301, f32[2048]{0} %broadcast.2022.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=131}
  %add.2073.clone.1 = f32[2048]{0} add(f32[2048]{0} %multiply.1344.clone.1, f32[2048]{0} %multiply.1343.clone.1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=131}
  %constant_14922 = f32[] constant(0)
  %reduce.332 = f32[] reduce(f32[2048]{0} %add.2073.clone.1, f32[] %constant_14922), dimensions={0}, to_apply=%primitive_computation_add__1.13163, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=135}
  %param_4.1444 = f32[2048]{0} parameter(4)
  %multiply.998.clone.1.clone.1 = f32[2048]{0} multiply(f32[2048]{0} %broadcast.1805.clone.1, f32[2048]{0} %param_4.1444), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=131}
  %param_3.2627 = f32[2048]{0} parameter(3)
  %multiply.997.clone.1.clone.1 = f32[2048]{0} multiply(f32[2048]{0} %param_3.2627, f32[2048]{0} %broadcast.2022.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=131}
  %add.1984.clone.1.clone.1 = f32[2048]{0} add(f32[2048]{0} %multiply.998.clone.1.clone.1, f32[2048]{0} %multiply.997.clone.1.clone.1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=131}
  %reduce.319.clone.1 = f32[] reduce(f32[2048]{0} %add.1984.clone.1.clone.1, f32[] %constant_14922), dimensions={0}, to_apply=%primitive_computation_add__1.15737, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=135}
  %param_6.586 = f32[2048]{0} parameter(6)
  %multiply.1316.clone.1.clone.1 = f32[2048]{0} multiply(f32[2048]{0} %broadcast.1805.clone.1, f32[2048]{0} %param_6.586), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=131}
  %param_5.620 = f32[2048]{0} parameter(5)
  %multiply.1315.clone.1.clone.1 = f32[2048]{0} multiply(f32[2048]{0} %param_5.620, f32[2048]{0} %broadcast.2022.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=131}
  %add.2066.clone.1.clone.1 = f32[2048]{0} add(f32[2048]{0} %multiply.1316.clone.1.clone.1, f32[2048]{0} %multiply.1315.clone.1.clone.1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=131}
  %reduce.331.clone.1 = f32[] reduce(f32[2048]{0} %add.2066.clone.1.clone.1, f32[] %constant_14922), dimensions={0}, to_apply=%primitive_computation_add__1.13367, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=135}
  %param_8.459 = f32[2048]{0} parameter(8)
  %multiply.1214.clone.1.clone.1 = f32[2048]{0} multiply(f32[2048]{0} %broadcast.1805.clone.1, f32[2048]{0} %param_8.459), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=131}
  %param_7.567 = f32[2048]{0} parameter(7)
  %multiply.1213.clone.1.clone.1 = f32[2048]{0} multiply(f32[2048]{0} %param_7.567, f32[2048]{0} %broadcast.2022.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=131}
  %add.2039.clone.1.clone.1 = f32[2048]{0} add(f32[2048]{0} %multiply.1214.clone.1.clone.1, f32[2048]{0} %multiply.1213.clone.1.clone.1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=131}
  %reduce.327.clone.1 = f32[] reduce(f32[2048]{0} %add.2039.clone.1.clone.1, f32[] %constant_14922), dimensions={0}, to_apply=%primitive_computation_add__1.14105, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=135}
  %param_10.284 = f32[2048]{0} parameter(10)
  %multiply.1025.clone.1.clone.1 = f32[2048]{0} multiply(f32[2048]{0} %broadcast.1805.clone.1, f32[2048]{0} %param_10.284), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=131}
  %param_9.303 = f32[2048]{0} parameter(9)
  %multiply.1024.clone.1.clone.1 = f32[2048]{0} multiply(f32[2048]{0} %param_9.303, f32[2048]{0} %broadcast.2022.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=131}
  %add.1991.clone.1.clone.1 = f32[2048]{0} add(f32[2048]{0} %multiply.1025.clone.1.clone.1, f32[2048]{0} %multiply.1024.clone.1.clone.1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=131}
  %reduce.320.clone.1 = f32[] reduce(f32[2048]{0} %add.1991.clone.1.clone.1, f32[] %constant_14922), dimensions={0}, to_apply=%primitive_computation_add__1.15533, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=135}
  %param_12.295 = f32[2048]{0} parameter(12)
  %multiply.1052.clone.1.clone.1 = f32[2048]{0} multiply(f32[2048]{0} %broadcast.1805.clone.1, f32[2048]{0} %param_12.295), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=131}
  %param_11.270 = f32[2048]{0} parameter(11)
  %multiply.1051.clone.1.clone.1 = f32[2048]{0} multiply(f32[2048]{0} %param_11.270, f32[2048]{0} %broadcast.2022.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=131}
  %add.1998.clone.1.clone.1 = f32[2048]{0} add(f32[2048]{0} %multiply.1052.clone.1.clone.1, f32[2048]{0} %multiply.1051.clone.1.clone.1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=131}
  %reduce.321.clone.1 = f32[] reduce(f32[2048]{0} %add.1998.clone.1.clone.1, f32[] %constant_14922), dimensions={0}, to_apply=%primitive_computation_add__1.15329, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=135}
  %param_14.306 = f32[2048]{0} parameter(14)
  %multiply.1260.clone.1.clone.1 = f32[2048]{0} multiply(f32[2048]{0} %broadcast.1805.clone.1, f32[2048]{0} %param_14.306), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=131}
  %param_13.317 = f32[2048]{0} parameter(13)
  %multiply.1259.clone.1.clone.1 = f32[2048]{0} multiply(f32[2048]{0} %param_13.317, f32[2048]{0} %broadcast.2022.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=131}
  %add.2052.clone.1.clone.1 = f32[2048]{0} add(f32[2048]{0} %multiply.1260.clone.1.clone.1, f32[2048]{0} %multiply.1259.clone.1.clone.1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=131}
  %reduce.329.clone.1 = f32[] reduce(f32[2048]{0} %add.2052.clone.1.clone.1, f32[] %constant_14922), dimensions={0}, to_apply=%primitive_computation_add__1.13775, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=135}
  %param_16.164 = f32[2048]{0} parameter(16)
  %multiply.1079.clone.1.clone.1 = f32[2048]{0} multiply(f32[2048]{0} %broadcast.1805.clone.1, f32[2048]{0} %param_16.164), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=131}
  %param_15.244 = f32[2048]{0} parameter(15)
  %multiply.1078.clone.1.clone.1 = f32[2048]{0} multiply(f32[2048]{0} %param_15.244, f32[2048]{0} %broadcast.2022.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=131}
  %add.2005.clone.1.clone.1 = f32[2048]{0} add(f32[2048]{0} %multiply.1079.clone.1.clone.1, f32[2048]{0} %multiply.1078.clone.1.clone.1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=131}
  %reduce.322.clone.1 = f32[] reduce(f32[2048]{0} %add.2005.clone.1.clone.1, f32[] %constant_14922), dimensions={0}, to_apply=%primitive_computation_add__1.15125, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=135}
  %param_18.90 = f32[2048]{0} parameter(18)
  %multiply.1289.clone.1.clone.1 = f32[2048]{0} multiply(f32[2048]{0} %broadcast.1805.clone.1, f32[2048]{0} %param_18.90), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=131}
  %param_17.94 = f32[2048]{0} parameter(17)
  %multiply.1288.clone.1.clone.1 = f32[2048]{0} multiply(f32[2048]{0} %param_17.94, f32[2048]{0} %broadcast.2022.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=131}
  %add.2059.clone.1.clone.1 = f32[2048]{0} add(f32[2048]{0} %multiply.1289.clone.1.clone.1, f32[2048]{0} %multiply.1288.clone.1.clone.1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=131}
  %reduce.330.clone.1 = f32[] reduce(f32[2048]{0} %add.2059.clone.1.clone.1, f32[] %constant_14922), dimensions={0}, to_apply=%primitive_computation_add__1.13571, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=135}
  ROOT %tuple.713 = (f32[], f32[2048]{0}, f32[], f32[2048]{0}, f32[], /*index=5*/f32[2048]{0}, f32[], f32[2048]{0}, f32[], f32[2048]{0}, /*index=10*/f32[], f32[2048]{0}, f32[], f32[2048]{0}, f32[], /*index=15*/f32[2048]{0}, f32[], f32[2048]{0}) tuple(f32[] %reduce.332, f32[2048]{0} %add.2073.clone.1, f32[] %reduce.319.clone.1, f32[2048]{0} %add.1984.clone.1.clone.1, f32[] %reduce.331.clone.1, /*index=5*/f32[2048]{0} %add.2066.clone.1.clone.1, f32[] %reduce.327.clone.1, f32[2048]{0} %add.2039.clone.1.clone.1, f32[] %reduce.320.clone.1, f32[2048]{0} %add.1991.clone.1.clone.1, /*index=10*/f32[] %reduce.321.clone.1, f32[2048]{0} %add.1998.clone.1.clone.1, f32[] %reduce.329.clone.1, f32[2048]{0} %add.2052.clone.1.clone.1, f32[] %reduce.322.clone.1, /*index=15*/f32[2048]{0} %add.2005.clone.1.clone.1, f32[] %reduce.330.clone.1, f32[2048]{0} %add.2059.clone.1.clone.1)
}

%primitive_computation_add__1.13037 (parameter.13038: f32[], parameter.13039: f32[]) -> f32[] {
  %parameter.13038 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.13039 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.13040 = f32[] add(f32[] %parameter.13038, f32[] %parameter.13039), metadata={op_type="add" op_name="add"}
}

%fused_computation.764 (param_0.2320: f32[32000], param_1.2928: f32[], param_2.2764: f32[32000]) -> (f32[], f32[32000]) {
  %param_1.2928 = f32[] parameter(1)
  %broadcast.1420.clone.1 = f32[32000]{0} broadcast(f32[] %param_1.2928), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=131}
  %param_2.2764 = f32[32000]{0} parameter(2)
  %multiply.1363.clone.1 = f32[32000]{0} multiply(f32[32000]{0} %broadcast.1420.clone.1, f32[32000]{0} %param_2.2764), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=131}
  %param_0.2320 = f32[32000]{0} parameter(0)
  %constant_11716_clone_1 = f32[] constant(1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/metrics.py" source_line=617}
  %subtract.322.clone.1 = f32[] subtract(f32[] %constant_11716_clone_1, f32[] %param_1.2928), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=124}
  %constant_11714_clone_1 = f32[] constant(0.0009765625)
  %multiply.1477.clone.1 = f32[] multiply(f32[] %subtract.322.clone.1, f32[] %constant_11714_clone_1)
  %broadcast.1419.clone.1 = f32[32000]{0} broadcast(f32[] %multiply.1477.clone.1), dimensions={}
  %multiply.1362.clone.1 = f32[32000]{0} multiply(f32[32000]{0} %param_0.2320, f32[32000]{0} %broadcast.1419.clone.1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=131}
  %add.2077.clone.1 = f32[32000]{0} add(f32[32000]{0} %multiply.1363.clone.1, f32[32000]{0} %multiply.1362.clone.1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=131}
  %constant_14944 = f32[] constant(0)
  %reduce.333 = f32[] reduce(f32[32000]{0} %add.2077.clone.1, f32[] %constant_14944), dimensions={0}, to_apply=%primitive_computation_add__1.13037, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=135}
  ROOT %tuple.661 = (f32[], f32[32000]{0}) tuple(f32[] %reduce.333, f32[32000]{0} %add.2077.clone.1)
}

%primitive_computation_add__1.7599 (parameter.7600: f32[], parameter.7601: f32[]) -> f32[] {
  %parameter.7600 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.7601 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.7602 = f32[] add(f32[] %parameter.7600, f32[] %parameter.7601), metadata={op_type="add" op_name="add"}
}

%fused_computation.765 (param_0.2334: f32[16,64], param_1.2930: f32[16,64], param_2.2766: f32[16,64], param_3.2629: f32[256], param_4.1446: f32[1024,256]) -> (f32[16,64], f32[16,64,256]) {
  %param_4.1446 = f32[1024,256]{1,0} parameter(4)
  %bitcast.1011.clone.1 = f32[16,64,256]{2,1,0} bitcast(f32[1024,256]{1,0} %param_4.1446), metadata={op_type="dot_general" op_name="pmap(_multi_device_update_fn)/dot_general[ dimension_numbers=(((2,), (0,)), ((), ()))\n                                           precision=None\n                                           preferred_element_type=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/core.py" source_line=96}
  %param_3.2629 = f32[256]{0} parameter(3)
  %broadcast.1930.clone.1 = f32[16,64,256]{2,1,0} broadcast(f32[256]{0} %param_3.2629), dimensions={2}, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/core.py" source_line=96}
  %add.3048.clone.1 = f32[16,64,256]{2,1,0} add(f32[16,64,256]{2,1,0} %bitcast.1011.clone.1, f32[16,64,256]{2,1,0} %broadcast.1930.clone.1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/core.py" source_line=96}
  %param_2.2766 = f32[16,64]{1,0} parameter(2)
  %bitcast.1010.clone.1 = f32[16,64,1]{1,0,2} bitcast(f32[16,64]{1,0} %param_2.2766), metadata={op_type="log" op_name="pmap(_multi_device_update_fn)/log" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=94}
  %param_1.2930 = f32[16,64]{1,0} parameter(1)
  %bitcast.1009.clone.1 = f32[16,64,1]{1,0,2} bitcast(f32[16,64]{1,0} %param_1.2930), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/broadcast_in_dim[ broadcast_dimensions=(0, 1)\n                                                shape=(16, 64, 1) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=94}
  %is-finite.16.clone.1 = pred[16,64,1]{1,0,2} is-finite(f32[16,64,1]{1,0,2} %bitcast.1009.clone.1), metadata={op_type="is_finite" op_name="pmap(_multi_device_update_fn)/is_finite" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=94}
  %constant_14466_clone_1 = f32[] constant(0)
  %broadcast.1929.clone.1 = f32[16,64,1]{1,0,2} broadcast(f32[] %constant_14466_clone_1), dimensions={}, metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/broadcast_in_dim[ broadcast_dimensions=(  )\n                                                shape=(16, 64, 1) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=94}
  %select.1990.clone.1 = f32[16,64,1]{1,0,2} select(pred[16,64,1]{1,0,2} %is-finite.16.clone.1, f32[16,64,1]{1,0,2} %bitcast.1009.clone.1, f32[16,64,1]{1,0,2} %broadcast.1929.clone.1), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=94}
  %add.3047.clone.1 = f32[16,64,1]{1,0,2} add(f32[16,64,1]{1,0,2} %bitcast.1010.clone.1, f32[16,64,1]{1,0,2} %select.1990.clone.1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=94}
  %bitcast.1008.clone.1 = f32[16,64]{1,0} bitcast(f32[16,64,1]{1,0,2} %add.3047.clone.1), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/core.py" source_line=794}
  %broadcast.1928.clone.1 = f32[16,64,256]{2,1,0} broadcast(f32[16,64]{1,0} %bitcast.1008.clone.1), dimensions={0,1}, metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/core.py" source_line=794}
  %subtract.622.clone.1 = f32[16,64,256]{2,1,0} subtract(f32[16,64,256]{2,1,0} %add.3048.clone.1, f32[16,64,256]{2,1,0} %broadcast.1928.clone.1), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/core.py" source_line=794}
  %param_0.2334 = f32[16,64]{1,0} parameter(0)
  %bitcast.1013.clone.1 = f32[16,64,1]{1,0,2} bitcast(f32[16,64]{1,0} %param_0.2334), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/broadcast_in_dim[ broadcast_dimensions=(0, 1)\n                                                shape=(16, 64, 1) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=94}
  %is-finite.18.clone.1 = pred[16,64,1]{1,0,2} is-finite(f32[16,64,1]{1,0,2} %bitcast.1013.clone.1), metadata={op_type="is_finite" op_name="pmap(_multi_device_update_fn)/is_finite" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=94}
  %select.1992.clone.1 = f32[16,64,1]{1,0,2} select(pred[16,64,1]{1,0,2} %is-finite.18.clone.1, f32[16,64,1]{1,0,2} %bitcast.1013.clone.1, f32[16,64,1]{1,0,2} %broadcast.1929.clone.1), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=94}
  %bitcast.737.clone.1 = f32[16,64]{1,0} bitcast(f32[16,64,1]{1,0,2} %select.1992.clone.1), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=94}
  %broadcast.1427.clone.1 = f32[16,64,256]{2,1,0} broadcast(f32[16,64]{1,0} %bitcast.737.clone.1), dimensions={0,1}, metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=94}
  %subtract.288.clone.1 = f32[16,64,256]{2,1,0} subtract(f32[16,64,256]{2,1,0} %subtract.622.clone.1, f32[16,64,256]{2,1,0} %broadcast.1427.clone.1), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=94}
  %exponential.135.clone.1 = f32[16,64,256]{2,1,0} exponential(f32[16,64,256]{2,1,0} %subtract.288.clone.1), metadata={op_type="exp" op_name="pmap(_multi_device_update_fn)/exp" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=94}
  %reduce.334 = f32[16,64]{1,0} reduce(f32[16,64,256]{2,1,0} %exponential.135.clone.1, f32[] %constant_14466_clone_1), dimensions={2}, to_apply=%primitive_computation_add__1.7599, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(2,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=94}
  ROOT %tuple.720 = (f32[16,64]{1,0}, f32[16,64,256]{2,1,0}) tuple(f32[16,64]{1,0} %reduce.334, f32[16,64,256]{2,1,0} %exponential.135.clone.1)
}

%primitive_computation_add__1.7494 (parameter.7495: f32[], parameter.7496: f32[]) -> f32[] {
  %parameter.7495 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.7496 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.7497 = f32[] add(f32[] %parameter.7495, f32[] %parameter.7496), metadata={op_type="add" op_name="add"}
}

%fused_computation.766 (param_0.2336: f32[16,64], param_1.2932: f32[256], param_2.2768: f32[1024,256]) -> (f32[16,64], f32[16,64,256]) {
  %param_2.2768 = f32[1024,256]{1,0} parameter(2)
  %bitcast.983.clone.1 = f32[16,64,256]{2,1,0} bitcast(f32[1024,256]{1,0} %param_2.2768), metadata={op_type="dot_general" op_name="pmap(_multi_device_update_fn)/dot_general[ dimension_numbers=(((2,), (0,)), ((), ()))\n                                           precision=None\n                                           preferred_element_type=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/core.py" source_line=96}
  %param_1.2932 = f32[256]{0} parameter(1)
  %broadcast.1905.clone.1 = f32[16,64,256]{2,1,0} broadcast(f32[256]{0} %param_1.2932), dimensions={2}, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/core.py" source_line=96}
  %add.3036.clone.1 = f32[16,64,256]{2,1,0} add(f32[16,64,256]{2,1,0} %bitcast.983.clone.1, f32[16,64,256]{2,1,0} %broadcast.1905.clone.1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/core.py" source_line=96}
  %param_0.2336 = f32[16,64]{1,0} parameter(0)
  %bitcast.985.clone.1 = f32[16,64,1]{1,0,2} bitcast(f32[16,64]{1,0} %param_0.2336), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/broadcast_in_dim[ broadcast_dimensions=(0, 1)\n                                                shape=(16, 64, 1) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=94}
  %is-finite.8.clone.1 = pred[16,64,1]{1,0,2} is-finite(f32[16,64,1]{1,0,2} %bitcast.985.clone.1), metadata={op_type="is_finite" op_name="pmap(_multi_device_update_fn)/is_finite" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=94}
  %constant_14448_clone_1 = f32[] constant(0)
  %broadcast.1907.clone.1 = f32[16,64,1]{1,0,2} broadcast(f32[] %constant_14448_clone_1), dimensions={}, metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/broadcast_in_dim[ broadcast_dimensions=(  )\n                                                shape=(16, 64, 1) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=94}
  %select.1981.clone.1 = f32[16,64,1]{1,0,2} select(pred[16,64,1]{1,0,2} %is-finite.8.clone.1, f32[16,64,1]{1,0,2} %bitcast.985.clone.1, f32[16,64,1]{1,0,2} %broadcast.1907.clone.1), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=94}
  %bitcast.741.clone.1 = f32[16,64]{1,0} bitcast(f32[16,64,1]{1,0,2} %select.1981.clone.1), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=94}
  %broadcast.1429.clone.1 = f32[16,64,256]{2,1,0} broadcast(f32[16,64]{1,0} %bitcast.741.clone.1), dimensions={0,1}, metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=94}
  %subtract.290.clone.1 = f32[16,64,256]{2,1,0} subtract(f32[16,64,256]{2,1,0} %add.3036.clone.1, f32[16,64,256]{2,1,0} %broadcast.1429.clone.1), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=94}
  %exponential.136.clone.1 = f32[16,64,256]{2,1,0} exponential(f32[16,64,256]{2,1,0} %subtract.290.clone.1), metadata={op_type="exp" op_name="pmap(_multi_device_update_fn)/exp" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=94}
  %reduce.335 = f32[16,64]{1,0} reduce(f32[16,64,256]{2,1,0} %exponential.136.clone.1, f32[] %constant_14448_clone_1), dimensions={2}, to_apply=%primitive_computation_add__1.7494, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(2,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=94}
  ROOT %tuple.721 = (f32[16,64]{1,0}, f32[16,64,256]{2,1,0}) tuple(f32[16,64]{1,0} %reduce.335, f32[16,64,256]{2,1,0} %exponential.136.clone.1)
}

%horizontally_fused_computation (param_0_0: f32[], param_1_0: f32[], param_2_0: f32[], param_3_0: f32[]) -> (f32[1], f32[1], f32[1], f32[1]) {
  %param_0_0 = f32[] parameter(0)
  %constant_14965 = f32[] constant(0.0009765625)
  %multiply.1940 = f32[] multiply(f32[] %param_0_0, f32[] %constant_14965), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %sqrt.62 = f32[] sqrt(f32[] %multiply.1940), metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %reshape.1925 = f32[1]{0} reshape(f32[] %sqrt.62)
  %param_1_0 = f32[] parameter(1)
  %multiply.1942 = f32[] multiply(f32[] %param_1_0, f32[] %constant_14965), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %sqrt.63 = f32[] sqrt(f32[] %multiply.1942), metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %reshape.1926 = f32[1]{0} reshape(f32[] %sqrt.63)
  %param_2_0 = f32[] parameter(2)
  %multiply.1943 = f32[] multiply(f32[] %param_2_0, f32[] %constant_14965), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %sqrt.64 = f32[] sqrt(f32[] %multiply.1943), metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %reshape.1927 = f32[1]{0} reshape(f32[] %sqrt.64)
  %param_3_0 = f32[] parameter(3)
  %multiply.1944 = f32[] multiply(f32[] %param_3_0, f32[] %constant_14965), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %sqrt.65 = f32[] sqrt(f32[] %multiply.1944), metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %reshape.1928 = f32[1]{0} reshape(f32[] %sqrt.65)
  %concatenate.235 = f32[4]{0} concatenate(f32[1]{0} %reshape.1925, f32[1]{0} %reshape.1926, f32[1]{0} %reshape.1927, f32[1]{0} %reshape.1928), dimensions={0}
  %slice.995 = f32[1]{0} slice(f32[4]{0} %concatenate.235), slice={[0:1]}
  %slice.996 = f32[1]{0} slice(f32[4]{0} %concatenate.235), slice={[1:2]}
  %slice.997 = f32[1]{0} slice(f32[4]{0} %concatenate.235), slice={[2:3]}
  %slice.998 = f32[1]{0} slice(f32[4]{0} %concatenate.235), slice={[3:4]}
  ROOT %tuple.730 = (f32[1]{0}, f32[1]{0}, f32[1]{0}, f32[1]{0}) tuple(f32[1]{0} %slice.995, f32[1]{0} %slice.996, f32[1]{0} %slice.997, f32[1]{0} %slice.998)
}

%horizontally_fused_computation.1 (param_0_0.1: f32[], param_1_0.1: f32[], param_2_0.1: f32[], param_3_0.1: f32[]) -> (f32[1], f32[1], f32[1], f32[1]) {
  %param_0_0.1 = f32[] parameter(0)
  %constant_14970 = f32[] constant(9.53674316e-07)
  %multiply.1945 = f32[] multiply(f32[] %param_0_0.1, f32[] %constant_14970), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %sqrt.66 = f32[] sqrt(f32[] %multiply.1945), metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %reshape.1929 = f32[1]{0} reshape(f32[] %sqrt.66)
  %param_1_0.1 = f32[] parameter(1)
  %multiply.1946 = f32[] multiply(f32[] %param_1_0.1, f32[] %constant_14970), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %sqrt.67 = f32[] sqrt(f32[] %multiply.1946), metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %reshape.1930 = f32[1]{0} reshape(f32[] %sqrt.67)
  %param_2_0.1 = f32[] parameter(2)
  %multiply.1947 = f32[] multiply(f32[] %param_2_0.1, f32[] %constant_14970), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %sqrt.68 = f32[] sqrt(f32[] %multiply.1947), metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %reshape.1931 = f32[1]{0} reshape(f32[] %sqrt.68)
  %param_3_0.1 = f32[] parameter(3)
  %multiply.1948 = f32[] multiply(f32[] %param_3_0.1, f32[] %constant_14970), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %sqrt.69 = f32[] sqrt(f32[] %multiply.1948), metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %reshape.1932 = f32[1]{0} reshape(f32[] %sqrt.69)
  %concatenate.236 = f32[4]{0} concatenate(f32[1]{0} %reshape.1929, f32[1]{0} %reshape.1930, f32[1]{0} %reshape.1931, f32[1]{0} %reshape.1932), dimensions={0}
  %slice.999 = f32[1]{0} slice(f32[4]{0} %concatenate.236), slice={[0:1]}
  %slice.1000 = f32[1]{0} slice(f32[4]{0} %concatenate.236), slice={[1:2]}
  %slice.1001 = f32[1]{0} slice(f32[4]{0} %concatenate.236), slice={[2:3]}
  %slice.1002 = f32[1]{0} slice(f32[4]{0} %concatenate.236), slice={[3:4]}
  ROOT %tuple.731 = (f32[1]{0}, f32[1]{0}, f32[1]{0}, f32[1]{0}) tuple(f32[1]{0} %slice.999, f32[1]{0} %slice.1000, f32[1]{0} %slice.1001, f32[1]{0} %slice.1002)
}

%horizontally_fused_computation.2 (param_0_0.2: f32[], param_1_0.2: f32[], param_2_0.2: f32[], param_3_0.2: f32[], param_4_0: f32[], param_5_0: f32[], param_6_0: f32[], param_7_0: f32[], param_8_0: f32[]) -> (f32[1], f32[1], f32[1], f32[1], f32[1], /*index=5*/f32[1], f32[1], f32[1], f32[1]) {
  %param_0_0.2 = f32[] parameter(0)
  %constant_14975 = f32[] constant(0.000244140625)
  %multiply.1949 = f32[] multiply(f32[] %param_0_0.2, f32[] %constant_14975), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %sqrt.70 = f32[] sqrt(f32[] %multiply.1949), metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %reshape.1933 = f32[1]{0} reshape(f32[] %sqrt.70)
  %param_1_0.2 = f32[] parameter(1)
  %multiply.1950 = f32[] multiply(f32[] %param_1_0.2, f32[] %constant_14975), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %sqrt.71 = f32[] sqrt(f32[] %multiply.1950), metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %reshape.1934 = f32[1]{0} reshape(f32[] %sqrt.71)
  %param_2_0.2 = f32[] parameter(2)
  %multiply.1951 = f32[] multiply(f32[] %param_2_0.2, f32[] %constant_14975), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %sqrt.72 = f32[] sqrt(f32[] %multiply.1951), metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %reshape.1935 = f32[1]{0} reshape(f32[] %sqrt.72)
  %param_3_0.2 = f32[] parameter(3)
  %multiply.1952 = f32[] multiply(f32[] %param_3_0.2, f32[] %constant_14975), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %sqrt.73 = f32[] sqrt(f32[] %multiply.1952), metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %reshape.1936 = f32[1]{0} reshape(f32[] %sqrt.73)
  %param_4_0 = f32[] parameter(4)
  %multiply.1953 = f32[] multiply(f32[] %param_4_0, f32[] %constant_14975), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %sqrt.74 = f32[] sqrt(f32[] %multiply.1953), metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %reshape.1937 = f32[1]{0} reshape(f32[] %sqrt.74)
  %param_5_0 = f32[] parameter(5)
  %multiply.1954 = f32[] multiply(f32[] %param_5_0, f32[] %constant_14975), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %sqrt.75 = f32[] sqrt(f32[] %multiply.1954), metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %reshape.1938 = f32[1]{0} reshape(f32[] %sqrt.75)
  %param_6_0 = f32[] parameter(6)
  %multiply.1955 = f32[] multiply(f32[] %param_6_0, f32[] %constant_14975), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %sqrt.76 = f32[] sqrt(f32[] %multiply.1955), metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %reshape.1939 = f32[1]{0} reshape(f32[] %sqrt.76)
  %param_7_0 = f32[] parameter(7)
  %multiply.1957 = f32[] multiply(f32[] %param_7_0, f32[] %constant_14975), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %sqrt.77 = f32[] sqrt(f32[] %multiply.1957), metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %reshape.1940 = f32[1]{0} reshape(f32[] %sqrt.77)
  %param_8_0 = f32[] parameter(8)
  %multiply.1958 = f32[] multiply(f32[] %param_8_0, f32[] %constant_14975), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %sqrt.78 = f32[] sqrt(f32[] %multiply.1958), metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %reshape.1941 = f32[1]{0} reshape(f32[] %sqrt.78)
  %concatenate.237 = f32[9]{0} concatenate(f32[1]{0} %reshape.1933, f32[1]{0} %reshape.1934, f32[1]{0} %reshape.1935, f32[1]{0} %reshape.1936, f32[1]{0} %reshape.1937, /*index=5*/f32[1]{0} %reshape.1938, f32[1]{0} %reshape.1939, f32[1]{0} %reshape.1940, f32[1]{0} %reshape.1941), dimensions={0}
  %slice.1003 = f32[1]{0} slice(f32[9]{0} %concatenate.237), slice={[0:1]}
  %slice.1004 = f32[1]{0} slice(f32[9]{0} %concatenate.237), slice={[1:2]}
  %slice.1005 = f32[1]{0} slice(f32[9]{0} %concatenate.237), slice={[2:3]}
  %slice.1006 = f32[1]{0} slice(f32[9]{0} %concatenate.237), slice={[3:4]}
  %slice.1007 = f32[1]{0} slice(f32[9]{0} %concatenate.237), slice={[4:5]}
  %slice.1008 = f32[1]{0} slice(f32[9]{0} %concatenate.237), slice={[5:6]}
  %slice.1009 = f32[1]{0} slice(f32[9]{0} %concatenate.237), slice={[6:7]}
  %slice.1010 = f32[1]{0} slice(f32[9]{0} %concatenate.237), slice={[7:8]}
  %slice.1011 = f32[1]{0} slice(f32[9]{0} %concatenate.237), slice={[8:9]}
  ROOT %tuple.732 = (f32[1]{0}, f32[1]{0}, f32[1]{0}, f32[1]{0}, f32[1]{0}, /*index=5*/f32[1]{0}, f32[1]{0}, f32[1]{0}, f32[1]{0}) tuple(f32[1]{0} %slice.1003, f32[1]{0} %slice.1004, f32[1]{0} %slice.1005, f32[1]{0} %slice.1006, f32[1]{0} %slice.1007, /*index=5*/f32[1]{0} %slice.1008, f32[1]{0} %slice.1009, f32[1]{0} %slice.1010, f32[1]{0} %slice.1011)
}

%horizontally_fused_computation.3 (param_0_0.3: f32[], param_1_0.3: f32[], param_2_0.3: f32[], param_3_0.3: f32[], param_4_0.1: f32[], param_5_0.1: f32[], param_6_0.1: f32[], param_7_0.1: f32[]) -> (f32[1], f32[1], f32[1], f32[1], f32[1], /*index=5*/f32[1], f32[1], f32[1]) {
  %param_0_0.3 = f32[] parameter(0)
  %constant_14986 = f32[] constant(1.1920929e-07)
  %multiply.1959 = f32[] multiply(f32[] %param_0_0.3, f32[] %constant_14986), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %sqrt.79 = f32[] sqrt(f32[] %multiply.1959), metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %reshape.1942 = f32[1]{0} reshape(f32[] %sqrt.79)
  %param_1_0.3 = f32[] parameter(1)
  %multiply.1960 = f32[] multiply(f32[] %param_1_0.3, f32[] %constant_14986), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %sqrt.80 = f32[] sqrt(f32[] %multiply.1960), metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %reshape.1943 = f32[1]{0} reshape(f32[] %sqrt.80)
  %param_2_0.3 = f32[] parameter(2)
  %multiply.1961 = f32[] multiply(f32[] %param_2_0.3, f32[] %constant_14986), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %sqrt.81 = f32[] sqrt(f32[] %multiply.1961), metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %reshape.1944 = f32[1]{0} reshape(f32[] %sqrt.81)
  %param_3_0.3 = f32[] parameter(3)
  %multiply.1962 = f32[] multiply(f32[] %param_3_0.3, f32[] %constant_14986), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %sqrt.82 = f32[] sqrt(f32[] %multiply.1962), metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %reshape.1945 = f32[1]{0} reshape(f32[] %sqrt.82)
  %param_4_0.1 = f32[] parameter(4)
  %multiply.1963 = f32[] multiply(f32[] %param_4_0.1, f32[] %constant_14986), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %sqrt.83 = f32[] sqrt(f32[] %multiply.1963), metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %reshape.1946 = f32[1]{0} reshape(f32[] %sqrt.83)
  %param_5_0.1 = f32[] parameter(5)
  %multiply.1964 = f32[] multiply(f32[] %param_5_0.1, f32[] %constant_14986), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %sqrt.84 = f32[] sqrt(f32[] %multiply.1964), metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %reshape.1947 = f32[1]{0} reshape(f32[] %sqrt.84)
  %param_6_0.1 = f32[] parameter(6)
  %multiply.1965 = f32[] multiply(f32[] %param_6_0.1, f32[] %constant_14986), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %sqrt.85 = f32[] sqrt(f32[] %multiply.1965), metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %reshape.1948 = f32[1]{0} reshape(f32[] %sqrt.85)
  %param_7_0.1 = f32[] parameter(7)
  %multiply.1966 = f32[] multiply(f32[] %param_7_0.1, f32[] %constant_14986), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %sqrt.86 = f32[] sqrt(f32[] %multiply.1966), metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %reshape.1949 = f32[1]{0} reshape(f32[] %sqrt.86)
  %concatenate.238 = f32[8]{0} concatenate(f32[1]{0} %reshape.1942, f32[1]{0} %reshape.1943, f32[1]{0} %reshape.1944, f32[1]{0} %reshape.1945, f32[1]{0} %reshape.1946, /*index=5*/f32[1]{0} %reshape.1947, f32[1]{0} %reshape.1948, f32[1]{0} %reshape.1949), dimensions={0}
  %slice.1012 = f32[1]{0} slice(f32[8]{0} %concatenate.238), slice={[0:1]}
  %slice.1013 = f32[1]{0} slice(f32[8]{0} %concatenate.238), slice={[1:2]}
  %slice.1015 = f32[1]{0} slice(f32[8]{0} %concatenate.238), slice={[2:3]}
  %slice.1017 = f32[1]{0} slice(f32[8]{0} %concatenate.238), slice={[3:4]}
  %slice.1020 = f32[1]{0} slice(f32[8]{0} %concatenate.238), slice={[4:5]}
  %slice.1021 = f32[1]{0} slice(f32[8]{0} %concatenate.238), slice={[5:6]}
  %slice.1022 = f32[1]{0} slice(f32[8]{0} %concatenate.238), slice={[6:7]}
  %slice.1023 = f32[1]{0} slice(f32[8]{0} %concatenate.238), slice={[7:8]}
  ROOT %tuple.733 = (f32[1]{0}, f32[1]{0}, f32[1]{0}, f32[1]{0}, f32[1]{0}, /*index=5*/f32[1]{0}, f32[1]{0}, f32[1]{0}) tuple(f32[1]{0} %slice.1012, f32[1]{0} %slice.1013, f32[1]{0} %slice.1015, f32[1]{0} %slice.1017, f32[1]{0} %slice.1020, /*index=5*/f32[1]{0} %slice.1021, f32[1]{0} %slice.1022, f32[1]{0} %slice.1023)
}

%horizontally_fused_computation.4 () -> (u32[32768], u32[32768]) {
  %iota.77 = u32[65536]{0} iota(), iota_dimension=0, metadata={op_type="iota" op_name="pmap(_multi_device_update_fn)/jit(_bernoulli)/jit(_uniform)/jit(_random_bits)/iota[ dimension=0\n                                                                                    dtype=uint32\n                                                                                    shape=(65536,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=86}
  %slice.1024 = u32[32768]{0} slice(u32[65536]{0} %iota.77), slice={[0:32768]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/jit(_bernoulli)/jit(_uniform)/jit(_random_bits)/jit(threefry_2x32)/slice[ limit_indices=(32768,)\n                                                                                                        start_indices=(0,)\n                                                                                                        strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=86}
  %reshape.1950 = u32[32768]{0} reshape(u32[32768]{0} %slice.1024)
  %iota.78 = u32[65536]{0} iota(), iota_dimension=0, metadata={op_type="iota" op_name="pmap(_multi_device_update_fn)/jit(_bernoulli)/jit(_uniform)/jit(_random_bits)/iota[ dimension=0\n                                                                                    dtype=uint32\n                                                                                    shape=(65536,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=86}
  %slice.1025 = u32[32768]{0} slice(u32[65536]{0} %iota.78), slice={[32768:65536]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/jit(_bernoulli)/jit(_uniform)/jit(_random_bits)/jit(threefry_2x32)/slice[ limit_indices=(65536,)\n                                                                                                        start_indices=(32768,)\n                                                                                                        strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=86}
  %reshape.1951 = u32[32768]{0} reshape(u32[32768]{0} %slice.1025)
  %concatenate.239 = u32[65536]{0} concatenate(u32[32768]{0} %reshape.1950, u32[32768]{0} %reshape.1951), dimensions={0}
  %slice.1026 = u32[32768]{0} slice(u32[65536]{0} %concatenate.239), slice={[0:32768]}
  %slice.1027 = u32[32768]{0} slice(u32[65536]{0} %concatenate.239), slice={[32768:65536]}
  ROOT %tuple.734 = (u32[32768]{0}, u32[32768]{0}) tuple(u32[32768]{0} %slice.1026, u32[32768]{0} %slice.1027)
}

%horizontally_fused_computation.5 () -> (u32[3], u32[3]) {
  %iota.79 = u32[6]{0} iota(), iota_dimension=0, metadata={op_type="iota" op_name="pmap(_multi_device_update_fn)/jit(_split)/iota[ dimension=0\n                                                dtype=uint32\n                                                shape=(6,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %slice.1028 = u32[3]{0} slice(u32[6]{0} %iota.79), slice={[0:3]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/slice[ limit_indices=(3,)\n                                                                    start_indices=(0,)\n                                                                    strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %reshape.1952 = u32[3]{0} reshape(u32[3]{0} %slice.1028)
  %iota.80 = u32[6]{0} iota(), iota_dimension=0, metadata={op_type="iota" op_name="pmap(_multi_device_update_fn)/jit(_split)/iota[ dimension=0\n                                                dtype=uint32\n                                                shape=(6,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %slice.1029 = u32[3]{0} slice(u32[6]{0} %iota.80), slice={[3:6]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/slice[ limit_indices=(6,)\n                                                                    start_indices=(3,)\n                                                                    strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %reshape.1953 = u32[3]{0} reshape(u32[3]{0} %slice.1029)
  %concatenate.240 = u32[6]{0} concatenate(u32[3]{0} %reshape.1952, u32[3]{0} %reshape.1953), dimensions={0}
  %slice.1030 = u32[3]{0} slice(u32[6]{0} %concatenate.240), slice={[0:3]}
  %slice.1031 = u32[3]{0} slice(u32[6]{0} %concatenate.240), slice={[3:6]}
  ROOT %tuple.735 = (u32[3]{0}, u32[3]{0}) tuple(u32[3]{0} %slice.1030, u32[3]{0} %slice.1031)
}

%horizontally_fused_computation.6 () -> (u32[3], u32[3]) {
  %iota.81 = u32[6]{0} iota(), iota_dimension=0, metadata={op_type="iota" op_name="pmap(_multi_device_update_fn)/jit(_split)/iota[ dimension=0\n                                                dtype=uint32\n                                                shape=(6,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %slice.1032 = u32[3]{0} slice(u32[6]{0} %iota.81), slice={[0:3]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/slice[ limit_indices=(3,)\n                                                                    start_indices=(0,)\n                                                                    strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %reshape.1954 = u32[3]{0} reshape(u32[3]{0} %slice.1032)
  %iota.82 = u32[6]{0} iota(), iota_dimension=0, metadata={op_type="iota" op_name="pmap(_multi_device_update_fn)/jit(_split)/iota[ dimension=0\n                                                dtype=uint32\n                                                shape=(6,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %slice.1033 = u32[3]{0} slice(u32[6]{0} %iota.82), slice={[3:6]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/slice[ limit_indices=(6,)\n                                                                    start_indices=(3,)\n                                                                    strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %reshape.1955 = u32[3]{0} reshape(u32[3]{0} %slice.1033)
  %concatenate.241 = u32[6]{0} concatenate(u32[3]{0} %reshape.1954, u32[3]{0} %reshape.1955), dimensions={0}
  %slice.1034 = u32[3]{0} slice(u32[6]{0} %concatenate.241), slice={[0:3]}
  %slice.1035 = u32[3]{0} slice(u32[6]{0} %concatenate.241), slice={[3:6]}
  ROOT %tuple.736 = (u32[3]{0}, u32[3]{0}) tuple(u32[3]{0} %slice.1034, u32[3]{0} %slice.1035)
}

%horizontally_fused_computation.7 () -> (u32[2], u32[2]) {
  %iota.83 = u32[4]{0} iota(), iota_dimension=0, metadata={op_type="iota" op_name="pmap(_multi_device_update_fn)/jit(_split)/iota[ dimension=0\n                                                dtype=uint32\n                                                shape=(4,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %slice.1036 = u32[2]{0} slice(u32[4]{0} %iota.83), slice={[0:2]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/slice[ limit_indices=(2,)\n                                                                    start_indices=(0,)\n                                                                    strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %reshape.1956 = u32[2]{0} reshape(u32[2]{0} %slice.1036)
  %iota.84 = u32[4]{0} iota(), iota_dimension=0, metadata={op_type="iota" op_name="pmap(_multi_device_update_fn)/jit(_split)/iota[ dimension=0\n                                                dtype=uint32\n                                                shape=(4,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %slice.1037 = u32[2]{0} slice(u32[4]{0} %iota.84), slice={[2:4]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/slice[ limit_indices=(4,)\n                                                                    start_indices=(2,)\n                                                                    strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %reshape.1957 = u32[2]{0} reshape(u32[2]{0} %slice.1037)
  %concatenate.242 = u32[4]{0} concatenate(u32[2]{0} %reshape.1956, u32[2]{0} %reshape.1957), dimensions={0}
  %slice.1038 = u32[2]{0} slice(u32[4]{0} %concatenate.242), slice={[0:2]}
  %slice.1040 = u32[2]{0} slice(u32[4]{0} %concatenate.242), slice={[2:4]}
  ROOT %tuple.737 = (u32[2]{0}, u32[2]{0}) tuple(u32[2]{0} %slice.1038, u32[2]{0} %slice.1040)
}

%horizontally_fused_computation.8 () -> (u32[2], u32[2]) {
  %iota.85 = u32[4]{0} iota(), iota_dimension=0, metadata={op_type="iota" op_name="pmap(_multi_device_update_fn)/jit(_split)/iota[ dimension=0\n                                                dtype=uint32\n                                                shape=(4,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %slice.1042 = u32[2]{0} slice(u32[4]{0} %iota.85), slice={[0:2]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/slice[ limit_indices=(2,)\n                                                                    start_indices=(0,)\n                                                                    strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %reshape.1958 = u32[2]{0} reshape(u32[2]{0} %slice.1042)
  %iota.86 = u32[4]{0} iota(), iota_dimension=0, metadata={op_type="iota" op_name="pmap(_multi_device_update_fn)/jit(_split)/iota[ dimension=0\n                                                dtype=uint32\n                                                shape=(4,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %slice.1044 = u32[2]{0} slice(u32[4]{0} %iota.86), slice={[2:4]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/slice[ limit_indices=(4,)\n                                                                    start_indices=(2,)\n                                                                    strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %reshape.1959 = u32[2]{0} reshape(u32[2]{0} %slice.1044)
  %concatenate.243 = u32[4]{0} concatenate(u32[2]{0} %reshape.1958, u32[2]{0} %reshape.1959), dimensions={0}
  %slice.1045 = u32[2]{0} slice(u32[4]{0} %concatenate.243), slice={[0:2]}
  %slice.1046 = u32[2]{0} slice(u32[4]{0} %concatenate.243), slice={[2:4]}
  ROOT %tuple.738 = (u32[2]{0}, u32[2]{0}) tuple(u32[2]{0} %slice.1045, u32[2]{0} %slice.1046)
}

%horizontally_fused_computation.9 () -> (u32[2], u32[2]) {
  %iota.87 = u32[4]{0} iota(), iota_dimension=0, metadata={op_type="iota" op_name="pmap(_multi_device_update_fn)/jit(_split)/iota[ dimension=0\n                                                dtype=uint32\n                                                shape=(4,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %slice.1047 = u32[2]{0} slice(u32[4]{0} %iota.87), slice={[0:2]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/slice[ limit_indices=(2,)\n                                                                    start_indices=(0,)\n                                                                    strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %reshape.1960 = u32[2]{0} reshape(u32[2]{0} %slice.1047)
  %iota.88 = u32[4]{0} iota(), iota_dimension=0, metadata={op_type="iota" op_name="pmap(_multi_device_update_fn)/jit(_split)/iota[ dimension=0\n                                                dtype=uint32\n                                                shape=(4,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %slice.1048 = u32[2]{0} slice(u32[4]{0} %iota.88), slice={[2:4]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/slice[ limit_indices=(4,)\n                                                                    start_indices=(2,)\n                                                                    strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %reshape.1961 = u32[2]{0} reshape(u32[2]{0} %slice.1048)
  %concatenate.244 = u32[4]{0} concatenate(u32[2]{0} %reshape.1960, u32[2]{0} %reshape.1961), dimensions={0}
  %slice.1050 = u32[2]{0} slice(u32[4]{0} %concatenate.244), slice={[0:2]}
  %slice.1052 = u32[2]{0} slice(u32[4]{0} %concatenate.244), slice={[2:4]}
  ROOT %tuple.739 = (u32[2]{0}, u32[2]{0}) tuple(u32[2]{0} %slice.1050, u32[2]{0} %slice.1052)
}

%horizontally_fused_computation.10 () -> (u32[11], u32[11]) {
  %iota.89 = u32[22]{0} iota(), iota_dimension=0, metadata={op_type="iota" op_name="pmap(_multi_device_update_fn)/jit(_split)/iota[ dimension=0\n                                                dtype=uint32\n                                                shape=(22,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %slice.1055 = u32[11]{0} slice(u32[22]{0} %iota.89), slice={[0:11]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/slice[ limit_indices=(11,)\n                                                                    start_indices=(0,)\n                                                                    strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %reshape.1962 = u32[11]{0} reshape(u32[11]{0} %slice.1055)
  %iota.90 = u32[22]{0} iota(), iota_dimension=0, metadata={op_type="iota" op_name="pmap(_multi_device_update_fn)/jit(_split)/iota[ dimension=0\n                                                dtype=uint32\n                                                shape=(22,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %slice.1056 = u32[11]{0} slice(u32[22]{0} %iota.90), slice={[11:22]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/slice[ limit_indices=(22,)\n                                                                    start_indices=(11,)\n                                                                    strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %reshape.1963 = u32[11]{0} reshape(u32[11]{0} %slice.1056)
  %concatenate.245 = u32[22]{0} concatenate(u32[11]{0} %reshape.1962, u32[11]{0} %reshape.1963), dimensions={0}
  %slice.1057 = u32[11]{0} slice(u32[22]{0} %concatenate.245), slice={[0:11]}
  %slice.1058 = u32[11]{0} slice(u32[22]{0} %concatenate.245), slice={[11:22]}
  ROOT %tuple.740 = (u32[11]{0}, u32[11]{0}) tuple(u32[11]{0} %slice.1057, u32[11]{0} %slice.1058)
}

%horizontally_fused_computation.11 () -> (u32[2], u32[2]) {
  %iota.91 = u32[4]{0} iota(), iota_dimension=0, metadata={op_type="iota" op_name="pmap(_multi_device_update_fn)/jit(_split)/iota[ dimension=0\n                                                dtype=uint32\n                                                shape=(4,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %slice.1059 = u32[2]{0} slice(u32[4]{0} %iota.91), slice={[0:2]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/slice[ limit_indices=(2,)\n                                                                    start_indices=(0,)\n                                                                    strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %reshape.1964 = u32[2]{0} reshape(u32[2]{0} %slice.1059)
  %iota.92 = u32[4]{0} iota(), iota_dimension=0, metadata={op_type="iota" op_name="pmap(_multi_device_update_fn)/jit(_split)/iota[ dimension=0\n                                                dtype=uint32\n                                                shape=(4,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %slice.1060 = u32[2]{0} slice(u32[4]{0} %iota.92), slice={[2:4]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/slice[ limit_indices=(4,)\n                                                                    start_indices=(2,)\n                                                                    strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %reshape.1965 = u32[2]{0} reshape(u32[2]{0} %slice.1060)
  %concatenate.246 = u32[4]{0} concatenate(u32[2]{0} %reshape.1964, u32[2]{0} %reshape.1965), dimensions={0}
  %slice.1061 = u32[2]{0} slice(u32[4]{0} %concatenate.246), slice={[0:2]}
  %slice.1062 = u32[2]{0} slice(u32[4]{0} %concatenate.246), slice={[2:4]}
  ROOT %tuple.741 = (u32[2]{0}, u32[2]{0}) tuple(u32[2]{0} %slice.1061, u32[2]{0} %slice.1062)
}

%primitive_computation_add__1.12594 (parameter.12595: f32[], parameter.12596: f32[]) -> f32[] {
  %parameter.12595 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.12596 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.12597 = f32[] add(f32[] %parameter.12595, f32[] %parameter.12596), metadata={op_type="add" op_name="add"}
}

ENTRY %pmap__multi_device_update_fn__2.16072 (parameter.82: f32[32000,1024], parameter.83: f32[2048,4096], parameter.84: f32[4096], parameter.85: f32[2048,4096], parameter.86: f32[4096], parameter.87: f32[2048,4096], parameter.88: f32[4096], parameter.89: f32[2048,4096], parameter.90: f32[4096], parameter.91: f32[256,1024], parameter.92: f32[2048,4096], parameter.93: f32[4096], parameter.94: f32[1024,1024], parameter.95: f32[1024], parameter.96: f32[1024,1024], parameter.97: f32[1024], parameter.98: f32[1024,1024], parameter.99: f32[1024], parameter.100: f32[1024,1024], parameter.101: f32[1024], parameter.102: f32[2048,4096], parameter.103: f32[4096], parameter.104: f32[2048,4096], parameter.105: f32[4096], parameter.106: f32[2048,4096], parameter.107: f32[4096], parameter.108: f32[2048,4096], parameter.109: f32[4096], parameter.110: f32[1024,256], parameter.111: f32[256], parameter.112: f32[32000], parameter.113: f32[1024], parameter.114: f32[2048], parameter.115: f32[4096], parameter.116: f32[4096], parameter.117: f32[2048], parameter.118: f32[4096], parameter.119: f32[4096], parameter.120: f32[2048], parameter.121: f32[4096], parameter.122: f32[4096], parameter.123: f32[2048], parameter.124: f32[4096], parameter.125: f32[4096], parameter.126: f32[256], parameter.127: f32[1024], parameter.128: f32[2048], parameter.129: f32[4096], parameter.130: f32[4096], parameter.131: f32[1024], parameter.132: f32[1024], parameter.133: f32[1024], parameter.134: f32[1024], parameter.135: f32[1024], parameter.136: f32[1024], parameter.137: f32[1024], parameter.138: f32[1024], parameter.139: f32[1024], parameter.140: f32[1024], parameter.141: f32[1024], parameter.142: f32[1024], parameter.143: f32[2048], parameter.144: f32[4096], parameter.145: f32[4096], parameter.146: f32[2048], parameter.147: f32[4096], parameter.148: f32[4096], parameter.149: f32[2048], parameter.150: f32[4096], parameter.151: f32[4096], parameter.152: f32[2048], parameter.153: f32[4096], parameter.154: f32[4096], parameter.155: f32[1024], parameter.156: f32[256], parameter.157: f32[256], parameter.158: s32[], parameter.159: f32[], parameter.160: f32[], parameter.161: f32[], parameter.162: f32[], parameter.163: f32[], parameter.164: f32[], parameter.165: s32[], parameter.166: f32[], parameter.167: s32[16,64], parameter.168: s32[16,64], parameter.169: f32[16,64], parameter.170: u32[2]) -> (f32[32000,1024], f32[2048,4096], f32[4096], f32[2048,4096], f32[4096], /*index=5*/f32[2048,4096], f32[4096], f32[2048,4096], f32[4096], f32[256,1024], /*index=10*/f32[2048,4096], f32[4096], f32[1024,1024], f32[1024], f32[1024,1024], /*index=15*/f32[1024], f32[1024,1024], f32[1024], f32[1024,1024], f32[1024], /*index=20*/f32[2048,4096], f32[4096], f32[2048,4096], f32[4096], f32[2048,4096], /*index=25*/f32[4096], f32[2048,4096], f32[4096], f32[1024,256], f32[256], /*index=30*/f32[32000], f32[1024], f32[2048], f32[4096], f32[4096], /*index=35*/f32[2048], f32[4096], f32[4096], f32[2048], f32[4096], /*index=40*/f32[4096], f32[2048], f32[4096], f32[4096], f32[256], /*index=45*/f32[1024], f32[2048], f32[4096], f32[4096], f32[1024], /*index=50*/f32[1024], f32[1024], f32[1024], f32[1024], f32[1024], /*index=55*/f32[1024], f32[1024], f32[1024], f32[1024], f32[1024], /*index=60*/f32[1024], f32[2048], f32[4096], f32[4096], f32[2048], /*index=65*/f32[4096], f32[4096], f32[2048], f32[4096], f32[4096], /*index=70*/f32[2048], f32[4096], f32[4096], f32[1024], f32[256], /*index=75*/f32[256], f32[], f32[], f32[]) {
  %parameter.159 = f32[] parameter(77), parameter_replication={false}
  %parameter.111 = f32[256]{0} parameter(29), parameter_replication={false}
  %parameter.101 = f32[1024]{0} parameter(19), parameter_replication={false}
  %parameter.170 = u32[2]{0} parameter(88), parameter_replication={false}
  %fusion.650 = (u32[2]{0}, u32[2]{0}) fusion(u32[2]{0} %parameter.170), kind=kLoop, calls=%fused_computation.650, metadata={op_type="threefry2x32" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/threefry2x32" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %get-tuple-element.5569 = u32[2]{0} get-tuple-element((u32[2]{0}, u32[2]{0}) %fusion.650), index=1
  %get-tuple-element.5568 = u32[2]{0} get-tuple-element((u32[2]{0}, u32[2]{0}) %fusion.650), index=0
  %fusion.778 = (u32[2]{0}, u32[2]{0}) fusion(), kind=kInput, calls=%horizontally_fused_computation.11
  %get-tuple-element.5631 = u32[2]{0} get-tuple-element((u32[2]{0}, u32[2]{0}) %fusion.778), index=0, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/slice[ limit_indices=(2,)\n                                                                    start_indices=(0,)\n                                                                    strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %get-tuple-element.5632 = u32[2]{0} get-tuple-element((u32[2]{0}, u32[2]{0}) %fusion.778), index=1, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/slice[ limit_indices=(4,)\n                                                                    start_indices=(2,)\n                                                                    strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %custom-call.47 = (u32[2]{0}, u32[2]{0}) custom-call(u32[2]{0} %get-tuple-element.5569, u32[2]{0} %get-tuple-element.5568, u32[2]{0} %get-tuple-element.5631, u32[2]{0} %get-tuple-element.5632), custom_call_target="cuda_threefry2x32", operand_layout_constraints={u32[2]{0}, u32[2]{0}, u32[2]{0}, u32[2]{0}}, metadata={op_type="threefry2x32" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/threefry2x32" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}, backend_config="\002\000\000\000\000\000\000\000"
  %get-tuple-element.97 = u32[2]{0} get-tuple-element((u32[2]{0}, u32[2]{0}) %custom-call.47), index=0, metadata={op_type="threefry2x32" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/threefry2x32" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %fusion.649 = (u32[11]{0}, u32[11]{0}) fusion(u32[2]{0} %get-tuple-element.97), kind=kLoop, calls=%fused_computation.649, metadata={op_type="threefry2x32" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/threefry2x32" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %get-tuple-element.5566 = u32[11]{0} get-tuple-element((u32[11]{0}, u32[11]{0}) %fusion.649), index=0
  %get-tuple-element.5567 = u32[11]{0} get-tuple-element((u32[11]{0}, u32[11]{0}) %fusion.649), index=1
  %fusion.777 = (u32[11]{0}, u32[11]{0}) fusion(), kind=kInput, calls=%horizontally_fused_computation.10
  %get-tuple-element.5629 = u32[11]{0} get-tuple-element((u32[11]{0}, u32[11]{0}) %fusion.777), index=0, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/slice[ limit_indices=(11,)\n                                                                    start_indices=(0,)\n                                                                    strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %get-tuple-element.5630 = u32[11]{0} get-tuple-element((u32[11]{0}, u32[11]{0}) %fusion.777), index=1, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/slice[ limit_indices=(22,)\n                                                                    start_indices=(11,)\n                                                                    strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %custom-call.48 = (u32[11]{0}, u32[11]{0}) custom-call(u32[11]{0} %get-tuple-element.5566, u32[11]{0} %get-tuple-element.5567, u32[11]{0} %get-tuple-element.5629, u32[11]{0} %get-tuple-element.5630), custom_call_target="cuda_threefry2x32", operand_layout_constraints={u32[11]{0}, u32[11]{0}, u32[11]{0}, u32[11]{0}}, metadata={op_type="threefry2x32" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/threefry2x32" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}, backend_config="\013\000\000\000\000\000\000\000"
  %get-tuple-element.100 = u32[11]{0} get-tuple-element((u32[11]{0}, u32[11]{0}) %custom-call.48), index=0, metadata={op_type="threefry2x32" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/threefry2x32" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %get-tuple-element.101 = u32[11]{0} get-tuple-element((u32[11]{0}, u32[11]{0}) %custom-call.48), index=1, metadata={op_type="threefry2x32" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/threefry2x32" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %fusion.646 = (u32[2]{0}, u32[2]{0}) fusion(u32[11]{0} %get-tuple-element.100, u32[11]{0} %get-tuple-element.101), kind=kLoop, calls=%fused_computation.646, metadata={op_type="threefry2x32" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/threefry2x32" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %get-tuple-element.5564 = u32[2]{0} get-tuple-element((u32[2]{0}, u32[2]{0}) %fusion.646), index=0
  %get-tuple-element.5565 = u32[2]{0} get-tuple-element((u32[2]{0}, u32[2]{0}) %fusion.646), index=1
  %fusion.776 = (u32[2]{0}, u32[2]{0}) fusion(), kind=kInput, calls=%horizontally_fused_computation.9
  %get-tuple-element.5627 = u32[2]{0} get-tuple-element((u32[2]{0}, u32[2]{0}) %fusion.776), index=0, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/slice[ limit_indices=(2,)\n                                                                    start_indices=(0,)\n                                                                    strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %get-tuple-element.5628 = u32[2]{0} get-tuple-element((u32[2]{0}, u32[2]{0}) %fusion.776), index=1, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/slice[ limit_indices=(4,)\n                                                                    start_indices=(2,)\n                                                                    strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %custom-call.68 = (u32[2]{0}, u32[2]{0}) custom-call(u32[2]{0} %get-tuple-element.5564, u32[2]{0} %get-tuple-element.5565, u32[2]{0} %get-tuple-element.5627, u32[2]{0} %get-tuple-element.5628), custom_call_target="cuda_threefry2x32", operand_layout_constraints={u32[2]{0}, u32[2]{0}, u32[2]{0}, u32[2]{0}}, metadata={op_type="threefry2x32" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/threefry2x32" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}, backend_config="\002\000\000\000\000\000\000\000"
  %get-tuple-element.175 = u32[2]{0} get-tuple-element((u32[2]{0}, u32[2]{0}) %custom-call.68), index=0, metadata={op_type="threefry2x32" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/threefry2x32" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %fusion.644 = (u32[2]{0}, u32[2]{0}) fusion(u32[2]{0} %get-tuple-element.175), kind=kLoop, calls=%fused_computation.644, metadata={op_type="threefry2x32" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/threefry2x32" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %get-tuple-element.5562 = u32[2]{0} get-tuple-element((u32[2]{0}, u32[2]{0}) %fusion.644), index=0
  %get-tuple-element.5563 = u32[2]{0} get-tuple-element((u32[2]{0}, u32[2]{0}) %fusion.644), index=1
  %fusion.775 = (u32[2]{0}, u32[2]{0}) fusion(), kind=kInput, calls=%horizontally_fused_computation.8
  %get-tuple-element.5625 = u32[2]{0} get-tuple-element((u32[2]{0}, u32[2]{0}) %fusion.775), index=0, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/slice[ limit_indices=(2,)\n                                                                    start_indices=(0,)\n                                                                    strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %get-tuple-element.5626 = u32[2]{0} get-tuple-element((u32[2]{0}, u32[2]{0}) %fusion.775), index=1, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/slice[ limit_indices=(4,)\n                                                                    start_indices=(2,)\n                                                                    strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %custom-call.69 = (u32[2]{0}, u32[2]{0}) custom-call(u32[2]{0} %get-tuple-element.5562, u32[2]{0} %get-tuple-element.5563, u32[2]{0} %get-tuple-element.5625, u32[2]{0} %get-tuple-element.5626), custom_call_target="cuda_threefry2x32", operand_layout_constraints={u32[2]{0}, u32[2]{0}, u32[2]{0}, u32[2]{0}}, metadata={op_type="threefry2x32" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/threefry2x32" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}, backend_config="\002\000\000\000\000\000\000\000"
  %get-tuple-element.178 = u32[2]{0} get-tuple-element((u32[2]{0}, u32[2]{0}) %custom-call.69), index=0, metadata={op_type="threefry2x32" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/threefry2x32" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %get-tuple-element.179 = u32[2]{0} get-tuple-element((u32[2]{0}, u32[2]{0}) %custom-call.69), index=1, metadata={op_type="threefry2x32" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/threefry2x32" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %fusion.641 = (u32[2]{0}, u32[2]{0}) fusion(u32[2]{0} %get-tuple-element.178, u32[2]{0} %get-tuple-element.179), kind=kLoop, calls=%fused_computation.641, metadata={op_type="threefry2x32" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/threefry2x32" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %get-tuple-element.5560 = u32[2]{0} get-tuple-element((u32[2]{0}, u32[2]{0}) %fusion.641), index=0
  %get-tuple-element.5561 = u32[2]{0} get-tuple-element((u32[2]{0}, u32[2]{0}) %fusion.641), index=1
  %fusion.774 = (u32[2]{0}, u32[2]{0}) fusion(), kind=kInput, calls=%horizontally_fused_computation.7
  %get-tuple-element.5623 = u32[2]{0} get-tuple-element((u32[2]{0}, u32[2]{0}) %fusion.774), index=0, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/slice[ limit_indices=(2,)\n                                                                    start_indices=(0,)\n                                                                    strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %get-tuple-element.5624 = u32[2]{0} get-tuple-element((u32[2]{0}, u32[2]{0}) %fusion.774), index=1, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/slice[ limit_indices=(4,)\n                                                                    start_indices=(2,)\n                                                                    strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %custom-call.70 = (u32[2]{0}, u32[2]{0}) custom-call(u32[2]{0} %get-tuple-element.5560, u32[2]{0} %get-tuple-element.5561, u32[2]{0} %get-tuple-element.5623, u32[2]{0} %get-tuple-element.5624), custom_call_target="cuda_threefry2x32", operand_layout_constraints={u32[2]{0}, u32[2]{0}, u32[2]{0}, u32[2]{0}}, metadata={op_type="threefry2x32" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/threefry2x32" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}, backend_config="\002\000\000\000\000\000\000\000"
  %get-tuple-element.181 = u32[2]{0} get-tuple-element((u32[2]{0}, u32[2]{0}) %custom-call.70), index=0, metadata={op_type="threefry2x32" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/threefry2x32" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %get-tuple-element.182 = u32[2]{0} get-tuple-element((u32[2]{0}, u32[2]{0}) %custom-call.70), index=1, metadata={op_type="threefry2x32" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/threefry2x32" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %fusion.638 = (u32[3]{0}, u32[3]{0}) fusion(u32[2]{0} %get-tuple-element.181, u32[2]{0} %get-tuple-element.182), kind=kLoop, calls=%fused_computation.638, metadata={op_type="threefry2x32" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/threefry2x32" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %get-tuple-element.5558 = u32[3]{0} get-tuple-element((u32[3]{0}, u32[3]{0}) %fusion.638), index=0
  %get-tuple-element.5559 = u32[3]{0} get-tuple-element((u32[3]{0}, u32[3]{0}) %fusion.638), index=1
  %fusion.773 = (u32[3]{0}, u32[3]{0}) fusion(), kind=kInput, calls=%horizontally_fused_computation.6
  %get-tuple-element.5621 = u32[3]{0} get-tuple-element((u32[3]{0}, u32[3]{0}) %fusion.773), index=0, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/slice[ limit_indices=(3,)\n                                                                    start_indices=(0,)\n                                                                    strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %get-tuple-element.5622 = u32[3]{0} get-tuple-element((u32[3]{0}, u32[3]{0}) %fusion.773), index=1, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/slice[ limit_indices=(6,)\n                                                                    start_indices=(3,)\n                                                                    strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %custom-call.71 = (u32[3]{0}, u32[3]{0}) custom-call(u32[3]{0} %get-tuple-element.5558, u32[3]{0} %get-tuple-element.5559, u32[3]{0} %get-tuple-element.5621, u32[3]{0} %get-tuple-element.5622), custom_call_target="cuda_threefry2x32", operand_layout_constraints={u32[3]{0}, u32[3]{0}, u32[3]{0}, u32[3]{0}}, metadata={op_type="threefry2x32" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/threefry2x32" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}, backend_config="\003\000\000\000\000\000\000\000"
  %get-tuple-element.184 = u32[3]{0} get-tuple-element((u32[3]{0}, u32[3]{0}) %custom-call.71), index=0, metadata={op_type="threefry2x32" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/threefry2x32" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %get-tuple-element.185 = u32[3]{0} get-tuple-element((u32[3]{0}, u32[3]{0}) %custom-call.71), index=1, metadata={op_type="threefry2x32" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/threefry2x32" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %fusion.635 = (u32[3]{0}, u32[3]{0}) fusion(u32[3]{0} %get-tuple-element.184, u32[3]{0} %get-tuple-element.185), kind=kLoop, calls=%fused_computation.635, metadata={op_type="threefry2x32" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/threefry2x32" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %get-tuple-element.5556 = u32[3]{0} get-tuple-element((u32[3]{0}, u32[3]{0}) %fusion.635), index=0
  %get-tuple-element.5557 = u32[3]{0} get-tuple-element((u32[3]{0}, u32[3]{0}) %fusion.635), index=1
  %fusion.772 = (u32[3]{0}, u32[3]{0}) fusion(), kind=kInput, calls=%horizontally_fused_computation.5
  %get-tuple-element.5619 = u32[3]{0} get-tuple-element((u32[3]{0}, u32[3]{0}) %fusion.772), index=0, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/slice[ limit_indices=(3,)\n                                                                    start_indices=(0,)\n                                                                    strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %get-tuple-element.5620 = u32[3]{0} get-tuple-element((u32[3]{0}, u32[3]{0}) %fusion.772), index=1, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/slice[ limit_indices=(6,)\n                                                                    start_indices=(3,)\n                                                                    strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %custom-call.72 = (u32[3]{0}, u32[3]{0}) custom-call(u32[3]{0} %get-tuple-element.5556, u32[3]{0} %get-tuple-element.5557, u32[3]{0} %get-tuple-element.5619, u32[3]{0} %get-tuple-element.5620), custom_call_target="cuda_threefry2x32", operand_layout_constraints={u32[3]{0}, u32[3]{0}, u32[3]{0}, u32[3]{0}}, metadata={op_type="threefry2x32" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/threefry2x32" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}, backend_config="\003\000\000\000\000\000\000\000"
  %get-tuple-element.189 = u32[3]{0} get-tuple-element((u32[3]{0}, u32[3]{0}) %custom-call.72), index=0, metadata={op_type="threefry2x32" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/threefry2x32" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %get-tuple-element.190 = u32[3]{0} get-tuple-element((u32[3]{0}, u32[3]{0}) %custom-call.72), index=1, metadata={op_type="threefry2x32" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/threefry2x32" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %fusion.632 = (u32[32768]{0}, u32[32768]{0}) fusion(u32[3]{0} %get-tuple-element.189, u32[3]{0} %get-tuple-element.190), kind=kLoop, calls=%fused_computation.632, metadata={op_type="threefry2x32" op_name="pmap(_multi_device_update_fn)/jit(_bernoulli)/jit(_uniform)/jit(_random_bits)/jit(threefry_2x32)/threefry2x32" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=86}
  %get-tuple-element.5554 = u32[32768]{0} get-tuple-element((u32[32768]{0}, u32[32768]{0}) %fusion.632), index=0
  %get-tuple-element.5555 = u32[32768]{0} get-tuple-element((u32[32768]{0}, u32[32768]{0}) %fusion.632), index=1
  %fusion.771 = (u32[32768]{0}, u32[32768]{0}) fusion(), kind=kInput, calls=%horizontally_fused_computation.4
  %get-tuple-element.5617 = u32[32768]{0} get-tuple-element((u32[32768]{0}, u32[32768]{0}) %fusion.771), index=0, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/jit(_bernoulli)/jit(_uniform)/jit(_random_bits)/jit(threefry_2x32)/slice[ limit_indices=(32768,)\n                                                                                                        start_indices=(0,)\n                                                                                                        strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=86}
  %get-tuple-element.5618 = u32[32768]{0} get-tuple-element((u32[32768]{0}, u32[32768]{0}) %fusion.771), index=1, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/jit(_bernoulli)/jit(_uniform)/jit(_random_bits)/jit(threefry_2x32)/slice[ limit_indices=(65536,)\n                                                                                                        start_indices=(32768,)\n                                                                                                        strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=86}
  %custom-call.77 = (u32[32768]{0}, u32[32768]{0}) custom-call(u32[32768]{0} %get-tuple-element.5554, u32[32768]{0} %get-tuple-element.5555, u32[32768]{0} %get-tuple-element.5617, u32[32768]{0} %get-tuple-element.5618), custom_call_target="cuda_threefry2x32", operand_layout_constraints={u32[32768]{0}, u32[32768]{0}, u32[32768]{0}, u32[32768]{0}}, metadata={op_type="threefry2x32" op_name="pmap(_multi_device_update_fn)/jit(_bernoulli)/jit(_uniform)/jit(_random_bits)/jit(threefry_2x32)/threefry2x32" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=86}, backend_config="\000\200\000\000\000\000\000\000"
  %get-tuple-element.206 = u32[32768]{0} get-tuple-element((u32[32768]{0}, u32[32768]{0}) %custom-call.77), index=0, metadata={op_type="threefry2x32" op_name="pmap(_multi_device_update_fn)/jit(_bernoulli)/jit(_uniform)/jit(_random_bits)/jit(threefry_2x32)/threefry2x32" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=86}
  %get-tuple-element.207 = u32[32768]{0} get-tuple-element((u32[32768]{0}, u32[32768]{0}) %custom-call.77), index=1, metadata={op_type="threefry2x32" op_name="pmap(_multi_device_update_fn)/jit(_bernoulli)/jit(_uniform)/jit(_random_bits)/jit(threefry_2x32)/threefry2x32" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=86}
  %fusion.630 = pred[16,1,64,64]{3,2,0,1} fusion(u32[32768]{0} %get-tuple-element.206, u32[32768]{0} %get-tuple-element.207), kind=kLoop, calls=%fused_computation.630, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/jit(_bernoulli)/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=86}
  %parameter.95 = f32[1024]{0} parameter(13), parameter_replication={false}
  %parameter.91 = f32[256,1024]{1,0} parameter(9), parameter_replication={false}
  %parameter.168 = s32[16,64]{1,0} parameter(86), parameter_replication={false}, metadata={op_type="pad" op_name="pmap(_multi_device_update_fn)/jit(_pad)/pad[ padding_config=((0, 0, 0), (0, 0, 0)) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/attention.py" source_line=741}
  %fusion.652 = f32[64,16,1024]{2,1,0} fusion(f32[256,1024]{1,0} %parameter.91, s32[16,64]{1,0} %parameter.168), kind=kLoop, calls=%fused_computation.652, metadata={op_type="transpose" op_name="pmap(_multi_device_update_fn)/transpose[ permutation=(1, 0, 2) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/combinators.py" source_line=342}
  %parameter.92 = f32[2048,4096]{1,0} parameter(10), parameter_replication={false}
  %parameter.93 = f32[4096]{0} parameter(11), parameter_replication={false}
  %bitcast.323 = f32[1,4096]{1,0} bitcast(f32[4096]{0} %parameter.93), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/broadcast_in_dim[ broadcast_dimensions=(1,)\n                                                shape=(1, 4096) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %constant_495 = s32[] constant(0), metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %copy.172 = s32[] copy(s32[] %constant_495)
  %constant_1 = f32[] constant(0)
  %broadcast.3322 = f32[16,2048]{1,0} broadcast(f32[] %constant_1), dimensions={}, metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/broadcast_in_dim[ broadcast_dimensions=(  )\n                                                shape=(16, 2048) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=88}
  %copy.173 = f32[16,2048]{1,0} copy(f32[16,2048]{1,0} %broadcast.3322)
  %broadcast.3360 = f32[64,16,1024]{2,1,0} broadcast(f32[] %constant_1), dimensions={}, metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/broadcast_in_dim[ broadcast_dimensions=(  )\n                                                     shape=(64, 16, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %copy.174 = f32[64,16,1024]{2,1,0} copy(f32[64,16,1024]{2,1,0} %broadcast.3360)
  %copy.175 = f32[64,16,1024]{2,1,0} copy(f32[64,16,1024]{2,1,0} %broadcast.3360)
  %copy.176 = f32[64,16,1024]{2,1,0} copy(f32[64,16,1024]{2,1,0} %broadcast.3360)
  %broadcast.3366 = f32[64,16,2048]{2,1,0} broadcast(f32[] %constant_1), dimensions={}, metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/broadcast_in_dim[ broadcast_dimensions=(  )\n                                                     shape=(64, 16, 2048) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %copy.177 = f32[64,16,2048]{2,1,0} copy(f32[64,16,2048]{2,1,0} %broadcast.3366)
  %copy.178 = f32[64,16,1024]{2,1,0} copy(f32[64,16,1024]{2,1,0} %broadcast.3360)
  %copy.179 = f32[64,16,1024]{2,1,0} copy(f32[64,16,1024]{2,1,0} %broadcast.3360)
  %copy.180 = f32[64,16,1024]{2,1,0} copy(f32[64,16,1024]{2,1,0} %broadcast.3360)
  %copy.181 = f32[64,16,1024]{2,1,0} copy(f32[64,16,1024]{2,1,0} %broadcast.3360)
  %copy.182 = f32[64,16,1024]{2,1,0} copy(f32[64,16,1024]{2,1,0} %broadcast.3360)
  %copy.183 = f32[64,16,1024]{2,1,0} copy(f32[64,16,1024]{2,1,0} %broadcast.3360)
  %copy.184 = f32[64,16,1024]{2,1,0} copy(f32[64,16,1024]{2,1,0} %broadcast.3360)
  %copy.185 = f32[64,16,1024]{2,1,0} copy(f32[64,16,1024]{2,1,0} %broadcast.3360)
  %copy.186 = f32[64,16,1024]{2,1,0} copy(f32[64,16,1024]{2,1,0} %broadcast.3360)
  %tuple.785 = (f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) tuple(f32[64,16,1024]{2,1,0} %fusion.652, f32[2048,4096]{1,0} %parameter.92, f32[1,4096]{1,0} %bitcast.323, s32[] %copy.172, f32[16,2048]{1,0} %copy.173, /*index=5*/f32[64,16,1024]{2,1,0} %copy.174, f32[64,16,1024]{2,1,0} %copy.175, f32[64,16,1024]{2,1,0} %copy.176, f32[64,16,2048]{2,1,0} %copy.177, f32[64,16,1024]{2,1,0} %copy.178, /*index=10*/f32[64,16,1024]{2,1,0} %copy.179, f32[64,16,1024]{2,1,0} %copy.180, f32[64,16,1024]{2,1,0} %copy.181, f32[64,16,1024]{2,1,0} %copy.182, f32[64,16,1024]{2,1,0} %copy.183, /*index=15*/f32[64,16,1024]{2,1,0} %copy.184, f32[64,16,1024]{2,1,0} %copy.185, f32[64,16,1024]{2,1,0} %copy.186)
  %while.45 = (f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) while((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %tuple.785), condition=%cond_computation__40.3810.clone.clone.clone, body=%body_computation__40.3389.clone.clone.clone.clone, backend_config="{\"known_trip_count\":{\"n\":\"64\"}}"
  %get-tuple-element.4521 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %while.45), index=5, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %fusion.628 = f32[1024,1024]{1,0} fusion(f32[64,16,1024]{2,1,0} %get-tuple-element.4521), kind=kLoop, calls=%fused_computation.628
  %parameter.94 = f32[1024,1024]{1,0} parameter(12), parameter_replication={false}
  %custom-call.137 = f32[1024,1024]{1,0} custom-call(f32[1024,1024]{1,0} %fusion.628, f32[1024,1024]{1,0} %parameter.94), custom_call_target="__cublas$gemm", backend_config="{\"alpha_real\":1,\"alpha_imag\":0,\"beta\":0,\"dot_dimension_numbers\":{\"lhs_contracting_dimensions\":[\"1\"],\"rhs_contracting_dimensions\":[\"0\"],\"lhs_batch_dimensions\":[],\"rhs_batch_dimensions\":[]},\"batch_size\":\"1\",\"selected_algorithm\":\"9\"}"
  %fusion.627 = f32[16,64,1024]{2,1,0} fusion(f32[1024]{0} %parameter.95, f32[1024,1024]{1,0} %custom-call.137), kind=kLoop, calls=%fused_computation.627, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/core.py" source_line=96}
  %parameter.97 = f32[1024]{0} parameter(15), parameter_replication={false}
  %parameter.82 = f32[32000,1024]{1,0} parameter(0), parameter_replication={false}
  %parameter.167 = s32[16,64]{1,0} parameter(85), parameter_replication={false}
  %fusion.626 = f32[64,16,1024]{2,1,0} fusion(f32[32000,1024]{1,0} %parameter.82, s32[16,64]{1,0} %parameter.167), kind=kLoop, calls=%fused_computation.626, metadata={op_type="transpose" op_name="pmap(_multi_device_update_fn)/transpose[ permutation=(1, 0, 2) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/combinators.py" source_line=342}
  %parameter.83 = f32[2048,4096]{1,0} parameter(1), parameter_replication={false}
  %parameter.84 = f32[4096]{0} parameter(2), parameter_replication={false}
  %bitcast.353 = f32[1,4096]{1,0} bitcast(f32[4096]{0} %parameter.84), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/broadcast_in_dim[ broadcast_dimensions=(1,)\n                                                shape=(1, 4096) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %copy.217 = s32[] copy(s32[] %constant_495)
  %copy.218 = f32[16,2048]{1,0} copy(f32[16,2048]{1,0} %broadcast.3322)
  %copy.219 = f32[64,16,1024]{2,1,0} copy(f32[64,16,1024]{2,1,0} %broadcast.3360)
  %copy.220 = f32[64,16,1024]{2,1,0} copy(f32[64,16,1024]{2,1,0} %broadcast.3360)
  %copy.221 = f32[64,16,1024]{2,1,0} copy(f32[64,16,1024]{2,1,0} %broadcast.3360)
  %copy.222 = f32[64,16,2048]{2,1,0} copy(f32[64,16,2048]{2,1,0} %broadcast.3366)
  %copy.223 = f32[64,16,1024]{2,1,0} copy(f32[64,16,1024]{2,1,0} %broadcast.3360)
  %copy.224 = f32[64,16,1024]{2,1,0} copy(f32[64,16,1024]{2,1,0} %broadcast.3360)
  %copy.225 = f32[64,16,1024]{2,1,0} copy(f32[64,16,1024]{2,1,0} %broadcast.3360)
  %copy.226 = f32[64,16,1024]{2,1,0} copy(f32[64,16,1024]{2,1,0} %broadcast.3360)
  %copy.227 = f32[64,16,1024]{2,1,0} copy(f32[64,16,1024]{2,1,0} %broadcast.3360)
  %copy.228 = f32[64,16,1024]{2,1,0} copy(f32[64,16,1024]{2,1,0} %broadcast.3360)
  %copy.229 = f32[64,16,1024]{2,1,0} copy(f32[64,16,1024]{2,1,0} %broadcast.3360)
  %copy.230 = f32[64,16,1024]{2,1,0} copy(f32[64,16,1024]{2,1,0} %broadcast.3360)
  %copy.231 = f32[64,16,1024]{2,1,0} copy(f32[64,16,1024]{2,1,0} %broadcast.3360)
  %tuple.788 = (f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) tuple(f32[64,16,1024]{2,1,0} %fusion.626, f32[2048,4096]{1,0} %parameter.83, f32[1,4096]{1,0} %bitcast.353, s32[] %copy.217, f32[16,2048]{1,0} %copy.218, /*index=5*/f32[64,16,1024]{2,1,0} %copy.219, f32[64,16,1024]{2,1,0} %copy.220, f32[64,16,1024]{2,1,0} %copy.221, f32[64,16,2048]{2,1,0} %copy.222, f32[64,16,1024]{2,1,0} %copy.223, /*index=10*/f32[64,16,1024]{2,1,0} %copy.224, f32[64,16,1024]{2,1,0} %copy.225, f32[64,16,1024]{2,1,0} %copy.226, f32[64,16,1024]{2,1,0} %copy.227, f32[64,16,1024]{2,1,0} %copy.228, /*index=15*/f32[64,16,1024]{2,1,0} %copy.229, f32[64,16,1024]{2,1,0} %copy.230, f32[64,16,1024]{2,1,0} %copy.231)
  %while.41 = (f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) while((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %tuple.788), condition=%cond_computation__36.920.clone.clone.clone, body=%body_computation__36.499.clone.clone.clone.clone, backend_config="{\"known_trip_count\":{\"n\":\"64\"}}"
  %get-tuple-element.4044 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %while.41), index=5, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %parameter.85 = f32[2048,4096]{1,0} parameter(3), parameter_replication={false}
  %parameter.86 = f32[4096]{0} parameter(4), parameter_replication={false}
  %bitcast.354 = f32[1,4096]{1,0} bitcast(f32[4096]{0} %parameter.86), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/broadcast_in_dim[ broadcast_dimensions=(1,)\n                                                shape=(1, 4096) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %copy.262 = s32[] copy(s32[] %constant_495)
  %copy.263 = f32[16,2048]{1,0} copy(f32[16,2048]{1,0} %broadcast.3322)
  %copy.264 = f32[64,16,1024]{2,1,0} copy(f32[64,16,1024]{2,1,0} %broadcast.3360)
  %copy.265 = f32[64,16,1024]{2,1,0} copy(f32[64,16,1024]{2,1,0} %broadcast.3360)
  %copy.266 = f32[64,16,1024]{2,1,0} copy(f32[64,16,1024]{2,1,0} %broadcast.3360)
  %copy.267 = f32[64,16,2048]{2,1,0} copy(f32[64,16,2048]{2,1,0} %broadcast.3366)
  %copy.268 = f32[64,16,1024]{2,1,0} copy(f32[64,16,1024]{2,1,0} %broadcast.3360)
  %copy.269 = f32[64,16,1024]{2,1,0} copy(f32[64,16,1024]{2,1,0} %broadcast.3360)
  %copy.270 = f32[64,16,1024]{2,1,0} copy(f32[64,16,1024]{2,1,0} %broadcast.3360)
  %copy.271 = f32[64,16,1024]{2,1,0} copy(f32[64,16,1024]{2,1,0} %broadcast.3360)
  %copy.272 = f32[64,16,1024]{2,1,0} copy(f32[64,16,1024]{2,1,0} %broadcast.3360)
  %copy.273 = f32[64,16,1024]{2,1,0} copy(f32[64,16,1024]{2,1,0} %broadcast.3360)
  %copy.274 = f32[64,16,1024]{2,1,0} copy(f32[64,16,1024]{2,1,0} %broadcast.3360)
  %copy.275 = f32[64,16,1024]{2,1,0} copy(f32[64,16,1024]{2,1,0} %broadcast.3360)
  %copy.276 = f32[64,16,1024]{2,1,0} copy(f32[64,16,1024]{2,1,0} %broadcast.3360)
  %tuple.791 = (f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) tuple(f32[64,16,1024]{2,1,0} %get-tuple-element.4044, f32[2048,4096]{1,0} %parameter.85, f32[1,4096]{1,0} %bitcast.354, s32[] %copy.262, f32[16,2048]{1,0} %copy.263, /*index=5*/f32[64,16,1024]{2,1,0} %copy.264, f32[64,16,1024]{2,1,0} %copy.265, f32[64,16,1024]{2,1,0} %copy.266, f32[64,16,2048]{2,1,0} %copy.267, f32[64,16,1024]{2,1,0} %copy.268, /*index=10*/f32[64,16,1024]{2,1,0} %copy.269, f32[64,16,1024]{2,1,0} %copy.270, f32[64,16,1024]{2,1,0} %copy.271, f32[64,16,1024]{2,1,0} %copy.272, f32[64,16,1024]{2,1,0} %copy.273, /*index=15*/f32[64,16,1024]{2,1,0} %copy.274, f32[64,16,1024]{2,1,0} %copy.275, f32[64,16,1024]{2,1,0} %copy.276)
  %while.42 = (f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) while((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %tuple.791), condition=%cond_computation__37.1600.clone.clone.clone, body=%body_computation__37.1179.clone.clone.clone.clone, backend_config="{\"known_trip_count\":{\"n\":\"64\"}}"
  %get-tuple-element.4165 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %while.42), index=5, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %parameter.87 = f32[2048,4096]{1,0} parameter(5), parameter_replication={false}
  %parameter.88 = f32[4096]{0} parameter(6), parameter_replication={false}
  %bitcast.355 = f32[1,4096]{1,0} bitcast(f32[4096]{0} %parameter.88), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/broadcast_in_dim[ broadcast_dimensions=(1,)\n                                                shape=(1, 4096) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %copy.307 = s32[] copy(s32[] %constant_495)
  %copy.308 = f32[16,2048]{1,0} copy(f32[16,2048]{1,0} %broadcast.3322)
  %copy.309 = f32[64,16,1024]{2,1,0} copy(f32[64,16,1024]{2,1,0} %broadcast.3360)
  %copy.310 = f32[64,16,1024]{2,1,0} copy(f32[64,16,1024]{2,1,0} %broadcast.3360)
  %copy.311 = f32[64,16,1024]{2,1,0} copy(f32[64,16,1024]{2,1,0} %broadcast.3360)
  %copy.312 = f32[64,16,2048]{2,1,0} copy(f32[64,16,2048]{2,1,0} %broadcast.3366)
  %copy.313 = f32[64,16,1024]{2,1,0} copy(f32[64,16,1024]{2,1,0} %broadcast.3360)
  %copy.314 = f32[64,16,1024]{2,1,0} copy(f32[64,16,1024]{2,1,0} %broadcast.3360)
  %copy.315 = f32[64,16,1024]{2,1,0} copy(f32[64,16,1024]{2,1,0} %broadcast.3360)
  %copy.316 = f32[64,16,1024]{2,1,0} copy(f32[64,16,1024]{2,1,0} %broadcast.3360)
  %copy.317 = f32[64,16,1024]{2,1,0} copy(f32[64,16,1024]{2,1,0} %broadcast.3360)
  %copy.318 = f32[64,16,1024]{2,1,0} copy(f32[64,16,1024]{2,1,0} %broadcast.3360)
  %copy.319 = f32[64,16,1024]{2,1,0} copy(f32[64,16,1024]{2,1,0} %broadcast.3360)
  %copy.320 = f32[64,16,1024]{2,1,0} copy(f32[64,16,1024]{2,1,0} %broadcast.3360)
  %copy.321 = f32[64,16,1024]{2,1,0} copy(f32[64,16,1024]{2,1,0} %broadcast.3360)
  %tuple.794 = (f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) tuple(f32[64,16,1024]{2,1,0} %get-tuple-element.4165, f32[2048,4096]{1,0} %parameter.87, f32[1,4096]{1,0} %bitcast.355, s32[] %copy.307, f32[16,2048]{1,0} %copy.308, /*index=5*/f32[64,16,1024]{2,1,0} %copy.309, f32[64,16,1024]{2,1,0} %copy.310, f32[64,16,1024]{2,1,0} %copy.311, f32[64,16,2048]{2,1,0} %copy.312, f32[64,16,1024]{2,1,0} %copy.313, /*index=10*/f32[64,16,1024]{2,1,0} %copy.314, f32[64,16,1024]{2,1,0} %copy.315, f32[64,16,1024]{2,1,0} %copy.316, f32[64,16,1024]{2,1,0} %copy.317, f32[64,16,1024]{2,1,0} %copy.318, /*index=15*/f32[64,16,1024]{2,1,0} %copy.319, f32[64,16,1024]{2,1,0} %copy.320, f32[64,16,1024]{2,1,0} %copy.321)
  %while.43 = (f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) while((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %tuple.794), condition=%cond_computation__38.2280.clone.clone.clone, body=%body_computation__38.1859.clone.clone.clone.clone, backend_config="{\"known_trip_count\":{\"n\":\"64\"}}"
  %get-tuple-element.4285 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %while.43), index=5, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %parameter.89 = f32[2048,4096]{1,0} parameter(7), parameter_replication={false}
  %parameter.90 = f32[4096]{0} parameter(8), parameter_replication={false}
  %bitcast.356 = f32[1,4096]{1,0} bitcast(f32[4096]{0} %parameter.90), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/broadcast_in_dim[ broadcast_dimensions=(1,)\n                                                shape=(1, 4096) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %copy.352 = s32[] copy(s32[] %constant_495)
  %copy.353 = f32[16,2048]{1,0} copy(f32[16,2048]{1,0} %broadcast.3322)
  %copy.354 = f32[64,16,1024]{2,1,0} copy(f32[64,16,1024]{2,1,0} %broadcast.3360)
  %copy.355 = f32[64,16,1024]{2,1,0} copy(f32[64,16,1024]{2,1,0} %broadcast.3360)
  %copy.356 = f32[64,16,1024]{2,1,0} copy(f32[64,16,1024]{2,1,0} %broadcast.3360)
  %copy.357 = f32[64,16,2048]{2,1,0} copy(f32[64,16,2048]{2,1,0} %broadcast.3366)
  %copy.358 = f32[64,16,1024]{2,1,0} copy(f32[64,16,1024]{2,1,0} %broadcast.3360)
  %copy.359 = f32[64,16,1024]{2,1,0} copy(f32[64,16,1024]{2,1,0} %broadcast.3360)
  %copy.360 = f32[64,16,1024]{2,1,0} copy(f32[64,16,1024]{2,1,0} %broadcast.3360)
  %copy.361 = f32[64,16,1024]{2,1,0} copy(f32[64,16,1024]{2,1,0} %broadcast.3360)
  %copy.362 = f32[64,16,1024]{2,1,0} copy(f32[64,16,1024]{2,1,0} %broadcast.3360)
  %copy.363 = f32[64,16,1024]{2,1,0} copy(f32[64,16,1024]{2,1,0} %broadcast.3360)
  %copy.364 = f32[64,16,1024]{2,1,0} copy(f32[64,16,1024]{2,1,0} %broadcast.3360)
  %copy.365 = f32[64,16,1024]{2,1,0} copy(f32[64,16,1024]{2,1,0} %broadcast.3360)
  %copy.366 = f32[64,16,1024]{2,1,0} copy(f32[64,16,1024]{2,1,0} %broadcast.3360)
  %tuple.797 = (f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) tuple(f32[64,16,1024]{2,1,0} %get-tuple-element.4285, f32[2048,4096]{1,0} %parameter.89, f32[1,4096]{1,0} %bitcast.356, s32[] %copy.352, f32[16,2048]{1,0} %copy.353, /*index=5*/f32[64,16,1024]{2,1,0} %copy.354, f32[64,16,1024]{2,1,0} %copy.355, f32[64,16,1024]{2,1,0} %copy.356, f32[64,16,2048]{2,1,0} %copy.357, f32[64,16,1024]{2,1,0} %copy.358, /*index=10*/f32[64,16,1024]{2,1,0} %copy.359, f32[64,16,1024]{2,1,0} %copy.360, f32[64,16,1024]{2,1,0} %copy.361, f32[64,16,1024]{2,1,0} %copy.362, f32[64,16,1024]{2,1,0} %copy.363, /*index=15*/f32[64,16,1024]{2,1,0} %copy.364, f32[64,16,1024]{2,1,0} %copy.365, f32[64,16,1024]{2,1,0} %copy.366)
  %while.44 = (f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) while((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %tuple.797), condition=%cond_computation__39.2960.clone.clone.clone, body=%body_computation__39.2539.clone.clone.clone.clone, backend_config="{\"known_trip_count\":{\"n\":\"64\"}}"
  %get-tuple-element.4404 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %while.44), index=5, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %fusion.625 = f32[1024,1024]{1,0} fusion(f32[64,16,1024]{2,1,0} %get-tuple-element.4404), kind=kLoop, calls=%fused_computation.625
  %parameter.96 = f32[1024,1024]{1,0} parameter(14), parameter_replication={false}
  %custom-call.138 = f32[1024,1024]{1,0} custom-call(f32[1024,1024]{1,0} %fusion.625, f32[1024,1024]{1,0} %parameter.96), custom_call_target="__cublas$gemm", backend_config="{\"alpha_real\":1,\"alpha_imag\":0,\"beta\":0,\"dot_dimension_numbers\":{\"lhs_contracting_dimensions\":[\"1\"],\"rhs_contracting_dimensions\":[\"0\"],\"lhs_batch_dimensions\":[],\"rhs_batch_dimensions\":[]},\"batch_size\":\"1\",\"selected_algorithm\":\"9\"}"
  %fusion.624 = f32[16,64,1024]{2,1,0} fusion(f32[1024]{0} %parameter.97, f32[1024,1024]{1,0} %custom-call.138), kind=kLoop, calls=%fused_computation.624, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/core.py" source_line=96}
  %fusion.623 = f32[16,1024,64]{2,1,0} fusion(f32[16,64,1024]{2,1,0} %fusion.624), kind=kLoop, calls=%fused_computation.623
  %custom-call.139 = f32[16,64,64]{2,1,0} custom-call(f32[16,64,1024]{2,1,0} %fusion.627, f32[16,1024,64]{2,1,0} %fusion.623), custom_call_target="__cublas$gemm", metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/attention.py" source_line=281}, backend_config="{\"alpha_real\":0.03125,\"alpha_imag\":0,\"beta\":0,\"dot_dimension_numbers\":{\"lhs_contracting_dimensions\":[\"2\"],\"rhs_contracting_dimensions\":[\"1\"],\"lhs_batch_dimensions\":[\"0\"],\"rhs_batch_dimensions\":[\"0\"]},\"batch_size\":\"16\",\"selected_algorithm\":\"18\"}"
  %fusion.621 = f32[16,64]{1,0} fusion(f32[16,64,64]{2,1,0} %custom-call.139, s32[16,64]{1,0} %parameter.167), kind=kInput, calls=%fused_computation.621
  %fusion.619 = f32[16,1,64,64]{3,2,0,1} fusion(f32[16,64,64]{2,1,0} %custom-call.139, s32[16,64]{1,0} %parameter.167, f32[16,64]{1,0} %fusion.621), kind=kLoop, calls=%fused_computation.619, metadata={op_type="exp" op_name="pmap(_multi_device_update_fn)/exp" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=94}
  %fusion.618 = f32[16,64]{1,0} fusion(f32[16,1,64,64]{3,2,0,1} %fusion.619), kind=kInput, calls=%fused_computation.618
  %fusion.689 = f32[16,1,64]{2,0,1} fusion(f32[16,64]{1,0} %fusion.618), kind=kLoop, calls=%fused_computation.689, metadata={op_type="log" op_name="pmap(_multi_device_update_fn)/log" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=94}
  %fusion.617 = f32[16,1,64,64]{3,2,0,1} fusion(f32[16,1,64]{2,0,1} %fusion.689, f32[16,64,64]{2,1,0} %custom-call.139, s32[16,64]{1,0} %parameter.167, f32[16,64]{1,0} %fusion.621), kind=kLoop, calls=%fused_computation.617, metadata={op_type="exp" op_name="pmap(_multi_device_update_fn)/exp" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/attention.py" source_line=287}
  %fusion.616 = f32[16,64,64]{2,1,0} fusion(pred[16,1,64,64]{3,2,0,1} %fusion.630, f32[16,1,64,64]{3,2,0,1} %fusion.617), kind=kLoop, calls=%fused_computation.616, metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/squeeze[ dimensions=(1,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/attention.py" source_line=293}
  %parameter.99 = f32[1024]{0} parameter(17), parameter_replication={false}
  %parameter.98 = f32[1024,1024]{1,0} parameter(16), parameter_replication={false}
  %custom-call.140 = f32[1024,1024]{1,0} custom-call(f32[1024,1024]{1,0} %fusion.625, f32[1024,1024]{1,0} %parameter.98), custom_call_target="__cublas$gemm", backend_config="{\"alpha_real\":1,\"alpha_imag\":0,\"beta\":0,\"dot_dimension_numbers\":{\"lhs_contracting_dimensions\":[\"1\"],\"rhs_contracting_dimensions\":[\"0\"],\"lhs_batch_dimensions\":[],\"rhs_batch_dimensions\":[]},\"batch_size\":\"1\",\"selected_algorithm\":\"9\"}"
  %fusion.615 = f32[16,64,1024]{2,1,0} fusion(f32[1024]{0} %parameter.99, f32[1024,1024]{1,0} %custom-call.140), kind=kLoop, calls=%fused_computation.615, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/core.py" source_line=96}
  %custom-call.141 = f32[16,64,1024]{2,1,0} custom-call(f32[16,64,64]{2,1,0} %fusion.616, f32[16,64,1024]{2,1,0} %fusion.615), custom_call_target="__cublas$gemm", backend_config="{\"alpha_real\":1,\"alpha_imag\":0,\"beta\":0,\"dot_dimension_numbers\":{\"lhs_contracting_dimensions\":[\"2\"],\"rhs_contracting_dimensions\":[\"1\"],\"lhs_batch_dimensions\":[\"0\"],\"rhs_batch_dimensions\":[\"0\"]},\"batch_size\":\"16\",\"selected_algorithm\":\"2\"}"
  %bitcast.369 = f32[1024,1024]{1,0} bitcast(f32[16,64,1024]{2,1,0} %custom-call.141)
  %parameter.100 = f32[1024,1024]{1,0} parameter(18), parameter_replication={false}
  %custom-call.142 = f32[1024,1024]{1,0} custom-call(f32[1024,1024]{1,0} %bitcast.369, f32[1024,1024]{1,0} %parameter.100), custom_call_target="__cublas$gemm", backend_config="{\"alpha_real\":1,\"alpha_imag\":0,\"beta\":0,\"dot_dimension_numbers\":{\"lhs_contracting_dimensions\":[\"1\"],\"rhs_contracting_dimensions\":[\"0\"],\"lhs_batch_dimensions\":[],\"rhs_batch_dimensions\":[]},\"batch_size\":\"1\",\"selected_algorithm\":\"9\"}"
  %fusion.614 = f32[64,16,1024]{2,1,0} fusion(f32[1024]{0} %parameter.101, f32[1024,1024]{1,0} %custom-call.142, f32[64,16,1024]{2,1,0} %get-tuple-element.4521), kind=kLoop, calls=%fused_computation.614, metadata={op_type="transpose" op_name="pmap(_multi_device_update_fn)/transpose[ permutation=(1, 0, 2) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/combinators.py" source_line=342}
  %parameter.102 = f32[2048,4096]{1,0} parameter(20), parameter_replication={false}
  %parameter.103 = f32[4096]{0} parameter(21), parameter_replication={false}
  %bitcast.370 = f32[1,4096]{1,0} bitcast(f32[4096]{0} %parameter.103), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/broadcast_in_dim[ broadcast_dimensions=(1,)\n                                                shape=(1, 4096) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %copy.397 = s32[] copy(s32[] %constant_495)
  %copy.398 = f32[16,2048]{1,0} copy(f32[16,2048]{1,0} %broadcast.3322)
  %copy.399 = f32[64,16,1024]{2,1,0} copy(f32[64,16,1024]{2,1,0} %broadcast.3360)
  %copy.400 = f32[64,16,1024]{2,1,0} copy(f32[64,16,1024]{2,1,0} %broadcast.3360)
  %copy.401 = f32[64,16,1024]{2,1,0} copy(f32[64,16,1024]{2,1,0} %broadcast.3360)
  %copy.402 = f32[64,16,2048]{2,1,0} copy(f32[64,16,2048]{2,1,0} %broadcast.3366)
  %copy.403 = f32[64,16,1024]{2,1,0} copy(f32[64,16,1024]{2,1,0} %broadcast.3360)
  %copy.404 = f32[64,16,1024]{2,1,0} copy(f32[64,16,1024]{2,1,0} %broadcast.3360)
  %copy.405 = f32[64,16,1024]{2,1,0} copy(f32[64,16,1024]{2,1,0} %broadcast.3360)
  %copy.406 = f32[64,16,1024]{2,1,0} copy(f32[64,16,1024]{2,1,0} %broadcast.3360)
  %copy.407 = f32[64,16,1024]{2,1,0} copy(f32[64,16,1024]{2,1,0} %broadcast.3360)
  %copy.408 = f32[64,16,1024]{2,1,0} copy(f32[64,16,1024]{2,1,0} %broadcast.3360)
  %copy.409 = f32[64,16,1024]{2,1,0} copy(f32[64,16,1024]{2,1,0} %broadcast.3360)
  %copy.410 = f32[64,16,1024]{2,1,0} copy(f32[64,16,1024]{2,1,0} %broadcast.3360)
  %copy.411 = f32[64,16,1024]{2,1,0} copy(f32[64,16,1024]{2,1,0} %broadcast.3360)
  %tuple.800 = (f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) tuple(f32[64,16,1024]{2,1,0} %fusion.614, f32[2048,4096]{1,0} %parameter.102, f32[1,4096]{1,0} %bitcast.370, s32[] %copy.397, f32[16,2048]{1,0} %copy.398, /*index=5*/f32[64,16,1024]{2,1,0} %copy.399, f32[64,16,1024]{2,1,0} %copy.400, f32[64,16,1024]{2,1,0} %copy.401, f32[64,16,2048]{2,1,0} %copy.402, f32[64,16,1024]{2,1,0} %copy.403, /*index=10*/f32[64,16,1024]{2,1,0} %copy.404, f32[64,16,1024]{2,1,0} %copy.405, f32[64,16,1024]{2,1,0} %copy.406, f32[64,16,1024]{2,1,0} %copy.407, f32[64,16,1024]{2,1,0} %copy.408, /*index=15*/f32[64,16,1024]{2,1,0} %copy.409, f32[64,16,1024]{2,1,0} %copy.410, f32[64,16,1024]{2,1,0} %copy.411)
  %while.46 = (f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) while((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %tuple.800), condition=%cond_computation__41.5330.clone.clone.clone, body=%body_computation__41.4909.clone.clone.clone.clone, backend_config="{\"known_trip_count\":{\"n\":\"64\"}}"
  %get-tuple-element.4642 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %while.46), index=5, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %parameter.104 = f32[2048,4096]{1,0} parameter(22), parameter_replication={false}
  %parameter.105 = f32[4096]{0} parameter(23), parameter_replication={false}
  %bitcast.371 = f32[1,4096]{1,0} bitcast(f32[4096]{0} %parameter.105), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/broadcast_in_dim[ broadcast_dimensions=(1,)\n                                                shape=(1, 4096) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %copy.442 = s32[] copy(s32[] %constant_495)
  %copy.443 = f32[16,2048]{1,0} copy(f32[16,2048]{1,0} %broadcast.3322)
  %copy.444 = f32[64,16,1024]{2,1,0} copy(f32[64,16,1024]{2,1,0} %broadcast.3360)
  %copy.445 = f32[64,16,1024]{2,1,0} copy(f32[64,16,1024]{2,1,0} %broadcast.3360)
  %copy.446 = f32[64,16,1024]{2,1,0} copy(f32[64,16,1024]{2,1,0} %broadcast.3360)
  %copy.447 = f32[64,16,2048]{2,1,0} copy(f32[64,16,2048]{2,1,0} %broadcast.3366)
  %copy.448 = f32[64,16,1024]{2,1,0} copy(f32[64,16,1024]{2,1,0} %broadcast.3360)
  %copy.449 = f32[64,16,1024]{2,1,0} copy(f32[64,16,1024]{2,1,0} %broadcast.3360)
  %copy.450 = f32[64,16,1024]{2,1,0} copy(f32[64,16,1024]{2,1,0} %broadcast.3360)
  %copy.451 = f32[64,16,1024]{2,1,0} copy(f32[64,16,1024]{2,1,0} %broadcast.3360)
  %copy.452 = f32[64,16,1024]{2,1,0} copy(f32[64,16,1024]{2,1,0} %broadcast.3360)
  %copy.453 = f32[64,16,1024]{2,1,0} copy(f32[64,16,1024]{2,1,0} %broadcast.3360)
  %copy.454 = f32[64,16,1024]{2,1,0} copy(f32[64,16,1024]{2,1,0} %broadcast.3360)
  %copy.455 = f32[64,16,1024]{2,1,0} copy(f32[64,16,1024]{2,1,0} %broadcast.3360)
  %copy.456 = f32[64,16,1024]{2,1,0} copy(f32[64,16,1024]{2,1,0} %broadcast.3360)
  %tuple.803 = (f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) tuple(f32[64,16,1024]{2,1,0} %get-tuple-element.4642, f32[2048,4096]{1,0} %parameter.104, f32[1,4096]{1,0} %bitcast.371, s32[] %copy.442, f32[16,2048]{1,0} %copy.443, /*index=5*/f32[64,16,1024]{2,1,0} %copy.444, f32[64,16,1024]{2,1,0} %copy.445, f32[64,16,1024]{2,1,0} %copy.446, f32[64,16,2048]{2,1,0} %copy.447, f32[64,16,1024]{2,1,0} %copy.448, /*index=10*/f32[64,16,1024]{2,1,0} %copy.449, f32[64,16,1024]{2,1,0} %copy.450, f32[64,16,1024]{2,1,0} %copy.451, f32[64,16,1024]{2,1,0} %copy.452, f32[64,16,1024]{2,1,0} %copy.453, /*index=15*/f32[64,16,1024]{2,1,0} %copy.454, f32[64,16,1024]{2,1,0} %copy.455, f32[64,16,1024]{2,1,0} %copy.456)
  %while.47 = (f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) while((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %tuple.803), condition=%cond_computation__42.6010.clone.clone.clone, body=%body_computation__42.5589.clone.clone.clone.clone, backend_config="{\"known_trip_count\":{\"n\":\"64\"}}"
  %get-tuple-element.4762 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %while.47), index=5, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %parameter.106 = f32[2048,4096]{1,0} parameter(24), parameter_replication={false}
  %parameter.107 = f32[4096]{0} parameter(25), parameter_replication={false}
  %bitcast.372 = f32[1,4096]{1,0} bitcast(f32[4096]{0} %parameter.107), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/broadcast_in_dim[ broadcast_dimensions=(1,)\n                                                shape=(1, 4096) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %copy.487 = s32[] copy(s32[] %constant_495)
  %copy.488 = f32[16,2048]{1,0} copy(f32[16,2048]{1,0} %broadcast.3322)
  %copy.489 = f32[64,16,1024]{2,1,0} copy(f32[64,16,1024]{2,1,0} %broadcast.3360)
  %copy.490 = f32[64,16,1024]{2,1,0} copy(f32[64,16,1024]{2,1,0} %broadcast.3360)
  %copy.491 = f32[64,16,1024]{2,1,0} copy(f32[64,16,1024]{2,1,0} %broadcast.3360)
  %copy.492 = f32[64,16,2048]{2,1,0} copy(f32[64,16,2048]{2,1,0} %broadcast.3366)
  %copy.493 = f32[64,16,1024]{2,1,0} copy(f32[64,16,1024]{2,1,0} %broadcast.3360)
  %copy.494 = f32[64,16,1024]{2,1,0} copy(f32[64,16,1024]{2,1,0} %broadcast.3360)
  %copy.495 = f32[64,16,1024]{2,1,0} copy(f32[64,16,1024]{2,1,0} %broadcast.3360)
  %copy.496 = f32[64,16,1024]{2,1,0} copy(f32[64,16,1024]{2,1,0} %broadcast.3360)
  %copy.497 = f32[64,16,1024]{2,1,0} copy(f32[64,16,1024]{2,1,0} %broadcast.3360)
  %copy.498 = f32[64,16,1024]{2,1,0} copy(f32[64,16,1024]{2,1,0} %broadcast.3360)
  %copy.499 = f32[64,16,1024]{2,1,0} copy(f32[64,16,1024]{2,1,0} %broadcast.3360)
  %copy.500 = f32[64,16,1024]{2,1,0} copy(f32[64,16,1024]{2,1,0} %broadcast.3360)
  %copy.501 = f32[64,16,1024]{2,1,0} copy(f32[64,16,1024]{2,1,0} %broadcast.3360)
  %tuple.806 = (f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) tuple(f32[64,16,1024]{2,1,0} %get-tuple-element.4762, f32[2048,4096]{1,0} %parameter.106, f32[1,4096]{1,0} %bitcast.372, s32[] %copy.487, f32[16,2048]{1,0} %copy.488, /*index=5*/f32[64,16,1024]{2,1,0} %copy.489, f32[64,16,1024]{2,1,0} %copy.490, f32[64,16,1024]{2,1,0} %copy.491, f32[64,16,2048]{2,1,0} %copy.492, f32[64,16,1024]{2,1,0} %copy.493, /*index=10*/f32[64,16,1024]{2,1,0} %copy.494, f32[64,16,1024]{2,1,0} %copy.495, f32[64,16,1024]{2,1,0} %copy.496, f32[64,16,1024]{2,1,0} %copy.497, f32[64,16,1024]{2,1,0} %copy.498, /*index=15*/f32[64,16,1024]{2,1,0} %copy.499, f32[64,16,1024]{2,1,0} %copy.500, f32[64,16,1024]{2,1,0} %copy.501)
  %while.48 = (f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) while((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %tuple.806), condition=%cond_computation__43.6690.clone.clone.clone, body=%body_computation__43.6269.clone.clone.clone.clone, backend_config="{\"known_trip_count\":{\"n\":\"64\"}}"
  %get-tuple-element.4888 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %while.48), index=5, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %parameter.108 = f32[2048,4096]{1,0} parameter(26), parameter_replication={false}
  %parameter.109 = f32[4096]{0} parameter(27), parameter_replication={false}
  %bitcast.373 = f32[1,4096]{1,0} bitcast(f32[4096]{0} %parameter.109), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/broadcast_in_dim[ broadcast_dimensions=(1,)\n                                                shape=(1, 4096) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %copy.532 = s32[] copy(s32[] %constant_495)
  %copy.533 = f32[16,2048]{1,0} copy(f32[16,2048]{1,0} %broadcast.3322)
  %copy.534 = f32[64,16,1024]{2,1,0} copy(f32[64,16,1024]{2,1,0} %broadcast.3360)
  %copy.535 = f32[64,16,1024]{2,1,0} copy(f32[64,16,1024]{2,1,0} %broadcast.3360)
  %copy.536 = f32[64,16,1024]{2,1,0} copy(f32[64,16,1024]{2,1,0} %broadcast.3360)
  %copy.538 = f32[64,16,1024]{2,1,0} copy(f32[64,16,1024]{2,1,0} %broadcast.3360)
  %copy.539 = f32[64,16,1024]{2,1,0} copy(f32[64,16,1024]{2,1,0} %broadcast.3360)
  %copy.540 = f32[64,16,1024]{2,1,0} copy(f32[64,16,1024]{2,1,0} %broadcast.3360)
  %copy.541 = f32[64,16,1024]{2,1,0} copy(f32[64,16,1024]{2,1,0} %broadcast.3360)
  %copy.542 = f32[64,16,1024]{2,1,0} copy(f32[64,16,1024]{2,1,0} %broadcast.3360)
  %copy.543 = f32[64,16,1024]{2,1,0} copy(f32[64,16,1024]{2,1,0} %broadcast.3360)
  %copy.544 = f32[64,16,1024]{2,1,0} copy(f32[64,16,1024]{2,1,0} %broadcast.3360)
  %copy.545 = f32[64,16,1024]{2,1,0} copy(f32[64,16,1024]{2,1,0} %broadcast.3360)
  %copy.546 = f32[64,16,1024]{2,1,0} copy(f32[64,16,1024]{2,1,0} %broadcast.3360)
  %tuple.809 = (f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) tuple(f32[64,16,1024]{2,1,0} %get-tuple-element.4888, f32[2048,4096]{1,0} %parameter.108, f32[1,4096]{1,0} %bitcast.373, s32[] %copy.532, f32[16,2048]{1,0} %copy.533, /*index=5*/f32[64,16,1024]{2,1,0} %copy.534, f32[64,16,1024]{2,1,0} %copy.535, f32[64,16,1024]{2,1,0} %copy.536, f32[64,16,2048]{2,1,0} %broadcast.3366, f32[64,16,1024]{2,1,0} %copy.538, /*index=10*/f32[64,16,1024]{2,1,0} %copy.539, f32[64,16,1024]{2,1,0} %copy.540, f32[64,16,1024]{2,1,0} %copy.541, f32[64,16,1024]{2,1,0} %copy.542, f32[64,16,1024]{2,1,0} %copy.543, /*index=15*/f32[64,16,1024]{2,1,0} %copy.544, f32[64,16,1024]{2,1,0} %copy.545, f32[64,16,1024]{2,1,0} %copy.546)
  %while.49 = (f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) while((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %tuple.809), condition=%cond_computation__44.7370.clone.clone.clone, body=%body_computation__44.6949.clone.clone.clone.clone, backend_config="{\"known_trip_count\":{\"n\":\"64\"}}"
  %get-tuple-element.5023 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %while.49), index=5, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %fusion.613 = f32[1024,1024]{1,0} fusion(f32[64,16,1024]{2,1,0} %get-tuple-element.5023), kind=kLoop, calls=%fused_computation.613
  %parameter.110 = f32[1024,256]{1,0} parameter(28), parameter_replication={false}
  %custom-call.143 = f32[1024,256]{1,0} custom-call(f32[1024,1024]{1,0} %fusion.613, f32[1024,256]{1,0} %parameter.110), custom_call_target="__cublas$gemm", backend_config="{\"alpha_real\":1,\"alpha_imag\":0,\"beta\":0,\"dot_dimension_numbers\":{\"lhs_contracting_dimensions\":[\"1\"],\"rhs_contracting_dimensions\":[\"0\"],\"lhs_batch_dimensions\":[],\"rhs_batch_dimensions\":[]},\"batch_size\":\"1\",\"selected_algorithm\":\"-1\"}"
  %fusion.706 = f32[16,64]{1,0} fusion(f32[256]{0} %parameter.111, f32[1024,256]{1,0} %custom-call.143), kind=kInput, calls=%fused_computation.706, metadata={op_type="reduce_max" op_name="pmap(_multi_device_update_fn)/reduce_max[ axes=(2,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=94}
  %fusion.766 = (f32[16,64]{1,0}, f32[16,64,256]{2,1,0}) fusion(f32[16,64]{1,0} %fusion.706, f32[256]{0} %parameter.111, f32[1024,256]{1,0} %custom-call.143), kind=kInput, calls=%fused_computation.766, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(2,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=94}
  %get-tuple-element.5553 = f32[16,64,256]{2,1,0} get-tuple-element((f32[16,64]{1,0}, f32[16,64,256]{2,1,0}) %fusion.766), index=1
  %get-tuple-element.5552 = f32[16,64]{1,0} get-tuple-element((f32[16,64]{1,0}, f32[16,64,256]{2,1,0}) %fusion.766), index=0
  %log.1 = f32[16,64]{1,0} log(f32[16,64]{1,0} %get-tuple-element.5552), metadata={op_type="log" op_name="pmap(_multi_device_update_fn)/log" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=94}
  %fusion.707 = f32[16,64]{1,0} fusion(f32[16,64]{1,0} %fusion.706, f32[16,64]{1,0} %log.1, f32[256]{0} %parameter.111, f32[1024,256]{1,0} %custom-call.143), kind=kInput, calls=%fused_computation.707, metadata={op_type="reduce_max" op_name="pmap(_multi_device_update_fn)/reduce_max[ axes=(2,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=94}
  %fusion.765 = (f32[16,64]{1,0}, f32[16,64,256]{2,1,0}) fusion(f32[16,64]{1,0} %fusion.707, f32[16,64]{1,0} %fusion.706, f32[16,64]{1,0} %log.1, f32[256]{0} %parameter.111, f32[1024,256]{1,0} %custom-call.143), kind=kInput, calls=%fused_computation.765, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(2,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=94}
  %get-tuple-element.5551 = f32[16,64,256]{2,1,0} get-tuple-element((f32[16,64]{1,0}, f32[16,64,256]{2,1,0}) %fusion.765), index=1
  %parameter.169 = f32[16,64]{1,0} parameter(87), parameter_replication={false}
  %get-tuple-element.5550 = f32[16,64]{1,0} get-tuple-element((f32[16,64]{1,0}, f32[16,64,256]{2,1,0}) %fusion.765), index=0
  %log.2 = f32[16,64]{1,0} log(f32[16,64]{1,0} %get-tuple-element.5550), metadata={op_type="log" op_name="pmap(_multi_device_update_fn)/log" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=94}
  %fusion.290 = f32[16,64]{1,0} fusion(f32[16,64]{1,0} %log.2, s32[16,64]{1,0} %parameter.168, f32[16,64]{1,0} %fusion.706, f32[16,64]{1,0} %log.1, f32[256]{0} %parameter.111, /*index=5*/f32[1024,256]{1,0} %custom-call.143, f32[16,64]{1,0} %fusion.707), kind=kInput, calls=%fused_computation.290, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(2,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/metrics.py" source_line=581}
  %fusion.656 = (f32[], f32[]) fusion(f32[16,64]{1,0} %parameter.169, f32[16,64]{1,0} %fusion.290), kind=kInput, calls=%fused_computation.656, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0, 1) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/metrics.py" source_line=102}
  %get-tuple-element.5545 = f32[] get-tuple-element((f32[], f32[]) %fusion.656), index=0
  %all-reduce.7676 = f32[] all-reduce(f32[] %get-tuple-element.5545), replica_groups={{0,1,2,3,4,5,6,7}}, to_apply=%primitive_computation_add__1.7672, metadata={op_type="psum" op_name="pmap(_multi_device_update_fn)/psum[ axes=(\'batch\',)\n                                    axis_index_groups=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=347}
  %fusion.654 = f32[16,64]{1,0} fusion(f32[16,64]{1,0} %parameter.169, f32[] %all-reduce.7676, s32[16,64]{1,0} %parameter.168), kind=kInput, calls=%fused_computation.654, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(2,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/core.py" source_line=794}
  %fusion.605 = f32[16,64]{1,0} fusion(f32[16,64,256]{2,1,0} %get-tuple-element.5551, f32[16,64]{1,0} %fusion.654, f32[16,64]{1,0} %get-tuple-element.5550, f32[16,64]{1,0} %parameter.169, f32[] %all-reduce.7676, /*index=5*/s32[16,64]{1,0} %parameter.168), kind=kInput, calls=%fused_computation.605, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(2,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/core.py" source_line=794}
  %fusion.604 = f32[16,64,256]{2,1,0} fusion(f32[16,64,256]{2,1,0} %get-tuple-element.5553, f32[16,64]{1,0} %fusion.605, f32[16,64]{1,0} %get-tuple-element.5552, f32[16,64,256]{2,1,0} %get-tuple-element.5551, f32[16,64]{1,0} %fusion.654, /*index=5*/f32[16,64]{1,0} %get-tuple-element.5550, f32[16,64]{1,0} %parameter.169, f32[] %all-reduce.7676, s32[16,64]{1,0} %parameter.168), kind=kLoop, calls=%fused_computation.604, metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=238}
  %bitcast.382 = f32[1024,256]{1,0} bitcast(f32[16,64,256]{2,1,0} %fusion.604)
  %custom-call.144 = f32[1024,1024]{1,0} custom-call(f32[1024,256]{1,0} %bitcast.382, f32[1024,256]{1,0} %parameter.110), custom_call_target="__cublas$gemm", backend_config="{\"alpha_real\":1,\"alpha_imag\":0,\"beta\":0,\"dot_dimension_numbers\":{\"lhs_contracting_dimensions\":[\"1\"],\"rhs_contracting_dimensions\":[\"1\"],\"lhs_batch_dimensions\":[],\"rhs_batch_dimensions\":[]},\"batch_size\":\"1\",\"selected_algorithm\":\"-1\"}"
  %fusion.603 = f32[64,16,1024]{2,1,0} fusion(f32[1024,1024]{1,0} %custom-call.144), kind=kLoop, calls=%fused_computation.603, metadata={op_type="transpose" op_name="pmap(_multi_device_update_fn)/transpose[ permutation=(1, 0, 2) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/combinators.py" source_line=342}
  %get-tuple-element.5024 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %while.49), index=6, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.5025 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %while.49), index=7, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.5026 = f32[64,16,2048]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %while.49), index=8, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.5027 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %while.49), index=9, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.5028 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %while.49), index=10, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.5029 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %while.49), index=11, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.5030 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %while.49), index=12, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.5031 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %while.49), index=13, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.5032 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %while.49), index=14, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.5033 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %while.49), index=15, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.5034 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %while.49), index=16, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.5035 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %while.49), index=17, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %copy.577 = s32[] copy(s32[] %constant_495)
  %broadcast.553 = f32[2048,4096]{1,0} broadcast(f32[] %constant_1), dimensions={}
  %copy.578 = f32[2048,4096]{1,0} copy(f32[2048,4096]{1,0} %broadcast.553)
  %broadcast.554 = f32[4096]{0} broadcast(f32[] %constant_1), dimensions={}
  %copy.579 = f32[4096]{0} copy(f32[4096]{0} %broadcast.554)
  %copy.580 = f32[16,2048]{1,0} copy(f32[16,2048]{1,0} %broadcast.3322)
  %copy.581 = f32[64,16,1024]{2,1,0} copy(f32[64,16,1024]{2,1,0} %broadcast.3360)
  %tuple.812 = (f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) tuple(f32[64,16,1024]{2,1,0} %fusion.603, f32[64,16,1024]{2,1,0} %get-tuple-element.5024, f32[64,16,1024]{2,1,0} %get-tuple-element.5025, f32[64,16,2048]{2,1,0} %get-tuple-element.5026, f32[64,16,1024]{2,1,0} %get-tuple-element.5027, /*index=5*/f32[64,16,1024]{2,1,0} %get-tuple-element.5028, f32[64,16,1024]{2,1,0} %get-tuple-element.5029, f32[64,16,1024]{2,1,0} %get-tuple-element.5030, f32[64,16,1024]{2,1,0} %get-tuple-element.5031, f32[64,16,1024]{2,1,0} %get-tuple-element.5032, /*index=10*/f32[64,16,1024]{2,1,0} %get-tuple-element.5033, f32[64,16,1024]{2,1,0} %get-tuple-element.5034, f32[64,16,1024]{2,1,0} %get-tuple-element.5035, f32[2048,4096]{1,0} %parameter.108, s32[] %copy.577, /*index=15*/f32[2048,4096]{1,0} %copy.578, f32[4096]{0} %copy.579, f32[16,2048]{1,0} %copy.580, f32[64,16,1024]{2,1,0} %copy.581)
  %while.32 = (f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) while((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %tuple.812), condition=%cond_computation__45.8178.clone.clone, body=%body_computation__45.7767.clone.clone, backend_config="{\"known_trip_count\":{\"n\":\"64\"}}"
  %get-tuple-element.3330 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %while.32), index=18, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=14\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.4889 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %while.48), index=6, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.4890 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %while.48), index=7, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.4891 = f32[64,16,2048]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %while.48), index=8, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.4892 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %while.48), index=9, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.4893 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %while.48), index=10, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.4894 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %while.48), index=11, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.4895 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %while.48), index=12, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.4896 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %while.48), index=13, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.4897 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %while.48), index=14, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.4898 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %while.48), index=15, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.4899 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %while.48), index=16, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.4900 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %while.48), index=17, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %copy.592 = s32[] copy(s32[] %constant_495)
  %copy.593 = f32[2048,4096]{1,0} copy(f32[2048,4096]{1,0} %broadcast.553)
  %copy.594 = f32[4096]{0} copy(f32[4096]{0} %broadcast.554)
  %copy.595 = f32[16,2048]{1,0} copy(f32[16,2048]{1,0} %broadcast.3322)
  %copy.596 = f32[64,16,1024]{2,1,0} copy(f32[64,16,1024]{2,1,0} %broadcast.3360)
  %tuple.815 = (f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) tuple(f32[64,16,1024]{2,1,0} %get-tuple-element.3330, f32[64,16,1024]{2,1,0} %get-tuple-element.4889, f32[64,16,1024]{2,1,0} %get-tuple-element.4890, f32[64,16,2048]{2,1,0} %get-tuple-element.4891, f32[64,16,1024]{2,1,0} %get-tuple-element.4892, /*index=5*/f32[64,16,1024]{2,1,0} %get-tuple-element.4893, f32[64,16,1024]{2,1,0} %get-tuple-element.4894, f32[64,16,1024]{2,1,0} %get-tuple-element.4895, f32[64,16,1024]{2,1,0} %get-tuple-element.4896, f32[64,16,1024]{2,1,0} %get-tuple-element.4897, /*index=10*/f32[64,16,1024]{2,1,0} %get-tuple-element.4898, f32[64,16,1024]{2,1,0} %get-tuple-element.4899, f32[64,16,1024]{2,1,0} %get-tuple-element.4900, f32[2048,4096]{1,0} %parameter.106, s32[] %copy.592, /*index=15*/f32[2048,4096]{1,0} %copy.593, f32[4096]{0} %copy.594, f32[16,2048]{1,0} %copy.595, f32[64,16,1024]{2,1,0} %copy.596)
  %while.33 = (f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) while((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %tuple.815), condition=%cond_computation__46.8690.clone.clone, body=%body_computation__46.8279.clone.clone, backend_config="{\"known_trip_count\":{\"n\":\"64\"}}"
  %get-tuple-element.3419 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %while.33), index=18, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=14\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.4763 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %while.47), index=6, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.4765 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %while.47), index=7, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.4766 = f32[64,16,2048]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %while.47), index=8, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.4767 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %while.47), index=9, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.4769 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %while.47), index=10, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.4770 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %while.47), index=11, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.4771 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %while.47), index=12, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.4772 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %while.47), index=13, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.4773 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %while.47), index=14, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.4774 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %while.47), index=15, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.4775 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %while.47), index=16, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.4776 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %while.47), index=17, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %copy.607 = s32[] copy(s32[] %constant_495)
  %copy.608 = f32[2048,4096]{1,0} copy(f32[2048,4096]{1,0} %broadcast.553)
  %copy.609 = f32[4096]{0} copy(f32[4096]{0} %broadcast.554)
  %copy.610 = f32[16,2048]{1,0} copy(f32[16,2048]{1,0} %broadcast.3322)
  %copy.611 = f32[64,16,1024]{2,1,0} copy(f32[64,16,1024]{2,1,0} %broadcast.3360)
  %tuple.818 = (f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) tuple(f32[64,16,1024]{2,1,0} %get-tuple-element.3419, f32[64,16,1024]{2,1,0} %get-tuple-element.4763, f32[64,16,1024]{2,1,0} %get-tuple-element.4765, f32[64,16,2048]{2,1,0} %get-tuple-element.4766, f32[64,16,1024]{2,1,0} %get-tuple-element.4767, /*index=5*/f32[64,16,1024]{2,1,0} %get-tuple-element.4769, f32[64,16,1024]{2,1,0} %get-tuple-element.4770, f32[64,16,1024]{2,1,0} %get-tuple-element.4771, f32[64,16,1024]{2,1,0} %get-tuple-element.4772, f32[64,16,1024]{2,1,0} %get-tuple-element.4773, /*index=10*/f32[64,16,1024]{2,1,0} %get-tuple-element.4774, f32[64,16,1024]{2,1,0} %get-tuple-element.4775, f32[64,16,1024]{2,1,0} %get-tuple-element.4776, f32[2048,4096]{1,0} %parameter.104, s32[] %copy.607, /*index=15*/f32[2048,4096]{1,0} %copy.608, f32[4096]{0} %copy.609, f32[16,2048]{1,0} %copy.610, f32[64,16,1024]{2,1,0} %copy.611)
  %while.34 = (f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) while((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %tuple.818), condition=%cond_computation__47.9202.clone.clone, body=%body_computation__47.8791.clone.clone, backend_config="{\"known_trip_count\":{\"n\":\"64\"}}"
  %get-tuple-element.3482 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %while.34), index=18, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=14\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.4643 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %while.46), index=6, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.4644 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %while.46), index=7, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.4645 = f32[64,16,2048]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %while.46), index=8, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.4646 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %while.46), index=9, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.4647 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %while.46), index=10, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.4649 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %while.46), index=11, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.4650 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %while.46), index=12, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.4651 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %while.46), index=13, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.4652 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %while.46), index=14, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.4653 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %while.46), index=15, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.4654 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %while.46), index=16, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.4655 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %while.46), index=17, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %copy.622 = s32[] copy(s32[] %constant_495)
  %copy.623 = f32[2048,4096]{1,0} copy(f32[2048,4096]{1,0} %broadcast.553)
  %copy.624 = f32[4096]{0} copy(f32[4096]{0} %broadcast.554)
  %copy.625 = f32[16,2048]{1,0} copy(f32[16,2048]{1,0} %broadcast.3322)
  %copy.626 = f32[64,16,1024]{2,1,0} copy(f32[64,16,1024]{2,1,0} %broadcast.3360)
  %tuple.821 = (f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) tuple(f32[64,16,1024]{2,1,0} %get-tuple-element.3482, f32[64,16,1024]{2,1,0} %get-tuple-element.4643, f32[64,16,1024]{2,1,0} %get-tuple-element.4644, f32[64,16,2048]{2,1,0} %get-tuple-element.4645, f32[64,16,1024]{2,1,0} %get-tuple-element.4646, /*index=5*/f32[64,16,1024]{2,1,0} %get-tuple-element.4647, f32[64,16,1024]{2,1,0} %get-tuple-element.4649, f32[64,16,1024]{2,1,0} %get-tuple-element.4650, f32[64,16,1024]{2,1,0} %get-tuple-element.4651, f32[64,16,1024]{2,1,0} %get-tuple-element.4652, /*index=10*/f32[64,16,1024]{2,1,0} %get-tuple-element.4653, f32[64,16,1024]{2,1,0} %get-tuple-element.4654, f32[64,16,1024]{2,1,0} %get-tuple-element.4655, f32[2048,4096]{1,0} %parameter.102, s32[] %copy.622, /*index=15*/f32[2048,4096]{1,0} %copy.623, f32[4096]{0} %copy.624, f32[16,2048]{1,0} %copy.625, f32[64,16,1024]{2,1,0} %copy.626)
  %while.35 = (f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) while((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %tuple.821), condition=%cond_computation__48.9714.clone.clone, body=%body_computation__48.9303.clone.clone, backend_config="{\"known_trip_count\":{\"n\":\"64\"}}"
  %get-tuple-element.3544 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %while.35), index=18, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=14\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %fusion.602 = (f32[1024,1024]{1,0}, f32[1024,1024]{1,0}) fusion(f32[64,16,1024]{2,1,0} %get-tuple-element.3544), kind=kLoop, calls=%fused_computation.602
  %get-tuple-element.5540 = f32[1024,1024]{1,0} get-tuple-element((f32[1024,1024]{1,0}, f32[1024,1024]{1,0}) %fusion.602), index=0
  %custom-call.145 = f32[1024,1024]{1,0} custom-call(f32[1024,1024]{1,0} %get-tuple-element.5540, f32[1024,1024]{1,0} %parameter.100), custom_call_target="__cublas$gemm", backend_config="{\"alpha_real\":1,\"alpha_imag\":0,\"beta\":0,\"dot_dimension_numbers\":{\"lhs_contracting_dimensions\":[\"1\"],\"rhs_contracting_dimensions\":[\"1\"],\"lhs_batch_dimensions\":[],\"rhs_batch_dimensions\":[]},\"batch_size\":\"1\",\"selected_algorithm\":\"7\"}"
  %fusion.601 = f32[16,1024,64]{2,1,0} fusion(f32[1024,1024]{1,0} %custom-call.145), kind=kLoop, calls=%fused_computation.601
  %custom-call.146 = f32[16,1024,64]{2,1,0} custom-call(f32[16,1024,64]{2,1,0} %fusion.601, f32[16,64,64]{2,1,0} %fusion.616), custom_call_target="__cublas$gemm", backend_config="{\"alpha_real\":1,\"alpha_imag\":0,\"beta\":0,\"dot_dimension_numbers\":{\"lhs_contracting_dimensions\":[\"2\"],\"rhs_contracting_dimensions\":[\"1\"],\"lhs_batch_dimensions\":[\"0\"],\"rhs_batch_dimensions\":[\"0\"]},\"batch_size\":\"16\",\"selected_algorithm\":\"0\"}"
  %fusion.599 = (f32[1024,1024]{1,0}, f32[1024,1024]{1,0}) fusion(f32[16,1024,64]{2,1,0} %custom-call.146), kind=kLoop, calls=%fused_computation.599
  %get-tuple-element.5538 = f32[1024,1024]{1,0} get-tuple-element((f32[1024,1024]{1,0}, f32[1024,1024]{1,0}) %fusion.599), index=0
  %bitcast.387 = f32[16,64,1024]{2,1,0} bitcast(f32[1024,1024]{1,0} %custom-call.145)
  %fusion.598 = f32[16,1024,64]{2,1,0} fusion(f32[16,64,1024]{2,1,0} %fusion.615), kind=kLoop, calls=%fused_computation.598
  %custom-call.148 = f32[16,64,64]{2,1,0} custom-call(f32[16,64,1024]{2,1,0} %bitcast.387, f32[16,1024,64]{2,1,0} %fusion.598), custom_call_target="__cublas$gemm", metadata={op_type="dot_general" op_name="pmap(_multi_device_update_fn)/dot_general[ dimension_numbers=(((2, 3), (1, 3)), ((0,), (0,)))\n                                           precision=None\n                                           preferred_element_type=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/attention.py" source_line=293}, backend_config="{\"alpha_real\":1,\"alpha_imag\":0,\"beta\":0,\"dot_dimension_numbers\":{\"lhs_contracting_dimensions\":[\"2\"],\"rhs_contracting_dimensions\":[\"1\"],\"lhs_batch_dimensions\":[\"0\"],\"rhs_batch_dimensions\":[\"0\"]},\"batch_size\":\"16\",\"selected_algorithm\":\"18\"}"
  %fusion.596 = f32[16,64]{1,0} fusion(f32[16,1,64,64]{3,2,0,1} %fusion.617, pred[16,1,64,64]{3,2,0,1} %fusion.630, f32[16,64,64]{2,1,0} %custom-call.148), kind=kInput, calls=%fused_computation.596
  %fusion.595 = f32[16,1,64,64]{3,2,0,1} fusion(f32[16,1,64,64]{3,2,0,1} %fusion.619, f32[16,64]{1,0} %fusion.596, f32[16,64]{1,0} %fusion.618, s32[16,64]{1,0} %parameter.167, f32[16,1,64,64]{3,2,0,1} %fusion.617, /*index=5*/pred[16,1,64,64]{3,2,0,1} %fusion.630, f32[16,64,64]{2,1,0} %custom-call.148), kind=kLoop, calls=%fused_computation.595, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/attention.py" source_line=281}
  %fusion.594 = f32[16,64,64]{2,1,0} fusion(f32[16,1,64,64]{3,2,0,1} %fusion.595), kind=kLoop, calls=%fused_computation.594
  %custom-call.149 = f32[16,64,1024]{2,1,0} custom-call(f32[16,64,64]{2,1,0} %fusion.594, f32[16,64,1024]{2,1,0} %fusion.627), custom_call_target="__cublas$gemm", metadata={op_type="reshape" op_name="pmap(_multi_device_update_fn)/reshape[ dimensions=None\n                                       new_sizes=(16, 64, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/attention.py" source_line=359}, backend_config="{\"alpha_real\":1,\"alpha_imag\":0,\"beta\":0,\"dot_dimension_numbers\":{\"lhs_contracting_dimensions\":[\"2\"],\"rhs_contracting_dimensions\":[\"1\"],\"lhs_batch_dimensions\":[\"0\"],\"rhs_batch_dimensions\":[\"0\"]},\"batch_size\":\"16\",\"selected_algorithm\":\"2\"}"
  %bitcast.394 = f32[1024,1024]{1,0} bitcast(f32[16,64,1024]{2,1,0} %custom-call.149)
  %custom-call.150 = f32[1024,1024]{1,0} custom-call(f32[1024,1024]{1,0} %bitcast.394, f32[1024,1024]{1,0} %parameter.96), custom_call_target="__cublas$gemm", backend_config="{\"alpha_real\":1,\"alpha_imag\":0,\"beta\":0,\"dot_dimension_numbers\":{\"lhs_contracting_dimensions\":[\"1\"],\"rhs_contracting_dimensions\":[\"1\"],\"lhs_batch_dimensions\":[],\"rhs_batch_dimensions\":[]},\"batch_size\":\"1\",\"selected_algorithm\":\"7\"}"
  %custom-call.151 = f32[1024,1024]{1,0} custom-call(f32[1024,1024]{1,0} %get-tuple-element.5538, f32[1024,1024]{1,0} %parameter.98, f32[1024,1024]{1,0} %custom-call.150), custom_call_target="__cublas$gemm", metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=238}, backend_config="{\"alpha_real\":1,\"alpha_imag\":0,\"beta\":1,\"dot_dimension_numbers\":{\"lhs_contracting_dimensions\":[\"1\"],\"rhs_contracting_dimensions\":[\"1\"],\"lhs_batch_dimensions\":[],\"rhs_batch_dimensions\":[]},\"batch_size\":\"1\",\"selected_algorithm\":\"9\"}"
  %fusion.593 = f32[64,16,1024]{2,1,0} fusion(f32[1024,1024]{1,0} %custom-call.151), kind=kLoop, calls=%fused_computation.593, metadata={op_type="transpose" op_name="pmap(_multi_device_update_fn)/transpose[ permutation=(1, 0, 2) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/combinators.py" source_line=342}
  %get-tuple-element.4405 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %while.44), index=6, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.4406 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %while.44), index=7, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.4407 = f32[64,16,2048]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %while.44), index=8, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.4408 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %while.44), index=9, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.4409 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %while.44), index=10, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.4410 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %while.44), index=11, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.4411 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %while.44), index=12, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.4412 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %while.44), index=13, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.4413 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %while.44), index=14, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.4414 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %while.44), index=15, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.4416 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %while.44), index=16, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.4417 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %while.44), index=17, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %copy.637 = s32[] copy(s32[] %constant_495)
  %copy.638 = f32[2048,4096]{1,0} copy(f32[2048,4096]{1,0} %broadcast.553)
  %copy.639 = f32[4096]{0} copy(f32[4096]{0} %broadcast.554)
  %copy.640 = f32[16,2048]{1,0} copy(f32[16,2048]{1,0} %broadcast.3322)
  %copy.641 = f32[64,16,1024]{2,1,0} copy(f32[64,16,1024]{2,1,0} %broadcast.3360)
  %tuple.824 = (f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) tuple(f32[64,16,1024]{2,1,0} %fusion.593, f32[64,16,1024]{2,1,0} %get-tuple-element.4405, f32[64,16,1024]{2,1,0} %get-tuple-element.4406, f32[64,16,2048]{2,1,0} %get-tuple-element.4407, f32[64,16,1024]{2,1,0} %get-tuple-element.4408, /*index=5*/f32[64,16,1024]{2,1,0} %get-tuple-element.4409, f32[64,16,1024]{2,1,0} %get-tuple-element.4410, f32[64,16,1024]{2,1,0} %get-tuple-element.4411, f32[64,16,1024]{2,1,0} %get-tuple-element.4412, f32[64,16,1024]{2,1,0} %get-tuple-element.4413, /*index=10*/f32[64,16,1024]{2,1,0} %get-tuple-element.4414, f32[64,16,1024]{2,1,0} %get-tuple-element.4416, f32[64,16,1024]{2,1,0} %get-tuple-element.4417, f32[2048,4096]{1,0} %parameter.89, s32[] %copy.637, /*index=15*/f32[2048,4096]{1,0} %copy.638, f32[4096]{0} %copy.639, f32[16,2048]{1,0} %copy.640, f32[64,16,1024]{2,1,0} %copy.641)
  %while.36 = (f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) while((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %tuple.824), condition=%cond_computation__49.10340.clone.clone, body=%body_computation__49.9929.clone.clone, backend_config="{\"known_trip_count\":{\"n\":\"64\"}}"
  %get-tuple-element.3605 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %while.36), index=18, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=14\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.4286 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %while.43), index=6, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.4287 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %while.43), index=7, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.4288 = f32[64,16,2048]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %while.43), index=8, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.4289 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %while.43), index=9, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.4290 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %while.43), index=10, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.4291 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %while.43), index=11, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.4292 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %while.43), index=12, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.4293 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %while.43), index=13, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.4294 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %while.43), index=14, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.4295 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %while.43), index=15, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.4296 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %while.43), index=16, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.4297 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %while.43), index=17, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %copy.652 = s32[] copy(s32[] %constant_495)
  %copy.653 = f32[2048,4096]{1,0} copy(f32[2048,4096]{1,0} %broadcast.553)
  %copy.654 = f32[4096]{0} copy(f32[4096]{0} %broadcast.554)
  %copy.655 = f32[16,2048]{1,0} copy(f32[16,2048]{1,0} %broadcast.3322)
  %copy.656 = f32[64,16,1024]{2,1,0} copy(f32[64,16,1024]{2,1,0} %broadcast.3360)
  %tuple.827 = (f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) tuple(f32[64,16,1024]{2,1,0} %get-tuple-element.3605, f32[64,16,1024]{2,1,0} %get-tuple-element.4286, f32[64,16,1024]{2,1,0} %get-tuple-element.4287, f32[64,16,2048]{2,1,0} %get-tuple-element.4288, f32[64,16,1024]{2,1,0} %get-tuple-element.4289, /*index=5*/f32[64,16,1024]{2,1,0} %get-tuple-element.4290, f32[64,16,1024]{2,1,0} %get-tuple-element.4291, f32[64,16,1024]{2,1,0} %get-tuple-element.4292, f32[64,16,1024]{2,1,0} %get-tuple-element.4293, f32[64,16,1024]{2,1,0} %get-tuple-element.4294, /*index=10*/f32[64,16,1024]{2,1,0} %get-tuple-element.4295, f32[64,16,1024]{2,1,0} %get-tuple-element.4296, f32[64,16,1024]{2,1,0} %get-tuple-element.4297, f32[2048,4096]{1,0} %parameter.87, s32[] %copy.652, /*index=15*/f32[2048,4096]{1,0} %copy.653, f32[4096]{0} %copy.654, f32[16,2048]{1,0} %copy.655, f32[64,16,1024]{2,1,0} %copy.656)
  %while.37 = (f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) while((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %tuple.827), condition=%cond_computation__50.10852.clone.clone, body=%body_computation__50.10441.clone.clone, backend_config="{\"known_trip_count\":{\"n\":\"64\"}}"
  %get-tuple-element.3666 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %while.37), index=18, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=14\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.4166 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %while.42), index=6, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.4167 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %while.42), index=7, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.4168 = f32[64,16,2048]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %while.42), index=8, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.4169 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %while.42), index=9, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.4170 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %while.42), index=10, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.4172 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %while.42), index=11, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.4173 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %while.42), index=12, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.4174 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %while.42), index=13, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.4176 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %while.42), index=14, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.4177 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %while.42), index=15, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.4178 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %while.42), index=16, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.4179 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %while.42), index=17, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %copy.667 = s32[] copy(s32[] %constant_495)
  %copy.668 = f32[2048,4096]{1,0} copy(f32[2048,4096]{1,0} %broadcast.553)
  %copy.669 = f32[4096]{0} copy(f32[4096]{0} %broadcast.554)
  %copy.670 = f32[16,2048]{1,0} copy(f32[16,2048]{1,0} %broadcast.3322)
  %copy.671 = f32[64,16,1024]{2,1,0} copy(f32[64,16,1024]{2,1,0} %broadcast.3360)
  %tuple.830 = (f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) tuple(f32[64,16,1024]{2,1,0} %get-tuple-element.3666, f32[64,16,1024]{2,1,0} %get-tuple-element.4166, f32[64,16,1024]{2,1,0} %get-tuple-element.4167, f32[64,16,2048]{2,1,0} %get-tuple-element.4168, f32[64,16,1024]{2,1,0} %get-tuple-element.4169, /*index=5*/f32[64,16,1024]{2,1,0} %get-tuple-element.4170, f32[64,16,1024]{2,1,0} %get-tuple-element.4172, f32[64,16,1024]{2,1,0} %get-tuple-element.4173, f32[64,16,1024]{2,1,0} %get-tuple-element.4174, f32[64,16,1024]{2,1,0} %get-tuple-element.4176, /*index=10*/f32[64,16,1024]{2,1,0} %get-tuple-element.4177, f32[64,16,1024]{2,1,0} %get-tuple-element.4178, f32[64,16,1024]{2,1,0} %get-tuple-element.4179, f32[2048,4096]{1,0} %parameter.85, s32[] %copy.667, /*index=15*/f32[2048,4096]{1,0} %copy.668, f32[4096]{0} %copy.669, f32[16,2048]{1,0} %copy.670, f32[64,16,1024]{2,1,0} %copy.671)
  %while.38 = (f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) while((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %tuple.830), condition=%cond_computation__51.11364.clone.clone, body=%body_computation__51.10953.clone.clone, backend_config="{\"known_trip_count\":{\"n\":\"64\"}}"
  %get-tuple-element.3727 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %while.38), index=18, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=14\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.4045 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %while.41), index=6, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.4046 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %while.41), index=7, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.4047 = f32[64,16,2048]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %while.41), index=8, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.4048 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %while.41), index=9, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.4049 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %while.41), index=10, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.4050 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %while.41), index=11, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.4051 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %while.41), index=12, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.4052 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %while.41), index=13, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.4053 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %while.41), index=14, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.4054 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %while.41), index=15, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.4055 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %while.41), index=16, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.4056 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %while.41), index=17, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %copy.682 = s32[] copy(s32[] %constant_495)
  %copy.683 = f32[2048,4096]{1,0} copy(f32[2048,4096]{1,0} %broadcast.553)
  %copy.684 = f32[4096]{0} copy(f32[4096]{0} %broadcast.554)
  %copy.685 = f32[16,2048]{1,0} copy(f32[16,2048]{1,0} %broadcast.3322)
  %copy.686 = f32[64,16,1024]{2,1,0} copy(f32[64,16,1024]{2,1,0} %broadcast.3360)
  %tuple.833 = (f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) tuple(f32[64,16,1024]{2,1,0} %get-tuple-element.3727, f32[64,16,1024]{2,1,0} %get-tuple-element.4045, f32[64,16,1024]{2,1,0} %get-tuple-element.4046, f32[64,16,2048]{2,1,0} %get-tuple-element.4047, f32[64,16,1024]{2,1,0} %get-tuple-element.4048, /*index=5*/f32[64,16,1024]{2,1,0} %get-tuple-element.4049, f32[64,16,1024]{2,1,0} %get-tuple-element.4050, f32[64,16,1024]{2,1,0} %get-tuple-element.4051, f32[64,16,1024]{2,1,0} %get-tuple-element.4052, f32[64,16,1024]{2,1,0} %get-tuple-element.4053, /*index=10*/f32[64,16,1024]{2,1,0} %get-tuple-element.4054, f32[64,16,1024]{2,1,0} %get-tuple-element.4055, f32[64,16,1024]{2,1,0} %get-tuple-element.4056, f32[2048,4096]{1,0} %parameter.83, s32[] %copy.682, /*index=15*/f32[2048,4096]{1,0} %copy.683, f32[4096]{0} %copy.684, f32[16,2048]{1,0} %copy.685, f32[64,16,1024]{2,1,0} %copy.686)
  %while.39 = (f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) while((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %tuple.833), condition=%cond_computation__52.11876.clone.clone, body=%body_computation__52.11465.clone.clone, backend_config="{\"known_trip_count\":{\"n\":\"64\"}}"
  %get-tuple-element.3788 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %while.39), index=18, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=14\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %fusion.592 = f32[32000,1024]{1,0} fusion(f32[64,16,1024]{2,1,0} %get-tuple-element.3788, s32[16,64]{1,0} %parameter.167), kind=kInput, calls=%fused_computation.592, metadata={op_type="scatter-add" op_name="pmap(_multi_device_update_fn)/scatter-add[ dimension_numbers=ScatterDimensionNumbers(update_window_dims=(2,), inserted_window_dims=(0,), scatter_dims_to_operand_dims=(0,))\n                                           indices_are_sorted=False\n                                           unique_indices=False\n                                           update_consts=(  ) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/core.py" source_line=182}
  %all-reduce.12508 = f32[32000,1024]{1,0} all-reduce(f32[32000,1024]{1,0} %fusion.592), replica_groups={{0,1,2,3,4,5,6,7}}, to_apply=%primitive_computation_add__1.12504, metadata={op_type="psum" op_name="pmap(_multi_device_update_fn)/psum[ axes=(\'batch\',)\n                                    axis_index_groups=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=347}
  %parameter.162 = f32[] parameter(80), parameter_replication={false}
  %get-tuple-element.5544 = f32[1024,1024]{1,0} get-tuple-element((f32[1024,1024]{1,0}, f32[1024,1024]{1,0}) %fusion.602), index=1
  %custom-call.157 = f32[1024,1024]{1,0} custom-call(f32[1024,1024]{1,0} %bitcast.369, f32[1024,1024]{1,0} %get-tuple-element.5544), custom_call_target="__cublas$gemm", metadata={op_type="transpose" op_name="pmap(_multi_device_update_fn)/transpose[ permutation=(1, 0) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/core.py" source_line=96}, backend_config="{\"alpha_real\":1,\"alpha_imag\":0,\"beta\":0,\"dot_dimension_numbers\":{\"lhs_contracting_dimensions\":[\"0\"],\"rhs_contracting_dimensions\":[\"1\"],\"lhs_batch_dimensions\":[],\"rhs_batch_dimensions\":[]},\"batch_size\":\"1\",\"selected_algorithm\":\"-1\"}"
  %get-tuple-element.5539 = f32[1024,1024]{1,0} get-tuple-element((f32[1024,1024]{1,0}, f32[1024,1024]{1,0}) %fusion.599), index=1
  %custom-call.156 = f32[1024,1024]{1,0} custom-call(f32[1024,1024]{1,0} %fusion.625, f32[1024,1024]{1,0} %get-tuple-element.5539), custom_call_target="__cublas$gemm", metadata={op_type="transpose" op_name="pmap(_multi_device_update_fn)/transpose[ permutation=(1, 0) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/core.py" source_line=96}, backend_config="{\"alpha_real\":1,\"alpha_imag\":0,\"beta\":0,\"dot_dimension_numbers\":{\"lhs_contracting_dimensions\":[\"0\"],\"rhs_contracting_dimensions\":[\"1\"],\"lhs_batch_dimensions\":[],\"rhs_batch_dimensions\":[]},\"batch_size\":\"1\",\"selected_algorithm\":\"-1\"}"
  %fusion.454 = f32[1024,1024]{0,1} fusion(f32[16,64,1024]{2,1,0} %custom-call.149), kind=kLoop, calls=%fused_computation.454
  %custom-call.155 = f32[1024,1024]{1,0} custom-call(f32[1024,1024]{1,0} %fusion.625, f32[1024,1024]{0,1} %fusion.454), custom_call_target="__cublas$gemm", metadata={op_type="transpose" op_name="pmap(_multi_device_update_fn)/transpose[ permutation=(1, 0) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/core.py" source_line=96}, backend_config="{\"alpha_real\":1,\"alpha_imag\":0,\"beta\":0,\"dot_dimension_numbers\":{\"lhs_contracting_dimensions\":[\"0\"],\"rhs_contracting_dimensions\":[\"1\"],\"lhs_batch_dimensions\":[],\"rhs_batch_dimensions\":[]},\"batch_size\":\"1\",\"selected_algorithm\":\"-1\"}"
  %bitcast.395 = f32[16,64,64]{2,1,0} bitcast(f32[16,1,64,64]{3,2,0,1} %fusion.595)
  %custom-call.152 = f32[16,64,1024]{2,1,0} custom-call(f32[16,64,64]{2,1,0} %bitcast.395, f32[16,64,1024]{2,1,0} %fusion.624), custom_call_target="__cublas$gemm", metadata={op_type="dot_general" op_name="pmap(_multi_device_update_fn)/dot_general[ dimension_numbers=(((2, 3), (1, 3)), ((0,), (0,)))\n                                           precision=None\n                                           preferred_element_type=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/attention.py" source_line=281}, backend_config="{\"alpha_real\":1,\"alpha_imag\":0,\"beta\":0,\"dot_dimension_numbers\":{\"lhs_contracting_dimensions\":[\"2\"],\"rhs_contracting_dimensions\":[\"1\"],\"lhs_batch_dimensions\":[\"0\"],\"rhs_batch_dimensions\":[\"0\"]},\"batch_size\":\"16\",\"selected_algorithm\":\"2\"}"
  %fusion.473 = f32[1024,1024]{0,1} fusion(f32[16,64,1024]{2,1,0} %custom-call.152), kind=kLoop, calls=%fused_computation.473
  %custom-call.154 = f32[1024,1024]{1,0} custom-call(f32[1024,1024]{1,0} %fusion.628, f32[1024,1024]{0,1} %fusion.473), custom_call_target="__cublas$gemm", metadata={op_type="transpose" op_name="pmap(_multi_device_update_fn)/transpose[ permutation=(1, 0) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/core.py" source_line=96}, backend_config="{\"alpha_real\":1,\"alpha_imag\":0,\"beta\":0,\"dot_dimension_numbers\":{\"lhs_contracting_dimensions\":[\"0\"],\"rhs_contracting_dimensions\":[\"1\"],\"lhs_batch_dimensions\":[],\"rhs_batch_dimensions\":[]},\"batch_size\":\"1\",\"selected_algorithm\":\"-1\"}"
  %bitcast.396 = f32[1024,1024]{1,0} bitcast(f32[16,64,1024]{2,1,0} %custom-call.152)
  %custom-call.153 = f32[1024,1024]{1,0} custom-call(f32[1024,1024]{1,0} %bitcast.396, f32[1024,1024]{1,0} %parameter.94), custom_call_target="__cublas$gemm", backend_config="{\"alpha_real\":1,\"alpha_imag\":0,\"beta\":0,\"dot_dimension_numbers\":{\"lhs_contracting_dimensions\":[\"1\"],\"rhs_contracting_dimensions\":[\"1\"],\"lhs_batch_dimensions\":[],\"rhs_batch_dimensions\":[]},\"batch_size\":\"1\",\"selected_algorithm\":\"7\"}"
  %fusion.505 = f32[64,16,1024]{2,1,0} fusion(f32[1024,1024]{1,0} %custom-call.153, f32[64,16,1024]{2,1,0} %get-tuple-element.3544), kind=kLoop, calls=%fused_computation.505, metadata={op_type="transpose" op_name="pmap(_multi_device_update_fn)/transpose[ permutation=(1, 0, 2) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/combinators.py" source_line=342}
  %get-tuple-element.4522 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %while.45), index=6, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.4523 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %while.45), index=7, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.4524 = f32[64,16,2048]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %while.45), index=8, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.4525 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %while.45), index=9, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.4526 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %while.45), index=10, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.4527 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %while.45), index=11, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.4528 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %while.45), index=12, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.4529 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %while.45), index=13, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.4531 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %while.45), index=14, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.4532 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %while.45), index=15, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.4533 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %while.45), index=16, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.4534 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[16,2048]{1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=15*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}) %while.45), index=17, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %copy.697 = s32[] copy(s32[] %constant_495)
  %copy.698 = f32[2048,4096]{1,0} copy(f32[2048,4096]{1,0} %broadcast.553)
  %copy.699 = f32[4096]{0} copy(f32[4096]{0} %broadcast.554)
  %copy.700 = f32[16,2048]{1,0} copy(f32[16,2048]{1,0} %broadcast.3322)
  %copy.701 = f32[64,16,1024]{2,1,0} copy(f32[64,16,1024]{2,1,0} %broadcast.3360)
  %tuple.836 = (f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) tuple(f32[64,16,1024]{2,1,0} %fusion.505, f32[64,16,1024]{2,1,0} %get-tuple-element.4522, f32[64,16,1024]{2,1,0} %get-tuple-element.4523, f32[64,16,2048]{2,1,0} %get-tuple-element.4524, f32[64,16,1024]{2,1,0} %get-tuple-element.4525, /*index=5*/f32[64,16,1024]{2,1,0} %get-tuple-element.4526, f32[64,16,1024]{2,1,0} %get-tuple-element.4527, f32[64,16,1024]{2,1,0} %get-tuple-element.4528, f32[64,16,1024]{2,1,0} %get-tuple-element.4529, f32[64,16,1024]{2,1,0} %get-tuple-element.4531, /*index=10*/f32[64,16,1024]{2,1,0} %get-tuple-element.4532, f32[64,16,1024]{2,1,0} %get-tuple-element.4533, f32[64,16,1024]{2,1,0} %get-tuple-element.4534, f32[2048,4096]{1,0} %parameter.92, s32[] %copy.697, /*index=15*/f32[2048,4096]{1,0} %copy.698, f32[4096]{0} %copy.699, f32[16,2048]{1,0} %copy.700, f32[64,16,1024]{2,1,0} %copy.701)
  %while.40 = (f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) while((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %tuple.836), condition=%cond_computation__53.12417.clone.clone, body=%body_computation__53.12006.clone.clone, backend_config="{\"known_trip_count\":{\"n\":\"64\"}}"
  %get-tuple-element.3932 = f32[64,16,1024]{2,1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %while.40), index=18, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=14\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %fusion.504 = f32[256,1024]{1,0} fusion(f32[64,16,1024]{2,1,0} %get-tuple-element.3932, s32[16,64]{1,0} %parameter.168), kind=kInput, calls=%fused_computation.504, metadata={op_type="scatter-add" op_name="pmap(_multi_device_update_fn)/scatter-add[ dimension_numbers=ScatterDimensionNumbers(update_window_dims=(2,), inserted_window_dims=(0,), scatter_dims_to_operand_dims=(0,))\n                                           indices_are_sorted=False\n                                           unique_indices=False\n                                           update_consts=(  ) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/core.py" source_line=182}
  %fusion.324 = f32[256,1024]{0,1} fusion(f32[16,64,256]{2,1,0} %fusion.604), kind=kLoop, calls=%fused_computation.324
  %custom-call.158 = f32[1024,256]{1,0} custom-call(f32[1024,1024]{1,0} %fusion.613, f32[256,1024]{0,1} %fusion.324), custom_call_target="__cublas$gemm", metadata={op_type="transpose" op_name="pmap(_multi_device_update_fn)/transpose[ permutation=(1, 0) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/core.py" source_line=96}, backend_config="{\"alpha_real\":1,\"alpha_imag\":0,\"beta\":0,\"dot_dimension_numbers\":{\"lhs_contracting_dimensions\":[\"0\"],\"rhs_contracting_dimensions\":[\"1\"],\"lhs_batch_dimensions\":[],\"rhs_batch_dimensions\":[]},\"batch_size\":\"1\",\"selected_algorithm\":\"-1\"}"
  %fusion.688 = f32[1024]{0} fusion(f32[16,64,1024]{2,1,0} %custom-call.152), kind=kInput, calls=%fused_computation.688, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0, 1) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/core.py" source_line=96}
  %fusion.687 = f32[1024]{0} fusion(f32[16,64,1024]{2,1,0} %custom-call.149), kind=kInput, calls=%fused_computation.687, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0, 1) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/core.py" source_line=96}
  %reduce.115 = f32[1024]{0} reduce(f32[16,1024,64]{2,1,0} %custom-call.146, f32[] %constant_1), dimensions={0,2}, to_apply=%primitive_computation_add__1.9819, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0, 1) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/core.py" source_line=96}
  %fusion.404 = f32[1024]{0} fusion(f32[64,16,1024]{2,1,0} %get-tuple-element.3544), kind=kInput, calls=%fused_computation.404, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0, 1) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/core.py" source_line=96}
  %get-tuple-element.3328 = f32[4096]{0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %while.32), index=16, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=14\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.3417 = f32[4096]{0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %while.33), index=16, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=14\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.3480 = f32[4096]{0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %while.34), index=16, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=14\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.3542 = f32[4096]{0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %while.35), index=16, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=14\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.3930 = f32[4096]{0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %while.40), index=16, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=14\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.3603 = f32[4096]{0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %while.36), index=16, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=14\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.3664 = f32[4096]{0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %while.37), index=16, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=14\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.3725 = f32[4096]{0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %while.38), index=16, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=14\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.3786 = f32[4096]{0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %while.39), index=16, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=14\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %fusion.686 = f32[256]{0} fusion(f32[16,64,256]{2,1,0} %fusion.604), kind=kInput, calls=%fused_computation.686, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0, 1) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/core.py" source_line=96}
  %all-reduce = (f32[1024,1024]{1,0}, f32[1024,1024]{1,0}, f32[1024,1024]{1,0}, f32[1024,1024]{1,0}, f32[256,1024]{1,0}, /*index=5*/f32[1024,256]{1,0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, /*index=10*/f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, /*index=15*/f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[256]{0}) all-reduce(f32[1024,1024]{1,0} %custom-call.157, f32[1024,1024]{1,0} %custom-call.156, f32[1024,1024]{1,0} %custom-call.155, f32[1024,1024]{1,0} %custom-call.154, f32[256,1024]{1,0} %fusion.504, /*index=5*/f32[1024,256]{1,0} %custom-call.158, f32[1024]{0} %fusion.688, f32[1024]{0} %fusion.687, f32[1024]{0} %reduce.115, f32[1024]{0} %fusion.404, /*index=10*/f32[4096]{0} %get-tuple-element.3328, f32[4096]{0} %get-tuple-element.3417, f32[4096]{0} %get-tuple-element.3480, f32[4096]{0} %get-tuple-element.3542, f32[4096]{0} %get-tuple-element.3930, /*index=15*/f32[4096]{0} %get-tuple-element.3603, f32[4096]{0} %get-tuple-element.3664, f32[4096]{0} %get-tuple-element.3725, f32[4096]{0} %get-tuple-element.3786, f32[256]{0} %fusion.686), replica_groups={{0,1,2,3,4,5,6,7}}, to_apply=%primitive_computation_add__1.12594, control-predecessors={%all-reduce.12508}
  %get-tuple-element.5689 = f32[1024,1024]{1,0} get-tuple-element((f32[1024,1024]{1,0}, f32[1024,1024]{1,0}, f32[1024,1024]{1,0}, f32[1024,1024]{1,0}, f32[256,1024]{1,0}, /*index=5*/f32[1024,256]{1,0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, /*index=10*/f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, /*index=15*/f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[256]{0}) %all-reduce), index=0, metadata={op_type="psum" op_name="pmap(_multi_device_update_fn)/psum[ axes=(\'batch\',)\n                                    axis_index_groups=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=347}
  %get-tuple-element.5690 = f32[1024,1024]{1,0} get-tuple-element((f32[1024,1024]{1,0}, f32[1024,1024]{1,0}, f32[1024,1024]{1,0}, f32[1024,1024]{1,0}, f32[256,1024]{1,0}, /*index=5*/f32[1024,256]{1,0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, /*index=10*/f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, /*index=15*/f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[256]{0}) %all-reduce), index=1, metadata={op_type="psum" op_name="pmap(_multi_device_update_fn)/psum[ axes=(\'batch\',)\n                                    axis_index_groups=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=347}
  %get-tuple-element.5691 = f32[1024,1024]{1,0} get-tuple-element((f32[1024,1024]{1,0}, f32[1024,1024]{1,0}, f32[1024,1024]{1,0}, f32[1024,1024]{1,0}, f32[256,1024]{1,0}, /*index=5*/f32[1024,256]{1,0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, /*index=10*/f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, /*index=15*/f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[256]{0}) %all-reduce), index=2, metadata={op_type="psum" op_name="pmap(_multi_device_update_fn)/psum[ axes=(\'batch\',)\n                                    axis_index_groups=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=347}
  %get-tuple-element.5692 = f32[1024,1024]{1,0} get-tuple-element((f32[1024,1024]{1,0}, f32[1024,1024]{1,0}, f32[1024,1024]{1,0}, f32[1024,1024]{1,0}, f32[256,1024]{1,0}, /*index=5*/f32[1024,256]{1,0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, /*index=10*/f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, /*index=15*/f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[256]{0}) %all-reduce), index=3, metadata={op_type="psum" op_name="pmap(_multi_device_update_fn)/psum[ axes=(\'batch\',)\n                                    axis_index_groups=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=347}
  %fusion.729 = (f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}) fusion(f32[1024,1024]{1,0} %get-tuple-element.5689, f32[1024,1024]{1,0} %get-tuple-element.5690, f32[1024,1024]{1,0} %get-tuple-element.5691, f32[1024,1024]{1,0} %get-tuple-element.5692), kind=kInput, calls=%fused_computation.729, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
  %get-tuple-element.5637 = f32[1024]{0} get-tuple-element((f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}) %fusion.729), index=0
  %parameter.161 = f32[] parameter(79), parameter_replication={false}
  %parameter.158 = s32[] parameter(76), parameter_replication={false}, metadata={op_type="convert_element_type" op_name="pmap(_multi_device_update_fn)/convert_element_type[ new_dtype=int32\n                                                    weak_type=False ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=115}
  %parameter.166 = f32[] parameter(84), parameter_replication={false}
  %parameter.165 = s32[] parameter(83), parameter_replication={false}
  %fusion.591 = (f32[], f32[]) fusion(f32[] %parameter.161, s32[] %parameter.158, f32[] %parameter.166, s32[] %parameter.165), kind=kLoop, calls=%fused_computation.591, metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=85}
  %get-tuple-element.5534 = f32[] get-tuple-element((f32[], f32[]) %fusion.591), index=0
  %parameter.141 = f32[1024]{0} parameter(59), parameter_replication={false}
  %get-tuple-element.5638 = f32[1024]{0} get-tuple-element((f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}) %fusion.729), index=1
  %parameter.138 = f32[1024]{0} parameter(56), parameter_replication={false}
  %get-tuple-element.5639 = f32[1024]{0} get-tuple-element((f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}) %fusion.729), index=2
  %parameter.135 = f32[1024]{0} parameter(53), parameter_replication={false}
  %get-tuple-element.5640 = f32[1024]{0} get-tuple-element((f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}) %fusion.729), index=3
  %parameter.132 = f32[1024]{0} parameter(50), parameter_replication={false}
  %get-tuple-element.5693 = f32[256,1024]{1,0} get-tuple-element((f32[1024,1024]{1,0}, f32[1024,1024]{1,0}, f32[1024,1024]{1,0}, f32[1024,1024]{1,0}, f32[256,1024]{1,0}, /*index=5*/f32[1024,256]{1,0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, /*index=10*/f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, /*index=15*/f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[256]{0}) %all-reduce), index=4, metadata={op_type="psum" op_name="pmap(_multi_device_update_fn)/psum[ axes=(\'batch\',)\n                                    axis_index_groups=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=347}
  %fusion.719 = f32[1024]{0} fusion(f32[256,1024]{1,0} %get-tuple-element.5693), kind=kInput, calls=%fused_computation.719, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
  %parameter.127 = f32[1024]{0} parameter(45), parameter_replication={false}
  %fusion.724 = (f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}) fusion(f32[1024,1024]{1,0} %get-tuple-element.5691, f32[1024,1024]{1,0} %get-tuple-element.5689, f32[1024,1024]{1,0} %get-tuple-element.5692, f32[1024,1024]{1,0} %get-tuple-element.5690), kind=kInput, calls=%fused_computation.724, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(1,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=131}
  %get-tuple-element.5633 = f32[1024]{0} get-tuple-element((f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}) %fusion.724), index=0
  %parameter.134 = f32[1024]{0} parameter(52), parameter_replication={false}
  %get-tuple-element.5634 = f32[1024]{0} get-tuple-element((f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}) %fusion.724), index=1
  %parameter.140 = f32[1024]{0} parameter(58), parameter_replication={false}
  %get-tuple-element.5694 = f32[1024,256]{1,0} get-tuple-element((f32[1024,1024]{1,0}, f32[1024,1024]{1,0}, f32[1024,1024]{1,0}, f32[1024,1024]{1,0}, f32[256,1024]{1,0}, /*index=5*/f32[1024,256]{1,0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, /*index=10*/f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, /*index=15*/f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[256]{0}) %all-reduce), index=5, metadata={op_type="psum" op_name="pmap(_multi_device_update_fn)/psum[ axes=(\'batch\',)\n                                    axis_index_groups=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=347}
  %fusion.738 = f32[1024]{0} fusion(f32[1024,256]{1,0} %get-tuple-element.5694), kind=kInput, calls=%fused_computation.738, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(1,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=131}
  %parameter.155 = f32[1024]{0} parameter(73), parameter_replication={false}
  %get-tuple-element.5635 = f32[1024]{0} get-tuple-element((f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}) %fusion.724), index=2
  %parameter.131 = f32[1024]{0} parameter(49), parameter_replication={false}
  %get-tuple-element.5636 = f32[1024]{0} get-tuple-element((f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}) %fusion.724), index=3
  %parameter.137 = f32[1024]{0} parameter(55), parameter_replication={false}
  %get-tuple-element.5695 = f32[1024]{0} get-tuple-element((f32[1024,1024]{1,0}, f32[1024,1024]{1,0}, f32[1024,1024]{1,0}, f32[1024,1024]{1,0}, f32[256,1024]{1,0}, /*index=5*/f32[1024,256]{1,0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, /*index=10*/f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, /*index=15*/f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[256]{0}) %all-reduce), index=6, metadata={op_type="psum" op_name="pmap(_multi_device_update_fn)/psum[ axes=(\'batch\',)\n                                    axis_index_groups=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=347}
  %parameter.133 = f32[1024]{0} parameter(51), parameter_replication={false}
  %get-tuple-element.5696 = f32[1024]{0} get-tuple-element((f32[1024,1024]{1,0}, f32[1024,1024]{1,0}, f32[1024,1024]{1,0}, f32[1024,1024]{1,0}, f32[256,1024]{1,0}, /*index=5*/f32[1024,256]{1,0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, /*index=10*/f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, /*index=15*/f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[256]{0}) %all-reduce), index=7, metadata={op_type="psum" op_name="pmap(_multi_device_update_fn)/psum[ axes=(\'batch\',)\n                                    axis_index_groups=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=347}
  %parameter.136 = f32[1024]{0} parameter(54), parameter_replication={false}
  %get-tuple-element.5697 = f32[1024]{0} get-tuple-element((f32[1024,1024]{1,0}, f32[1024,1024]{1,0}, f32[1024,1024]{1,0}, f32[1024,1024]{1,0}, f32[256,1024]{1,0}, /*index=5*/f32[1024,256]{1,0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, /*index=10*/f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, /*index=15*/f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[256]{0}) %all-reduce), index=8, metadata={op_type="psum" op_name="pmap(_multi_device_update_fn)/psum[ axes=(\'batch\',)\n                                    axis_index_groups=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=347}
  %parameter.139 = f32[1024]{0} parameter(57), parameter_replication={false}
  %get-tuple-element.5698 = f32[1024]{0} get-tuple-element((f32[1024,1024]{1,0}, f32[1024,1024]{1,0}, f32[1024,1024]{1,0}, f32[1024,1024]{1,0}, f32[256,1024]{1,0}, /*index=5*/f32[1024,256]{1,0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, /*index=10*/f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, /*index=15*/f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[256]{0}) %all-reduce), index=9, metadata={op_type="psum" op_name="pmap(_multi_device_update_fn)/psum[ axes=(\'batch\',)\n                                    axis_index_groups=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=347}
  %parameter.142 = f32[1024]{0} parameter(60), parameter_replication={false}
  %fusion.756 = (f32[], f32[1024]{0}, f32[], f32[1024]{0}, f32[], /*index=5*/f32[1024]{0}, f32[], f32[1024]{0}, f32[], f32[1024]{0}, /*index=10*/f32[], f32[1024]{0}, f32[1024]{0}, f32[], f32[], /*index=15*/f32[1024]{0}, f32[1024]{0}, f32[], f32[], f32[1024]{0}, /*index=20*/f32[1024]{0}, f32[], f32[], f32[1024]{0}, f32[1024]{0}, /*index=25*/f32[]) fusion(f32[1024]{0} %get-tuple-element.5633, f32[] %get-tuple-element.5534, f32[1024]{0} %parameter.134, f32[1024]{0} %get-tuple-element.5634, f32[1024]{0} %parameter.140, /*index=5*/f32[1024]{0} %fusion.738, f32[1024]{0} %parameter.155, f32[1024]{0} %get-tuple-element.5635, f32[1024]{0} %parameter.131, f32[1024]{0} %get-tuple-element.5636, /*index=10*/f32[1024]{0} %parameter.137, f32[1024]{0} %get-tuple-element.5695, f32[] %parameter.162, f32[1024]{0} %parameter.133, f32[1024]{0} %get-tuple-element.5696, /*index=15*/f32[1024]{0} %parameter.136, f32[1024]{0} %get-tuple-element.5697, f32[1024]{0} %parameter.139, f32[1024]{0} %get-tuple-element.5698, f32[1024]{0} %parameter.142), kind=kInput, calls=%fused_computation.756, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=135}
  %get-tuple-element.5489 = f32[1024]{0} get-tuple-element((f32[], f32[1024]{0}, f32[], f32[1024]{0}, f32[], /*index=5*/f32[1024]{0}, f32[], f32[1024]{0}, f32[], f32[1024]{0}, /*index=10*/f32[], f32[1024]{0}, f32[1024]{0}, f32[], f32[], /*index=15*/f32[1024]{0}, f32[1024]{0}, f32[], f32[], f32[1024]{0}, /*index=20*/f32[1024]{0}, f32[], f32[], f32[1024]{0}, f32[1024]{0}, /*index=25*/f32[]) %fusion.756), index=5
  %get-tuple-element.5488 = f32[] get-tuple-element((f32[], f32[1024]{0}, f32[], f32[1024]{0}, f32[], /*index=5*/f32[1024]{0}, f32[], f32[1024]{0}, f32[], f32[1024]{0}, /*index=10*/f32[], f32[1024]{0}, f32[1024]{0}, f32[], f32[], /*index=15*/f32[1024]{0}, f32[1024]{0}, f32[], f32[], f32[1024]{0}, /*index=20*/f32[1024]{0}, f32[], f32[], f32[1024]{0}, f32[1024]{0}, /*index=25*/f32[]) %fusion.756), index=4
  %get-tuple-element.5487 = f32[1024]{0} get-tuple-element((f32[], f32[1024]{0}, f32[], f32[1024]{0}, f32[], /*index=5*/f32[1024]{0}, f32[], f32[1024]{0}, f32[], f32[1024]{0}, /*index=10*/f32[], f32[1024]{0}, f32[1024]{0}, f32[], f32[], /*index=15*/f32[1024]{0}, f32[1024]{0}, f32[], f32[], f32[1024]{0}, /*index=20*/f32[1024]{0}, f32[], f32[], f32[1024]{0}, f32[1024]{0}, /*index=25*/f32[]) %fusion.756), index=3
  %get-tuple-element.5486 = f32[] get-tuple-element((f32[], f32[1024]{0}, f32[], f32[1024]{0}, f32[], /*index=5*/f32[1024]{0}, f32[], f32[1024]{0}, f32[], f32[1024]{0}, /*index=10*/f32[], f32[1024]{0}, f32[1024]{0}, f32[], f32[], /*index=15*/f32[1024]{0}, f32[1024]{0}, f32[], f32[], f32[1024]{0}, /*index=20*/f32[1024]{0}, f32[], f32[], f32[1024]{0}, f32[1024]{0}, /*index=25*/f32[]) %fusion.756), index=2
  %get-tuple-element.5493 = f32[1024]{0} get-tuple-element((f32[], f32[1024]{0}, f32[], f32[1024]{0}, f32[], /*index=5*/f32[1024]{0}, f32[], f32[1024]{0}, f32[], f32[1024]{0}, /*index=10*/f32[], f32[1024]{0}, f32[1024]{0}, f32[], f32[], /*index=15*/f32[1024]{0}, f32[1024]{0}, f32[], f32[], f32[1024]{0}, /*index=20*/f32[1024]{0}, f32[], f32[], f32[1024]{0}, f32[1024]{0}, /*index=25*/f32[]) %fusion.756), index=9
  %get-tuple-element.5492 = f32[] get-tuple-element((f32[], f32[1024]{0}, f32[], f32[1024]{0}, f32[], /*index=5*/f32[1024]{0}, f32[], f32[1024]{0}, f32[], f32[1024]{0}, /*index=10*/f32[], f32[1024]{0}, f32[1024]{0}, f32[], f32[], /*index=15*/f32[1024]{0}, f32[1024]{0}, f32[], f32[], f32[1024]{0}, /*index=20*/f32[1024]{0}, f32[], f32[], f32[1024]{0}, f32[1024]{0}, /*index=25*/f32[]) %fusion.756), index=8
  %get-tuple-element.5200 = f32[1024]{0} get-tuple-element((f32[], f32[1024]{0}, f32[], f32[1024]{0}, f32[], /*index=5*/f32[1024]{0}, f32[], f32[1024]{0}, f32[], f32[1024]{0}, /*index=10*/f32[], f32[1024]{0}, f32[1024]{0}, f32[], f32[], /*index=15*/f32[1024]{0}, f32[1024]{0}, f32[], f32[], f32[1024]{0}, /*index=20*/f32[1024]{0}, f32[], f32[], f32[1024]{0}, f32[1024]{0}, /*index=25*/f32[]) %fusion.756), index=1
  %get-tuple-element.5199 = f32[] get-tuple-element((f32[], f32[1024]{0}, f32[], f32[1024]{0}, f32[], /*index=5*/f32[1024]{0}, f32[], f32[1024]{0}, f32[], f32[1024]{0}, /*index=10*/f32[], f32[1024]{0}, f32[1024]{0}, f32[], f32[], /*index=15*/f32[1024]{0}, f32[1024]{0}, f32[], f32[], f32[1024]{0}, /*index=20*/f32[1024]{0}, f32[], f32[], f32[1024]{0}, f32[1024]{0}, /*index=25*/f32[]) %fusion.756), index=0
  %get-tuple-element.5491 = f32[1024]{0} get-tuple-element((f32[], f32[1024]{0}, f32[], f32[1024]{0}, f32[], /*index=5*/f32[1024]{0}, f32[], f32[1024]{0}, f32[], f32[1024]{0}, /*index=10*/f32[], f32[1024]{0}, f32[1024]{0}, f32[], f32[], /*index=15*/f32[1024]{0}, f32[1024]{0}, f32[], f32[], f32[1024]{0}, /*index=20*/f32[1024]{0}, f32[], f32[], f32[1024]{0}, f32[1024]{0}, /*index=25*/f32[]) %fusion.756), index=7
  %get-tuple-element.5490 = f32[] get-tuple-element((f32[], f32[1024]{0}, f32[], f32[1024]{0}, f32[], /*index=5*/f32[1024]{0}, f32[], f32[1024]{0}, f32[], f32[1024]{0}, /*index=10*/f32[], f32[1024]{0}, f32[1024]{0}, f32[], f32[], /*index=15*/f32[1024]{0}, f32[1024]{0}, f32[], f32[], f32[1024]{0}, /*index=20*/f32[1024]{0}, f32[], f32[], f32[1024]{0}, f32[1024]{0}, /*index=25*/f32[]) %fusion.756), index=6
  %fusion.709 = f32[1024]{0} fusion(f32[32000,1024]{1,0} %all-reduce.12508), kind=kInput, calls=%fused_computation.709, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
  %parameter.113 = f32[1024]{0} parameter(31), parameter_replication={false}
  %fusion.411 = (f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, /*index=5*/f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, /*index=10*/f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, /*index=15*/f32[1024]{0}, f32[1024]{0}) fusion(f32[] %parameter.162, f32[1024]{0} %get-tuple-element.5637, f32[] %get-tuple-element.5534, f32[1024]{0} %parameter.141, f32[1024]{0} %get-tuple-element.5638, /*index=5*/f32[1024]{0} %parameter.138, f32[1024]{0} %get-tuple-element.5639, f32[1024]{0} %parameter.135, f32[1024]{0} %get-tuple-element.5640, f32[1024]{0} %parameter.132, /*index=10*/f32[1024]{0} %fusion.719, f32[1024]{0} %parameter.127, f32[1024]{0} %get-tuple-element.5489, f32[] %get-tuple-element.5488, f32[1024]{0} %get-tuple-element.5487, /*index=15*/f32[] %get-tuple-element.5486, f32[1024]{0} %get-tuple-element.5493, f32[] %get-tuple-element.5492, f32[1024]{0} %get-tuple-element.5200, f32[] %get-tuple-element.5199, /*index=20*/f32[1024]{0} %get-tuple-element.5491, f32[] %get-tuple-element.5490, f32[1024]{0} %fusion.709, f32[1024]{0} %parameter.113), kind=kLoop, calls=%fused_computation.411, metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
  %get-tuple-element.5466 = f32[1024]{0} get-tuple-element((f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, /*index=5*/f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, /*index=10*/f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, /*index=15*/f32[1024]{0}, f32[1024]{0}) %fusion.411), index=10
  %fusion.708 = f32[32000]{0} fusion(f32[32000,1024]{1,0} %all-reduce.12508), kind=kInput, calls=%fused_computation.708, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(1,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=131}
  %parameter.112 = f32[32000]{0} parameter(30), parameter_replication={false}
  %fusion.764 = (f32[], f32[32000]{0}) fusion(f32[32000]{0} %fusion.708, f32[] %get-tuple-element.5534, f32[32000]{0} %parameter.112), kind=kInput, calls=%fused_computation.764, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=135}
  %get-tuple-element.5311 = f32[32000]{0} get-tuple-element((f32[], f32[32000]{0}) %fusion.764), index=1
  %get-tuple-element.5310 = f32[] get-tuple-element((f32[], f32[32000]{0}) %fusion.764), index=0
  %fusion.588 = f32[32000]{0} fusion(f32[32000]{0} %get-tuple-element.5311, f32[] %parameter.162, f32[] %get-tuple-element.5310), kind=kLoop, calls=%fused_computation.588, metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  %fusion.307 = (f32[], f32[]) fusion(f32[32000,1024]{1,0} %all-reduce.12508, f32[1024]{0} %get-tuple-element.5466, f32[32000]{0} %fusion.588), kind=kInput, calls=%fused_computation.307, metadata={op_type="dot_general" op_name="pmap(_multi_device_update_fn)/dot_general[ dimension_numbers=(((0,), (0,)), ((), ()))\n                                           precision=None\n                                           preferred_element_type=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %get-tuple-element.5537 = f32[] get-tuple-element((f32[], f32[]) %fusion.307), index=1
  %fusion.583 = f32[] fusion(f32[] %get-tuple-element.5537), kind=kLoop, calls=%fused_computation.583, metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %parameter.160 = f32[] parameter(78), parameter_replication={false}
  %parameter.164 = f32[] parameter(82), parameter_replication={false}
  %fusion.314 = f32[] fusion(f32[256]{0} %parameter.111), kind=kInput, calls=%fused_computation.314, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %fusion.507 = (f32[], f32[]) fusion(f32[256,1024]{1,0} %parameter.91, f32[1024,256]{1,0} %parameter.110), kind=kInput, calls=%fused_computation.507, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0, 1) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %get-tuple-element.5656 = f32[] get-tuple-element((f32[], f32[]) %fusion.507), index=1
  %fusion.387 = (f32[], f32[], f32[], f32[], f32[], /*index=5*/f32[], f32[], f32[], f32[]) fusion(f32[4096]{0} %parameter.103, f32[4096]{0} %parameter.93, f32[4096]{0} %parameter.90, f32[4096]{0} %parameter.88, f32[4096]{0} %parameter.105, /*index=5*/f32[4096]{0} %parameter.86, f32[4096]{0} %parameter.107, f32[4096]{0} %parameter.84, f32[4096]{0} %parameter.109), kind=kInput, calls=%fused_computation.387, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %get-tuple-element.5653 = f32[] get-tuple-element((f32[], f32[], f32[], f32[], f32[], /*index=5*/f32[], f32[], f32[], f32[]) %fusion.387), index=8
  %fusion.493 = (f32[], f32[], f32[], f32[], f32[], /*index=5*/f32[], f32[], f32[], f32[]) fusion(f32[2048,4096]{1,0} %parameter.92, f32[2048,4096]{1,0} %parameter.102, f32[2048,4096]{1,0} %parameter.89, f32[2048,4096]{1,0} %parameter.104, f32[2048,4096]{1,0} %parameter.87, /*index=5*/f32[2048,4096]{1,0} %parameter.106, f32[2048,4096]{1,0} %parameter.85, f32[2048,4096]{1,0} %parameter.108, f32[2048,4096]{1,0} %parameter.83), kind=kInput, calls=%fused_computation.493, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0, 1) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %get-tuple-element.5669 = f32[] get-tuple-element((f32[], f32[], f32[], f32[], f32[], /*index=5*/f32[], f32[], f32[], f32[]) %fusion.493), index=7
  %get-tuple-element.5651 = f32[] get-tuple-element((f32[], f32[], f32[], f32[], f32[], /*index=5*/f32[], f32[], f32[], f32[]) %fusion.387), index=6
  %get-tuple-element.5666 = f32[] get-tuple-element((f32[], f32[], f32[], f32[], f32[], /*index=5*/f32[], f32[], f32[], f32[]) %fusion.493), index=5
  %get-tuple-element.5649 = f32[] get-tuple-element((f32[], f32[], f32[], f32[], f32[], /*index=5*/f32[], f32[], f32[], f32[]) %fusion.387), index=4
  %get-tuple-element.5664 = f32[] get-tuple-element((f32[], f32[], f32[], f32[], f32[], /*index=5*/f32[], f32[], f32[], f32[]) %fusion.493), index=3
  %get-tuple-element.5645 = f32[] get-tuple-element((f32[], f32[], f32[], f32[], f32[], /*index=5*/f32[], f32[], f32[], f32[]) %fusion.387), index=0
  %get-tuple-element.5662 = f32[] get-tuple-element((f32[], f32[], f32[], f32[], f32[], /*index=5*/f32[], f32[], f32[], f32[]) %fusion.493), index=1
  %fusion.463 = (f32[], f32[], f32[], f32[]) fusion(f32[1024]{0} %parameter.95, f32[1024]{0} %parameter.97, f32[1024]{0} %parameter.99, f32[1024]{0} %parameter.101), kind=kInput, calls=%fused_computation.463, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %get-tuple-element.5644 = f32[] get-tuple-element((f32[], f32[], f32[], f32[]) %fusion.463), index=3
  %fusion.456 = (f32[], f32[], f32[], f32[]) fusion(f32[1024,1024]{1,0} %parameter.96, f32[1024,1024]{1,0} %parameter.94, f32[1024,1024]{1,0} %parameter.98, f32[1024,1024]{1,0} %parameter.100), kind=kInput, calls=%fused_computation.456, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0, 1) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %get-tuple-element.5660 = f32[] get-tuple-element((f32[], f32[], f32[], f32[]) %fusion.456), index=3
  %get-tuple-element.5643 = f32[] get-tuple-element((f32[], f32[], f32[], f32[]) %fusion.463), index=2
  %get-tuple-element.5659 = f32[] get-tuple-element((f32[], f32[], f32[], f32[]) %fusion.456), index=2
  %get-tuple-element.5642 = f32[] get-tuple-element((f32[], f32[], f32[], f32[]) %fusion.463), index=1
  %get-tuple-element.5657 = f32[] get-tuple-element((f32[], f32[], f32[], f32[]) %fusion.456), index=0
  %get-tuple-element.5641 = f32[] get-tuple-element((f32[], f32[], f32[], f32[]) %fusion.463), index=0
  %get-tuple-element.5658 = f32[] get-tuple-element((f32[], f32[], f32[], f32[]) %fusion.456), index=1
  %get-tuple-element.5646 = f32[] get-tuple-element((f32[], f32[], f32[], f32[], f32[], /*index=5*/f32[], f32[], f32[], f32[]) %fusion.387), index=1
  %get-tuple-element.5661 = f32[] get-tuple-element((f32[], f32[], f32[], f32[], f32[], /*index=5*/f32[], f32[], f32[], f32[]) %fusion.493), index=0
  %get-tuple-element.5654 = f32[] get-tuple-element((f32[], f32[]) %fusion.507), index=0
  %get-tuple-element.5647 = f32[] get-tuple-element((f32[], f32[], f32[], f32[], f32[], /*index=5*/f32[], f32[], f32[], f32[]) %fusion.387), index=2
  %get-tuple-element.5663 = f32[] get-tuple-element((f32[], f32[], f32[], f32[], f32[], /*index=5*/f32[], f32[], f32[], f32[]) %fusion.493), index=2
  %get-tuple-element.5648 = f32[] get-tuple-element((f32[], f32[], f32[], f32[], f32[], /*index=5*/f32[], f32[], f32[], f32[]) %fusion.387), index=3
  %get-tuple-element.5665 = f32[] get-tuple-element((f32[], f32[], f32[], f32[], f32[], /*index=5*/f32[], f32[], f32[], f32[]) %fusion.493), index=4
  %get-tuple-element.5650 = f32[] get-tuple-element((f32[], f32[], f32[], f32[], f32[], /*index=5*/f32[], f32[], f32[], f32[]) %fusion.387), index=5
  %get-tuple-element.5667 = f32[] get-tuple-element((f32[], f32[], f32[], f32[], f32[], /*index=5*/f32[], f32[], f32[], f32[]) %fusion.493), index=6
  %get-tuple-element.5652 = f32[] get-tuple-element((f32[], f32[], f32[], f32[], f32[], /*index=5*/f32[], f32[], f32[], f32[]) %fusion.387), index=7
  %fusion.660 = f32[] fusion(f32[32000,1024]{1,0} %parameter.82), kind=kInput, calls=%fused_computation.660, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0, 1) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %get-tuple-element.5670 = f32[] get-tuple-element((f32[], f32[], f32[], f32[], f32[], /*index=5*/f32[], f32[], f32[], f32[]) %fusion.493), index=8
  %fusion.313 = (f32[], f32[], f32[], f32[], f32[], /*index=5*/f32[], f32[], f32[], f32[], f32[], /*index=10*/f32[], f32[], f32[], f32[], f32[], /*index=15*/f32[], f32[], f32[], f32[], f32[], /*index=20*/f32[], f32[], f32[], f32[], f32[], /*index=25*/f32[], f32[], f32[], f32[], f32[], /*index=30*/f32[]) fusion(f32[] %fusion.314, f32[] %get-tuple-element.5656, f32[] %get-tuple-element.5653, f32[] %get-tuple-element.5669, f32[] %get-tuple-element.5651, /*index=5*/f32[] %get-tuple-element.5666, f32[] %get-tuple-element.5649, f32[] %get-tuple-element.5664, f32[] %get-tuple-element.5645, f32[] %get-tuple-element.5662, /*index=10*/f32[] %get-tuple-element.5644, f32[] %get-tuple-element.5660, f32[] %get-tuple-element.5643, f32[] %get-tuple-element.5659, f32[] %get-tuple-element.5642, /*index=15*/f32[] %get-tuple-element.5657, f32[] %get-tuple-element.5641, f32[] %get-tuple-element.5658, f32[] %get-tuple-element.5646, f32[] %get-tuple-element.5661, /*index=20*/f32[] %get-tuple-element.5654, f32[] %get-tuple-element.5647, f32[] %get-tuple-element.5663, f32[] %get-tuple-element.5648, f32[] %get-tuple-element.5665, /*index=25*/f32[] %get-tuple-element.5650, f32[] %get-tuple-element.5667, f32[] %get-tuple-element.5652, f32[] %fusion.660, f32[] %get-tuple-element.5670), kind=kLoop, calls=%fused_computation.313, metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %get-tuple-element.5309 = f32[] get-tuple-element((f32[], f32[], f32[], f32[], f32[], /*index=5*/f32[], f32[], f32[], f32[], f32[], /*index=10*/f32[], f32[], f32[], f32[], f32[], /*index=15*/f32[], f32[], f32[], f32[], f32[], /*index=20*/f32[], f32[], f32[], f32[], f32[], /*index=25*/f32[], f32[], f32[], f32[], f32[], /*index=30*/f32[]) %fusion.313), index=30
  %parameter.163 = f32[] parameter(81), parameter_replication={false}
  %get-tuple-element.5535 = f32[] get-tuple-element((f32[], f32[]) %fusion.591), index=1
  %fusion.582 = f32[32000,1024]{1,0} fusion(f32[] %fusion.583, f32[] %parameter.160, f32[] %parameter.164, f32[] %get-tuple-element.5309, f32[] %parameter.163, /*index=5*/f32[32000,1024]{1,0} %parameter.82, f32[] %get-tuple-element.5535, f32[1024]{0} %get-tuple-element.5466, f32[32000,1024]{1,0} %all-reduce.12508, f32[32000]{0} %fusion.588), kind=kLoop, calls=%fused_computation.582, metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  %get-tuple-element.3785 = f32[2048,4096]{1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %while.39), index=15, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=14\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %all-reduce.12513 = f32[2048,4096]{1,0} all-reduce(f32[2048,4096]{1,0} %get-tuple-element.3785), replica_groups={{0,1,2,3,4,5,6,7}}, to_apply=%primitive_computation_add__1.12509, control-predecessors={%all-reduce}, metadata={op_type="psum" op_name="pmap(_multi_device_update_fn)/psum[ axes=(\'batch\',)\n                                    axis_index_groups=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=347}
  %get-tuple-element.3327 = f32[2048,4096]{1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %while.32), index=15, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=14\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %all-reduce.12638 = f32[2048,4096]{1,0} all-reduce(f32[2048,4096]{1,0} %get-tuple-element.3327), replica_groups={{0,1,2,3,4,5,6,7}}, to_apply=%primitive_computation_add__1.12634, control-predecessors={%all-reduce.12513}, metadata={op_type="psum" op_name="pmap(_multi_device_update_fn)/psum[ axes=(\'batch\',)\n                                    axis_index_groups=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=347}
  %get-tuple-element.3416 = f32[2048,4096]{1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %while.33), index=15, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=14\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %all-reduce.12628 = f32[2048,4096]{1,0} all-reduce(f32[2048,4096]{1,0} %get-tuple-element.3416), replica_groups={{0,1,2,3,4,5,6,7}}, to_apply=%primitive_computation_add__1.12624, control-predecessors={%all-reduce.12638}, metadata={op_type="psum" op_name="pmap(_multi_device_update_fn)/psum[ axes=(\'batch\',)\n                                    axis_index_groups=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=347}
  %get-tuple-element.3479 = f32[2048,4096]{1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %while.34), index=15, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=14\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %all-reduce.12618 = f32[2048,4096]{1,0} all-reduce(f32[2048,4096]{1,0} %get-tuple-element.3479), replica_groups={{0,1,2,3,4,5,6,7}}, to_apply=%primitive_computation_add__1.12614, control-predecessors={%all-reduce.12628}, metadata={op_type="psum" op_name="pmap(_multi_device_update_fn)/psum[ axes=(\'batch\',)\n                                    axis_index_groups=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=347}
  %fusion.711 = (f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}) fusion(f32[2048,4096]{1,0} %all-reduce.12513, f32[2048,4096]{1,0} %all-reduce.12638, f32[2048,4096]{1,0} %all-reduce.12628, f32[2048,4096]{1,0} %all-reduce.12618), kind=kInput, calls=%fused_computation.711, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
  %get-tuple-element.5671 = f32[4096]{0} get-tuple-element((f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}) %fusion.711), index=0
  %parameter.115 = f32[4096]{0} parameter(33), parameter_replication={false}
  %get-tuple-element.5672 = f32[4096]{0} get-tuple-element((f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}) %fusion.711), index=1
  %parameter.153 = f32[4096]{0} parameter(71), parameter_replication={false}
  %get-tuple-element.5673 = f32[4096]{0} get-tuple-element((f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}) %fusion.711), index=2
  %parameter.150 = f32[4096]{0} parameter(68), parameter_replication={false}
  %get-tuple-element.5674 = f32[4096]{0} get-tuple-element((f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}) %fusion.711), index=3
  %parameter.147 = f32[4096]{0} parameter(65), parameter_replication={false}
  %get-tuple-element.3541 = f32[2048,4096]{1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %while.35), index=15, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=14\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %all-reduce.12608 = f32[2048,4096]{1,0} all-reduce(f32[2048,4096]{1,0} %get-tuple-element.3541), replica_groups={{0,1,2,3,4,5,6,7}}, to_apply=%primitive_computation_add__1.12604, control-predecessors={%all-reduce.12618}, metadata={op_type="psum" op_name="pmap(_multi_device_update_fn)/psum[ axes=(\'batch\',)\n                                    axis_index_groups=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=347}
  %get-tuple-element.3929 = f32[2048,4096]{1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %while.40), index=15, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=14\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %all-reduce.12558 = f32[2048,4096]{1,0} all-reduce(f32[2048,4096]{1,0} %get-tuple-element.3929), replica_groups={{0,1,2,3,4,5,6,7}}, to_apply=%primitive_computation_add__1.12554, control-predecessors={%all-reduce.12608}, metadata={op_type="psum" op_name="pmap(_multi_device_update_fn)/psum[ axes=(\'batch\',)\n                                    axis_index_groups=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=347}
  %get-tuple-element.3602 = f32[2048,4096]{1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %while.36), index=15, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=14\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %all-reduce.12543 = f32[2048,4096]{1,0} all-reduce(f32[2048,4096]{1,0} %get-tuple-element.3602), replica_groups={{0,1,2,3,4,5,6,7}}, to_apply=%primitive_computation_add__1.12539, control-predecessors={%all-reduce.12558}, metadata={op_type="psum" op_name="pmap(_multi_device_update_fn)/psum[ axes=(\'batch\',)\n                                    axis_index_groups=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=347}
  %get-tuple-element.3663 = f32[2048,4096]{1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %while.37), index=15, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=14\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %all-reduce.12533 = f32[2048,4096]{1,0} all-reduce(f32[2048,4096]{1,0} %get-tuple-element.3663), replica_groups={{0,1,2,3,4,5,6,7}}, to_apply=%primitive_computation_add__1.12529, control-predecessors={%all-reduce.12543}, metadata={op_type="psum" op_name="pmap(_multi_device_update_fn)/psum[ axes=(\'batch\',)\n                                    axis_index_groups=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=347}
  %fusion.731 = (f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}) fusion(f32[2048,4096]{1,0} %all-reduce.12608, f32[2048,4096]{1,0} %all-reduce.12558, f32[2048,4096]{1,0} %all-reduce.12543, f32[2048,4096]{1,0} %all-reduce.12533), kind=kInput, calls=%fused_computation.731, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
  %get-tuple-element.5675 = f32[4096]{0} get-tuple-element((f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}) %fusion.731), index=0
  %parameter.144 = f32[4096]{0} parameter(62), parameter_replication={false}
  %get-tuple-element.5676 = f32[4096]{0} get-tuple-element((f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}) %fusion.731), index=1
  %parameter.129 = f32[4096]{0} parameter(47), parameter_replication={false}
  %get-tuple-element.5677 = f32[4096]{0} get-tuple-element((f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}) %fusion.731), index=2
  %parameter.124 = f32[4096]{0} parameter(42), parameter_replication={false}
  %get-tuple-element.5678 = f32[4096]{0} get-tuple-element((f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}) %fusion.731), index=3
  %parameter.121 = f32[4096]{0} parameter(39), parameter_replication={false}
  %get-tuple-element.3724 = f32[2048,4096]{1,0} get-tuple-element((f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,2048]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=5*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, /*index=10*/f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[64,16,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[16,2048]{1,0}, f32[64,16,1024]{2,1,0}) %while.38), index=15, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=14\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %all-reduce.12523 = f32[2048,4096]{1,0} all-reduce(f32[2048,4096]{1,0} %get-tuple-element.3724), replica_groups={{0,1,2,3,4,5,6,7}}, to_apply=%primitive_computation_add__1.12519, control-predecessors={%all-reduce.12533}, metadata={op_type="psum" op_name="pmap(_multi_device_update_fn)/psum[ axes=(\'batch\',)\n                                    axis_index_groups=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=347}
  %fusion.713 = f32[4096]{0} fusion(f32[2048,4096]{1,0} %all-reduce.12523), kind=kInput, calls=%fused_computation.713, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
  %parameter.118 = f32[4096]{0} parameter(36), parameter_replication={false}
  %fusion.573 = (f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, /*index=5*/f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, /*index=10*/f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, /*index=15*/f32[4096]{0}, f32[4096]{0}, f32[4096]{0}) fusion(f32[] %parameter.162, f32[4096]{0} %get-tuple-element.5671, f32[] %get-tuple-element.5534, f32[4096]{0} %parameter.115, f32[4096]{0} %get-tuple-element.5672, /*index=5*/f32[4096]{0} %parameter.153, f32[4096]{0} %get-tuple-element.5673, f32[4096]{0} %parameter.150, f32[4096]{0} %get-tuple-element.5674, f32[4096]{0} %parameter.147, /*index=10*/f32[4096]{0} %get-tuple-element.5675, f32[4096]{0} %parameter.144, f32[4096]{0} %get-tuple-element.5676, f32[4096]{0} %parameter.129, f32[4096]{0} %get-tuple-element.5677, /*index=15*/f32[4096]{0} %parameter.124, f32[4096]{0} %get-tuple-element.5678, f32[4096]{0} %parameter.121, f32[4096]{0} %fusion.713, f32[4096]{0} %parameter.118), kind=kLoop, calls=%fused_computation.573, metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
  %get-tuple-element.5280 = f32[4096]{0} get-tuple-element((f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, /*index=5*/f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, /*index=10*/f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, /*index=15*/f32[4096]{0}, f32[4096]{0}, f32[4096]{0}) %fusion.573), index=0
  %fusion.710 = (f32[2048]{0}, f32[2048]{0}, f32[2048]{0}, f32[2048]{0}, f32[2048]{0}, /*index=5*/f32[2048]{0}, f32[2048]{0}, f32[2048]{0}, f32[2048]{0}) fusion(f32[2048,4096]{1,0} %all-reduce.12513, f32[2048,4096]{1,0} %all-reduce.12638, f32[2048,4096]{1,0} %all-reduce.12523, f32[2048,4096]{1,0} %all-reduce.12558, f32[2048,4096]{1,0} %all-reduce.12628, /*index=5*/f32[2048,4096]{1,0} %all-reduce.12618, f32[2048,4096]{1,0} %all-reduce.12543, f32[2048,4096]{1,0} %all-reduce.12608, f32[2048,4096]{1,0} %all-reduce.12533), kind=kInput, calls=%fused_computation.710, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(1,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=131}
  %get-tuple-element.5679 = f32[2048]{0} get-tuple-element((f32[2048]{0}, f32[2048]{0}, f32[2048]{0}, f32[2048]{0}, f32[2048]{0}, /*index=5*/f32[2048]{0}, f32[2048]{0}, f32[2048]{0}, f32[2048]{0}) %fusion.710), index=0
  %parameter.114 = f32[2048]{0} parameter(32), parameter_replication={false}
  %get-tuple-element.5680 = f32[2048]{0} get-tuple-element((f32[2048]{0}, f32[2048]{0}, f32[2048]{0}, f32[2048]{0}, f32[2048]{0}, /*index=5*/f32[2048]{0}, f32[2048]{0}, f32[2048]{0}, f32[2048]{0}) %fusion.710), index=1
  %parameter.152 = f32[2048]{0} parameter(70), parameter_replication={false}
  %get-tuple-element.5681 = f32[2048]{0} get-tuple-element((f32[2048]{0}, f32[2048]{0}, f32[2048]{0}, f32[2048]{0}, f32[2048]{0}, /*index=5*/f32[2048]{0}, f32[2048]{0}, f32[2048]{0}, f32[2048]{0}) %fusion.710), index=2
  %parameter.117 = f32[2048]{0} parameter(35), parameter_replication={false}
  %get-tuple-element.5682 = f32[2048]{0} get-tuple-element((f32[2048]{0}, f32[2048]{0}, f32[2048]{0}, f32[2048]{0}, f32[2048]{0}, /*index=5*/f32[2048]{0}, f32[2048]{0}, f32[2048]{0}, f32[2048]{0}) %fusion.710), index=3
  %parameter.128 = f32[2048]{0} parameter(46), parameter_replication={false}
  %get-tuple-element.5683 = f32[2048]{0} get-tuple-element((f32[2048]{0}, f32[2048]{0}, f32[2048]{0}, f32[2048]{0}, f32[2048]{0}, /*index=5*/f32[2048]{0}, f32[2048]{0}, f32[2048]{0}, f32[2048]{0}) %fusion.710), index=4
  %parameter.149 = f32[2048]{0} parameter(67), parameter_replication={false}
  %get-tuple-element.5684 = f32[2048]{0} get-tuple-element((f32[2048]{0}, f32[2048]{0}, f32[2048]{0}, f32[2048]{0}, f32[2048]{0}, /*index=5*/f32[2048]{0}, f32[2048]{0}, f32[2048]{0}, f32[2048]{0}) %fusion.710), index=5
  %parameter.146 = f32[2048]{0} parameter(64), parameter_replication={false}
  %get-tuple-element.5686 = f32[2048]{0} get-tuple-element((f32[2048]{0}, f32[2048]{0}, f32[2048]{0}, f32[2048]{0}, f32[2048]{0}, /*index=5*/f32[2048]{0}, f32[2048]{0}, f32[2048]{0}, f32[2048]{0}) %fusion.710), index=6
  %parameter.123 = f32[2048]{0} parameter(41), parameter_replication={false}
  %get-tuple-element.5687 = f32[2048]{0} get-tuple-element((f32[2048]{0}, f32[2048]{0}, f32[2048]{0}, f32[2048]{0}, f32[2048]{0}, /*index=5*/f32[2048]{0}, f32[2048]{0}, f32[2048]{0}, f32[2048]{0}) %fusion.710), index=7
  %parameter.143 = f32[2048]{0} parameter(61), parameter_replication={false}
  %get-tuple-element.5688 = f32[2048]{0} get-tuple-element((f32[2048]{0}, f32[2048]{0}, f32[2048]{0}, f32[2048]{0}, f32[2048]{0}, /*index=5*/f32[2048]{0}, f32[2048]{0}, f32[2048]{0}, f32[2048]{0}) %fusion.710), index=8
  %parameter.120 = f32[2048]{0} parameter(38), parameter_replication={false}
  %fusion.763 = (f32[], f32[2048]{0}, f32[], f32[2048]{0}, f32[], /*index=5*/f32[2048]{0}, f32[], f32[2048]{0}, f32[], f32[2048]{0}, /*index=10*/f32[], f32[2048]{0}, f32[], f32[2048]{0}, f32[], /*index=15*/f32[2048]{0}, f32[], f32[2048]{0}) fusion(f32[2048]{0} %get-tuple-element.5679, f32[] %get-tuple-element.5534, f32[2048]{0} %parameter.114, f32[2048]{0} %get-tuple-element.5680, f32[2048]{0} %parameter.152, /*index=5*/f32[2048]{0} %get-tuple-element.5681, f32[2048]{0} %parameter.117, f32[2048]{0} %get-tuple-element.5682, f32[2048]{0} %parameter.128, f32[2048]{0} %get-tuple-element.5683, /*index=10*/f32[2048]{0} %parameter.149, f32[2048]{0} %get-tuple-element.5684, f32[2048]{0} %parameter.146, f32[2048]{0} %get-tuple-element.5686, f32[2048]{0} %parameter.123, /*index=15*/f32[2048]{0} %get-tuple-element.5687, f32[2048]{0} %parameter.143, f32[2048]{0} %get-tuple-element.5688, f32[2048]{0} %parameter.120), kind=kInput, calls=%fused_computation.763, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=135}
  %get-tuple-element.5279 = f32[2048]{0} get-tuple-element((f32[], f32[2048]{0}, f32[], f32[2048]{0}, f32[], /*index=5*/f32[2048]{0}, f32[], f32[2048]{0}, f32[], f32[2048]{0}, /*index=10*/f32[], f32[2048]{0}, f32[], f32[2048]{0}, f32[], /*index=15*/f32[2048]{0}, f32[], f32[2048]{0}) %fusion.763), index=1
  %get-tuple-element.5278 = f32[] get-tuple-element((f32[], f32[2048]{0}, f32[], f32[2048]{0}, f32[], /*index=5*/f32[2048]{0}, f32[], f32[2048]{0}, f32[], f32[2048]{0}, /*index=10*/f32[], f32[2048]{0}, f32[], f32[2048]{0}, f32[], /*index=15*/f32[2048]{0}, f32[], f32[2048]{0}) %fusion.763), index=0
  %get-tuple-element.5514 = f32[2048]{0} get-tuple-element((f32[], f32[2048]{0}, f32[], f32[2048]{0}, f32[], /*index=5*/f32[2048]{0}, f32[], f32[2048]{0}, f32[], f32[2048]{0}, /*index=10*/f32[], f32[2048]{0}, f32[], f32[2048]{0}, f32[], /*index=15*/f32[2048]{0}, f32[], f32[2048]{0}) %fusion.763), index=3
  %get-tuple-element.5513 = f32[] get-tuple-element((f32[], f32[2048]{0}, f32[], f32[2048]{0}, f32[], /*index=5*/f32[2048]{0}, f32[], f32[2048]{0}, f32[], f32[2048]{0}, /*index=10*/f32[], f32[2048]{0}, f32[], f32[2048]{0}, f32[], /*index=15*/f32[2048]{0}, f32[], f32[2048]{0}) %fusion.763), index=2
  %get-tuple-element.5521 = f32[2048]{0} get-tuple-element((f32[], f32[2048]{0}, f32[], f32[2048]{0}, f32[], /*index=5*/f32[2048]{0}, f32[], f32[2048]{0}, f32[], f32[2048]{0}, /*index=10*/f32[], f32[2048]{0}, f32[], f32[2048]{0}, f32[], /*index=15*/f32[2048]{0}, f32[], f32[2048]{0}) %fusion.763), index=9
  %get-tuple-element.5520 = f32[] get-tuple-element((f32[], f32[2048]{0}, f32[], f32[2048]{0}, f32[], /*index=5*/f32[2048]{0}, f32[], f32[2048]{0}, f32[], f32[2048]{0}, /*index=10*/f32[], f32[2048]{0}, f32[], f32[2048]{0}, f32[], /*index=15*/f32[2048]{0}, f32[], f32[2048]{0}) %fusion.763), index=8
  %get-tuple-element.5523 = f32[2048]{0} get-tuple-element((f32[], f32[2048]{0}, f32[], f32[2048]{0}, f32[], /*index=5*/f32[2048]{0}, f32[], f32[2048]{0}, f32[], f32[2048]{0}, /*index=10*/f32[], f32[2048]{0}, f32[], f32[2048]{0}, f32[], /*index=15*/f32[2048]{0}, f32[], f32[2048]{0}) %fusion.763), index=11
  %get-tuple-element.5522 = f32[] get-tuple-element((f32[], f32[2048]{0}, f32[], f32[2048]{0}, f32[], /*index=5*/f32[2048]{0}, f32[], f32[2048]{0}, f32[], f32[2048]{0}, /*index=10*/f32[], f32[2048]{0}, f32[], f32[2048]{0}, f32[], /*index=15*/f32[2048]{0}, f32[], f32[2048]{0}) %fusion.763), index=10
  %get-tuple-element.5527 = f32[2048]{0} get-tuple-element((f32[], f32[2048]{0}, f32[], f32[2048]{0}, f32[], /*index=5*/f32[2048]{0}, f32[], f32[2048]{0}, f32[], f32[2048]{0}, /*index=10*/f32[], f32[2048]{0}, f32[], f32[2048]{0}, f32[], /*index=15*/f32[2048]{0}, f32[], f32[2048]{0}) %fusion.763), index=15
  %get-tuple-element.5526 = f32[] get-tuple-element((f32[], f32[2048]{0}, f32[], f32[2048]{0}, f32[], /*index=5*/f32[2048]{0}, f32[], f32[2048]{0}, f32[], f32[2048]{0}, /*index=10*/f32[], f32[2048]{0}, f32[], f32[2048]{0}, f32[], /*index=15*/f32[2048]{0}, f32[], f32[2048]{0}) %fusion.763), index=14
  %get-tuple-element.5519 = f32[2048]{0} get-tuple-element((f32[], f32[2048]{0}, f32[], f32[2048]{0}, f32[], /*index=5*/f32[2048]{0}, f32[], f32[2048]{0}, f32[], f32[2048]{0}, /*index=10*/f32[], f32[2048]{0}, f32[], f32[2048]{0}, f32[], /*index=15*/f32[2048]{0}, f32[], f32[2048]{0}) %fusion.763), index=7
  %get-tuple-element.5518 = f32[] get-tuple-element((f32[], f32[2048]{0}, f32[], f32[2048]{0}, f32[], /*index=5*/f32[2048]{0}, f32[], f32[2048]{0}, f32[], f32[2048]{0}, /*index=10*/f32[], f32[2048]{0}, f32[], f32[2048]{0}, f32[], /*index=15*/f32[2048]{0}, f32[], f32[2048]{0}) %fusion.763), index=6
  %get-tuple-element.5525 = f32[2048]{0} get-tuple-element((f32[], f32[2048]{0}, f32[], f32[2048]{0}, f32[], /*index=5*/f32[2048]{0}, f32[], f32[2048]{0}, f32[], f32[2048]{0}, /*index=10*/f32[], f32[2048]{0}, f32[], f32[2048]{0}, f32[], /*index=15*/f32[2048]{0}, f32[], f32[2048]{0}) %fusion.763), index=13
  %get-tuple-element.5524 = f32[] get-tuple-element((f32[], f32[2048]{0}, f32[], f32[2048]{0}, f32[], /*index=5*/f32[2048]{0}, f32[], f32[2048]{0}, f32[], f32[2048]{0}, /*index=10*/f32[], f32[2048]{0}, f32[], f32[2048]{0}, f32[], /*index=15*/f32[2048]{0}, f32[], f32[2048]{0}) %fusion.763), index=12
  %get-tuple-element.5529 = f32[2048]{0} get-tuple-element((f32[], f32[2048]{0}, f32[], f32[2048]{0}, f32[], /*index=5*/f32[2048]{0}, f32[], f32[2048]{0}, f32[], f32[2048]{0}, /*index=10*/f32[], f32[2048]{0}, f32[], f32[2048]{0}, f32[], /*index=15*/f32[2048]{0}, f32[], f32[2048]{0}) %fusion.763), index=17
  %get-tuple-element.5528 = f32[] get-tuple-element((f32[], f32[2048]{0}, f32[], f32[2048]{0}, f32[], /*index=5*/f32[2048]{0}, f32[], f32[2048]{0}, f32[], f32[2048]{0}, /*index=10*/f32[], f32[2048]{0}, f32[], f32[2048]{0}, f32[], /*index=15*/f32[2048]{0}, f32[], f32[2048]{0}) %fusion.763), index=16
  %get-tuple-element.5517 = f32[2048]{0} get-tuple-element((f32[], f32[2048]{0}, f32[], f32[2048]{0}, f32[], /*index=5*/f32[2048]{0}, f32[], f32[2048]{0}, f32[], f32[2048]{0}, /*index=10*/f32[], f32[2048]{0}, f32[], f32[2048]{0}, f32[], /*index=15*/f32[2048]{0}, f32[], f32[2048]{0}) %fusion.763), index=5
  %get-tuple-element.5515 = f32[] get-tuple-element((f32[], f32[2048]{0}, f32[], f32[2048]{0}, f32[], /*index=5*/f32[2048]{0}, f32[], f32[2048]{0}, f32[], f32[2048]{0}, /*index=10*/f32[], f32[2048]{0}, f32[], f32[2048]{0}, f32[], /*index=15*/f32[2048]{0}, f32[], f32[2048]{0}) %fusion.763), index=4
  %fusion.576 = (f32[2048]{0}, f32[2048]{0}, f32[2048]{0}, f32[2048]{0}, f32[2048]{0}, /*index=5*/f32[2048]{0}, f32[2048]{0}, f32[2048]{0}, f32[2048]{0}) fusion(f32[2048]{0} %get-tuple-element.5279, f32[] %get-tuple-element.5278, f32[] %parameter.162, f32[2048]{0} %get-tuple-element.5514, f32[] %get-tuple-element.5513, /*index=5*/f32[2048]{0} %get-tuple-element.5521, f32[] %get-tuple-element.5520, f32[2048]{0} %get-tuple-element.5523, f32[] %get-tuple-element.5522, f32[2048]{0} %get-tuple-element.5527, /*index=10*/f32[] %get-tuple-element.5526, f32[2048]{0} %get-tuple-element.5519, f32[] %get-tuple-element.5518, f32[2048]{0} %get-tuple-element.5525, f32[] %get-tuple-element.5524, /*index=15*/f32[2048]{0} %get-tuple-element.5529, f32[] %get-tuple-element.5528, f32[2048]{0} %get-tuple-element.5517, f32[] %get-tuple-element.5515), kind=kLoop, calls=%fused_computation.576, metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  %get-tuple-element.5474 = f32[2048]{0} get-tuple-element((f32[2048]{0}, f32[2048]{0}, f32[2048]{0}, f32[2048]{0}, f32[2048]{0}, /*index=5*/f32[2048]{0}, f32[2048]{0}, f32[2048]{0}, f32[2048]{0}) %fusion.576), index=0
  %fusion.306 = (f32[], f32[]) fusion(f32[2048,4096]{1,0} %all-reduce.12513, f32[4096]{0} %get-tuple-element.5280, f32[2048]{0} %get-tuple-element.5474), kind=kInput, calls=%fused_computation.306, metadata={op_type="dot_general" op_name="pmap(_multi_device_update_fn)/dot_general[ dimension_numbers=(((0,), (0,)), ((), ()))\n                                           precision=None\n                                           preferred_element_type=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %get-tuple-element.5283 = f32[] get-tuple-element((f32[], f32[]) %fusion.306), index=1
  %get-tuple-element.5312 = f32[4096]{0} get-tuple-element((f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, /*index=5*/f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, /*index=10*/f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, /*index=15*/f32[4096]{0}, f32[4096]{0}, f32[4096]{0}) %fusion.573), index=2
  %get-tuple-element.5475 = f32[2048]{0} get-tuple-element((f32[2048]{0}, f32[2048]{0}, f32[2048]{0}, f32[2048]{0}, f32[2048]{0}, /*index=5*/f32[2048]{0}, f32[2048]{0}, f32[2048]{0}, f32[2048]{0}) %fusion.576), index=1
  %fusion.293 = (f32[], f32[]) fusion(f32[2048,4096]{1,0} %all-reduce.12638, f32[4096]{0} %get-tuple-element.5312, f32[2048]{0} %get-tuple-element.5475), kind=kInput, calls=%fused_computation.293, metadata={op_type="dot_general" op_name="pmap(_multi_device_update_fn)/dot_general[ dimension_numbers=(((0,), (0,)), ((), ()))\n                                           precision=None\n                                           preferred_element_type=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %get-tuple-element.5132 = f32[] get-tuple-element((f32[], f32[]) %fusion.293), index=1
  %get-tuple-element.5314 = f32[4096]{0} get-tuple-element((f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, /*index=5*/f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, /*index=10*/f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, /*index=15*/f32[4096]{0}, f32[4096]{0}, f32[4096]{0}) %fusion.573), index=4
  %get-tuple-element.5476 = f32[2048]{0} get-tuple-element((f32[2048]{0}, f32[2048]{0}, f32[2048]{0}, f32[2048]{0}, f32[2048]{0}, /*index=5*/f32[2048]{0}, f32[2048]{0}, f32[2048]{0}, f32[2048]{0}) %fusion.576), index=2
  %fusion.294 = (f32[], f32[]) fusion(f32[2048,4096]{1,0} %all-reduce.12628, f32[4096]{0} %get-tuple-element.5314, f32[2048]{0} %get-tuple-element.5476), kind=kInput, calls=%fused_computation.294, metadata={op_type="dot_general" op_name="pmap(_multi_device_update_fn)/dot_general[ dimension_numbers=(((0,), (0,)), ((), ()))\n                                           precision=None\n                                           preferred_element_type=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %get-tuple-element.5144 = f32[] get-tuple-element((f32[], f32[]) %fusion.294), index=1
  %get-tuple-element.5316 = f32[4096]{0} get-tuple-element((f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, /*index=5*/f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, /*index=10*/f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, /*index=15*/f32[4096]{0}, f32[4096]{0}, f32[4096]{0}) %fusion.573), index=6
  %get-tuple-element.5477 = f32[2048]{0} get-tuple-element((f32[2048]{0}, f32[2048]{0}, f32[2048]{0}, f32[2048]{0}, f32[2048]{0}, /*index=5*/f32[2048]{0}, f32[2048]{0}, f32[2048]{0}, f32[2048]{0}) %fusion.576), index=3
  %fusion.295 = (f32[], f32[]) fusion(f32[2048,4096]{1,0} %all-reduce.12618, f32[4096]{0} %get-tuple-element.5316, f32[2048]{0} %get-tuple-element.5477), kind=kInput, calls=%fused_computation.295, metadata={op_type="dot_general" op_name="pmap(_multi_device_update_fn)/dot_general[ dimension_numbers=(((0,), (0,)), ((), ()))\n                                           precision=None\n                                           preferred_element_type=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %get-tuple-element.5156 = f32[] get-tuple-element((f32[], f32[]) %fusion.295), index=1
  %get-tuple-element.5318 = f32[4096]{0} get-tuple-element((f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, /*index=5*/f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, /*index=10*/f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, /*index=15*/f32[4096]{0}, f32[4096]{0}, f32[4096]{0}) %fusion.573), index=8
  %get-tuple-element.5478 = f32[2048]{0} get-tuple-element((f32[2048]{0}, f32[2048]{0}, f32[2048]{0}, f32[2048]{0}, f32[2048]{0}, /*index=5*/f32[2048]{0}, f32[2048]{0}, f32[2048]{0}, f32[2048]{0}) %fusion.576), index=4
  %fusion.296 = (f32[], f32[]) fusion(f32[2048,4096]{1,0} %all-reduce.12608, f32[4096]{0} %get-tuple-element.5318, f32[2048]{0} %get-tuple-element.5478), kind=kInput, calls=%fused_computation.296, metadata={op_type="dot_general" op_name="pmap(_multi_device_update_fn)/dot_general[ dimension_numbers=(((0,), (0,)), ((), ()))\n                                           precision=None\n                                           preferred_element_type=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %get-tuple-element.5168 = f32[] get-tuple-element((f32[], f32[]) %fusion.296), index=1
  %get-tuple-element.5320 = f32[4096]{0} get-tuple-element((f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, /*index=5*/f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, /*index=10*/f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, /*index=15*/f32[4096]{0}, f32[4096]{0}, f32[4096]{0}) %fusion.573), index=10
  %get-tuple-element.5480 = f32[2048]{0} get-tuple-element((f32[2048]{0}, f32[2048]{0}, f32[2048]{0}, f32[2048]{0}, f32[2048]{0}, /*index=5*/f32[2048]{0}, f32[2048]{0}, f32[2048]{0}, f32[2048]{0}) %fusion.576), index=5
  %fusion.301 = (f32[], f32[]) fusion(f32[2048,4096]{1,0} %all-reduce.12558, f32[4096]{0} %get-tuple-element.5320, f32[2048]{0} %get-tuple-element.5480), kind=kInput, calls=%fused_computation.301, metadata={op_type="dot_general" op_name="pmap(_multi_device_update_fn)/dot_general[ dimension_numbers=(((0,), (0,)), ((), ()))\n                                           precision=None\n                                           preferred_element_type=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %get-tuple-element.5228 = f32[] get-tuple-element((f32[], f32[]) %fusion.301), index=1
  %get-tuple-element.5322 = f32[4096]{0} get-tuple-element((f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, /*index=5*/f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, /*index=10*/f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, /*index=15*/f32[4096]{0}, f32[4096]{0}, f32[4096]{0}) %fusion.573), index=12
  %get-tuple-element.5481 = f32[2048]{0} get-tuple-element((f32[2048]{0}, f32[2048]{0}, f32[2048]{0}, f32[2048]{0}, f32[2048]{0}, /*index=5*/f32[2048]{0}, f32[2048]{0}, f32[2048]{0}, f32[2048]{0}) %fusion.576), index=6
  %fusion.303 = (f32[], f32[]) fusion(f32[2048,4096]{1,0} %all-reduce.12543, f32[4096]{0} %get-tuple-element.5322, f32[2048]{0} %get-tuple-element.5481), kind=kInput, calls=%fused_computation.303, metadata={op_type="dot_general" op_name="pmap(_multi_device_update_fn)/dot_general[ dimension_numbers=(((0,), (0,)), ((), ()))\n                                           precision=None\n                                           preferred_element_type=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %get-tuple-element.5247 = f32[] get-tuple-element((f32[], f32[]) %fusion.303), index=1
  %get-tuple-element.5324 = f32[4096]{0} get-tuple-element((f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, /*index=5*/f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, /*index=10*/f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, /*index=15*/f32[4096]{0}, f32[4096]{0}, f32[4096]{0}) %fusion.573), index=14
  %get-tuple-element.5482 = f32[2048]{0} get-tuple-element((f32[2048]{0}, f32[2048]{0}, f32[2048]{0}, f32[2048]{0}, f32[2048]{0}, /*index=5*/f32[2048]{0}, f32[2048]{0}, f32[2048]{0}, f32[2048]{0}) %fusion.576), index=7
  %fusion.304 = (f32[], f32[]) fusion(f32[2048,4096]{1,0} %all-reduce.12533, f32[4096]{0} %get-tuple-element.5324, f32[2048]{0} %get-tuple-element.5482), kind=kInput, calls=%fused_computation.304, metadata={op_type="dot_general" op_name="pmap(_multi_device_update_fn)/dot_general[ dimension_numbers=(((0,), (0,)), ((), ()))\n                                           precision=None\n                                           preferred_element_type=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %get-tuple-element.5259 = f32[] get-tuple-element((f32[], f32[]) %fusion.304), index=1
  %fusion.770 = (f32[1]{0}, f32[1]{0}, f32[1]{0}, f32[1]{0}, f32[1]{0}, /*index=5*/f32[1]{0}, f32[1]{0}, f32[1]{0}) fusion(f32[] %get-tuple-element.5283, f32[] %get-tuple-element.5132, f32[] %get-tuple-element.5144, f32[] %get-tuple-element.5156, f32[] %get-tuple-element.5168, /*index=5*/f32[] %get-tuple-element.5228, f32[] %get-tuple-element.5247, f32[] %get-tuple-element.5259), kind=kInput, calls=%horizontally_fused_computation.3
  %get-tuple-element.5587 = f32[1]{0} get-tuple-element((f32[1]{0}, f32[1]{0}, f32[1]{0}, f32[1]{0}, f32[1]{0}, /*index=5*/f32[1]{0}, f32[1]{0}, f32[1]{0}) %fusion.770), index=0
  %bitcast.1041 = f32[] bitcast(f32[1]{0} %get-tuple-element.5587), metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %get-tuple-element.5277 = f32[] get-tuple-element((f32[], f32[], f32[], f32[], f32[], /*index=5*/f32[], f32[], f32[], f32[], f32[], /*index=10*/f32[], f32[], f32[], f32[], f32[], /*index=15*/f32[], f32[], f32[], f32[], f32[], /*index=20*/f32[], f32[], f32[], f32[], f32[], /*index=25*/f32[], f32[], f32[], f32[], f32[], /*index=30*/f32[]) %fusion.313), index=29
  %get-tuple-element.5588 = f32[1]{0} get-tuple-element((f32[1]{0}, f32[1]{0}, f32[1]{0}, f32[1]{0}, f32[1]{0}, /*index=5*/f32[1]{0}, f32[1]{0}, f32[1]{0}) %fusion.770), index=1
  %bitcast.1042 = f32[] bitcast(f32[1]{0} %get-tuple-element.5588), metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %get-tuple-element.5126 = f32[] get-tuple-element((f32[], f32[], f32[], f32[], f32[], /*index=5*/f32[], f32[], f32[], f32[], f32[], /*index=10*/f32[], f32[], f32[], f32[], f32[], /*index=15*/f32[], f32[], f32[], f32[], f32[], /*index=20*/f32[], f32[], f32[], f32[], f32[], /*index=25*/f32[], f32[], f32[], f32[], f32[], /*index=30*/f32[]) %fusion.313), index=4
  %get-tuple-element.5589 = f32[1]{0} get-tuple-element((f32[1]{0}, f32[1]{0}, f32[1]{0}, f32[1]{0}, f32[1]{0}, /*index=5*/f32[1]{0}, f32[1]{0}, f32[1]{0}) %fusion.770), index=2
  %bitcast.1043 = f32[] bitcast(f32[1]{0} %get-tuple-element.5589), metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %get-tuple-element.5138 = f32[] get-tuple-element((f32[], f32[], f32[], f32[], f32[], /*index=5*/f32[], f32[], f32[], f32[], f32[], /*index=10*/f32[], f32[], f32[], f32[], f32[], /*index=15*/f32[], f32[], f32[], f32[], f32[], /*index=20*/f32[], f32[], f32[], f32[], f32[], /*index=25*/f32[], f32[], f32[], f32[], f32[], /*index=30*/f32[]) %fusion.313), index=6
  %get-tuple-element.5590 = f32[1]{0} get-tuple-element((f32[1]{0}, f32[1]{0}, f32[1]{0}, f32[1]{0}, f32[1]{0}, /*index=5*/f32[1]{0}, f32[1]{0}, f32[1]{0}) %fusion.770), index=3
  %bitcast.1044 = f32[] bitcast(f32[1]{0} %get-tuple-element.5590), metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %get-tuple-element.5150 = f32[] get-tuple-element((f32[], f32[], f32[], f32[], f32[], /*index=5*/f32[], f32[], f32[], f32[], f32[], /*index=10*/f32[], f32[], f32[], f32[], f32[], /*index=15*/f32[], f32[], f32[], f32[], f32[], /*index=20*/f32[], f32[], f32[], f32[], f32[], /*index=25*/f32[], f32[], f32[], f32[], f32[], /*index=30*/f32[]) %fusion.313), index=8
  %get-tuple-element.5613 = f32[1]{0} get-tuple-element((f32[1]{0}, f32[1]{0}, f32[1]{0}, f32[1]{0}, f32[1]{0}, /*index=5*/f32[1]{0}, f32[1]{0}, f32[1]{0}) %fusion.770), index=4
  %bitcast.1045 = f32[] bitcast(f32[1]{0} %get-tuple-element.5613), metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %get-tuple-element.5162 = f32[] get-tuple-element((f32[], f32[], f32[], f32[], f32[], /*index=5*/f32[], f32[], f32[], f32[], f32[], /*index=10*/f32[], f32[], f32[], f32[], f32[], /*index=15*/f32[], f32[], f32[], f32[], f32[], /*index=20*/f32[], f32[], f32[], f32[], f32[], /*index=25*/f32[], f32[], f32[], f32[], f32[], /*index=30*/f32[]) %fusion.313), index=10
  %get-tuple-element.5614 = f32[1]{0} get-tuple-element((f32[1]{0}, f32[1]{0}, f32[1]{0}, f32[1]{0}, f32[1]{0}, /*index=5*/f32[1]{0}, f32[1]{0}, f32[1]{0}) %fusion.770), index=5
  %bitcast.1046 = f32[] bitcast(f32[1]{0} %get-tuple-element.5614), metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %get-tuple-element.5222 = f32[] get-tuple-element((f32[], f32[], f32[], f32[], f32[], /*index=5*/f32[], f32[], f32[], f32[], f32[], /*index=10*/f32[], f32[], f32[], f32[], f32[], /*index=15*/f32[], f32[], f32[], f32[], f32[], /*index=20*/f32[], f32[], f32[], f32[], f32[], /*index=25*/f32[], f32[], f32[], f32[], f32[], /*index=30*/f32[]) %fusion.313), index=20
  %get-tuple-element.5615 = f32[1]{0} get-tuple-element((f32[1]{0}, f32[1]{0}, f32[1]{0}, f32[1]{0}, f32[1]{0}, /*index=5*/f32[1]{0}, f32[1]{0}, f32[1]{0}) %fusion.770), index=6
  %bitcast.1047 = f32[] bitcast(f32[1]{0} %get-tuple-element.5615), metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %get-tuple-element.5241 = f32[] get-tuple-element((f32[], f32[], f32[], f32[], f32[], /*index=5*/f32[], f32[], f32[], f32[], f32[], /*index=10*/f32[], f32[], f32[], f32[], f32[], /*index=15*/f32[], f32[], f32[], f32[], f32[], /*index=20*/f32[], f32[], f32[], f32[], f32[], /*index=25*/f32[], f32[], f32[], f32[], f32[], /*index=30*/f32[]) %fusion.313), index=23
  %get-tuple-element.5616 = f32[1]{0} get-tuple-element((f32[1]{0}, f32[1]{0}, f32[1]{0}, f32[1]{0}, f32[1]{0}, /*index=5*/f32[1]{0}, f32[1]{0}, f32[1]{0}) %fusion.770), index=7
  %bitcast.1048 = f32[] bitcast(f32[1]{0} %get-tuple-element.5616), metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %get-tuple-element.5253 = f32[] get-tuple-element((f32[], f32[], f32[], f32[], f32[], /*index=5*/f32[], f32[], f32[], f32[], f32[], /*index=10*/f32[], f32[], f32[], f32[], f32[], /*index=15*/f32[], f32[], f32[], f32[], f32[], /*index=20*/f32[], f32[], f32[], f32[], f32[], /*index=25*/f32[], f32[], f32[], f32[], f32[], /*index=30*/f32[]) %fusion.313), index=25
  %fusion.569 = (f32[2048,4096]{1,0}, f32[2048,4096]{1,0}, f32[2048,4096]{1,0}, f32[2048,4096]{1,0}, f32[2048,4096]{1,0}, /*index=5*/f32[2048,4096]{1,0}, f32[2048,4096]{1,0}, f32[2048,4096]{1,0}) fusion(f32[] %bitcast.1041, f32[] %parameter.160, f32[] %parameter.164, f32[] %get-tuple-element.5277, f32[] %parameter.163, /*index=5*/f32[2048,4096]{1,0} %parameter.83, f32[] %get-tuple-element.5535, f32[4096]{0} %get-tuple-element.5280, f32[2048,4096]{1,0} %all-reduce.12513, f32[2048]{0} %get-tuple-element.5474, /*index=10*/f32[] %bitcast.1042, f32[4096]{0} %get-tuple-element.5312, f32[2048,4096]{1,0} %all-reduce.12638, f32[2048]{0} %get-tuple-element.5475, f32[] %get-tuple-element.5126, /*index=15*/f32[2048,4096]{1,0} %parameter.108, f32[] %bitcast.1043, f32[4096]{0} %get-tuple-element.5314, f32[2048,4096]{1,0} %all-reduce.12628, f32[2048]{0} %get-tuple-element.5476, /*index=20*/f32[] %get-tuple-element.5138, f32[2048,4096]{1,0} %parameter.106, f32[] %bitcast.1044, f32[4096]{0} %get-tuple-element.5316, f32[2048,4096]{1,0} %all-reduce.12618, /*index=25*/f32[2048]{0} %get-tuple-element.5477, f32[] %get-tuple-element.5150, f32[2048,4096]{1,0} %parameter.104, f32[] %bitcast.1045, f32[4096]{0} %get-tuple-element.5318, /*index=30*/f32[2048,4096]{1,0} %all-reduce.12608, f32[2048]{0} %get-tuple-element.5478, f32[] %get-tuple-element.5162, f32[2048,4096]{1,0} %parameter.102, f32[] %bitcast.1046, /*index=35*/f32[4096]{0} %get-tuple-element.5320, f32[2048,4096]{1,0} %all-reduce.12558, f32[2048]{0} %get-tuple-element.5480, f32[] %get-tuple-element.5222, f32[2048,4096]{1,0} %parameter.92, /*index=40*/f32[] %bitcast.1047, f32[4096]{0} %get-tuple-element.5322, f32[2048,4096]{1,0} %all-reduce.12543, f32[2048]{0} %get-tuple-element.5481, f32[] %get-tuple-element.5241, /*index=45*/f32[2048,4096]{1,0} %parameter.89, f32[] %bitcast.1048, f32[4096]{0} %get-tuple-element.5324, f32[2048,4096]{1,0} %all-reduce.12533, f32[2048]{0} %get-tuple-element.5482, /*index=50*/f32[] %get-tuple-element.5253, f32[2048,4096]{1,0} %parameter.87), kind=kLoop, calls=%fused_computation.569, metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  %get-tuple-element.5284 = f32[2048,4096]{1,0} get-tuple-element((f32[2048,4096]{1,0}, f32[2048,4096]{1,0}, f32[2048,4096]{1,0}, f32[2048,4096]{1,0}, f32[2048,4096]{1,0}, /*index=5*/f32[2048,4096]{1,0}, f32[2048,4096]{1,0}, f32[2048,4096]{1,0}) %fusion.569), index=0
  %get-tuple-element.5699 = f32[4096]{0} get-tuple-element((f32[1024,1024]{1,0}, f32[1024,1024]{1,0}, f32[1024,1024]{1,0}, f32[1024,1024]{1,0}, f32[256,1024]{1,0}, /*index=5*/f32[1024,256]{1,0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, /*index=10*/f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, /*index=15*/f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[256]{0}) %all-reduce), index=10, metadata={op_type="psum" op_name="pmap(_multi_device_update_fn)/psum[ axes=(\'batch\',)\n                                    axis_index_groups=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=347}
  %parameter.154 = f32[4096]{0} parameter(72), parameter_replication={false}
  %get-tuple-element.5700 = f32[4096]{0} get-tuple-element((f32[1024,1024]{1,0}, f32[1024,1024]{1,0}, f32[1024,1024]{1,0}, f32[1024,1024]{1,0}, f32[256,1024]{1,0}, /*index=5*/f32[1024,256]{1,0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, /*index=10*/f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, /*index=15*/f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[256]{0}) %all-reduce), index=11, metadata={op_type="psum" op_name="pmap(_multi_device_update_fn)/psum[ axes=(\'batch\',)\n                                    axis_index_groups=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=347}
  %parameter.151 = f32[4096]{0} parameter(69), parameter_replication={false}
  %get-tuple-element.5701 = f32[4096]{0} get-tuple-element((f32[1024,1024]{1,0}, f32[1024,1024]{1,0}, f32[1024,1024]{1,0}, f32[1024,1024]{1,0}, f32[256,1024]{1,0}, /*index=5*/f32[1024,256]{1,0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, /*index=10*/f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, /*index=15*/f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[256]{0}) %all-reduce), index=12, metadata={op_type="psum" op_name="pmap(_multi_device_update_fn)/psum[ axes=(\'batch\',)\n                                    axis_index_groups=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=347}
  %parameter.148 = f32[4096]{0} parameter(66), parameter_replication={false}
  %get-tuple-element.5702 = f32[4096]{0} get-tuple-element((f32[1024,1024]{1,0}, f32[1024,1024]{1,0}, f32[1024,1024]{1,0}, f32[1024,1024]{1,0}, f32[256,1024]{1,0}, /*index=5*/f32[1024,256]{1,0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, /*index=10*/f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, /*index=15*/f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[256]{0}) %all-reduce), index=13, metadata={op_type="psum" op_name="pmap(_multi_device_update_fn)/psum[ axes=(\'batch\',)\n                                    axis_index_groups=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=347}
  %parameter.145 = f32[4096]{0} parameter(63), parameter_replication={false}
  %get-tuple-element.5703 = f32[4096]{0} get-tuple-element((f32[1024,1024]{1,0}, f32[1024,1024]{1,0}, f32[1024,1024]{1,0}, f32[1024,1024]{1,0}, f32[256,1024]{1,0}, /*index=5*/f32[1024,256]{1,0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, /*index=10*/f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, /*index=15*/f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[256]{0}) %all-reduce), index=14, metadata={op_type="psum" op_name="pmap(_multi_device_update_fn)/psum[ axes=(\'batch\',)\n                                    axis_index_groups=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=347}
  %parameter.130 = f32[4096]{0} parameter(48), parameter_replication={false}
  %get-tuple-element.5704 = f32[4096]{0} get-tuple-element((f32[1024,1024]{1,0}, f32[1024,1024]{1,0}, f32[1024,1024]{1,0}, f32[1024,1024]{1,0}, f32[256,1024]{1,0}, /*index=5*/f32[1024,256]{1,0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, /*index=10*/f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, /*index=15*/f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[256]{0}) %all-reduce), index=15, metadata={op_type="psum" op_name="pmap(_multi_device_update_fn)/psum[ axes=(\'batch\',)\n                                    axis_index_groups=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=347}
  %parameter.125 = f32[4096]{0} parameter(43), parameter_replication={false}
  %get-tuple-element.5705 = f32[4096]{0} get-tuple-element((f32[1024,1024]{1,0}, f32[1024,1024]{1,0}, f32[1024,1024]{1,0}, f32[1024,1024]{1,0}, f32[256,1024]{1,0}, /*index=5*/f32[1024,256]{1,0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, /*index=10*/f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, /*index=15*/f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[256]{0}) %all-reduce), index=16, metadata={op_type="psum" op_name="pmap(_multi_device_update_fn)/psum[ axes=(\'batch\',)\n                                    axis_index_groups=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=347}
  %parameter.122 = f32[4096]{0} parameter(40), parameter_replication={false}
  %get-tuple-element.5706 = f32[4096]{0} get-tuple-element((f32[1024,1024]{1,0}, f32[1024,1024]{1,0}, f32[1024,1024]{1,0}, f32[1024,1024]{1,0}, f32[256,1024]{1,0}, /*index=5*/f32[1024,256]{1,0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, /*index=10*/f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, /*index=15*/f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[256]{0}) %all-reduce), index=17, metadata={op_type="psum" op_name="pmap(_multi_device_update_fn)/psum[ axes=(\'batch\',)\n                                    axis_index_groups=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=347}
  %parameter.119 = f32[4096]{0} parameter(37), parameter_replication={false}
  %get-tuple-element.5707 = f32[4096]{0} get-tuple-element((f32[1024,1024]{1,0}, f32[1024,1024]{1,0}, f32[1024,1024]{1,0}, f32[1024,1024]{1,0}, f32[256,1024]{1,0}, /*index=5*/f32[1024,256]{1,0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, /*index=10*/f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, /*index=15*/f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[256]{0}) %all-reduce), index=18, metadata={op_type="psum" op_name="pmap(_multi_device_update_fn)/psum[ axes=(\'batch\',)\n                                    axis_index_groups=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=347}
  %parameter.116 = f32[4096]{0} parameter(34), parameter_replication={false}
  %fusion.329 = (f32[], f32[4096]{0}, f32[4096]{0}, f32[], f32[], /*index=5*/f32[4096]{0}, f32[4096]{0}, f32[], f32[], f32[4096]{0}, /*index=10*/f32[4096]{0}, f32[], f32[], f32[4096]{0}, f32[4096]{0}, /*index=15*/f32[], f32[], f32[4096]{0}, f32[4096]{0}, f32[], /*index=20*/f32[], f32[4096]{0}, f32[4096]{0}, f32[], f32[], /*index=25*/f32[4096]{0}, f32[4096]{0}, f32[], f32[], f32[4096]{0}, /*index=30*/f32[4096]{0}, f32[], f32[], f32[4096]{0}, f32[4096]{0}, /*index=35*/f32[]) fusion(f32[] %parameter.162, f32[4096]{0} %get-tuple-element.5699, f32[] %get-tuple-element.5534, f32[4096]{0} %parameter.154, f32[4096]{0} %get-tuple-element.5700, /*index=5*/f32[4096]{0} %parameter.151, f32[4096]{0} %get-tuple-element.5701, f32[4096]{0} %parameter.148, f32[4096]{0} %get-tuple-element.5702, f32[4096]{0} %parameter.145, /*index=10*/f32[4096]{0} %get-tuple-element.5703, f32[4096]{0} %parameter.130, f32[4096]{0} %get-tuple-element.5704, f32[4096]{0} %parameter.125, f32[4096]{0} %get-tuple-element.5705, /*index=15*/f32[4096]{0} %parameter.122, f32[4096]{0} %get-tuple-element.5706, f32[4096]{0} %parameter.119, f32[4096]{0} %get-tuple-element.5707, f32[4096]{0} %parameter.116), kind=kInput, calls=%fused_computation.329, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %get-tuple-element.5441 = f32[4096]{0} get-tuple-element((f32[], f32[4096]{0}, f32[4096]{0}, f32[], f32[], /*index=5*/f32[4096]{0}, f32[4096]{0}, f32[], f32[], f32[4096]{0}, /*index=10*/f32[4096]{0}, f32[], f32[], f32[4096]{0}, f32[4096]{0}, /*index=15*/f32[], f32[], f32[4096]{0}, f32[4096]{0}, f32[], /*index=20*/f32[], f32[4096]{0}, f32[4096]{0}, f32[], f32[], /*index=25*/f32[4096]{0}, f32[4096]{0}, f32[], f32[], f32[4096]{0}, /*index=30*/f32[4096]{0}, f32[], f32[], f32[4096]{0}, f32[4096]{0}, /*index=35*/f32[]) %fusion.329), index=33
  %get-tuple-element.5440 = f32[] get-tuple-element((f32[], f32[4096]{0}, f32[4096]{0}, f32[], f32[], /*index=5*/f32[4096]{0}, f32[4096]{0}, f32[], f32[], f32[4096]{0}, /*index=10*/f32[4096]{0}, f32[], f32[], f32[4096]{0}, f32[4096]{0}, /*index=15*/f32[], f32[], f32[4096]{0}, f32[4096]{0}, f32[], /*index=20*/f32[], f32[4096]{0}, f32[4096]{0}, f32[], f32[], /*index=25*/f32[4096]{0}, f32[4096]{0}, f32[], f32[], f32[4096]{0}, /*index=30*/f32[4096]{0}, f32[], f32[], f32[4096]{0}, f32[4096]{0}, /*index=35*/f32[]) %fusion.329), index=32
  %get-tuple-element.5122 = f32[] get-tuple-element((f32[], f32[4096]{0}, f32[4096]{0}, f32[], f32[], /*index=5*/f32[4096]{0}, f32[4096]{0}, f32[], f32[], f32[4096]{0}, /*index=10*/f32[4096]{0}, f32[], f32[], f32[4096]{0}, f32[4096]{0}, /*index=15*/f32[], f32[], f32[4096]{0}, f32[4096]{0}, f32[], /*index=20*/f32[], f32[4096]{0}, f32[4096]{0}, f32[], f32[], /*index=25*/f32[4096]{0}, f32[4096]{0}, f32[], f32[], f32[4096]{0}, /*index=30*/f32[4096]{0}, f32[], f32[], f32[4096]{0}, f32[4096]{0}, /*index=35*/f32[]) %fusion.329), index=0
  %get-tuple-element.5329 = f32[] get-tuple-element((f32[], f32[4096]{0}, f32[4096]{0}, f32[], f32[], /*index=5*/f32[4096]{0}, f32[4096]{0}, f32[], f32[], f32[4096]{0}, /*index=10*/f32[4096]{0}, f32[], f32[], f32[4096]{0}, f32[4096]{0}, /*index=15*/f32[], f32[], f32[4096]{0}, f32[4096]{0}, f32[], /*index=20*/f32[], f32[4096]{0}, f32[4096]{0}, f32[], f32[], /*index=25*/f32[4096]{0}, f32[4096]{0}, f32[], f32[], f32[4096]{0}, /*index=30*/f32[4096]{0}, f32[], f32[], f32[4096]{0}, f32[4096]{0}, /*index=35*/f32[]) %fusion.329), index=4
  %get-tuple-element.5355 = f32[] get-tuple-element((f32[], f32[4096]{0}, f32[4096]{0}, f32[], f32[], /*index=5*/f32[4096]{0}, f32[4096]{0}, f32[], f32[], f32[4096]{0}, /*index=10*/f32[4096]{0}, f32[], f32[], f32[4096]{0}, f32[4096]{0}, /*index=15*/f32[], f32[], f32[4096]{0}, f32[4096]{0}, f32[], /*index=20*/f32[], f32[4096]{0}, f32[4096]{0}, f32[], f32[], /*index=25*/f32[4096]{0}, f32[4096]{0}, f32[], f32[], f32[4096]{0}, /*index=30*/f32[4096]{0}, f32[], f32[], f32[4096]{0}, f32[4096]{0}, /*index=35*/f32[]) %fusion.329), index=8
  %get-tuple-element.5400 = f32[] get-tuple-element((f32[], f32[4096]{0}, f32[4096]{0}, f32[], f32[], /*index=5*/f32[4096]{0}, f32[4096]{0}, f32[], f32[], f32[4096]{0}, /*index=10*/f32[4096]{0}, f32[], f32[], f32[4096]{0}, f32[4096]{0}, /*index=15*/f32[], f32[], f32[4096]{0}, f32[4096]{0}, f32[], /*index=20*/f32[], f32[4096]{0}, f32[4096]{0}, f32[], f32[], /*index=25*/f32[4096]{0}, f32[4096]{0}, f32[], f32[], f32[4096]{0}, /*index=30*/f32[4096]{0}, f32[], f32[], f32[4096]{0}, f32[4096]{0}, /*index=35*/f32[]) %fusion.329), index=12
  %get-tuple-element.5422 = f32[] get-tuple-element((f32[], f32[4096]{0}, f32[4096]{0}, f32[], f32[], /*index=5*/f32[4096]{0}, f32[4096]{0}, f32[], f32[], f32[4096]{0}, /*index=10*/f32[4096]{0}, f32[], f32[], f32[4096]{0}, f32[4096]{0}, /*index=15*/f32[], f32[], f32[4096]{0}, f32[4096]{0}, f32[], /*index=20*/f32[], f32[4096]{0}, f32[4096]{0}, f32[], f32[], /*index=25*/f32[4096]{0}, f32[4096]{0}, f32[], f32[], f32[4096]{0}, /*index=30*/f32[4096]{0}, f32[], f32[], f32[4096]{0}, f32[4096]{0}, /*index=35*/f32[]) %fusion.329), index=16
  %get-tuple-element.5426 = f32[] get-tuple-element((f32[], f32[4096]{0}, f32[4096]{0}, f32[], f32[], /*index=5*/f32[4096]{0}, f32[4096]{0}, f32[], f32[], f32[4096]{0}, /*index=10*/f32[4096]{0}, f32[], f32[], f32[4096]{0}, f32[4096]{0}, /*index=15*/f32[], f32[], f32[4096]{0}, f32[4096]{0}, f32[], /*index=20*/f32[], f32[4096]{0}, f32[4096]{0}, f32[], f32[], /*index=25*/f32[4096]{0}, f32[4096]{0}, f32[], f32[], f32[4096]{0}, /*index=30*/f32[4096]{0}, f32[], f32[], f32[4096]{0}, f32[4096]{0}, /*index=35*/f32[]) %fusion.329), index=20
  %get-tuple-element.5430 = f32[] get-tuple-element((f32[], f32[4096]{0}, f32[4096]{0}, f32[], f32[], /*index=5*/f32[4096]{0}, f32[4096]{0}, f32[], f32[], f32[4096]{0}, /*index=10*/f32[4096]{0}, f32[], f32[], f32[4096]{0}, f32[4096]{0}, /*index=15*/f32[], f32[], f32[4096]{0}, f32[4096]{0}, f32[], /*index=20*/f32[], f32[4096]{0}, f32[4096]{0}, f32[], f32[], /*index=25*/f32[4096]{0}, f32[4096]{0}, f32[], f32[], f32[4096]{0}, /*index=30*/f32[4096]{0}, f32[], f32[], f32[4096]{0}, f32[4096]{0}, /*index=35*/f32[]) %fusion.329), index=24
  %get-tuple-element.5434 = f32[] get-tuple-element((f32[], f32[4096]{0}, f32[4096]{0}, f32[], f32[], /*index=5*/f32[4096]{0}, f32[4096]{0}, f32[], f32[], f32[4096]{0}, /*index=10*/f32[4096]{0}, f32[], f32[], f32[4096]{0}, f32[4096]{0}, /*index=15*/f32[], f32[], f32[4096]{0}, f32[4096]{0}, f32[], /*index=20*/f32[], f32[4096]{0}, f32[4096]{0}, f32[], f32[], /*index=25*/f32[4096]{0}, f32[4096]{0}, f32[], f32[], f32[4096]{0}, /*index=30*/f32[4096]{0}, f32[], f32[], f32[4096]{0}, f32[4096]{0}, /*index=35*/f32[]) %fusion.329), index=28
  %fusion.769 = (f32[1]{0}, f32[1]{0}, f32[1]{0}, f32[1]{0}, f32[1]{0}, /*index=5*/f32[1]{0}, f32[1]{0}, f32[1]{0}, f32[1]{0}) fusion(f32[] %get-tuple-element.5440, f32[] %get-tuple-element.5122, f32[] %get-tuple-element.5329, f32[] %get-tuple-element.5355, f32[] %get-tuple-element.5400, /*index=5*/f32[] %get-tuple-element.5422, f32[] %get-tuple-element.5426, f32[] %get-tuple-element.5430, f32[] %get-tuple-element.5434), kind=kInput, calls=%horizontally_fused_computation.2
  %get-tuple-element.5578 = f32[1]{0} get-tuple-element((f32[1]{0}, f32[1]{0}, f32[1]{0}, f32[1]{0}, f32[1]{0}, /*index=5*/f32[1]{0}, f32[1]{0}, f32[1]{0}, f32[1]{0}) %fusion.769), index=0
  %bitcast.1032 = f32[] bitcast(f32[1]{0} %get-tuple-element.5578), metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %get-tuple-element.5272 = f32[] get-tuple-element((f32[], f32[], f32[], f32[], f32[], /*index=5*/f32[], f32[], f32[], f32[], f32[], /*index=10*/f32[], f32[], f32[], f32[], f32[], /*index=15*/f32[], f32[], f32[], f32[], f32[], /*index=20*/f32[], f32[], f32[], f32[], f32[], /*index=25*/f32[], f32[], f32[], f32[], f32[], /*index=30*/f32[]) %fusion.313), index=28
  %get-tuple-element.5123 = f32[4096]{0} get-tuple-element((f32[], f32[4096]{0}, f32[4096]{0}, f32[], f32[], /*index=5*/f32[4096]{0}, f32[4096]{0}, f32[], f32[], f32[4096]{0}, /*index=10*/f32[4096]{0}, f32[], f32[], f32[4096]{0}, f32[4096]{0}, /*index=15*/f32[], f32[], f32[4096]{0}, f32[4096]{0}, f32[], /*index=20*/f32[], f32[4096]{0}, f32[4096]{0}, f32[], f32[], /*index=25*/f32[4096]{0}, f32[4096]{0}, f32[], f32[], f32[4096]{0}, /*index=30*/f32[4096]{0}, f32[], f32[], f32[4096]{0}, f32[4096]{0}, /*index=35*/f32[]) %fusion.329), index=1
  %get-tuple-element.5579 = f32[1]{0} get-tuple-element((f32[1]{0}, f32[1]{0}, f32[1]{0}, f32[1]{0}, f32[1]{0}, /*index=5*/f32[1]{0}, f32[1]{0}, f32[1]{0}, f32[1]{0}) %fusion.769), index=1
  %bitcast.1033 = f32[] bitcast(f32[1]{0} %get-tuple-element.5579), metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %get-tuple-element.5121 = f32[] get-tuple-element((f32[], f32[], f32[], f32[], f32[], /*index=5*/f32[], f32[], f32[], f32[], f32[], /*index=10*/f32[], f32[], f32[], f32[], f32[], /*index=15*/f32[], f32[], f32[], f32[], f32[], /*index=20*/f32[], f32[], f32[], f32[], f32[], /*index=25*/f32[], f32[], f32[], f32[], f32[], /*index=30*/f32[]) %fusion.313), index=3
  %get-tuple-element.5330 = f32[4096]{0} get-tuple-element((f32[], f32[4096]{0}, f32[4096]{0}, f32[], f32[], /*index=5*/f32[4096]{0}, f32[4096]{0}, f32[], f32[], f32[4096]{0}, /*index=10*/f32[4096]{0}, f32[], f32[], f32[4096]{0}, f32[4096]{0}, /*index=15*/f32[], f32[], f32[4096]{0}, f32[4096]{0}, f32[], /*index=20*/f32[], f32[4096]{0}, f32[4096]{0}, f32[], f32[], /*index=25*/f32[4096]{0}, f32[4096]{0}, f32[], f32[], f32[4096]{0}, /*index=30*/f32[4096]{0}, f32[], f32[], f32[4096]{0}, f32[4096]{0}, /*index=35*/f32[]) %fusion.329), index=5
  %get-tuple-element.5580 = f32[1]{0} get-tuple-element((f32[1]{0}, f32[1]{0}, f32[1]{0}, f32[1]{0}, f32[1]{0}, /*index=5*/f32[1]{0}, f32[1]{0}, f32[1]{0}, f32[1]{0}) %fusion.769), index=2
  %bitcast.1034 = f32[] bitcast(f32[1]{0} %get-tuple-element.5580), metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %get-tuple-element.5133 = f32[] get-tuple-element((f32[], f32[], f32[], f32[], f32[], /*index=5*/f32[], f32[], f32[], f32[], f32[], /*index=10*/f32[], f32[], f32[], f32[], f32[], /*index=15*/f32[], f32[], f32[], f32[], f32[], /*index=20*/f32[], f32[], f32[], f32[], f32[], /*index=25*/f32[], f32[], f32[], f32[], f32[], /*index=30*/f32[]) %fusion.313), index=5
  %get-tuple-element.5356 = f32[4096]{0} get-tuple-element((f32[], f32[4096]{0}, f32[4096]{0}, f32[], f32[], /*index=5*/f32[4096]{0}, f32[4096]{0}, f32[], f32[], f32[4096]{0}, /*index=10*/f32[4096]{0}, f32[], f32[], f32[4096]{0}, f32[4096]{0}, /*index=15*/f32[], f32[], f32[4096]{0}, f32[4096]{0}, f32[], /*index=20*/f32[], f32[4096]{0}, f32[4096]{0}, f32[], f32[], /*index=25*/f32[4096]{0}, f32[4096]{0}, f32[], f32[], f32[4096]{0}, /*index=30*/f32[4096]{0}, f32[], f32[], f32[4096]{0}, f32[4096]{0}, /*index=35*/f32[]) %fusion.329), index=9
  %get-tuple-element.5581 = f32[1]{0} get-tuple-element((f32[1]{0}, f32[1]{0}, f32[1]{0}, f32[1]{0}, f32[1]{0}, /*index=5*/f32[1]{0}, f32[1]{0}, f32[1]{0}, f32[1]{0}) %fusion.769), index=3
  %bitcast.1035 = f32[] bitcast(f32[1]{0} %get-tuple-element.5581), metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %get-tuple-element.5145 = f32[] get-tuple-element((f32[], f32[], f32[], f32[], f32[], /*index=5*/f32[], f32[], f32[], f32[], f32[], /*index=10*/f32[], f32[], f32[], f32[], f32[], /*index=15*/f32[], f32[], f32[], f32[], f32[], /*index=20*/f32[], f32[], f32[], f32[], f32[], /*index=25*/f32[], f32[], f32[], f32[], f32[], /*index=30*/f32[]) %fusion.313), index=7
  %get-tuple-element.5419 = f32[4096]{0} get-tuple-element((f32[], f32[4096]{0}, f32[4096]{0}, f32[], f32[], /*index=5*/f32[4096]{0}, f32[4096]{0}, f32[], f32[], f32[4096]{0}, /*index=10*/f32[4096]{0}, f32[], f32[], f32[4096]{0}, f32[4096]{0}, /*index=15*/f32[], f32[], f32[4096]{0}, f32[4096]{0}, f32[], /*index=20*/f32[], f32[4096]{0}, f32[4096]{0}, f32[], f32[], /*index=25*/f32[4096]{0}, f32[4096]{0}, f32[], f32[], f32[4096]{0}, /*index=30*/f32[4096]{0}, f32[], f32[], f32[4096]{0}, f32[4096]{0}, /*index=35*/f32[]) %fusion.329), index=13
  %get-tuple-element.5582 = f32[1]{0} get-tuple-element((f32[1]{0}, f32[1]{0}, f32[1]{0}, f32[1]{0}, f32[1]{0}, /*index=5*/f32[1]{0}, f32[1]{0}, f32[1]{0}, f32[1]{0}) %fusion.769), index=4
  %bitcast.1036 = f32[] bitcast(f32[1]{0} %get-tuple-element.5582), metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %get-tuple-element.5157 = f32[] get-tuple-element((f32[], f32[], f32[], f32[], f32[], /*index=5*/f32[], f32[], f32[], f32[], f32[], /*index=10*/f32[], f32[], f32[], f32[], f32[], /*index=15*/f32[], f32[], f32[], f32[], f32[], /*index=20*/f32[], f32[], f32[], f32[], f32[], /*index=25*/f32[], f32[], f32[], f32[], f32[], /*index=30*/f32[]) %fusion.313), index=9
  %get-tuple-element.5423 = f32[4096]{0} get-tuple-element((f32[], f32[4096]{0}, f32[4096]{0}, f32[], f32[], /*index=5*/f32[4096]{0}, f32[4096]{0}, f32[], f32[], f32[4096]{0}, /*index=10*/f32[4096]{0}, f32[], f32[], f32[4096]{0}, f32[4096]{0}, /*index=15*/f32[], f32[], f32[4096]{0}, f32[4096]{0}, f32[], /*index=20*/f32[], f32[4096]{0}, f32[4096]{0}, f32[], f32[], /*index=25*/f32[4096]{0}, f32[4096]{0}, f32[], f32[], f32[4096]{0}, /*index=30*/f32[4096]{0}, f32[], f32[], f32[4096]{0}, f32[4096]{0}, /*index=35*/f32[]) %fusion.329), index=17
  %get-tuple-element.5583 = f32[1]{0} get-tuple-element((f32[1]{0}, f32[1]{0}, f32[1]{0}, f32[1]{0}, f32[1]{0}, /*index=5*/f32[1]{0}, f32[1]{0}, f32[1]{0}, f32[1]{0}) %fusion.769), index=5
  %bitcast.1037 = f32[] bitcast(f32[1]{0} %get-tuple-element.5583), metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %get-tuple-element.5217 = f32[] get-tuple-element((f32[], f32[], f32[], f32[], f32[], /*index=5*/f32[], f32[], f32[], f32[], f32[], /*index=10*/f32[], f32[], f32[], f32[], f32[], /*index=15*/f32[], f32[], f32[], f32[], f32[], /*index=20*/f32[], f32[], f32[], f32[], f32[], /*index=25*/f32[], f32[], f32[], f32[], f32[], /*index=30*/f32[]) %fusion.313), index=19
  %get-tuple-element.5427 = f32[4096]{0} get-tuple-element((f32[], f32[4096]{0}, f32[4096]{0}, f32[], f32[], /*index=5*/f32[4096]{0}, f32[4096]{0}, f32[], f32[], f32[4096]{0}, /*index=10*/f32[4096]{0}, f32[], f32[], f32[4096]{0}, f32[4096]{0}, /*index=15*/f32[], f32[], f32[4096]{0}, f32[4096]{0}, f32[], /*index=20*/f32[], f32[4096]{0}, f32[4096]{0}, f32[], f32[], /*index=25*/f32[4096]{0}, f32[4096]{0}, f32[], f32[], f32[4096]{0}, /*index=30*/f32[4096]{0}, f32[], f32[], f32[4096]{0}, f32[4096]{0}, /*index=35*/f32[]) %fusion.329), index=21
  %get-tuple-element.5584 = f32[1]{0} get-tuple-element((f32[1]{0}, f32[1]{0}, f32[1]{0}, f32[1]{0}, f32[1]{0}, /*index=5*/f32[1]{0}, f32[1]{0}, f32[1]{0}, f32[1]{0}) %fusion.769), index=6
  %bitcast.1038 = f32[] bitcast(f32[1]{0} %get-tuple-element.5584), metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %get-tuple-element.5236 = f32[] get-tuple-element((f32[], f32[], f32[], f32[], f32[], /*index=5*/f32[], f32[], f32[], f32[], f32[], /*index=10*/f32[], f32[], f32[], f32[], f32[], /*index=15*/f32[], f32[], f32[], f32[], f32[], /*index=20*/f32[], f32[], f32[], f32[], f32[], /*index=25*/f32[], f32[], f32[], f32[], f32[], /*index=30*/f32[]) %fusion.313), index=22
  %get-tuple-element.5431 = f32[4096]{0} get-tuple-element((f32[], f32[4096]{0}, f32[4096]{0}, f32[], f32[], /*index=5*/f32[4096]{0}, f32[4096]{0}, f32[], f32[], f32[4096]{0}, /*index=10*/f32[4096]{0}, f32[], f32[], f32[4096]{0}, f32[4096]{0}, /*index=15*/f32[], f32[], f32[4096]{0}, f32[4096]{0}, f32[], /*index=20*/f32[], f32[4096]{0}, f32[4096]{0}, f32[], f32[], /*index=25*/f32[4096]{0}, f32[4096]{0}, f32[], f32[], f32[4096]{0}, /*index=30*/f32[4096]{0}, f32[], f32[], f32[4096]{0}, f32[4096]{0}, /*index=35*/f32[]) %fusion.329), index=25
  %get-tuple-element.5585 = f32[1]{0} get-tuple-element((f32[1]{0}, f32[1]{0}, f32[1]{0}, f32[1]{0}, f32[1]{0}, /*index=5*/f32[1]{0}, f32[1]{0}, f32[1]{0}, f32[1]{0}) %fusion.769), index=7
  %bitcast.1039 = f32[] bitcast(f32[1]{0} %get-tuple-element.5585), metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %get-tuple-element.5248 = f32[] get-tuple-element((f32[], f32[], f32[], f32[], f32[], /*index=5*/f32[], f32[], f32[], f32[], f32[], /*index=10*/f32[], f32[], f32[], f32[], f32[], /*index=15*/f32[], f32[], f32[], f32[], f32[], /*index=20*/f32[], f32[], f32[], f32[], f32[], /*index=25*/f32[], f32[], f32[], f32[], f32[], /*index=30*/f32[]) %fusion.313), index=24
  %get-tuple-element.5437 = f32[4096]{0} get-tuple-element((f32[], f32[4096]{0}, f32[4096]{0}, f32[], f32[], /*index=5*/f32[4096]{0}, f32[4096]{0}, f32[], f32[], f32[4096]{0}, /*index=10*/f32[4096]{0}, f32[], f32[], f32[4096]{0}, f32[4096]{0}, /*index=15*/f32[], f32[], f32[4096]{0}, f32[4096]{0}, f32[], /*index=20*/f32[], f32[4096]{0}, f32[4096]{0}, f32[], f32[], /*index=25*/f32[4096]{0}, f32[4096]{0}, f32[], f32[], f32[4096]{0}, /*index=30*/f32[4096]{0}, f32[], f32[], f32[4096]{0}, f32[4096]{0}, /*index=35*/f32[]) %fusion.329), index=29
  %get-tuple-element.5586 = f32[1]{0} get-tuple-element((f32[1]{0}, f32[1]{0}, f32[1]{0}, f32[1]{0}, f32[1]{0}, /*index=5*/f32[1]{0}, f32[1]{0}, f32[1]{0}, f32[1]{0}) %fusion.769), index=8
  %bitcast.1040 = f32[] bitcast(f32[1]{0} %get-tuple-element.5586), metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %get-tuple-element.5260 = f32[] get-tuple-element((f32[], f32[], f32[], f32[], f32[], /*index=5*/f32[], f32[], f32[], f32[], f32[], /*index=10*/f32[], f32[], f32[], f32[], f32[], /*index=15*/f32[], f32[], f32[], f32[], f32[], /*index=20*/f32[], f32[], f32[], f32[], f32[], /*index=25*/f32[], f32[], f32[], f32[], f32[], /*index=30*/f32[]) %fusion.313), index=26
  %fusion.562 = (f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, /*index=5*/f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}) fusion(f32[4096]{0} %get-tuple-element.5441, f32[] %bitcast.1032, f32[] %parameter.160, f32[] %parameter.164, f32[] %get-tuple-element.5272, /*index=5*/f32[] %parameter.163, f32[4096]{0} %parameter.84, f32[] %get-tuple-element.5535, f32[4096]{0} %get-tuple-element.5123, f32[] %bitcast.1033, /*index=10*/f32[] %get-tuple-element.5121, f32[4096]{0} %parameter.109, f32[4096]{0} %get-tuple-element.5330, f32[] %bitcast.1034, f32[] %get-tuple-element.5133, /*index=15*/f32[4096]{0} %parameter.107, f32[4096]{0} %get-tuple-element.5356, f32[] %bitcast.1035, f32[] %get-tuple-element.5145, f32[4096]{0} %parameter.105, /*index=20*/f32[4096]{0} %get-tuple-element.5419, f32[] %bitcast.1036, f32[] %get-tuple-element.5157, f32[4096]{0} %parameter.103, f32[4096]{0} %get-tuple-element.5423, /*index=25*/f32[] %bitcast.1037, f32[] %get-tuple-element.5217, f32[4096]{0} %parameter.93, f32[4096]{0} %get-tuple-element.5427, f32[] %bitcast.1038, /*index=30*/f32[] %get-tuple-element.5236, f32[4096]{0} %parameter.90, f32[4096]{0} %get-tuple-element.5431, f32[] %bitcast.1039, f32[] %get-tuple-element.5248, /*index=35*/f32[4096]{0} %parameter.88, f32[4096]{0} %get-tuple-element.5437, f32[] %bitcast.1040, f32[] %get-tuple-element.5260, f32[4096]{0} %parameter.86), kind=kLoop, calls=%fused_computation.562, metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  %get-tuple-element.5292 = f32[4096]{0} get-tuple-element((f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, /*index=5*/f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}) %fusion.562), index=0
  %get-tuple-element.5326 = f32[4096]{0} get-tuple-element((f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, /*index=5*/f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, /*index=10*/f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, /*index=15*/f32[4096]{0}, f32[4096]{0}, f32[4096]{0}) %fusion.573), index=16
  %get-tuple-element.5484 = f32[2048]{0} get-tuple-element((f32[2048]{0}, f32[2048]{0}, f32[2048]{0}, f32[2048]{0}, f32[2048]{0}, /*index=5*/f32[2048]{0}, f32[2048]{0}, f32[2048]{0}, f32[2048]{0}) %fusion.576), index=8
  %fusion.305 = (f32[], f32[]) fusion(f32[2048,4096]{1,0} %all-reduce.12523, f32[4096]{0} %get-tuple-element.5326, f32[2048]{0} %get-tuple-element.5484), kind=kInput, calls=%fused_computation.305, metadata={op_type="dot_general" op_name="pmap(_multi_device_update_fn)/dot_general[ dimension_numbers=(((0,), (0,)), ((), ()))\n                                           precision=None\n                                           preferred_element_type=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %get-tuple-element.5271 = f32[] get-tuple-element((f32[], f32[]) %fusion.305), index=1
  %fusion.552 = f32[] fusion(f32[] %get-tuple-element.5271), kind=kLoop, calls=%fused_computation.552, metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %get-tuple-element.5265 = f32[] get-tuple-element((f32[], f32[], f32[], f32[], f32[], /*index=5*/f32[], f32[], f32[], f32[], f32[], /*index=10*/f32[], f32[], f32[], f32[], f32[], /*index=15*/f32[], f32[], f32[], f32[], f32[], /*index=20*/f32[], f32[], f32[], f32[], f32[], /*index=25*/f32[], f32[], f32[], f32[], f32[], /*index=30*/f32[]) %fusion.313), index=27
  %fusion.551 = f32[2048,4096]{1,0} fusion(f32[] %fusion.552, f32[] %parameter.160, f32[] %parameter.164, f32[] %get-tuple-element.5265, f32[] %parameter.163, /*index=5*/f32[2048,4096]{1,0} %parameter.85, f32[] %get-tuple-element.5535, f32[4096]{0} %get-tuple-element.5326, f32[2048,4096]{1,0} %all-reduce.12523, f32[2048]{0} %get-tuple-element.5484), kind=kLoop, calls=%fused_computation.551, metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  %get-tuple-element.5300 = f32[4096]{0} get-tuple-element((f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, /*index=5*/f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}) %fusion.562), index=8
  %get-tuple-element.5291 = f32[2048,4096]{1,0} get-tuple-element((f32[2048,4096]{1,0}, f32[2048,4096]{1,0}, f32[2048,4096]{1,0}, f32[2048,4096]{1,0}, f32[2048,4096]{1,0}, /*index=5*/f32[2048,4096]{1,0}, f32[2048,4096]{1,0}, f32[2048,4096]{1,0}) %fusion.569), index=7
  %get-tuple-element.5299 = f32[4096]{0} get-tuple-element((f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, /*index=5*/f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}) %fusion.562), index=7
  %get-tuple-element.5290 = f32[2048,4096]{1,0} get-tuple-element((f32[2048,4096]{1,0}, f32[2048,4096]{1,0}, f32[2048,4096]{1,0}, f32[2048,4096]{1,0}, f32[2048,4096]{1,0}, /*index=5*/f32[2048,4096]{1,0}, f32[2048,4096]{1,0}, f32[2048,4096]{1,0}) %fusion.569), index=6
  %get-tuple-element.5298 = f32[4096]{0} get-tuple-element((f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, /*index=5*/f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}) %fusion.562), index=6
  %get-tuple-element.5464 = f32[1024]{0} get-tuple-element((f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, /*index=5*/f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, /*index=10*/f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, /*index=15*/f32[1024]{0}, f32[1024]{0}) %fusion.411), index=8
  %fusion.739 = f32[256]{0} fusion(f32[1024,256]{1,0} %get-tuple-element.5694), kind=kInput, calls=%fused_computation.739, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
  %parameter.156 = f32[256]{0} parameter(74), parameter_replication={false}
  %fusion.718 = f32[256]{0} fusion(f32[256,1024]{1,0} %get-tuple-element.5693), kind=kInput, calls=%fused_computation.718, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(1,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=131}
  %parameter.126 = f32[256]{0} parameter(44), parameter_replication={false}
  %get-tuple-element.5708 = f32[256]{0} get-tuple-element((f32[1024,1024]{1,0}, f32[1024,1024]{1,0}, f32[1024,1024]{1,0}, f32[1024,1024]{1,0}, f32[256,1024]{1,0}, /*index=5*/f32[1024,256]{1,0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, /*index=10*/f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, /*index=15*/f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[256]{0}) %all-reduce), index=19, metadata={op_type="psum" op_name="pmap(_multi_device_update_fn)/psum[ axes=(\'batch\',)\n                                    axis_index_groups=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=347}
  %parameter.157 = f32[256]{0} parameter(75), parameter_replication={false}
  %fusion.759 = (f32[], f32[256]{0}, f32[], f32[256]{0}, f32[256]{0}, /*index=5*/f32[]) fusion(f32[256]{0} %fusion.718, f32[] %get-tuple-element.5534, f32[256]{0} %parameter.126, f32[256]{0} %get-tuple-element.5708, f32[] %parameter.162, /*index=5*/f32[256]{0} %parameter.157), kind=kInput, calls=%fused_computation.759, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=135}
  %get-tuple-element.5231 = f32[256]{0} get-tuple-element((f32[], f32[256]{0}, f32[], f32[256]{0}, f32[256]{0}, /*index=5*/f32[]) %fusion.759), index=1
  %get-tuple-element.5230 = f32[] get-tuple-element((f32[], f32[256]{0}, f32[], f32[256]{0}, f32[256]{0}, /*index=5*/f32[]) %fusion.759), index=0
  %fusion.319 = (f32[256]{0}, f32[256]{0}, f32[256]{0}) fusion(f32[] %parameter.162, f32[256]{0} %fusion.739, f32[] %get-tuple-element.5534, f32[256]{0} %parameter.156, f32[256]{0} %get-tuple-element.5231, /*index=5*/f32[] %get-tuple-element.5230), kind=kLoop, calls=%fused_computation.319, metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
  %get-tuple-element.5328 = f32[256]{0} get-tuple-element((f32[256]{0}, f32[256]{0}, f32[256]{0}) %fusion.319), index=2
  %fusion.302 = (f32[], f32[]) fusion(f32[256,1024]{1,0} %get-tuple-element.5693, f32[1024]{0} %get-tuple-element.5464, f32[256]{0} %get-tuple-element.5328), kind=kInput, calls=%fused_computation.302, metadata={op_type="dot_general" op_name="pmap(_multi_device_update_fn)/dot_general[ dimension_numbers=(((0,), (0,)), ((), ()))\n                                           precision=None\n                                           preferred_element_type=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %get-tuple-element.5235 = f32[] get-tuple-element((f32[], f32[]) %fusion.302), index=1
  %fusion.495 = f32[] fusion(f32[] %get-tuple-element.5235), kind=kLoop, calls=%fused_computation.495, metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %get-tuple-element.5229 = f32[] get-tuple-element((f32[], f32[], f32[], f32[], f32[], /*index=5*/f32[], f32[], f32[], f32[], f32[], /*index=10*/f32[], f32[], f32[], f32[], f32[], /*index=15*/f32[], f32[], f32[], f32[], f32[], /*index=20*/f32[], f32[], f32[], f32[], f32[], /*index=25*/f32[], f32[], f32[], f32[], f32[], /*index=30*/f32[]) %fusion.313), index=21
  %fusion.494 = f32[256,1024]{1,0} fusion(f32[] %fusion.495, f32[] %parameter.160, f32[] %parameter.164, f32[] %get-tuple-element.5229, f32[] %parameter.163, /*index=5*/f32[256,1024]{1,0} %parameter.91, f32[] %get-tuple-element.5535, f32[1024]{0} %get-tuple-element.5464, f32[256,1024]{1,0} %get-tuple-element.5693, f32[256]{0} %get-tuple-element.5328), kind=kLoop, calls=%fused_computation.494, metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  %get-tuple-element.5289 = f32[2048,4096]{1,0} get-tuple-element((f32[2048,4096]{1,0}, f32[2048,4096]{1,0}, f32[2048,4096]{1,0}, f32[2048,4096]{1,0}, f32[2048,4096]{1,0}, /*index=5*/f32[2048,4096]{1,0}, f32[2048,4096]{1,0}, f32[2048,4096]{1,0}) %fusion.569), index=5
  %get-tuple-element.5297 = f32[4096]{0} get-tuple-element((f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, /*index=5*/f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}) %fusion.562), index=5
  %get-tuple-element.5462 = f32[1024]{0} get-tuple-element((f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, /*index=5*/f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, /*index=10*/f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, /*index=15*/f32[1024]{0}, f32[1024]{0}) %fusion.411), index=6
  %get-tuple-element.5473 = f32[1024]{0} get-tuple-element((f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, /*index=5*/f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, /*index=10*/f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, /*index=15*/f32[1024]{0}, f32[1024]{0}) %fusion.411), index=15
  %fusion.300 = (f32[], f32[]) fusion(f32[1024,1024]{1,0} %get-tuple-element.5692, f32[1024]{0} %get-tuple-element.5462, f32[1024]{0} %get-tuple-element.5473), kind=kInput, calls=%fused_computation.300, metadata={op_type="dot_general" op_name="pmap(_multi_device_update_fn)/dot_general[ dimension_numbers=(((0,), (0,)), ((), ()))\n                                           precision=None\n                                           preferred_element_type=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %get-tuple-element.5216 = f32[] get-tuple-element((f32[], f32[]) %fusion.300), index=1
  %get-tuple-element.5177 = f32[1024]{0} get-tuple-element((f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, /*index=5*/f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, /*index=10*/f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, /*index=15*/f32[1024]{0}, f32[1024]{0}) %fusion.411), index=0
  %get-tuple-element.5468 = f32[1024]{0} get-tuple-element((f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, /*index=5*/f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, /*index=10*/f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, /*index=15*/f32[1024]{0}, f32[1024]{0}) %fusion.411), index=12
  %fusion.297 = (f32[], f32[]) fusion(f32[1024,1024]{1,0} %get-tuple-element.5689, f32[1024]{0} %get-tuple-element.5177, f32[1024]{0} %get-tuple-element.5468), kind=kInput, calls=%fused_computation.297, metadata={op_type="dot_general" op_name="pmap(_multi_device_update_fn)/dot_general[ dimension_numbers=(((0,), (0,)), ((), ()))\n                                           precision=None\n                                           preferred_element_type=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %get-tuple-element.5180 = f32[] get-tuple-element((f32[], f32[]) %fusion.297), index=1
  %get-tuple-element.5458 = f32[1024]{0} get-tuple-element((f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, /*index=5*/f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, /*index=10*/f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, /*index=15*/f32[1024]{0}, f32[1024]{0}) %fusion.411), index=2
  %get-tuple-element.5469 = f32[1024]{0} get-tuple-element((f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, /*index=5*/f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, /*index=10*/f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, /*index=15*/f32[1024]{0}, f32[1024]{0}) %fusion.411), index=13
  %fusion.298 = (f32[], f32[]) fusion(f32[1024,1024]{1,0} %get-tuple-element.5690, f32[1024]{0} %get-tuple-element.5458, f32[1024]{0} %get-tuple-element.5469), kind=kInput, calls=%fused_computation.298, metadata={op_type="dot_general" op_name="pmap(_multi_device_update_fn)/dot_general[ dimension_numbers=(((0,), (0,)), ((), ()))\n                                           precision=None\n                                           preferred_element_type=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %get-tuple-element.5192 = f32[] get-tuple-element((f32[], f32[]) %fusion.298), index=1
  %get-tuple-element.5460 = f32[1024]{0} get-tuple-element((f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, /*index=5*/f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, /*index=10*/f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, /*index=15*/f32[1024]{0}, f32[1024]{0}) %fusion.411), index=4
  %get-tuple-element.5472 = f32[1024]{0} get-tuple-element((f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, /*index=5*/f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, /*index=10*/f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, /*index=15*/f32[1024]{0}, f32[1024]{0}) %fusion.411), index=14
  %fusion.299 = (f32[], f32[]) fusion(f32[1024,1024]{1,0} %get-tuple-element.5691, f32[1024]{0} %get-tuple-element.5460, f32[1024]{0} %get-tuple-element.5472), kind=kInput, calls=%fused_computation.299, metadata={op_type="dot_general" op_name="pmap(_multi_device_update_fn)/dot_general[ dimension_numbers=(((0,), (0,)), ((), ()))\n                                           precision=None\n                                           preferred_element_type=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %get-tuple-element.5204 = f32[] get-tuple-element((f32[], f32[]) %fusion.299), index=1
  %fusion.768 = (f32[1]{0}, f32[1]{0}, f32[1]{0}, f32[1]{0}) fusion(f32[] %get-tuple-element.5216, f32[] %get-tuple-element.5180, f32[] %get-tuple-element.5192, f32[] %get-tuple-element.5204), kind=kInput, calls=%horizontally_fused_computation.1
  %get-tuple-element.5574 = f32[1]{0} get-tuple-element((f32[1]{0}, f32[1]{0}, f32[1]{0}, f32[1]{0}) %fusion.768), index=0
  %bitcast.1028 = f32[] bitcast(f32[1]{0} %get-tuple-element.5574), metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %get-tuple-element.5210 = f32[] get-tuple-element((f32[], f32[], f32[], f32[], f32[], /*index=5*/f32[], f32[], f32[], f32[], f32[], /*index=10*/f32[], f32[], f32[], f32[], f32[], /*index=15*/f32[], f32[], f32[], f32[], f32[], /*index=20*/f32[], f32[], f32[], f32[], f32[], /*index=25*/f32[], f32[], f32[], f32[], f32[], /*index=30*/f32[]) %fusion.313), index=18
  %get-tuple-element.5575 = f32[1]{0} get-tuple-element((f32[1]{0}, f32[1]{0}, f32[1]{0}, f32[1]{0}) %fusion.768), index=1
  %bitcast.1029 = f32[] bitcast(f32[1]{0} %get-tuple-element.5575), metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %get-tuple-element.5174 = f32[] get-tuple-element((f32[], f32[], f32[], f32[], f32[], /*index=5*/f32[], f32[], f32[], f32[], f32[], /*index=10*/f32[], f32[], f32[], f32[], f32[], /*index=15*/f32[], f32[], f32[], f32[], f32[], /*index=20*/f32[], f32[], f32[], f32[], f32[], /*index=25*/f32[], f32[], f32[], f32[], f32[], /*index=30*/f32[]) %fusion.313), index=12
  %get-tuple-element.5576 = f32[1]{0} get-tuple-element((f32[1]{0}, f32[1]{0}, f32[1]{0}, f32[1]{0}) %fusion.768), index=2
  %bitcast.1030 = f32[] bitcast(f32[1]{0} %get-tuple-element.5576), metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %get-tuple-element.5186 = f32[] get-tuple-element((f32[], f32[], f32[], f32[], f32[], /*index=5*/f32[], f32[], f32[], f32[], f32[], /*index=10*/f32[], f32[], f32[], f32[], f32[], /*index=15*/f32[], f32[], f32[], f32[], f32[], /*index=20*/f32[], f32[], f32[], f32[], f32[], /*index=25*/f32[], f32[], f32[], f32[], f32[], /*index=30*/f32[]) %fusion.313), index=14
  %get-tuple-element.5577 = f32[1]{0} get-tuple-element((f32[1]{0}, f32[1]{0}, f32[1]{0}, f32[1]{0}) %fusion.768), index=3
  %bitcast.1031 = f32[] bitcast(f32[1]{0} %get-tuple-element.5577), metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %get-tuple-element.5198 = f32[] get-tuple-element((f32[], f32[], f32[], f32[], f32[], /*index=5*/f32[], f32[], f32[], f32[], f32[], /*index=10*/f32[], f32[], f32[], f32[], f32[], /*index=15*/f32[], f32[], f32[], f32[], f32[], /*index=20*/f32[], f32[], f32[], f32[], f32[], /*index=25*/f32[], f32[], f32[], f32[], f32[], /*index=30*/f32[]) %fusion.313), index=16
  %fusion.464 = (f32[1024,1024]{1,0}, f32[1024,1024]{1,0}, f32[1024,1024]{1,0}, f32[1024,1024]{1,0}) fusion(f32[] %bitcast.1028, f32[] %parameter.160, f32[] %parameter.164, f32[] %get-tuple-element.5210, f32[] %parameter.163, /*index=5*/f32[1024,1024]{1,0} %parameter.94, f32[] %get-tuple-element.5535, f32[1024]{0} %get-tuple-element.5462, f32[1024,1024]{1,0} %get-tuple-element.5692, f32[1024]{0} %get-tuple-element.5473, /*index=10*/f32[] %bitcast.1029, f32[1024]{0} %get-tuple-element.5177, f32[1024,1024]{1,0} %get-tuple-element.5689, f32[1024]{0} %get-tuple-element.5468, f32[] %get-tuple-element.5174, /*index=15*/f32[1024,1024]{1,0} %parameter.100, f32[] %bitcast.1030, f32[1024]{0} %get-tuple-element.5458, f32[1024,1024]{1,0} %get-tuple-element.5690, f32[1024]{0} %get-tuple-element.5469, /*index=20*/f32[] %get-tuple-element.5186, f32[1024,1024]{1,0} %parameter.98, f32[] %bitcast.1031, f32[1024]{0} %get-tuple-element.5460, f32[1024,1024]{1,0} %get-tuple-element.5691, /*index=25*/f32[1024]{0} %get-tuple-element.5472, f32[] %get-tuple-element.5198, f32[1024,1024]{1,0} %parameter.96), kind=kLoop, calls=%fused_computation.464, metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  %get-tuple-element.5301 = f32[1024,1024]{1,0} get-tuple-element((f32[1024,1024]{1,0}, f32[1024,1024]{1,0}, f32[1024,1024]{1,0}, f32[1024,1024]{1,0}) %fusion.464), index=0
  %get-tuple-element.5509 = f32[1024]{0} get-tuple-element((f32[], f32[1024]{0}, f32[], f32[1024]{0}, f32[], /*index=5*/f32[1024]{0}, f32[], f32[1024]{0}, f32[], f32[1024]{0}, /*index=10*/f32[], f32[1024]{0}, f32[1024]{0}, f32[], f32[], /*index=15*/f32[1024]{0}, f32[1024]{0}, f32[], f32[], f32[1024]{0}, /*index=20*/f32[1024]{0}, f32[], f32[], f32[1024]{0}, f32[1024]{0}, /*index=25*/f32[]) %fusion.756), index=23
  %get-tuple-element.5508 = f32[] get-tuple-element((f32[], f32[1024]{0}, f32[], f32[1024]{0}, f32[], /*index=5*/f32[1024]{0}, f32[], f32[1024]{0}, f32[], f32[1024]{0}, /*index=10*/f32[], f32[1024]{0}, f32[1024]{0}, f32[], f32[], /*index=15*/f32[1024]{0}, f32[1024]{0}, f32[], f32[], f32[1024]{0}, /*index=20*/f32[1024]{0}, f32[], f32[], f32[1024]{0}, f32[1024]{0}, /*index=25*/f32[]) %fusion.756), index=22
  %get-tuple-element.5494 = f32[] get-tuple-element((f32[], f32[1024]{0}, f32[], f32[1024]{0}, f32[], /*index=5*/f32[1024]{0}, f32[], f32[1024]{0}, f32[], f32[1024]{0}, /*index=10*/f32[], f32[1024]{0}, f32[1024]{0}, f32[], f32[], /*index=15*/f32[1024]{0}, f32[1024]{0}, f32[], f32[], f32[1024]{0}, /*index=20*/f32[1024]{0}, f32[], f32[], f32[1024]{0}, f32[1024]{0}, /*index=25*/f32[]) %fusion.756), index=10
  %get-tuple-element.5498 = f32[] get-tuple-element((f32[], f32[1024]{0}, f32[], f32[1024]{0}, f32[], /*index=5*/f32[1024]{0}, f32[], f32[1024]{0}, f32[], f32[1024]{0}, /*index=10*/f32[], f32[1024]{0}, f32[1024]{0}, f32[], f32[], /*index=15*/f32[1024]{0}, f32[1024]{0}, f32[], f32[], f32[1024]{0}, /*index=20*/f32[1024]{0}, f32[], f32[], f32[1024]{0}, f32[1024]{0}, /*index=25*/f32[]) %fusion.756), index=14
  %get-tuple-element.5502 = f32[] get-tuple-element((f32[], f32[1024]{0}, f32[], f32[1024]{0}, f32[], /*index=5*/f32[1024]{0}, f32[], f32[1024]{0}, f32[], f32[1024]{0}, /*index=10*/f32[], f32[1024]{0}, f32[1024]{0}, f32[], f32[], /*index=15*/f32[1024]{0}, f32[1024]{0}, f32[], f32[], f32[1024]{0}, /*index=20*/f32[1024]{0}, f32[], f32[], f32[1024]{0}, f32[1024]{0}, /*index=25*/f32[]) %fusion.756), index=18
  %fusion.767 = (f32[1]{0}, f32[1]{0}, f32[1]{0}, f32[1]{0}) fusion(f32[] %get-tuple-element.5508, f32[] %get-tuple-element.5494, f32[] %get-tuple-element.5498, f32[] %get-tuple-element.5502), kind=kInput, calls=%horizontally_fused_computation
  %get-tuple-element.5570 = f32[1]{0} get-tuple-element((f32[1]{0}, f32[1]{0}, f32[1]{0}, f32[1]{0}) %fusion.767), index=0
  %bitcast.1024 = f32[] bitcast(f32[1]{0} %get-tuple-element.5570), metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %get-tuple-element.5205 = f32[] get-tuple-element((f32[], f32[], f32[], f32[], f32[], /*index=5*/f32[], f32[], f32[], f32[], f32[], /*index=10*/f32[], f32[], f32[], f32[], f32[], /*index=15*/f32[], f32[], f32[], f32[], f32[], /*index=20*/f32[], f32[], f32[], f32[], f32[], /*index=25*/f32[], f32[], f32[], f32[], f32[], /*index=30*/f32[]) %fusion.313), index=17
  %get-tuple-element.5495 = f32[1024]{0} get-tuple-element((f32[], f32[1024]{0}, f32[], f32[1024]{0}, f32[], /*index=5*/f32[1024]{0}, f32[], f32[1024]{0}, f32[], f32[1024]{0}, /*index=10*/f32[], f32[1024]{0}, f32[1024]{0}, f32[], f32[], /*index=15*/f32[1024]{0}, f32[1024]{0}, f32[], f32[], f32[1024]{0}, /*index=20*/f32[1024]{0}, f32[], f32[], f32[1024]{0}, f32[1024]{0}, /*index=25*/f32[]) %fusion.756), index=11
  %get-tuple-element.5571 = f32[1]{0} get-tuple-element((f32[1]{0}, f32[1]{0}, f32[1]{0}, f32[1]{0}) %fusion.767), index=1
  %bitcast.1025 = f32[] bitcast(f32[1]{0} %get-tuple-element.5571), metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %get-tuple-element.5169 = f32[] get-tuple-element((f32[], f32[], f32[], f32[], f32[], /*index=5*/f32[], f32[], f32[], f32[], f32[], /*index=10*/f32[], f32[], f32[], f32[], f32[], /*index=15*/f32[], f32[], f32[], f32[], f32[], /*index=20*/f32[], f32[], f32[], f32[], f32[], /*index=25*/f32[], f32[], f32[], f32[], f32[], /*index=30*/f32[]) %fusion.313), index=11
  %get-tuple-element.5499 = f32[1024]{0} get-tuple-element((f32[], f32[1024]{0}, f32[], f32[1024]{0}, f32[], /*index=5*/f32[1024]{0}, f32[], f32[1024]{0}, f32[], f32[1024]{0}, /*index=10*/f32[], f32[1024]{0}, f32[1024]{0}, f32[], f32[], /*index=15*/f32[1024]{0}, f32[1024]{0}, f32[], f32[], f32[1024]{0}, /*index=20*/f32[1024]{0}, f32[], f32[], f32[1024]{0}, f32[1024]{0}, /*index=25*/f32[]) %fusion.756), index=15
  %get-tuple-element.5572 = f32[1]{0} get-tuple-element((f32[1]{0}, f32[1]{0}, f32[1]{0}, f32[1]{0}) %fusion.767), index=2
  %bitcast.1026 = f32[] bitcast(f32[1]{0} %get-tuple-element.5572), metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %get-tuple-element.5181 = f32[] get-tuple-element((f32[], f32[], f32[], f32[], f32[], /*index=5*/f32[], f32[], f32[], f32[], f32[], /*index=10*/f32[], f32[], f32[], f32[], f32[], /*index=15*/f32[], f32[], f32[], f32[], f32[], /*index=20*/f32[], f32[], f32[], f32[], f32[], /*index=25*/f32[], f32[], f32[], f32[], f32[], /*index=30*/f32[]) %fusion.313), index=13
  %get-tuple-element.5505 = f32[1024]{0} get-tuple-element((f32[], f32[1024]{0}, f32[], f32[1024]{0}, f32[], /*index=5*/f32[1024]{0}, f32[], f32[1024]{0}, f32[], f32[1024]{0}, /*index=10*/f32[], f32[1024]{0}, f32[1024]{0}, f32[], f32[], /*index=15*/f32[1024]{0}, f32[1024]{0}, f32[], f32[], f32[1024]{0}, /*index=20*/f32[1024]{0}, f32[], f32[], f32[1024]{0}, f32[1024]{0}, /*index=25*/f32[]) %fusion.756), index=19
  %get-tuple-element.5573 = f32[1]{0} get-tuple-element((f32[1]{0}, f32[1]{0}, f32[1]{0}, f32[1]{0}) %fusion.767), index=3
  %bitcast.1027 = f32[] bitcast(f32[1]{0} %get-tuple-element.5573), metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %get-tuple-element.5193 = f32[] get-tuple-element((f32[], f32[], f32[], f32[], f32[], /*index=5*/f32[], f32[], f32[], f32[], f32[], /*index=10*/f32[], f32[], f32[], f32[], f32[], /*index=15*/f32[], f32[], f32[], f32[], f32[], /*index=20*/f32[], f32[], f32[], f32[], f32[], /*index=25*/f32[], f32[], f32[], f32[], f32[], /*index=30*/f32[]) %fusion.313), index=15
  %fusion.457 = (f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}) fusion(f32[1024]{0} %get-tuple-element.5509, f32[] %bitcast.1024, f32[] %parameter.160, f32[] %parameter.164, f32[] %get-tuple-element.5205, /*index=5*/f32[] %parameter.163, f32[1024]{0} %parameter.95, f32[] %get-tuple-element.5535, f32[1024]{0} %get-tuple-element.5495, f32[] %bitcast.1025, /*index=10*/f32[] %get-tuple-element.5169, f32[1024]{0} %parameter.101, f32[1024]{0} %get-tuple-element.5499, f32[] %bitcast.1026, f32[] %get-tuple-element.5181, /*index=15*/f32[1024]{0} %parameter.99, f32[1024]{0} %get-tuple-element.5505, f32[] %bitcast.1027, f32[] %get-tuple-element.5193, f32[1024]{0} %parameter.97), kind=kLoop, calls=%fused_computation.457, metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  %get-tuple-element.5305 = f32[1024]{0} get-tuple-element((f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}) %fusion.457), index=0
  %get-tuple-element.5304 = f32[1024,1024]{1,0} get-tuple-element((f32[1024,1024]{1,0}, f32[1024,1024]{1,0}, f32[1024,1024]{1,0}, f32[1024,1024]{1,0}) %fusion.464), index=3
  %get-tuple-element.5308 = f32[1024]{0} get-tuple-element((f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}) %fusion.457), index=3
  %get-tuple-element.5303 = f32[1024,1024]{1,0} get-tuple-element((f32[1024,1024]{1,0}, f32[1024,1024]{1,0}, f32[1024,1024]{1,0}, f32[1024,1024]{1,0}) %fusion.464), index=2
  %get-tuple-element.5307 = f32[1024]{0} get-tuple-element((f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}) %fusion.457), index=2
  %get-tuple-element.5302 = f32[1024,1024]{1,0} get-tuple-element((f32[1024,1024]{1,0}, f32[1024,1024]{1,0}, f32[1024,1024]{1,0}, f32[1024,1024]{1,0}) %fusion.464), index=1
  %get-tuple-element.5306 = f32[1024]{0} get-tuple-element((f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}) %fusion.457), index=1
  %get-tuple-element.5288 = f32[2048,4096]{1,0} get-tuple-element((f32[2048,4096]{1,0}, f32[2048,4096]{1,0}, f32[2048,4096]{1,0}, f32[2048,4096]{1,0}, f32[2048,4096]{1,0}, /*index=5*/f32[2048,4096]{1,0}, f32[2048,4096]{1,0}, f32[2048,4096]{1,0}) %fusion.569), index=4
  %get-tuple-element.5296 = f32[4096]{0} get-tuple-element((f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, /*index=5*/f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}) %fusion.562), index=4
  %get-tuple-element.5287 = f32[2048,4096]{1,0} get-tuple-element((f32[2048,4096]{1,0}, f32[2048,4096]{1,0}, f32[2048,4096]{1,0}, f32[2048,4096]{1,0}, f32[2048,4096]{1,0}, /*index=5*/f32[2048,4096]{1,0}, f32[2048,4096]{1,0}, f32[2048,4096]{1,0}) %fusion.569), index=3
  %get-tuple-element.5295 = f32[4096]{0} get-tuple-element((f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, /*index=5*/f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}) %fusion.562), index=3
  %get-tuple-element.5286 = f32[2048,4096]{1,0} get-tuple-element((f32[2048,4096]{1,0}, f32[2048,4096]{1,0}, f32[2048,4096]{1,0}, f32[2048,4096]{1,0}, f32[2048,4096]{1,0}, /*index=5*/f32[2048,4096]{1,0}, f32[2048,4096]{1,0}, f32[2048,4096]{1,0}) %fusion.569), index=2
  %get-tuple-element.5294 = f32[4096]{0} get-tuple-element((f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, /*index=5*/f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}) %fusion.562), index=2
  %get-tuple-element.5285 = f32[2048,4096]{1,0} get-tuple-element((f32[2048,4096]{1,0}, f32[2048,4096]{1,0}, f32[2048,4096]{1,0}, f32[2048,4096]{1,0}, f32[2048,4096]{1,0}, /*index=5*/f32[2048,4096]{1,0}, f32[2048,4096]{1,0}, f32[2048,4096]{1,0}) %fusion.569), index=1
  %get-tuple-element.5293 = f32[4096]{0} get-tuple-element((f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, /*index=5*/f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}) %fusion.562), index=1
  %get-tuple-element.5117 = f32[256]{0} get-tuple-element((f32[256]{0}, f32[256]{0}, f32[256]{0}) %fusion.319), index=0
  %get-tuple-element.5467 = f32[1024]{0} get-tuple-element((f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, /*index=5*/f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, /*index=10*/f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, /*index=15*/f32[1024]{0}, f32[1024]{0}) %fusion.411), index=11
  %fusion.292 = (f32[], f32[]) fusion(f32[1024,256]{1,0} %get-tuple-element.5694, f32[256]{0} %get-tuple-element.5117, f32[1024]{0} %get-tuple-element.5467), kind=kInput, calls=%fused_computation.292, metadata={op_type="dot_general" op_name="pmap(_multi_device_update_fn)/dot_general[ dimension_numbers=(((0,), (0,)), ((), ()))\n                                           precision=None\n                                           preferred_element_type=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %get-tuple-element.5120 = f32[] get-tuple-element((f32[], f32[]) %fusion.292), index=1
  %fusion.316 = f32[] fusion(f32[] %get-tuple-element.5120), kind=kLoop, calls=%fused_computation.316, metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %get-tuple-element.5114 = f32[] get-tuple-element((f32[], f32[], f32[], f32[], f32[], /*index=5*/f32[], f32[], f32[], f32[], f32[], /*index=10*/f32[], f32[], f32[], f32[], f32[], /*index=15*/f32[], f32[], f32[], f32[], f32[], /*index=20*/f32[], f32[], f32[], f32[], f32[], /*index=25*/f32[], f32[], f32[], f32[], f32[], /*index=30*/f32[]) %fusion.313), index=2
  %fusion.315 = f32[1024,256]{1,0} fusion(f32[] %fusion.316, f32[] %parameter.160, f32[] %parameter.164, f32[] %get-tuple-element.5114, f32[] %parameter.163, /*index=5*/f32[1024,256]{1,0} %parameter.110, f32[] %get-tuple-element.5535, f32[256]{0} %get-tuple-element.5117, f32[1024,256]{1,0} %get-tuple-element.5694, f32[1024]{0} %get-tuple-element.5467), kind=kLoop, calls=%fused_computation.315, metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  %get-tuple-element.5531 = f32[256]{0} get-tuple-element((f32[], f32[256]{0}, f32[], f32[256]{0}, f32[256]{0}, /*index=5*/f32[]) %fusion.759), index=3
  %get-tuple-element.5530 = f32[] get-tuple-element((f32[], f32[256]{0}, f32[], f32[256]{0}, f32[256]{0}, /*index=5*/f32[]) %fusion.759), index=2
  %fusion.309 = f32[] fusion(f32[] %get-tuple-element.5530), kind=kLoop, calls=%fused_computation.309, metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %get-tuple-element.5108 = f32[] get-tuple-element((f32[], f32[], f32[], f32[], f32[], /*index=5*/f32[], f32[], f32[], f32[], f32[], /*index=10*/f32[], f32[], f32[], f32[], f32[], /*index=15*/f32[], f32[], f32[], f32[], f32[], /*index=20*/f32[], f32[], f32[], f32[], f32[], /*index=25*/f32[], f32[], f32[], f32[], f32[], /*index=30*/f32[]) %fusion.313), index=0
  %fusion.308 = f32[256]{0} fusion(f32[256]{0} %get-tuple-element.5531, f32[] %fusion.309, f32[] %parameter.160, f32[] %parameter.164, f32[] %get-tuple-element.5108, /*index=5*/f32[] %parameter.163, f32[256]{0} %parameter.111, f32[] %get-tuple-element.5535), kind=kLoop, calls=%fused_computation.308, metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  %copy.818 = f32[32000]{0} copy(f32[32000]{0} %get-tuple-element.5311)
  %get-tuple-element.5485 = f32[1024]{0} get-tuple-element((f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, /*index=5*/f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, /*index=10*/f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, /*index=15*/f32[1024]{0}, f32[1024]{0}) %fusion.411), index=16
  %copy.820 = f32[2048]{0} copy(f32[2048]{0} %get-tuple-element.5279)
  %get-tuple-element.5281 = f32[4096]{0} get-tuple-element((f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, /*index=5*/f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, /*index=10*/f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, /*index=15*/f32[4096]{0}, f32[4096]{0}, f32[4096]{0}) %fusion.573), index=1
  %get-tuple-element.5442 = f32[4096]{0} get-tuple-element((f32[], f32[4096]{0}, f32[4096]{0}, f32[], f32[], /*index=5*/f32[4096]{0}, f32[4096]{0}, f32[], f32[], f32[4096]{0}, /*index=10*/f32[4096]{0}, f32[], f32[], f32[4096]{0}, f32[4096]{0}, /*index=15*/f32[], f32[], f32[4096]{0}, f32[4096]{0}, f32[], /*index=20*/f32[], f32[4096]{0}, f32[4096]{0}, f32[], f32[], /*index=25*/f32[4096]{0}, f32[4096]{0}, f32[], f32[], f32[4096]{0}, /*index=30*/f32[4096]{0}, f32[], f32[], f32[4096]{0}, f32[4096]{0}, /*index=35*/f32[]) %fusion.329), index=34
  %copy.822 = f32[4096]{0} copy(f32[4096]{0} %get-tuple-element.5442)
  %copy.823 = f32[2048]{0} copy(f32[2048]{0} %get-tuple-element.5517)
  %get-tuple-element.5327 = f32[4096]{0} get-tuple-element((f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, /*index=5*/f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, /*index=10*/f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, /*index=15*/f32[4096]{0}, f32[4096]{0}, f32[4096]{0}) %fusion.573), index=17
  %get-tuple-element.5438 = f32[4096]{0} get-tuple-element((f32[], f32[4096]{0}, f32[4096]{0}, f32[], f32[], /*index=5*/f32[4096]{0}, f32[4096]{0}, f32[], f32[], f32[4096]{0}, /*index=10*/f32[4096]{0}, f32[], f32[], f32[4096]{0}, f32[4096]{0}, /*index=15*/f32[], f32[], f32[4096]{0}, f32[4096]{0}, f32[], /*index=20*/f32[], f32[4096]{0}, f32[4096]{0}, f32[], f32[], /*index=25*/f32[4096]{0}, f32[4096]{0}, f32[], f32[], f32[4096]{0}, /*index=30*/f32[4096]{0}, f32[], f32[], f32[4096]{0}, f32[4096]{0}, /*index=35*/f32[]) %fusion.329), index=30
  %copy.825 = f32[4096]{0} copy(f32[4096]{0} %get-tuple-element.5438)
  %copy.826 = f32[2048]{0} copy(f32[2048]{0} %get-tuple-element.5529)
  %get-tuple-element.5325 = f32[4096]{0} get-tuple-element((f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, /*index=5*/f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, /*index=10*/f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, /*index=15*/f32[4096]{0}, f32[4096]{0}, f32[4096]{0}) %fusion.573), index=15
  %get-tuple-element.5432 = f32[4096]{0} get-tuple-element((f32[], f32[4096]{0}, f32[4096]{0}, f32[], f32[], /*index=5*/f32[4096]{0}, f32[4096]{0}, f32[], f32[], f32[4096]{0}, /*index=10*/f32[4096]{0}, f32[], f32[], f32[4096]{0}, f32[4096]{0}, /*index=15*/f32[], f32[], f32[4096]{0}, f32[4096]{0}, f32[], /*index=20*/f32[], f32[4096]{0}, f32[4096]{0}, f32[], f32[], /*index=25*/f32[4096]{0}, f32[4096]{0}, f32[], f32[], f32[4096]{0}, /*index=30*/f32[4096]{0}, f32[], f32[], f32[4096]{0}, f32[4096]{0}, /*index=35*/f32[]) %fusion.329), index=26
  %copy.828 = f32[4096]{0} copy(f32[4096]{0} %get-tuple-element.5432)
  %copy.829 = f32[2048]{0} copy(f32[2048]{0} %get-tuple-element.5525)
  %get-tuple-element.5323 = f32[4096]{0} get-tuple-element((f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, /*index=5*/f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, /*index=10*/f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, /*index=15*/f32[4096]{0}, f32[4096]{0}, f32[4096]{0}) %fusion.573), index=13
  %get-tuple-element.5428 = f32[4096]{0} get-tuple-element((f32[], f32[4096]{0}, f32[4096]{0}, f32[], f32[], /*index=5*/f32[4096]{0}, f32[4096]{0}, f32[], f32[], f32[4096]{0}, /*index=10*/f32[4096]{0}, f32[], f32[], f32[4096]{0}, f32[4096]{0}, /*index=15*/f32[], f32[], f32[4096]{0}, f32[4096]{0}, f32[], /*index=20*/f32[], f32[4096]{0}, f32[4096]{0}, f32[], f32[], /*index=25*/f32[4096]{0}, f32[4096]{0}, f32[], f32[], f32[4096]{0}, /*index=30*/f32[4096]{0}, f32[], f32[], f32[4096]{0}, f32[4096]{0}, /*index=35*/f32[]) %fusion.329), index=22
  %copy.831 = f32[4096]{0} copy(f32[4096]{0} %get-tuple-element.5428)
  %copy.832 = f32[256]{0} copy(f32[256]{0} %get-tuple-element.5231)
  %get-tuple-element.5465 = f32[1024]{0} get-tuple-element((f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, /*index=5*/f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, /*index=10*/f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, /*index=15*/f32[1024]{0}, f32[1024]{0}) %fusion.411), index=9
  %copy.834 = f32[2048]{0} copy(f32[2048]{0} %get-tuple-element.5519)
  %get-tuple-element.5321 = f32[4096]{0} get-tuple-element((f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, /*index=5*/f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, /*index=10*/f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, /*index=15*/f32[4096]{0}, f32[4096]{0}, f32[4096]{0}) %fusion.573), index=11
  %get-tuple-element.5424 = f32[4096]{0} get-tuple-element((f32[], f32[4096]{0}, f32[4096]{0}, f32[], f32[], /*index=5*/f32[4096]{0}, f32[4096]{0}, f32[], f32[], f32[4096]{0}, /*index=10*/f32[4096]{0}, f32[], f32[], f32[4096]{0}, f32[4096]{0}, /*index=15*/f32[], f32[], f32[4096]{0}, f32[4096]{0}, f32[], /*index=20*/f32[], f32[4096]{0}, f32[4096]{0}, f32[], f32[], /*index=25*/f32[4096]{0}, f32[4096]{0}, f32[], f32[], f32[4096]{0}, /*index=30*/f32[4096]{0}, f32[], f32[], f32[4096]{0}, f32[4096]{0}, /*index=35*/f32[]) %fusion.329), index=18
  %copy.836 = f32[4096]{0} copy(f32[4096]{0} %get-tuple-element.5424)
  %copy.837 = f32[1024]{0} copy(f32[1024]{0} %get-tuple-element.5491)
  %get-tuple-element.5463 = f32[1024]{0} get-tuple-element((f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, /*index=5*/f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, /*index=10*/f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, /*index=15*/f32[1024]{0}, f32[1024]{0}) %fusion.411), index=7
  %get-tuple-element.5510 = f32[1024]{0} get-tuple-element((f32[], f32[1024]{0}, f32[], f32[1024]{0}, f32[], /*index=5*/f32[1024]{0}, f32[], f32[1024]{0}, f32[], f32[1024]{0}, /*index=10*/f32[], f32[1024]{0}, f32[1024]{0}, f32[], f32[], /*index=15*/f32[1024]{0}, f32[1024]{0}, f32[], f32[], f32[1024]{0}, /*index=20*/f32[1024]{0}, f32[], f32[], f32[1024]{0}, f32[1024]{0}, /*index=25*/f32[]) %fusion.756), index=24
  %copy.839 = f32[1024]{0} copy(f32[1024]{0} %get-tuple-element.5510)
  %copy.840 = f32[1024]{0} copy(f32[1024]{0} %get-tuple-element.5200)
  %get-tuple-element.5461 = f32[1024]{0} get-tuple-element((f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, /*index=5*/f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, /*index=10*/f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, /*index=15*/f32[1024]{0}, f32[1024]{0}) %fusion.411), index=5
  %get-tuple-element.5506 = f32[1024]{0} get-tuple-element((f32[], f32[1024]{0}, f32[], f32[1024]{0}, f32[], /*index=5*/f32[1024]{0}, f32[], f32[1024]{0}, f32[], f32[1024]{0}, /*index=10*/f32[], f32[1024]{0}, f32[1024]{0}, f32[], f32[], /*index=15*/f32[1024]{0}, f32[1024]{0}, f32[], f32[], f32[1024]{0}, /*index=20*/f32[1024]{0}, f32[], f32[], f32[1024]{0}, f32[1024]{0}, /*index=25*/f32[]) %fusion.756), index=20
  %copy.842 = f32[1024]{0} copy(f32[1024]{0} %get-tuple-element.5506)
  %copy.843 = f32[1024]{0} copy(f32[1024]{0} %get-tuple-element.5493)
  %get-tuple-element.5459 = f32[1024]{0} get-tuple-element((f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, /*index=5*/f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, /*index=10*/f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, /*index=15*/f32[1024]{0}, f32[1024]{0}) %fusion.411), index=3
  %get-tuple-element.5500 = f32[1024]{0} get-tuple-element((f32[], f32[1024]{0}, f32[], f32[1024]{0}, f32[], /*index=5*/f32[1024]{0}, f32[], f32[1024]{0}, f32[], f32[1024]{0}, /*index=10*/f32[], f32[1024]{0}, f32[1024]{0}, f32[], f32[], /*index=15*/f32[1024]{0}, f32[1024]{0}, f32[], f32[], f32[1024]{0}, /*index=20*/f32[1024]{0}, f32[], f32[], f32[1024]{0}, f32[1024]{0}, /*index=25*/f32[]) %fusion.756), index=16
  %copy.845 = f32[1024]{0} copy(f32[1024]{0} %get-tuple-element.5500)
  %copy.846 = f32[1024]{0} copy(f32[1024]{0} %get-tuple-element.5487)
  %get-tuple-element.5178 = f32[1024]{0} get-tuple-element((f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, /*index=5*/f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, /*index=10*/f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, /*index=15*/f32[1024]{0}, f32[1024]{0}) %fusion.411), index=1
  %get-tuple-element.5496 = f32[1024]{0} get-tuple-element((f32[], f32[1024]{0}, f32[], f32[1024]{0}, f32[], /*index=5*/f32[1024]{0}, f32[], f32[1024]{0}, f32[], f32[1024]{0}, /*index=10*/f32[], f32[1024]{0}, f32[1024]{0}, f32[], f32[], /*index=15*/f32[1024]{0}, f32[1024]{0}, f32[], f32[], f32[1024]{0}, /*index=20*/f32[1024]{0}, f32[], f32[], f32[1024]{0}, f32[1024]{0}, /*index=25*/f32[]) %fusion.756), index=12
  %copy.848 = f32[1024]{0} copy(f32[1024]{0} %get-tuple-element.5496)
  %copy.849 = f32[2048]{0} copy(f32[2048]{0} %get-tuple-element.5527)
  %get-tuple-element.5319 = f32[4096]{0} get-tuple-element((f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, /*index=5*/f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, /*index=10*/f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, /*index=15*/f32[4096]{0}, f32[4096]{0}, f32[4096]{0}) %fusion.573), index=9
  %get-tuple-element.5420 = f32[4096]{0} get-tuple-element((f32[], f32[4096]{0}, f32[4096]{0}, f32[], f32[], /*index=5*/f32[4096]{0}, f32[4096]{0}, f32[], f32[], f32[4096]{0}, /*index=10*/f32[4096]{0}, f32[], f32[], f32[4096]{0}, f32[4096]{0}, /*index=15*/f32[], f32[], f32[4096]{0}, f32[4096]{0}, f32[], /*index=20*/f32[], f32[4096]{0}, f32[4096]{0}, f32[], f32[], /*index=25*/f32[4096]{0}, f32[4096]{0}, f32[], f32[], f32[4096]{0}, /*index=30*/f32[4096]{0}, f32[], f32[], f32[4096]{0}, f32[4096]{0}, /*index=35*/f32[]) %fusion.329), index=14
  %copy.851 = f32[4096]{0} copy(f32[4096]{0} %get-tuple-element.5420)
  %copy.852 = f32[2048]{0} copy(f32[2048]{0} %get-tuple-element.5523)
  %get-tuple-element.5317 = f32[4096]{0} get-tuple-element((f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, /*index=5*/f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, /*index=10*/f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, /*index=15*/f32[4096]{0}, f32[4096]{0}, f32[4096]{0}) %fusion.573), index=7
  %get-tuple-element.5357 = f32[4096]{0} get-tuple-element((f32[], f32[4096]{0}, f32[4096]{0}, f32[], f32[], /*index=5*/f32[4096]{0}, f32[4096]{0}, f32[], f32[], f32[4096]{0}, /*index=10*/f32[4096]{0}, f32[], f32[], f32[4096]{0}, f32[4096]{0}, /*index=15*/f32[], f32[], f32[4096]{0}, f32[4096]{0}, f32[], /*index=20*/f32[], f32[4096]{0}, f32[4096]{0}, f32[], f32[], /*index=25*/f32[4096]{0}, f32[4096]{0}, f32[], f32[], f32[4096]{0}, /*index=30*/f32[4096]{0}, f32[], f32[], f32[4096]{0}, f32[4096]{0}, /*index=35*/f32[]) %fusion.329), index=10
  %copy.854 = f32[4096]{0} copy(f32[4096]{0} %get-tuple-element.5357)
  %copy.855 = f32[2048]{0} copy(f32[2048]{0} %get-tuple-element.5521)
  %get-tuple-element.5315 = f32[4096]{0} get-tuple-element((f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, /*index=5*/f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, /*index=10*/f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, /*index=15*/f32[4096]{0}, f32[4096]{0}, f32[4096]{0}) %fusion.573), index=5
  %get-tuple-element.5331 = f32[4096]{0} get-tuple-element((f32[], f32[4096]{0}, f32[4096]{0}, f32[], f32[], /*index=5*/f32[4096]{0}, f32[4096]{0}, f32[], f32[], f32[4096]{0}, /*index=10*/f32[4096]{0}, f32[], f32[], f32[4096]{0}, f32[4096]{0}, /*index=15*/f32[], f32[], f32[4096]{0}, f32[4096]{0}, f32[], /*index=20*/f32[], f32[4096]{0}, f32[4096]{0}, f32[], f32[], /*index=25*/f32[4096]{0}, f32[4096]{0}, f32[], f32[], f32[4096]{0}, /*index=30*/f32[4096]{0}, f32[], f32[], f32[4096]{0}, f32[4096]{0}, /*index=35*/f32[]) %fusion.329), index=6
  %copy.857 = f32[4096]{0} copy(f32[4096]{0} %get-tuple-element.5331)
  %copy.858 = f32[2048]{0} copy(f32[2048]{0} %get-tuple-element.5514)
  %get-tuple-element.5313 = f32[4096]{0} get-tuple-element((f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, /*index=5*/f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, /*index=10*/f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, f32[4096]{0}, /*index=15*/f32[4096]{0}, f32[4096]{0}, f32[4096]{0}) %fusion.573), index=3
  %get-tuple-element.5124 = f32[4096]{0} get-tuple-element((f32[], f32[4096]{0}, f32[4096]{0}, f32[], f32[], /*index=5*/f32[4096]{0}, f32[4096]{0}, f32[], f32[], f32[4096]{0}, /*index=10*/f32[4096]{0}, f32[], f32[], f32[4096]{0}, f32[4096]{0}, /*index=15*/f32[], f32[], f32[4096]{0}, f32[4096]{0}, f32[], /*index=20*/f32[], f32[4096]{0}, f32[4096]{0}, f32[], f32[], /*index=25*/f32[4096]{0}, f32[4096]{0}, f32[], f32[], f32[4096]{0}, /*index=30*/f32[4096]{0}, f32[], f32[], f32[4096]{0}, f32[4096]{0}, /*index=35*/f32[]) %fusion.329), index=2
  %copy.860 = f32[4096]{0} copy(f32[4096]{0} %get-tuple-element.5124)
  %copy.861 = f32[1024]{0} copy(f32[1024]{0} %get-tuple-element.5489)
  %get-tuple-element.5118 = f32[256]{0} get-tuple-element((f32[256]{0}, f32[256]{0}, f32[256]{0}) %fusion.319), index=1
  %get-tuple-element.5532 = f32[256]{0} get-tuple-element((f32[], f32[256]{0}, f32[], f32[256]{0}, f32[256]{0}, /*index=5*/f32[]) %fusion.759), index=4
  %copy.863 = f32[256]{0} copy(f32[256]{0} %get-tuple-element.5532)
  %get-tuple-element.5533 = f32[] get-tuple-element((f32[], f32[256]{0}, f32[], f32[256]{0}, f32[256]{0}, /*index=5*/f32[]) %fusion.759), index=5
  %get-tuple-element.5119 = f32[] get-tuple-element((f32[], f32[]) %fusion.292), index=0
  %get-tuple-element.5125 = f32[] get-tuple-element((f32[], f32[4096]{0}, f32[4096]{0}, f32[], f32[], /*index=5*/f32[4096]{0}, f32[4096]{0}, f32[], f32[], f32[4096]{0}, /*index=10*/f32[4096]{0}, f32[], f32[], f32[4096]{0}, f32[4096]{0}, /*index=15*/f32[], f32[], f32[4096]{0}, f32[4096]{0}, f32[], /*index=20*/f32[], f32[4096]{0}, f32[4096]{0}, f32[], f32[], /*index=25*/f32[4096]{0}, f32[4096]{0}, f32[], f32[], f32[4096]{0}, /*index=30*/f32[4096]{0}, f32[], f32[], f32[4096]{0}, f32[4096]{0}, /*index=35*/f32[]) %fusion.329), index=3
  %get-tuple-element.5131 = f32[] get-tuple-element((f32[], f32[]) %fusion.293), index=0
  %get-tuple-element.5354 = f32[] get-tuple-element((f32[], f32[4096]{0}, f32[4096]{0}, f32[], f32[], /*index=5*/f32[4096]{0}, f32[4096]{0}, f32[], f32[], f32[4096]{0}, /*index=10*/f32[4096]{0}, f32[], f32[], f32[4096]{0}, f32[4096]{0}, /*index=15*/f32[], f32[], f32[4096]{0}, f32[4096]{0}, f32[], /*index=20*/f32[], f32[4096]{0}, f32[4096]{0}, f32[], f32[], /*index=25*/f32[4096]{0}, f32[4096]{0}, f32[], f32[], f32[4096]{0}, /*index=30*/f32[4096]{0}, f32[], f32[], f32[4096]{0}, f32[4096]{0}, /*index=35*/f32[]) %fusion.329), index=7
  %get-tuple-element.5143 = f32[] get-tuple-element((f32[], f32[]) %fusion.294), index=0
  %get-tuple-element.5380 = f32[] get-tuple-element((f32[], f32[4096]{0}, f32[4096]{0}, f32[], f32[], /*index=5*/f32[4096]{0}, f32[4096]{0}, f32[], f32[], f32[4096]{0}, /*index=10*/f32[4096]{0}, f32[], f32[], f32[4096]{0}, f32[4096]{0}, /*index=15*/f32[], f32[], f32[4096]{0}, f32[4096]{0}, f32[], /*index=20*/f32[], f32[4096]{0}, f32[4096]{0}, f32[], f32[], /*index=25*/f32[4096]{0}, f32[4096]{0}, f32[], f32[], f32[4096]{0}, /*index=30*/f32[4096]{0}, f32[], f32[], f32[4096]{0}, f32[4096]{0}, /*index=35*/f32[]) %fusion.329), index=11
  %get-tuple-element.5155 = f32[] get-tuple-element((f32[], f32[]) %fusion.295), index=0
  %get-tuple-element.5421 = f32[] get-tuple-element((f32[], f32[4096]{0}, f32[4096]{0}, f32[], f32[], /*index=5*/f32[4096]{0}, f32[4096]{0}, f32[], f32[], f32[4096]{0}, /*index=10*/f32[4096]{0}, f32[], f32[], f32[4096]{0}, f32[4096]{0}, /*index=15*/f32[], f32[], f32[4096]{0}, f32[4096]{0}, f32[], /*index=20*/f32[], f32[4096]{0}, f32[4096]{0}, f32[], f32[], /*index=25*/f32[4096]{0}, f32[4096]{0}, f32[], f32[], f32[4096]{0}, /*index=30*/f32[4096]{0}, f32[], f32[], f32[4096]{0}, f32[4096]{0}, /*index=35*/f32[]) %fusion.329), index=15
  %get-tuple-element.5167 = f32[] get-tuple-element((f32[], f32[]) %fusion.296), index=0
  %get-tuple-element.5497 = f32[] get-tuple-element((f32[], f32[1024]{0}, f32[], f32[1024]{0}, f32[], /*index=5*/f32[1024]{0}, f32[], f32[1024]{0}, f32[], f32[1024]{0}, /*index=10*/f32[], f32[1024]{0}, f32[1024]{0}, f32[], f32[], /*index=15*/f32[1024]{0}, f32[1024]{0}, f32[], f32[], f32[1024]{0}, /*index=20*/f32[1024]{0}, f32[], f32[], f32[1024]{0}, f32[1024]{0}, /*index=25*/f32[]) %fusion.756), index=13
  %get-tuple-element.5179 = f32[] get-tuple-element((f32[], f32[]) %fusion.297), index=0
  %get-tuple-element.5501 = f32[] get-tuple-element((f32[], f32[1024]{0}, f32[], f32[1024]{0}, f32[], /*index=5*/f32[1024]{0}, f32[], f32[1024]{0}, f32[], f32[1024]{0}, /*index=10*/f32[], f32[1024]{0}, f32[1024]{0}, f32[], f32[], /*index=15*/f32[1024]{0}, f32[1024]{0}, f32[], f32[], f32[1024]{0}, /*index=20*/f32[1024]{0}, f32[], f32[], f32[1024]{0}, f32[1024]{0}, /*index=25*/f32[]) %fusion.756), index=17
  %get-tuple-element.5191 = f32[] get-tuple-element((f32[], f32[]) %fusion.298), index=0
  %get-tuple-element.5507 = f32[] get-tuple-element((f32[], f32[1024]{0}, f32[], f32[1024]{0}, f32[], /*index=5*/f32[1024]{0}, f32[], f32[1024]{0}, f32[], f32[1024]{0}, /*index=10*/f32[], f32[1024]{0}, f32[1024]{0}, f32[], f32[], /*index=15*/f32[1024]{0}, f32[1024]{0}, f32[], f32[], f32[1024]{0}, /*index=20*/f32[1024]{0}, f32[], f32[], f32[1024]{0}, f32[1024]{0}, /*index=25*/f32[]) %fusion.756), index=21
  %get-tuple-element.5203 = f32[] get-tuple-element((f32[], f32[]) %fusion.299), index=0
  %get-tuple-element.5511 = f32[] get-tuple-element((f32[], f32[1024]{0}, f32[], f32[1024]{0}, f32[], /*index=5*/f32[1024]{0}, f32[], f32[1024]{0}, f32[], f32[1024]{0}, /*index=10*/f32[], f32[1024]{0}, f32[1024]{0}, f32[], f32[], /*index=15*/f32[1024]{0}, f32[1024]{0}, f32[], f32[], f32[1024]{0}, /*index=20*/f32[1024]{0}, f32[], f32[], f32[1024]{0}, f32[1024]{0}, /*index=25*/f32[]) %fusion.756), index=25
  %get-tuple-element.5215 = f32[] get-tuple-element((f32[], f32[]) %fusion.300), index=0
  %get-tuple-element.5425 = f32[] get-tuple-element((f32[], f32[4096]{0}, f32[4096]{0}, f32[], f32[], /*index=5*/f32[4096]{0}, f32[4096]{0}, f32[], f32[], f32[4096]{0}, /*index=10*/f32[4096]{0}, f32[], f32[], f32[4096]{0}, f32[4096]{0}, /*index=15*/f32[], f32[], f32[4096]{0}, f32[4096]{0}, f32[], /*index=20*/f32[], f32[4096]{0}, f32[4096]{0}, f32[], f32[], /*index=25*/f32[4096]{0}, f32[4096]{0}, f32[], f32[], f32[4096]{0}, /*index=30*/f32[4096]{0}, f32[], f32[], f32[4096]{0}, f32[4096]{0}, /*index=35*/f32[]) %fusion.329), index=19
  %get-tuple-element.5227 = f32[] get-tuple-element((f32[], f32[]) %fusion.301), index=0
  %get-tuple-element.5234 = f32[] get-tuple-element((f32[], f32[]) %fusion.302), index=0
  %get-tuple-element.5429 = f32[] get-tuple-element((f32[], f32[4096]{0}, f32[4096]{0}, f32[], f32[], /*index=5*/f32[4096]{0}, f32[4096]{0}, f32[], f32[], f32[4096]{0}, /*index=10*/f32[4096]{0}, f32[], f32[], f32[4096]{0}, f32[4096]{0}, /*index=15*/f32[], f32[], f32[4096]{0}, f32[4096]{0}, f32[], /*index=20*/f32[], f32[4096]{0}, f32[4096]{0}, f32[], f32[], /*index=25*/f32[4096]{0}, f32[4096]{0}, f32[], f32[], f32[4096]{0}, /*index=30*/f32[4096]{0}, f32[], f32[], f32[4096]{0}, f32[4096]{0}, /*index=35*/f32[]) %fusion.329), index=23
  %get-tuple-element.5246 = f32[] get-tuple-element((f32[], f32[]) %fusion.303), index=0
  %get-tuple-element.5433 = f32[] get-tuple-element((f32[], f32[4096]{0}, f32[4096]{0}, f32[], f32[], /*index=5*/f32[4096]{0}, f32[4096]{0}, f32[], f32[], f32[4096]{0}, /*index=10*/f32[4096]{0}, f32[], f32[], f32[4096]{0}, f32[4096]{0}, /*index=15*/f32[], f32[], f32[4096]{0}, f32[4096]{0}, f32[], /*index=20*/f32[], f32[4096]{0}, f32[4096]{0}, f32[], f32[], /*index=25*/f32[4096]{0}, f32[4096]{0}, f32[], f32[], f32[4096]{0}, /*index=30*/f32[4096]{0}, f32[], f32[], f32[4096]{0}, f32[4096]{0}, /*index=35*/f32[]) %fusion.329), index=27
  %get-tuple-element.5258 = f32[] get-tuple-element((f32[], f32[]) %fusion.304), index=0
  %get-tuple-element.5439 = f32[] get-tuple-element((f32[], f32[4096]{0}, f32[4096]{0}, f32[], f32[], /*index=5*/f32[4096]{0}, f32[4096]{0}, f32[], f32[], f32[4096]{0}, /*index=10*/f32[4096]{0}, f32[], f32[], f32[4096]{0}, f32[4096]{0}, /*index=15*/f32[], f32[], f32[4096]{0}, f32[4096]{0}, f32[], /*index=20*/f32[], f32[4096]{0}, f32[4096]{0}, f32[], f32[], /*index=25*/f32[4096]{0}, f32[4096]{0}, f32[], f32[], f32[4096]{0}, /*index=30*/f32[4096]{0}, f32[], f32[], f32[4096]{0}, f32[4096]{0}, /*index=35*/f32[]) %fusion.329), index=31
  %get-tuple-element.5270 = f32[] get-tuple-element((f32[], f32[]) %fusion.305), index=0
  %get-tuple-element.5443 = f32[] get-tuple-element((f32[], f32[4096]{0}, f32[4096]{0}, f32[], f32[], /*index=5*/f32[4096]{0}, f32[4096]{0}, f32[], f32[], f32[4096]{0}, /*index=10*/f32[4096]{0}, f32[], f32[], f32[4096]{0}, f32[4096]{0}, /*index=15*/f32[], f32[], f32[4096]{0}, f32[4096]{0}, f32[], /*index=20*/f32[], f32[4096]{0}, f32[4096]{0}, f32[], f32[], /*index=25*/f32[4096]{0}, f32[4096]{0}, f32[], f32[], f32[4096]{0}, /*index=30*/f32[4096]{0}, f32[], f32[], f32[4096]{0}, f32[4096]{0}, /*index=35*/f32[]) %fusion.329), index=35
  %get-tuple-element.5536 = f32[] get-tuple-element((f32[], f32[]) %fusion.307), index=0
  %get-tuple-element.5282 = f32[] get-tuple-element((f32[], f32[]) %fusion.306), index=0
  %fusion.291 = f32[] fusion(f32[] %get-tuple-element.5533, f32[] %get-tuple-element.5119, f32[] %get-tuple-element.5125, f32[] %get-tuple-element.5131, f32[] %get-tuple-element.5354, /*index=5*/f32[] %get-tuple-element.5143, f32[] %get-tuple-element.5380, f32[] %get-tuple-element.5155, f32[] %get-tuple-element.5421, f32[] %get-tuple-element.5167, /*index=10*/f32[] %get-tuple-element.5497, f32[] %get-tuple-element.5179, f32[] %get-tuple-element.5501, f32[] %get-tuple-element.5191, f32[] %get-tuple-element.5507, /*index=15*/f32[] %get-tuple-element.5203, f32[] %get-tuple-element.5511, f32[] %get-tuple-element.5215, f32[] %get-tuple-element.5425, f32[] %get-tuple-element.5227, /*index=20*/f32[] %get-tuple-element.5234, f32[] %get-tuple-element.5429, f32[] %get-tuple-element.5246, f32[] %get-tuple-element.5433, f32[] %get-tuple-element.5258, /*index=25*/f32[] %get-tuple-element.5439, f32[] %get-tuple-element.5270, f32[] %get-tuple-element.5443, f32[] %get-tuple-element.5536, f32[] %get-tuple-element.5282), kind=kLoop, calls=%fused_computation.291, metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %get-tuple-element.5549 = f32[] get-tuple-element((f32[], f32[]) %fusion.656), index=1
  %fusion.671 = f32[] fusion(f32[] %get-tuple-element.5549, f32[] %all-reduce.7676), kind=kLoop, calls=%fused_computation.671, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/metrics.py" source_line=617}
  %get-tuple-element.5109 = f32[] get-tuple-element((f32[], f32[], f32[], f32[], f32[], /*index=5*/f32[], f32[], f32[], f32[], f32[], /*index=10*/f32[], f32[], f32[], f32[], f32[], /*index=15*/f32[], f32[], f32[], f32[], f32[], /*index=20*/f32[], f32[], f32[], f32[], f32[], /*index=25*/f32[], f32[], f32[], f32[], f32[], /*index=30*/f32[]) %fusion.313), index=1
  ROOT %tuple.839 = (f32[32000,1024]{1,0}, f32[2048,4096]{1,0}, f32[4096]{0}, f32[2048,4096]{1,0}, f32[4096]{0}, /*index=5*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[2048,4096]{1,0}, f32[4096]{0}, f32[256,1024]{1,0}, /*index=10*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[1024,1024]{1,0}, f32[1024]{0}, f32[1024,1024]{1,0}, /*index=15*/f32[1024]{0}, f32[1024,1024]{1,0}, f32[1024]{0}, f32[1024,1024]{1,0}, f32[1024]{0}, /*index=20*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[2048,4096]{1,0}, f32[4096]{0}, f32[2048,4096]{1,0}, /*index=25*/f32[4096]{0}, f32[2048,4096]{1,0}, f32[4096]{0}, f32[1024,256]{1,0}, f32[256]{0}, /*index=30*/f32[32000]{0}, f32[1024]{0}, f32[2048]{0}, f32[4096]{0}, f32[4096]{0}, /*index=35*/f32[2048]{0}, f32[4096]{0}, f32[4096]{0}, f32[2048]{0}, f32[4096]{0}, /*index=40*/f32[4096]{0}, f32[2048]{0}, f32[4096]{0}, f32[4096]{0}, f32[256]{0}, /*index=45*/f32[1024]{0}, f32[2048]{0}, f32[4096]{0}, f32[4096]{0}, f32[1024]{0}, /*index=50*/f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, /*index=55*/f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, /*index=60*/f32[1024]{0}, f32[2048]{0}, f32[4096]{0}, f32[4096]{0}, f32[2048]{0}, /*index=65*/f32[4096]{0}, f32[4096]{0}, f32[2048]{0}, f32[4096]{0}, f32[4096]{0}, /*index=70*/f32[2048]{0}, f32[4096]{0}, f32[4096]{0}, f32[1024]{0}, f32[256]{0}, /*index=75*/f32[256]{0}, f32[], f32[], f32[]) tuple(f32[32000,1024]{1,0} %fusion.582, f32[2048,4096]{1,0} %get-tuple-element.5284, f32[4096]{0} %get-tuple-element.5292, f32[2048,4096]{1,0} %fusion.551, f32[4096]{0} %get-tuple-element.5300, /*index=5*/f32[2048,4096]{1,0} %get-tuple-element.5291, f32[4096]{0} %get-tuple-element.5299, f32[2048,4096]{1,0} %get-tuple-element.5290, f32[4096]{0} %get-tuple-element.5298, f32[256,1024]{1,0} %fusion.494, /*index=10*/f32[2048,4096]{1,0} %get-tuple-element.5289, f32[4096]{0} %get-tuple-element.5297, f32[1024,1024]{1,0} %get-tuple-element.5301, f32[1024]{0} %get-tuple-element.5305, f32[1024,1024]{1,0} %get-tuple-element.5304, /*index=15*/f32[1024]{0} %get-tuple-element.5308, f32[1024,1024]{1,0} %get-tuple-element.5303, f32[1024]{0} %get-tuple-element.5307, f32[1024,1024]{1,0} %get-tuple-element.5302, f32[1024]{0} %get-tuple-element.5306, /*index=20*/f32[2048,4096]{1,0} %get-tuple-element.5288, f32[4096]{0} %get-tuple-element.5296, f32[2048,4096]{1,0} %get-tuple-element.5287, f32[4096]{0} %get-tuple-element.5295, f32[2048,4096]{1,0} %get-tuple-element.5286, /*index=25*/f32[4096]{0} %get-tuple-element.5294, f32[2048,4096]{1,0} %get-tuple-element.5285, f32[4096]{0} %get-tuple-element.5293, f32[1024,256]{1,0} %fusion.315, f32[256]{0} %fusion.308, /*index=30*/f32[32000]{0} %copy.818, f32[1024]{0} %get-tuple-element.5485, f32[2048]{0} %copy.820, f32[4096]{0} %get-tuple-element.5281, f32[4096]{0} %copy.822, /*index=35*/f32[2048]{0} %copy.823, f32[4096]{0} %get-tuple-element.5327, f32[4096]{0} %copy.825, f32[2048]{0} %copy.826, f32[4096]{0} %get-tuple-element.5325, /*index=40*/f32[4096]{0} %copy.828, f32[2048]{0} %copy.829, f32[4096]{0} %get-tuple-element.5323, f32[4096]{0} %copy.831, f32[256]{0} %copy.832, /*index=45*/f32[1024]{0} %get-tuple-element.5465, f32[2048]{0} %copy.834, f32[4096]{0} %get-tuple-element.5321, f32[4096]{0} %copy.836, f32[1024]{0} %copy.837, /*index=50*/f32[1024]{0} %get-tuple-element.5463, f32[1024]{0} %copy.839, f32[1024]{0} %copy.840, f32[1024]{0} %get-tuple-element.5461, f32[1024]{0} %copy.842, /*index=55*/f32[1024]{0} %copy.843, f32[1024]{0} %get-tuple-element.5459, f32[1024]{0} %copy.845, f32[1024]{0} %copy.846, f32[1024]{0} %get-tuple-element.5178, /*index=60*/f32[1024]{0} %copy.848, f32[2048]{0} %copy.849, f32[4096]{0} %get-tuple-element.5319, f32[4096]{0} %copy.851, f32[2048]{0} %copy.852, /*index=65*/f32[4096]{0} %get-tuple-element.5317, f32[4096]{0} %copy.854, f32[2048]{0} %copy.855, f32[4096]{0} %get-tuple-element.5315, f32[4096]{0} %copy.857, /*index=70*/f32[2048]{0} %copy.858, f32[4096]{0} %get-tuple-element.5313, f32[4096]{0} %copy.860, f32[1024]{0} %copy.861, f32[256]{0} %get-tuple-element.5118, /*index=75*/f32[256]{0} %copy.863, f32[] %fusion.291, f32[] %fusion.671, f32[] %get-tuple-element.5109)
}

