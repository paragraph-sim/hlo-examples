HloModule pmap__multi_device_update_fn__2.21607

%primitive_computation_add__1.13202 (parameter.13203: f32[], parameter.13204: f32[]) -> f32[] {
  %parameter.13203 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.13204 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.13205 = f32[] add(f32[] %parameter.13203, f32[] %parameter.13204), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.13207 (parameter.13208: f32[], parameter.13209: f32[]) -> f32[] {
  %parameter.13208 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.13209 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.13210 = f32[] add(f32[] %parameter.13208, f32[] %parameter.13209), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.13265 (parameter.13266: f32[], parameter.13267: f32[]) -> f32[] {
  %parameter.13266 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.13267 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.13268 = f32[] add(f32[] %parameter.13266, f32[] %parameter.13267), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.17503 (parameter.17504: f32[], parameter.17505: f32[]) -> f32[] {
  %parameter.17504 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.17505 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.17506 = f32[] add(f32[] %parameter.17504, f32[] %parameter.17505), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.18039 (parameter.18040: f32[], parameter.18041: f32[]) -> f32[] {
  %parameter.18040 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.18041 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.18042 = f32[] add(f32[] %parameter.18040, f32[] %parameter.18041), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.18044 (parameter.18045: f32[], parameter.18046: f32[]) -> f32[] {
  %parameter.18045 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.18046 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.18047 = f32[] add(f32[] %parameter.18045, f32[] %parameter.18046), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.18049 (parameter.18050: f32[], parameter.18051: f32[]) -> f32[] {
  %parameter.18050 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.18051 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.18052 = f32[] add(f32[] %parameter.18050, f32[] %parameter.18051), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.18054 (parameter.18055: f32[], parameter.18056: f32[]) -> f32[] {
  %parameter.18055 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.18056 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.18057 = f32[] add(f32[] %parameter.18055, f32[] %parameter.18056), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.18059 (parameter.18060: f32[], parameter.18061: f32[]) -> f32[] {
  %parameter.18060 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.18061 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.18062 = f32[] add(f32[] %parameter.18060, f32[] %parameter.18061), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.18064 (parameter.18065: f32[], parameter.18066: f32[]) -> f32[] {
  %parameter.18065 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.18066 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.18067 = f32[] add(f32[] %parameter.18065, f32[] %parameter.18066), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.18069 (parameter.18070: f32[], parameter.18071: f32[]) -> f32[] {
  %parameter.18070 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.18071 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.18072 = f32[] add(f32[] %parameter.18070, f32[] %parameter.18071), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.18074 (parameter.18075: f32[], parameter.18076: f32[]) -> f32[] {
  %parameter.18075 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.18076 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.18077 = f32[] add(f32[] %parameter.18075, f32[] %parameter.18076), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.18079 (parameter.18080: f32[], parameter.18081: f32[]) -> f32[] {
  %parameter.18080 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.18081 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.18082 = f32[] add(f32[] %parameter.18080, f32[] %parameter.18081), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.18084 (parameter.18085: f32[], parameter.18086: f32[]) -> f32[] {
  %parameter.18085 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.18086 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.18087 = f32[] add(f32[] %parameter.18085, f32[] %parameter.18086), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.18089 (parameter.18090: f32[], parameter.18091: f32[]) -> f32[] {
  %parameter.18090 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.18091 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.18092 = f32[] add(f32[] %parameter.18090, f32[] %parameter.18091), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.18094 (parameter.18095: f32[], parameter.18096: f32[]) -> f32[] {
  %parameter.18095 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.18096 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.18097 = f32[] add(f32[] %parameter.18095, f32[] %parameter.18096), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.18099 (parameter.18100: f32[], parameter.18101: f32[]) -> f32[] {
  %parameter.18100 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.18101 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.18102 = f32[] add(f32[] %parameter.18100, f32[] %parameter.18101), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.18104 (parameter.18105: f32[], parameter.18106: f32[]) -> f32[] {
  %parameter.18105 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.18106 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.18107 = f32[] add(f32[] %parameter.18105, f32[] %parameter.18106), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.18109 (parameter.18110: f32[], parameter.18111: f32[]) -> f32[] {
  %parameter.18110 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.18111 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.18112 = f32[] add(f32[] %parameter.18110, f32[] %parameter.18111), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.18114 (parameter.18115: f32[], parameter.18116: f32[]) -> f32[] {
  %parameter.18115 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.18116 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.18117 = f32[] add(f32[] %parameter.18115, f32[] %parameter.18116), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.18119 (parameter.18120: f32[], parameter.18121: f32[]) -> f32[] {
  %parameter.18120 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.18121 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.18122 = f32[] add(f32[] %parameter.18120, f32[] %parameter.18121), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.18124 (parameter.18125: f32[], parameter.18126: f32[]) -> f32[] {
  %parameter.18125 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.18126 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.18127 = f32[] add(f32[] %parameter.18125, f32[] %parameter.18126), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.18129 (parameter.18130: f32[], parameter.18131: f32[]) -> f32[] {
  %parameter.18130 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.18131 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.18132 = f32[] add(f32[] %parameter.18130, f32[] %parameter.18131), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.18134 (parameter.18135: f32[], parameter.18136: f32[]) -> f32[] {
  %parameter.18135 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.18136 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.18137 = f32[] add(f32[] %parameter.18135, f32[] %parameter.18136), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.18139 (parameter.18140: f32[], parameter.18141: f32[]) -> f32[] {
  %parameter.18140 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.18141 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.18142 = f32[] add(f32[] %parameter.18140, f32[] %parameter.18141), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.18144 (parameter.18145: f32[], parameter.18146: f32[]) -> f32[] {
  %parameter.18145 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.18146 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.18147 = f32[] add(f32[] %parameter.18145, f32[] %parameter.18146), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.18149 (parameter.18150: f32[], parameter.18151: f32[]) -> f32[] {
  %parameter.18150 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.18151 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.18152 = f32[] add(f32[] %parameter.18150, f32[] %parameter.18151), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.18154 (parameter.18155: f32[], parameter.18156: f32[]) -> f32[] {
  %parameter.18155 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.18156 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.18157 = f32[] add(f32[] %parameter.18155, f32[] %parameter.18156), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.18159 (parameter.18160: f32[], parameter.18161: f32[]) -> f32[] {
  %parameter.18160 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.18161 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.18162 = f32[] add(f32[] %parameter.18160, f32[] %parameter.18161), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.18164 (parameter.18165: f32[], parameter.18166: f32[]) -> f32[] {
  %parameter.18165 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.18166 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.18167 = f32[] add(f32[] %parameter.18165, f32[] %parameter.18166), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.18169 (parameter.18170: f32[], parameter.18171: f32[]) -> f32[] {
  %parameter.18170 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.18171 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.18172 = f32[] add(f32[] %parameter.18170, f32[] %parameter.18171), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.18174 (parameter.18175: f32[], parameter.18176: f32[]) -> f32[] {
  %parameter.18175 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.18176 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.18177 = f32[] add(f32[] %parameter.18175, f32[] %parameter.18176), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.18179 (parameter.18180: f32[], parameter.18181: f32[]) -> f32[] {
  %parameter.18180 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.18181 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.18182 = f32[] add(f32[] %parameter.18180, f32[] %parameter.18181), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.18184 (parameter.18185: f32[], parameter.18186: f32[]) -> f32[] {
  %parameter.18185 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.18186 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.18187 = f32[] add(f32[] %parameter.18185, f32[] %parameter.18186), metadata={op_type="add" op_name="add"}
}

%fused_computation (param_0: f32[32000,1024], param_1.3: f32[512,1024], param_2.4: s32[], param_3.4: pred[], param_4.6: s32[512]) -> f32[32000,1024] {
  %param_0 = f32[32000,1024]{1,0} parameter(0)
  %param_3.4 = pred[] parameter(3)
  %broadcast.1584 = pred[1,1024]{1,0} broadcast(pred[] %param_3.4), dimensions={}
  %param_4.6 = s32[512]{0} parameter(4)
  %param_2.4 = s32[] parameter(2)
  %dynamic-slice.772 = s32[1]{0} dynamic-slice(s32[512]{0} %param_4.6, s32[] %param_2.4), dynamic_slice_sizes={1}
  %reshape.2798 = s32[] reshape(s32[1]{0} %dynamic-slice.772)
  %constant.20353 = s32[] constant(0)
  %dynamic-slice.771 = f32[1,1024]{1,0} dynamic-slice(f32[32000,1024]{1,0} %param_0, s32[] %reshape.2798, s32[] %constant.20353), dynamic_slice_sizes={1,1024}
  %param_1.3 = f32[512,1024]{1,0} parameter(1)
  %dynamic-slice.770 = f32[1,1024]{1,0} dynamic-slice(f32[512,1024]{1,0} %param_1.3, s32[] %param_2.4, s32[] %constant.20353), dynamic_slice_sizes={1,1024}
  %add.3855 = f32[1,1024]{1,0} add(f32[1,1024]{1,0} %dynamic-slice.771, f32[1,1024]{1,0} %dynamic-slice.770)
  %select.2631 = f32[1,1024]{1,0} select(pred[1,1024]{1,0} %broadcast.1584, f32[1,1024]{1,0} %add.3855, f32[1,1024]{1,0} %dynamic-slice.771)
  ROOT %dynamic-update-slice.762 = f32[32000,1024]{1,0} dynamic-update-slice(f32[32000,1024]{1,0} %param_0, f32[1,1024]{1,0} %select.2631, s32[] %reshape.2798, s32[] %constant.20353)
}

%and.reduce_sub_computation (lhs: pred[], rhs: pred[]) -> pred[] {
  %lhs = pred[] parameter(0)
  %rhs = pred[] parameter(1)
  ROOT %and.16 = pred[] and(pred[] %lhs, pred[] %rhs)
}

%fused_computation.1 (param_0.4: s32[2]) -> pred[] {
  %constant.20357 = s32[] constant(0)
  %broadcast.1585 = s32[2]{0} broadcast(s32[] %constant.20357), dimensions={}
  %param_0.4 = s32[2]{0} parameter(0)
  %compare.2741 = pred[2]{0} compare(s32[2]{0} %broadcast.1585, s32[2]{0} %param_0.4), direction=LE
  %constant.20355 = s32[2]{0} constant({31999, 0})
  %compare.2739 = pred[2]{0} compare(s32[2]{0} %constant.20355, s32[2]{0} %param_0.4), direction=GE
  %and.20 = pred[2]{0} and(pred[2]{0} %compare.2741, pred[2]{0} %compare.2739)
  %constant.20354 = pred[] constant(true)
  ROOT %reduce.281 = pred[] reduce(pred[2]{0} %and.20, pred[] %constant.20354), dimensions={0}, to_apply=%and.reduce_sub_computation
}

%fused_computation.2 (param_0.7: s32[512], param_1.13: s32[]) -> s32[2] {
  %param_0.7 = s32[512]{0} parameter(0)
  %param_1.13 = s32[] parameter(1)
  %dynamic-slice.773 = s32[1]{0} dynamic-slice(s32[512]{0} %param_0.7, s32[] %param_1.13), dynamic_slice_sizes={1}
  %constant.20358 = s32[1]{0} constant({0})
  ROOT %concatenate.226 = s32[2]{0} concatenate(s32[1]{0} %dynamic-slice.773, s32[1]{0} %constant.20358), dimensions={0}
}

%while_body (param.0: (s32[], f32[32000,1024], s32[512], f32[512,1024])) -> (s32[], f32[32000,1024], s32[512], f32[512,1024]) {
  %param.0 = (s32[], f32[32000,1024]{1,0}, s32[512]{0}, f32[512,1024]{1,0}) parameter(0)
  %get-tuple-element.27942 = s32[] get-tuple-element((s32[], f32[32000,1024]{1,0}, s32[512]{0}, f32[512,1024]{1,0}) %param.0), index=0
  %copy.931 = s32[] copy(s32[] %get-tuple-element.27942)
  %constant.1120 = s32[] constant(1)
  %add.196 = s32[] add(s32[] %copy.931, s32[] %constant.1120)
  %get-tuple-element.27943 = f32[32000,1024]{1,0} get-tuple-element((s32[], f32[32000,1024]{1,0}, s32[512]{0}, f32[512,1024]{1,0}) %param.0), index=1
  %get-tuple-element.27945 = f32[512,1024]{1,0} get-tuple-element((s32[], f32[32000,1024]{1,0}, s32[512]{0}, f32[512,1024]{1,0}) %param.0), index=3
  %get-tuple-element.27944 = s32[512]{0} get-tuple-element((s32[], f32[32000,1024]{1,0}, s32[512]{0}, f32[512,1024]{1,0}) %param.0), index=2
  %fusion.2 = s32[2]{0} fusion(s32[512]{0} %get-tuple-element.27944, s32[] %copy.931), kind=kLoop, calls=%fused_computation.2
  %fusion.1 = pred[] fusion(s32[2]{0} %fusion.2), kind=kLoop, calls=%fused_computation.1
  %fusion = f32[32000,1024]{1,0} fusion(f32[32000,1024]{1,0} %get-tuple-element.27943, f32[512,1024]{1,0} %get-tuple-element.27945, s32[] %copy.931, pred[] %fusion.1, s32[512]{0} %get-tuple-element.27944), kind=kLoop, calls=%fused_computation
  ROOT %tuple.1347 = (s32[], f32[32000,1024]{1,0}, s32[512]{0}, f32[512,1024]{1,0}) tuple(s32[] %add.196, f32[32000,1024]{1,0} %fusion, s32[512]{0} %get-tuple-element.27944, f32[512,1024]{1,0} %get-tuple-element.27945)
}

%while_cond (param.1: (s32[], f32[32000,1024], s32[512], f32[512,1024])) -> pred[] {
  %param.1 = (s32[], f32[32000,1024]{1,0}, s32[512]{0}, f32[512,1024]{1,0}) parameter(0)
  %get-tuple-element.3534 = s32[] get-tuple-element((s32[], f32[32000,1024]{1,0}, s32[512]{0}, f32[512,1024]{1,0}) %param.1), index=0
  %constant.1128 = s32[] constant(512)
  ROOT %compare.12 = pred[] compare(s32[] %get-tuple-element.3534, s32[] %constant.1128), direction=LT
}

%fused_computation.3 (param_0.8: f32[256,1024], param_1.17: f32[512,1024], param_2.12: s32[], param_3.9: pred[], param_4.13: s32[512]) -> f32[256,1024] {
  %param_0.8 = f32[256,1024]{1,0} parameter(0)
  %param_3.9 = pred[] parameter(3)
  %broadcast.1586 = pred[1,1024]{1,0} broadcast(pred[] %param_3.9), dimensions={}
  %param_4.13 = s32[512]{0} parameter(4)
  %param_2.12 = s32[] parameter(2)
  %dynamic-slice.776 = s32[1]{0} dynamic-slice(s32[512]{0} %param_4.13, s32[] %param_2.12), dynamic_slice_sizes={1}
  %reshape.2799 = s32[] reshape(s32[1]{0} %dynamic-slice.776)
  %constant.20359 = s32[] constant(0)
  %dynamic-slice.775 = f32[1,1024]{1,0} dynamic-slice(f32[256,1024]{1,0} %param_0.8, s32[] %reshape.2799, s32[] %constant.20359), dynamic_slice_sizes={1,1024}
  %param_1.17 = f32[512,1024]{1,0} parameter(1)
  %dynamic-slice.774 = f32[1,1024]{1,0} dynamic-slice(f32[512,1024]{1,0} %param_1.17, s32[] %param_2.12, s32[] %constant.20359), dynamic_slice_sizes={1,1024}
  %add.3856 = f32[1,1024]{1,0} add(f32[1,1024]{1,0} %dynamic-slice.775, f32[1,1024]{1,0} %dynamic-slice.774)
  %select.2632 = f32[1,1024]{1,0} select(pred[1,1024]{1,0} %broadcast.1586, f32[1,1024]{1,0} %add.3856, f32[1,1024]{1,0} %dynamic-slice.775)
  ROOT %dynamic-update-slice.763 = f32[256,1024]{1,0} dynamic-update-slice(f32[256,1024]{1,0} %param_0.8, f32[1,1024]{1,0} %select.2632, s32[] %reshape.2799, s32[] %constant.20359)
}

%and.reduce_sub_computation.1 (lhs.1: pred[], rhs.1: pred[]) -> pred[] {
  %lhs.1 = pred[] parameter(0)
  %rhs.1 = pred[] parameter(1)
  ROOT %and.18 = pred[] and(pred[] %lhs.1, pred[] %rhs.1)
}

%fused_computation.4 (param_0.12: s32[2]) -> pred[] {
  %constant.20363 = s32[] constant(0)
  %broadcast.1587 = s32[2]{0} broadcast(s32[] %constant.20363), dimensions={}
  %param_0.12 = s32[2]{0} parameter(0)
  %compare.2743 = pred[2]{0} compare(s32[2]{0} %broadcast.1587, s32[2]{0} %param_0.12), direction=LE
  %constant.20362 = s32[2]{0} constant({255, 0})
  %compare.2742 = pred[2]{0} compare(s32[2]{0} %constant.20362, s32[2]{0} %param_0.12), direction=GE
  %and.21 = pred[2]{0} and(pred[2]{0} %compare.2743, pred[2]{0} %compare.2742)
  %constant.20360 = pred[] constant(true)
  ROOT %reduce.282 = pred[] reduce(pred[2]{0} %and.21, pred[] %constant.20360), dimensions={0}, to_apply=%and.reduce_sub_computation.1
}

%fused_computation.5 (param_0.15: s32[512], param_1.27: s32[]) -> s32[2] {
  %param_0.15 = s32[512]{0} parameter(0)
  %param_1.27 = s32[] parameter(1)
  %dynamic-slice.777 = s32[1]{0} dynamic-slice(s32[512]{0} %param_0.15, s32[] %param_1.27), dynamic_slice_sizes={1}
  %constant.20364 = s32[1]{0} constant({0})
  ROOT %concatenate.227 = s32[2]{0} concatenate(s32[1]{0} %dynamic-slice.777, s32[1]{0} %constant.20364), dimensions={0}
}

%while_body.1 (param.2: (s32[], f32[256,1024], s32[512], f32[512,1024])) -> (s32[], f32[256,1024], s32[512], f32[512,1024]) {
  %param.2 = (s32[], f32[256,1024]{1,0}, s32[512]{0}, f32[512,1024]{1,0}) parameter(0)
  %get-tuple-element.28011 = s32[] get-tuple-element((s32[], f32[256,1024]{1,0}, s32[512]{0}, f32[512,1024]{1,0}) %param.2), index=0
  %copy.952 = s32[] copy(s32[] %get-tuple-element.28011)
  %constant.1134 = s32[] constant(1)
  %add.197 = s32[] add(s32[] %copy.952, s32[] %constant.1134)
  %get-tuple-element.28012 = f32[256,1024]{1,0} get-tuple-element((s32[], f32[256,1024]{1,0}, s32[512]{0}, f32[512,1024]{1,0}) %param.2), index=1
  %get-tuple-element.28014 = f32[512,1024]{1,0} get-tuple-element((s32[], f32[256,1024]{1,0}, s32[512]{0}, f32[512,1024]{1,0}) %param.2), index=3
  %get-tuple-element.28013 = s32[512]{0} get-tuple-element((s32[], f32[256,1024]{1,0}, s32[512]{0}, f32[512,1024]{1,0}) %param.2), index=2
  %fusion.5 = s32[2]{0} fusion(s32[512]{0} %get-tuple-element.28013, s32[] %copy.952), kind=kLoop, calls=%fused_computation.5
  %fusion.4 = pred[] fusion(s32[2]{0} %fusion.5), kind=kLoop, calls=%fused_computation.4
  %fusion.3 = f32[256,1024]{1,0} fusion(f32[256,1024]{1,0} %get-tuple-element.28012, f32[512,1024]{1,0} %get-tuple-element.28014, s32[] %copy.952, pred[] %fusion.4, s32[512]{0} %get-tuple-element.28013), kind=kLoop, calls=%fused_computation.3
  ROOT %tuple.1353 = (s32[], f32[256,1024]{1,0}, s32[512]{0}, f32[512,1024]{1,0}) tuple(s32[] %add.197, f32[256,1024]{1,0} %fusion.3, s32[512]{0} %get-tuple-element.28013, f32[512,1024]{1,0} %get-tuple-element.28014)
}

%while_cond.1 (param.3: (s32[], f32[256,1024], s32[512], f32[512,1024])) -> pred[] {
  %param.3 = (s32[], f32[256,1024]{1,0}, s32[512]{0}, f32[512,1024]{1,0}) parameter(0)
  %get-tuple-element.3543 = s32[] get-tuple-element((s32[], f32[256,1024]{1,0}, s32[512]{0}, f32[512,1024]{1,0}) %param.3), index=0
  %constant.1141 = s32[] constant(512)
  ROOT %compare.15 = pred[] compare(s32[] %get-tuple-element.3543, s32[] %constant.1141), direction=LT
}

%primitive_computation_add__1.13228 (parameter.13229: f32[], parameter.13230: f32[]) -> f32[] {
  %parameter.13229 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.13230 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.13231 = f32[] add(f32[] %parameter.13229, f32[] %parameter.13230), metadata={op_type="add" op_name="add"}
}

%primitive_computation_max.8155 (parameter.8156: f32[], parameter.8157: f32[]) -> f32[] {
  %parameter.8156 = f32[] parameter(0), metadata={op_type="max" op_name="max"}
  %parameter.8157 = f32[] parameter(1), metadata={op_type="max" op_name="max"}
  ROOT %maximum.8158 = f32[] maximum(f32[] %parameter.8156, f32[] %parameter.8157), metadata={op_type="max" op_name="max"}
}

%primitive_computation_add__1.8183 (parameter.8184: f32[], parameter.8185: f32[]) -> f32[] {
  %parameter.8184 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.8185 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.8186 = f32[] add(f32[] %parameter.8184, f32[] %parameter.8185), metadata={op_type="add" op_name="add"}
}

%primitive_computation_max.12878 (parameter.12879: f32[], parameter.12880: f32[]) -> f32[] {
  %parameter.12879 = f32[] parameter(0), metadata={op_type="max" op_name="max"}
  %parameter.12880 = f32[] parameter(1), metadata={op_type="max" op_name="max"}
  ROOT %maximum.12881 = f32[] maximum(f32[] %parameter.12879, f32[] %parameter.12880), metadata={op_type="max" op_name="max"}
}

%primitive_computation_add__1.12906 (parameter.12907: f32[], parameter.12908: f32[]) -> f32[] {
  %parameter.12907 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.12908 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.12909 = f32[] add(f32[] %parameter.12907, f32[] %parameter.12908), metadata={op_type="add" op_name="add"}
}

%primitive_computation_max.13106 (parameter.13107: f32[], parameter.13108: f32[]) -> f32[] {
  %parameter.13107 = f32[] parameter(0), metadata={op_type="max" op_name="max"}
  %parameter.13108 = f32[] parameter(1), metadata={op_type="max" op_name="max"}
  ROOT %maximum.13109 = f32[] maximum(f32[] %parameter.13107, f32[] %parameter.13108), metadata={op_type="max" op_name="max"}
}

%primitive_computation_add__1.13134 (parameter.13135: f32[], parameter.13136: f32[]) -> f32[] {
  %parameter.13135 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.13136 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.13137 = f32[] add(f32[] %parameter.13135, f32[] %parameter.13136), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.13247 (parameter.13248: f32[], parameter.13249: f32[]) -> f32[] {
  %parameter.13248 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.13249 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.13250 = f32[] add(f32[] %parameter.13248, f32[] %parameter.13249), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.15389 (parameter.15390: f32[], parameter.15391: f32[]) -> f32[] {
  %parameter.15390 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.15391 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.15392 = f32[] add(f32[] %parameter.15390, f32[] %parameter.15391), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.18530 (parameter.18531: f32[], parameter.18532: f32[]) -> f32[] {
  %parameter.18531 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.18532 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.18533 = f32[] add(f32[] %parameter.18531, f32[] %parameter.18532), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.18572 (parameter.18573: f32[], parameter.18574: f32[]) -> f32[] {
  %parameter.18573 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.18574 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.18575 = f32[] add(f32[] %parameter.18573, f32[] %parameter.18574), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.18604 (parameter.18605: f32[], parameter.18606: f32[]) -> f32[] {
  %parameter.18605 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.18606 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.18607 = f32[] add(f32[] %parameter.18605, f32[] %parameter.18606), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.18656 (parameter.18657: f32[], parameter.18658: f32[]) -> f32[] {
  %parameter.18657 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.18658 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.18659 = f32[] add(f32[] %parameter.18657, f32[] %parameter.18658), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.18698 (parameter.18699: f32[], parameter.18700: f32[]) -> f32[] {
  %parameter.18699 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.18700 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.18701 = f32[] add(f32[] %parameter.18699, f32[] %parameter.18700), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.18730 (parameter.18731: f32[], parameter.18732: f32[]) -> f32[] {
  %parameter.18731 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.18732 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.18733 = f32[] add(f32[] %parameter.18731, f32[] %parameter.18732), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.18782 (parameter.18783: f32[], parameter.18784: f32[]) -> f32[] {
  %parameter.18783 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.18784 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.18785 = f32[] add(f32[] %parameter.18783, f32[] %parameter.18784), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.18808 (parameter.18809: f32[], parameter.18810: f32[]) -> f32[] {
  %parameter.18809 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.18810 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.18811 = f32[] add(f32[] %parameter.18809, f32[] %parameter.18810), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.18860 (parameter.18861: f32[], parameter.18862: f32[]) -> f32[] {
  %parameter.18861 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.18862 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.18863 = f32[] add(f32[] %parameter.18861, f32[] %parameter.18862), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.18902 (parameter.18903: f32[], parameter.18904: f32[]) -> f32[] {
  %parameter.18903 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.18904 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.18905 = f32[] add(f32[] %parameter.18903, f32[] %parameter.18904), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.18934 (parameter.18935: f32[], parameter.18936: f32[]) -> f32[] {
  %parameter.18935 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.18936 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.18937 = f32[] add(f32[] %parameter.18935, f32[] %parameter.18936), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.18986 (parameter.18987: f32[], parameter.18988: f32[]) -> f32[] {
  %parameter.18987 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.18988 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.18989 = f32[] add(f32[] %parameter.18987, f32[] %parameter.18988), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.19012 (parameter.19013: f32[], parameter.19014: f32[]) -> f32[] {
  %parameter.19013 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.19014 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.19015 = f32[] add(f32[] %parameter.19013, f32[] %parameter.19014), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.19064 (parameter.19065: f32[], parameter.19066: f32[]) -> f32[] {
  %parameter.19065 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.19066 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.19067 = f32[] add(f32[] %parameter.19065, f32[] %parameter.19066), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.19106 (parameter.19107: f32[], parameter.19108: f32[]) -> f32[] {
  %parameter.19107 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.19108 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.19109 = f32[] add(f32[] %parameter.19107, f32[] %parameter.19108), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.19138 (parameter.19139: f32[], parameter.19140: f32[]) -> f32[] {
  %parameter.19139 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.19140 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.19141 = f32[] add(f32[] %parameter.19139, f32[] %parameter.19140), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.19190 (parameter.19191: f32[], parameter.19192: f32[]) -> f32[] {
  %parameter.19191 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.19192 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.19193 = f32[] add(f32[] %parameter.19191, f32[] %parameter.19192), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.19216 (parameter.19217: f32[], parameter.19218: f32[]) -> f32[] {
  %parameter.19217 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.19218 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.19219 = f32[] add(f32[] %parameter.19217, f32[] %parameter.19218), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.19268 (parameter.19269: f32[], parameter.19270: f32[]) -> f32[] {
  %parameter.19269 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.19270 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.19271 = f32[] add(f32[] %parameter.19269, f32[] %parameter.19270), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.19310 (parameter.19311: f32[], parameter.19312: f32[]) -> f32[] {
  %parameter.19311 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.19312 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.19313 = f32[] add(f32[] %parameter.19311, f32[] %parameter.19312), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.19342 (parameter.19343: f32[], parameter.19344: f32[]) -> f32[] {
  %parameter.19343 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.19344 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.19345 = f32[] add(f32[] %parameter.19343, f32[] %parameter.19344), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.19394 (parameter.19395: f32[], parameter.19396: f32[]) -> f32[] {
  %parameter.19395 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.19396 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.19397 = f32[] add(f32[] %parameter.19395, f32[] %parameter.19396), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.19420 (parameter.19421: f32[], parameter.19422: f32[]) -> f32[] {
  %parameter.19421 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.19422 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.19423 = f32[] add(f32[] %parameter.19421, f32[] %parameter.19422), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.19472 (parameter.19473: f32[], parameter.19474: f32[]) -> f32[] {
  %parameter.19473 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.19474 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.19475 = f32[] add(f32[] %parameter.19473, f32[] %parameter.19474), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.19488 (parameter.19489: f32[], parameter.19490: f32[]) -> f32[] {
  %parameter.19489 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.19490 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.19491 = f32[] add(f32[] %parameter.19489, f32[] %parameter.19490), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.19514 (parameter.19515: f32[], parameter.19516: f32[]) -> f32[] {
  %parameter.19515 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.19516 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.19517 = f32[] add(f32[] %parameter.19515, f32[] %parameter.19516), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.19502 (parameter.19503: f32[], parameter.19504: f32[]) -> f32[] {
  %parameter.19503 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.19504 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.19505 = f32[] add(f32[] %parameter.19503, f32[] %parameter.19504), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.19546 (parameter.19547: f32[], parameter.19548: f32[]) -> f32[] {
  %parameter.19547 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.19548 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.19549 = f32[] add(f32[] %parameter.19547, f32[] %parameter.19548), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.19598 (parameter.19599: f32[], parameter.19600: f32[]) -> f32[] {
  %parameter.19599 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.19600 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.19601 = f32[] add(f32[] %parameter.19599, f32[] %parameter.19600), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.19640 (parameter.19641: f32[], parameter.19642: f32[]) -> f32[] {
  %parameter.19641 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.19642 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.19643 = f32[] add(f32[] %parameter.19641, f32[] %parameter.19642), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.19672 (parameter.19673: f32[], parameter.19674: f32[]) -> f32[] {
  %parameter.19673 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.19674 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.19675 = f32[] add(f32[] %parameter.19673, f32[] %parameter.19674), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.19724 (parameter.19725: f32[], parameter.19726: f32[]) -> f32[] {
  %parameter.19725 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.19726 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.19727 = f32[] add(f32[] %parameter.19725, f32[] %parameter.19726), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.19750 (parameter.19751: f32[], parameter.19752: f32[]) -> f32[] {
  %parameter.19751 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.19752 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.19753 = f32[] add(f32[] %parameter.19751, f32[] %parameter.19752), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.19802 (parameter.19803: f32[], parameter.19804: f32[]) -> f32[] {
  %parameter.19803 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.19804 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.19805 = f32[] add(f32[] %parameter.19803, f32[] %parameter.19804), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.19818 (parameter.19819: f32[], parameter.19820: f32[]) -> f32[] {
  %parameter.19819 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.19820 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.19821 = f32[] add(f32[] %parameter.19819, f32[] %parameter.19820), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.19844 (parameter.19845: f32[], parameter.19846: f32[]) -> f32[] {
  %parameter.19845 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.19846 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.19847 = f32[] add(f32[] %parameter.19845, f32[] %parameter.19846), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.19832 (parameter.19833: f32[], parameter.19834: f32[]) -> f32[] {
  %parameter.19833 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.19834 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.19835 = f32[] add(f32[] %parameter.19833, f32[] %parameter.19834), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.19876 (parameter.19877: f32[], parameter.19878: f32[]) -> f32[] {
  %parameter.19877 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.19878 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.19879 = f32[] add(f32[] %parameter.19877, f32[] %parameter.19878), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.19928 (parameter.19929: f32[], parameter.19930: f32[]) -> f32[] {
  %parameter.19929 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.19930 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.19931 = f32[] add(f32[] %parameter.19929, f32[] %parameter.19930), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.19954 (parameter.19955: f32[], parameter.19956: f32[]) -> f32[] {
  %parameter.19955 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.19956 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.19957 = f32[] add(f32[] %parameter.19955, f32[] %parameter.19956), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.20006 (parameter.20007: f32[], parameter.20008: f32[]) -> f32[] {
  %parameter.20007 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.20008 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.20009 = f32[] add(f32[] %parameter.20007, f32[] %parameter.20008), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.20022 (parameter.20023: f32[], parameter.20024: f32[]) -> f32[] {
  %parameter.20023 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.20024 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.20025 = f32[] add(f32[] %parameter.20023, f32[] %parameter.20024), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.20048 (parameter.20049: f32[], parameter.20050: f32[]) -> f32[] {
  %parameter.20049 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.20050 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.20051 = f32[] add(f32[] %parameter.20049, f32[] %parameter.20050), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.20036 (parameter.20037: f32[], parameter.20038: f32[]) -> f32[] {
  %parameter.20037 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.20038 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.20039 = f32[] add(f32[] %parameter.20037, f32[] %parameter.20038), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.20080 (parameter.20081: f32[], parameter.20082: f32[]) -> f32[] {
  %parameter.20081 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.20082 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.20083 = f32[] add(f32[] %parameter.20081, f32[] %parameter.20082), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.20132 (parameter.20133: f32[], parameter.20134: f32[]) -> f32[] {
  %parameter.20133 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.20134 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.20135 = f32[] add(f32[] %parameter.20133, f32[] %parameter.20134), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.20158 (parameter.20159: f32[], parameter.20160: f32[]) -> f32[] {
  %parameter.20159 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.20160 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.20161 = f32[] add(f32[] %parameter.20159, f32[] %parameter.20160), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.20210 (parameter.20211: f32[], parameter.20212: f32[]) -> f32[] {
  %parameter.20211 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.20212 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.20213 = f32[] add(f32[] %parameter.20211, f32[] %parameter.20212), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.20226 (parameter.20227: f32[], parameter.20228: f32[]) -> f32[] {
  %parameter.20227 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.20228 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.20229 = f32[] add(f32[] %parameter.20227, f32[] %parameter.20228), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.20252 (parameter.20253: f32[], parameter.20254: f32[]) -> f32[] {
  %parameter.20253 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.20254 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.20255 = f32[] add(f32[] %parameter.20253, f32[] %parameter.20254), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.20240 (parameter.20241: f32[], parameter.20242: f32[]) -> f32[] {
  %parameter.20241 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.20242 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.20243 = f32[] add(f32[] %parameter.20241, f32[] %parameter.20242), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.20284 (parameter.20285: f32[], parameter.20286: f32[]) -> f32[] {
  %parameter.20285 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.20286 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.20287 = f32[] add(f32[] %parameter.20285, f32[] %parameter.20286), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.20336 (parameter.20337: f32[], parameter.20338: f32[]) -> f32[] {
  %parameter.20337 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.20338 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.20339 = f32[] add(f32[] %parameter.20337, f32[] %parameter.20338), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.20362 (parameter.20363: f32[], parameter.20364: f32[]) -> f32[] {
  %parameter.20363 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.20364 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.20365 = f32[] add(f32[] %parameter.20363, f32[] %parameter.20364), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.20414 (parameter.20415: f32[], parameter.20416: f32[]) -> f32[] {
  %parameter.20415 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.20416 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.20417 = f32[] add(f32[] %parameter.20415, f32[] %parameter.20416), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.20430 (parameter.20431: f32[], parameter.20432: f32[]) -> f32[] {
  %parameter.20431 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.20432 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.20433 = f32[] add(f32[] %parameter.20431, f32[] %parameter.20432), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.20456 (parameter.20457: f32[], parameter.20458: f32[]) -> f32[] {
  %parameter.20457 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.20458 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.20459 = f32[] add(f32[] %parameter.20457, f32[] %parameter.20458), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.20444 (parameter.20445: f32[], parameter.20446: f32[]) -> f32[] {
  %parameter.20445 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.20446 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.20447 = f32[] add(f32[] %parameter.20445, f32[] %parameter.20446), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.20488 (parameter.20489: f32[], parameter.20490: f32[]) -> f32[] {
  %parameter.20489 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.20490 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.20491 = f32[] add(f32[] %parameter.20489, f32[] %parameter.20490), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.20540 (parameter.20541: f32[], parameter.20542: f32[]) -> f32[] {
  %parameter.20541 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.20542 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.20543 = f32[] add(f32[] %parameter.20541, f32[] %parameter.20542), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.20566 (parameter.20567: f32[], parameter.20568: f32[]) -> f32[] {
  %parameter.20567 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.20568 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.20569 = f32[] add(f32[] %parameter.20567, f32[] %parameter.20568), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.20618 (parameter.20619: f32[], parameter.20620: f32[]) -> f32[] {
  %parameter.20619 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.20620 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.20621 = f32[] add(f32[] %parameter.20619, f32[] %parameter.20620), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.20660 (parameter.20661: f32[], parameter.20662: f32[]) -> f32[] {
  %parameter.20661 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.20662 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.20663 = f32[] add(f32[] %parameter.20661, f32[] %parameter.20662), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.20692 (parameter.20693: f32[], parameter.20694: f32[]) -> f32[] {
  %parameter.20693 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.20694 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.20695 = f32[] add(f32[] %parameter.20693, f32[] %parameter.20694), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.20744 (parameter.20745: f32[], parameter.20746: f32[]) -> f32[] {
  %parameter.20745 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.20746 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.20747 = f32[] add(f32[] %parameter.20745, f32[] %parameter.20746), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.20770 (parameter.20771: f32[], parameter.20772: f32[]) -> f32[] {
  %parameter.20771 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.20772 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.20773 = f32[] add(f32[] %parameter.20771, f32[] %parameter.20772), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.20822 (parameter.20823: f32[], parameter.20824: f32[]) -> f32[] {
  %parameter.20823 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.20824 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.20825 = f32[] add(f32[] %parameter.20823, f32[] %parameter.20824), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.20864 (parameter.20865: f32[], parameter.20866: f32[]) -> f32[] {
  %parameter.20865 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.20866 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.20867 = f32[] add(f32[] %parameter.20865, f32[] %parameter.20866), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.20896 (parameter.20897: f32[], parameter.20898: f32[]) -> f32[] {
  %parameter.20897 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.20898 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.20899 = f32[] add(f32[] %parameter.20897, f32[] %parameter.20898), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.20948 (parameter.20949: f32[], parameter.20950: f32[]) -> f32[] {
  %parameter.20949 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.20950 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.20951 = f32[] add(f32[] %parameter.20949, f32[] %parameter.20950), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.20974 (parameter.20975: f32[], parameter.20976: f32[]) -> f32[] {
  %parameter.20975 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.20976 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.20977 = f32[] add(f32[] %parameter.20975, f32[] %parameter.20976), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.21026 (parameter.21027: f32[], parameter.21028: f32[]) -> f32[] {
  %parameter.21027 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.21028 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.21029 = f32[] add(f32[] %parameter.21027, f32[] %parameter.21028), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.21068 (parameter.21069: f32[], parameter.21070: f32[]) -> f32[] {
  %parameter.21069 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.21070 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.21071 = f32[] add(f32[] %parameter.21069, f32[] %parameter.21070), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.21100 (parameter.21101: f32[], parameter.21102: f32[]) -> f32[] {
  %parameter.21101 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.21102 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.21103 = f32[] add(f32[] %parameter.21101, f32[] %parameter.21102), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.21152 (parameter.21153: f32[], parameter.21154: f32[]) -> f32[] {
  %parameter.21153 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.21154 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.21155 = f32[] add(f32[] %parameter.21153, f32[] %parameter.21154), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.21178 (parameter.21179: f32[], parameter.21180: f32[]) -> f32[] {
  %parameter.21179 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.21180 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.21181 = f32[] add(f32[] %parameter.21179, f32[] %parameter.21180), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.21230 (parameter.21231: f32[], parameter.21232: f32[]) -> f32[] {
  %parameter.21231 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.21232 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.21233 = f32[] add(f32[] %parameter.21231, f32[] %parameter.21232), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.21272 (parameter.21273: f32[], parameter.21274: f32[]) -> f32[] {
  %parameter.21273 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.21274 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.21275 = f32[] add(f32[] %parameter.21273, f32[] %parameter.21274), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.21304 (parameter.21305: f32[], parameter.21306: f32[]) -> f32[] {
  %parameter.21305 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.21306 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.21307 = f32[] add(f32[] %parameter.21305, f32[] %parameter.21306), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.21356 (parameter.21357: f32[], parameter.21358: f32[]) -> f32[] {
  %parameter.21357 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.21358 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.21359 = f32[] add(f32[] %parameter.21357, f32[] %parameter.21358), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.21382 (parameter.21383: f32[], parameter.21384: f32[]) -> f32[] {
  %parameter.21383 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.21384 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.21385 = f32[] add(f32[] %parameter.21383, f32[] %parameter.21384), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.21434 (parameter.21435: f32[], parameter.21436: f32[]) -> f32[] {
  %parameter.21435 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.21436 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.21437 = f32[] add(f32[] %parameter.21435, f32[] %parameter.21436), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.21450 (parameter.21451: f32[], parameter.21452: f32[]) -> f32[] {
  %parameter.21451 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.21452 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.21453 = f32[] add(f32[] %parameter.21451, f32[] %parameter.21452), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.21476 (parameter.21477: f32[], parameter.21478: f32[]) -> f32[] {
  %parameter.21477 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.21478 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.21479 = f32[] add(f32[] %parameter.21477, f32[] %parameter.21478), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.21464 (parameter.21465: f32[], parameter.21466: f32[]) -> f32[] {
  %parameter.21465 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.21466 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.21467 = f32[] add(f32[] %parameter.21465, f32[] %parameter.21466), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.21508 (parameter.21509: f32[], parameter.21510: f32[]) -> f32[] {
  %parameter.21509 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.21510 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.21511 = f32[] add(f32[] %parameter.21509, f32[] %parameter.21510), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.21560 (parameter.21561: f32[], parameter.21562: f32[]) -> f32[] {
  %parameter.21561 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.21562 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.21563 = f32[] add(f32[] %parameter.21561, f32[] %parameter.21562), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.21586 (parameter.21587: f32[], parameter.21588: f32[]) -> f32[] {
  %parameter.21587 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.21588 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.21589 = f32[] add(f32[] %parameter.21587, f32[] %parameter.21588), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.13186 (parameter.13187: f32[], parameter.13188: f32[]) -> f32[] {
  %parameter.13187 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.13188 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.13189 = f32[] add(f32[] %parameter.13187, f32[] %parameter.13188), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.15330 (parameter.15331: f32[], parameter.15332: f32[]) -> f32[] {
  %parameter.15331 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.15332 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.15333 = f32[] add(f32[] %parameter.15331, f32[] %parameter.15332), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.18546 (parameter.18547: f32[], parameter.18548: f32[]) -> f32[] {
  %parameter.18547 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.18548 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.18549 = f32[] add(f32[] %parameter.18547, f32[] %parameter.18548), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.18560 (parameter.18561: f32[], parameter.18562: f32[]) -> f32[] {
  %parameter.18561 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.18562 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.18563 = f32[] add(f32[] %parameter.18561, f32[] %parameter.18562), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.18672 (parameter.18673: f32[], parameter.18674: f32[]) -> f32[] {
  %parameter.18673 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.18674 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.18675 = f32[] add(f32[] %parameter.18673, f32[] %parameter.18674), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.18686 (parameter.18687: f32[], parameter.18688: f32[]) -> f32[] {
  %parameter.18687 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.18688 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.18689 = f32[] add(f32[] %parameter.18687, f32[] %parameter.18688), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.18876 (parameter.18877: f32[], parameter.18878: f32[]) -> f32[] {
  %parameter.18877 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.18878 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.18879 = f32[] add(f32[] %parameter.18877, f32[] %parameter.18878), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.18890 (parameter.18891: f32[], parameter.18892: f32[]) -> f32[] {
  %parameter.18891 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.18892 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.18893 = f32[] add(f32[] %parameter.18891, f32[] %parameter.18892), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.19080 (parameter.19081: f32[], parameter.19082: f32[]) -> f32[] {
  %parameter.19081 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.19082 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.19083 = f32[] add(f32[] %parameter.19081, f32[] %parameter.19082), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.19094 (parameter.19095: f32[], parameter.19096: f32[]) -> f32[] {
  %parameter.19095 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.19096 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.19097 = f32[] add(f32[] %parameter.19095, f32[] %parameter.19096), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.19284 (parameter.19285: f32[], parameter.19286: f32[]) -> f32[] {
  %parameter.19285 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.19286 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.19287 = f32[] add(f32[] %parameter.19285, f32[] %parameter.19286), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.19298 (parameter.19299: f32[], parameter.19300: f32[]) -> f32[] {
  %parameter.19299 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.19300 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.19301 = f32[] add(f32[] %parameter.19299, f32[] %parameter.19300), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.19614 (parameter.19615: f32[], parameter.19616: f32[]) -> f32[] {
  %parameter.19615 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.19616 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.19617 = f32[] add(f32[] %parameter.19615, f32[] %parameter.19616), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.19628 (parameter.19629: f32[], parameter.19630: f32[]) -> f32[] {
  %parameter.19629 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.19630 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.19631 = f32[] add(f32[] %parameter.19629, f32[] %parameter.19630), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.20634 (parameter.20635: f32[], parameter.20636: f32[]) -> f32[] {
  %parameter.20635 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.20636 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.20637 = f32[] add(f32[] %parameter.20635, f32[] %parameter.20636), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.20648 (parameter.20649: f32[], parameter.20650: f32[]) -> f32[] {
  %parameter.20649 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.20650 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.20651 = f32[] add(f32[] %parameter.20649, f32[] %parameter.20650), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.20838 (parameter.20839: f32[], parameter.20840: f32[]) -> f32[] {
  %parameter.20839 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.20840 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.20841 = f32[] add(f32[] %parameter.20839, f32[] %parameter.20840), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.20852 (parameter.20853: f32[], parameter.20854: f32[]) -> f32[] {
  %parameter.20853 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.20854 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.20855 = f32[] add(f32[] %parameter.20853, f32[] %parameter.20854), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.21042 (parameter.21043: f32[], parameter.21044: f32[]) -> f32[] {
  %parameter.21043 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.21044 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.21045 = f32[] add(f32[] %parameter.21043, f32[] %parameter.21044), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.21056 (parameter.21057: f32[], parameter.21058: f32[]) -> f32[] {
  %parameter.21057 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.21058 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.21059 = f32[] add(f32[] %parameter.21057, f32[] %parameter.21058), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.21246 (parameter.21247: f32[], parameter.21248: f32[]) -> f32[] {
  %parameter.21247 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.21248 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.21249 = f32[] add(f32[] %parameter.21247, f32[] %parameter.21248), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.21260 (parameter.21261: f32[], parameter.21262: f32[]) -> f32[] {
  %parameter.21261 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.21262 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.21263 = f32[] add(f32[] %parameter.21261, f32[] %parameter.21262), metadata={op_type="add" op_name="add"}
}

%primitive_computation_add__1.15426 (parameter.15427: f32[], parameter.15428: f32[]) -> f32[] {
  %parameter.15427 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.15428 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.15429 = f32[] add(f32[] %parameter.15427, f32[] %parameter.15428), metadata={op_type="add" op_name="add"}
}

%fused_computation.6 (param_0.18: u32[], param_1.33: u32[4], param_2.22: u32[2], param_3.17: u32[2], param_4.26: s32[]) -> u32[2] {
  %param_3.17 = u32[2]{0} parameter(3)
  %param_2.22 = u32[2]{0} parameter(2)
  %add.3863 = u32[2]{0} add(u32[2]{0} %param_3.17, u32[2]{0} %param_2.22), metadata={op_type="add" op_name="scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %param_1.33 = u32[4]{0} parameter(1)
  %slice.1182 = u32[1]{0} slice(u32[4]{0} %param_1.33), slice={[0:1]}, metadata={op_type="slice" op_name="scan/while/body/slice[ limit_indices=(1,)\n                       start_indices=(0,)\n                       strides=(1,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %reshape.2803 = u32[] reshape(u32[1]{0} %slice.1182), metadata={op_type="squeeze" op_name="scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %broadcast.1598 = u32[2]{0} broadcast(u32[] %reshape.2803), dimensions={}, metadata={op_type="shift_left" op_name="scan/while/body/shift_left" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %shift-left.99 = u32[2]{0} shift-left(u32[2]{0} %param_2.22, u32[2]{0} %broadcast.1598), metadata={op_type="shift_left" op_name="scan/while/body/shift_left" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %constant.20365 = u32[] constant(32), metadata={op_type="sub" op_name="scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %subtract.435 = u32[] subtract(u32[] %constant.20365, u32[] %reshape.2803), metadata={op_type="sub" op_name="scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %broadcast.1597 = u32[2]{0} broadcast(u32[] %subtract.435), dimensions={}, metadata={op_type="shift_right_logical" op_name="scan/while/body/shift_right_logical" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %shift-right-logical.118 = u32[2]{0} shift-right-logical(u32[2]{0} %param_2.22, u32[2]{0} %broadcast.1597), metadata={op_type="shift_right_logical" op_name="scan/while/body/shift_right_logical" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %or.102 = u32[2]{0} or(u32[2]{0} %shift-left.99, u32[2]{0} %shift-right-logical.118), metadata={op_type="or" op_name="scan/while/body/or" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %xor.289 = u32[2]{0} xor(u32[2]{0} %add.3863, u32[2]{0} %or.102), metadata={op_type="xor" op_name="scan/while/body/xor" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %add.3862 = u32[2]{0} add(u32[2]{0} %add.3863, u32[2]{0} %xor.289), metadata={op_type="add" op_name="scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %slice.1181 = u32[1]{0} slice(u32[4]{0} %param_1.33), slice={[1:2]}, metadata={op_type="slice" op_name="scan/while/body/slice[ limit_indices=(2,)\n                       start_indices=(1,)\n                       strides=(1,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %reshape.2802 = u32[] reshape(u32[1]{0} %slice.1181), metadata={op_type="squeeze" op_name="scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %broadcast.1596 = u32[2]{0} broadcast(u32[] %reshape.2802), dimensions={}, metadata={op_type="shift_left" op_name="scan/while/body/shift_left" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %shift-left.98 = u32[2]{0} shift-left(u32[2]{0} %xor.289, u32[2]{0} %broadcast.1596), metadata={op_type="shift_left" op_name="scan/while/body/shift_left" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %subtract.434 = u32[] subtract(u32[] %constant.20365, u32[] %reshape.2802), metadata={op_type="sub" op_name="scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %broadcast.1595 = u32[2]{0} broadcast(u32[] %subtract.434), dimensions={}, metadata={op_type="shift_right_logical" op_name="scan/while/body/shift_right_logical" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %shift-right-logical.117 = u32[2]{0} shift-right-logical(u32[2]{0} %xor.289, u32[2]{0} %broadcast.1595), metadata={op_type="shift_right_logical" op_name="scan/while/body/shift_right_logical" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %or.101 = u32[2]{0} or(u32[2]{0} %shift-left.98, u32[2]{0} %shift-right-logical.117), metadata={op_type="or" op_name="scan/while/body/or" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %xor.288 = u32[2]{0} xor(u32[2]{0} %add.3862, u32[2]{0} %or.101), metadata={op_type="xor" op_name="scan/while/body/xor" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %add.3860 = u32[2]{0} add(u32[2]{0} %add.3862, u32[2]{0} %xor.288), metadata={op_type="add" op_name="scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %slice.1180 = u32[1]{0} slice(u32[4]{0} %param_1.33), slice={[2:3]}, metadata={op_type="slice" op_name="scan/while/body/slice[ limit_indices=(3,)\n                       start_indices=(2,)\n                       strides=(1,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %reshape.2801 = u32[] reshape(u32[1]{0} %slice.1180), metadata={op_type="squeeze" op_name="scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %broadcast.1594 = u32[2]{0} broadcast(u32[] %reshape.2801), dimensions={}, metadata={op_type="shift_left" op_name="scan/while/body/shift_left" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %shift-left.97 = u32[2]{0} shift-left(u32[2]{0} %xor.288, u32[2]{0} %broadcast.1594), metadata={op_type="shift_left" op_name="scan/while/body/shift_left" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %subtract.433 = u32[] subtract(u32[] %constant.20365, u32[] %reshape.2801), metadata={op_type="sub" op_name="scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %broadcast.1593 = u32[2]{0} broadcast(u32[] %subtract.433), dimensions={}, metadata={op_type="shift_right_logical" op_name="scan/while/body/shift_right_logical" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %shift-right-logical.116 = u32[2]{0} shift-right-logical(u32[2]{0} %xor.288, u32[2]{0} %broadcast.1593), metadata={op_type="shift_right_logical" op_name="scan/while/body/shift_right_logical" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %or.100 = u32[2]{0} or(u32[2]{0} %shift-left.97, u32[2]{0} %shift-right-logical.116), metadata={op_type="or" op_name="scan/while/body/or" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %xor.287 = u32[2]{0} xor(u32[2]{0} %add.3860, u32[2]{0} %or.100), metadata={op_type="xor" op_name="scan/while/body/xor" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %add.3859 = u32[2]{0} add(u32[2]{0} %add.3860, u32[2]{0} %xor.287), metadata={op_type="add" op_name="scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %slice.1179 = u32[1]{0} slice(u32[4]{0} %param_1.33), slice={[3:4]}, metadata={op_type="slice" op_name="scan/while/body/slice[ limit_indices=(4,)\n                       start_indices=(3,)\n                       strides=(1,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %reshape.2800 = u32[] reshape(u32[1]{0} %slice.1179), metadata={op_type="squeeze" op_name="scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %broadcast.1592 = u32[2]{0} broadcast(u32[] %reshape.2800), dimensions={}, metadata={op_type="shift_left" op_name="scan/while/body/shift_left" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %shift-left.96 = u32[2]{0} shift-left(u32[2]{0} %xor.287, u32[2]{0} %broadcast.1592), metadata={op_type="shift_left" op_name="scan/while/body/shift_left" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %subtract.432 = u32[] subtract(u32[] %constant.20365, u32[] %reshape.2800), metadata={op_type="sub" op_name="scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %broadcast.1590 = u32[2]{0} broadcast(u32[] %subtract.432), dimensions={}, metadata={op_type="shift_right_logical" op_name="scan/while/body/shift_right_logical" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %shift-right-logical.115 = u32[2]{0} shift-right-logical(u32[2]{0} %xor.287, u32[2]{0} %broadcast.1590), metadata={op_type="shift_right_logical" op_name="scan/while/body/shift_right_logical" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %or.99 = u32[2]{0} or(u32[2]{0} %shift-left.96, u32[2]{0} %shift-right-logical.115), metadata={op_type="or" op_name="scan/while/body/or" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %xor.286 = u32[2]{0} xor(u32[2]{0} %add.3859, u32[2]{0} %or.99), metadata={op_type="xor" op_name="scan/while/body/xor" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %param_0.18 = u32[] parameter(0)
  %broadcast.1589 = u32[2]{0} broadcast(u32[] %param_0.18), dimensions={}, metadata={op_type="add" op_name="scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %add.3858 = u32[2]{0} add(u32[2]{0} %xor.286, u32[2]{0} %broadcast.1589), metadata={op_type="add" op_name="scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %param_4.26 = s32[] parameter(4)
  %constant.20366 = s32[] constant(1), metadata={op_type="add" op_name="scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %add.3864 = s32[] add(s32[] %param_4.26, s32[] %constant.20366), metadata={op_type="add" op_name="scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %convert.66 = u32[] convert(s32[] %add.3864), metadata={op_type="convert_element_type" op_name="scan/while/body/convert_element_type[ new_dtype=uint32\n                                      weak_type=False ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %broadcast.1588 = u32[2]{0} broadcast(u32[] %convert.66), dimensions={}, metadata={op_type="add" op_name="scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  ROOT %add.3857 = u32[2]{0} add(u32[2]{0} %add.3858, u32[2]{0} %broadcast.1588), metadata={op_type="add" op_name="scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
}

%fused_computation.7 (param_0.20: u32[], param_1.39: u32[4], param_2.30: u32[2], param_3.27: u32[2]) -> u32[2] {
  %param_3.27 = u32[2]{0} parameter(3)
  %param_2.30 = u32[2]{0} parameter(2)
  %add.3870 = u32[2]{0} add(u32[2]{0} %param_3.27, u32[2]{0} %param_2.30), metadata={op_type="add" op_name="scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %param_1.39 = u32[4]{0} parameter(1)
  %slice.1185 = u32[1]{0} slice(u32[4]{0} %param_1.39), slice={[0:1]}, metadata={op_type="slice" op_name="scan/while/body/slice[ limit_indices=(1,)\n                       start_indices=(0,)\n                       strides=(1,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %reshape.2806 = u32[] reshape(u32[1]{0} %slice.1185), metadata={op_type="squeeze" op_name="scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %broadcast.1605 = u32[2]{0} broadcast(u32[] %reshape.2806), dimensions={}, metadata={op_type="shift_left" op_name="scan/while/body/shift_left" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %shift-left.102 = u32[2]{0} shift-left(u32[2]{0} %param_2.30, u32[2]{0} %broadcast.1605), metadata={op_type="shift_left" op_name="scan/while/body/shift_left" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %constant.20368 = u32[] constant(32), metadata={op_type="sub" op_name="scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %subtract.438 = u32[] subtract(u32[] %constant.20368, u32[] %reshape.2806), metadata={op_type="sub" op_name="scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %broadcast.1604 = u32[2]{0} broadcast(u32[] %subtract.438), dimensions={}, metadata={op_type="shift_right_logical" op_name="scan/while/body/shift_right_logical" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %shift-right-logical.121 = u32[2]{0} shift-right-logical(u32[2]{0} %param_2.30, u32[2]{0} %broadcast.1604), metadata={op_type="shift_right_logical" op_name="scan/while/body/shift_right_logical" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %or.105 = u32[2]{0} or(u32[2]{0} %shift-left.102, u32[2]{0} %shift-right-logical.121), metadata={op_type="or" op_name="scan/while/body/or" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %xor.292 = u32[2]{0} xor(u32[2]{0} %add.3870, u32[2]{0} %or.105), metadata={op_type="xor" op_name="scan/while/body/xor" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %add.3868 = u32[2]{0} add(u32[2]{0} %add.3870, u32[2]{0} %xor.292), metadata={op_type="add" op_name="scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %slice.1184 = u32[1]{0} slice(u32[4]{0} %param_1.39), slice={[1:2]}, metadata={op_type="slice" op_name="scan/while/body/slice[ limit_indices=(2,)\n                       start_indices=(1,)\n                       strides=(1,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %reshape.2805 = u32[] reshape(u32[1]{0} %slice.1184), metadata={op_type="squeeze" op_name="scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %broadcast.1603 = u32[2]{0} broadcast(u32[] %reshape.2805), dimensions={}, metadata={op_type="shift_left" op_name="scan/while/body/shift_left" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %shift-left.101 = u32[2]{0} shift-left(u32[2]{0} %xor.292, u32[2]{0} %broadcast.1603), metadata={op_type="shift_left" op_name="scan/while/body/shift_left" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %subtract.437 = u32[] subtract(u32[] %constant.20368, u32[] %reshape.2805), metadata={op_type="sub" op_name="scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %broadcast.1602 = u32[2]{0} broadcast(u32[] %subtract.437), dimensions={}, metadata={op_type="shift_right_logical" op_name="scan/while/body/shift_right_logical" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %shift-right-logical.120 = u32[2]{0} shift-right-logical(u32[2]{0} %xor.292, u32[2]{0} %broadcast.1602), metadata={op_type="shift_right_logical" op_name="scan/while/body/shift_right_logical" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %or.104 = u32[2]{0} or(u32[2]{0} %shift-left.101, u32[2]{0} %shift-right-logical.120), metadata={op_type="or" op_name="scan/while/body/or" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %xor.291 = u32[2]{0} xor(u32[2]{0} %add.3868, u32[2]{0} %or.104), metadata={op_type="xor" op_name="scan/while/body/xor" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %add.3867 = u32[2]{0} add(u32[2]{0} %add.3868, u32[2]{0} %xor.291), metadata={op_type="add" op_name="scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %slice.1183 = u32[1]{0} slice(u32[4]{0} %param_1.39), slice={[2:3]}, metadata={op_type="slice" op_name="scan/while/body/slice[ limit_indices=(3,)\n                       start_indices=(2,)\n                       strides=(1,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %reshape.2804 = u32[] reshape(u32[1]{0} %slice.1183), metadata={op_type="squeeze" op_name="scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %broadcast.1601 = u32[2]{0} broadcast(u32[] %reshape.2804), dimensions={}, metadata={op_type="shift_left" op_name="scan/while/body/shift_left" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %shift-left.100 = u32[2]{0} shift-left(u32[2]{0} %xor.291, u32[2]{0} %broadcast.1601), metadata={op_type="shift_left" op_name="scan/while/body/shift_left" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %subtract.436 = u32[] subtract(u32[] %constant.20368, u32[] %reshape.2804), metadata={op_type="sub" op_name="scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %broadcast.1600 = u32[2]{0} broadcast(u32[] %subtract.436), dimensions={}, metadata={op_type="shift_right_logical" op_name="scan/while/body/shift_right_logical" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %shift-right-logical.119 = u32[2]{0} shift-right-logical(u32[2]{0} %xor.291, u32[2]{0} %broadcast.1600), metadata={op_type="shift_right_logical" op_name="scan/while/body/shift_right_logical" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %or.103 = u32[2]{0} or(u32[2]{0} %shift-left.100, u32[2]{0} %shift-right-logical.119), metadata={op_type="or" op_name="scan/while/body/or" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %xor.290 = u32[2]{0} xor(u32[2]{0} %add.3867, u32[2]{0} %or.103), metadata={op_type="xor" op_name="scan/while/body/xor" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %add.3866 = u32[2]{0} add(u32[2]{0} %add.3867, u32[2]{0} %xor.290), metadata={op_type="add" op_name="scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %param_0.20 = u32[] parameter(0)
  %broadcast.1599 = u32[2]{0} broadcast(u32[] %param_0.20), dimensions={}, metadata={op_type="add" op_name="scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  ROOT %add.3865 = u32[2]{0} add(u32[2]{0} %add.3866, u32[2]{0} %broadcast.1599), metadata={op_type="add" op_name="scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
}

%body_computation__140.172.clone.clone.clone (parameter.24: (s32[], u32[2], u32[2], u32[], u32[], /*index=5*/u32[], u32[4], u32[4])) -> (s32[], u32[2], u32[2], u32[], u32[], /*index=5*/u32[], u32[4], u32[4]) {
  %parameter.24 = (s32[], u32[2]{0}, u32[2]{0}, u32[], u32[], /*index=5*/u32[], u32[4]{0}, u32[4]{0}) parameter(0)
  %get-tuple-element.27082 = s32[] get-tuple-element((s32[], u32[2]{0}, u32[2]{0}, u32[], u32[], /*index=5*/u32[], u32[4]{0}, u32[4]{0}) %parameter.24), index=0
  %copy.445 = s32[] copy(s32[] %get-tuple-element.27082)
  %constant.10273 = s32[] constant(1), metadata={op_type="add" op_name="scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %add.1344 = s32[] add(s32[] %copy.445, s32[] %constant.10273), metadata={op_type="add" op_name="scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.27085 = u32[] get-tuple-element((s32[], u32[2]{0}, u32[2]{0}, u32[], u32[], /*index=5*/u32[], u32[4]{0}, u32[4]{0}) %parameter.24), index=3
  %copy.448 = u32[] copy(u32[] %get-tuple-element.27085)
  %get-tuple-element.27088 = u32[4]{0} get-tuple-element((s32[], u32[2]{0}, u32[2]{0}, u32[], u32[], /*index=5*/u32[], u32[4]{0}, u32[4]{0}) %parameter.24), index=6
  %copy.451 = u32[4]{0} copy(u32[4]{0} %get-tuple-element.27088)
  %get-tuple-element.27084 = u32[2]{0} get-tuple-element((s32[], u32[2]{0}, u32[2]{0}, u32[], u32[], /*index=5*/u32[], u32[4]{0}, u32[4]{0}) %parameter.24), index=2
  %copy.447 = u32[2]{0} copy(u32[2]{0} %get-tuple-element.27084)
  %get-tuple-element.27083 = u32[2]{0} get-tuple-element((s32[], u32[2]{0}, u32[2]{0}, u32[], u32[], /*index=5*/u32[], u32[4]{0}, u32[4]{0}) %parameter.24), index=1
  %copy.446 = u32[2]{0} copy(u32[2]{0} %get-tuple-element.27083)
  %fusion.7 = u32[2]{0} fusion(u32[] %copy.448, u32[4]{0} %copy.451, u32[2]{0} %copy.447, u32[2]{0} %copy.446), kind=kLoop, calls=%fused_computation.7, metadata={op_type="add" op_name="scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %get-tuple-element.27086 = u32[] get-tuple-element((s32[], u32[2]{0}, u32[2]{0}, u32[], u32[], /*index=5*/u32[], u32[4]{0}, u32[4]{0}) %parameter.24), index=4
  %copy.449 = u32[] copy(u32[] %get-tuple-element.27086)
  %fusion.6 = u32[2]{0} fusion(u32[] %copy.449, u32[4]{0} %copy.451, u32[2]{0} %copy.447, u32[2]{0} %copy.446, s32[] %copy.445), kind=kLoop, calls=%fused_computation.6, metadata={op_type="add" op_name="scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %copy.456 = u32[] copy(u32[] %copy.449), control-predecessors={%copy.448}
  %get-tuple-element.27087 = u32[] get-tuple-element((s32[], u32[2]{0}, u32[2]{0}, u32[], u32[], /*index=5*/u32[], u32[4]{0}, u32[4]{0}) %parameter.24), index=5
  %copy.450 = u32[] copy(u32[] %get-tuple-element.27087)
  %copy.457 = u32[] copy(u32[] %copy.450), control-predecessors={%copy.449}
  %copy.458 = u32[] copy(u32[] %copy.448), control-predecessors={%copy.450}
  %get-tuple-element.27089 = u32[4]{0} get-tuple-element((s32[], u32[2]{0}, u32[2]{0}, u32[], u32[], /*index=5*/u32[], u32[4]{0}, u32[4]{0}) %parameter.24), index=7
  %copy.452 = u32[4]{0} copy(u32[4]{0} %get-tuple-element.27089)
  %copy.459 = u32[4]{0} copy(u32[4]{0} %copy.452), control-predecessors={%copy.451}
  %copy.460 = u32[4]{0} copy(u32[4]{0} %copy.451), control-predecessors={%copy.452}
  ROOT %tuple.1284 = (s32[], u32[2]{0}, u32[2]{0}, u32[], u32[], /*index=5*/u32[], u32[4]{0}, u32[4]{0}) tuple(s32[] %add.1344, u32[2]{0} %fusion.7, u32[2]{0} %fusion.6, u32[] %copy.456, u32[] %copy.457, /*index=5*/u32[] %copy.458, u32[4]{0} %copy.459, u32[4]{0} %copy.460)
}

%cond_computation__140.242.clone.clone (parameter.25: (s32[], u32[2], u32[2], u32[], u32[], /*index=5*/u32[], u32[4], u32[4])) -> pred[] {
  %parameter.25 = (s32[], u32[2]{0}, u32[2]{0}, u32[], u32[], /*index=5*/u32[], u32[4]{0}, u32[4]{0}) parameter(0)
  %get-tuple-element.15057 = s32[] get-tuple-element((s32[], u32[2]{0}, u32[2]{0}, u32[], u32[], /*index=5*/u32[], u32[4]{0}, u32[4]{0}) %parameter.25), index=0
  %constant.10277 = s32[] constant(5), metadata={op_type="lt" op_name="scan/while/cond/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %compare.1601 = pred[] compare(s32[] %get-tuple-element.15057, s32[] %constant.10277), direction=LT, metadata={op_type="lt" op_name="scan/while/cond/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.8 (param_0.23: u32[], param_1.45: u32[4], param_2.37: u32[11], param_3.35: u32[11], param_4.55: s32[]) -> u32[11] {
  %param_3.35 = u32[11]{0} parameter(3)
  %param_2.37 = u32[11]{0} parameter(2)
  %add.3877 = u32[11]{0} add(u32[11]{0} %param_3.35, u32[11]{0} %param_2.37), metadata={op_type="add" op_name="scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %param_1.45 = u32[4]{0} parameter(1)
  %slice.1189 = u32[1]{0} slice(u32[4]{0} %param_1.45), slice={[0:1]}, metadata={op_type="slice" op_name="scan/while/body/slice[ limit_indices=(1,)\n                       start_indices=(0,)\n                       strides=(1,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %reshape.2810 = u32[] reshape(u32[1]{0} %slice.1189), metadata={op_type="squeeze" op_name="scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %broadcast.1616 = u32[11]{0} broadcast(u32[] %reshape.2810), dimensions={}, metadata={op_type="shift_left" op_name="scan/while/body/shift_left" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %shift-left.106 = u32[11]{0} shift-left(u32[11]{0} %param_2.37, u32[11]{0} %broadcast.1616), metadata={op_type="shift_left" op_name="scan/while/body/shift_left" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %constant.20369 = u32[] constant(32), metadata={op_type="sub" op_name="scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %subtract.442 = u32[] subtract(u32[] %constant.20369, u32[] %reshape.2810), metadata={op_type="sub" op_name="scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %broadcast.1615 = u32[11]{0} broadcast(u32[] %subtract.442), dimensions={}, metadata={op_type="shift_right_logical" op_name="scan/while/body/shift_right_logical" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %shift-right-logical.125 = u32[11]{0} shift-right-logical(u32[11]{0} %param_2.37, u32[11]{0} %broadcast.1615), metadata={op_type="shift_right_logical" op_name="scan/while/body/shift_right_logical" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %or.109 = u32[11]{0} or(u32[11]{0} %shift-left.106, u32[11]{0} %shift-right-logical.125), metadata={op_type="or" op_name="scan/while/body/or" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %xor.296 = u32[11]{0} xor(u32[11]{0} %add.3877, u32[11]{0} %or.109), metadata={op_type="xor" op_name="scan/while/body/xor" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %add.3876 = u32[11]{0} add(u32[11]{0} %add.3877, u32[11]{0} %xor.296), metadata={op_type="add" op_name="scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %slice.1188 = u32[1]{0} slice(u32[4]{0} %param_1.45), slice={[1:2]}, metadata={op_type="slice" op_name="scan/while/body/slice[ limit_indices=(2,)\n                       start_indices=(1,)\n                       strides=(1,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %reshape.2809 = u32[] reshape(u32[1]{0} %slice.1188), metadata={op_type="squeeze" op_name="scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %broadcast.1613 = u32[11]{0} broadcast(u32[] %reshape.2809), dimensions={}, metadata={op_type="shift_left" op_name="scan/while/body/shift_left" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %shift-left.105 = u32[11]{0} shift-left(u32[11]{0} %xor.296, u32[11]{0} %broadcast.1613), metadata={op_type="shift_left" op_name="scan/while/body/shift_left" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %subtract.441 = u32[] subtract(u32[] %constant.20369, u32[] %reshape.2809), metadata={op_type="sub" op_name="scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %broadcast.1612 = u32[11]{0} broadcast(u32[] %subtract.441), dimensions={}, metadata={op_type="shift_right_logical" op_name="scan/while/body/shift_right_logical" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %shift-right-logical.124 = u32[11]{0} shift-right-logical(u32[11]{0} %xor.296, u32[11]{0} %broadcast.1612), metadata={op_type="shift_right_logical" op_name="scan/while/body/shift_right_logical" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %or.108 = u32[11]{0} or(u32[11]{0} %shift-left.105, u32[11]{0} %shift-right-logical.124), metadata={op_type="or" op_name="scan/while/body/or" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %xor.295 = u32[11]{0} xor(u32[11]{0} %add.3876, u32[11]{0} %or.108), metadata={op_type="xor" op_name="scan/while/body/xor" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %add.3875 = u32[11]{0} add(u32[11]{0} %add.3876, u32[11]{0} %xor.295), metadata={op_type="add" op_name="scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %slice.1187 = u32[1]{0} slice(u32[4]{0} %param_1.45), slice={[2:3]}, metadata={op_type="slice" op_name="scan/while/body/slice[ limit_indices=(3,)\n                       start_indices=(2,)\n                       strides=(1,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %reshape.2808 = u32[] reshape(u32[1]{0} %slice.1187), metadata={op_type="squeeze" op_name="scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %broadcast.1611 = u32[11]{0} broadcast(u32[] %reshape.2808), dimensions={}, metadata={op_type="shift_left" op_name="scan/while/body/shift_left" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %shift-left.104 = u32[11]{0} shift-left(u32[11]{0} %xor.295, u32[11]{0} %broadcast.1611), metadata={op_type="shift_left" op_name="scan/while/body/shift_left" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %subtract.440 = u32[] subtract(u32[] %constant.20369, u32[] %reshape.2808), metadata={op_type="sub" op_name="scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %broadcast.1610 = u32[11]{0} broadcast(u32[] %subtract.440), dimensions={}, metadata={op_type="shift_right_logical" op_name="scan/while/body/shift_right_logical" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %shift-right-logical.123 = u32[11]{0} shift-right-logical(u32[11]{0} %xor.295, u32[11]{0} %broadcast.1610), metadata={op_type="shift_right_logical" op_name="scan/while/body/shift_right_logical" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %or.107 = u32[11]{0} or(u32[11]{0} %shift-left.104, u32[11]{0} %shift-right-logical.123), metadata={op_type="or" op_name="scan/while/body/or" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %xor.294 = u32[11]{0} xor(u32[11]{0} %add.3875, u32[11]{0} %or.107), metadata={op_type="xor" op_name="scan/while/body/xor" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %add.3873 = u32[11]{0} add(u32[11]{0} %add.3875, u32[11]{0} %xor.294), metadata={op_type="add" op_name="scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %slice.1186 = u32[1]{0} slice(u32[4]{0} %param_1.45), slice={[3:4]}, metadata={op_type="slice" op_name="scan/while/body/slice[ limit_indices=(4,)\n                       start_indices=(3,)\n                       strides=(1,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %reshape.2807 = u32[] reshape(u32[1]{0} %slice.1186), metadata={op_type="squeeze" op_name="scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %broadcast.1609 = u32[11]{0} broadcast(u32[] %reshape.2807), dimensions={}, metadata={op_type="shift_left" op_name="scan/while/body/shift_left" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %shift-left.103 = u32[11]{0} shift-left(u32[11]{0} %xor.294, u32[11]{0} %broadcast.1609), metadata={op_type="shift_left" op_name="scan/while/body/shift_left" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %subtract.439 = u32[] subtract(u32[] %constant.20369, u32[] %reshape.2807), metadata={op_type="sub" op_name="scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %broadcast.1608 = u32[11]{0} broadcast(u32[] %subtract.439), dimensions={}, metadata={op_type="shift_right_logical" op_name="scan/while/body/shift_right_logical" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %shift-right-logical.122 = u32[11]{0} shift-right-logical(u32[11]{0} %xor.294, u32[11]{0} %broadcast.1608), metadata={op_type="shift_right_logical" op_name="scan/while/body/shift_right_logical" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %or.106 = u32[11]{0} or(u32[11]{0} %shift-left.103, u32[11]{0} %shift-right-logical.122), metadata={op_type="or" op_name="scan/while/body/or" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %xor.293 = u32[11]{0} xor(u32[11]{0} %add.3873, u32[11]{0} %or.106), metadata={op_type="xor" op_name="scan/while/body/xor" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %param_0.23 = u32[] parameter(0)
  %broadcast.1607 = u32[11]{0} broadcast(u32[] %param_0.23), dimensions={}, metadata={op_type="add" op_name="scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %add.3872 = u32[11]{0} add(u32[11]{0} %xor.293, u32[11]{0} %broadcast.1607), metadata={op_type="add" op_name="scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %param_4.55 = s32[] parameter(4)
  %constant.20370 = s32[] constant(1), metadata={op_type="add" op_name="scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %add.3878 = s32[] add(s32[] %param_4.55, s32[] %constant.20370), metadata={op_type="add" op_name="scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %convert.67 = u32[] convert(s32[] %add.3878), metadata={op_type="convert_element_type" op_name="scan/while/body/convert_element_type[ new_dtype=uint32\n                                      weak_type=False ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %broadcast.1606 = u32[11]{0} broadcast(u32[] %convert.67), dimensions={}, metadata={op_type="add" op_name="scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  ROOT %add.3871 = u32[11]{0} add(u32[11]{0} %add.3872, u32[11]{0} %broadcast.1606), metadata={op_type="add" op_name="scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
}

%fused_computation.9 (param_0.25: u32[], param_1.51: u32[4], param_2.45: u32[11], param_3.45: u32[11]) -> u32[11] {
  %param_3.45 = u32[11]{0} parameter(3)
  %param_2.45 = u32[11]{0} parameter(2)
  %add.3883 = u32[11]{0} add(u32[11]{0} %param_3.45, u32[11]{0} %param_2.45), metadata={op_type="add" op_name="scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %param_1.51 = u32[4]{0} parameter(1)
  %slice.1192 = u32[1]{0} slice(u32[4]{0} %param_1.51), slice={[0:1]}, metadata={op_type="slice" op_name="scan/while/body/slice[ limit_indices=(1,)\n                       start_indices=(0,)\n                       strides=(1,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %reshape.2813 = u32[] reshape(u32[1]{0} %slice.1192), metadata={op_type="squeeze" op_name="scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %broadcast.1623 = u32[11]{0} broadcast(u32[] %reshape.2813), dimensions={}, metadata={op_type="shift_left" op_name="scan/while/body/shift_left" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %shift-left.109 = u32[11]{0} shift-left(u32[11]{0} %param_2.45, u32[11]{0} %broadcast.1623), metadata={op_type="shift_left" op_name="scan/while/body/shift_left" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %constant.20372 = u32[] constant(32), metadata={op_type="sub" op_name="scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %subtract.445 = u32[] subtract(u32[] %constant.20372, u32[] %reshape.2813), metadata={op_type="sub" op_name="scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %broadcast.1622 = u32[11]{0} broadcast(u32[] %subtract.445), dimensions={}, metadata={op_type="shift_right_logical" op_name="scan/while/body/shift_right_logical" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %shift-right-logical.128 = u32[11]{0} shift-right-logical(u32[11]{0} %param_2.45, u32[11]{0} %broadcast.1622), metadata={op_type="shift_right_logical" op_name="scan/while/body/shift_right_logical" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %or.112 = u32[11]{0} or(u32[11]{0} %shift-left.109, u32[11]{0} %shift-right-logical.128), metadata={op_type="or" op_name="scan/while/body/or" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %xor.299 = u32[11]{0} xor(u32[11]{0} %add.3883, u32[11]{0} %or.112), metadata={op_type="xor" op_name="scan/while/body/xor" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %add.3882 = u32[11]{0} add(u32[11]{0} %add.3883, u32[11]{0} %xor.299), metadata={op_type="add" op_name="scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %slice.1191 = u32[1]{0} slice(u32[4]{0} %param_1.51), slice={[1:2]}, metadata={op_type="slice" op_name="scan/while/body/slice[ limit_indices=(2,)\n                       start_indices=(1,)\n                       strides=(1,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %reshape.2812 = u32[] reshape(u32[1]{0} %slice.1191), metadata={op_type="squeeze" op_name="scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %broadcast.1621 = u32[11]{0} broadcast(u32[] %reshape.2812), dimensions={}, metadata={op_type="shift_left" op_name="scan/while/body/shift_left" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %shift-left.108 = u32[11]{0} shift-left(u32[11]{0} %xor.299, u32[11]{0} %broadcast.1621), metadata={op_type="shift_left" op_name="scan/while/body/shift_left" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %subtract.444 = u32[] subtract(u32[] %constant.20372, u32[] %reshape.2812), metadata={op_type="sub" op_name="scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %broadcast.1620 = u32[11]{0} broadcast(u32[] %subtract.444), dimensions={}, metadata={op_type="shift_right_logical" op_name="scan/while/body/shift_right_logical" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %shift-right-logical.127 = u32[11]{0} shift-right-logical(u32[11]{0} %xor.299, u32[11]{0} %broadcast.1620), metadata={op_type="shift_right_logical" op_name="scan/while/body/shift_right_logical" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %or.111 = u32[11]{0} or(u32[11]{0} %shift-left.108, u32[11]{0} %shift-right-logical.127), metadata={op_type="or" op_name="scan/while/body/or" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %xor.298 = u32[11]{0} xor(u32[11]{0} %add.3882, u32[11]{0} %or.111), metadata={op_type="xor" op_name="scan/while/body/xor" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %add.3881 = u32[11]{0} add(u32[11]{0} %add.3882, u32[11]{0} %xor.298), metadata={op_type="add" op_name="scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %slice.1190 = u32[1]{0} slice(u32[4]{0} %param_1.51), slice={[2:3]}, metadata={op_type="slice" op_name="scan/while/body/slice[ limit_indices=(3,)\n                       start_indices=(2,)\n                       strides=(1,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %reshape.2811 = u32[] reshape(u32[1]{0} %slice.1190), metadata={op_type="squeeze" op_name="scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %broadcast.1619 = u32[11]{0} broadcast(u32[] %reshape.2811), dimensions={}, metadata={op_type="shift_left" op_name="scan/while/body/shift_left" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %shift-left.107 = u32[11]{0} shift-left(u32[11]{0} %xor.298, u32[11]{0} %broadcast.1619), metadata={op_type="shift_left" op_name="scan/while/body/shift_left" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %subtract.443 = u32[] subtract(u32[] %constant.20372, u32[] %reshape.2811), metadata={op_type="sub" op_name="scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %broadcast.1618 = u32[11]{0} broadcast(u32[] %subtract.443), dimensions={}, metadata={op_type="shift_right_logical" op_name="scan/while/body/shift_right_logical" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %shift-right-logical.126 = u32[11]{0} shift-right-logical(u32[11]{0} %xor.298, u32[11]{0} %broadcast.1618), metadata={op_type="shift_right_logical" op_name="scan/while/body/shift_right_logical" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %or.110 = u32[11]{0} or(u32[11]{0} %shift-left.107, u32[11]{0} %shift-right-logical.126), metadata={op_type="or" op_name="scan/while/body/or" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %xor.297 = u32[11]{0} xor(u32[11]{0} %add.3881, u32[11]{0} %or.110), metadata={op_type="xor" op_name="scan/while/body/xor" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %add.3880 = u32[11]{0} add(u32[11]{0} %add.3881, u32[11]{0} %xor.297), metadata={op_type="add" op_name="scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %param_0.25 = u32[] parameter(0)
  %broadcast.1617 = u32[11]{0} broadcast(u32[] %param_0.25), dimensions={}, metadata={op_type="add" op_name="scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  ROOT %add.3879 = u32[11]{0} add(u32[11]{0} %add.3880, u32[11]{0} %broadcast.1617), metadata={op_type="add" op_name="scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
}

%body_computation__141.328.clone.clone.clone (parameter.26: (s32[], u32[11], u32[11], u32[], u32[], /*index=5*/u32[], u32[4], u32[4])) -> (s32[], u32[11], u32[11], u32[], u32[], /*index=5*/u32[], u32[4], u32[4]) {
  %parameter.26 = (s32[], u32[11]{0}, u32[11]{0}, u32[], u32[], /*index=5*/u32[], u32[4]{0}, u32[4]{0}) parameter(0)
  %get-tuple-element.27106 = s32[] get-tuple-element((s32[], u32[11]{0}, u32[11]{0}, u32[], u32[], /*index=5*/u32[], u32[4]{0}, u32[4]{0}) %parameter.26), index=0
  %copy.469 = s32[] copy(s32[] %get-tuple-element.27106)
  %constant.10284 = s32[] constant(1), metadata={op_type="add" op_name="scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %add.1354 = s32[] add(s32[] %copy.469, s32[] %constant.10284), metadata={op_type="add" op_name="scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.27109 = u32[] get-tuple-element((s32[], u32[11]{0}, u32[11]{0}, u32[], u32[], /*index=5*/u32[], u32[4]{0}, u32[4]{0}) %parameter.26), index=3
  %copy.472 = u32[] copy(u32[] %get-tuple-element.27109)
  %get-tuple-element.27112 = u32[4]{0} get-tuple-element((s32[], u32[11]{0}, u32[11]{0}, u32[], u32[], /*index=5*/u32[], u32[4]{0}, u32[4]{0}) %parameter.26), index=6
  %copy.475 = u32[4]{0} copy(u32[4]{0} %get-tuple-element.27112)
  %get-tuple-element.27108 = u32[11]{0} get-tuple-element((s32[], u32[11]{0}, u32[11]{0}, u32[], u32[], /*index=5*/u32[], u32[4]{0}, u32[4]{0}) %parameter.26), index=2
  %copy.471 = u32[11]{0} copy(u32[11]{0} %get-tuple-element.27108)
  %get-tuple-element.27107 = u32[11]{0} get-tuple-element((s32[], u32[11]{0}, u32[11]{0}, u32[], u32[], /*index=5*/u32[], u32[4]{0}, u32[4]{0}) %parameter.26), index=1
  %copy.470 = u32[11]{0} copy(u32[11]{0} %get-tuple-element.27107)
  %fusion.9 = u32[11]{0} fusion(u32[] %copy.472, u32[4]{0} %copy.475, u32[11]{0} %copy.471, u32[11]{0} %copy.470), kind=kLoop, calls=%fused_computation.9, metadata={op_type="add" op_name="scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %get-tuple-element.27110 = u32[] get-tuple-element((s32[], u32[11]{0}, u32[11]{0}, u32[], u32[], /*index=5*/u32[], u32[4]{0}, u32[4]{0}) %parameter.26), index=4
  %copy.473 = u32[] copy(u32[] %get-tuple-element.27110)
  %fusion.8 = u32[11]{0} fusion(u32[] %copy.473, u32[4]{0} %copy.475, u32[11]{0} %copy.471, u32[11]{0} %copy.470, s32[] %copy.469), kind=kLoop, calls=%fused_computation.8, metadata={op_type="add" op_name="scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %copy.480 = u32[] copy(u32[] %copy.473), control-predecessors={%copy.472}
  %get-tuple-element.27111 = u32[] get-tuple-element((s32[], u32[11]{0}, u32[11]{0}, u32[], u32[], /*index=5*/u32[], u32[4]{0}, u32[4]{0}) %parameter.26), index=5
  %copy.474 = u32[] copy(u32[] %get-tuple-element.27111)
  %copy.481 = u32[] copy(u32[] %copy.474), control-predecessors={%copy.473}
  %copy.482 = u32[] copy(u32[] %copy.472), control-predecessors={%copy.474}
  %get-tuple-element.27113 = u32[4]{0} get-tuple-element((s32[], u32[11]{0}, u32[11]{0}, u32[], u32[], /*index=5*/u32[], u32[4]{0}, u32[4]{0}) %parameter.26), index=7
  %copy.476 = u32[4]{0} copy(u32[4]{0} %get-tuple-element.27113)
  %copy.483 = u32[4]{0} copy(u32[4]{0} %copy.476), control-predecessors={%copy.475}
  %copy.484 = u32[4]{0} copy(u32[4]{0} %copy.475), control-predecessors={%copy.476}
  ROOT %tuple.1288 = (s32[], u32[11]{0}, u32[11]{0}, u32[], u32[], /*index=5*/u32[], u32[4]{0}, u32[4]{0}) tuple(s32[] %add.1354, u32[11]{0} %fusion.9, u32[11]{0} %fusion.8, u32[] %copy.480, u32[] %copy.481, /*index=5*/u32[] %copy.482, u32[4]{0} %copy.483, u32[4]{0} %copy.484)
}

%cond_computation__141.398.clone.clone (parameter.27: (s32[], u32[11], u32[11], u32[], u32[], /*index=5*/u32[], u32[4], u32[4])) -> pred[] {
  %parameter.27 = (s32[], u32[11]{0}, u32[11]{0}, u32[], u32[], /*index=5*/u32[], u32[4]{0}, u32[4]{0}) parameter(0)
  %get-tuple-element.15109 = s32[] get-tuple-element((s32[], u32[11]{0}, u32[11]{0}, u32[], u32[], /*index=5*/u32[], u32[4]{0}, u32[4]{0}) %parameter.27), index=0
  %constant.10291 = s32[] constant(5), metadata={op_type="lt" op_name="scan/while/cond/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %compare.1602 = pred[] compare(s32[] %get-tuple-element.15109, s32[] %constant.10291), direction=LT, metadata={op_type="lt" op_name="scan/while/cond/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.10 (param_0.28: u32[], param_1.57: u32[4], param_2.52: u32[2], param_3.53: u32[2], param_4.84: s32[]) -> u32[2] {
  %param_3.53 = u32[2]{0} parameter(3)
  %param_2.52 = u32[2]{0} parameter(2)
  %add.3889 = u32[2]{0} add(u32[2]{0} %param_3.53, u32[2]{0} %param_2.52), metadata={op_type="add" op_name="scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %param_1.57 = u32[4]{0} parameter(1)
  %slice.1196 = u32[1]{0} slice(u32[4]{0} %param_1.57), slice={[0:1]}, metadata={op_type="slice" op_name="scan/while/body/slice[ limit_indices=(1,)\n                       start_indices=(0,)\n                       strides=(1,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %reshape.2817 = u32[] reshape(u32[1]{0} %slice.1196), metadata={op_type="squeeze" op_name="scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %broadcast.1633 = u32[2]{0} broadcast(u32[] %reshape.2817), dimensions={}, metadata={op_type="shift_left" op_name="scan/while/body/shift_left" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %shift-left.113 = u32[2]{0} shift-left(u32[2]{0} %param_2.52, u32[2]{0} %broadcast.1633), metadata={op_type="shift_left" op_name="scan/while/body/shift_left" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %constant.20373 = u32[] constant(32), metadata={op_type="sub" op_name="scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %subtract.449 = u32[] subtract(u32[] %constant.20373, u32[] %reshape.2817), metadata={op_type="sub" op_name="scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %broadcast.1632 = u32[2]{0} broadcast(u32[] %subtract.449), dimensions={}, metadata={op_type="shift_right_logical" op_name="scan/while/body/shift_right_logical" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %shift-right-logical.132 = u32[2]{0} shift-right-logical(u32[2]{0} %param_2.52, u32[2]{0} %broadcast.1632), metadata={op_type="shift_right_logical" op_name="scan/while/body/shift_right_logical" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %or.116 = u32[2]{0} or(u32[2]{0} %shift-left.113, u32[2]{0} %shift-right-logical.132), metadata={op_type="or" op_name="scan/while/body/or" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %xor.303 = u32[2]{0} xor(u32[2]{0} %add.3889, u32[2]{0} %or.116), metadata={op_type="xor" op_name="scan/while/body/xor" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %add.3888 = u32[2]{0} add(u32[2]{0} %add.3889, u32[2]{0} %xor.303), metadata={op_type="add" op_name="scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %slice.1195 = u32[1]{0} slice(u32[4]{0} %param_1.57), slice={[1:2]}, metadata={op_type="slice" op_name="scan/while/body/slice[ limit_indices=(2,)\n                       start_indices=(1,)\n                       strides=(1,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %reshape.2816 = u32[] reshape(u32[1]{0} %slice.1195), metadata={op_type="squeeze" op_name="scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %broadcast.1631 = u32[2]{0} broadcast(u32[] %reshape.2816), dimensions={}, metadata={op_type="shift_left" op_name="scan/while/body/shift_left" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %shift-left.112 = u32[2]{0} shift-left(u32[2]{0} %xor.303, u32[2]{0} %broadcast.1631), metadata={op_type="shift_left" op_name="scan/while/body/shift_left" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %subtract.448 = u32[] subtract(u32[] %constant.20373, u32[] %reshape.2816), metadata={op_type="sub" op_name="scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %broadcast.1630 = u32[2]{0} broadcast(u32[] %subtract.448), dimensions={}, metadata={op_type="shift_right_logical" op_name="scan/while/body/shift_right_logical" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %shift-right-logical.131 = u32[2]{0} shift-right-logical(u32[2]{0} %xor.303, u32[2]{0} %broadcast.1630), metadata={op_type="shift_right_logical" op_name="scan/while/body/shift_right_logical" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %or.115 = u32[2]{0} or(u32[2]{0} %shift-left.112, u32[2]{0} %shift-right-logical.131), metadata={op_type="or" op_name="scan/while/body/or" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %xor.302 = u32[2]{0} xor(u32[2]{0} %add.3888, u32[2]{0} %or.115), metadata={op_type="xor" op_name="scan/while/body/xor" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %add.3887 = u32[2]{0} add(u32[2]{0} %add.3888, u32[2]{0} %xor.302), metadata={op_type="add" op_name="scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %slice.1194 = u32[1]{0} slice(u32[4]{0} %param_1.57), slice={[2:3]}, metadata={op_type="slice" op_name="scan/while/body/slice[ limit_indices=(3,)\n                       start_indices=(2,)\n                       strides=(1,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %reshape.2815 = u32[] reshape(u32[1]{0} %slice.1194), metadata={op_type="squeeze" op_name="scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %broadcast.1629 = u32[2]{0} broadcast(u32[] %reshape.2815), dimensions={}, metadata={op_type="shift_left" op_name="scan/while/body/shift_left" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %shift-left.111 = u32[2]{0} shift-left(u32[2]{0} %xor.302, u32[2]{0} %broadcast.1629), metadata={op_type="shift_left" op_name="scan/while/body/shift_left" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %subtract.447 = u32[] subtract(u32[] %constant.20373, u32[] %reshape.2815), metadata={op_type="sub" op_name="scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %broadcast.1628 = u32[2]{0} broadcast(u32[] %subtract.447), dimensions={}, metadata={op_type="shift_right_logical" op_name="scan/while/body/shift_right_logical" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %shift-right-logical.130 = u32[2]{0} shift-right-logical(u32[2]{0} %xor.302, u32[2]{0} %broadcast.1628), metadata={op_type="shift_right_logical" op_name="scan/while/body/shift_right_logical" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %or.114 = u32[2]{0} or(u32[2]{0} %shift-left.111, u32[2]{0} %shift-right-logical.130), metadata={op_type="or" op_name="scan/while/body/or" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %xor.301 = u32[2]{0} xor(u32[2]{0} %add.3887, u32[2]{0} %or.114), metadata={op_type="xor" op_name="scan/while/body/xor" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %add.3886 = u32[2]{0} add(u32[2]{0} %add.3887, u32[2]{0} %xor.301), metadata={op_type="add" op_name="scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %slice.1193 = u32[1]{0} slice(u32[4]{0} %param_1.57), slice={[3:4]}, metadata={op_type="slice" op_name="scan/while/body/slice[ limit_indices=(4,)\n                       start_indices=(3,)\n                       strides=(1,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %reshape.2814 = u32[] reshape(u32[1]{0} %slice.1193), metadata={op_type="squeeze" op_name="scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %broadcast.1627 = u32[2]{0} broadcast(u32[] %reshape.2814), dimensions={}, metadata={op_type="shift_left" op_name="scan/while/body/shift_left" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %shift-left.110 = u32[2]{0} shift-left(u32[2]{0} %xor.301, u32[2]{0} %broadcast.1627), metadata={op_type="shift_left" op_name="scan/while/body/shift_left" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %subtract.446 = u32[] subtract(u32[] %constant.20373, u32[] %reshape.2814), metadata={op_type="sub" op_name="scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %broadcast.1626 = u32[2]{0} broadcast(u32[] %subtract.446), dimensions={}, metadata={op_type="shift_right_logical" op_name="scan/while/body/shift_right_logical" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %shift-right-logical.129 = u32[2]{0} shift-right-logical(u32[2]{0} %xor.301, u32[2]{0} %broadcast.1626), metadata={op_type="shift_right_logical" op_name="scan/while/body/shift_right_logical" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %or.113 = u32[2]{0} or(u32[2]{0} %shift-left.110, u32[2]{0} %shift-right-logical.129), metadata={op_type="or" op_name="scan/while/body/or" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %xor.300 = u32[2]{0} xor(u32[2]{0} %add.3886, u32[2]{0} %or.113), metadata={op_type="xor" op_name="scan/while/body/xor" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %param_0.28 = u32[] parameter(0)
  %broadcast.1625 = u32[2]{0} broadcast(u32[] %param_0.28), dimensions={}, metadata={op_type="add" op_name="scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %add.3885 = u32[2]{0} add(u32[2]{0} %xor.300, u32[2]{0} %broadcast.1625), metadata={op_type="add" op_name="scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %param_4.84 = s32[] parameter(4)
  %constant.20374 = s32[] constant(1), metadata={op_type="add" op_name="scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %add.3890 = s32[] add(s32[] %param_4.84, s32[] %constant.20374), metadata={op_type="add" op_name="scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %convert.68 = u32[] convert(s32[] %add.3890), metadata={op_type="convert_element_type" op_name="scan/while/body/convert_element_type[ new_dtype=uint32\n                                      weak_type=False ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %broadcast.1624 = u32[2]{0} broadcast(u32[] %convert.68), dimensions={}, metadata={op_type="add" op_name="scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  ROOT %add.3884 = u32[2]{0} add(u32[2]{0} %add.3885, u32[2]{0} %broadcast.1624), metadata={op_type="add" op_name="scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
}

%fused_computation.11 (param_0.30: u32[], param_1.63: u32[4], param_2.60: u32[2], param_3.63: u32[2]) -> u32[2] {
  %param_3.63 = u32[2]{0} parameter(3)
  %param_2.60 = u32[2]{0} parameter(2)
  %add.3895 = u32[2]{0} add(u32[2]{0} %param_3.63, u32[2]{0} %param_2.60), metadata={op_type="add" op_name="scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %param_1.63 = u32[4]{0} parameter(1)
  %slice.1199 = u32[1]{0} slice(u32[4]{0} %param_1.63), slice={[0:1]}, metadata={op_type="slice" op_name="scan/while/body/slice[ limit_indices=(1,)\n                       start_indices=(0,)\n                       strides=(1,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %reshape.2820 = u32[] reshape(u32[1]{0} %slice.1199), metadata={op_type="squeeze" op_name="scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %broadcast.1641 = u32[2]{0} broadcast(u32[] %reshape.2820), dimensions={}, metadata={op_type="shift_left" op_name="scan/while/body/shift_left" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %shift-left.116 = u32[2]{0} shift-left(u32[2]{0} %param_2.60, u32[2]{0} %broadcast.1641), metadata={op_type="shift_left" op_name="scan/while/body/shift_left" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %constant.20375 = u32[] constant(32), metadata={op_type="sub" op_name="scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %subtract.452 = u32[] subtract(u32[] %constant.20375, u32[] %reshape.2820), metadata={op_type="sub" op_name="scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %broadcast.1640 = u32[2]{0} broadcast(u32[] %subtract.452), dimensions={}, metadata={op_type="shift_right_logical" op_name="scan/while/body/shift_right_logical" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %shift-right-logical.135 = u32[2]{0} shift-right-logical(u32[2]{0} %param_2.60, u32[2]{0} %broadcast.1640), metadata={op_type="shift_right_logical" op_name="scan/while/body/shift_right_logical" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %or.119 = u32[2]{0} or(u32[2]{0} %shift-left.116, u32[2]{0} %shift-right-logical.135), metadata={op_type="or" op_name="scan/while/body/or" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %xor.306 = u32[2]{0} xor(u32[2]{0} %add.3895, u32[2]{0} %or.119), metadata={op_type="xor" op_name="scan/while/body/xor" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %add.3894 = u32[2]{0} add(u32[2]{0} %add.3895, u32[2]{0} %xor.306), metadata={op_type="add" op_name="scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %slice.1198 = u32[1]{0} slice(u32[4]{0} %param_1.63), slice={[1:2]}, metadata={op_type="slice" op_name="scan/while/body/slice[ limit_indices=(2,)\n                       start_indices=(1,)\n                       strides=(1,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %reshape.2819 = u32[] reshape(u32[1]{0} %slice.1198), metadata={op_type="squeeze" op_name="scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %broadcast.1639 = u32[2]{0} broadcast(u32[] %reshape.2819), dimensions={}, metadata={op_type="shift_left" op_name="scan/while/body/shift_left" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %shift-left.115 = u32[2]{0} shift-left(u32[2]{0} %xor.306, u32[2]{0} %broadcast.1639), metadata={op_type="shift_left" op_name="scan/while/body/shift_left" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %subtract.451 = u32[] subtract(u32[] %constant.20375, u32[] %reshape.2819), metadata={op_type="sub" op_name="scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %broadcast.1638 = u32[2]{0} broadcast(u32[] %subtract.451), dimensions={}, metadata={op_type="shift_right_logical" op_name="scan/while/body/shift_right_logical" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %shift-right-logical.134 = u32[2]{0} shift-right-logical(u32[2]{0} %xor.306, u32[2]{0} %broadcast.1638), metadata={op_type="shift_right_logical" op_name="scan/while/body/shift_right_logical" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %or.118 = u32[2]{0} or(u32[2]{0} %shift-left.115, u32[2]{0} %shift-right-logical.134), metadata={op_type="or" op_name="scan/while/body/or" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %xor.305 = u32[2]{0} xor(u32[2]{0} %add.3894, u32[2]{0} %or.118), metadata={op_type="xor" op_name="scan/while/body/xor" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %add.3893 = u32[2]{0} add(u32[2]{0} %add.3894, u32[2]{0} %xor.305), metadata={op_type="add" op_name="scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %slice.1197 = u32[1]{0} slice(u32[4]{0} %param_1.63), slice={[2:3]}, metadata={op_type="slice" op_name="scan/while/body/slice[ limit_indices=(3,)\n                       start_indices=(2,)\n                       strides=(1,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %reshape.2818 = u32[] reshape(u32[1]{0} %slice.1197), metadata={op_type="squeeze" op_name="scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %broadcast.1636 = u32[2]{0} broadcast(u32[] %reshape.2818), dimensions={}, metadata={op_type="shift_left" op_name="scan/while/body/shift_left" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %shift-left.114 = u32[2]{0} shift-left(u32[2]{0} %xor.305, u32[2]{0} %broadcast.1636), metadata={op_type="shift_left" op_name="scan/while/body/shift_left" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %subtract.450 = u32[] subtract(u32[] %constant.20375, u32[] %reshape.2818), metadata={op_type="sub" op_name="scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %broadcast.1635 = u32[2]{0} broadcast(u32[] %subtract.450), dimensions={}, metadata={op_type="shift_right_logical" op_name="scan/while/body/shift_right_logical" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %shift-right-logical.133 = u32[2]{0} shift-right-logical(u32[2]{0} %xor.305, u32[2]{0} %broadcast.1635), metadata={op_type="shift_right_logical" op_name="scan/while/body/shift_right_logical" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %or.117 = u32[2]{0} or(u32[2]{0} %shift-left.114, u32[2]{0} %shift-right-logical.133), metadata={op_type="or" op_name="scan/while/body/or" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %xor.304 = u32[2]{0} xor(u32[2]{0} %add.3893, u32[2]{0} %or.117), metadata={op_type="xor" op_name="scan/while/body/xor" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %add.3892 = u32[2]{0} add(u32[2]{0} %add.3893, u32[2]{0} %xor.304), metadata={op_type="add" op_name="scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %param_0.30 = u32[] parameter(0)
  %broadcast.1634 = u32[2]{0} broadcast(u32[] %param_0.30), dimensions={}, metadata={op_type="add" op_name="scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  ROOT %add.3891 = u32[2]{0} add(u32[2]{0} %add.3892, u32[2]{0} %broadcast.1634), metadata={op_type="add" op_name="scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
}

%body_computation__166.6495.clone.clone.clone (parameter.28: (s32[], u32[2], u32[2], u32[], u32[], /*index=5*/u32[], u32[4], u32[4])) -> (s32[], u32[2], u32[2], u32[], u32[], /*index=5*/u32[], u32[4], u32[4]) {
  %parameter.28 = (s32[], u32[2]{0}, u32[2]{0}, u32[], u32[], /*index=5*/u32[], u32[4]{0}, u32[4]{0}) parameter(0)
  %get-tuple-element.27130 = s32[] get-tuple-element((s32[], u32[2]{0}, u32[2]{0}, u32[], u32[], /*index=5*/u32[], u32[4]{0}, u32[4]{0}) %parameter.28), index=0
  %copy.493 = s32[] copy(s32[] %get-tuple-element.27130)
  %constant.10308 = s32[] constant(1), metadata={op_type="add" op_name="scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %add.1364 = s32[] add(s32[] %copy.493, s32[] %constant.10308), metadata={op_type="add" op_name="scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.27133 = u32[] get-tuple-element((s32[], u32[2]{0}, u32[2]{0}, u32[], u32[], /*index=5*/u32[], u32[4]{0}, u32[4]{0}) %parameter.28), index=3
  %copy.496 = u32[] copy(u32[] %get-tuple-element.27133)
  %get-tuple-element.27136 = u32[4]{0} get-tuple-element((s32[], u32[2]{0}, u32[2]{0}, u32[], u32[], /*index=5*/u32[], u32[4]{0}, u32[4]{0}) %parameter.28), index=6
  %copy.499 = u32[4]{0} copy(u32[4]{0} %get-tuple-element.27136)
  %get-tuple-element.27132 = u32[2]{0} get-tuple-element((s32[], u32[2]{0}, u32[2]{0}, u32[], u32[], /*index=5*/u32[], u32[4]{0}, u32[4]{0}) %parameter.28), index=2
  %copy.495 = u32[2]{0} copy(u32[2]{0} %get-tuple-element.27132)
  %get-tuple-element.27131 = u32[2]{0} get-tuple-element((s32[], u32[2]{0}, u32[2]{0}, u32[], u32[], /*index=5*/u32[], u32[4]{0}, u32[4]{0}) %parameter.28), index=1
  %copy.494 = u32[2]{0} copy(u32[2]{0} %get-tuple-element.27131)
  %fusion.11 = u32[2]{0} fusion(u32[] %copy.496, u32[4]{0} %copy.499, u32[2]{0} %copy.495, u32[2]{0} %copy.494), kind=kLoop, calls=%fused_computation.11, metadata={op_type="add" op_name="scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %get-tuple-element.27134 = u32[] get-tuple-element((s32[], u32[2]{0}, u32[2]{0}, u32[], u32[], /*index=5*/u32[], u32[4]{0}, u32[4]{0}) %parameter.28), index=4
  %copy.497 = u32[] copy(u32[] %get-tuple-element.27134)
  %fusion.10 = u32[2]{0} fusion(u32[] %copy.497, u32[4]{0} %copy.499, u32[2]{0} %copy.495, u32[2]{0} %copy.494, s32[] %copy.493), kind=kLoop, calls=%fused_computation.10, metadata={op_type="add" op_name="scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %copy.504 = u32[] copy(u32[] %copy.497), control-predecessors={%copy.496}
  %get-tuple-element.27135 = u32[] get-tuple-element((s32[], u32[2]{0}, u32[2]{0}, u32[], u32[], /*index=5*/u32[], u32[4]{0}, u32[4]{0}) %parameter.28), index=5
  %copy.498 = u32[] copy(u32[] %get-tuple-element.27135)
  %copy.505 = u32[] copy(u32[] %copy.498), control-predecessors={%copy.497}
  %copy.506 = u32[] copy(u32[] %copy.496), control-predecessors={%copy.498}
  %get-tuple-element.27137 = u32[4]{0} get-tuple-element((s32[], u32[2]{0}, u32[2]{0}, u32[], u32[], /*index=5*/u32[], u32[4]{0}, u32[4]{0}) %parameter.28), index=7
  %copy.500 = u32[4]{0} copy(u32[4]{0} %get-tuple-element.27137)
  %copy.507 = u32[4]{0} copy(u32[4]{0} %copy.500), control-predecessors={%copy.499}
  %copy.508 = u32[4]{0} copy(u32[4]{0} %copy.499), control-predecessors={%copy.500}
  ROOT %tuple.1291 = (s32[], u32[2]{0}, u32[2]{0}, u32[], u32[], /*index=5*/u32[], u32[4]{0}, u32[4]{0}) tuple(s32[] %add.1364, u32[2]{0} %fusion.11, u32[2]{0} %fusion.10, u32[] %copy.504, u32[] %copy.505, /*index=5*/u32[] %copy.506, u32[4]{0} %copy.507, u32[4]{0} %copy.508)
}

%cond_computation__166.6565.clone.clone (parameter.29: (s32[], u32[2], u32[2], u32[], u32[], /*index=5*/u32[], u32[4], u32[4])) -> pred[] {
  %parameter.29 = (s32[], u32[2]{0}, u32[2]{0}, u32[], u32[], /*index=5*/u32[], u32[4]{0}, u32[4]{0}) parameter(0)
  %get-tuple-element.15161 = s32[] get-tuple-element((s32[], u32[2]{0}, u32[2]{0}, u32[], u32[], /*index=5*/u32[], u32[4]{0}, u32[4]{0}) %parameter.29), index=0
  %constant.10312 = s32[] constant(5), metadata={op_type="lt" op_name="scan/while/cond/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %compare.1603 = pred[] compare(s32[] %get-tuple-element.15161, s32[] %constant.10312), direction=LT, metadata={op_type="lt" op_name="scan/while/cond/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.12 (param_0.33: u32[], param_1.69: u32[4], param_2.67: u32[2], param_3.71: u32[2], param_4.113: s32[]) -> u32[2] {
  %param_3.71 = u32[2]{0} parameter(3)
  %param_2.67 = u32[2]{0} parameter(2)
  %add.3901 = u32[2]{0} add(u32[2]{0} %param_3.71, u32[2]{0} %param_2.67), metadata={op_type="add" op_name="scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %param_1.69 = u32[4]{0} parameter(1)
  %slice.1203 = u32[1]{0} slice(u32[4]{0} %param_1.69), slice={[0:1]}, metadata={op_type="slice" op_name="scan/while/body/slice[ limit_indices=(1,)\n                       start_indices=(0,)\n                       strides=(1,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %reshape.2824 = u32[] reshape(u32[1]{0} %slice.1203), metadata={op_type="squeeze" op_name="scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %broadcast.1651 = u32[2]{0} broadcast(u32[] %reshape.2824), dimensions={}, metadata={op_type="shift_left" op_name="scan/while/body/shift_left" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %shift-left.120 = u32[2]{0} shift-left(u32[2]{0} %param_2.67, u32[2]{0} %broadcast.1651), metadata={op_type="shift_left" op_name="scan/while/body/shift_left" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %constant.20376 = u32[] constant(32), metadata={op_type="sub" op_name="scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %subtract.456 = u32[] subtract(u32[] %constant.20376, u32[] %reshape.2824), metadata={op_type="sub" op_name="scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %broadcast.1650 = u32[2]{0} broadcast(u32[] %subtract.456), dimensions={}, metadata={op_type="shift_right_logical" op_name="scan/while/body/shift_right_logical" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %shift-right-logical.139 = u32[2]{0} shift-right-logical(u32[2]{0} %param_2.67, u32[2]{0} %broadcast.1650), metadata={op_type="shift_right_logical" op_name="scan/while/body/shift_right_logical" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %or.123 = u32[2]{0} or(u32[2]{0} %shift-left.120, u32[2]{0} %shift-right-logical.139), metadata={op_type="or" op_name="scan/while/body/or" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %xor.310 = u32[2]{0} xor(u32[2]{0} %add.3901, u32[2]{0} %or.123), metadata={op_type="xor" op_name="scan/while/body/xor" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %add.3900 = u32[2]{0} add(u32[2]{0} %add.3901, u32[2]{0} %xor.310), metadata={op_type="add" op_name="scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %slice.1202 = u32[1]{0} slice(u32[4]{0} %param_1.69), slice={[1:2]}, metadata={op_type="slice" op_name="scan/while/body/slice[ limit_indices=(2,)\n                       start_indices=(1,)\n                       strides=(1,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %reshape.2823 = u32[] reshape(u32[1]{0} %slice.1202), metadata={op_type="squeeze" op_name="scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %broadcast.1649 = u32[2]{0} broadcast(u32[] %reshape.2823), dimensions={}, metadata={op_type="shift_left" op_name="scan/while/body/shift_left" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %shift-left.119 = u32[2]{0} shift-left(u32[2]{0} %xor.310, u32[2]{0} %broadcast.1649), metadata={op_type="shift_left" op_name="scan/while/body/shift_left" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %subtract.455 = u32[] subtract(u32[] %constant.20376, u32[] %reshape.2823), metadata={op_type="sub" op_name="scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %broadcast.1648 = u32[2]{0} broadcast(u32[] %subtract.455), dimensions={}, metadata={op_type="shift_right_logical" op_name="scan/while/body/shift_right_logical" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %shift-right-logical.138 = u32[2]{0} shift-right-logical(u32[2]{0} %xor.310, u32[2]{0} %broadcast.1648), metadata={op_type="shift_right_logical" op_name="scan/while/body/shift_right_logical" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %or.122 = u32[2]{0} or(u32[2]{0} %shift-left.119, u32[2]{0} %shift-right-logical.138), metadata={op_type="or" op_name="scan/while/body/or" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %xor.309 = u32[2]{0} xor(u32[2]{0} %add.3900, u32[2]{0} %or.122), metadata={op_type="xor" op_name="scan/while/body/xor" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %add.3899 = u32[2]{0} add(u32[2]{0} %add.3900, u32[2]{0} %xor.309), metadata={op_type="add" op_name="scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %slice.1201 = u32[1]{0} slice(u32[4]{0} %param_1.69), slice={[2:3]}, metadata={op_type="slice" op_name="scan/while/body/slice[ limit_indices=(3,)\n                       start_indices=(2,)\n                       strides=(1,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %reshape.2822 = u32[] reshape(u32[1]{0} %slice.1201), metadata={op_type="squeeze" op_name="scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %broadcast.1647 = u32[2]{0} broadcast(u32[] %reshape.2822), dimensions={}, metadata={op_type="shift_left" op_name="scan/while/body/shift_left" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %shift-left.118 = u32[2]{0} shift-left(u32[2]{0} %xor.309, u32[2]{0} %broadcast.1647), metadata={op_type="shift_left" op_name="scan/while/body/shift_left" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %subtract.454 = u32[] subtract(u32[] %constant.20376, u32[] %reshape.2822), metadata={op_type="sub" op_name="scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %broadcast.1646 = u32[2]{0} broadcast(u32[] %subtract.454), dimensions={}, metadata={op_type="shift_right_logical" op_name="scan/while/body/shift_right_logical" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %shift-right-logical.137 = u32[2]{0} shift-right-logical(u32[2]{0} %xor.309, u32[2]{0} %broadcast.1646), metadata={op_type="shift_right_logical" op_name="scan/while/body/shift_right_logical" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %or.121 = u32[2]{0} or(u32[2]{0} %shift-left.118, u32[2]{0} %shift-right-logical.137), metadata={op_type="or" op_name="scan/while/body/or" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %xor.308 = u32[2]{0} xor(u32[2]{0} %add.3899, u32[2]{0} %or.121), metadata={op_type="xor" op_name="scan/while/body/xor" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %add.3898 = u32[2]{0} add(u32[2]{0} %add.3899, u32[2]{0} %xor.308), metadata={op_type="add" op_name="scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %slice.1200 = u32[1]{0} slice(u32[4]{0} %param_1.69), slice={[3:4]}, metadata={op_type="slice" op_name="scan/while/body/slice[ limit_indices=(4,)\n                       start_indices=(3,)\n                       strides=(1,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %reshape.2821 = u32[] reshape(u32[1]{0} %slice.1200), metadata={op_type="squeeze" op_name="scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %broadcast.1645 = u32[2]{0} broadcast(u32[] %reshape.2821), dimensions={}, metadata={op_type="shift_left" op_name="scan/while/body/shift_left" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %shift-left.117 = u32[2]{0} shift-left(u32[2]{0} %xor.308, u32[2]{0} %broadcast.1645), metadata={op_type="shift_left" op_name="scan/while/body/shift_left" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %subtract.453 = u32[] subtract(u32[] %constant.20376, u32[] %reshape.2821), metadata={op_type="sub" op_name="scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %broadcast.1644 = u32[2]{0} broadcast(u32[] %subtract.453), dimensions={}, metadata={op_type="shift_right_logical" op_name="scan/while/body/shift_right_logical" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %shift-right-logical.136 = u32[2]{0} shift-right-logical(u32[2]{0} %xor.308, u32[2]{0} %broadcast.1644), metadata={op_type="shift_right_logical" op_name="scan/while/body/shift_right_logical" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %or.120 = u32[2]{0} or(u32[2]{0} %shift-left.117, u32[2]{0} %shift-right-logical.136), metadata={op_type="or" op_name="scan/while/body/or" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %xor.307 = u32[2]{0} xor(u32[2]{0} %add.3898, u32[2]{0} %or.120), metadata={op_type="xor" op_name="scan/while/body/xor" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %param_0.33 = u32[] parameter(0)
  %broadcast.1643 = u32[2]{0} broadcast(u32[] %param_0.33), dimensions={}, metadata={op_type="add" op_name="scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %add.3897 = u32[2]{0} add(u32[2]{0} %xor.307, u32[2]{0} %broadcast.1643), metadata={op_type="add" op_name="scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %param_4.113 = s32[] parameter(4)
  %constant.20378 = s32[] constant(1), metadata={op_type="add" op_name="scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %add.3902 = s32[] add(s32[] %param_4.113, s32[] %constant.20378), metadata={op_type="add" op_name="scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %convert.69 = u32[] convert(s32[] %add.3902), metadata={op_type="convert_element_type" op_name="scan/while/body/convert_element_type[ new_dtype=uint32\n                                      weak_type=False ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %broadcast.1642 = u32[2]{0} broadcast(u32[] %convert.69), dimensions={}, metadata={op_type="add" op_name="scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  ROOT %add.3896 = u32[2]{0} add(u32[2]{0} %add.3897, u32[2]{0} %broadcast.1642), metadata={op_type="add" op_name="scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
}

%fused_computation.13 (param_0.35: u32[], param_1.75: u32[4], param_2.75: u32[2], param_3.81: u32[2]) -> u32[2] {
  %param_3.81 = u32[2]{0} parameter(3)
  %param_2.75 = u32[2]{0} parameter(2)
  %add.3907 = u32[2]{0} add(u32[2]{0} %param_3.81, u32[2]{0} %param_2.75), metadata={op_type="add" op_name="scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %param_1.75 = u32[4]{0} parameter(1)
  %slice.1206 = u32[1]{0} slice(u32[4]{0} %param_1.75), slice={[0:1]}, metadata={op_type="slice" op_name="scan/while/body/slice[ limit_indices=(1,)\n                       start_indices=(0,)\n                       strides=(1,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %reshape.2827 = u32[] reshape(u32[1]{0} %slice.1206), metadata={op_type="squeeze" op_name="scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %broadcast.1658 = u32[2]{0} broadcast(u32[] %reshape.2827), dimensions={}, metadata={op_type="shift_left" op_name="scan/while/body/shift_left" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %shift-left.123 = u32[2]{0} shift-left(u32[2]{0} %param_2.75, u32[2]{0} %broadcast.1658), metadata={op_type="shift_left" op_name="scan/while/body/shift_left" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %constant.20379 = u32[] constant(32), metadata={op_type="sub" op_name="scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %subtract.459 = u32[] subtract(u32[] %constant.20379, u32[] %reshape.2827), metadata={op_type="sub" op_name="scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %broadcast.1657 = u32[2]{0} broadcast(u32[] %subtract.459), dimensions={}, metadata={op_type="shift_right_logical" op_name="scan/while/body/shift_right_logical" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %shift-right-logical.142 = u32[2]{0} shift-right-logical(u32[2]{0} %param_2.75, u32[2]{0} %broadcast.1657), metadata={op_type="shift_right_logical" op_name="scan/while/body/shift_right_logical" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %or.126 = u32[2]{0} or(u32[2]{0} %shift-left.123, u32[2]{0} %shift-right-logical.142), metadata={op_type="or" op_name="scan/while/body/or" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %xor.313 = u32[2]{0} xor(u32[2]{0} %add.3907, u32[2]{0} %or.126), metadata={op_type="xor" op_name="scan/while/body/xor" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %add.3906 = u32[2]{0} add(u32[2]{0} %add.3907, u32[2]{0} %xor.313), metadata={op_type="add" op_name="scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %slice.1205 = u32[1]{0} slice(u32[4]{0} %param_1.75), slice={[1:2]}, metadata={op_type="slice" op_name="scan/while/body/slice[ limit_indices=(2,)\n                       start_indices=(1,)\n                       strides=(1,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %reshape.2826 = u32[] reshape(u32[1]{0} %slice.1205), metadata={op_type="squeeze" op_name="scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %broadcast.1656 = u32[2]{0} broadcast(u32[] %reshape.2826), dimensions={}, metadata={op_type="shift_left" op_name="scan/while/body/shift_left" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %shift-left.122 = u32[2]{0} shift-left(u32[2]{0} %xor.313, u32[2]{0} %broadcast.1656), metadata={op_type="shift_left" op_name="scan/while/body/shift_left" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %subtract.458 = u32[] subtract(u32[] %constant.20379, u32[] %reshape.2826), metadata={op_type="sub" op_name="scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %broadcast.1655 = u32[2]{0} broadcast(u32[] %subtract.458), dimensions={}, metadata={op_type="shift_right_logical" op_name="scan/while/body/shift_right_logical" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %shift-right-logical.141 = u32[2]{0} shift-right-logical(u32[2]{0} %xor.313, u32[2]{0} %broadcast.1655), metadata={op_type="shift_right_logical" op_name="scan/while/body/shift_right_logical" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %or.125 = u32[2]{0} or(u32[2]{0} %shift-left.122, u32[2]{0} %shift-right-logical.141), metadata={op_type="or" op_name="scan/while/body/or" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %xor.312 = u32[2]{0} xor(u32[2]{0} %add.3906, u32[2]{0} %or.125), metadata={op_type="xor" op_name="scan/while/body/xor" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %add.3905 = u32[2]{0} add(u32[2]{0} %add.3906, u32[2]{0} %xor.312), metadata={op_type="add" op_name="scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %slice.1204 = u32[1]{0} slice(u32[4]{0} %param_1.75), slice={[2:3]}, metadata={op_type="slice" op_name="scan/while/body/slice[ limit_indices=(3,)\n                       start_indices=(2,)\n                       strides=(1,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %reshape.2825 = u32[] reshape(u32[1]{0} %slice.1204), metadata={op_type="squeeze" op_name="scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %broadcast.1654 = u32[2]{0} broadcast(u32[] %reshape.2825), dimensions={}, metadata={op_type="shift_left" op_name="scan/while/body/shift_left" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %shift-left.121 = u32[2]{0} shift-left(u32[2]{0} %xor.312, u32[2]{0} %broadcast.1654), metadata={op_type="shift_left" op_name="scan/while/body/shift_left" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %subtract.457 = u32[] subtract(u32[] %constant.20379, u32[] %reshape.2825), metadata={op_type="sub" op_name="scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %broadcast.1653 = u32[2]{0} broadcast(u32[] %subtract.457), dimensions={}, metadata={op_type="shift_right_logical" op_name="scan/while/body/shift_right_logical" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %shift-right-logical.140 = u32[2]{0} shift-right-logical(u32[2]{0} %xor.312, u32[2]{0} %broadcast.1653), metadata={op_type="shift_right_logical" op_name="scan/while/body/shift_right_logical" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %or.124 = u32[2]{0} or(u32[2]{0} %shift-left.121, u32[2]{0} %shift-right-logical.140), metadata={op_type="or" op_name="scan/while/body/or" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %xor.311 = u32[2]{0} xor(u32[2]{0} %add.3905, u32[2]{0} %or.124), metadata={op_type="xor" op_name="scan/while/body/xor" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %add.3904 = u32[2]{0} add(u32[2]{0} %add.3905, u32[2]{0} %xor.311), metadata={op_type="add" op_name="scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %param_0.35 = u32[] parameter(0)
  %broadcast.1652 = u32[2]{0} broadcast(u32[] %param_0.35), dimensions={}, metadata={op_type="add" op_name="scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  ROOT %add.3903 = u32[2]{0} add(u32[2]{0} %add.3904, u32[2]{0} %broadcast.1652), metadata={op_type="add" op_name="scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
}

%body_computation__167.6651.clone.clone.clone (parameter.30: (s32[], u32[2], u32[2], u32[], u32[], /*index=5*/u32[], u32[4], u32[4])) -> (s32[], u32[2], u32[2], u32[], u32[], /*index=5*/u32[], u32[4], u32[4]) {
  %parameter.30 = (s32[], u32[2]{0}, u32[2]{0}, u32[], u32[], /*index=5*/u32[], u32[4]{0}, u32[4]{0}) parameter(0)
  %get-tuple-element.27154 = s32[] get-tuple-element((s32[], u32[2]{0}, u32[2]{0}, u32[], u32[], /*index=5*/u32[], u32[4]{0}, u32[4]{0}) %parameter.30), index=0
  %copy.517 = s32[] copy(s32[] %get-tuple-element.27154)
  %constant.10320 = s32[] constant(1), metadata={op_type="add" op_name="scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %add.1374 = s32[] add(s32[] %copy.517, s32[] %constant.10320), metadata={op_type="add" op_name="scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.27157 = u32[] get-tuple-element((s32[], u32[2]{0}, u32[2]{0}, u32[], u32[], /*index=5*/u32[], u32[4]{0}, u32[4]{0}) %parameter.30), index=3
  %copy.520 = u32[] copy(u32[] %get-tuple-element.27157)
  %get-tuple-element.27160 = u32[4]{0} get-tuple-element((s32[], u32[2]{0}, u32[2]{0}, u32[], u32[], /*index=5*/u32[], u32[4]{0}, u32[4]{0}) %parameter.30), index=6
  %copy.523 = u32[4]{0} copy(u32[4]{0} %get-tuple-element.27160)
  %get-tuple-element.27156 = u32[2]{0} get-tuple-element((s32[], u32[2]{0}, u32[2]{0}, u32[], u32[], /*index=5*/u32[], u32[4]{0}, u32[4]{0}) %parameter.30), index=2
  %copy.519 = u32[2]{0} copy(u32[2]{0} %get-tuple-element.27156)
  %get-tuple-element.27155 = u32[2]{0} get-tuple-element((s32[], u32[2]{0}, u32[2]{0}, u32[], u32[], /*index=5*/u32[], u32[4]{0}, u32[4]{0}) %parameter.30), index=1
  %copy.518 = u32[2]{0} copy(u32[2]{0} %get-tuple-element.27155)
  %fusion.13 = u32[2]{0} fusion(u32[] %copy.520, u32[4]{0} %copy.523, u32[2]{0} %copy.519, u32[2]{0} %copy.518), kind=kLoop, calls=%fused_computation.13, metadata={op_type="add" op_name="scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %get-tuple-element.27158 = u32[] get-tuple-element((s32[], u32[2]{0}, u32[2]{0}, u32[], u32[], /*index=5*/u32[], u32[4]{0}, u32[4]{0}) %parameter.30), index=4
  %copy.521 = u32[] copy(u32[] %get-tuple-element.27158)
  %fusion.12 = u32[2]{0} fusion(u32[] %copy.521, u32[4]{0} %copy.523, u32[2]{0} %copy.519, u32[2]{0} %copy.518, s32[] %copy.517), kind=kLoop, calls=%fused_computation.12, metadata={op_type="add" op_name="scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %copy.528 = u32[] copy(u32[] %copy.521), control-predecessors={%copy.520}
  %get-tuple-element.27159 = u32[] get-tuple-element((s32[], u32[2]{0}, u32[2]{0}, u32[], u32[], /*index=5*/u32[], u32[4]{0}, u32[4]{0}) %parameter.30), index=5
  %copy.522 = u32[] copy(u32[] %get-tuple-element.27159)
  %copy.529 = u32[] copy(u32[] %copy.522), control-predecessors={%copy.521}
  %copy.530 = u32[] copy(u32[] %copy.520), control-predecessors={%copy.522}
  %get-tuple-element.27161 = u32[4]{0} get-tuple-element((s32[], u32[2]{0}, u32[2]{0}, u32[], u32[], /*index=5*/u32[], u32[4]{0}, u32[4]{0}) %parameter.30), index=7
  %copy.524 = u32[4]{0} copy(u32[4]{0} %get-tuple-element.27161)
  %copy.531 = u32[4]{0} copy(u32[4]{0} %copy.524), control-predecessors={%copy.523}
  %copy.532 = u32[4]{0} copy(u32[4]{0} %copy.523), control-predecessors={%copy.524}
  ROOT %tuple.1294 = (s32[], u32[2]{0}, u32[2]{0}, u32[], u32[], /*index=5*/u32[], u32[4]{0}, u32[4]{0}) tuple(s32[] %add.1374, u32[2]{0} %fusion.13, u32[2]{0} %fusion.12, u32[] %copy.528, u32[] %copy.529, /*index=5*/u32[] %copy.530, u32[4]{0} %copy.531, u32[4]{0} %copy.532)
}

%cond_computation__167.6721.clone.clone (parameter.31: (s32[], u32[2], u32[2], u32[], u32[], /*index=5*/u32[], u32[4], u32[4])) -> pred[] {
  %parameter.31 = (s32[], u32[2]{0}, u32[2]{0}, u32[], u32[], /*index=5*/u32[], u32[4]{0}, u32[4]{0}) parameter(0)
  %get-tuple-element.15213 = s32[] get-tuple-element((s32[], u32[2]{0}, u32[2]{0}, u32[], u32[], /*index=5*/u32[], u32[4]{0}, u32[4]{0}) %parameter.31), index=0
  %constant.10326 = s32[] constant(5), metadata={op_type="lt" op_name="scan/while/cond/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %compare.1604 = pred[] compare(s32[] %get-tuple-element.15213, s32[] %constant.10326), direction=LT, metadata={op_type="lt" op_name="scan/while/cond/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.14 (param_0.38: u32[], param_1.81: u32[4], param_2.82: u32[2], param_3.89: u32[2], param_4.142: s32[]) -> u32[2] {
  %param_3.89 = u32[2]{0} parameter(3)
  %param_2.82 = u32[2]{0} parameter(2)
  %add.3913 = u32[2]{0} add(u32[2]{0} %param_3.89, u32[2]{0} %param_2.82), metadata={op_type="add" op_name="scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %param_1.81 = u32[4]{0} parameter(1)
  %slice.1210 = u32[1]{0} slice(u32[4]{0} %param_1.81), slice={[0:1]}, metadata={op_type="slice" op_name="scan/while/body/slice[ limit_indices=(1,)\n                       start_indices=(0,)\n                       strides=(1,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %reshape.2831 = u32[] reshape(u32[1]{0} %slice.1210), metadata={op_type="squeeze" op_name="scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %broadcast.1669 = u32[2]{0} broadcast(u32[] %reshape.2831), dimensions={}, metadata={op_type="shift_left" op_name="scan/while/body/shift_left" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %shift-left.127 = u32[2]{0} shift-left(u32[2]{0} %param_2.82, u32[2]{0} %broadcast.1669), metadata={op_type="shift_left" op_name="scan/while/body/shift_left" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %constant.20380 = u32[] constant(32), metadata={op_type="sub" op_name="scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %subtract.463 = u32[] subtract(u32[] %constant.20380, u32[] %reshape.2831), metadata={op_type="sub" op_name="scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %broadcast.1668 = u32[2]{0} broadcast(u32[] %subtract.463), dimensions={}, metadata={op_type="shift_right_logical" op_name="scan/while/body/shift_right_logical" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %shift-right-logical.146 = u32[2]{0} shift-right-logical(u32[2]{0} %param_2.82, u32[2]{0} %broadcast.1668), metadata={op_type="shift_right_logical" op_name="scan/while/body/shift_right_logical" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %or.130 = u32[2]{0} or(u32[2]{0} %shift-left.127, u32[2]{0} %shift-right-logical.146), metadata={op_type="or" op_name="scan/while/body/or" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %xor.317 = u32[2]{0} xor(u32[2]{0} %add.3913, u32[2]{0} %or.130), metadata={op_type="xor" op_name="scan/while/body/xor" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %add.3912 = u32[2]{0} add(u32[2]{0} %add.3913, u32[2]{0} %xor.317), metadata={op_type="add" op_name="scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %slice.1209 = u32[1]{0} slice(u32[4]{0} %param_1.81), slice={[1:2]}, metadata={op_type="slice" op_name="scan/while/body/slice[ limit_indices=(2,)\n                       start_indices=(1,)\n                       strides=(1,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %reshape.2830 = u32[] reshape(u32[1]{0} %slice.1209), metadata={op_type="squeeze" op_name="scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %broadcast.1667 = u32[2]{0} broadcast(u32[] %reshape.2830), dimensions={}, metadata={op_type="shift_left" op_name="scan/while/body/shift_left" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %shift-left.126 = u32[2]{0} shift-left(u32[2]{0} %xor.317, u32[2]{0} %broadcast.1667), metadata={op_type="shift_left" op_name="scan/while/body/shift_left" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %subtract.462 = u32[] subtract(u32[] %constant.20380, u32[] %reshape.2830), metadata={op_type="sub" op_name="scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %broadcast.1666 = u32[2]{0} broadcast(u32[] %subtract.462), dimensions={}, metadata={op_type="shift_right_logical" op_name="scan/while/body/shift_right_logical" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %shift-right-logical.145 = u32[2]{0} shift-right-logical(u32[2]{0} %xor.317, u32[2]{0} %broadcast.1666), metadata={op_type="shift_right_logical" op_name="scan/while/body/shift_right_logical" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %or.129 = u32[2]{0} or(u32[2]{0} %shift-left.126, u32[2]{0} %shift-right-logical.145), metadata={op_type="or" op_name="scan/while/body/or" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %xor.316 = u32[2]{0} xor(u32[2]{0} %add.3912, u32[2]{0} %or.129), metadata={op_type="xor" op_name="scan/while/body/xor" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %add.3911 = u32[2]{0} add(u32[2]{0} %add.3912, u32[2]{0} %xor.316), metadata={op_type="add" op_name="scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %slice.1208 = u32[1]{0} slice(u32[4]{0} %param_1.81), slice={[2:3]}, metadata={op_type="slice" op_name="scan/while/body/slice[ limit_indices=(3,)\n                       start_indices=(2,)\n                       strides=(1,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %reshape.2829 = u32[] reshape(u32[1]{0} %slice.1208), metadata={op_type="squeeze" op_name="scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %broadcast.1665 = u32[2]{0} broadcast(u32[] %reshape.2829), dimensions={}, metadata={op_type="shift_left" op_name="scan/while/body/shift_left" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %shift-left.125 = u32[2]{0} shift-left(u32[2]{0} %xor.316, u32[2]{0} %broadcast.1665), metadata={op_type="shift_left" op_name="scan/while/body/shift_left" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %subtract.461 = u32[] subtract(u32[] %constant.20380, u32[] %reshape.2829), metadata={op_type="sub" op_name="scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %broadcast.1664 = u32[2]{0} broadcast(u32[] %subtract.461), dimensions={}, metadata={op_type="shift_right_logical" op_name="scan/while/body/shift_right_logical" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %shift-right-logical.144 = u32[2]{0} shift-right-logical(u32[2]{0} %xor.316, u32[2]{0} %broadcast.1664), metadata={op_type="shift_right_logical" op_name="scan/while/body/shift_right_logical" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %or.128 = u32[2]{0} or(u32[2]{0} %shift-left.125, u32[2]{0} %shift-right-logical.144), metadata={op_type="or" op_name="scan/while/body/or" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %xor.315 = u32[2]{0} xor(u32[2]{0} %add.3911, u32[2]{0} %or.128), metadata={op_type="xor" op_name="scan/while/body/xor" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %add.3910 = u32[2]{0} add(u32[2]{0} %add.3911, u32[2]{0} %xor.315), metadata={op_type="add" op_name="scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %slice.1207 = u32[1]{0} slice(u32[4]{0} %param_1.81), slice={[3:4]}, metadata={op_type="slice" op_name="scan/while/body/slice[ limit_indices=(4,)\n                       start_indices=(3,)\n                       strides=(1,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %reshape.2828 = u32[] reshape(u32[1]{0} %slice.1207), metadata={op_type="squeeze" op_name="scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %broadcast.1663 = u32[2]{0} broadcast(u32[] %reshape.2828), dimensions={}, metadata={op_type="shift_left" op_name="scan/while/body/shift_left" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %shift-left.124 = u32[2]{0} shift-left(u32[2]{0} %xor.315, u32[2]{0} %broadcast.1663), metadata={op_type="shift_left" op_name="scan/while/body/shift_left" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %subtract.460 = u32[] subtract(u32[] %constant.20380, u32[] %reshape.2828), metadata={op_type="sub" op_name="scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %broadcast.1662 = u32[2]{0} broadcast(u32[] %subtract.460), dimensions={}, metadata={op_type="shift_right_logical" op_name="scan/while/body/shift_right_logical" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %shift-right-logical.143 = u32[2]{0} shift-right-logical(u32[2]{0} %xor.315, u32[2]{0} %broadcast.1662), metadata={op_type="shift_right_logical" op_name="scan/while/body/shift_right_logical" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %or.127 = u32[2]{0} or(u32[2]{0} %shift-left.124, u32[2]{0} %shift-right-logical.143), metadata={op_type="or" op_name="scan/while/body/or" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %xor.314 = u32[2]{0} xor(u32[2]{0} %add.3910, u32[2]{0} %or.127), metadata={op_type="xor" op_name="scan/while/body/xor" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %param_0.38 = u32[] parameter(0)
  %broadcast.1661 = u32[2]{0} broadcast(u32[] %param_0.38), dimensions={}, metadata={op_type="add" op_name="scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %add.3909 = u32[2]{0} add(u32[2]{0} %xor.314, u32[2]{0} %broadcast.1661), metadata={op_type="add" op_name="scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %param_4.142 = s32[] parameter(4)
  %constant.20381 = s32[] constant(1), metadata={op_type="add" op_name="scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %add.3914 = s32[] add(s32[] %param_4.142, s32[] %constant.20381), metadata={op_type="add" op_name="scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %convert.70 = u32[] convert(s32[] %add.3914), metadata={op_type="convert_element_type" op_name="scan/while/body/convert_element_type[ new_dtype=uint32\n                                      weak_type=False ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %broadcast.1659 = u32[2]{0} broadcast(u32[] %convert.70), dimensions={}, metadata={op_type="add" op_name="scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  ROOT %add.3908 = u32[2]{0} add(u32[2]{0} %add.3909, u32[2]{0} %broadcast.1659), metadata={op_type="add" op_name="scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
}

%fused_computation.15 (param_0.40: u32[], param_1.87: u32[4], param_2.90: u32[2], param_3.99: u32[2]) -> u32[2] {
  %param_3.99 = u32[2]{0} parameter(3)
  %param_2.90 = u32[2]{0} parameter(2)
  %add.3919 = u32[2]{0} add(u32[2]{0} %param_3.99, u32[2]{0} %param_2.90), metadata={op_type="add" op_name="scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %param_1.87 = u32[4]{0} parameter(1)
  %slice.1213 = u32[1]{0} slice(u32[4]{0} %param_1.87), slice={[0:1]}, metadata={op_type="slice" op_name="scan/while/body/slice[ limit_indices=(1,)\n                       start_indices=(0,)\n                       strides=(1,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %reshape.2834 = u32[] reshape(u32[1]{0} %slice.1213), metadata={op_type="squeeze" op_name="scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %broadcast.1676 = u32[2]{0} broadcast(u32[] %reshape.2834), dimensions={}, metadata={op_type="shift_left" op_name="scan/while/body/shift_left" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %shift-left.130 = u32[2]{0} shift-left(u32[2]{0} %param_2.90, u32[2]{0} %broadcast.1676), metadata={op_type="shift_left" op_name="scan/while/body/shift_left" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %constant.20383 = u32[] constant(32), metadata={op_type="sub" op_name="scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %subtract.466 = u32[] subtract(u32[] %constant.20383, u32[] %reshape.2834), metadata={op_type="sub" op_name="scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %broadcast.1675 = u32[2]{0} broadcast(u32[] %subtract.466), dimensions={}, metadata={op_type="shift_right_logical" op_name="scan/while/body/shift_right_logical" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %shift-right-logical.149 = u32[2]{0} shift-right-logical(u32[2]{0} %param_2.90, u32[2]{0} %broadcast.1675), metadata={op_type="shift_right_logical" op_name="scan/while/body/shift_right_logical" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %or.133 = u32[2]{0} or(u32[2]{0} %shift-left.130, u32[2]{0} %shift-right-logical.149), metadata={op_type="or" op_name="scan/while/body/or" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %xor.320 = u32[2]{0} xor(u32[2]{0} %add.3919, u32[2]{0} %or.133), metadata={op_type="xor" op_name="scan/while/body/xor" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %add.3918 = u32[2]{0} add(u32[2]{0} %add.3919, u32[2]{0} %xor.320), metadata={op_type="add" op_name="scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %slice.1212 = u32[1]{0} slice(u32[4]{0} %param_1.87), slice={[1:2]}, metadata={op_type="slice" op_name="scan/while/body/slice[ limit_indices=(2,)\n                       start_indices=(1,)\n                       strides=(1,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %reshape.2833 = u32[] reshape(u32[1]{0} %slice.1212), metadata={op_type="squeeze" op_name="scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %broadcast.1674 = u32[2]{0} broadcast(u32[] %reshape.2833), dimensions={}, metadata={op_type="shift_left" op_name="scan/while/body/shift_left" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %shift-left.129 = u32[2]{0} shift-left(u32[2]{0} %xor.320, u32[2]{0} %broadcast.1674), metadata={op_type="shift_left" op_name="scan/while/body/shift_left" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %subtract.465 = u32[] subtract(u32[] %constant.20383, u32[] %reshape.2833), metadata={op_type="sub" op_name="scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %broadcast.1673 = u32[2]{0} broadcast(u32[] %subtract.465), dimensions={}, metadata={op_type="shift_right_logical" op_name="scan/while/body/shift_right_logical" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %shift-right-logical.148 = u32[2]{0} shift-right-logical(u32[2]{0} %xor.320, u32[2]{0} %broadcast.1673), metadata={op_type="shift_right_logical" op_name="scan/while/body/shift_right_logical" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %or.132 = u32[2]{0} or(u32[2]{0} %shift-left.129, u32[2]{0} %shift-right-logical.148), metadata={op_type="or" op_name="scan/while/body/or" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %xor.319 = u32[2]{0} xor(u32[2]{0} %add.3918, u32[2]{0} %or.132), metadata={op_type="xor" op_name="scan/while/body/xor" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %add.3917 = u32[2]{0} add(u32[2]{0} %add.3918, u32[2]{0} %xor.319), metadata={op_type="add" op_name="scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %slice.1211 = u32[1]{0} slice(u32[4]{0} %param_1.87), slice={[2:3]}, metadata={op_type="slice" op_name="scan/while/body/slice[ limit_indices=(3,)\n                       start_indices=(2,)\n                       strides=(1,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %reshape.2832 = u32[] reshape(u32[1]{0} %slice.1211), metadata={op_type="squeeze" op_name="scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %broadcast.1672 = u32[2]{0} broadcast(u32[] %reshape.2832), dimensions={}, metadata={op_type="shift_left" op_name="scan/while/body/shift_left" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %shift-left.128 = u32[2]{0} shift-left(u32[2]{0} %xor.319, u32[2]{0} %broadcast.1672), metadata={op_type="shift_left" op_name="scan/while/body/shift_left" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %subtract.464 = u32[] subtract(u32[] %constant.20383, u32[] %reshape.2832), metadata={op_type="sub" op_name="scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %broadcast.1671 = u32[2]{0} broadcast(u32[] %subtract.464), dimensions={}, metadata={op_type="shift_right_logical" op_name="scan/while/body/shift_right_logical" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %shift-right-logical.147 = u32[2]{0} shift-right-logical(u32[2]{0} %xor.319, u32[2]{0} %broadcast.1671), metadata={op_type="shift_right_logical" op_name="scan/while/body/shift_right_logical" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %or.131 = u32[2]{0} or(u32[2]{0} %shift-left.128, u32[2]{0} %shift-right-logical.147), metadata={op_type="or" op_name="scan/while/body/or" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %xor.318 = u32[2]{0} xor(u32[2]{0} %add.3917, u32[2]{0} %or.131), metadata={op_type="xor" op_name="scan/while/body/xor" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %add.3916 = u32[2]{0} add(u32[2]{0} %add.3917, u32[2]{0} %xor.318), metadata={op_type="add" op_name="scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %param_0.40 = u32[] parameter(0)
  %broadcast.1670 = u32[2]{0} broadcast(u32[] %param_0.40), dimensions={}, metadata={op_type="add" op_name="scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  ROOT %add.3915 = u32[2]{0} add(u32[2]{0} %add.3916, u32[2]{0} %broadcast.1670), metadata={op_type="add" op_name="scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
}

%body_computation__168.6807.clone.clone.clone (parameter.32: (s32[], u32[2], u32[2], u32[], u32[], /*index=5*/u32[], u32[4], u32[4])) -> (s32[], u32[2], u32[2], u32[], u32[], /*index=5*/u32[], u32[4], u32[4]) {
  %parameter.32 = (s32[], u32[2]{0}, u32[2]{0}, u32[], u32[], /*index=5*/u32[], u32[4]{0}, u32[4]{0}) parameter(0)
  %get-tuple-element.27178 = s32[] get-tuple-element((s32[], u32[2]{0}, u32[2]{0}, u32[], u32[], /*index=5*/u32[], u32[4]{0}, u32[4]{0}) %parameter.32), index=0
  %copy.541 = s32[] copy(s32[] %get-tuple-element.27178)
  %constant.10334 = s32[] constant(1), metadata={op_type="add" op_name="scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %add.1384 = s32[] add(s32[] %copy.541, s32[] %constant.10334), metadata={op_type="add" op_name="scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.27181 = u32[] get-tuple-element((s32[], u32[2]{0}, u32[2]{0}, u32[], u32[], /*index=5*/u32[], u32[4]{0}, u32[4]{0}) %parameter.32), index=3
  %copy.544 = u32[] copy(u32[] %get-tuple-element.27181)
  %get-tuple-element.27184 = u32[4]{0} get-tuple-element((s32[], u32[2]{0}, u32[2]{0}, u32[], u32[], /*index=5*/u32[], u32[4]{0}, u32[4]{0}) %parameter.32), index=6
  %copy.547 = u32[4]{0} copy(u32[4]{0} %get-tuple-element.27184)
  %get-tuple-element.27180 = u32[2]{0} get-tuple-element((s32[], u32[2]{0}, u32[2]{0}, u32[], u32[], /*index=5*/u32[], u32[4]{0}, u32[4]{0}) %parameter.32), index=2
  %copy.543 = u32[2]{0} copy(u32[2]{0} %get-tuple-element.27180)
  %get-tuple-element.27179 = u32[2]{0} get-tuple-element((s32[], u32[2]{0}, u32[2]{0}, u32[], u32[], /*index=5*/u32[], u32[4]{0}, u32[4]{0}) %parameter.32), index=1
  %copy.542 = u32[2]{0} copy(u32[2]{0} %get-tuple-element.27179)
  %fusion.15 = u32[2]{0} fusion(u32[] %copy.544, u32[4]{0} %copy.547, u32[2]{0} %copy.543, u32[2]{0} %copy.542), kind=kLoop, calls=%fused_computation.15, metadata={op_type="add" op_name="scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %get-tuple-element.27182 = u32[] get-tuple-element((s32[], u32[2]{0}, u32[2]{0}, u32[], u32[], /*index=5*/u32[], u32[4]{0}, u32[4]{0}) %parameter.32), index=4
  %copy.545 = u32[] copy(u32[] %get-tuple-element.27182)
  %fusion.14 = u32[2]{0} fusion(u32[] %copy.545, u32[4]{0} %copy.547, u32[2]{0} %copy.543, u32[2]{0} %copy.542, s32[] %copy.541), kind=kLoop, calls=%fused_computation.14, metadata={op_type="add" op_name="scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %copy.552 = u32[] copy(u32[] %copy.545), control-predecessors={%copy.544}
  %get-tuple-element.27183 = u32[] get-tuple-element((s32[], u32[2]{0}, u32[2]{0}, u32[], u32[], /*index=5*/u32[], u32[4]{0}, u32[4]{0}) %parameter.32), index=5
  %copy.546 = u32[] copy(u32[] %get-tuple-element.27183)
  %copy.553 = u32[] copy(u32[] %copy.546), control-predecessors={%copy.545}
  %copy.554 = u32[] copy(u32[] %copy.544), control-predecessors={%copy.546}
  %get-tuple-element.27185 = u32[4]{0} get-tuple-element((s32[], u32[2]{0}, u32[2]{0}, u32[], u32[], /*index=5*/u32[], u32[4]{0}, u32[4]{0}) %parameter.32), index=7
  %copy.548 = u32[4]{0} copy(u32[4]{0} %get-tuple-element.27185)
  %copy.555 = u32[4]{0} copy(u32[4]{0} %copy.548), control-predecessors={%copy.547}
  %copy.556 = u32[4]{0} copy(u32[4]{0} %copy.547), control-predecessors={%copy.548}
  ROOT %tuple.1297 = (s32[], u32[2]{0}, u32[2]{0}, u32[], u32[], /*index=5*/u32[], u32[4]{0}, u32[4]{0}) tuple(s32[] %add.1384, u32[2]{0} %fusion.15, u32[2]{0} %fusion.14, u32[] %copy.552, u32[] %copy.553, /*index=5*/u32[] %copy.554, u32[4]{0} %copy.555, u32[4]{0} %copy.556)
}

%cond_computation__168.6877.clone.clone (parameter.33: (s32[], u32[2], u32[2], u32[], u32[], /*index=5*/u32[], u32[4], u32[4])) -> pred[] {
  %parameter.33 = (s32[], u32[2]{0}, u32[2]{0}, u32[], u32[], /*index=5*/u32[], u32[4]{0}, u32[4]{0}) parameter(0)
  %get-tuple-element.15336 = s32[] get-tuple-element((s32[], u32[2]{0}, u32[2]{0}, u32[], u32[], /*index=5*/u32[], u32[4]{0}, u32[4]{0}) %parameter.33), index=0
  %constant.10340 = s32[] constant(5), metadata={op_type="lt" op_name="scan/while/cond/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %compare.1605 = pred[] compare(s32[] %get-tuple-element.15336, s32[] %constant.10340), direction=LT, metadata={op_type="lt" op_name="scan/while/cond/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.16 (param_0.43: u32[], param_1.93: u32[4], param_2.97: u32[3], param_3.107: u32[3], param_4.171: s32[]) -> u32[3] {
  %param_3.107 = u32[3]{0} parameter(3)
  %param_2.97 = u32[3]{0} parameter(2)
  %add.3925 = u32[3]{0} add(u32[3]{0} %param_3.107, u32[3]{0} %param_2.97), metadata={op_type="add" op_name="scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %param_1.93 = u32[4]{0} parameter(1)
  %slice.1217 = u32[1]{0} slice(u32[4]{0} %param_1.93), slice={[0:1]}, metadata={op_type="slice" op_name="scan/while/body/slice[ limit_indices=(1,)\n                       start_indices=(0,)\n                       strides=(1,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %reshape.2838 = u32[] reshape(u32[1]{0} %slice.1217), metadata={op_type="squeeze" op_name="scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %broadcast.1687 = u32[3]{0} broadcast(u32[] %reshape.2838), dimensions={}, metadata={op_type="shift_left" op_name="scan/while/body/shift_left" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %shift-left.134 = u32[3]{0} shift-left(u32[3]{0} %param_2.97, u32[3]{0} %broadcast.1687), metadata={op_type="shift_left" op_name="scan/while/body/shift_left" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %constant.20384 = u32[] constant(32), metadata={op_type="sub" op_name="scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %subtract.470 = u32[] subtract(u32[] %constant.20384, u32[] %reshape.2838), metadata={op_type="sub" op_name="scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %broadcast.1686 = u32[3]{0} broadcast(u32[] %subtract.470), dimensions={}, metadata={op_type="shift_right_logical" op_name="scan/while/body/shift_right_logical" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %shift-right-logical.153 = u32[3]{0} shift-right-logical(u32[3]{0} %param_2.97, u32[3]{0} %broadcast.1686), metadata={op_type="shift_right_logical" op_name="scan/while/body/shift_right_logical" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %or.137 = u32[3]{0} or(u32[3]{0} %shift-left.134, u32[3]{0} %shift-right-logical.153), metadata={op_type="or" op_name="scan/while/body/or" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %xor.324 = u32[3]{0} xor(u32[3]{0} %add.3925, u32[3]{0} %or.137), metadata={op_type="xor" op_name="scan/while/body/xor" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %add.3924 = u32[3]{0} add(u32[3]{0} %add.3925, u32[3]{0} %xor.324), metadata={op_type="add" op_name="scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %slice.1216 = u32[1]{0} slice(u32[4]{0} %param_1.93), slice={[1:2]}, metadata={op_type="slice" op_name="scan/while/body/slice[ limit_indices=(2,)\n                       start_indices=(1,)\n                       strides=(1,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %reshape.2837 = u32[] reshape(u32[1]{0} %slice.1216), metadata={op_type="squeeze" op_name="scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %broadcast.1685 = u32[3]{0} broadcast(u32[] %reshape.2837), dimensions={}, metadata={op_type="shift_left" op_name="scan/while/body/shift_left" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %shift-left.133 = u32[3]{0} shift-left(u32[3]{0} %xor.324, u32[3]{0} %broadcast.1685), metadata={op_type="shift_left" op_name="scan/while/body/shift_left" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %subtract.469 = u32[] subtract(u32[] %constant.20384, u32[] %reshape.2837), metadata={op_type="sub" op_name="scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %broadcast.1684 = u32[3]{0} broadcast(u32[] %subtract.469), dimensions={}, metadata={op_type="shift_right_logical" op_name="scan/while/body/shift_right_logical" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %shift-right-logical.152 = u32[3]{0} shift-right-logical(u32[3]{0} %xor.324, u32[3]{0} %broadcast.1684), metadata={op_type="shift_right_logical" op_name="scan/while/body/shift_right_logical" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %or.136 = u32[3]{0} or(u32[3]{0} %shift-left.133, u32[3]{0} %shift-right-logical.152), metadata={op_type="or" op_name="scan/while/body/or" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %xor.323 = u32[3]{0} xor(u32[3]{0} %add.3924, u32[3]{0} %or.136), metadata={op_type="xor" op_name="scan/while/body/xor" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %add.3923 = u32[3]{0} add(u32[3]{0} %add.3924, u32[3]{0} %xor.323), metadata={op_type="add" op_name="scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %slice.1215 = u32[1]{0} slice(u32[4]{0} %param_1.93), slice={[2:3]}, metadata={op_type="slice" op_name="scan/while/body/slice[ limit_indices=(3,)\n                       start_indices=(2,)\n                       strides=(1,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %reshape.2836 = u32[] reshape(u32[1]{0} %slice.1215), metadata={op_type="squeeze" op_name="scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %broadcast.1682 = u32[3]{0} broadcast(u32[] %reshape.2836), dimensions={}, metadata={op_type="shift_left" op_name="scan/while/body/shift_left" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %shift-left.132 = u32[3]{0} shift-left(u32[3]{0} %xor.323, u32[3]{0} %broadcast.1682), metadata={op_type="shift_left" op_name="scan/while/body/shift_left" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %subtract.468 = u32[] subtract(u32[] %constant.20384, u32[] %reshape.2836), metadata={op_type="sub" op_name="scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %broadcast.1681 = u32[3]{0} broadcast(u32[] %subtract.468), dimensions={}, metadata={op_type="shift_right_logical" op_name="scan/while/body/shift_right_logical" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %shift-right-logical.151 = u32[3]{0} shift-right-logical(u32[3]{0} %xor.323, u32[3]{0} %broadcast.1681), metadata={op_type="shift_right_logical" op_name="scan/while/body/shift_right_logical" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %or.135 = u32[3]{0} or(u32[3]{0} %shift-left.132, u32[3]{0} %shift-right-logical.151), metadata={op_type="or" op_name="scan/while/body/or" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %xor.322 = u32[3]{0} xor(u32[3]{0} %add.3923, u32[3]{0} %or.135), metadata={op_type="xor" op_name="scan/while/body/xor" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %add.3922 = u32[3]{0} add(u32[3]{0} %add.3923, u32[3]{0} %xor.322), metadata={op_type="add" op_name="scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %slice.1214 = u32[1]{0} slice(u32[4]{0} %param_1.93), slice={[3:4]}, metadata={op_type="slice" op_name="scan/while/body/slice[ limit_indices=(4,)\n                       start_indices=(3,)\n                       strides=(1,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %reshape.2835 = u32[] reshape(u32[1]{0} %slice.1214), metadata={op_type="squeeze" op_name="scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %broadcast.1680 = u32[3]{0} broadcast(u32[] %reshape.2835), dimensions={}, metadata={op_type="shift_left" op_name="scan/while/body/shift_left" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %shift-left.131 = u32[3]{0} shift-left(u32[3]{0} %xor.322, u32[3]{0} %broadcast.1680), metadata={op_type="shift_left" op_name="scan/while/body/shift_left" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %subtract.467 = u32[] subtract(u32[] %constant.20384, u32[] %reshape.2835), metadata={op_type="sub" op_name="scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %broadcast.1679 = u32[3]{0} broadcast(u32[] %subtract.467), dimensions={}, metadata={op_type="shift_right_logical" op_name="scan/while/body/shift_right_logical" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %shift-right-logical.150 = u32[3]{0} shift-right-logical(u32[3]{0} %xor.322, u32[3]{0} %broadcast.1679), metadata={op_type="shift_right_logical" op_name="scan/while/body/shift_right_logical" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %or.134 = u32[3]{0} or(u32[3]{0} %shift-left.131, u32[3]{0} %shift-right-logical.150), metadata={op_type="or" op_name="scan/while/body/or" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %xor.321 = u32[3]{0} xor(u32[3]{0} %add.3922, u32[3]{0} %or.134), metadata={op_type="xor" op_name="scan/while/body/xor" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %param_0.43 = u32[] parameter(0)
  %broadcast.1678 = u32[3]{0} broadcast(u32[] %param_0.43), dimensions={}, metadata={op_type="add" op_name="scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %add.3921 = u32[3]{0} add(u32[3]{0} %xor.321, u32[3]{0} %broadcast.1678), metadata={op_type="add" op_name="scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %param_4.171 = s32[] parameter(4)
  %constant.20385 = s32[] constant(1), metadata={op_type="add" op_name="scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %add.3926 = s32[] add(s32[] %param_4.171, s32[] %constant.20385), metadata={op_type="add" op_name="scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %convert.71 = u32[] convert(s32[] %add.3926), metadata={op_type="convert_element_type" op_name="scan/while/body/convert_element_type[ new_dtype=uint32\n                                      weak_type=False ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %broadcast.1677 = u32[3]{0} broadcast(u32[] %convert.71), dimensions={}, metadata={op_type="add" op_name="scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  ROOT %add.3920 = u32[3]{0} add(u32[3]{0} %add.3921, u32[3]{0} %broadcast.1677), metadata={op_type="add" op_name="scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
}

%fused_computation.17 (param_0.45: u32[], param_1.99: u32[4], param_2.105: u32[3], param_3.117: u32[3]) -> u32[3] {
  %param_3.117 = u32[3]{0} parameter(3)
  %param_2.105 = u32[3]{0} parameter(2)
  %add.3931 = u32[3]{0} add(u32[3]{0} %param_3.117, u32[3]{0} %param_2.105), metadata={op_type="add" op_name="scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %param_1.99 = u32[4]{0} parameter(1)
  %slice.1220 = u32[1]{0} slice(u32[4]{0} %param_1.99), slice={[0:1]}, metadata={op_type="slice" op_name="scan/while/body/slice[ limit_indices=(1,)\n                       start_indices=(0,)\n                       strides=(1,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %reshape.2841 = u32[] reshape(u32[1]{0} %slice.1220), metadata={op_type="squeeze" op_name="scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %broadcast.1694 = u32[3]{0} broadcast(u32[] %reshape.2841), dimensions={}, metadata={op_type="shift_left" op_name="scan/while/body/shift_left" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %shift-left.137 = u32[3]{0} shift-left(u32[3]{0} %param_2.105, u32[3]{0} %broadcast.1694), metadata={op_type="shift_left" op_name="scan/while/body/shift_left" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %constant.20386 = u32[] constant(32), metadata={op_type="sub" op_name="scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %subtract.473 = u32[] subtract(u32[] %constant.20386, u32[] %reshape.2841), metadata={op_type="sub" op_name="scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %broadcast.1693 = u32[3]{0} broadcast(u32[] %subtract.473), dimensions={}, metadata={op_type="shift_right_logical" op_name="scan/while/body/shift_right_logical" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %shift-right-logical.156 = u32[3]{0} shift-right-logical(u32[3]{0} %param_2.105, u32[3]{0} %broadcast.1693), metadata={op_type="shift_right_logical" op_name="scan/while/body/shift_right_logical" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %or.140 = u32[3]{0} or(u32[3]{0} %shift-left.137, u32[3]{0} %shift-right-logical.156), metadata={op_type="or" op_name="scan/while/body/or" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %xor.327 = u32[3]{0} xor(u32[3]{0} %add.3931, u32[3]{0} %or.140), metadata={op_type="xor" op_name="scan/while/body/xor" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %add.3930 = u32[3]{0} add(u32[3]{0} %add.3931, u32[3]{0} %xor.327), metadata={op_type="add" op_name="scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %slice.1219 = u32[1]{0} slice(u32[4]{0} %param_1.99), slice={[1:2]}, metadata={op_type="slice" op_name="scan/while/body/slice[ limit_indices=(2,)\n                       start_indices=(1,)\n                       strides=(1,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %reshape.2840 = u32[] reshape(u32[1]{0} %slice.1219), metadata={op_type="squeeze" op_name="scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %broadcast.1692 = u32[3]{0} broadcast(u32[] %reshape.2840), dimensions={}, metadata={op_type="shift_left" op_name="scan/while/body/shift_left" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %shift-left.136 = u32[3]{0} shift-left(u32[3]{0} %xor.327, u32[3]{0} %broadcast.1692), metadata={op_type="shift_left" op_name="scan/while/body/shift_left" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %subtract.472 = u32[] subtract(u32[] %constant.20386, u32[] %reshape.2840), metadata={op_type="sub" op_name="scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %broadcast.1691 = u32[3]{0} broadcast(u32[] %subtract.472), dimensions={}, metadata={op_type="shift_right_logical" op_name="scan/while/body/shift_right_logical" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %shift-right-logical.155 = u32[3]{0} shift-right-logical(u32[3]{0} %xor.327, u32[3]{0} %broadcast.1691), metadata={op_type="shift_right_logical" op_name="scan/while/body/shift_right_logical" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %or.139 = u32[3]{0} or(u32[3]{0} %shift-left.136, u32[3]{0} %shift-right-logical.155), metadata={op_type="or" op_name="scan/while/body/or" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %xor.326 = u32[3]{0} xor(u32[3]{0} %add.3930, u32[3]{0} %or.139), metadata={op_type="xor" op_name="scan/while/body/xor" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %add.3929 = u32[3]{0} add(u32[3]{0} %add.3930, u32[3]{0} %xor.326), metadata={op_type="add" op_name="scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %slice.1218 = u32[1]{0} slice(u32[4]{0} %param_1.99), slice={[2:3]}, metadata={op_type="slice" op_name="scan/while/body/slice[ limit_indices=(3,)\n                       start_indices=(2,)\n                       strides=(1,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %reshape.2839 = u32[] reshape(u32[1]{0} %slice.1218), metadata={op_type="squeeze" op_name="scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %broadcast.1690 = u32[3]{0} broadcast(u32[] %reshape.2839), dimensions={}, metadata={op_type="shift_left" op_name="scan/while/body/shift_left" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %shift-left.135 = u32[3]{0} shift-left(u32[3]{0} %xor.326, u32[3]{0} %broadcast.1690), metadata={op_type="shift_left" op_name="scan/while/body/shift_left" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %subtract.471 = u32[] subtract(u32[] %constant.20386, u32[] %reshape.2839), metadata={op_type="sub" op_name="scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %broadcast.1689 = u32[3]{0} broadcast(u32[] %subtract.471), dimensions={}, metadata={op_type="shift_right_logical" op_name="scan/while/body/shift_right_logical" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %shift-right-logical.154 = u32[3]{0} shift-right-logical(u32[3]{0} %xor.326, u32[3]{0} %broadcast.1689), metadata={op_type="shift_right_logical" op_name="scan/while/body/shift_right_logical" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %or.138 = u32[3]{0} or(u32[3]{0} %shift-left.135, u32[3]{0} %shift-right-logical.154), metadata={op_type="or" op_name="scan/while/body/or" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %xor.325 = u32[3]{0} xor(u32[3]{0} %add.3929, u32[3]{0} %or.138), metadata={op_type="xor" op_name="scan/while/body/xor" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %add.3928 = u32[3]{0} add(u32[3]{0} %add.3929, u32[3]{0} %xor.325), metadata={op_type="add" op_name="scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %param_0.45 = u32[] parameter(0)
  %broadcast.1688 = u32[3]{0} broadcast(u32[] %param_0.45), dimensions={}, metadata={op_type="add" op_name="scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  ROOT %add.3927 = u32[3]{0} add(u32[3]{0} %add.3928, u32[3]{0} %broadcast.1688), metadata={op_type="add" op_name="scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
}

%body_computation__169.6963.clone.clone.clone (parameter.34: (s32[], u32[3], u32[3], u32[], u32[], /*index=5*/u32[], u32[4], u32[4])) -> (s32[], u32[3], u32[3], u32[], u32[], /*index=5*/u32[], u32[4], u32[4]) {
  %parameter.34 = (s32[], u32[3]{0}, u32[3]{0}, u32[], u32[], /*index=5*/u32[], u32[4]{0}, u32[4]{0}) parameter(0)
  %get-tuple-element.27202 = s32[] get-tuple-element((s32[], u32[3]{0}, u32[3]{0}, u32[], u32[], /*index=5*/u32[], u32[4]{0}, u32[4]{0}) %parameter.34), index=0
  %copy.565 = s32[] copy(s32[] %get-tuple-element.27202)
  %constant.10347 = s32[] constant(1), metadata={op_type="add" op_name="scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %add.1396 = s32[] add(s32[] %copy.565, s32[] %constant.10347), metadata={op_type="add" op_name="scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.27205 = u32[] get-tuple-element((s32[], u32[3]{0}, u32[3]{0}, u32[], u32[], /*index=5*/u32[], u32[4]{0}, u32[4]{0}) %parameter.34), index=3
  %copy.568 = u32[] copy(u32[] %get-tuple-element.27205)
  %get-tuple-element.27208 = u32[4]{0} get-tuple-element((s32[], u32[3]{0}, u32[3]{0}, u32[], u32[], /*index=5*/u32[], u32[4]{0}, u32[4]{0}) %parameter.34), index=6
  %copy.571 = u32[4]{0} copy(u32[4]{0} %get-tuple-element.27208)
  %get-tuple-element.27204 = u32[3]{0} get-tuple-element((s32[], u32[3]{0}, u32[3]{0}, u32[], u32[], /*index=5*/u32[], u32[4]{0}, u32[4]{0}) %parameter.34), index=2
  %copy.567 = u32[3]{0} copy(u32[3]{0} %get-tuple-element.27204)
  %get-tuple-element.27203 = u32[3]{0} get-tuple-element((s32[], u32[3]{0}, u32[3]{0}, u32[], u32[], /*index=5*/u32[], u32[4]{0}, u32[4]{0}) %parameter.34), index=1
  %copy.566 = u32[3]{0} copy(u32[3]{0} %get-tuple-element.27203)
  %fusion.17 = u32[3]{0} fusion(u32[] %copy.568, u32[4]{0} %copy.571, u32[3]{0} %copy.567, u32[3]{0} %copy.566), kind=kLoop, calls=%fused_computation.17, metadata={op_type="add" op_name="scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %get-tuple-element.27206 = u32[] get-tuple-element((s32[], u32[3]{0}, u32[3]{0}, u32[], u32[], /*index=5*/u32[], u32[4]{0}, u32[4]{0}) %parameter.34), index=4
  %copy.569 = u32[] copy(u32[] %get-tuple-element.27206)
  %fusion.16 = u32[3]{0} fusion(u32[] %copy.569, u32[4]{0} %copy.571, u32[3]{0} %copy.567, u32[3]{0} %copy.566, s32[] %copy.565), kind=kLoop, calls=%fused_computation.16, metadata={op_type="add" op_name="scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %copy.576 = u32[] copy(u32[] %copy.569), control-predecessors={%copy.568}
  %get-tuple-element.27207 = u32[] get-tuple-element((s32[], u32[3]{0}, u32[3]{0}, u32[], u32[], /*index=5*/u32[], u32[4]{0}, u32[4]{0}) %parameter.34), index=5
  %copy.570 = u32[] copy(u32[] %get-tuple-element.27207)
  %copy.577 = u32[] copy(u32[] %copy.570), control-predecessors={%copy.569}
  %copy.578 = u32[] copy(u32[] %copy.568), control-predecessors={%copy.570}
  %get-tuple-element.27209 = u32[4]{0} get-tuple-element((s32[], u32[3]{0}, u32[3]{0}, u32[], u32[], /*index=5*/u32[], u32[4]{0}, u32[4]{0}) %parameter.34), index=7
  %copy.572 = u32[4]{0} copy(u32[4]{0} %get-tuple-element.27209)
  %copy.579 = u32[4]{0} copy(u32[4]{0} %copy.572), control-predecessors={%copy.571}
  %copy.580 = u32[4]{0} copy(u32[4]{0} %copy.571), control-predecessors={%copy.572}
  ROOT %tuple.1300 = (s32[], u32[3]{0}, u32[3]{0}, u32[], u32[], /*index=5*/u32[], u32[4]{0}, u32[4]{0}) tuple(s32[] %add.1396, u32[3]{0} %fusion.17, u32[3]{0} %fusion.16, u32[] %copy.576, u32[] %copy.577, /*index=5*/u32[] %copy.578, u32[4]{0} %copy.579, u32[4]{0} %copy.580)
}

%cond_computation__169.7033.clone.clone (parameter.35: (s32[], u32[3], u32[3], u32[], u32[], /*index=5*/u32[], u32[4], u32[4])) -> pred[] {
  %parameter.35 = (s32[], u32[3]{0}, u32[3]{0}, u32[], u32[], /*index=5*/u32[], u32[4]{0}, u32[4]{0}) parameter(0)
  %get-tuple-element.15389 = s32[] get-tuple-element((s32[], u32[3]{0}, u32[3]{0}, u32[], u32[], /*index=5*/u32[], u32[4]{0}, u32[4]{0}) %parameter.35), index=0
  %constant.10353 = s32[] constant(5), metadata={op_type="lt" op_name="scan/while/cond/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %compare.1606 = pred[] compare(s32[] %get-tuple-element.15389, s32[] %constant.10353), direction=LT, metadata={op_type="lt" op_name="scan/while/cond/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.18 (param_0.48: u32[], param_1.105: u32[4], param_2.112: u32[3], param_3.125: u32[3], param_4.200: s32[]) -> u32[3] {
  %param_3.125 = u32[3]{0} parameter(3)
  %param_2.112 = u32[3]{0} parameter(2)
  %add.3937 = u32[3]{0} add(u32[3]{0} %param_3.125, u32[3]{0} %param_2.112), metadata={op_type="add" op_name="scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %param_1.105 = u32[4]{0} parameter(1)
  %slice.1225 = u32[1]{0} slice(u32[4]{0} %param_1.105), slice={[0:1]}, metadata={op_type="slice" op_name="scan/while/body/slice[ limit_indices=(1,)\n                       start_indices=(0,)\n                       strides=(1,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %reshape.2845 = u32[] reshape(u32[1]{0} %slice.1225), metadata={op_type="squeeze" op_name="scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %broadcast.1704 = u32[3]{0} broadcast(u32[] %reshape.2845), dimensions={}, metadata={op_type="shift_left" op_name="scan/while/body/shift_left" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %shift-left.141 = u32[3]{0} shift-left(u32[3]{0} %param_2.112, u32[3]{0} %broadcast.1704), metadata={op_type="shift_left" op_name="scan/while/body/shift_left" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %constant.20388 = u32[] constant(32), metadata={op_type="sub" op_name="scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %subtract.477 = u32[] subtract(u32[] %constant.20388, u32[] %reshape.2845), metadata={op_type="sub" op_name="scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %broadcast.1703 = u32[3]{0} broadcast(u32[] %subtract.477), dimensions={}, metadata={op_type="shift_right_logical" op_name="scan/while/body/shift_right_logical" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %shift-right-logical.160 = u32[3]{0} shift-right-logical(u32[3]{0} %param_2.112, u32[3]{0} %broadcast.1703), metadata={op_type="shift_right_logical" op_name="scan/while/body/shift_right_logical" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %or.144 = u32[3]{0} or(u32[3]{0} %shift-left.141, u32[3]{0} %shift-right-logical.160), metadata={op_type="or" op_name="scan/while/body/or" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %xor.331 = u32[3]{0} xor(u32[3]{0} %add.3937, u32[3]{0} %or.144), metadata={op_type="xor" op_name="scan/while/body/xor" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %add.3936 = u32[3]{0} add(u32[3]{0} %add.3937, u32[3]{0} %xor.331), metadata={op_type="add" op_name="scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %slice.1223 = u32[1]{0} slice(u32[4]{0} %param_1.105), slice={[1:2]}, metadata={op_type="slice" op_name="scan/while/body/slice[ limit_indices=(2,)\n                       start_indices=(1,)\n                       strides=(1,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %reshape.2844 = u32[] reshape(u32[1]{0} %slice.1223), metadata={op_type="squeeze" op_name="scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %broadcast.1702 = u32[3]{0} broadcast(u32[] %reshape.2844), dimensions={}, metadata={op_type="shift_left" op_name="scan/while/body/shift_left" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %shift-left.140 = u32[3]{0} shift-left(u32[3]{0} %xor.331, u32[3]{0} %broadcast.1702), metadata={op_type="shift_left" op_name="scan/while/body/shift_left" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %subtract.476 = u32[] subtract(u32[] %constant.20388, u32[] %reshape.2844), metadata={op_type="sub" op_name="scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %broadcast.1701 = u32[3]{0} broadcast(u32[] %subtract.476), dimensions={}, metadata={op_type="shift_right_logical" op_name="scan/while/body/shift_right_logical" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %shift-right-logical.159 = u32[3]{0} shift-right-logical(u32[3]{0} %xor.331, u32[3]{0} %broadcast.1701), metadata={op_type="shift_right_logical" op_name="scan/while/body/shift_right_logical" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %or.143 = u32[3]{0} or(u32[3]{0} %shift-left.140, u32[3]{0} %shift-right-logical.159), metadata={op_type="or" op_name="scan/while/body/or" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %xor.330 = u32[3]{0} xor(u32[3]{0} %add.3936, u32[3]{0} %or.143), metadata={op_type="xor" op_name="scan/while/body/xor" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %add.3935 = u32[3]{0} add(u32[3]{0} %add.3936, u32[3]{0} %xor.330), metadata={op_type="add" op_name="scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %slice.1222 = u32[1]{0} slice(u32[4]{0} %param_1.105), slice={[2:3]}, metadata={op_type="slice" op_name="scan/while/body/slice[ limit_indices=(3,)\n                       start_indices=(2,)\n                       strides=(1,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %reshape.2843 = u32[] reshape(u32[1]{0} %slice.1222), metadata={op_type="squeeze" op_name="scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %broadcast.1700 = u32[3]{0} broadcast(u32[] %reshape.2843), dimensions={}, metadata={op_type="shift_left" op_name="scan/while/body/shift_left" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %shift-left.139 = u32[3]{0} shift-left(u32[3]{0} %xor.330, u32[3]{0} %broadcast.1700), metadata={op_type="shift_left" op_name="scan/while/body/shift_left" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %subtract.475 = u32[] subtract(u32[] %constant.20388, u32[] %reshape.2843), metadata={op_type="sub" op_name="scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %broadcast.1699 = u32[3]{0} broadcast(u32[] %subtract.475), dimensions={}, metadata={op_type="shift_right_logical" op_name="scan/while/body/shift_right_logical" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %shift-right-logical.158 = u32[3]{0} shift-right-logical(u32[3]{0} %xor.330, u32[3]{0} %broadcast.1699), metadata={op_type="shift_right_logical" op_name="scan/while/body/shift_right_logical" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %or.142 = u32[3]{0} or(u32[3]{0} %shift-left.139, u32[3]{0} %shift-right-logical.158), metadata={op_type="or" op_name="scan/while/body/or" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %xor.329 = u32[3]{0} xor(u32[3]{0} %add.3935, u32[3]{0} %or.142), metadata={op_type="xor" op_name="scan/while/body/xor" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %add.3934 = u32[3]{0} add(u32[3]{0} %add.3935, u32[3]{0} %xor.329), metadata={op_type="add" op_name="scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %slice.1221 = u32[1]{0} slice(u32[4]{0} %param_1.105), slice={[3:4]}, metadata={op_type="slice" op_name="scan/while/body/slice[ limit_indices=(4,)\n                       start_indices=(3,)\n                       strides=(1,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %reshape.2842 = u32[] reshape(u32[1]{0} %slice.1221), metadata={op_type="squeeze" op_name="scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %broadcast.1698 = u32[3]{0} broadcast(u32[] %reshape.2842), dimensions={}, metadata={op_type="shift_left" op_name="scan/while/body/shift_left" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %shift-left.138 = u32[3]{0} shift-left(u32[3]{0} %xor.329, u32[3]{0} %broadcast.1698), metadata={op_type="shift_left" op_name="scan/while/body/shift_left" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %subtract.474 = u32[] subtract(u32[] %constant.20388, u32[] %reshape.2842), metadata={op_type="sub" op_name="scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %broadcast.1697 = u32[3]{0} broadcast(u32[] %subtract.474), dimensions={}, metadata={op_type="shift_right_logical" op_name="scan/while/body/shift_right_logical" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %shift-right-logical.157 = u32[3]{0} shift-right-logical(u32[3]{0} %xor.329, u32[3]{0} %broadcast.1697), metadata={op_type="shift_right_logical" op_name="scan/while/body/shift_right_logical" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %or.141 = u32[3]{0} or(u32[3]{0} %shift-left.138, u32[3]{0} %shift-right-logical.157), metadata={op_type="or" op_name="scan/while/body/or" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %xor.328 = u32[3]{0} xor(u32[3]{0} %add.3934, u32[3]{0} %or.141), metadata={op_type="xor" op_name="scan/while/body/xor" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %param_0.48 = u32[] parameter(0)
  %broadcast.1696 = u32[3]{0} broadcast(u32[] %param_0.48), dimensions={}, metadata={op_type="add" op_name="scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %add.3933 = u32[3]{0} add(u32[3]{0} %xor.328, u32[3]{0} %broadcast.1696), metadata={op_type="add" op_name="scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %param_4.200 = s32[] parameter(4)
  %constant.20389 = s32[] constant(1), metadata={op_type="add" op_name="scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %add.3938 = s32[] add(s32[] %param_4.200, s32[] %constant.20389), metadata={op_type="add" op_name="scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %convert.72 = u32[] convert(s32[] %add.3938), metadata={op_type="convert_element_type" op_name="scan/while/body/convert_element_type[ new_dtype=uint32\n                                      weak_type=False ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %broadcast.1695 = u32[3]{0} broadcast(u32[] %convert.72), dimensions={}, metadata={op_type="add" op_name="scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  ROOT %add.3932 = u32[3]{0} add(u32[3]{0} %add.3933, u32[3]{0} %broadcast.1695), metadata={op_type="add" op_name="scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
}

%fused_computation.19 (param_0.50: u32[], param_1.111: u32[4], param_2.120: u32[3], param_3.135: u32[3]) -> u32[3] {
  %param_3.135 = u32[3]{0} parameter(3)
  %param_2.120 = u32[3]{0} parameter(2)
  %add.3943 = u32[3]{0} add(u32[3]{0} %param_3.135, u32[3]{0} %param_2.120), metadata={op_type="add" op_name="scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %param_1.111 = u32[4]{0} parameter(1)
  %slice.1231 = u32[1]{0} slice(u32[4]{0} %param_1.111), slice={[0:1]}, metadata={op_type="slice" op_name="scan/while/body/slice[ limit_indices=(1,)\n                       start_indices=(0,)\n                       strides=(1,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %reshape.2848 = u32[] reshape(u32[1]{0} %slice.1231), metadata={op_type="squeeze" op_name="scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %broadcast.1712 = u32[3]{0} broadcast(u32[] %reshape.2848), dimensions={}, metadata={op_type="shift_left" op_name="scan/while/body/shift_left" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %shift-left.144 = u32[3]{0} shift-left(u32[3]{0} %param_2.120, u32[3]{0} %broadcast.1712), metadata={op_type="shift_left" op_name="scan/while/body/shift_left" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %constant.20390 = u32[] constant(32), metadata={op_type="sub" op_name="scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %subtract.480 = u32[] subtract(u32[] %constant.20390, u32[] %reshape.2848), metadata={op_type="sub" op_name="scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %broadcast.1711 = u32[3]{0} broadcast(u32[] %subtract.480), dimensions={}, metadata={op_type="shift_right_logical" op_name="scan/while/body/shift_right_logical" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %shift-right-logical.163 = u32[3]{0} shift-right-logical(u32[3]{0} %param_2.120, u32[3]{0} %broadcast.1711), metadata={op_type="shift_right_logical" op_name="scan/while/body/shift_right_logical" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %or.147 = u32[3]{0} or(u32[3]{0} %shift-left.144, u32[3]{0} %shift-right-logical.163), metadata={op_type="or" op_name="scan/while/body/or" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %xor.334 = u32[3]{0} xor(u32[3]{0} %add.3943, u32[3]{0} %or.147), metadata={op_type="xor" op_name="scan/while/body/xor" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %add.3942 = u32[3]{0} add(u32[3]{0} %add.3943, u32[3]{0} %xor.334), metadata={op_type="add" op_name="scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %slice.1230 = u32[1]{0} slice(u32[4]{0} %param_1.111), slice={[1:2]}, metadata={op_type="slice" op_name="scan/while/body/slice[ limit_indices=(2,)\n                       start_indices=(1,)\n                       strides=(1,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %reshape.2847 = u32[] reshape(u32[1]{0} %slice.1230), metadata={op_type="squeeze" op_name="scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %broadcast.1710 = u32[3]{0} broadcast(u32[] %reshape.2847), dimensions={}, metadata={op_type="shift_left" op_name="scan/while/body/shift_left" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %shift-left.143 = u32[3]{0} shift-left(u32[3]{0} %xor.334, u32[3]{0} %broadcast.1710), metadata={op_type="shift_left" op_name="scan/while/body/shift_left" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %subtract.479 = u32[] subtract(u32[] %constant.20390, u32[] %reshape.2847), metadata={op_type="sub" op_name="scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %broadcast.1709 = u32[3]{0} broadcast(u32[] %subtract.479), dimensions={}, metadata={op_type="shift_right_logical" op_name="scan/while/body/shift_right_logical" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %shift-right-logical.162 = u32[3]{0} shift-right-logical(u32[3]{0} %xor.334, u32[3]{0} %broadcast.1709), metadata={op_type="shift_right_logical" op_name="scan/while/body/shift_right_logical" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %or.146 = u32[3]{0} or(u32[3]{0} %shift-left.143, u32[3]{0} %shift-right-logical.162), metadata={op_type="or" op_name="scan/while/body/or" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %xor.333 = u32[3]{0} xor(u32[3]{0} %add.3942, u32[3]{0} %or.146), metadata={op_type="xor" op_name="scan/while/body/xor" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %add.3941 = u32[3]{0} add(u32[3]{0} %add.3942, u32[3]{0} %xor.333), metadata={op_type="add" op_name="scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %slice.1227 = u32[1]{0} slice(u32[4]{0} %param_1.111), slice={[2:3]}, metadata={op_type="slice" op_name="scan/while/body/slice[ limit_indices=(3,)\n                       start_indices=(2,)\n                       strides=(1,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %reshape.2846 = u32[] reshape(u32[1]{0} %slice.1227), metadata={op_type="squeeze" op_name="scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %broadcast.1708 = u32[3]{0} broadcast(u32[] %reshape.2846), dimensions={}, metadata={op_type="shift_left" op_name="scan/while/body/shift_left" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %shift-left.142 = u32[3]{0} shift-left(u32[3]{0} %xor.333, u32[3]{0} %broadcast.1708), metadata={op_type="shift_left" op_name="scan/while/body/shift_left" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %subtract.478 = u32[] subtract(u32[] %constant.20390, u32[] %reshape.2846), metadata={op_type="sub" op_name="scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %broadcast.1707 = u32[3]{0} broadcast(u32[] %subtract.478), dimensions={}, metadata={op_type="shift_right_logical" op_name="scan/while/body/shift_right_logical" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %shift-right-logical.161 = u32[3]{0} shift-right-logical(u32[3]{0} %xor.333, u32[3]{0} %broadcast.1707), metadata={op_type="shift_right_logical" op_name="scan/while/body/shift_right_logical" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %or.145 = u32[3]{0} or(u32[3]{0} %shift-left.142, u32[3]{0} %shift-right-logical.161), metadata={op_type="or" op_name="scan/while/body/or" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %xor.332 = u32[3]{0} xor(u32[3]{0} %add.3941, u32[3]{0} %or.145), metadata={op_type="xor" op_name="scan/while/body/xor" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %add.3940 = u32[3]{0} add(u32[3]{0} %add.3941, u32[3]{0} %xor.332), metadata={op_type="add" op_name="scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %param_0.50 = u32[] parameter(0)
  %broadcast.1705 = u32[3]{0} broadcast(u32[] %param_0.50), dimensions={}, metadata={op_type="add" op_name="scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  ROOT %add.3939 = u32[3]{0} add(u32[3]{0} %add.3940, u32[3]{0} %broadcast.1705), metadata={op_type="add" op_name="scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
}

%body_computation__170.7121.clone.clone.clone (parameter.36: (s32[], u32[3], u32[3], u32[], u32[], /*index=5*/u32[], u32[4], u32[4])) -> (s32[], u32[3], u32[3], u32[], u32[], /*index=5*/u32[], u32[4], u32[4]) {
  %parameter.36 = (s32[], u32[3]{0}, u32[3]{0}, u32[], u32[], /*index=5*/u32[], u32[4]{0}, u32[4]{0}) parameter(0)
  %get-tuple-element.27226 = s32[] get-tuple-element((s32[], u32[3]{0}, u32[3]{0}, u32[], u32[], /*index=5*/u32[], u32[4]{0}, u32[4]{0}) %parameter.36), index=0
  %copy.589 = s32[] copy(s32[] %get-tuple-element.27226)
  %constant.10361 = s32[] constant(1), metadata={op_type="add" op_name="scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %add.1407 = s32[] add(s32[] %copy.589, s32[] %constant.10361), metadata={op_type="add" op_name="scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.27229 = u32[] get-tuple-element((s32[], u32[3]{0}, u32[3]{0}, u32[], u32[], /*index=5*/u32[], u32[4]{0}, u32[4]{0}) %parameter.36), index=3
  %copy.592 = u32[] copy(u32[] %get-tuple-element.27229)
  %get-tuple-element.27232 = u32[4]{0} get-tuple-element((s32[], u32[3]{0}, u32[3]{0}, u32[], u32[], /*index=5*/u32[], u32[4]{0}, u32[4]{0}) %parameter.36), index=6
  %copy.595 = u32[4]{0} copy(u32[4]{0} %get-tuple-element.27232)
  %get-tuple-element.27228 = u32[3]{0} get-tuple-element((s32[], u32[3]{0}, u32[3]{0}, u32[], u32[], /*index=5*/u32[], u32[4]{0}, u32[4]{0}) %parameter.36), index=2
  %copy.591 = u32[3]{0} copy(u32[3]{0} %get-tuple-element.27228)
  %get-tuple-element.27227 = u32[3]{0} get-tuple-element((s32[], u32[3]{0}, u32[3]{0}, u32[], u32[], /*index=5*/u32[], u32[4]{0}, u32[4]{0}) %parameter.36), index=1
  %copy.590 = u32[3]{0} copy(u32[3]{0} %get-tuple-element.27227)
  %fusion.19 = u32[3]{0} fusion(u32[] %copy.592, u32[4]{0} %copy.595, u32[3]{0} %copy.591, u32[3]{0} %copy.590), kind=kLoop, calls=%fused_computation.19, metadata={op_type="add" op_name="scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %get-tuple-element.27230 = u32[] get-tuple-element((s32[], u32[3]{0}, u32[3]{0}, u32[], u32[], /*index=5*/u32[], u32[4]{0}, u32[4]{0}) %parameter.36), index=4
  %copy.593 = u32[] copy(u32[] %get-tuple-element.27230)
  %fusion.18 = u32[3]{0} fusion(u32[] %copy.593, u32[4]{0} %copy.595, u32[3]{0} %copy.591, u32[3]{0} %copy.590, s32[] %copy.589), kind=kLoop, calls=%fused_computation.18, metadata={op_type="add" op_name="scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %copy.600 = u32[] copy(u32[] %copy.593), control-predecessors={%copy.592}
  %get-tuple-element.27231 = u32[] get-tuple-element((s32[], u32[3]{0}, u32[3]{0}, u32[], u32[], /*index=5*/u32[], u32[4]{0}, u32[4]{0}) %parameter.36), index=5
  %copy.594 = u32[] copy(u32[] %get-tuple-element.27231)
  %copy.601 = u32[] copy(u32[] %copy.594), control-predecessors={%copy.593}
  %copy.602 = u32[] copy(u32[] %copy.592), control-predecessors={%copy.594}
  %get-tuple-element.27233 = u32[4]{0} get-tuple-element((s32[], u32[3]{0}, u32[3]{0}, u32[], u32[], /*index=5*/u32[], u32[4]{0}, u32[4]{0}) %parameter.36), index=7
  %copy.596 = u32[4]{0} copy(u32[4]{0} %get-tuple-element.27233)
  %copy.603 = u32[4]{0} copy(u32[4]{0} %copy.596), control-predecessors={%copy.595}
  %copy.604 = u32[4]{0} copy(u32[4]{0} %copy.595), control-predecessors={%copy.596}
  ROOT %tuple.1303 = (s32[], u32[3]{0}, u32[3]{0}, u32[], u32[], /*index=5*/u32[], u32[4]{0}, u32[4]{0}) tuple(s32[] %add.1407, u32[3]{0} %fusion.19, u32[3]{0} %fusion.18, u32[] %copy.600, u32[] %copy.601, /*index=5*/u32[] %copy.602, u32[4]{0} %copy.603, u32[4]{0} %copy.604)
}

%cond_computation__170.7191.clone.clone (parameter.37: (s32[], u32[3], u32[3], u32[], u32[], /*index=5*/u32[], u32[4], u32[4])) -> pred[] {
  %parameter.37 = (s32[], u32[3]{0}, u32[3]{0}, u32[], u32[], /*index=5*/u32[], u32[4]{0}, u32[4]{0}) parameter(0)
  %get-tuple-element.15442 = s32[] get-tuple-element((s32[], u32[3]{0}, u32[3]{0}, u32[], u32[], /*index=5*/u32[], u32[4]{0}, u32[4]{0}) %parameter.37), index=0
  %constant.10368 = s32[] constant(5), metadata={op_type="lt" op_name="scan/while/cond/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %compare.1608 = pred[] compare(s32[] %get-tuple-element.15442, s32[] %constant.10368), direction=LT, metadata={op_type="lt" op_name="scan/while/cond/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.20.clone (param_0.1406: u32[], param_1.2254: u32[4], param_2.1914: u32[16384], param_3.1528: u32[16384], param_4.872: s32[]) -> u32[16384] {
  %param_3.1528 = u32[16384]{0} parameter(3)
  %param_2.1914 = u32[16384]{0} parameter(2)
  %add.4381 = u32[16384]{0} add(u32[16384]{0} %param_3.1528, u32[16384]{0} %param_2.1914), metadata={op_type="add" op_name="scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_1.2254 = u32[4]{0} parameter(1)
  %slice.1450 = u32[1]{0} slice(u32[4]{0} %param_1.2254), slice={[0:1]}, metadata={op_type="slice" op_name="scan/while/body/slice[ limit_indices=(1,)\n                       start_indices=(0,)\n                       strides=(1,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %reshape.3426 = u32[] reshape(u32[1]{0} %slice.1450), metadata={op_type="squeeze" op_name="scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %broadcast.2454 = u32[16384]{0} broadcast(u32[] %reshape.3426), dimensions={}, metadata={op_type="shift_left" op_name="scan/while/body/shift_left" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %shift-left.152 = u32[16384]{0} shift-left(u32[16384]{0} %param_2.1914, u32[16384]{0} %broadcast.2454), metadata={op_type="shift_left" op_name="scan/while/body/shift_left" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant.21328 = u32[] constant(32), metadata={op_type="sub" op_name="scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %subtract.714 = u32[] subtract(u32[] %constant.21328, u32[] %reshape.3426), metadata={op_type="sub" op_name="scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %broadcast.2453 = u32[16384]{0} broadcast(u32[] %subtract.714), dimensions={}, metadata={op_type="shift_right_logical" op_name="scan/while/body/shift_right_logical" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %shift-right-logical.173 = u32[16384]{0} shift-right-logical(u32[16384]{0} %param_2.1914, u32[16384]{0} %broadcast.2453), metadata={op_type="shift_right_logical" op_name="scan/while/body/shift_right_logical" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %or.157 = u32[16384]{0} or(u32[16384]{0} %shift-left.152, u32[16384]{0} %shift-right-logical.173), metadata={op_type="or" op_name="scan/while/body/or" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %xor.359 = u32[16384]{0} xor(u32[16384]{0} %add.4381, u32[16384]{0} %or.157), metadata={op_type="xor" op_name="scan/while/body/xor" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.4382 = u32[16384]{0} add(u32[16384]{0} %add.4381, u32[16384]{0} %xor.359), metadata={op_type="add" op_name="scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %slice.1449 = u32[1]{0} slice(u32[4]{0} %param_1.2254), slice={[1:2]}, metadata={op_type="slice" op_name="scan/while/body/slice[ limit_indices=(2,)\n                       start_indices=(1,)\n                       strides=(1,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %reshape.3425 = u32[] reshape(u32[1]{0} %slice.1449), metadata={op_type="squeeze" op_name="scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %broadcast.2455 = u32[16384]{0} broadcast(u32[] %reshape.3425), dimensions={}, metadata={op_type="shift_left" op_name="scan/while/body/shift_left" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %shift-left.153 = u32[16384]{0} shift-left(u32[16384]{0} %xor.359, u32[16384]{0} %broadcast.2455), metadata={op_type="shift_left" op_name="scan/while/body/shift_left" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %subtract.713 = u32[] subtract(u32[] %constant.21328, u32[] %reshape.3425), metadata={op_type="sub" op_name="scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %broadcast.2452 = u32[16384]{0} broadcast(u32[] %subtract.713), dimensions={}, metadata={op_type="shift_right_logical" op_name="scan/while/body/shift_right_logical" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %shift-right-logical.174 = u32[16384]{0} shift-right-logical(u32[16384]{0} %xor.359, u32[16384]{0} %broadcast.2452), metadata={op_type="shift_right_logical" op_name="scan/while/body/shift_right_logical" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %or.158 = u32[16384]{0} or(u32[16384]{0} %shift-left.153, u32[16384]{0} %shift-right-logical.174), metadata={op_type="or" op_name="scan/while/body/or" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %xor.360 = u32[16384]{0} xor(u32[16384]{0} %add.4382, u32[16384]{0} %or.158), metadata={op_type="xor" op_name="scan/while/body/xor" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.4383 = u32[16384]{0} add(u32[16384]{0} %add.4382, u32[16384]{0} %xor.360), metadata={op_type="add" op_name="scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %slice.1448 = u32[1]{0} slice(u32[4]{0} %param_1.2254), slice={[2:3]}, metadata={op_type="slice" op_name="scan/while/body/slice[ limit_indices=(3,)\n                       start_indices=(2,)\n                       strides=(1,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %reshape.3424 = u32[] reshape(u32[1]{0} %slice.1448), metadata={op_type="squeeze" op_name="scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %broadcast.2456 = u32[16384]{0} broadcast(u32[] %reshape.3424), dimensions={}, metadata={op_type="shift_left" op_name="scan/while/body/shift_left" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %shift-left.154 = u32[16384]{0} shift-left(u32[16384]{0} %xor.360, u32[16384]{0} %broadcast.2456), metadata={op_type="shift_left" op_name="scan/while/body/shift_left" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %subtract.712 = u32[] subtract(u32[] %constant.21328, u32[] %reshape.3424), metadata={op_type="sub" op_name="scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %broadcast.2451 = u32[16384]{0} broadcast(u32[] %subtract.712), dimensions={}, metadata={op_type="shift_right_logical" op_name="scan/while/body/shift_right_logical" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %shift-right-logical.175 = u32[16384]{0} shift-right-logical(u32[16384]{0} %xor.360, u32[16384]{0} %broadcast.2451), metadata={op_type="shift_right_logical" op_name="scan/while/body/shift_right_logical" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %or.159 = u32[16384]{0} or(u32[16384]{0} %shift-left.154, u32[16384]{0} %shift-right-logical.175), metadata={op_type="or" op_name="scan/while/body/or" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %xor.361 = u32[16384]{0} xor(u32[16384]{0} %add.4383, u32[16384]{0} %or.159), metadata={op_type="xor" op_name="scan/while/body/xor" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.4385 = u32[16384]{0} add(u32[16384]{0} %add.4383, u32[16384]{0} %xor.361), metadata={op_type="add" op_name="scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %slice.1447 = u32[1]{0} slice(u32[4]{0} %param_1.2254), slice={[3:4]}, metadata={op_type="slice" op_name="scan/while/body/slice[ limit_indices=(4,)\n                       start_indices=(3,)\n                       strides=(1,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %reshape.3423 = u32[] reshape(u32[1]{0} %slice.1447), metadata={op_type="squeeze" op_name="scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %broadcast.2457 = u32[16384]{0} broadcast(u32[] %reshape.3423), dimensions={}, metadata={op_type="shift_left" op_name="scan/while/body/shift_left" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %shift-left.155 = u32[16384]{0} shift-left(u32[16384]{0} %xor.361, u32[16384]{0} %broadcast.2457), metadata={op_type="shift_left" op_name="scan/while/body/shift_left" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %subtract.710 = u32[] subtract(u32[] %constant.21328, u32[] %reshape.3423), metadata={op_type="sub" op_name="scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %broadcast.2450 = u32[16384]{0} broadcast(u32[] %subtract.710), dimensions={}, metadata={op_type="shift_right_logical" op_name="scan/while/body/shift_right_logical" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %shift-right-logical.176 = u32[16384]{0} shift-right-logical(u32[16384]{0} %xor.361, u32[16384]{0} %broadcast.2450), metadata={op_type="shift_right_logical" op_name="scan/while/body/shift_right_logical" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %or.160 = u32[16384]{0} or(u32[16384]{0} %shift-left.155, u32[16384]{0} %shift-right-logical.176), metadata={op_type="or" op_name="scan/while/body/or" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %xor.362 = u32[16384]{0} xor(u32[16384]{0} %add.4385, u32[16384]{0} %or.160), metadata={op_type="xor" op_name="scan/while/body/xor" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_0.1406 = u32[] parameter(0)
  %broadcast.2449 = u32[16384]{0} broadcast(u32[] %param_0.1406), dimensions={}, metadata={op_type="add" op_name="scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.4387 = u32[16384]{0} add(u32[16384]{0} %xor.362, u32[16384]{0} %broadcast.2449), metadata={op_type="add" op_name="scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_4.872 = s32[] parameter(4)
  %constant.21327 = s32[] constant(1), metadata={op_type="add" op_name="scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.4380 = s32[] add(s32[] %param_4.872, s32[] %constant.21327), metadata={op_type="add" op_name="scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %convert.82 = u32[] convert(s32[] %add.4380), metadata={op_type="convert_element_type" op_name="scan/while/body/convert_element_type[ new_dtype=uint32\n                                      weak_type=False ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %broadcast.2448 = u32[16384]{0} broadcast(u32[] %convert.82), dimensions={}, metadata={op_type="add" op_name="scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %add.4388 = u32[16384]{0} add(u32[16384]{0} %add.4387, u32[16384]{0} %broadcast.2448), metadata={op_type="add" op_name="scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%parallel_fusion.20 (p.62: u32[], p.63: u32[4], p.64: u32[16384], p.65: u32[16384], p.66: s32[]) -> u32[16384] {
  %p.62 = u32[] parameter(0)
  %p.63 = u32[4]{0} parameter(1)
  %p.64 = u32[16384]{0} parameter(2)
  %p.65 = u32[16384]{0} parameter(3)
  %p.66 = s32[] parameter(4)
  ROOT %fusion.20.clone = u32[16384]{0} fusion(u32[] %p.62, u32[4]{0} %p.63, u32[16384]{0} %p.64, u32[16384]{0} %p.65, s32[] %p.66), kind=kLoop, calls=%fused_computation.20.clone, outer_dimension_partitions={23}, metadata={op_type="add" op_name="scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.21.clone (param_0.1407: u32[], param_1.2255: u32[4], param_2.1915: u32[16384], param_3.1529: u32[16384]) -> u32[16384] {
  %param_3.1529 = u32[16384]{0} parameter(3)
  %param_2.1915 = u32[16384]{0} parameter(2)
  %add.4389 = u32[16384]{0} add(u32[16384]{0} %param_3.1529, u32[16384]{0} %param_2.1915), metadata={op_type="add" op_name="scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_1.2255 = u32[4]{0} parameter(1)
  %slice.1453 = u32[1]{0} slice(u32[4]{0} %param_1.2255), slice={[0:1]}, metadata={op_type="slice" op_name="scan/while/body/slice[ limit_indices=(1,)\n                       start_indices=(0,)\n                       strides=(1,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %reshape.3429 = u32[] reshape(u32[1]{0} %slice.1453), metadata={op_type="squeeze" op_name="scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %broadcast.2463 = u32[16384]{0} broadcast(u32[] %reshape.3429), dimensions={}, metadata={op_type="shift_left" op_name="scan/while/body/shift_left" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %shift-left.156 = u32[16384]{0} shift-left(u32[16384]{0} %param_2.1915, u32[16384]{0} %broadcast.2463), metadata={op_type="shift_left" op_name="scan/while/body/shift_left" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant.21330 = u32[] constant(32), metadata={op_type="sub" op_name="scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %subtract.717 = u32[] subtract(u32[] %constant.21330, u32[] %reshape.3429), metadata={op_type="sub" op_name="scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %broadcast.2461 = u32[16384]{0} broadcast(u32[] %subtract.717), dimensions={}, metadata={op_type="shift_right_logical" op_name="scan/while/body/shift_right_logical" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %shift-right-logical.177 = u32[16384]{0} shift-right-logical(u32[16384]{0} %param_2.1915, u32[16384]{0} %broadcast.2461), metadata={op_type="shift_right_logical" op_name="scan/while/body/shift_right_logical" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %or.161 = u32[16384]{0} or(u32[16384]{0} %shift-left.156, u32[16384]{0} %shift-right-logical.177), metadata={op_type="or" op_name="scan/while/body/or" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %xor.363 = u32[16384]{0} xor(u32[16384]{0} %add.4389, u32[16384]{0} %or.161), metadata={op_type="xor" op_name="scan/while/body/xor" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.4390 = u32[16384]{0} add(u32[16384]{0} %add.4389, u32[16384]{0} %xor.363), metadata={op_type="add" op_name="scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %slice.1452 = u32[1]{0} slice(u32[4]{0} %param_1.2255), slice={[1:2]}, metadata={op_type="slice" op_name="scan/while/body/slice[ limit_indices=(2,)\n                       start_indices=(1,)\n                       strides=(1,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %reshape.3428 = u32[] reshape(u32[1]{0} %slice.1452), metadata={op_type="squeeze" op_name="scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %broadcast.2464 = u32[16384]{0} broadcast(u32[] %reshape.3428), dimensions={}, metadata={op_type="shift_left" op_name="scan/while/body/shift_left" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %shift-left.157 = u32[16384]{0} shift-left(u32[16384]{0} %xor.363, u32[16384]{0} %broadcast.2464), metadata={op_type="shift_left" op_name="scan/while/body/shift_left" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %subtract.716 = u32[] subtract(u32[] %constant.21330, u32[] %reshape.3428), metadata={op_type="sub" op_name="scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %broadcast.2460 = u32[16384]{0} broadcast(u32[] %subtract.716), dimensions={}, metadata={op_type="shift_right_logical" op_name="scan/while/body/shift_right_logical" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %shift-right-logical.178 = u32[16384]{0} shift-right-logical(u32[16384]{0} %xor.363, u32[16384]{0} %broadcast.2460), metadata={op_type="shift_right_logical" op_name="scan/while/body/shift_right_logical" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %or.162 = u32[16384]{0} or(u32[16384]{0} %shift-left.157, u32[16384]{0} %shift-right-logical.178), metadata={op_type="or" op_name="scan/while/body/or" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %xor.364 = u32[16384]{0} xor(u32[16384]{0} %add.4390, u32[16384]{0} %or.162), metadata={op_type="xor" op_name="scan/while/body/xor" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.4391 = u32[16384]{0} add(u32[16384]{0} %add.4390, u32[16384]{0} %xor.364), metadata={op_type="add" op_name="scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %slice.1451 = u32[1]{0} slice(u32[4]{0} %param_1.2255), slice={[2:3]}, metadata={op_type="slice" op_name="scan/while/body/slice[ limit_indices=(3,)\n                       start_indices=(2,)\n                       strides=(1,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %reshape.3427 = u32[] reshape(u32[1]{0} %slice.1451), metadata={op_type="squeeze" op_name="scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %broadcast.2465 = u32[16384]{0} broadcast(u32[] %reshape.3427), dimensions={}, metadata={op_type="shift_left" op_name="scan/while/body/shift_left" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %shift-left.158 = u32[16384]{0} shift-left(u32[16384]{0} %xor.364, u32[16384]{0} %broadcast.2465), metadata={op_type="shift_left" op_name="scan/while/body/shift_left" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %subtract.715 = u32[] subtract(u32[] %constant.21330, u32[] %reshape.3427), metadata={op_type="sub" op_name="scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %broadcast.2459 = u32[16384]{0} broadcast(u32[] %subtract.715), dimensions={}, metadata={op_type="shift_right_logical" op_name="scan/while/body/shift_right_logical" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %shift-right-logical.179 = u32[16384]{0} shift-right-logical(u32[16384]{0} %xor.364, u32[16384]{0} %broadcast.2459), metadata={op_type="shift_right_logical" op_name="scan/while/body/shift_right_logical" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %or.163 = u32[16384]{0} or(u32[16384]{0} %shift-left.158, u32[16384]{0} %shift-right-logical.179), metadata={op_type="or" op_name="scan/while/body/or" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %xor.365 = u32[16384]{0} xor(u32[16384]{0} %add.4391, u32[16384]{0} %or.163), metadata={op_type="xor" op_name="scan/while/body/xor" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.4392 = u32[16384]{0} add(u32[16384]{0} %add.4391, u32[16384]{0} %xor.365), metadata={op_type="add" op_name="scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_0.1407 = u32[] parameter(0)
  %broadcast.2458 = u32[16384]{0} broadcast(u32[] %param_0.1407), dimensions={}, metadata={op_type="add" op_name="scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %add.4393 = u32[16384]{0} add(u32[16384]{0} %add.4392, u32[16384]{0} %broadcast.2458), metadata={op_type="add" op_name="scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%parallel_fusion.21 (p.67: u32[], p.68: u32[4], p.69: u32[16384], p.70: u32[16384]) -> u32[16384] {
  %p.67 = u32[] parameter(0)
  %p.68 = u32[4]{0} parameter(1)
  %p.69 = u32[16384]{0} parameter(2)
  %p.70 = u32[16384]{0} parameter(3)
  ROOT %fusion.21.clone = u32[16384]{0} fusion(u32[] %p.67, u32[4]{0} %p.68, u32[16384]{0} %p.69, u32[16384]{0} %p.70), kind=kLoop, calls=%fused_computation.21.clone, outer_dimension_partitions={22}, metadata={op_type="add" op_name="scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%body_computation__175.8226.clone.clone.clone (parameter.38: (s32[], u32[16384], u32[16384], u32[], u32[], /*index=5*/u32[], u32[4], u32[4])) -> (s32[], u32[16384], u32[16384], u32[], u32[], /*index=5*/u32[], u32[4], u32[4]) {
  %parameter.38 = (s32[], u32[16384]{0}, u32[16384]{0}, u32[], u32[], /*index=5*/u32[], u32[4]{0}, u32[4]{0}) parameter(0)
  %get-tuple-element.27250 = s32[] get-tuple-element((s32[], u32[16384]{0}, u32[16384]{0}, u32[], u32[], /*index=5*/u32[], u32[4]{0}, u32[4]{0}) %parameter.38), index=0
  %copy.613 = s32[] copy(s32[] %get-tuple-element.27250)
  %constant.10378 = s32[] constant(1), metadata={op_type="add" op_name="scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.1418 = s32[] add(s32[] %copy.613, s32[] %constant.10378), metadata={op_type="add" op_name="scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.27253 = u32[] get-tuple-element((s32[], u32[16384]{0}, u32[16384]{0}, u32[], u32[], /*index=5*/u32[], u32[4]{0}, u32[4]{0}) %parameter.38), index=3
  %copy.616 = u32[] copy(u32[] %get-tuple-element.27253)
  %get-tuple-element.27256 = u32[4]{0} get-tuple-element((s32[], u32[16384]{0}, u32[16384]{0}, u32[], u32[], /*index=5*/u32[], u32[4]{0}, u32[4]{0}) %parameter.38), index=6
  %copy.619 = u32[4]{0} copy(u32[4]{0} %get-tuple-element.27256)
  %get-tuple-element.27252 = u32[16384]{0} get-tuple-element((s32[], u32[16384]{0}, u32[16384]{0}, u32[], u32[], /*index=5*/u32[], u32[4]{0}, u32[4]{0}) %parameter.38), index=2
  %copy.615 = u32[16384]{0} copy(u32[16384]{0} %get-tuple-element.27252)
  %get-tuple-element.27251 = u32[16384]{0} get-tuple-element((s32[], u32[16384]{0}, u32[16384]{0}, u32[], u32[], /*index=5*/u32[], u32[4]{0}, u32[4]{0}) %parameter.38), index=1
  %copy.614 = u32[16384]{0} copy(u32[16384]{0} %get-tuple-element.27251)
  %call.99 = u32[16384]{0} call(u32[] %copy.616, u32[4]{0} %copy.619, u32[16384]{0} %copy.615, u32[16384]{0} %copy.614), to_apply=%parallel_fusion.21
  %get-tuple-element.27254 = u32[] get-tuple-element((s32[], u32[16384]{0}, u32[16384]{0}, u32[], u32[], /*index=5*/u32[], u32[4]{0}, u32[4]{0}) %parameter.38), index=4
  %copy.617 = u32[] copy(u32[] %get-tuple-element.27254)
  %call.98 = u32[16384]{0} call(u32[] %copy.617, u32[4]{0} %copy.619, u32[16384]{0} %copy.615, u32[16384]{0} %copy.614, s32[] %copy.613), to_apply=%parallel_fusion.20
  %copy.624 = u32[] copy(u32[] %copy.617), control-predecessors={%copy.616}
  %get-tuple-element.27255 = u32[] get-tuple-element((s32[], u32[16384]{0}, u32[16384]{0}, u32[], u32[], /*index=5*/u32[], u32[4]{0}, u32[4]{0}) %parameter.38), index=5
  %copy.618 = u32[] copy(u32[] %get-tuple-element.27255)
  %copy.625 = u32[] copy(u32[] %copy.618), control-predecessors={%copy.617}
  %copy.626 = u32[] copy(u32[] %copy.616), control-predecessors={%copy.618}
  %get-tuple-element.27257 = u32[4]{0} get-tuple-element((s32[], u32[16384]{0}, u32[16384]{0}, u32[], u32[], /*index=5*/u32[], u32[4]{0}, u32[4]{0}) %parameter.38), index=7
  %copy.620 = u32[4]{0} copy(u32[4]{0} %get-tuple-element.27257)
  %copy.627 = u32[4]{0} copy(u32[4]{0} %copy.620), control-predecessors={%copy.619}
  %copy.628 = u32[4]{0} copy(u32[4]{0} %copy.619), control-predecessors={%copy.620}
  ROOT %tuple.1307 = (s32[], u32[16384]{0}, u32[16384]{0}, u32[], u32[], /*index=5*/u32[], u32[4]{0}, u32[4]{0}) tuple(s32[] %add.1418, u32[16384]{0} %call.99, u32[16384]{0} %call.98, u32[] %copy.624, u32[] %copy.625, /*index=5*/u32[] %copy.626, u32[4]{0} %copy.627, u32[4]{0} %copy.628)
}

%cond_computation__175.8296.clone.clone (parameter.39: (s32[], u32[16384], u32[16384], u32[], u32[], /*index=5*/u32[], u32[4], u32[4])) -> pred[] {
  %parameter.39 = (s32[], u32[16384]{0}, u32[16384]{0}, u32[], u32[], /*index=5*/u32[], u32[4]{0}, u32[4]{0}) parameter(0)
  %get-tuple-element.15519 = s32[] get-tuple-element((s32[], u32[16384]{0}, u32[16384]{0}, u32[], u32[], /*index=5*/u32[], u32[4]{0}, u32[4]{0}) %parameter.39), index=0
  %constant.10384 = s32[] constant(5), metadata={op_type="lt" op_name="scan/while/cond/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %compare.1609 = pred[] compare(s32[] %get-tuple-element.15519, s32[] %constant.10384), direction=LT, metadata={op_type="lt" op_name="scan/while/cond/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%primitive_computation_add__1.15354 (parameter.15355: f32[], parameter.15356: f32[]) -> f32[] {
  %parameter.15355 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.15356 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.15357 = f32[] add(f32[] %parameter.15355, f32[] %parameter.15356), metadata={op_type="add" op_name="add"}
}

%fused_computation.22 (param_0.56: f32[64,8,1024], param_1.125: s32[], param_2.139: f32[8,1024]) -> f32[64,8,1024] {
  %param_0.56 = f32[64,8,1024]{2,1,0} parameter(0)
  %constant.20396 = f32[] constant(1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %broadcast.1731 = f32[8,1024]{1,0} broadcast(f32[] %constant.20396), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %param_2.139 = f32[8,1024]{1,0} parameter(2)
  %subtract.488 = f32[8,1024]{1,0} subtract(f32[8,1024]{1,0} %broadcast.1731, f32[8,1024]{1,0} %param_2.139), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %reshape.2856 = f32[1,8,1024]{2,1,0} reshape(f32[8,1024]{1,0} %subtract.488), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_1.125 = s32[] parameter(1)
  %constant.20395 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.764 = f32[64,8,1024]{2,1,0} dynamic-update-slice(f32[64,8,1024]{2,1,0} %param_0.56, f32[1,8,1024]{2,1,0} %reshape.2856, s32[] %param_1.125, s32[] %constant.20395, s32[] %constant.20395), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.23 (param_0.57: f32[64,8,1024], param_1.127: s32[], param_2.142: f32[8,1024]) -> f32[64,8,1024] {
  %param_0.57 = f32[64,8,1024]{2,1,0} parameter(0)
  %param_2.142 = f32[8,1024]{1,0} parameter(2)
  %reshape.2857 = f32[1,8,1024]{2,1,0} reshape(f32[8,1024]{1,0} %param_2.142), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_1.127 = s32[] parameter(1)
  %constant.20397 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.765 = f32[64,8,1024]{2,1,0} dynamic-update-slice(f32[64,8,1024]{2,1,0} %param_0.57, f32[1,8,1024]{2,1,0} %reshape.2857, s32[] %param_1.127, s32[] %constant.20397, s32[] %constant.20397), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.24 (param_0.58: f32[64,8,1024], param_1.129: s32[], param_2.146: f32[8,1024]) -> f32[64,8,1024] {
  %param_0.58 = f32[64,8,1024]{2,1,0} parameter(0)
  %constant.20399 = f32[] constant(1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %broadcast.1732 = f32[8,1024]{1,0} broadcast(f32[] %constant.20399), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %param_2.146 = f32[8,1024]{1,0} parameter(2)
  %subtract.489 = f32[8,1024]{1,0} subtract(f32[8,1024]{1,0} %broadcast.1732, f32[8,1024]{1,0} %param_2.146), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  %reshape.2858 = f32[1,8,1024]{2,1,0} reshape(f32[8,1024]{1,0} %subtract.489), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_1.129 = s32[] parameter(1)
  %constant.20398 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.766 = f32[64,8,1024]{2,1,0} dynamic-update-slice(f32[64,8,1024]{2,1,0} %param_0.58, f32[1,8,1024]{2,1,0} %reshape.2858, s32[] %param_1.129, s32[] %constant.20398, s32[] %constant.20398), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.25 (param_0.59: f32[64,8,1024], param_1.131: s32[], param_2.149: f32[8,1024]) -> f32[64,8,1024] {
  %param_0.59 = f32[64,8,1024]{2,1,0} parameter(0)
  %param_2.149 = f32[8,1024]{1,0} parameter(2)
  %reshape.2859 = f32[1,8,1024]{2,1,0} reshape(f32[8,1024]{1,0} %param_2.149), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_1.131 = s32[] parameter(1)
  %constant.20401 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.767 = f32[64,8,1024]{2,1,0} dynamic-update-slice(f32[64,8,1024]{2,1,0} %param_0.59, f32[1,8,1024]{2,1,0} %reshape.2859, s32[] %param_1.131, s32[] %constant.20401, s32[] %constant.20401), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.26 (param_0.60: f32[64,8,1024], param_1.133: s32[], param_2.153: f32[8,1024]) -> f32[64,8,1024] {
  %param_0.60 = f32[64,8,1024]{2,1,0} parameter(0)
  %constant.20403 = f32[] constant(1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %broadcast.1733 = f32[8,1024]{1,0} broadcast(f32[] %constant.20403), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %param_2.153 = f32[8,1024]{1,0} parameter(2)
  %subtract.490 = f32[8,1024]{1,0} subtract(f32[8,1024]{1,0} %broadcast.1733, f32[8,1024]{1,0} %param_2.153), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %reshape.2860 = f32[1,8,1024]{2,1,0} reshape(f32[8,1024]{1,0} %subtract.490), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_1.133 = s32[] parameter(1)
  %constant.20402 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.768 = f32[64,8,1024]{2,1,0} dynamic-update-slice(f32[64,8,1024]{2,1,0} %param_0.60, f32[1,8,1024]{2,1,0} %reshape.2860, s32[] %param_1.133, s32[] %constant.20402, s32[] %constant.20402), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.27 (param_0.61: f32[64,8,1024], param_1.135: s32[], param_2.156: f32[8,1024]) -> f32[64,8,1024] {
  %param_0.61 = f32[64,8,1024]{2,1,0} parameter(0)
  %param_2.156 = f32[8,1024]{1,0} parameter(2)
  %reshape.2861 = f32[1,8,1024]{2,1,0} reshape(f32[8,1024]{1,0} %param_2.156), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_1.135 = s32[] parameter(1)
  %constant.20404 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.769 = f32[64,8,1024]{2,1,0} dynamic-update-slice(f32[64,8,1024]{2,1,0} %param_0.61, f32[1,8,1024]{2,1,0} %reshape.2861, s32[] %param_1.135, s32[] %constant.20404, s32[] %constant.20404), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.28 (param_0.62: f32[64,8,1024], param_1.137: s32[], param_2.160: f32[8,1024]) -> f32[64,8,1024] {
  %param_0.62 = f32[64,8,1024]{2,1,0} parameter(0)
  %constant.20407 = f32[] constant(1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %broadcast.1734 = f32[8,1024]{1,0} broadcast(f32[] %constant.20407), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %param_2.160 = f32[8,1024]{1,0} parameter(2)
  %subtract.491 = f32[8,1024]{1,0} subtract(f32[8,1024]{1,0} %broadcast.1734, f32[8,1024]{1,0} %param_2.160), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %reshape.2862 = f32[1,8,1024]{2,1,0} reshape(f32[8,1024]{1,0} %subtract.491), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_1.137 = s32[] parameter(1)
  %constant.20405 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.770 = f32[64,8,1024]{2,1,0} dynamic-update-slice(f32[64,8,1024]{2,1,0} %param_0.62, f32[1,8,1024]{2,1,0} %reshape.2862, s32[] %param_1.137, s32[] %constant.20405, s32[] %constant.20405), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.29 (param_0.63: f32[64,8,1024], param_1.139: s32[], param_2.163: f32[8,1024]) -> f32[64,8,1024] {
  %param_0.63 = f32[64,8,1024]{2,1,0} parameter(0)
  %param_2.163 = f32[8,1024]{1,0} parameter(2)
  %reshape.2863 = f32[1,8,1024]{2,1,0} reshape(f32[8,1024]{1,0} %param_2.163), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_1.139 = s32[] parameter(1)
  %constant.20408 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.771 = f32[64,8,1024]{2,1,0} dynamic-update-slice(f32[64,8,1024]{2,1,0} %param_0.63, f32[1,8,1024]{2,1,0} %reshape.2863, s32[] %param_1.139, s32[] %constant.20408, s32[] %constant.20408), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.30 (param_0.64: f32[64,8,1024], param_1.141: s32[], param_2.167: f32[8,1024]) -> f32[64,8,1024] {
  %param_0.64 = f32[64,8,1024]{2,1,0} parameter(0)
  %constant.20411 = f32[] constant(1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %broadcast.1735 = f32[8,1024]{1,0} broadcast(f32[] %constant.20411), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %param_2.167 = f32[8,1024]{1,0} parameter(2)
  %subtract.492 = f32[8,1024]{1,0} subtract(f32[8,1024]{1,0} %broadcast.1735, f32[8,1024]{1,0} %param_2.167), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %reshape.2864 = f32[1,8,1024]{2,1,0} reshape(f32[8,1024]{1,0} %subtract.492), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_1.141 = s32[] parameter(1)
  %constant.20409 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.772 = f32[64,8,1024]{2,1,0} dynamic-update-slice(f32[64,8,1024]{2,1,0} %param_0.64, f32[1,8,1024]{2,1,0} %reshape.2864, s32[] %param_1.141, s32[] %constant.20409, s32[] %constant.20409), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.31 (param_0.65: f32[64,8,2048], param_1.143: s32[], param_2.170: f32[8,2048]) -> f32[64,8,2048] {
  %param_0.65 = f32[64,8,2048]{2,1,0} parameter(0)
  %param_2.170 = f32[8,2048]{1,0} parameter(2)
  %reshape.2865 = f32[1,8,2048]{2,1,0} reshape(f32[8,2048]{1,0} %param_2.170), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 8, 2048) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_1.143 = s32[] parameter(1)
  %constant.20412 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.773 = f32[64,8,2048]{2,1,0} dynamic-update-slice(f32[64,8,2048]{2,1,0} %param_0.65, f32[1,8,2048]{2,1,0} %reshape.2865, s32[] %param_1.143, s32[] %constant.20412, s32[] %constant.20412), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.32 (param_0.66: f32[64,8,1024], param_1.145: s32[], param_2.174: f32[8,2048]) -> f32[64,8,1024] {
  %param_0.66 = f32[64,8,1024]{2,1,0} parameter(0)
  %param_2.174 = f32[8,2048]{1,0} parameter(2)
  %slice.1239 = f32[8,1024]{1,0} slice(f32[8,2048]{1,0} %param_2.174), slice={[0:8], [0:1024]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(8, 1024)\n                                                     start_indices=(0, 0)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=54}
  %reshape.2866 = f32[1,8,1024]{2,1,0} reshape(f32[8,1024]{1,0} %slice.1239), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_1.145 = s32[] parameter(1)
  %constant.20414 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.774 = f32[64,8,1024]{2,1,0} dynamic-update-slice(f32[64,8,1024]{2,1,0} %param_0.66, f32[1,8,1024]{2,1,0} %reshape.2866, s32[] %param_1.145, s32[] %constant.20414, s32[] %constant.20414), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.33 (param_0.67: f32[64,8,1024], param_1.147: s32[], param_2.177: f32[8,1024]) -> f32[64,8,1024] {
  %param_0.67 = f32[64,8,1024]{2,1,0} parameter(0)
  %param_2.177 = f32[8,1024]{1,0} parameter(2)
  %reshape.2867 = f32[1,8,1024]{2,1,0} reshape(f32[8,1024]{1,0} %param_2.177), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_1.147 = s32[] parameter(1)
  %constant.20415 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.775 = f32[64,8,1024]{2,1,0} dynamic-update-slice(f32[64,8,1024]{2,1,0} %param_0.67, f32[1,8,1024]{2,1,0} %reshape.2867, s32[] %param_1.147, s32[] %constant.20415, s32[] %constant.20415), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.34 (param_0.68: f32[64,8,1024], param_1.149: s32[], param_2.180: f32[8,1024], param_3.196: f32[8,1024]) -> f32[64,8,1024] {
  %param_0.68 = f32[64,8,1024]{2,1,0} parameter(0)
  %param_2.180 = f32[8,1024]{1,0} parameter(2)
  %param_3.196 = f32[8,1024]{1,0} parameter(3)
  %multiply.1364 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %param_2.180, f32[8,1024]{1,0} %param_3.196), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  %reshape.2868 = f32[1,8,1024]{2,1,0} reshape(f32[8,1024]{1,0} %multiply.1364), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_1.149 = s32[] parameter(1)
  %constant.20416 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.776 = f32[64,8,1024]{2,1,0} dynamic-update-slice(f32[64,8,1024]{2,1,0} %param_0.68, f32[1,8,1024]{2,1,0} %reshape.2868, s32[] %param_1.149, s32[] %constant.20416, s32[] %constant.20416), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.35 (param_0.69: f32[8,1024], param_1.151: f32[8,1024], param_2.181: f32[8,1024]) -> f32[8,2048] {
  %param_0.69 = f32[8,1024]{1,0} parameter(0)
  %param_1.151 = f32[8,1024]{1,0} parameter(1)
  %param_2.181 = f32[8,1024]{1,0} parameter(2)
  %multiply.1365 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %param_1.151, f32[8,1024]{1,0} %param_2.181), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  ROOT %concatenate.228 = f32[8,2048]{1,0} concatenate(f32[8,1024]{1,0} %param_0.69, f32[8,1024]{1,0} %multiply.1365), dimensions={1}, metadata={op_type="concatenate" op_name="pmap(_multi_device_update_fn)/scan/while/body/concatenate[ dimension=1 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=65}
}

%fused_computation.36 (param_0.71: f32[8,4096], param_1.158: f32[1,4096]) -> f32[8,1024] {
  %constant.20417 = f32[] constant(1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %broadcast.1737 = f32[8,1024]{1,0} broadcast(f32[] %constant.20417), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %param_0.71 = f32[8,4096]{1,0} parameter(0)
  %param_1.158 = f32[1,4096]{1,0} parameter(1)
  %reshape.2869 = f32[4096]{0} reshape(f32[1,4096]{1,0} %param_1.158), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %broadcast.1736 = f32[8,4096]{1,0} broadcast(f32[4096]{0} %reshape.2869), dimensions={1}, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %add.3957 = f32[8,4096]{1,0} add(f32[8,4096]{1,0} %param_0.71, f32[8,4096]{1,0} %broadcast.1736), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %slice.1240 = f32[8,1024]{1,0} slice(f32[8,4096]{1,0} %add.3957), slice={[0:8], [3072:4096]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(8, 4096)\n                                                     start_indices=(0, 3072)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  %negate.190 = f32[8,1024]{1,0} negate(f32[8,1024]{1,0} %slice.1240), metadata={op_type="neg" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/neg" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %exponential.162 = f32[8,1024]{1,0} exponential(f32[8,1024]{1,0} %negate.190), metadata={op_type="exp" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/exp" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %add.3956 = f32[8,1024]{1,0} add(f32[8,1024]{1,0} %broadcast.1737, f32[8,1024]{1,0} %exponential.162), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  ROOT %divide.166 = f32[8,1024]{1,0} divide(f32[8,1024]{1,0} %broadcast.1737, f32[8,1024]{1,0} %add.3956), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
}

%fused_computation.37 (param_0.73: f32[8,1024], param_1.161: f32[8,1024], param_2.188: f32[8,1024], param_3.198: f32[8,2048]) -> f32[8,1024] {
  %param_3.198 = f32[8,2048]{1,0} parameter(3)
  %slice.1241 = f32[8,1024]{1,0} slice(f32[8,2048]{1,0} %param_3.198), slice={[0:8], [0:1024]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(8, 1024)\n                                                     start_indices=(0, 0)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=54}
  %param_2.188 = f32[8,1024]{1,0} parameter(2)
  %multiply.1367 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %slice.1241, f32[8,1024]{1,0} %param_2.188), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %param_0.73 = f32[8,1024]{1,0} parameter(0)
  %param_1.161 = f32[8,1024]{1,0} parameter(1)
  %multiply.1366 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %param_0.73, f32[8,1024]{1,0} %param_1.161), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  ROOT %add.3958 = f32[8,1024]{1,0} add(f32[8,1024]{1,0} %multiply.1367, f32[8,1024]{1,0} %multiply.1366), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
}

%fused_computation.38 (param_0.76: f32[8,4096], param_1.164: f32[1,4096]) -> f32[8,1024] {
  %param_0.76 = f32[8,4096]{1,0} parameter(0)
  %param_1.164 = f32[1,4096]{1,0} parameter(1)
  %reshape.2870 = f32[4096]{0} reshape(f32[1,4096]{1,0} %param_1.164), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %broadcast.1738 = f32[8,4096]{1,0} broadcast(f32[4096]{0} %reshape.2870), dimensions={1}, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %add.3959 = f32[8,4096]{1,0} add(f32[8,4096]{1,0} %param_0.76, f32[8,4096]{1,0} %broadcast.1738), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %slice.1242 = f32[8,1024]{1,0} slice(f32[8,4096]{1,0} %add.3959), slice={[0:8], [1024:2048]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(8, 2048)\n                                                     start_indices=(0, 1024)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  ROOT %tanh.108 = f32[8,1024]{1,0} tanh(f32[8,1024]{1,0} %slice.1242), metadata={op_type="tanh" op_name="pmap(_multi_device_update_fn)/scan/while/body/tanh" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
}

%fused_computation.39 (param_0.78: f32[8,4096], param_1.171: f32[1,4096]) -> f32[8,1024] {
  %constant.20418 = f32[] constant(1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %broadcast.1740 = f32[8,1024]{1,0} broadcast(f32[] %constant.20418), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %param_0.78 = f32[8,4096]{1,0} parameter(0)
  %param_1.171 = f32[1,4096]{1,0} parameter(1)
  %reshape.2871 = f32[4096]{0} reshape(f32[1,4096]{1,0} %param_1.171), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %broadcast.1739 = f32[8,4096]{1,0} broadcast(f32[4096]{0} %reshape.2871), dimensions={1}, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %add.3961 = f32[8,4096]{1,0} add(f32[8,4096]{1,0} %param_0.78, f32[8,4096]{1,0} %broadcast.1739), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %slice.1243 = f32[8,1024]{1,0} slice(f32[8,4096]{1,0} %add.3961), slice={[0:8], [0:1024]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(8, 1024)\n                                                     start_indices=(0, 0)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  %negate.191 = f32[8,1024]{1,0} negate(f32[8,1024]{1,0} %slice.1243), metadata={op_type="neg" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/neg" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %exponential.163 = f32[8,1024]{1,0} exponential(f32[8,1024]{1,0} %negate.191), metadata={op_type="exp" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/exp" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %add.3960 = f32[8,1024]{1,0} add(f32[8,1024]{1,0} %broadcast.1740, f32[8,1024]{1,0} %exponential.163), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  ROOT %divide.167 = f32[8,1024]{1,0} divide(f32[8,1024]{1,0} %broadcast.1740, f32[8,1024]{1,0} %add.3960), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
}

%fused_computation.40 (param_0.80: f32[8,4096], param_1.178: f32[1,4096]) -> f32[8,1024] {
  %constant.20420 = f32[] constant(1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %broadcast.1742 = f32[8,1024]{1,0} broadcast(f32[] %constant.20420), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %param_0.80 = f32[8,4096]{1,0} parameter(0)
  %param_1.178 = f32[1,4096]{1,0} parameter(1)
  %reshape.2872 = f32[4096]{0} reshape(f32[1,4096]{1,0} %param_1.178), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %broadcast.1741 = f32[8,4096]{1,0} broadcast(f32[4096]{0} %reshape.2872), dimensions={1}, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %add.3963 = f32[8,4096]{1,0} add(f32[8,4096]{1,0} %param_0.80, f32[8,4096]{1,0} %broadcast.1741), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %slice.1244 = f32[8,1024]{1,0} slice(f32[8,4096]{1,0} %add.3963), slice={[0:8], [2048:3072]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(8, 3072)\n                                                     start_indices=(0, 2048)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  %negate.192 = f32[8,1024]{1,0} negate(f32[8,1024]{1,0} %slice.1244), metadata={op_type="neg" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/neg" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %exponential.164 = f32[8,1024]{1,0} exponential(f32[8,1024]{1,0} %negate.192), metadata={op_type="exp" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/exp" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %add.3962 = f32[8,1024]{1,0} add(f32[8,1024]{1,0} %broadcast.1742, f32[8,1024]{1,0} %exponential.164), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  ROOT %divide.168 = f32[8,1024]{1,0} divide(f32[8,1024]{1,0} %broadcast.1742, f32[8,1024]{1,0} %add.3962), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
}

%fused_computation.41 (param_0.82: f32[8,2048], param_1.182: f32[64,8,1024], param_2.197: s32[]) -> f32[8,2048] {
  %param_1.182 = f32[64,8,1024]{2,1,0} parameter(1)
  %param_2.197 = s32[] parameter(2)
  %constant.20421 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %dynamic-slice.778 = f32[1,8,1024]{2,1,0} dynamic-slice(f32[64,8,1024]{2,1,0} %param_1.182, s32[] %param_2.197, s32[] %constant.20421, s32[] %constant.20421), dynamic_slice_sizes={1,8,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %reshape.2873 = f32[8,1024]{1,0} reshape(f32[1,8,1024]{2,1,0} %dynamic-slice.778), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_0.82 = f32[8,2048]{1,0} parameter(0)
  %slice.1245 = f32[8,1024]{1,0} slice(f32[8,2048]{1,0} %param_0.82), slice={[0:8], [1024:2048]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(8, 2048)\n                                                     start_indices=(0, 1024)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=54}
  ROOT %concatenate.229 = f32[8,2048]{1,0} concatenate(f32[8,1024]{1,0} %reshape.2873, f32[8,1024]{1,0} %slice.1245), dimensions={1}, metadata={op_type="concatenate" op_name="pmap(_multi_device_update_fn)/scan/while/body/concatenate[ dimension=1 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
}

%fused_computation.42 (param_0.84: s32[]) -> s32[] {
  %param_0.84 = s32[] parameter(0)
  %constant.20423 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.2744 = pred[] compare(s32[] %param_0.84, s32[] %constant.20423), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant.20422 = s32[] constant(64), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.3964 = s32[] add(s32[] %param_0.84, s32[] %constant.20422), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %select.2633 = s32[] select(pred[] %compare.2744, s32[] %add.3964, s32[] %param_0.84), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%wide.body_computation__147.1360.clone.clone.clone.clone.clone (wide_param.171: (f32[64,8,1024], f32[2048,4096], f32[1,4096], s32[], f32[8,2048], /*index=5*/f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[64,8,2048], f32[64,8,1024], /*index=10*/f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], /*index=15*/f32[64,8,1024], f32[64,8,1024], f32[64,8,1024])) -> (f32[64,8,1024], f32[2048,4096], f32[1,4096], s32[], f32[8,2048], /*index=5*/f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[64,8,2048], f32[64,8,1024], /*index=10*/f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], /*index=15*/f32[64,8,1024], f32[64,8,1024], f32[64,8,1024]) {
  %wide_param.171 = (f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) parameter(0)
  %get-tuple-element.26876 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %wide_param.171), index=0
  %get-tuple-element.26877 = f32[2048,4096]{1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %wide_param.171), index=1
  %get-tuple-element.26878 = f32[1,4096]{1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %wide_param.171), index=2
  %get-tuple-element.26879 = s32[] get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %wide_param.171), index=3
  %copy.272 = s32[] copy(s32[] %get-tuple-element.26879)
  %constant.18475 = s32[] constant(1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.3413 = s32[] add(s32[] %copy.272, s32[] %constant.18475), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.26880 = f32[8,2048]{1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %wide_param.171), index=4
  %copy.273 = f32[8,2048]{1,0} copy(f32[8,2048]{1,0} %get-tuple-element.26880)
  %fusion.42 = s32[] fusion(s32[] %copy.272), kind=kLoop, calls=%fused_computation.42, metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %fusion.41 = f32[8,2048]{1,0} fusion(f32[8,2048]{1,0} %copy.273, f32[64,8,1024]{2,1,0} %get-tuple-element.26876, s32[] %fusion.42), kind=kLoop, calls=%fused_computation.41, metadata={op_type="concatenate" op_name="pmap(_multi_device_update_fn)/scan/while/body/concatenate[ dimension=1 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %dot.170 = f32[8,4096]{1,0} dot(f32[8,2048]{1,0} %fusion.41, f32[2048,4096]{1,0} %get-tuple-element.26877), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="dot_general" op_name="pmap(_multi_device_update_fn)/scan/while/body/dot_general[ dimension_numbers=(((1,), (0,)), ((), ()))\n                                                           precision=None\n                                                           preferred_element_type=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %fusion.39 = f32[8,1024]{1,0} fusion(f32[8,4096]{1,0} %dot.170, f32[1,4096]{1,0} %get-tuple-element.26878), kind=kLoop, calls=%fused_computation.39, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %fusion.38 = f32[8,1024]{1,0} fusion(f32[8,4096]{1,0} %dot.170, f32[1,4096]{1,0} %get-tuple-element.26878), kind=kLoop, calls=%fused_computation.38, metadata={op_type="tanh" op_name="pmap(_multi_device_update_fn)/scan/while/body/tanh" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %fusion.40 = f32[8,1024]{1,0} fusion(f32[8,4096]{1,0} %dot.170, f32[1,4096]{1,0} %get-tuple-element.26878), kind=kLoop, calls=%fused_computation.40, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %fusion.37 = f32[8,1024]{1,0} fusion(f32[8,1024]{1,0} %fusion.39, f32[8,1024]{1,0} %fusion.38, f32[8,1024]{1,0} %fusion.40, f32[8,2048]{1,0} %copy.273), kind=kLoop, calls=%fused_computation.37, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %tanh.91 = f32[8,1024]{1,0} tanh(f32[8,1024]{1,0} %fusion.37), metadata={op_type="tanh" op_name="pmap(_multi_device_update_fn)/scan/while/body/tanh" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  %fusion.36 = f32[8,1024]{1,0} fusion(f32[8,4096]{1,0} %dot.170, f32[1,4096]{1,0} %get-tuple-element.26878), kind=kLoop, calls=%fused_computation.36, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %fusion.35 = f32[8,2048]{1,0} fusion(f32[8,1024]{1,0} %fusion.37, f32[8,1024]{1,0} %tanh.91, f32[8,1024]{1,0} %fusion.36), kind=kLoop, calls=%fused_computation.35, metadata={op_type="concatenate" op_name="pmap(_multi_device_update_fn)/scan/while/body/concatenate[ dimension=1 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=65}
  %get-tuple-element.26881 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %wide_param.171), index=5
  %fusion.34 = f32[64,8,1024]{2,1,0} fusion(f32[64,8,1024]{2,1,0} %get-tuple-element.26881, s32[] %fusion.42, f32[8,1024]{1,0} %tanh.91, f32[8,1024]{1,0} %fusion.36), kind=kLoop, calls=%fused_computation.34, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.26882 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %wide_param.171), index=6
  %fusion.33 = f32[64,8,1024]{2,1,0} fusion(f32[64,8,1024]{2,1,0} %get-tuple-element.26882, s32[] %fusion.42, f32[8,1024]{1,0} %fusion.40), kind=kLoop, calls=%fused_computation.33, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.26883 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %wide_param.171), index=7
  %fusion.32 = f32[64,8,1024]{2,1,0} fusion(f32[64,8,1024]{2,1,0} %get-tuple-element.26883, s32[] %fusion.42, f32[8,2048]{1,0} %copy.273), kind=kLoop, calls=%fused_computation.32, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.26884 = f32[64,8,2048]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %wide_param.171), index=8
  %fusion.31 = f32[64,8,2048]{2,1,0} fusion(f32[64,8,2048]{2,1,0} %get-tuple-element.26884, s32[] %fusion.42, f32[8,2048]{1,0} %fusion.41), kind=kLoop, calls=%fused_computation.31, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.26885 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %wide_param.171), index=9
  %fusion.30 = f32[64,8,1024]{2,1,0} fusion(f32[64,8,1024]{2,1,0} %get-tuple-element.26885, s32[] %fusion.42, f32[8,1024]{1,0} %fusion.40), kind=kLoop, calls=%fused_computation.30, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.26886 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %wide_param.171), index=10
  %fusion.29 = f32[64,8,1024]{2,1,0} fusion(f32[64,8,1024]{2,1,0} %get-tuple-element.26886, s32[] %fusion.42, f32[8,1024]{1,0} %fusion.39), kind=kLoop, calls=%fused_computation.29, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.26887 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %wide_param.171), index=11
  %fusion.28 = f32[64,8,1024]{2,1,0} fusion(f32[64,8,1024]{2,1,0} %get-tuple-element.26887, s32[] %fusion.42, f32[8,1024]{1,0} %fusion.39), kind=kLoop, calls=%fused_computation.28, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.26888 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %wide_param.171), index=12
  %fusion.27 = f32[64,8,1024]{2,1,0} fusion(f32[64,8,1024]{2,1,0} %get-tuple-element.26888, s32[] %fusion.42, f32[8,1024]{1,0} %fusion.38), kind=kLoop, calls=%fused_computation.27, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.26889 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %wide_param.171), index=13
  %fusion.26 = f32[64,8,1024]{2,1,0} fusion(f32[64,8,1024]{2,1,0} %get-tuple-element.26889, s32[] %fusion.42, f32[8,1024]{1,0} %fusion.38), kind=kLoop, calls=%fused_computation.26, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.26890 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %wide_param.171), index=14
  %fusion.25 = f32[64,8,1024]{2,1,0} fusion(f32[64,8,1024]{2,1,0} %get-tuple-element.26890, s32[] %fusion.42, f32[8,1024]{1,0} %tanh.91), kind=kLoop, calls=%fused_computation.25, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.26891 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %wide_param.171), index=15
  %fusion.24 = f32[64,8,1024]{2,1,0} fusion(f32[64,8,1024]{2,1,0} %get-tuple-element.26891, s32[] %fusion.42, f32[8,1024]{1,0} %tanh.91), kind=kLoop, calls=%fused_computation.24, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.26892 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %wide_param.171), index=16
  %fusion.23 = f32[64,8,1024]{2,1,0} fusion(f32[64,8,1024]{2,1,0} %get-tuple-element.26892, s32[] %fusion.42, f32[8,1024]{1,0} %fusion.36), kind=kLoop, calls=%fused_computation.23, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.26893 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %wide_param.171), index=17
  %fusion.22 = f32[64,8,1024]{2,1,0} fusion(f32[64,8,1024]{2,1,0} %get-tuple-element.26893, s32[] %fusion.42, f32[8,1024]{1,0} %fusion.36), kind=kLoop, calls=%fused_computation.22, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %tuple.1270 = (f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) tuple(f32[64,8,1024]{2,1,0} %get-tuple-element.26876, f32[2048,4096]{1,0} %get-tuple-element.26877, f32[1,4096]{1,0} %get-tuple-element.26878, s32[] %add.3413, f32[8,2048]{1,0} %fusion.35, /*index=5*/f32[64,8,1024]{2,1,0} %fusion.34, f32[64,8,1024]{2,1,0} %fusion.33, f32[64,8,1024]{2,1,0} %fusion.32, f32[64,8,2048]{2,1,0} %fusion.31, f32[64,8,1024]{2,1,0} %fusion.30, /*index=10*/f32[64,8,1024]{2,1,0} %fusion.29, f32[64,8,1024]{2,1,0} %fusion.28, f32[64,8,1024]{2,1,0} %fusion.27, f32[64,8,1024]{2,1,0} %fusion.26, f32[64,8,1024]{2,1,0} %fusion.25, /*index=15*/f32[64,8,1024]{2,1,0} %fusion.24, f32[64,8,1024]{2,1,0} %fusion.23, f32[64,8,1024]{2,1,0} %fusion.22)
}

%wide.cond_computation__147.1781.clone.clone.clone.clone (wide_param.172: (f32[64,8,1024], f32[2048,4096], f32[1,4096], s32[], f32[8,2048], /*index=5*/f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[64,8,2048], f32[64,8,1024], /*index=10*/f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], /*index=15*/f32[64,8,1024], f32[64,8,1024], f32[64,8,1024])) -> pred[] {
  %wide_param.172 = (f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) parameter(0)
  %get-tuple-element.24374 = s32[] get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %wide_param.172), index=3
  %constant.18478 = s32[] constant(64), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/cond/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %compare.2454 = pred[] compare(s32[] %get-tuple-element.24374, s32[] %constant.18478), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/cond/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.43 (param_0.85: f32[64,8,1024], param_1.187: s32[], param_2.203: f32[8,1024]) -> f32[64,8,1024] {
  %param_0.85 = f32[64,8,1024]{2,1,0} parameter(0)
  %constant.20426 = f32[] constant(1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %broadcast.1743 = f32[8,1024]{1,0} broadcast(f32[] %constant.20426), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %param_2.203 = f32[8,1024]{1,0} parameter(2)
  %subtract.493 = f32[8,1024]{1,0} subtract(f32[8,1024]{1,0} %broadcast.1743, f32[8,1024]{1,0} %param_2.203), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %reshape.2874 = f32[1,8,1024]{2,1,0} reshape(f32[8,1024]{1,0} %subtract.493), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_1.187 = s32[] parameter(1)
  %constant.20425 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.777 = f32[64,8,1024]{2,1,0} dynamic-update-slice(f32[64,8,1024]{2,1,0} %param_0.85, f32[1,8,1024]{2,1,0} %reshape.2874, s32[] %param_1.187, s32[] %constant.20425, s32[] %constant.20425), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.44 (param_0.86: f32[64,8,1024], param_1.189: s32[], param_2.206: f32[8,1024]) -> f32[64,8,1024] {
  %param_0.86 = f32[64,8,1024]{2,1,0} parameter(0)
  %param_2.206 = f32[8,1024]{1,0} parameter(2)
  %reshape.2875 = f32[1,8,1024]{2,1,0} reshape(f32[8,1024]{1,0} %param_2.206), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_1.189 = s32[] parameter(1)
  %constant.20427 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.778 = f32[64,8,1024]{2,1,0} dynamic-update-slice(f32[64,8,1024]{2,1,0} %param_0.86, f32[1,8,1024]{2,1,0} %reshape.2875, s32[] %param_1.189, s32[] %constant.20427, s32[] %constant.20427), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.45 (param_0.87: f32[64,8,1024], param_1.191: s32[], param_2.210: f32[8,1024]) -> f32[64,8,1024] {
  %param_0.87 = f32[64,8,1024]{2,1,0} parameter(0)
  %constant.20430 = f32[] constant(1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %broadcast.1744 = f32[8,1024]{1,0} broadcast(f32[] %constant.20430), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %param_2.210 = f32[8,1024]{1,0} parameter(2)
  %subtract.494 = f32[8,1024]{1,0} subtract(f32[8,1024]{1,0} %broadcast.1744, f32[8,1024]{1,0} %param_2.210), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  %reshape.2876 = f32[1,8,1024]{2,1,0} reshape(f32[8,1024]{1,0} %subtract.494), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_1.191 = s32[] parameter(1)
  %constant.20428 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.779 = f32[64,8,1024]{2,1,0} dynamic-update-slice(f32[64,8,1024]{2,1,0} %param_0.87, f32[1,8,1024]{2,1,0} %reshape.2876, s32[] %param_1.191, s32[] %constant.20428, s32[] %constant.20428), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.46 (param_0.88: f32[64,8,1024], param_1.193: s32[], param_2.213: f32[8,1024]) -> f32[64,8,1024] {
  %param_0.88 = f32[64,8,1024]{2,1,0} parameter(0)
  %param_2.213 = f32[8,1024]{1,0} parameter(2)
  %reshape.2877 = f32[1,8,1024]{2,1,0} reshape(f32[8,1024]{1,0} %param_2.213), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_1.193 = s32[] parameter(1)
  %constant.20431 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.780 = f32[64,8,1024]{2,1,0} dynamic-update-slice(f32[64,8,1024]{2,1,0} %param_0.88, f32[1,8,1024]{2,1,0} %reshape.2877, s32[] %param_1.193, s32[] %constant.20431, s32[] %constant.20431), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.47 (param_0.89: f32[64,8,1024], param_1.195: s32[], param_2.217: f32[8,1024]) -> f32[64,8,1024] {
  %param_0.89 = f32[64,8,1024]{2,1,0} parameter(0)
  %constant.20433 = f32[] constant(1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %broadcast.1745 = f32[8,1024]{1,0} broadcast(f32[] %constant.20433), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %param_2.217 = f32[8,1024]{1,0} parameter(2)
  %subtract.495 = f32[8,1024]{1,0} subtract(f32[8,1024]{1,0} %broadcast.1745, f32[8,1024]{1,0} %param_2.217), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %reshape.2878 = f32[1,8,1024]{2,1,0} reshape(f32[8,1024]{1,0} %subtract.495), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_1.195 = s32[] parameter(1)
  %constant.20432 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.781 = f32[64,8,1024]{2,1,0} dynamic-update-slice(f32[64,8,1024]{2,1,0} %param_0.89, f32[1,8,1024]{2,1,0} %reshape.2878, s32[] %param_1.195, s32[] %constant.20432, s32[] %constant.20432), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.48 (param_0.90: f32[64,8,1024], param_1.197: s32[], param_2.220: f32[8,1024]) -> f32[64,8,1024] {
  %param_0.90 = f32[64,8,1024]{2,1,0} parameter(0)
  %param_2.220 = f32[8,1024]{1,0} parameter(2)
  %reshape.2879 = f32[1,8,1024]{2,1,0} reshape(f32[8,1024]{1,0} %param_2.220), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_1.197 = s32[] parameter(1)
  %constant.20434 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.782 = f32[64,8,1024]{2,1,0} dynamic-update-slice(f32[64,8,1024]{2,1,0} %param_0.90, f32[1,8,1024]{2,1,0} %reshape.2879, s32[] %param_1.197, s32[] %constant.20434, s32[] %constant.20434), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.49 (param_0.91: f32[64,8,1024], param_1.199: s32[], param_2.224: f32[8,1024]) -> f32[64,8,1024] {
  %param_0.91 = f32[64,8,1024]{2,1,0} parameter(0)
  %constant.20437 = f32[] constant(1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %broadcast.1746 = f32[8,1024]{1,0} broadcast(f32[] %constant.20437), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %param_2.224 = f32[8,1024]{1,0} parameter(2)
  %subtract.496 = f32[8,1024]{1,0} subtract(f32[8,1024]{1,0} %broadcast.1746, f32[8,1024]{1,0} %param_2.224), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %reshape.2880 = f32[1,8,1024]{2,1,0} reshape(f32[8,1024]{1,0} %subtract.496), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_1.199 = s32[] parameter(1)
  %constant.20436 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.783 = f32[64,8,1024]{2,1,0} dynamic-update-slice(f32[64,8,1024]{2,1,0} %param_0.91, f32[1,8,1024]{2,1,0} %reshape.2880, s32[] %param_1.199, s32[] %constant.20436, s32[] %constant.20436), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.50 (param_0.92: f32[64,8,1024], param_1.201: s32[], param_2.227: f32[8,1024]) -> f32[64,8,1024] {
  %param_0.92 = f32[64,8,1024]{2,1,0} parameter(0)
  %param_2.227 = f32[8,1024]{1,0} parameter(2)
  %reshape.2881 = f32[1,8,1024]{2,1,0} reshape(f32[8,1024]{1,0} %param_2.227), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_1.201 = s32[] parameter(1)
  %constant.20438 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.784 = f32[64,8,1024]{2,1,0} dynamic-update-slice(f32[64,8,1024]{2,1,0} %param_0.92, f32[1,8,1024]{2,1,0} %reshape.2881, s32[] %param_1.201, s32[] %constant.20438, s32[] %constant.20438), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.51 (param_0.93: f32[64,8,1024], param_1.203: s32[], param_2.231: f32[8,1024]) -> f32[64,8,1024] {
  %param_0.93 = f32[64,8,1024]{2,1,0} parameter(0)
  %constant.20440 = f32[] constant(1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %broadcast.1747 = f32[8,1024]{1,0} broadcast(f32[] %constant.20440), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %param_2.231 = f32[8,1024]{1,0} parameter(2)
  %subtract.497 = f32[8,1024]{1,0} subtract(f32[8,1024]{1,0} %broadcast.1747, f32[8,1024]{1,0} %param_2.231), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %reshape.2882 = f32[1,8,1024]{2,1,0} reshape(f32[8,1024]{1,0} %subtract.497), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_1.203 = s32[] parameter(1)
  %constant.20439 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.785 = f32[64,8,1024]{2,1,0} dynamic-update-slice(f32[64,8,1024]{2,1,0} %param_0.93, f32[1,8,1024]{2,1,0} %reshape.2882, s32[] %param_1.203, s32[] %constant.20439, s32[] %constant.20439), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.52 (param_0.94: f32[64,8,2048], param_1.205: s32[], param_2.234: f32[8,2048]) -> f32[64,8,2048] {
  %param_0.94 = f32[64,8,2048]{2,1,0} parameter(0)
  %param_2.234 = f32[8,2048]{1,0} parameter(2)
  %reshape.2883 = f32[1,8,2048]{2,1,0} reshape(f32[8,2048]{1,0} %param_2.234), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 8, 2048) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_1.205 = s32[] parameter(1)
  %constant.20441 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.786 = f32[64,8,2048]{2,1,0} dynamic-update-slice(f32[64,8,2048]{2,1,0} %param_0.94, f32[1,8,2048]{2,1,0} %reshape.2883, s32[] %param_1.205, s32[] %constant.20441, s32[] %constant.20441), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.53 (param_0.95: f32[64,8,1024], param_1.207: s32[], param_2.238: f32[8,2048]) -> f32[64,8,1024] {
  %param_0.95 = f32[64,8,1024]{2,1,0} parameter(0)
  %param_2.238 = f32[8,2048]{1,0} parameter(2)
  %slice.1246 = f32[8,1024]{1,0} slice(f32[8,2048]{1,0} %param_2.238), slice={[0:8], [0:1024]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(8, 1024)\n                                                     start_indices=(0, 0)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=54}
  %reshape.2884 = f32[1,8,1024]{2,1,0} reshape(f32[8,1024]{1,0} %slice.1246), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_1.207 = s32[] parameter(1)
  %constant.20442 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.787 = f32[64,8,1024]{2,1,0} dynamic-update-slice(f32[64,8,1024]{2,1,0} %param_0.95, f32[1,8,1024]{2,1,0} %reshape.2884, s32[] %param_1.207, s32[] %constant.20442, s32[] %constant.20442), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.54 (param_0.96: f32[64,8,1024], param_1.209: s32[], param_2.241: f32[8,1024]) -> f32[64,8,1024] {
  %param_0.96 = f32[64,8,1024]{2,1,0} parameter(0)
  %param_2.241 = f32[8,1024]{1,0} parameter(2)
  %reshape.2885 = f32[1,8,1024]{2,1,0} reshape(f32[8,1024]{1,0} %param_2.241), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_1.209 = s32[] parameter(1)
  %constant.20444 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.788 = f32[64,8,1024]{2,1,0} dynamic-update-slice(f32[64,8,1024]{2,1,0} %param_0.96, f32[1,8,1024]{2,1,0} %reshape.2885, s32[] %param_1.209, s32[] %constant.20444, s32[] %constant.20444), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.55 (param_0.97: f32[64,8,1024], param_1.211: s32[], param_2.244: f32[8,1024], param_3.242: f32[8,1024]) -> f32[64,8,1024] {
  %param_0.97 = f32[64,8,1024]{2,1,0} parameter(0)
  %param_2.244 = f32[8,1024]{1,0} parameter(2)
  %param_3.242 = f32[8,1024]{1,0} parameter(3)
  %multiply.1368 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %param_2.244, f32[8,1024]{1,0} %param_3.242), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  %reshape.2886 = f32[1,8,1024]{2,1,0} reshape(f32[8,1024]{1,0} %multiply.1368), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_1.211 = s32[] parameter(1)
  %constant.20445 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.789 = f32[64,8,1024]{2,1,0} dynamic-update-slice(f32[64,8,1024]{2,1,0} %param_0.97, f32[1,8,1024]{2,1,0} %reshape.2886, s32[] %param_1.211, s32[] %constant.20445, s32[] %constant.20445), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.56 (param_0.98: f32[8,1024], param_1.213: f32[8,1024], param_2.245: f32[8,1024]) -> f32[8,2048] {
  %param_0.98 = f32[8,1024]{1,0} parameter(0)
  %param_1.213 = f32[8,1024]{1,0} parameter(1)
  %param_2.245 = f32[8,1024]{1,0} parameter(2)
  %multiply.1369 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %param_1.213, f32[8,1024]{1,0} %param_2.245), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  ROOT %concatenate.230 = f32[8,2048]{1,0} concatenate(f32[8,1024]{1,0} %param_0.98, f32[8,1024]{1,0} %multiply.1369), dimensions={1}, metadata={op_type="concatenate" op_name="pmap(_multi_device_update_fn)/scan/while/body/concatenate[ dimension=1 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=65}
}

%fused_computation.57 (param_0.100: f32[8,4096], param_1.220: f32[1,4096]) -> f32[8,1024] {
  %constant.20446 = f32[] constant(1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %broadcast.1749 = f32[8,1024]{1,0} broadcast(f32[] %constant.20446), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %param_0.100 = f32[8,4096]{1,0} parameter(0)
  %param_1.220 = f32[1,4096]{1,0} parameter(1)
  %reshape.2887 = f32[4096]{0} reshape(f32[1,4096]{1,0} %param_1.220), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %broadcast.1748 = f32[8,4096]{1,0} broadcast(f32[4096]{0} %reshape.2887), dimensions={1}, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %add.3966 = f32[8,4096]{1,0} add(f32[8,4096]{1,0} %param_0.100, f32[8,4096]{1,0} %broadcast.1748), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %slice.1247 = f32[8,1024]{1,0} slice(f32[8,4096]{1,0} %add.3966), slice={[0:8], [3072:4096]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(8, 4096)\n                                                     start_indices=(0, 3072)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  %negate.193 = f32[8,1024]{1,0} negate(f32[8,1024]{1,0} %slice.1247), metadata={op_type="neg" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/neg" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %exponential.165 = f32[8,1024]{1,0} exponential(f32[8,1024]{1,0} %negate.193), metadata={op_type="exp" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/exp" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %add.3965 = f32[8,1024]{1,0} add(f32[8,1024]{1,0} %broadcast.1749, f32[8,1024]{1,0} %exponential.165), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  ROOT %divide.169 = f32[8,1024]{1,0} divide(f32[8,1024]{1,0} %broadcast.1749, f32[8,1024]{1,0} %add.3965), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
}

%fused_computation.58 (param_0.102: f32[8,1024], param_1.223: f32[8,1024], param_2.252: f32[8,1024], param_3.244: f32[8,2048]) -> f32[8,1024] {
  %param_3.244 = f32[8,2048]{1,0} parameter(3)
  %slice.1248 = f32[8,1024]{1,0} slice(f32[8,2048]{1,0} %param_3.244), slice={[0:8], [0:1024]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(8, 1024)\n                                                     start_indices=(0, 0)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=54}
  %param_2.252 = f32[8,1024]{1,0} parameter(2)
  %multiply.1371 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %slice.1248, f32[8,1024]{1,0} %param_2.252), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %param_0.102 = f32[8,1024]{1,0} parameter(0)
  %param_1.223 = f32[8,1024]{1,0} parameter(1)
  %multiply.1370 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %param_0.102, f32[8,1024]{1,0} %param_1.223), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  ROOT %add.3967 = f32[8,1024]{1,0} add(f32[8,1024]{1,0} %multiply.1371, f32[8,1024]{1,0} %multiply.1370), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
}

%fused_computation.59 (param_0.105: f32[8,4096], param_1.226: f32[1,4096]) -> f32[8,1024] {
  %param_0.105 = f32[8,4096]{1,0} parameter(0)
  %param_1.226 = f32[1,4096]{1,0} parameter(1)
  %reshape.2888 = f32[4096]{0} reshape(f32[1,4096]{1,0} %param_1.226), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %broadcast.1750 = f32[8,4096]{1,0} broadcast(f32[4096]{0} %reshape.2888), dimensions={1}, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %add.3968 = f32[8,4096]{1,0} add(f32[8,4096]{1,0} %param_0.105, f32[8,4096]{1,0} %broadcast.1750), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %slice.1249 = f32[8,1024]{1,0} slice(f32[8,4096]{1,0} %add.3968), slice={[0:8], [1024:2048]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(8, 2048)\n                                                     start_indices=(0, 1024)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  ROOT %tanh.109 = f32[8,1024]{1,0} tanh(f32[8,1024]{1,0} %slice.1249), metadata={op_type="tanh" op_name="pmap(_multi_device_update_fn)/scan/while/body/tanh" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
}

%fused_computation.60 (param_0.107: f32[8,4096], param_1.233: f32[1,4096]) -> f32[8,1024] {
  %constant.20447 = f32[] constant(1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %broadcast.1753 = f32[8,1024]{1,0} broadcast(f32[] %constant.20447), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %param_0.107 = f32[8,4096]{1,0} parameter(0)
  %param_1.233 = f32[1,4096]{1,0} parameter(1)
  %reshape.2889 = f32[4096]{0} reshape(f32[1,4096]{1,0} %param_1.233), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %broadcast.1751 = f32[8,4096]{1,0} broadcast(f32[4096]{0} %reshape.2889), dimensions={1}, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %add.3970 = f32[8,4096]{1,0} add(f32[8,4096]{1,0} %param_0.107, f32[8,4096]{1,0} %broadcast.1751), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %slice.1250 = f32[8,1024]{1,0} slice(f32[8,4096]{1,0} %add.3970), slice={[0:8], [0:1024]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(8, 1024)\n                                                     start_indices=(0, 0)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  %negate.194 = f32[8,1024]{1,0} negate(f32[8,1024]{1,0} %slice.1250), metadata={op_type="neg" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/neg" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %exponential.166 = f32[8,1024]{1,0} exponential(f32[8,1024]{1,0} %negate.194), metadata={op_type="exp" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/exp" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %add.3969 = f32[8,1024]{1,0} add(f32[8,1024]{1,0} %broadcast.1753, f32[8,1024]{1,0} %exponential.166), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  ROOT %divide.170 = f32[8,1024]{1,0} divide(f32[8,1024]{1,0} %broadcast.1753, f32[8,1024]{1,0} %add.3969), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
}

%fused_computation.61 (param_0.109: f32[8,4096], param_1.240: f32[1,4096]) -> f32[8,1024] {
  %constant.20448 = f32[] constant(1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %broadcast.1755 = f32[8,1024]{1,0} broadcast(f32[] %constant.20448), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %param_0.109 = f32[8,4096]{1,0} parameter(0)
  %param_1.240 = f32[1,4096]{1,0} parameter(1)
  %reshape.2890 = f32[4096]{0} reshape(f32[1,4096]{1,0} %param_1.240), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %broadcast.1754 = f32[8,4096]{1,0} broadcast(f32[4096]{0} %reshape.2890), dimensions={1}, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %add.3972 = f32[8,4096]{1,0} add(f32[8,4096]{1,0} %param_0.109, f32[8,4096]{1,0} %broadcast.1754), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %slice.1251 = f32[8,1024]{1,0} slice(f32[8,4096]{1,0} %add.3972), slice={[0:8], [2048:3072]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(8, 3072)\n                                                     start_indices=(0, 2048)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  %negate.195 = f32[8,1024]{1,0} negate(f32[8,1024]{1,0} %slice.1251), metadata={op_type="neg" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/neg" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %exponential.167 = f32[8,1024]{1,0} exponential(f32[8,1024]{1,0} %negate.195), metadata={op_type="exp" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/exp" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %add.3971 = f32[8,1024]{1,0} add(f32[8,1024]{1,0} %broadcast.1755, f32[8,1024]{1,0} %exponential.167), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  ROOT %divide.171 = f32[8,1024]{1,0} divide(f32[8,1024]{1,0} %broadcast.1755, f32[8,1024]{1,0} %add.3971), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
}

%fused_computation.62 (param_0.111: f32[8,2048], param_1.244: f32[64,8,1024], param_2.261: s32[]) -> f32[8,2048] {
  %param_1.244 = f32[64,8,1024]{2,1,0} parameter(1)
  %param_2.261 = s32[] parameter(2)
  %constant.20450 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %dynamic-slice.779 = f32[1,8,1024]{2,1,0} dynamic-slice(f32[64,8,1024]{2,1,0} %param_1.244, s32[] %param_2.261, s32[] %constant.20450, s32[] %constant.20450), dynamic_slice_sizes={1,8,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %reshape.2891 = f32[8,1024]{1,0} reshape(f32[1,8,1024]{2,1,0} %dynamic-slice.779), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_0.111 = f32[8,2048]{1,0} parameter(0)
  %slice.1252 = f32[8,1024]{1,0} slice(f32[8,2048]{1,0} %param_0.111), slice={[0:8], [1024:2048]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(8, 2048)\n                                                     start_indices=(0, 1024)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=54}
  ROOT %concatenate.231 = f32[8,2048]{1,0} concatenate(f32[8,1024]{1,0} %reshape.2891, f32[8,1024]{1,0} %slice.1252), dimensions={1}, metadata={op_type="concatenate" op_name="pmap(_multi_device_update_fn)/scan/while/body/concatenate[ dimension=1 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
}

%fused_computation.63 (param_0.113: s32[]) -> s32[] {
  %param_0.113 = s32[] parameter(0)
  %constant.20452 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.2745 = pred[] compare(s32[] %param_0.113, s32[] %constant.20452), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant.20451 = s32[] constant(64), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.3973 = s32[] add(s32[] %param_0.113, s32[] %constant.20451), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %select.2634 = s32[] select(pred[] %compare.2745, s32[] %add.3973, s32[] %param_0.113), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%wide.body_computation__151.2409.clone.clone.clone.clone.clone (wide_param.173: (f32[64,8,1024], f32[2048,4096], f32[1,4096], s32[], f32[8,2048], /*index=5*/f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[64,8,2048], f32[64,8,1024], /*index=10*/f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], /*index=15*/f32[64,8,1024], f32[64,8,1024], f32[64,8,1024])) -> (f32[64,8,1024], f32[2048,4096], f32[1,4096], s32[], f32[8,2048], /*index=5*/f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[64,8,2048], f32[64,8,1024], /*index=10*/f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], /*index=15*/f32[64,8,1024], f32[64,8,1024], f32[64,8,1024]) {
  %wide_param.173 = (f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) parameter(0)
  %get-tuple-element.26930 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %wide_param.173), index=0
  %get-tuple-element.26931 = f32[2048,4096]{1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %wide_param.173), index=1
  %get-tuple-element.26932 = f32[1,4096]{1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %wide_param.173), index=2
  %get-tuple-element.26933 = s32[] get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %wide_param.173), index=3
  %copy.317 = s32[] copy(s32[] %get-tuple-element.26933)
  %constant.18558 = s32[] constant(1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.3433 = s32[] add(s32[] %copy.317, s32[] %constant.18558), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.26934 = f32[8,2048]{1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %wide_param.173), index=4
  %copy.318 = f32[8,2048]{1,0} copy(f32[8,2048]{1,0} %get-tuple-element.26934)
  %fusion.63 = s32[] fusion(s32[] %copy.317), kind=kLoop, calls=%fused_computation.63, metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %fusion.62 = f32[8,2048]{1,0} fusion(f32[8,2048]{1,0} %copy.318, f32[64,8,1024]{2,1,0} %get-tuple-element.26930, s32[] %fusion.63), kind=kLoop, calls=%fused_computation.62, metadata={op_type="concatenate" op_name="pmap(_multi_device_update_fn)/scan/while/body/concatenate[ dimension=1 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %dot.171 = f32[8,4096]{1,0} dot(f32[8,2048]{1,0} %fusion.62, f32[2048,4096]{1,0} %get-tuple-element.26931), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="dot_general" op_name="pmap(_multi_device_update_fn)/scan/while/body/dot_general[ dimension_numbers=(((1,), (0,)), ((), ()))\n                                                           precision=None\n                                                           preferred_element_type=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %fusion.60 = f32[8,1024]{1,0} fusion(f32[8,4096]{1,0} %dot.171, f32[1,4096]{1,0} %get-tuple-element.26932), kind=kLoop, calls=%fused_computation.60, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %fusion.59 = f32[8,1024]{1,0} fusion(f32[8,4096]{1,0} %dot.171, f32[1,4096]{1,0} %get-tuple-element.26932), kind=kLoop, calls=%fused_computation.59, metadata={op_type="tanh" op_name="pmap(_multi_device_update_fn)/scan/while/body/tanh" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %fusion.61 = f32[8,1024]{1,0} fusion(f32[8,4096]{1,0} %dot.171, f32[1,4096]{1,0} %get-tuple-element.26932), kind=kLoop, calls=%fused_computation.61, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %fusion.58 = f32[8,1024]{1,0} fusion(f32[8,1024]{1,0} %fusion.60, f32[8,1024]{1,0} %fusion.59, f32[8,1024]{1,0} %fusion.61, f32[8,2048]{1,0} %copy.318), kind=kLoop, calls=%fused_computation.58, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %tanh.93 = f32[8,1024]{1,0} tanh(f32[8,1024]{1,0} %fusion.58), metadata={op_type="tanh" op_name="pmap(_multi_device_update_fn)/scan/while/body/tanh" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  %fusion.57 = f32[8,1024]{1,0} fusion(f32[8,4096]{1,0} %dot.171, f32[1,4096]{1,0} %get-tuple-element.26932), kind=kLoop, calls=%fused_computation.57, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %fusion.56 = f32[8,2048]{1,0} fusion(f32[8,1024]{1,0} %fusion.58, f32[8,1024]{1,0} %tanh.93, f32[8,1024]{1,0} %fusion.57), kind=kLoop, calls=%fused_computation.56, metadata={op_type="concatenate" op_name="pmap(_multi_device_update_fn)/scan/while/body/concatenate[ dimension=1 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=65}
  %get-tuple-element.26935 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %wide_param.173), index=5
  %fusion.55 = f32[64,8,1024]{2,1,0} fusion(f32[64,8,1024]{2,1,0} %get-tuple-element.26935, s32[] %fusion.63, f32[8,1024]{1,0} %tanh.93, f32[8,1024]{1,0} %fusion.57), kind=kLoop, calls=%fused_computation.55, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.26936 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %wide_param.173), index=6
  %fusion.54 = f32[64,8,1024]{2,1,0} fusion(f32[64,8,1024]{2,1,0} %get-tuple-element.26936, s32[] %fusion.63, f32[8,1024]{1,0} %fusion.61), kind=kLoop, calls=%fused_computation.54, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.26937 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %wide_param.173), index=7
  %fusion.53 = f32[64,8,1024]{2,1,0} fusion(f32[64,8,1024]{2,1,0} %get-tuple-element.26937, s32[] %fusion.63, f32[8,2048]{1,0} %copy.318), kind=kLoop, calls=%fused_computation.53, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.26938 = f32[64,8,2048]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %wide_param.173), index=8
  %fusion.52 = f32[64,8,2048]{2,1,0} fusion(f32[64,8,2048]{2,1,0} %get-tuple-element.26938, s32[] %fusion.63, f32[8,2048]{1,0} %fusion.62), kind=kLoop, calls=%fused_computation.52, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.26939 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %wide_param.173), index=9
  %fusion.51 = f32[64,8,1024]{2,1,0} fusion(f32[64,8,1024]{2,1,0} %get-tuple-element.26939, s32[] %fusion.63, f32[8,1024]{1,0} %fusion.61), kind=kLoop, calls=%fused_computation.51, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.26940 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %wide_param.173), index=10
  %fusion.50 = f32[64,8,1024]{2,1,0} fusion(f32[64,8,1024]{2,1,0} %get-tuple-element.26940, s32[] %fusion.63, f32[8,1024]{1,0} %fusion.60), kind=kLoop, calls=%fused_computation.50, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.26941 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %wide_param.173), index=11
  %fusion.49 = f32[64,8,1024]{2,1,0} fusion(f32[64,8,1024]{2,1,0} %get-tuple-element.26941, s32[] %fusion.63, f32[8,1024]{1,0} %fusion.60), kind=kLoop, calls=%fused_computation.49, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.26942 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %wide_param.173), index=12
  %fusion.48 = f32[64,8,1024]{2,1,0} fusion(f32[64,8,1024]{2,1,0} %get-tuple-element.26942, s32[] %fusion.63, f32[8,1024]{1,0} %fusion.59), kind=kLoop, calls=%fused_computation.48, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.26943 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %wide_param.173), index=13
  %fusion.47 = f32[64,8,1024]{2,1,0} fusion(f32[64,8,1024]{2,1,0} %get-tuple-element.26943, s32[] %fusion.63, f32[8,1024]{1,0} %fusion.59), kind=kLoop, calls=%fused_computation.47, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.26944 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %wide_param.173), index=14
  %fusion.46 = f32[64,8,1024]{2,1,0} fusion(f32[64,8,1024]{2,1,0} %get-tuple-element.26944, s32[] %fusion.63, f32[8,1024]{1,0} %tanh.93), kind=kLoop, calls=%fused_computation.46, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.26945 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %wide_param.173), index=15
  %fusion.45 = f32[64,8,1024]{2,1,0} fusion(f32[64,8,1024]{2,1,0} %get-tuple-element.26945, s32[] %fusion.63, f32[8,1024]{1,0} %tanh.93), kind=kLoop, calls=%fused_computation.45, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.26946 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %wide_param.173), index=16
  %fusion.44 = f32[64,8,1024]{2,1,0} fusion(f32[64,8,1024]{2,1,0} %get-tuple-element.26946, s32[] %fusion.63, f32[8,1024]{1,0} %fusion.57), kind=kLoop, calls=%fused_computation.44, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.26947 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %wide_param.173), index=17
  %fusion.43 = f32[64,8,1024]{2,1,0} fusion(f32[64,8,1024]{2,1,0} %get-tuple-element.26947, s32[] %fusion.63, f32[8,1024]{1,0} %fusion.57), kind=kLoop, calls=%fused_computation.43, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %tuple.1274 = (f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) tuple(f32[64,8,1024]{2,1,0} %get-tuple-element.26930, f32[2048,4096]{1,0} %get-tuple-element.26931, f32[1,4096]{1,0} %get-tuple-element.26932, s32[] %add.3433, f32[8,2048]{1,0} %fusion.56, /*index=5*/f32[64,8,1024]{2,1,0} %fusion.55, f32[64,8,1024]{2,1,0} %fusion.54, f32[64,8,1024]{2,1,0} %fusion.53, f32[64,8,2048]{2,1,0} %fusion.52, f32[64,8,1024]{2,1,0} %fusion.51, /*index=10*/f32[64,8,1024]{2,1,0} %fusion.50, f32[64,8,1024]{2,1,0} %fusion.49, f32[64,8,1024]{2,1,0} %fusion.48, f32[64,8,1024]{2,1,0} %fusion.47, f32[64,8,1024]{2,1,0} %fusion.46, /*index=15*/f32[64,8,1024]{2,1,0} %fusion.45, f32[64,8,1024]{2,1,0} %fusion.44, f32[64,8,1024]{2,1,0} %fusion.43)
}

%wide.cond_computation__151.2830.clone.clone.clone.clone (wide_param.174: (f32[64,8,1024], f32[2048,4096], f32[1,4096], s32[], f32[8,2048], /*index=5*/f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[64,8,2048], f32[64,8,1024], /*index=10*/f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], /*index=15*/f32[64,8,1024], f32[64,8,1024], f32[64,8,1024])) -> pred[] {
  %wide_param.174 = (f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) parameter(0)
  %get-tuple-element.24484 = s32[] get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %wide_param.174), index=3
  %constant.18562 = s32[] constant(64), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/cond/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %compare.2469 = pred[] compare(s32[] %get-tuple-element.24484, s32[] %constant.18562), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/cond/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.64 (param_0.114: f32[64,8,1024], param_1.249: s32[], param_2.267: f32[8,1024]) -> f32[64,8,1024] {
  %param_0.114 = f32[64,8,1024]{2,1,0} parameter(0)
  %constant.20454 = f32[] constant(1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %broadcast.1756 = f32[8,1024]{1,0} broadcast(f32[] %constant.20454), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %param_2.267 = f32[8,1024]{1,0} parameter(2)
  %subtract.498 = f32[8,1024]{1,0} subtract(f32[8,1024]{1,0} %broadcast.1756, f32[8,1024]{1,0} %param_2.267), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %reshape.2892 = f32[1,8,1024]{2,1,0} reshape(f32[8,1024]{1,0} %subtract.498), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_1.249 = s32[] parameter(1)
  %constant.20453 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.790 = f32[64,8,1024]{2,1,0} dynamic-update-slice(f32[64,8,1024]{2,1,0} %param_0.114, f32[1,8,1024]{2,1,0} %reshape.2892, s32[] %param_1.249, s32[] %constant.20453, s32[] %constant.20453), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.65 (param_0.115: f32[64,8,1024], param_1.251: s32[], param_2.270: f32[8,1024]) -> f32[64,8,1024] {
  %param_0.115 = f32[64,8,1024]{2,1,0} parameter(0)
  %param_2.270 = f32[8,1024]{1,0} parameter(2)
  %reshape.2893 = f32[1,8,1024]{2,1,0} reshape(f32[8,1024]{1,0} %param_2.270), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_1.251 = s32[] parameter(1)
  %constant.20456 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.791 = f32[64,8,1024]{2,1,0} dynamic-update-slice(f32[64,8,1024]{2,1,0} %param_0.115, f32[1,8,1024]{2,1,0} %reshape.2893, s32[] %param_1.251, s32[] %constant.20456, s32[] %constant.20456), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.66 (param_0.116: f32[64,8,1024], param_1.253: s32[], param_2.274: f32[8,1024]) -> f32[64,8,1024] {
  %param_0.116 = f32[64,8,1024]{2,1,0} parameter(0)
  %constant.20458 = f32[] constant(1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %broadcast.1757 = f32[8,1024]{1,0} broadcast(f32[] %constant.20458), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %param_2.274 = f32[8,1024]{1,0} parameter(2)
  %subtract.499 = f32[8,1024]{1,0} subtract(f32[8,1024]{1,0} %broadcast.1757, f32[8,1024]{1,0} %param_2.274), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  %reshape.2894 = f32[1,8,1024]{2,1,0} reshape(f32[8,1024]{1,0} %subtract.499), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_1.253 = s32[] parameter(1)
  %constant.20457 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.792 = f32[64,8,1024]{2,1,0} dynamic-update-slice(f32[64,8,1024]{2,1,0} %param_0.116, f32[1,8,1024]{2,1,0} %reshape.2894, s32[] %param_1.253, s32[] %constant.20457, s32[] %constant.20457), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.67 (param_0.117: f32[64,8,1024], param_1.255: s32[], param_2.277: f32[8,1024]) -> f32[64,8,1024] {
  %param_0.117 = f32[64,8,1024]{2,1,0} parameter(0)
  %param_2.277 = f32[8,1024]{1,0} parameter(2)
  %reshape.2895 = f32[1,8,1024]{2,1,0} reshape(f32[8,1024]{1,0} %param_2.277), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_1.255 = s32[] parameter(1)
  %constant.20459 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.793 = f32[64,8,1024]{2,1,0} dynamic-update-slice(f32[64,8,1024]{2,1,0} %param_0.117, f32[1,8,1024]{2,1,0} %reshape.2895, s32[] %param_1.255, s32[] %constant.20459, s32[] %constant.20459), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.68 (param_0.118: f32[64,8,1024], param_1.257: s32[], param_2.281: f32[8,1024]) -> f32[64,8,1024] {
  %param_0.118 = f32[64,8,1024]{2,1,0} parameter(0)
  %constant.20461 = f32[] constant(1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %broadcast.1758 = f32[8,1024]{1,0} broadcast(f32[] %constant.20461), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %param_2.281 = f32[8,1024]{1,0} parameter(2)
  %subtract.500 = f32[8,1024]{1,0} subtract(f32[8,1024]{1,0} %broadcast.1758, f32[8,1024]{1,0} %param_2.281), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %reshape.2896 = f32[1,8,1024]{2,1,0} reshape(f32[8,1024]{1,0} %subtract.500), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_1.257 = s32[] parameter(1)
  %constant.20460 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.794 = f32[64,8,1024]{2,1,0} dynamic-update-slice(f32[64,8,1024]{2,1,0} %param_0.118, f32[1,8,1024]{2,1,0} %reshape.2896, s32[] %param_1.257, s32[] %constant.20460, s32[] %constant.20460), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.69 (param_0.119: f32[64,8,1024], param_1.259: s32[], param_2.284: f32[8,1024]) -> f32[64,8,1024] {
  %param_0.119 = f32[64,8,1024]{2,1,0} parameter(0)
  %param_2.284 = f32[8,1024]{1,0} parameter(2)
  %reshape.2897 = f32[1,8,1024]{2,1,0} reshape(f32[8,1024]{1,0} %param_2.284), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_1.259 = s32[] parameter(1)
  %constant.20463 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.795 = f32[64,8,1024]{2,1,0} dynamic-update-slice(f32[64,8,1024]{2,1,0} %param_0.119, f32[1,8,1024]{2,1,0} %reshape.2897, s32[] %param_1.259, s32[] %constant.20463, s32[] %constant.20463), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.70 (param_0.120: f32[64,8,1024], param_1.261: s32[], param_2.288: f32[8,1024]) -> f32[64,8,1024] {
  %param_0.120 = f32[64,8,1024]{2,1,0} parameter(0)
  %constant.20465 = f32[] constant(1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %broadcast.1759 = f32[8,1024]{1,0} broadcast(f32[] %constant.20465), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %param_2.288 = f32[8,1024]{1,0} parameter(2)
  %subtract.501 = f32[8,1024]{1,0} subtract(f32[8,1024]{1,0} %broadcast.1759, f32[8,1024]{1,0} %param_2.288), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %reshape.2898 = f32[1,8,1024]{2,1,0} reshape(f32[8,1024]{1,0} %subtract.501), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_1.261 = s32[] parameter(1)
  %constant.20464 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.796 = f32[64,8,1024]{2,1,0} dynamic-update-slice(f32[64,8,1024]{2,1,0} %param_0.120, f32[1,8,1024]{2,1,0} %reshape.2898, s32[] %param_1.261, s32[] %constant.20464, s32[] %constant.20464), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.71 (param_0.121: f32[64,8,1024], param_1.263: s32[], param_2.291: f32[8,1024]) -> f32[64,8,1024] {
  %param_0.121 = f32[64,8,1024]{2,1,0} parameter(0)
  %param_2.291 = f32[8,1024]{1,0} parameter(2)
  %reshape.2899 = f32[1,8,1024]{2,1,0} reshape(f32[8,1024]{1,0} %param_2.291), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_1.263 = s32[] parameter(1)
  %constant.20466 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.797 = f32[64,8,1024]{2,1,0} dynamic-update-slice(f32[64,8,1024]{2,1,0} %param_0.121, f32[1,8,1024]{2,1,0} %reshape.2899, s32[] %param_1.263, s32[] %constant.20466, s32[] %constant.20466), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.72 (param_0.122: f32[64,8,1024], param_1.265: s32[], param_2.295: f32[8,1024]) -> f32[64,8,1024] {
  %param_0.122 = f32[64,8,1024]{2,1,0} parameter(0)
  %constant.20468 = f32[] constant(1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %broadcast.1760 = f32[8,1024]{1,0} broadcast(f32[] %constant.20468), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %param_2.295 = f32[8,1024]{1,0} parameter(2)
  %subtract.502 = f32[8,1024]{1,0} subtract(f32[8,1024]{1,0} %broadcast.1760, f32[8,1024]{1,0} %param_2.295), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %reshape.2900 = f32[1,8,1024]{2,1,0} reshape(f32[8,1024]{1,0} %subtract.502), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_1.265 = s32[] parameter(1)
  %constant.20467 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.798 = f32[64,8,1024]{2,1,0} dynamic-update-slice(f32[64,8,1024]{2,1,0} %param_0.122, f32[1,8,1024]{2,1,0} %reshape.2900, s32[] %param_1.265, s32[] %constant.20467, s32[] %constant.20467), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.73 (param_0.123: f32[64,8,2048], param_1.267: s32[], param_2.298: f32[8,2048]) -> f32[64,8,2048] {
  %param_0.123 = f32[64,8,2048]{2,1,0} parameter(0)
  %param_2.298 = f32[8,2048]{1,0} parameter(2)
  %reshape.2901 = f32[1,8,2048]{2,1,0} reshape(f32[8,2048]{1,0} %param_2.298), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 8, 2048) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_1.267 = s32[] parameter(1)
  %constant.20469 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.799 = f32[64,8,2048]{2,1,0} dynamic-update-slice(f32[64,8,2048]{2,1,0} %param_0.123, f32[1,8,2048]{2,1,0} %reshape.2901, s32[] %param_1.267, s32[] %constant.20469, s32[] %constant.20469), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.74 (param_0.124: f32[64,8,1024], param_1.269: s32[], param_2.302: f32[8,2048]) -> f32[64,8,1024] {
  %param_0.124 = f32[64,8,1024]{2,1,0} parameter(0)
  %param_2.302 = f32[8,2048]{1,0} parameter(2)
  %slice.1253 = f32[8,1024]{1,0} slice(f32[8,2048]{1,0} %param_2.302), slice={[0:8], [0:1024]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(8, 1024)\n                                                     start_indices=(0, 0)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=54}
  %reshape.2902 = f32[1,8,1024]{2,1,0} reshape(f32[8,1024]{1,0} %slice.1253), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_1.269 = s32[] parameter(1)
  %constant.20471 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.800 = f32[64,8,1024]{2,1,0} dynamic-update-slice(f32[64,8,1024]{2,1,0} %param_0.124, f32[1,8,1024]{2,1,0} %reshape.2902, s32[] %param_1.269, s32[] %constant.20471, s32[] %constant.20471), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.75 (param_0.125: f32[64,8,1024], param_1.271: s32[], param_2.305: f32[8,1024]) -> f32[64,8,1024] {
  %param_0.125 = f32[64,8,1024]{2,1,0} parameter(0)
  %param_2.305 = f32[8,1024]{1,0} parameter(2)
  %reshape.2903 = f32[1,8,1024]{2,1,0} reshape(f32[8,1024]{1,0} %param_2.305), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_1.271 = s32[] parameter(1)
  %constant.20472 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.801 = f32[64,8,1024]{2,1,0} dynamic-update-slice(f32[64,8,1024]{2,1,0} %param_0.125, f32[1,8,1024]{2,1,0} %reshape.2903, s32[] %param_1.271, s32[] %constant.20472, s32[] %constant.20472), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.76 (param_0.126: f32[64,8,1024], param_1.273: s32[], param_2.308: f32[8,1024], param_3.288: f32[8,1024]) -> f32[64,8,1024] {
  %param_0.126 = f32[64,8,1024]{2,1,0} parameter(0)
  %param_2.308 = f32[8,1024]{1,0} parameter(2)
  %param_3.288 = f32[8,1024]{1,0} parameter(3)
  %multiply.1372 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %param_2.308, f32[8,1024]{1,0} %param_3.288), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  %reshape.2904 = f32[1,8,1024]{2,1,0} reshape(f32[8,1024]{1,0} %multiply.1372), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_1.273 = s32[] parameter(1)
  %constant.20473 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.802 = f32[64,8,1024]{2,1,0} dynamic-update-slice(f32[64,8,1024]{2,1,0} %param_0.126, f32[1,8,1024]{2,1,0} %reshape.2904, s32[] %param_1.273, s32[] %constant.20473, s32[] %constant.20473), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.77 (param_0.127: f32[8,1024], param_1.275: f32[8,1024], param_2.309: f32[8,1024]) -> f32[8,2048] {
  %param_0.127 = f32[8,1024]{1,0} parameter(0)
  %param_1.275 = f32[8,1024]{1,0} parameter(1)
  %param_2.309 = f32[8,1024]{1,0} parameter(2)
  %multiply.1373 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %param_1.275, f32[8,1024]{1,0} %param_2.309), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  ROOT %concatenate.232 = f32[8,2048]{1,0} concatenate(f32[8,1024]{1,0} %param_0.127, f32[8,1024]{1,0} %multiply.1373), dimensions={1}, metadata={op_type="concatenate" op_name="pmap(_multi_device_update_fn)/scan/while/body/concatenate[ dimension=1 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=65}
}

%fused_computation.78 (param_0.129: f32[8,4096], param_1.282: f32[1,4096]) -> f32[8,1024] {
  %constant.20474 = f32[] constant(1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %broadcast.1762 = f32[8,1024]{1,0} broadcast(f32[] %constant.20474), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %param_0.129 = f32[8,4096]{1,0} parameter(0)
  %param_1.282 = f32[1,4096]{1,0} parameter(1)
  %reshape.2905 = f32[4096]{0} reshape(f32[1,4096]{1,0} %param_1.282), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %broadcast.1761 = f32[8,4096]{1,0} broadcast(f32[4096]{0} %reshape.2905), dimensions={1}, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %add.3975 = f32[8,4096]{1,0} add(f32[8,4096]{1,0} %param_0.129, f32[8,4096]{1,0} %broadcast.1761), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %slice.1254 = f32[8,1024]{1,0} slice(f32[8,4096]{1,0} %add.3975), slice={[0:8], [3072:4096]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(8, 4096)\n                                                     start_indices=(0, 3072)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  %negate.196 = f32[8,1024]{1,0} negate(f32[8,1024]{1,0} %slice.1254), metadata={op_type="neg" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/neg" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %exponential.168 = f32[8,1024]{1,0} exponential(f32[8,1024]{1,0} %negate.196), metadata={op_type="exp" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/exp" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %add.3974 = f32[8,1024]{1,0} add(f32[8,1024]{1,0} %broadcast.1762, f32[8,1024]{1,0} %exponential.168), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  ROOT %divide.172 = f32[8,1024]{1,0} divide(f32[8,1024]{1,0} %broadcast.1762, f32[8,1024]{1,0} %add.3974), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
}

%fused_computation.79 (param_0.131: f32[8,1024], param_1.285: f32[8,1024], param_2.316: f32[8,1024], param_3.290: f32[8,2048]) -> f32[8,1024] {
  %param_3.290 = f32[8,2048]{1,0} parameter(3)
  %slice.1255 = f32[8,1024]{1,0} slice(f32[8,2048]{1,0} %param_3.290), slice={[0:8], [0:1024]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(8, 1024)\n                                                     start_indices=(0, 0)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=54}
  %param_2.316 = f32[8,1024]{1,0} parameter(2)
  %multiply.1375 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %slice.1255, f32[8,1024]{1,0} %param_2.316), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %param_0.131 = f32[8,1024]{1,0} parameter(0)
  %param_1.285 = f32[8,1024]{1,0} parameter(1)
  %multiply.1374 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %param_0.131, f32[8,1024]{1,0} %param_1.285), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  ROOT %add.3976 = f32[8,1024]{1,0} add(f32[8,1024]{1,0} %multiply.1375, f32[8,1024]{1,0} %multiply.1374), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
}

%fused_computation.80 (param_0.134: f32[8,4096], param_1.288: f32[1,4096]) -> f32[8,1024] {
  %param_0.134 = f32[8,4096]{1,0} parameter(0)
  %param_1.288 = f32[1,4096]{1,0} parameter(1)
  %reshape.2906 = f32[4096]{0} reshape(f32[1,4096]{1,0} %param_1.288), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %broadcast.1763 = f32[8,4096]{1,0} broadcast(f32[4096]{0} %reshape.2906), dimensions={1}, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %add.3977 = f32[8,4096]{1,0} add(f32[8,4096]{1,0} %param_0.134, f32[8,4096]{1,0} %broadcast.1763), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %slice.1256 = f32[8,1024]{1,0} slice(f32[8,4096]{1,0} %add.3977), slice={[0:8], [1024:2048]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(8, 2048)\n                                                     start_indices=(0, 1024)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  ROOT %tanh.110 = f32[8,1024]{1,0} tanh(f32[8,1024]{1,0} %slice.1256), metadata={op_type="tanh" op_name="pmap(_multi_device_update_fn)/scan/while/body/tanh" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
}

%fused_computation.81 (param_0.136: f32[8,4096], param_1.295: f32[1,4096]) -> f32[8,1024] {
  %constant.20476 = f32[] constant(1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %broadcast.1765 = f32[8,1024]{1,0} broadcast(f32[] %constant.20476), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %param_0.136 = f32[8,4096]{1,0} parameter(0)
  %param_1.295 = f32[1,4096]{1,0} parameter(1)
  %reshape.2907 = f32[4096]{0} reshape(f32[1,4096]{1,0} %param_1.295), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %broadcast.1764 = f32[8,4096]{1,0} broadcast(f32[4096]{0} %reshape.2907), dimensions={1}, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %add.3979 = f32[8,4096]{1,0} add(f32[8,4096]{1,0} %param_0.136, f32[8,4096]{1,0} %broadcast.1764), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %slice.1257 = f32[8,1024]{1,0} slice(f32[8,4096]{1,0} %add.3979), slice={[0:8], [0:1024]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(8, 1024)\n                                                     start_indices=(0, 0)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  %negate.197 = f32[8,1024]{1,0} negate(f32[8,1024]{1,0} %slice.1257), metadata={op_type="neg" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/neg" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %exponential.169 = f32[8,1024]{1,0} exponential(f32[8,1024]{1,0} %negate.197), metadata={op_type="exp" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/exp" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %add.3978 = f32[8,1024]{1,0} add(f32[8,1024]{1,0} %broadcast.1765, f32[8,1024]{1,0} %exponential.169), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  ROOT %divide.173 = f32[8,1024]{1,0} divide(f32[8,1024]{1,0} %broadcast.1765, f32[8,1024]{1,0} %add.3978), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
}

%fused_computation.82 (param_0.138: f32[8,4096], param_1.302: f32[1,4096]) -> f32[8,1024] {
  %constant.20477 = f32[] constant(1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %broadcast.1767 = f32[8,1024]{1,0} broadcast(f32[] %constant.20477), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %param_0.138 = f32[8,4096]{1,0} parameter(0)
  %param_1.302 = f32[1,4096]{1,0} parameter(1)
  %reshape.2908 = f32[4096]{0} reshape(f32[1,4096]{1,0} %param_1.302), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %broadcast.1766 = f32[8,4096]{1,0} broadcast(f32[4096]{0} %reshape.2908), dimensions={1}, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %add.3981 = f32[8,4096]{1,0} add(f32[8,4096]{1,0} %param_0.138, f32[8,4096]{1,0} %broadcast.1766), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %slice.1258 = f32[8,1024]{1,0} slice(f32[8,4096]{1,0} %add.3981), slice={[0:8], [2048:3072]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(8, 3072)\n                                                     start_indices=(0, 2048)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  %negate.198 = f32[8,1024]{1,0} negate(f32[8,1024]{1,0} %slice.1258), metadata={op_type="neg" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/neg" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %exponential.170 = f32[8,1024]{1,0} exponential(f32[8,1024]{1,0} %negate.198), metadata={op_type="exp" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/exp" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %add.3980 = f32[8,1024]{1,0} add(f32[8,1024]{1,0} %broadcast.1767, f32[8,1024]{1,0} %exponential.170), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  ROOT %divide.174 = f32[8,1024]{1,0} divide(f32[8,1024]{1,0} %broadcast.1767, f32[8,1024]{1,0} %add.3980), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
}

%fused_computation.83 (param_0.140: f32[8,2048], param_1.306: f32[64,8,1024], param_2.325: s32[]) -> f32[8,2048] {
  %param_1.306 = f32[64,8,1024]{2,1,0} parameter(1)
  %param_2.325 = s32[] parameter(2)
  %constant.20478 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %dynamic-slice.780 = f32[1,8,1024]{2,1,0} dynamic-slice(f32[64,8,1024]{2,1,0} %param_1.306, s32[] %param_2.325, s32[] %constant.20478, s32[] %constant.20478), dynamic_slice_sizes={1,8,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %reshape.2909 = f32[8,1024]{1,0} reshape(f32[1,8,1024]{2,1,0} %dynamic-slice.780), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_0.140 = f32[8,2048]{1,0} parameter(0)
  %slice.1259 = f32[8,1024]{1,0} slice(f32[8,2048]{1,0} %param_0.140), slice={[0:8], [1024:2048]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(8, 2048)\n                                                     start_indices=(0, 1024)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=54}
  ROOT %concatenate.233 = f32[8,2048]{1,0} concatenate(f32[8,1024]{1,0} %reshape.2909, f32[8,1024]{1,0} %slice.1259), dimensions={1}, metadata={op_type="concatenate" op_name="pmap(_multi_device_update_fn)/scan/while/body/concatenate[ dimension=1 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
}

%fused_computation.84 (param_0.142: s32[]) -> s32[] {
  %param_0.142 = s32[] parameter(0)
  %constant.20480 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.2746 = pred[] compare(s32[] %param_0.142, s32[] %constant.20480), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant.20479 = s32[] constant(64), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.3983 = s32[] add(s32[] %param_0.142, s32[] %constant.20479), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %select.2635 = s32[] select(pred[] %compare.2746, s32[] %add.3983, s32[] %param_0.142), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%wide.body_computation__155.3458.clone.clone.clone.clone.clone (wide_param.175: (f32[64,8,1024], f32[2048,4096], f32[1,4096], s32[], f32[8,2048], /*index=5*/f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[64,8,2048], f32[64,8,1024], /*index=10*/f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], /*index=15*/f32[64,8,1024], f32[64,8,1024], f32[64,8,1024])) -> (f32[64,8,1024], f32[2048,4096], f32[1,4096], s32[], f32[8,2048], /*index=5*/f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[64,8,2048], f32[64,8,1024], /*index=10*/f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], /*index=15*/f32[64,8,1024], f32[64,8,1024], f32[64,8,1024]) {
  %wide_param.175 = (f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) parameter(0)
  %get-tuple-element.26984 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %wide_param.175), index=0
  %get-tuple-element.26985 = f32[2048,4096]{1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %wide_param.175), index=1
  %get-tuple-element.26986 = f32[1,4096]{1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %wide_param.175), index=2
  %get-tuple-element.26987 = s32[] get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %wide_param.175), index=3
  %copy.362 = s32[] copy(s32[] %get-tuple-element.26987)
  %constant.18644 = s32[] constant(1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.3453 = s32[] add(s32[] %copy.362, s32[] %constant.18644), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.26988 = f32[8,2048]{1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %wide_param.175), index=4
  %copy.363 = f32[8,2048]{1,0} copy(f32[8,2048]{1,0} %get-tuple-element.26988)
  %fusion.84 = s32[] fusion(s32[] %copy.362), kind=kLoop, calls=%fused_computation.84, metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %fusion.83 = f32[8,2048]{1,0} fusion(f32[8,2048]{1,0} %copy.363, f32[64,8,1024]{2,1,0} %get-tuple-element.26984, s32[] %fusion.84), kind=kLoop, calls=%fused_computation.83, metadata={op_type="concatenate" op_name="pmap(_multi_device_update_fn)/scan/while/body/concatenate[ dimension=1 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %dot.172 = f32[8,4096]{1,0} dot(f32[8,2048]{1,0} %fusion.83, f32[2048,4096]{1,0} %get-tuple-element.26985), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="dot_general" op_name="pmap(_multi_device_update_fn)/scan/while/body/dot_general[ dimension_numbers=(((1,), (0,)), ((), ()))\n                                                           precision=None\n                                                           preferred_element_type=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %fusion.81 = f32[8,1024]{1,0} fusion(f32[8,4096]{1,0} %dot.172, f32[1,4096]{1,0} %get-tuple-element.26986), kind=kLoop, calls=%fused_computation.81, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %fusion.80 = f32[8,1024]{1,0} fusion(f32[8,4096]{1,0} %dot.172, f32[1,4096]{1,0} %get-tuple-element.26986), kind=kLoop, calls=%fused_computation.80, metadata={op_type="tanh" op_name="pmap(_multi_device_update_fn)/scan/while/body/tanh" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %fusion.82 = f32[8,1024]{1,0} fusion(f32[8,4096]{1,0} %dot.172, f32[1,4096]{1,0} %get-tuple-element.26986), kind=kLoop, calls=%fused_computation.82, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %fusion.79 = f32[8,1024]{1,0} fusion(f32[8,1024]{1,0} %fusion.81, f32[8,1024]{1,0} %fusion.80, f32[8,1024]{1,0} %fusion.82, f32[8,2048]{1,0} %copy.363), kind=kLoop, calls=%fused_computation.79, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %tanh.95 = f32[8,1024]{1,0} tanh(f32[8,1024]{1,0} %fusion.79), metadata={op_type="tanh" op_name="pmap(_multi_device_update_fn)/scan/while/body/tanh" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  %fusion.78 = f32[8,1024]{1,0} fusion(f32[8,4096]{1,0} %dot.172, f32[1,4096]{1,0} %get-tuple-element.26986), kind=kLoop, calls=%fused_computation.78, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %fusion.77 = f32[8,2048]{1,0} fusion(f32[8,1024]{1,0} %fusion.79, f32[8,1024]{1,0} %tanh.95, f32[8,1024]{1,0} %fusion.78), kind=kLoop, calls=%fused_computation.77, metadata={op_type="concatenate" op_name="pmap(_multi_device_update_fn)/scan/while/body/concatenate[ dimension=1 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=65}
  %get-tuple-element.26989 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %wide_param.175), index=5
  %fusion.76 = f32[64,8,1024]{2,1,0} fusion(f32[64,8,1024]{2,1,0} %get-tuple-element.26989, s32[] %fusion.84, f32[8,1024]{1,0} %tanh.95, f32[8,1024]{1,0} %fusion.78), kind=kLoop, calls=%fused_computation.76, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.26990 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %wide_param.175), index=6
  %fusion.75 = f32[64,8,1024]{2,1,0} fusion(f32[64,8,1024]{2,1,0} %get-tuple-element.26990, s32[] %fusion.84, f32[8,1024]{1,0} %fusion.82), kind=kLoop, calls=%fused_computation.75, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.26991 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %wide_param.175), index=7
  %fusion.74 = f32[64,8,1024]{2,1,0} fusion(f32[64,8,1024]{2,1,0} %get-tuple-element.26991, s32[] %fusion.84, f32[8,2048]{1,0} %copy.363), kind=kLoop, calls=%fused_computation.74, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.26992 = f32[64,8,2048]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %wide_param.175), index=8
  %fusion.73 = f32[64,8,2048]{2,1,0} fusion(f32[64,8,2048]{2,1,0} %get-tuple-element.26992, s32[] %fusion.84, f32[8,2048]{1,0} %fusion.83), kind=kLoop, calls=%fused_computation.73, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.26993 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %wide_param.175), index=9
  %fusion.72 = f32[64,8,1024]{2,1,0} fusion(f32[64,8,1024]{2,1,0} %get-tuple-element.26993, s32[] %fusion.84, f32[8,1024]{1,0} %fusion.82), kind=kLoop, calls=%fused_computation.72, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.26994 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %wide_param.175), index=10
  %fusion.71 = f32[64,8,1024]{2,1,0} fusion(f32[64,8,1024]{2,1,0} %get-tuple-element.26994, s32[] %fusion.84, f32[8,1024]{1,0} %fusion.81), kind=kLoop, calls=%fused_computation.71, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.26995 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %wide_param.175), index=11
  %fusion.70 = f32[64,8,1024]{2,1,0} fusion(f32[64,8,1024]{2,1,0} %get-tuple-element.26995, s32[] %fusion.84, f32[8,1024]{1,0} %fusion.81), kind=kLoop, calls=%fused_computation.70, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.26996 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %wide_param.175), index=12
  %fusion.69 = f32[64,8,1024]{2,1,0} fusion(f32[64,8,1024]{2,1,0} %get-tuple-element.26996, s32[] %fusion.84, f32[8,1024]{1,0} %fusion.80), kind=kLoop, calls=%fused_computation.69, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.26997 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %wide_param.175), index=13
  %fusion.68 = f32[64,8,1024]{2,1,0} fusion(f32[64,8,1024]{2,1,0} %get-tuple-element.26997, s32[] %fusion.84, f32[8,1024]{1,0} %fusion.80), kind=kLoop, calls=%fused_computation.68, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.26998 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %wide_param.175), index=14
  %fusion.67 = f32[64,8,1024]{2,1,0} fusion(f32[64,8,1024]{2,1,0} %get-tuple-element.26998, s32[] %fusion.84, f32[8,1024]{1,0} %tanh.95), kind=kLoop, calls=%fused_computation.67, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.26999 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %wide_param.175), index=15
  %fusion.66 = f32[64,8,1024]{2,1,0} fusion(f32[64,8,1024]{2,1,0} %get-tuple-element.26999, s32[] %fusion.84, f32[8,1024]{1,0} %tanh.95), kind=kLoop, calls=%fused_computation.66, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.27000 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %wide_param.175), index=16
  %fusion.65 = f32[64,8,1024]{2,1,0} fusion(f32[64,8,1024]{2,1,0} %get-tuple-element.27000, s32[] %fusion.84, f32[8,1024]{1,0} %fusion.78), kind=kLoop, calls=%fused_computation.65, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.27001 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %wide_param.175), index=17
  %fusion.64 = f32[64,8,1024]{2,1,0} fusion(f32[64,8,1024]{2,1,0} %get-tuple-element.27001, s32[] %fusion.84, f32[8,1024]{1,0} %fusion.78), kind=kLoop, calls=%fused_computation.64, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %tuple.1278 = (f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) tuple(f32[64,8,1024]{2,1,0} %get-tuple-element.26984, f32[2048,4096]{1,0} %get-tuple-element.26985, f32[1,4096]{1,0} %get-tuple-element.26986, s32[] %add.3453, f32[8,2048]{1,0} %fusion.77, /*index=5*/f32[64,8,1024]{2,1,0} %fusion.76, f32[64,8,1024]{2,1,0} %fusion.75, f32[64,8,1024]{2,1,0} %fusion.74, f32[64,8,2048]{2,1,0} %fusion.73, f32[64,8,1024]{2,1,0} %fusion.72, /*index=10*/f32[64,8,1024]{2,1,0} %fusion.71, f32[64,8,1024]{2,1,0} %fusion.70, f32[64,8,1024]{2,1,0} %fusion.69, f32[64,8,1024]{2,1,0} %fusion.68, f32[64,8,1024]{2,1,0} %fusion.67, /*index=15*/f32[64,8,1024]{2,1,0} %fusion.66, f32[64,8,1024]{2,1,0} %fusion.65, f32[64,8,1024]{2,1,0} %fusion.64)
}

%wide.cond_computation__155.3879.clone.clone.clone.clone (wide_param.176: (f32[64,8,1024], f32[2048,4096], f32[1,4096], s32[], f32[8,2048], /*index=5*/f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[64,8,2048], f32[64,8,1024], /*index=10*/f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], /*index=15*/f32[64,8,1024], f32[64,8,1024], f32[64,8,1024])) -> pred[] {
  %wide_param.176 = (f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) parameter(0)
  %get-tuple-element.24594 = s32[] get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %wide_param.176), index=3
  %constant.18647 = s32[] constant(64), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/cond/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %compare.2484 = pred[] compare(s32[] %get-tuple-element.24594, s32[] %constant.18647), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/cond/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.85 (param_0.143: f32[64,8,1024], param_1.311: s32[], param_2.331: f32[8,1024]) -> f32[64,8,1024] {
  %param_0.143 = f32[64,8,1024]{2,1,0} parameter(0)
  %constant.20482 = f32[] constant(1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %broadcast.1768 = f32[8,1024]{1,0} broadcast(f32[] %constant.20482), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %param_2.331 = f32[8,1024]{1,0} parameter(2)
  %subtract.503 = f32[8,1024]{1,0} subtract(f32[8,1024]{1,0} %broadcast.1768, f32[8,1024]{1,0} %param_2.331), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %reshape.2910 = f32[1,8,1024]{2,1,0} reshape(f32[8,1024]{1,0} %subtract.503), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_1.311 = s32[] parameter(1)
  %constant.20481 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.803 = f32[64,8,1024]{2,1,0} dynamic-update-slice(f32[64,8,1024]{2,1,0} %param_0.143, f32[1,8,1024]{2,1,0} %reshape.2910, s32[] %param_1.311, s32[] %constant.20481, s32[] %constant.20481), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.86 (param_0.144: f32[64,8,1024], param_1.313: s32[], param_2.334: f32[8,1024]) -> f32[64,8,1024] {
  %param_0.144 = f32[64,8,1024]{2,1,0} parameter(0)
  %param_2.334 = f32[8,1024]{1,0} parameter(2)
  %reshape.2911 = f32[1,8,1024]{2,1,0} reshape(f32[8,1024]{1,0} %param_2.334), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_1.313 = s32[] parameter(1)
  %constant.20483 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.804 = f32[64,8,1024]{2,1,0} dynamic-update-slice(f32[64,8,1024]{2,1,0} %param_0.144, f32[1,8,1024]{2,1,0} %reshape.2911, s32[] %param_1.313, s32[] %constant.20483, s32[] %constant.20483), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.87 (param_0.145: f32[64,8,1024], param_1.315: s32[], param_2.338: f32[8,1024]) -> f32[64,8,1024] {
  %param_0.145 = f32[64,8,1024]{2,1,0} parameter(0)
  %constant.20485 = f32[] constant(1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %broadcast.1769 = f32[8,1024]{1,0} broadcast(f32[] %constant.20485), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %param_2.338 = f32[8,1024]{1,0} parameter(2)
  %subtract.504 = f32[8,1024]{1,0} subtract(f32[8,1024]{1,0} %broadcast.1769, f32[8,1024]{1,0} %param_2.338), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  %reshape.2912 = f32[1,8,1024]{2,1,0} reshape(f32[8,1024]{1,0} %subtract.504), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_1.315 = s32[] parameter(1)
  %constant.20484 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.805 = f32[64,8,1024]{2,1,0} dynamic-update-slice(f32[64,8,1024]{2,1,0} %param_0.145, f32[1,8,1024]{2,1,0} %reshape.2912, s32[] %param_1.315, s32[] %constant.20484, s32[] %constant.20484), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.88 (param_0.146: f32[64,8,1024], param_1.317: s32[], param_2.341: f32[8,1024]) -> f32[64,8,1024] {
  %param_0.146 = f32[64,8,1024]{2,1,0} parameter(0)
  %param_2.341 = f32[8,1024]{1,0} parameter(2)
  %reshape.2913 = f32[1,8,1024]{2,1,0} reshape(f32[8,1024]{1,0} %param_2.341), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_1.317 = s32[] parameter(1)
  %constant.20486 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.806 = f32[64,8,1024]{2,1,0} dynamic-update-slice(f32[64,8,1024]{2,1,0} %param_0.146, f32[1,8,1024]{2,1,0} %reshape.2913, s32[] %param_1.317, s32[] %constant.20486, s32[] %constant.20486), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.89 (param_0.147: f32[64,8,1024], param_1.319: s32[], param_2.345: f32[8,1024]) -> f32[64,8,1024] {
  %param_0.147 = f32[64,8,1024]{2,1,0} parameter(0)
  %constant.20489 = f32[] constant(1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %broadcast.1770 = f32[8,1024]{1,0} broadcast(f32[] %constant.20489), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %param_2.345 = f32[8,1024]{1,0} parameter(2)
  %subtract.505 = f32[8,1024]{1,0} subtract(f32[8,1024]{1,0} %broadcast.1770, f32[8,1024]{1,0} %param_2.345), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %reshape.2914 = f32[1,8,1024]{2,1,0} reshape(f32[8,1024]{1,0} %subtract.505), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_1.319 = s32[] parameter(1)
  %constant.20488 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.807 = f32[64,8,1024]{2,1,0} dynamic-update-slice(f32[64,8,1024]{2,1,0} %param_0.147, f32[1,8,1024]{2,1,0} %reshape.2914, s32[] %param_1.319, s32[] %constant.20488, s32[] %constant.20488), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.90 (param_0.148: f32[64,8,1024], param_1.321: s32[], param_2.348: f32[8,1024]) -> f32[64,8,1024] {
  %param_0.148 = f32[64,8,1024]{2,1,0} parameter(0)
  %param_2.348 = f32[8,1024]{1,0} parameter(2)
  %reshape.2915 = f32[1,8,1024]{2,1,0} reshape(f32[8,1024]{1,0} %param_2.348), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_1.321 = s32[] parameter(1)
  %constant.20490 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.808 = f32[64,8,1024]{2,1,0} dynamic-update-slice(f32[64,8,1024]{2,1,0} %param_0.148, f32[1,8,1024]{2,1,0} %reshape.2915, s32[] %param_1.321, s32[] %constant.20490, s32[] %constant.20490), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.91 (param_0.149: f32[64,8,1024], param_1.323: s32[], param_2.352: f32[8,1024]) -> f32[64,8,1024] {
  %param_0.149 = f32[64,8,1024]{2,1,0} parameter(0)
  %constant.20492 = f32[] constant(1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %broadcast.1771 = f32[8,1024]{1,0} broadcast(f32[] %constant.20492), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %param_2.352 = f32[8,1024]{1,0} parameter(2)
  %subtract.506 = f32[8,1024]{1,0} subtract(f32[8,1024]{1,0} %broadcast.1771, f32[8,1024]{1,0} %param_2.352), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %reshape.2916 = f32[1,8,1024]{2,1,0} reshape(f32[8,1024]{1,0} %subtract.506), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_1.323 = s32[] parameter(1)
  %constant.20491 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.809 = f32[64,8,1024]{2,1,0} dynamic-update-slice(f32[64,8,1024]{2,1,0} %param_0.149, f32[1,8,1024]{2,1,0} %reshape.2916, s32[] %param_1.323, s32[] %constant.20491, s32[] %constant.20491), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.92 (param_0.150: f32[64,8,1024], param_1.325: s32[], param_2.355: f32[8,1024]) -> f32[64,8,1024] {
  %param_0.150 = f32[64,8,1024]{2,1,0} parameter(0)
  %param_2.355 = f32[8,1024]{1,0} parameter(2)
  %reshape.2917 = f32[1,8,1024]{2,1,0} reshape(f32[8,1024]{1,0} %param_2.355), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_1.325 = s32[] parameter(1)
  %constant.20494 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.810 = f32[64,8,1024]{2,1,0} dynamic-update-slice(f32[64,8,1024]{2,1,0} %param_0.150, f32[1,8,1024]{2,1,0} %reshape.2917, s32[] %param_1.325, s32[] %constant.20494, s32[] %constant.20494), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.93 (param_0.151: f32[64,8,1024], param_1.327: s32[], param_2.359: f32[8,1024]) -> f32[64,8,1024] {
  %param_0.151 = f32[64,8,1024]{2,1,0} parameter(0)
  %constant.20496 = f32[] constant(1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %broadcast.1772 = f32[8,1024]{1,0} broadcast(f32[] %constant.20496), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %param_2.359 = f32[8,1024]{1,0} parameter(2)
  %subtract.507 = f32[8,1024]{1,0} subtract(f32[8,1024]{1,0} %broadcast.1772, f32[8,1024]{1,0} %param_2.359), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %reshape.2918 = f32[1,8,1024]{2,1,0} reshape(f32[8,1024]{1,0} %subtract.507), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_1.327 = s32[] parameter(1)
  %constant.20495 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.811 = f32[64,8,1024]{2,1,0} dynamic-update-slice(f32[64,8,1024]{2,1,0} %param_0.151, f32[1,8,1024]{2,1,0} %reshape.2918, s32[] %param_1.327, s32[] %constant.20495, s32[] %constant.20495), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.94 (param_0.152: f32[64,8,2048], param_1.329: s32[], param_2.362: f32[8,2048]) -> f32[64,8,2048] {
  %param_0.152 = f32[64,8,2048]{2,1,0} parameter(0)
  %param_2.362 = f32[8,2048]{1,0} parameter(2)
  %reshape.2919 = f32[1,8,2048]{2,1,0} reshape(f32[8,2048]{1,0} %param_2.362), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 8, 2048) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_1.329 = s32[] parameter(1)
  %constant.20498 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.812 = f32[64,8,2048]{2,1,0} dynamic-update-slice(f32[64,8,2048]{2,1,0} %param_0.152, f32[1,8,2048]{2,1,0} %reshape.2919, s32[] %param_1.329, s32[] %constant.20498, s32[] %constant.20498), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.95 (param_0.153: f32[64,8,1024], param_1.331: s32[], param_2.366: f32[8,2048]) -> f32[64,8,1024] {
  %param_0.153 = f32[64,8,1024]{2,1,0} parameter(0)
  %param_2.366 = f32[8,2048]{1,0} parameter(2)
  %slice.1260 = f32[8,1024]{1,0} slice(f32[8,2048]{1,0} %param_2.366), slice={[0:8], [0:1024]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(8, 1024)\n                                                     start_indices=(0, 0)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=54}
  %reshape.2920 = f32[1,8,1024]{2,1,0} reshape(f32[8,1024]{1,0} %slice.1260), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_1.331 = s32[] parameter(1)
  %constant.20499 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.813 = f32[64,8,1024]{2,1,0} dynamic-update-slice(f32[64,8,1024]{2,1,0} %param_0.153, f32[1,8,1024]{2,1,0} %reshape.2920, s32[] %param_1.331, s32[] %constant.20499, s32[] %constant.20499), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.96 (param_0.154: f32[64,8,1024], param_1.333: s32[], param_2.369: f32[8,1024]) -> f32[64,8,1024] {
  %param_0.154 = f32[64,8,1024]{2,1,0} parameter(0)
  %param_2.369 = f32[8,1024]{1,0} parameter(2)
  %reshape.2921 = f32[1,8,1024]{2,1,0} reshape(f32[8,1024]{1,0} %param_2.369), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_1.333 = s32[] parameter(1)
  %constant.20500 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.814 = f32[64,8,1024]{2,1,0} dynamic-update-slice(f32[64,8,1024]{2,1,0} %param_0.154, f32[1,8,1024]{2,1,0} %reshape.2921, s32[] %param_1.333, s32[] %constant.20500, s32[] %constant.20500), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.97 (param_0.155: f32[64,8,1024], param_1.335: s32[], param_2.372: f32[8,1024], param_3.334: f32[8,1024]) -> f32[64,8,1024] {
  %param_0.155 = f32[64,8,1024]{2,1,0} parameter(0)
  %param_2.372 = f32[8,1024]{1,0} parameter(2)
  %param_3.334 = f32[8,1024]{1,0} parameter(3)
  %multiply.1376 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %param_2.372, f32[8,1024]{1,0} %param_3.334), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  %reshape.2922 = f32[1,8,1024]{2,1,0} reshape(f32[8,1024]{1,0} %multiply.1376), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_1.335 = s32[] parameter(1)
  %constant.20501 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.815 = f32[64,8,1024]{2,1,0} dynamic-update-slice(f32[64,8,1024]{2,1,0} %param_0.155, f32[1,8,1024]{2,1,0} %reshape.2922, s32[] %param_1.335, s32[] %constant.20501, s32[] %constant.20501), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.98 (param_0.156: f32[8,1024], param_1.337: f32[8,1024], param_2.373: f32[8,1024]) -> f32[8,2048] {
  %param_0.156 = f32[8,1024]{1,0} parameter(0)
  %param_1.337 = f32[8,1024]{1,0} parameter(1)
  %param_2.373 = f32[8,1024]{1,0} parameter(2)
  %multiply.1377 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %param_1.337, f32[8,1024]{1,0} %param_2.373), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  ROOT %concatenate.234 = f32[8,2048]{1,0} concatenate(f32[8,1024]{1,0} %param_0.156, f32[8,1024]{1,0} %multiply.1377), dimensions={1}, metadata={op_type="concatenate" op_name="pmap(_multi_device_update_fn)/scan/while/body/concatenate[ dimension=1 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=65}
}

%fused_computation.99 (param_0.158: f32[8,4096], param_1.344: f32[1,4096]) -> f32[8,1024] {
  %constant.20502 = f32[] constant(1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %broadcast.1774 = f32[8,1024]{1,0} broadcast(f32[] %constant.20502), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %param_0.158 = f32[8,4096]{1,0} parameter(0)
  %param_1.344 = f32[1,4096]{1,0} parameter(1)
  %reshape.2923 = f32[4096]{0} reshape(f32[1,4096]{1,0} %param_1.344), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %broadcast.1773 = f32[8,4096]{1,0} broadcast(f32[4096]{0} %reshape.2923), dimensions={1}, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %add.3985 = f32[8,4096]{1,0} add(f32[8,4096]{1,0} %param_0.158, f32[8,4096]{1,0} %broadcast.1773), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %slice.1261 = f32[8,1024]{1,0} slice(f32[8,4096]{1,0} %add.3985), slice={[0:8], [3072:4096]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(8, 4096)\n                                                     start_indices=(0, 3072)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  %negate.199 = f32[8,1024]{1,0} negate(f32[8,1024]{1,0} %slice.1261), metadata={op_type="neg" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/neg" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %exponential.171 = f32[8,1024]{1,0} exponential(f32[8,1024]{1,0} %negate.199), metadata={op_type="exp" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/exp" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %add.3984 = f32[8,1024]{1,0} add(f32[8,1024]{1,0} %broadcast.1774, f32[8,1024]{1,0} %exponential.171), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  ROOT %divide.175 = f32[8,1024]{1,0} divide(f32[8,1024]{1,0} %broadcast.1774, f32[8,1024]{1,0} %add.3984), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
}

%fused_computation.100 (param_0.160: f32[8,1024], param_1.347: f32[8,1024], param_2.380: f32[8,1024], param_3.336: f32[8,2048]) -> f32[8,1024] {
  %param_3.336 = f32[8,2048]{1,0} parameter(3)
  %slice.1262 = f32[8,1024]{1,0} slice(f32[8,2048]{1,0} %param_3.336), slice={[0:8], [0:1024]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(8, 1024)\n                                                     start_indices=(0, 0)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=54}
  %param_2.380 = f32[8,1024]{1,0} parameter(2)
  %multiply.1379 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %slice.1262, f32[8,1024]{1,0} %param_2.380), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %param_0.160 = f32[8,1024]{1,0} parameter(0)
  %param_1.347 = f32[8,1024]{1,0} parameter(1)
  %multiply.1378 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %param_0.160, f32[8,1024]{1,0} %param_1.347), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  ROOT %add.3986 = f32[8,1024]{1,0} add(f32[8,1024]{1,0} %multiply.1379, f32[8,1024]{1,0} %multiply.1378), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
}

%fused_computation.101 (param_0.163: f32[8,4096], param_1.350: f32[1,4096]) -> f32[8,1024] {
  %param_0.163 = f32[8,4096]{1,0} parameter(0)
  %param_1.350 = f32[1,4096]{1,0} parameter(1)
  %reshape.2924 = f32[4096]{0} reshape(f32[1,4096]{1,0} %param_1.350), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %broadcast.1775 = f32[8,4096]{1,0} broadcast(f32[4096]{0} %reshape.2924), dimensions={1}, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %add.3987 = f32[8,4096]{1,0} add(f32[8,4096]{1,0} %param_0.163, f32[8,4096]{1,0} %broadcast.1775), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %slice.1263 = f32[8,1024]{1,0} slice(f32[8,4096]{1,0} %add.3987), slice={[0:8], [1024:2048]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(8, 2048)\n                                                     start_indices=(0, 1024)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  ROOT %tanh.111 = f32[8,1024]{1,0} tanh(f32[8,1024]{1,0} %slice.1263), metadata={op_type="tanh" op_name="pmap(_multi_device_update_fn)/scan/while/body/tanh" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
}

%fused_computation.102 (param_0.165: f32[8,4096], param_1.357: f32[1,4096]) -> f32[8,1024] {
  %constant.20504 = f32[] constant(1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %broadcast.1777 = f32[8,1024]{1,0} broadcast(f32[] %constant.20504), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %param_0.165 = f32[8,4096]{1,0} parameter(0)
  %param_1.357 = f32[1,4096]{1,0} parameter(1)
  %reshape.2925 = f32[4096]{0} reshape(f32[1,4096]{1,0} %param_1.357), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %broadcast.1776 = f32[8,4096]{1,0} broadcast(f32[4096]{0} %reshape.2925), dimensions={1}, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %add.3989 = f32[8,4096]{1,0} add(f32[8,4096]{1,0} %param_0.165, f32[8,4096]{1,0} %broadcast.1776), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %slice.1264 = f32[8,1024]{1,0} slice(f32[8,4096]{1,0} %add.3989), slice={[0:8], [0:1024]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(8, 1024)\n                                                     start_indices=(0, 0)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  %negate.200 = f32[8,1024]{1,0} negate(f32[8,1024]{1,0} %slice.1264), metadata={op_type="neg" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/neg" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %exponential.172 = f32[8,1024]{1,0} exponential(f32[8,1024]{1,0} %negate.200), metadata={op_type="exp" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/exp" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %add.3988 = f32[8,1024]{1,0} add(f32[8,1024]{1,0} %broadcast.1777, f32[8,1024]{1,0} %exponential.172), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  ROOT %divide.176 = f32[8,1024]{1,0} divide(f32[8,1024]{1,0} %broadcast.1777, f32[8,1024]{1,0} %add.3988), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
}

%fused_computation.103 (param_0.167: f32[8,4096], param_1.364: f32[1,4096]) -> f32[8,1024] {
  %constant.20505 = f32[] constant(1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %broadcast.1779 = f32[8,1024]{1,0} broadcast(f32[] %constant.20505), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %param_0.167 = f32[8,4096]{1,0} parameter(0)
  %param_1.364 = f32[1,4096]{1,0} parameter(1)
  %reshape.2926 = f32[4096]{0} reshape(f32[1,4096]{1,0} %param_1.364), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %broadcast.1778 = f32[8,4096]{1,0} broadcast(f32[4096]{0} %reshape.2926), dimensions={1}, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %add.3992 = f32[8,4096]{1,0} add(f32[8,4096]{1,0} %param_0.167, f32[8,4096]{1,0} %broadcast.1778), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %slice.1265 = f32[8,1024]{1,0} slice(f32[8,4096]{1,0} %add.3992), slice={[0:8], [2048:3072]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(8, 3072)\n                                                     start_indices=(0, 2048)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  %negate.201 = f32[8,1024]{1,0} negate(f32[8,1024]{1,0} %slice.1265), metadata={op_type="neg" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/neg" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %exponential.173 = f32[8,1024]{1,0} exponential(f32[8,1024]{1,0} %negate.201), metadata={op_type="exp" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/exp" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %add.3990 = f32[8,1024]{1,0} add(f32[8,1024]{1,0} %broadcast.1779, f32[8,1024]{1,0} %exponential.173), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  ROOT %divide.177 = f32[8,1024]{1,0} divide(f32[8,1024]{1,0} %broadcast.1779, f32[8,1024]{1,0} %add.3990), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
}

%fused_computation.104 (param_0.169: f32[8,2048], param_1.368: f32[64,8,1024], param_2.389: s32[]) -> f32[8,2048] {
  %param_1.368 = f32[64,8,1024]{2,1,0} parameter(1)
  %param_2.389 = s32[] parameter(2)
  %constant.20506 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %dynamic-slice.781 = f32[1,8,1024]{2,1,0} dynamic-slice(f32[64,8,1024]{2,1,0} %param_1.368, s32[] %param_2.389, s32[] %constant.20506, s32[] %constant.20506), dynamic_slice_sizes={1,8,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %reshape.2927 = f32[8,1024]{1,0} reshape(f32[1,8,1024]{2,1,0} %dynamic-slice.781), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_0.169 = f32[8,2048]{1,0} parameter(0)
  %slice.1266 = f32[8,1024]{1,0} slice(f32[8,2048]{1,0} %param_0.169), slice={[0:8], [1024:2048]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(8, 2048)\n                                                     start_indices=(0, 1024)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=54}
  ROOT %concatenate.235 = f32[8,2048]{1,0} concatenate(f32[8,1024]{1,0} %reshape.2927, f32[8,1024]{1,0} %slice.1266), dimensions={1}, metadata={op_type="concatenate" op_name="pmap(_multi_device_update_fn)/scan/while/body/concatenate[ dimension=1 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
}

%fused_computation.105 (param_0.171: s32[]) -> s32[] {
  %param_0.171 = s32[] parameter(0)
  %constant.20509 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.2747 = pred[] compare(s32[] %param_0.171, s32[] %constant.20509), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant.20507 = s32[] constant(64), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.3993 = s32[] add(s32[] %param_0.171, s32[] %constant.20507), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %select.2636 = s32[] select(pred[] %compare.2747, s32[] %add.3993, s32[] %param_0.171), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%wide.body_computation__159.4507.clone.clone.clone.clone.clone (wide_param.177: (f32[64,8,1024], f32[2048,4096], f32[1,4096], s32[], f32[8,2048], /*index=5*/f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[64,8,2048], f32[64,8,1024], /*index=10*/f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], /*index=15*/f32[64,8,1024], f32[64,8,1024], f32[64,8,1024])) -> (f32[64,8,1024], f32[2048,4096], f32[1,4096], s32[], f32[8,2048], /*index=5*/f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[64,8,2048], f32[64,8,1024], /*index=10*/f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], /*index=15*/f32[64,8,1024], f32[64,8,1024], f32[64,8,1024]) {
  %wide_param.177 = (f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) parameter(0)
  %get-tuple-element.27038 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %wide_param.177), index=0
  %get-tuple-element.27039 = f32[2048,4096]{1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %wide_param.177), index=1
  %get-tuple-element.27040 = f32[1,4096]{1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %wide_param.177), index=2
  %get-tuple-element.27041 = s32[] get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %wide_param.177), index=3
  %copy.407 = s32[] copy(s32[] %get-tuple-element.27041)
  %constant.18730 = s32[] constant(1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.3473 = s32[] add(s32[] %copy.407, s32[] %constant.18730), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.27042 = f32[8,2048]{1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %wide_param.177), index=4
  %copy.408 = f32[8,2048]{1,0} copy(f32[8,2048]{1,0} %get-tuple-element.27042)
  %fusion.105 = s32[] fusion(s32[] %copy.407), kind=kLoop, calls=%fused_computation.105, metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %fusion.104 = f32[8,2048]{1,0} fusion(f32[8,2048]{1,0} %copy.408, f32[64,8,1024]{2,1,0} %get-tuple-element.27038, s32[] %fusion.105), kind=kLoop, calls=%fused_computation.104, metadata={op_type="concatenate" op_name="pmap(_multi_device_update_fn)/scan/while/body/concatenate[ dimension=1 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %dot.173 = f32[8,4096]{1,0} dot(f32[8,2048]{1,0} %fusion.104, f32[2048,4096]{1,0} %get-tuple-element.27039), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="dot_general" op_name="pmap(_multi_device_update_fn)/scan/while/body/dot_general[ dimension_numbers=(((1,), (0,)), ((), ()))\n                                                           precision=None\n                                                           preferred_element_type=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %fusion.102 = f32[8,1024]{1,0} fusion(f32[8,4096]{1,0} %dot.173, f32[1,4096]{1,0} %get-tuple-element.27040), kind=kLoop, calls=%fused_computation.102, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %fusion.101 = f32[8,1024]{1,0} fusion(f32[8,4096]{1,0} %dot.173, f32[1,4096]{1,0} %get-tuple-element.27040), kind=kLoop, calls=%fused_computation.101, metadata={op_type="tanh" op_name="pmap(_multi_device_update_fn)/scan/while/body/tanh" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %fusion.103 = f32[8,1024]{1,0} fusion(f32[8,4096]{1,0} %dot.173, f32[1,4096]{1,0} %get-tuple-element.27040), kind=kLoop, calls=%fused_computation.103, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %fusion.100 = f32[8,1024]{1,0} fusion(f32[8,1024]{1,0} %fusion.102, f32[8,1024]{1,0} %fusion.101, f32[8,1024]{1,0} %fusion.103, f32[8,2048]{1,0} %copy.408), kind=kLoop, calls=%fused_computation.100, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %tanh.97 = f32[8,1024]{1,0} tanh(f32[8,1024]{1,0} %fusion.100), metadata={op_type="tanh" op_name="pmap(_multi_device_update_fn)/scan/while/body/tanh" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  %fusion.99 = f32[8,1024]{1,0} fusion(f32[8,4096]{1,0} %dot.173, f32[1,4096]{1,0} %get-tuple-element.27040), kind=kLoop, calls=%fused_computation.99, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %fusion.98 = f32[8,2048]{1,0} fusion(f32[8,1024]{1,0} %fusion.100, f32[8,1024]{1,0} %tanh.97, f32[8,1024]{1,0} %fusion.99), kind=kLoop, calls=%fused_computation.98, metadata={op_type="concatenate" op_name="pmap(_multi_device_update_fn)/scan/while/body/concatenate[ dimension=1 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=65}
  %get-tuple-element.27043 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %wide_param.177), index=5
  %fusion.97 = f32[64,8,1024]{2,1,0} fusion(f32[64,8,1024]{2,1,0} %get-tuple-element.27043, s32[] %fusion.105, f32[8,1024]{1,0} %tanh.97, f32[8,1024]{1,0} %fusion.99), kind=kLoop, calls=%fused_computation.97, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.27044 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %wide_param.177), index=6
  %fusion.96 = f32[64,8,1024]{2,1,0} fusion(f32[64,8,1024]{2,1,0} %get-tuple-element.27044, s32[] %fusion.105, f32[8,1024]{1,0} %fusion.103), kind=kLoop, calls=%fused_computation.96, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.27045 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %wide_param.177), index=7
  %fusion.95 = f32[64,8,1024]{2,1,0} fusion(f32[64,8,1024]{2,1,0} %get-tuple-element.27045, s32[] %fusion.105, f32[8,2048]{1,0} %copy.408), kind=kLoop, calls=%fused_computation.95, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.27046 = f32[64,8,2048]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %wide_param.177), index=8
  %fusion.94 = f32[64,8,2048]{2,1,0} fusion(f32[64,8,2048]{2,1,0} %get-tuple-element.27046, s32[] %fusion.105, f32[8,2048]{1,0} %fusion.104), kind=kLoop, calls=%fused_computation.94, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.27047 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %wide_param.177), index=9
  %fusion.93 = f32[64,8,1024]{2,1,0} fusion(f32[64,8,1024]{2,1,0} %get-tuple-element.27047, s32[] %fusion.105, f32[8,1024]{1,0} %fusion.103), kind=kLoop, calls=%fused_computation.93, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.27048 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %wide_param.177), index=10
  %fusion.92 = f32[64,8,1024]{2,1,0} fusion(f32[64,8,1024]{2,1,0} %get-tuple-element.27048, s32[] %fusion.105, f32[8,1024]{1,0} %fusion.102), kind=kLoop, calls=%fused_computation.92, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.27049 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %wide_param.177), index=11
  %fusion.91 = f32[64,8,1024]{2,1,0} fusion(f32[64,8,1024]{2,1,0} %get-tuple-element.27049, s32[] %fusion.105, f32[8,1024]{1,0} %fusion.102), kind=kLoop, calls=%fused_computation.91, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.27050 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %wide_param.177), index=12
  %fusion.90 = f32[64,8,1024]{2,1,0} fusion(f32[64,8,1024]{2,1,0} %get-tuple-element.27050, s32[] %fusion.105, f32[8,1024]{1,0} %fusion.101), kind=kLoop, calls=%fused_computation.90, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.27051 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %wide_param.177), index=13
  %fusion.89 = f32[64,8,1024]{2,1,0} fusion(f32[64,8,1024]{2,1,0} %get-tuple-element.27051, s32[] %fusion.105, f32[8,1024]{1,0} %fusion.101), kind=kLoop, calls=%fused_computation.89, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.27052 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %wide_param.177), index=14
  %fusion.88 = f32[64,8,1024]{2,1,0} fusion(f32[64,8,1024]{2,1,0} %get-tuple-element.27052, s32[] %fusion.105, f32[8,1024]{1,0} %tanh.97), kind=kLoop, calls=%fused_computation.88, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.27053 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %wide_param.177), index=15
  %fusion.87 = f32[64,8,1024]{2,1,0} fusion(f32[64,8,1024]{2,1,0} %get-tuple-element.27053, s32[] %fusion.105, f32[8,1024]{1,0} %tanh.97), kind=kLoop, calls=%fused_computation.87, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.27054 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %wide_param.177), index=16
  %fusion.86 = f32[64,8,1024]{2,1,0} fusion(f32[64,8,1024]{2,1,0} %get-tuple-element.27054, s32[] %fusion.105, f32[8,1024]{1,0} %fusion.99), kind=kLoop, calls=%fused_computation.86, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.27055 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %wide_param.177), index=17
  %fusion.85 = f32[64,8,1024]{2,1,0} fusion(f32[64,8,1024]{2,1,0} %get-tuple-element.27055, s32[] %fusion.105, f32[8,1024]{1,0} %fusion.99), kind=kLoop, calls=%fused_computation.85, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %tuple.1281 = (f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) tuple(f32[64,8,1024]{2,1,0} %get-tuple-element.27038, f32[2048,4096]{1,0} %get-tuple-element.27039, f32[1,4096]{1,0} %get-tuple-element.27040, s32[] %add.3473, f32[8,2048]{1,0} %fusion.98, /*index=5*/f32[64,8,1024]{2,1,0} %fusion.97, f32[64,8,1024]{2,1,0} %fusion.96, f32[64,8,1024]{2,1,0} %fusion.95, f32[64,8,2048]{2,1,0} %fusion.94, f32[64,8,1024]{2,1,0} %fusion.93, /*index=10*/f32[64,8,1024]{2,1,0} %fusion.92, f32[64,8,1024]{2,1,0} %fusion.91, f32[64,8,1024]{2,1,0} %fusion.90, f32[64,8,1024]{2,1,0} %fusion.89, f32[64,8,1024]{2,1,0} %fusion.88, /*index=15*/f32[64,8,1024]{2,1,0} %fusion.87, f32[64,8,1024]{2,1,0} %fusion.86, f32[64,8,1024]{2,1,0} %fusion.85)
}

%wide.cond_computation__159.4928.clone.clone.clone.clone (wide_param.178: (f32[64,8,1024], f32[2048,4096], f32[1,4096], s32[], f32[8,2048], /*index=5*/f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[64,8,2048], f32[64,8,1024], /*index=10*/f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], /*index=15*/f32[64,8,1024], f32[64,8,1024], f32[64,8,1024])) -> pred[] {
  %wide_param.178 = (f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) parameter(0)
  %get-tuple-element.24704 = s32[] get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %wide_param.178), index=3
  %constant.18733 = s32[] constant(64), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/cond/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %compare.2499 = pred[] compare(s32[] %get-tuple-element.24704, s32[] %constant.18733), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/cond/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.106 (param_0.172: f32[64,8,1024], param_1.373: s32[], param_2.395: f32[8,1024]) -> f32[64,8,1024] {
  %param_0.172 = f32[64,8,1024]{2,1,0} parameter(0)
  %constant.20511 = f32[] constant(1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %broadcast.1780 = f32[8,1024]{1,0} broadcast(f32[] %constant.20511), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %param_2.395 = f32[8,1024]{1,0} parameter(2)
  %subtract.508 = f32[8,1024]{1,0} subtract(f32[8,1024]{1,0} %broadcast.1780, f32[8,1024]{1,0} %param_2.395), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %reshape.2928 = f32[1,8,1024]{2,1,0} reshape(f32[8,1024]{1,0} %subtract.508), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_1.373 = s32[] parameter(1)
  %constant.20510 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.816 = f32[64,8,1024]{2,1,0} dynamic-update-slice(f32[64,8,1024]{2,1,0} %param_0.172, f32[1,8,1024]{2,1,0} %reshape.2928, s32[] %param_1.373, s32[] %constant.20510, s32[] %constant.20510), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.107 (param_0.173: f32[64,8,1024], param_1.375: s32[], param_2.398: f32[8,1024]) -> f32[64,8,1024] {
  %param_0.173 = f32[64,8,1024]{2,1,0} parameter(0)
  %param_2.398 = f32[8,1024]{1,0} parameter(2)
  %reshape.2929 = f32[1,8,1024]{2,1,0} reshape(f32[8,1024]{1,0} %param_2.398), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_1.375 = s32[] parameter(1)
  %constant.20512 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.817 = f32[64,8,1024]{2,1,0} dynamic-update-slice(f32[64,8,1024]{2,1,0} %param_0.173, f32[1,8,1024]{2,1,0} %reshape.2929, s32[] %param_1.375, s32[] %constant.20512, s32[] %constant.20512), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.108 (param_0.174: f32[64,8,1024], param_1.377: s32[], param_2.402: f32[8,1024]) -> f32[64,8,1024] {
  %param_0.174 = f32[64,8,1024]{2,1,0} parameter(0)
  %constant.20515 = f32[] constant(1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %broadcast.1781 = f32[8,1024]{1,0} broadcast(f32[] %constant.20515), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %param_2.402 = f32[8,1024]{1,0} parameter(2)
  %subtract.509 = f32[8,1024]{1,0} subtract(f32[8,1024]{1,0} %broadcast.1781, f32[8,1024]{1,0} %param_2.402), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  %reshape.2930 = f32[1,8,1024]{2,1,0} reshape(f32[8,1024]{1,0} %subtract.509), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_1.377 = s32[] parameter(1)
  %constant.20514 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.818 = f32[64,8,1024]{2,1,0} dynamic-update-slice(f32[64,8,1024]{2,1,0} %param_0.174, f32[1,8,1024]{2,1,0} %reshape.2930, s32[] %param_1.377, s32[] %constant.20514, s32[] %constant.20514), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.109 (param_0.175: f32[64,8,1024], param_1.379: s32[], param_2.405: f32[8,1024]) -> f32[64,8,1024] {
  %param_0.175 = f32[64,8,1024]{2,1,0} parameter(0)
  %param_2.405 = f32[8,1024]{1,0} parameter(2)
  %reshape.2931 = f32[1,8,1024]{2,1,0} reshape(f32[8,1024]{1,0} %param_2.405), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_1.379 = s32[] parameter(1)
  %constant.20516 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.819 = f32[64,8,1024]{2,1,0} dynamic-update-slice(f32[64,8,1024]{2,1,0} %param_0.175, f32[1,8,1024]{2,1,0} %reshape.2931, s32[] %param_1.379, s32[] %constant.20516, s32[] %constant.20516), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.110 (param_0.176: f32[64,8,1024], param_1.381: s32[], param_2.409: f32[8,1024]) -> f32[64,8,1024] {
  %param_0.176 = f32[64,8,1024]{2,1,0} parameter(0)
  %constant.20519 = f32[] constant(1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %broadcast.1782 = f32[8,1024]{1,0} broadcast(f32[] %constant.20519), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %param_2.409 = f32[8,1024]{1,0} parameter(2)
  %subtract.510 = f32[8,1024]{1,0} subtract(f32[8,1024]{1,0} %broadcast.1782, f32[8,1024]{1,0} %param_2.409), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %reshape.2932 = f32[1,8,1024]{2,1,0} reshape(f32[8,1024]{1,0} %subtract.510), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_1.381 = s32[] parameter(1)
  %constant.20517 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.820 = f32[64,8,1024]{2,1,0} dynamic-update-slice(f32[64,8,1024]{2,1,0} %param_0.176, f32[1,8,1024]{2,1,0} %reshape.2932, s32[] %param_1.381, s32[] %constant.20517, s32[] %constant.20517), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.111 (param_0.177: f32[64,8,1024], param_1.383: s32[], param_2.412: f32[8,1024]) -> f32[64,8,1024] {
  %param_0.177 = f32[64,8,1024]{2,1,0} parameter(0)
  %param_2.412 = f32[8,1024]{1,0} parameter(2)
  %reshape.2933 = f32[1,8,1024]{2,1,0} reshape(f32[8,1024]{1,0} %param_2.412), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_1.383 = s32[] parameter(1)
  %constant.20520 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.821 = f32[64,8,1024]{2,1,0} dynamic-update-slice(f32[64,8,1024]{2,1,0} %param_0.177, f32[1,8,1024]{2,1,0} %reshape.2933, s32[] %param_1.383, s32[] %constant.20520, s32[] %constant.20520), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.112 (param_0.178: f32[64,8,1024], param_1.385: s32[], param_2.416: f32[8,1024]) -> f32[64,8,1024] {
  %param_0.178 = f32[64,8,1024]{2,1,0} parameter(0)
  %constant.20522 = f32[] constant(1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %broadcast.1783 = f32[8,1024]{1,0} broadcast(f32[] %constant.20522), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %param_2.416 = f32[8,1024]{1,0} parameter(2)
  %subtract.511 = f32[8,1024]{1,0} subtract(f32[8,1024]{1,0} %broadcast.1783, f32[8,1024]{1,0} %param_2.416), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %reshape.2934 = f32[1,8,1024]{2,1,0} reshape(f32[8,1024]{1,0} %subtract.511), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_1.385 = s32[] parameter(1)
  %constant.20521 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.822 = f32[64,8,1024]{2,1,0} dynamic-update-slice(f32[64,8,1024]{2,1,0} %param_0.178, f32[1,8,1024]{2,1,0} %reshape.2934, s32[] %param_1.385, s32[] %constant.20521, s32[] %constant.20521), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.113 (param_0.179: f32[64,8,1024], param_1.387: s32[], param_2.419: f32[8,1024]) -> f32[64,8,1024] {
  %param_0.179 = f32[64,8,1024]{2,1,0} parameter(0)
  %param_2.419 = f32[8,1024]{1,0} parameter(2)
  %reshape.2936 = f32[1,8,1024]{2,1,0} reshape(f32[8,1024]{1,0} %param_2.419), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_1.387 = s32[] parameter(1)
  %constant.20523 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.823 = f32[64,8,1024]{2,1,0} dynamic-update-slice(f32[64,8,1024]{2,1,0} %param_0.179, f32[1,8,1024]{2,1,0} %reshape.2936, s32[] %param_1.387, s32[] %constant.20523, s32[] %constant.20523), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.114 (param_0.180: f32[64,8,1024], param_1.389: s32[], param_2.423: f32[8,1024]) -> f32[64,8,1024] {
  %param_0.180 = f32[64,8,1024]{2,1,0} parameter(0)
  %constant.20525 = f32[] constant(1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %broadcast.1784 = f32[8,1024]{1,0} broadcast(f32[] %constant.20525), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %param_2.423 = f32[8,1024]{1,0} parameter(2)
  %subtract.512 = f32[8,1024]{1,0} subtract(f32[8,1024]{1,0} %broadcast.1784, f32[8,1024]{1,0} %param_2.423), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %reshape.2938 = f32[1,8,1024]{2,1,0} reshape(f32[8,1024]{1,0} %subtract.512), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_1.389 = s32[] parameter(1)
  %constant.20524 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.824 = f32[64,8,1024]{2,1,0} dynamic-update-slice(f32[64,8,1024]{2,1,0} %param_0.180, f32[1,8,1024]{2,1,0} %reshape.2938, s32[] %param_1.389, s32[] %constant.20524, s32[] %constant.20524), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.115 (param_0.181: f32[64,8,2048], param_1.391: s32[], param_2.426: f32[8,2048]) -> f32[64,8,2048] {
  %param_0.181 = f32[64,8,2048]{2,1,0} parameter(0)
  %param_2.426 = f32[8,2048]{1,0} parameter(2)
  %reshape.2940 = f32[1,8,2048]{2,1,0} reshape(f32[8,2048]{1,0} %param_2.426), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 8, 2048) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_1.391 = s32[] parameter(1)
  %constant.20527 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.825 = f32[64,8,2048]{2,1,0} dynamic-update-slice(f32[64,8,2048]{2,1,0} %param_0.181, f32[1,8,2048]{2,1,0} %reshape.2940, s32[] %param_1.391, s32[] %constant.20527, s32[] %constant.20527), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.116 (param_0.182: f32[64,8,1024], param_1.393: s32[], param_2.430: f32[8,2048]) -> f32[64,8,1024] {
  %param_0.182 = f32[64,8,1024]{2,1,0} parameter(0)
  %param_2.430 = f32[8,2048]{1,0} parameter(2)
  %slice.1267 = f32[8,1024]{1,0} slice(f32[8,2048]{1,0} %param_2.430), slice={[0:8], [0:1024]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(8, 1024)\n                                                     start_indices=(0, 0)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=54}
  %reshape.2942 = f32[1,8,1024]{2,1,0} reshape(f32[8,1024]{1,0} %slice.1267), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_1.393 = s32[] parameter(1)
  %constant.20528 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.826 = f32[64,8,1024]{2,1,0} dynamic-update-slice(f32[64,8,1024]{2,1,0} %param_0.182, f32[1,8,1024]{2,1,0} %reshape.2942, s32[] %param_1.393, s32[] %constant.20528, s32[] %constant.20528), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.117 (param_0.183: f32[64,8,1024], param_1.395: s32[], param_2.433: f32[8,1024]) -> f32[64,8,1024] {
  %param_0.183 = f32[64,8,1024]{2,1,0} parameter(0)
  %param_2.433 = f32[8,1024]{1,0} parameter(2)
  %reshape.2943 = f32[1,8,1024]{2,1,0} reshape(f32[8,1024]{1,0} %param_2.433), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_1.395 = s32[] parameter(1)
  %constant.20529 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.827 = f32[64,8,1024]{2,1,0} dynamic-update-slice(f32[64,8,1024]{2,1,0} %param_0.183, f32[1,8,1024]{2,1,0} %reshape.2943, s32[] %param_1.395, s32[] %constant.20529, s32[] %constant.20529), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.118 (param_0.184: f32[64,8,1024], param_1.397: s32[], param_2.436: f32[8,1024], param_3.380: f32[8,1024]) -> f32[64,8,1024] {
  %param_0.184 = f32[64,8,1024]{2,1,0} parameter(0)
  %param_2.436 = f32[8,1024]{1,0} parameter(2)
  %param_3.380 = f32[8,1024]{1,0} parameter(3)
  %multiply.1380 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %param_2.436, f32[8,1024]{1,0} %param_3.380), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  %reshape.2944 = f32[1,8,1024]{2,1,0} reshape(f32[8,1024]{1,0} %multiply.1380), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_1.397 = s32[] parameter(1)
  %constant.20530 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.828 = f32[64,8,1024]{2,1,0} dynamic-update-slice(f32[64,8,1024]{2,1,0} %param_0.184, f32[1,8,1024]{2,1,0} %reshape.2944, s32[] %param_1.397, s32[] %constant.20530, s32[] %constant.20530), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.119 (param_0.185: f32[8,1024], param_1.399: f32[8,1024], param_2.437: f32[8,1024]) -> f32[8,2048] {
  %param_0.185 = f32[8,1024]{1,0} parameter(0)
  %param_1.399 = f32[8,1024]{1,0} parameter(1)
  %param_2.437 = f32[8,1024]{1,0} parameter(2)
  %multiply.1381 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %param_1.399, f32[8,1024]{1,0} %param_2.437), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  ROOT %concatenate.236 = f32[8,2048]{1,0} concatenate(f32[8,1024]{1,0} %param_0.185, f32[8,1024]{1,0} %multiply.1381), dimensions={1}, metadata={op_type="concatenate" op_name="pmap(_multi_device_update_fn)/scan/while/body/concatenate[ dimension=1 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=65}
}

%fused_computation.120 (param_0.187: f32[8,4096], param_1.406: f32[1,4096]) -> f32[8,1024] {
  %constant.20531 = f32[] constant(1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %broadcast.1786 = f32[8,1024]{1,0} broadcast(f32[] %constant.20531), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %param_0.187 = f32[8,4096]{1,0} parameter(0)
  %param_1.406 = f32[1,4096]{1,0} parameter(1)
  %reshape.2945 = f32[4096]{0} reshape(f32[1,4096]{1,0} %param_1.406), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %broadcast.1785 = f32[8,4096]{1,0} broadcast(f32[4096]{0} %reshape.2945), dimensions={1}, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %add.3995 = f32[8,4096]{1,0} add(f32[8,4096]{1,0} %param_0.187, f32[8,4096]{1,0} %broadcast.1785), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %slice.1268 = f32[8,1024]{1,0} slice(f32[8,4096]{1,0} %add.3995), slice={[0:8], [3072:4096]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(8, 4096)\n                                                     start_indices=(0, 3072)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  %negate.202 = f32[8,1024]{1,0} negate(f32[8,1024]{1,0} %slice.1268), metadata={op_type="neg" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/neg" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %exponential.174 = f32[8,1024]{1,0} exponential(f32[8,1024]{1,0} %negate.202), metadata={op_type="exp" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/exp" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %add.3994 = f32[8,1024]{1,0} add(f32[8,1024]{1,0} %broadcast.1786, f32[8,1024]{1,0} %exponential.174), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  ROOT %divide.178 = f32[8,1024]{1,0} divide(f32[8,1024]{1,0} %broadcast.1786, f32[8,1024]{1,0} %add.3994), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
}

%fused_computation.121 (param_0.189: f32[8,1024], param_1.409: f32[8,1024], param_2.444: f32[8,1024], param_3.382: f32[8,2048]) -> f32[8,1024] {
  %param_3.382 = f32[8,2048]{1,0} parameter(3)
  %slice.1269 = f32[8,1024]{1,0} slice(f32[8,2048]{1,0} %param_3.382), slice={[0:8], [0:1024]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(8, 1024)\n                                                     start_indices=(0, 0)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=54}
  %param_2.444 = f32[8,1024]{1,0} parameter(2)
  %multiply.1383 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %slice.1269, f32[8,1024]{1,0} %param_2.444), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %param_0.189 = f32[8,1024]{1,0} parameter(0)
  %param_1.409 = f32[8,1024]{1,0} parameter(1)
  %multiply.1382 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %param_0.189, f32[8,1024]{1,0} %param_1.409), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  ROOT %add.3996 = f32[8,1024]{1,0} add(f32[8,1024]{1,0} %multiply.1383, f32[8,1024]{1,0} %multiply.1382), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
}

%fused_computation.122 (param_0.192: f32[8,4096], param_1.412: f32[1,4096]) -> f32[8,1024] {
  %param_0.192 = f32[8,4096]{1,0} parameter(0)
  %param_1.412 = f32[1,4096]{1,0} parameter(1)
  %reshape.2946 = f32[4096]{0} reshape(f32[1,4096]{1,0} %param_1.412), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %broadcast.1787 = f32[8,4096]{1,0} broadcast(f32[4096]{0} %reshape.2946), dimensions={1}, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %add.3997 = f32[8,4096]{1,0} add(f32[8,4096]{1,0} %param_0.192, f32[8,4096]{1,0} %broadcast.1787), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %slice.1270 = f32[8,1024]{1,0} slice(f32[8,4096]{1,0} %add.3997), slice={[0:8], [1024:2048]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(8, 2048)\n                                                     start_indices=(0, 1024)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  ROOT %tanh.112 = f32[8,1024]{1,0} tanh(f32[8,1024]{1,0} %slice.1270), metadata={op_type="tanh" op_name="pmap(_multi_device_update_fn)/scan/while/body/tanh" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
}

%fused_computation.123 (param_0.194: f32[8,4096], param_1.419: f32[1,4096]) -> f32[8,1024] {
  %constant.20533 = f32[] constant(1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %broadcast.1789 = f32[8,1024]{1,0} broadcast(f32[] %constant.20533), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %param_0.194 = f32[8,4096]{1,0} parameter(0)
  %param_1.419 = f32[1,4096]{1,0} parameter(1)
  %reshape.2947 = f32[4096]{0} reshape(f32[1,4096]{1,0} %param_1.419), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %broadcast.1788 = f32[8,4096]{1,0} broadcast(f32[4096]{0} %reshape.2947), dimensions={1}, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %add.3999 = f32[8,4096]{1,0} add(f32[8,4096]{1,0} %param_0.194, f32[8,4096]{1,0} %broadcast.1788), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %slice.1271 = f32[8,1024]{1,0} slice(f32[8,4096]{1,0} %add.3999), slice={[0:8], [0:1024]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(8, 1024)\n                                                     start_indices=(0, 0)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  %negate.203 = f32[8,1024]{1,0} negate(f32[8,1024]{1,0} %slice.1271), metadata={op_type="neg" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/neg" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %exponential.175 = f32[8,1024]{1,0} exponential(f32[8,1024]{1,0} %negate.203), metadata={op_type="exp" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/exp" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %add.3998 = f32[8,1024]{1,0} add(f32[8,1024]{1,0} %broadcast.1789, f32[8,1024]{1,0} %exponential.175), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  ROOT %divide.179 = f32[8,1024]{1,0} divide(f32[8,1024]{1,0} %broadcast.1789, f32[8,1024]{1,0} %add.3998), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
}

%fused_computation.124 (param_0.196: f32[8,4096], param_1.426: f32[1,4096]) -> f32[8,1024] {
  %constant.20534 = f32[] constant(1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %broadcast.1791 = f32[8,1024]{1,0} broadcast(f32[] %constant.20534), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %param_0.196 = f32[8,4096]{1,0} parameter(0)
  %param_1.426 = f32[1,4096]{1,0} parameter(1)
  %reshape.2948 = f32[4096]{0} reshape(f32[1,4096]{1,0} %param_1.426), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %broadcast.1790 = f32[8,4096]{1,0} broadcast(f32[4096]{0} %reshape.2948), dimensions={1}, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %add.4002 = f32[8,4096]{1,0} add(f32[8,4096]{1,0} %param_0.196, f32[8,4096]{1,0} %broadcast.1790), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %slice.1272 = f32[8,1024]{1,0} slice(f32[8,4096]{1,0} %add.4002), slice={[0:8], [2048:3072]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(8, 3072)\n                                                     start_indices=(0, 2048)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  %negate.204 = f32[8,1024]{1,0} negate(f32[8,1024]{1,0} %slice.1272), metadata={op_type="neg" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/neg" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %exponential.176 = f32[8,1024]{1,0} exponential(f32[8,1024]{1,0} %negate.204), metadata={op_type="exp" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/exp" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %add.4001 = f32[8,1024]{1,0} add(f32[8,1024]{1,0} %broadcast.1791, f32[8,1024]{1,0} %exponential.176), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  ROOT %divide.180 = f32[8,1024]{1,0} divide(f32[8,1024]{1,0} %broadcast.1791, f32[8,1024]{1,0} %add.4001), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
}

%fused_computation.125 (param_0.198: f32[8,2048], param_1.430: f32[64,8,1024], param_2.453: s32[]) -> f32[8,2048] {
  %param_1.430 = f32[64,8,1024]{2,1,0} parameter(1)
  %param_2.453 = s32[] parameter(2)
  %constant.20535 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %dynamic-slice.782 = f32[1,8,1024]{2,1,0} dynamic-slice(f32[64,8,1024]{2,1,0} %param_1.430, s32[] %param_2.453, s32[] %constant.20535, s32[] %constant.20535), dynamic_slice_sizes={1,8,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %reshape.2949 = f32[8,1024]{1,0} reshape(f32[1,8,1024]{2,1,0} %dynamic-slice.782), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_0.198 = f32[8,2048]{1,0} parameter(0)
  %slice.1273 = f32[8,1024]{1,0} slice(f32[8,2048]{1,0} %param_0.198), slice={[0:8], [1024:2048]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(8, 2048)\n                                                     start_indices=(0, 1024)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=54}
  ROOT %concatenate.237 = f32[8,2048]{1,0} concatenate(f32[8,1024]{1,0} %reshape.2949, f32[8,1024]{1,0} %slice.1273), dimensions={1}, metadata={op_type="concatenate" op_name="pmap(_multi_device_update_fn)/scan/while/body/concatenate[ dimension=1 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
}

%fused_computation.126 (param_0.200: s32[]) -> s32[] {
  %param_0.200 = s32[] parameter(0)
  %constant.20538 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.2749 = pred[] compare(s32[] %param_0.200, s32[] %constant.20538), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant.20537 = s32[] constant(64), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.4003 = s32[] add(s32[] %param_0.200, s32[] %constant.20537), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %select.2637 = s32[] select(pred[] %compare.2749, s32[] %add.4003, s32[] %param_0.200), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%wide.body_computation__165.5972.clone.clone.clone.clone.clone (wide_param.179: (f32[64,8,1024], f32[2048,4096], f32[1,4096], s32[], f32[8,2048], /*index=5*/f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[64,8,2048], f32[64,8,1024], /*index=10*/f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], /*index=15*/f32[64,8,1024], f32[64,8,1024], f32[64,8,1024])) -> (f32[64,8,1024], f32[2048,4096], f32[1,4096], s32[], f32[8,2048], /*index=5*/f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[64,8,2048], f32[64,8,1024], /*index=10*/f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], /*index=15*/f32[64,8,1024], f32[64,8,1024], f32[64,8,1024]) {
  %wide_param.179 = (f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) parameter(0)
  %get-tuple-element.26822 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %wide_param.179), index=0
  %get-tuple-element.26823 = f32[2048,4096]{1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %wide_param.179), index=1
  %get-tuple-element.26824 = f32[1,4096]{1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %wide_param.179), index=2
  %get-tuple-element.26825 = s32[] get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %wide_param.179), index=3
  %copy.227 = s32[] copy(s32[] %get-tuple-element.26825)
  %constant.18818 = s32[] constant(1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.3495 = s32[] add(s32[] %copy.227, s32[] %constant.18818), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.26826 = f32[8,2048]{1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %wide_param.179), index=4
  %copy.228 = f32[8,2048]{1,0} copy(f32[8,2048]{1,0} %get-tuple-element.26826)
  %fusion.126 = s32[] fusion(s32[] %copy.227), kind=kLoop, calls=%fused_computation.126, metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %fusion.125 = f32[8,2048]{1,0} fusion(f32[8,2048]{1,0} %copy.228, f32[64,8,1024]{2,1,0} %get-tuple-element.26822, s32[] %fusion.126), kind=kLoop, calls=%fused_computation.125, metadata={op_type="concatenate" op_name="pmap(_multi_device_update_fn)/scan/while/body/concatenate[ dimension=1 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %dot.174 = f32[8,4096]{1,0} dot(f32[8,2048]{1,0} %fusion.125, f32[2048,4096]{1,0} %get-tuple-element.26823), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="dot_general" op_name="pmap(_multi_device_update_fn)/scan/while/body/dot_general[ dimension_numbers=(((1,), (0,)), ((), ()))\n                                                           precision=None\n                                                           preferred_element_type=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %fusion.123 = f32[8,1024]{1,0} fusion(f32[8,4096]{1,0} %dot.174, f32[1,4096]{1,0} %get-tuple-element.26824), kind=kLoop, calls=%fused_computation.123, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %fusion.122 = f32[8,1024]{1,0} fusion(f32[8,4096]{1,0} %dot.174, f32[1,4096]{1,0} %get-tuple-element.26824), kind=kLoop, calls=%fused_computation.122, metadata={op_type="tanh" op_name="pmap(_multi_device_update_fn)/scan/while/body/tanh" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %fusion.124 = f32[8,1024]{1,0} fusion(f32[8,4096]{1,0} %dot.174, f32[1,4096]{1,0} %get-tuple-element.26824), kind=kLoop, calls=%fused_computation.124, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %fusion.121 = f32[8,1024]{1,0} fusion(f32[8,1024]{1,0} %fusion.123, f32[8,1024]{1,0} %fusion.122, f32[8,1024]{1,0} %fusion.124, f32[8,2048]{1,0} %copy.228), kind=kLoop, calls=%fused_computation.121, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %tanh.99 = f32[8,1024]{1,0} tanh(f32[8,1024]{1,0} %fusion.121), metadata={op_type="tanh" op_name="pmap(_multi_device_update_fn)/scan/while/body/tanh" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  %fusion.120 = f32[8,1024]{1,0} fusion(f32[8,4096]{1,0} %dot.174, f32[1,4096]{1,0} %get-tuple-element.26824), kind=kLoop, calls=%fused_computation.120, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %fusion.119 = f32[8,2048]{1,0} fusion(f32[8,1024]{1,0} %fusion.121, f32[8,1024]{1,0} %tanh.99, f32[8,1024]{1,0} %fusion.120), kind=kLoop, calls=%fused_computation.119, metadata={op_type="concatenate" op_name="pmap(_multi_device_update_fn)/scan/while/body/concatenate[ dimension=1 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=65}
  %get-tuple-element.26827 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %wide_param.179), index=5
  %fusion.118 = f32[64,8,1024]{2,1,0} fusion(f32[64,8,1024]{2,1,0} %get-tuple-element.26827, s32[] %fusion.126, f32[8,1024]{1,0} %tanh.99, f32[8,1024]{1,0} %fusion.120), kind=kLoop, calls=%fused_computation.118, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.26828 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %wide_param.179), index=6
  %fusion.117 = f32[64,8,1024]{2,1,0} fusion(f32[64,8,1024]{2,1,0} %get-tuple-element.26828, s32[] %fusion.126, f32[8,1024]{1,0} %fusion.124), kind=kLoop, calls=%fused_computation.117, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.26829 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %wide_param.179), index=7
  %fusion.116 = f32[64,8,1024]{2,1,0} fusion(f32[64,8,1024]{2,1,0} %get-tuple-element.26829, s32[] %fusion.126, f32[8,2048]{1,0} %copy.228), kind=kLoop, calls=%fused_computation.116, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.26830 = f32[64,8,2048]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %wide_param.179), index=8
  %fusion.115 = f32[64,8,2048]{2,1,0} fusion(f32[64,8,2048]{2,1,0} %get-tuple-element.26830, s32[] %fusion.126, f32[8,2048]{1,0} %fusion.125), kind=kLoop, calls=%fused_computation.115, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.26831 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %wide_param.179), index=9
  %fusion.114 = f32[64,8,1024]{2,1,0} fusion(f32[64,8,1024]{2,1,0} %get-tuple-element.26831, s32[] %fusion.126, f32[8,1024]{1,0} %fusion.124), kind=kLoop, calls=%fused_computation.114, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.26832 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %wide_param.179), index=10
  %fusion.113 = f32[64,8,1024]{2,1,0} fusion(f32[64,8,1024]{2,1,0} %get-tuple-element.26832, s32[] %fusion.126, f32[8,1024]{1,0} %fusion.123), kind=kLoop, calls=%fused_computation.113, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.26833 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %wide_param.179), index=11
  %fusion.112 = f32[64,8,1024]{2,1,0} fusion(f32[64,8,1024]{2,1,0} %get-tuple-element.26833, s32[] %fusion.126, f32[8,1024]{1,0} %fusion.123), kind=kLoop, calls=%fused_computation.112, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.26834 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %wide_param.179), index=12
  %fusion.111 = f32[64,8,1024]{2,1,0} fusion(f32[64,8,1024]{2,1,0} %get-tuple-element.26834, s32[] %fusion.126, f32[8,1024]{1,0} %fusion.122), kind=kLoop, calls=%fused_computation.111, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.26835 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %wide_param.179), index=13
  %fusion.110 = f32[64,8,1024]{2,1,0} fusion(f32[64,8,1024]{2,1,0} %get-tuple-element.26835, s32[] %fusion.126, f32[8,1024]{1,0} %fusion.122), kind=kLoop, calls=%fused_computation.110, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.26836 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %wide_param.179), index=14
  %fusion.109 = f32[64,8,1024]{2,1,0} fusion(f32[64,8,1024]{2,1,0} %get-tuple-element.26836, s32[] %fusion.126, f32[8,1024]{1,0} %tanh.99), kind=kLoop, calls=%fused_computation.109, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.26837 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %wide_param.179), index=15
  %fusion.108 = f32[64,8,1024]{2,1,0} fusion(f32[64,8,1024]{2,1,0} %get-tuple-element.26837, s32[] %fusion.126, f32[8,1024]{1,0} %tanh.99), kind=kLoop, calls=%fused_computation.108, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.26838 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %wide_param.179), index=16
  %fusion.107 = f32[64,8,1024]{2,1,0} fusion(f32[64,8,1024]{2,1,0} %get-tuple-element.26838, s32[] %fusion.126, f32[8,1024]{1,0} %fusion.120), kind=kLoop, calls=%fused_computation.107, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.26839 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %wide_param.179), index=17
  %fusion.106 = f32[64,8,1024]{2,1,0} fusion(f32[64,8,1024]{2,1,0} %get-tuple-element.26839, s32[] %fusion.126, f32[8,1024]{1,0} %fusion.120), kind=kLoop, calls=%fused_computation.106, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %tuple.1267 = (f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) tuple(f32[64,8,1024]{2,1,0} %get-tuple-element.26822, f32[2048,4096]{1,0} %get-tuple-element.26823, f32[1,4096]{1,0} %get-tuple-element.26824, s32[] %add.3495, f32[8,2048]{1,0} %fusion.119, /*index=5*/f32[64,8,1024]{2,1,0} %fusion.118, f32[64,8,1024]{2,1,0} %fusion.117, f32[64,8,1024]{2,1,0} %fusion.116, f32[64,8,2048]{2,1,0} %fusion.115, f32[64,8,1024]{2,1,0} %fusion.114, /*index=10*/f32[64,8,1024]{2,1,0} %fusion.113, f32[64,8,1024]{2,1,0} %fusion.112, f32[64,8,1024]{2,1,0} %fusion.111, f32[64,8,1024]{2,1,0} %fusion.110, f32[64,8,1024]{2,1,0} %fusion.109, /*index=15*/f32[64,8,1024]{2,1,0} %fusion.108, f32[64,8,1024]{2,1,0} %fusion.107, f32[64,8,1024]{2,1,0} %fusion.106)
}

%wide.cond_computation__165.6393.clone.clone.clone.clone (wide_param.180: (f32[64,8,1024], f32[2048,4096], f32[1,4096], s32[], f32[8,2048], /*index=5*/f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[64,8,2048], f32[64,8,1024], /*index=10*/f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], /*index=15*/f32[64,8,1024], f32[64,8,1024], f32[64,8,1024])) -> pred[] {
  %wide_param.180 = (f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) parameter(0)
  %get-tuple-element.24814 = s32[] get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %wide_param.180), index=3
  %constant.18821 = s32[] constant(64), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/cond/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %compare.2514 = pred[] compare(s32[] %get-tuple-element.24814, s32[] %constant.18821), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/cond/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.127 (param_0.201: f32[64,8,1024], param_1.435: s32[], param_2.459: f32[8,1024]) -> f32[64,8,1024] {
  %param_0.201 = f32[64,8,1024]{2,1,0} parameter(0)
  %constant.20541 = f32[] constant(1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %broadcast.1792 = f32[8,1024]{1,0} broadcast(f32[] %constant.20541), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %param_2.459 = f32[8,1024]{1,0} parameter(2)
  %subtract.513 = f32[8,1024]{1,0} subtract(f32[8,1024]{1,0} %broadcast.1792, f32[8,1024]{1,0} %param_2.459), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %reshape.2950 = f32[1,8,1024]{2,1,0} reshape(f32[8,1024]{1,0} %subtract.513), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_1.435 = s32[] parameter(1)
  %constant.20540 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.829 = f32[64,8,1024]{2,1,0} dynamic-update-slice(f32[64,8,1024]{2,1,0} %param_0.201, f32[1,8,1024]{2,1,0} %reshape.2950, s32[] %param_1.435, s32[] %constant.20540, s32[] %constant.20540), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.128 (param_0.202: f32[64,8,1024], param_1.437: s32[], param_2.462: f32[8,1024]) -> f32[64,8,1024] {
  %param_0.202 = f32[64,8,1024]{2,1,0} parameter(0)
  %param_2.462 = f32[8,1024]{1,0} parameter(2)
  %reshape.2951 = f32[1,8,1024]{2,1,0} reshape(f32[8,1024]{1,0} %param_2.462), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_1.437 = s32[] parameter(1)
  %constant.20542 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.830 = f32[64,8,1024]{2,1,0} dynamic-update-slice(f32[64,8,1024]{2,1,0} %param_0.202, f32[1,8,1024]{2,1,0} %reshape.2951, s32[] %param_1.437, s32[] %constant.20542, s32[] %constant.20542), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.129 (param_0.203: f32[64,8,1024], param_1.439: s32[], param_2.466: f32[8,1024]) -> f32[64,8,1024] {
  %param_0.203 = f32[64,8,1024]{2,1,0} parameter(0)
  %constant.20544 = f32[] constant(1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %broadcast.1793 = f32[8,1024]{1,0} broadcast(f32[] %constant.20544), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %param_2.466 = f32[8,1024]{1,0} parameter(2)
  %subtract.514 = f32[8,1024]{1,0} subtract(f32[8,1024]{1,0} %broadcast.1793, f32[8,1024]{1,0} %param_2.466), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  %reshape.2952 = f32[1,8,1024]{2,1,0} reshape(f32[8,1024]{1,0} %subtract.514), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_1.439 = s32[] parameter(1)
  %constant.20543 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.831 = f32[64,8,1024]{2,1,0} dynamic-update-slice(f32[64,8,1024]{2,1,0} %param_0.203, f32[1,8,1024]{2,1,0} %reshape.2952, s32[] %param_1.439, s32[] %constant.20543, s32[] %constant.20543), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.130 (param_0.204: f32[64,8,1024], param_1.441: s32[], param_2.469: f32[8,1024]) -> f32[64,8,1024] {
  %param_0.204 = f32[64,8,1024]{2,1,0} parameter(0)
  %param_2.469 = f32[8,1024]{1,0} parameter(2)
  %reshape.2953 = f32[1,8,1024]{2,1,0} reshape(f32[8,1024]{1,0} %param_2.469), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_1.441 = s32[] parameter(1)
  %constant.20546 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.832 = f32[64,8,1024]{2,1,0} dynamic-update-slice(f32[64,8,1024]{2,1,0} %param_0.204, f32[1,8,1024]{2,1,0} %reshape.2953, s32[] %param_1.441, s32[] %constant.20546, s32[] %constant.20546), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.131 (param_0.205: f32[64,8,1024], param_1.443: s32[], param_2.473: f32[8,1024]) -> f32[64,8,1024] {
  %param_0.205 = f32[64,8,1024]{2,1,0} parameter(0)
  %constant.20548 = f32[] constant(1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %broadcast.1794 = f32[8,1024]{1,0} broadcast(f32[] %constant.20548), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %param_2.473 = f32[8,1024]{1,0} parameter(2)
  %subtract.515 = f32[8,1024]{1,0} subtract(f32[8,1024]{1,0} %broadcast.1794, f32[8,1024]{1,0} %param_2.473), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %reshape.2954 = f32[1,8,1024]{2,1,0} reshape(f32[8,1024]{1,0} %subtract.515), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_1.443 = s32[] parameter(1)
  %constant.20547 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.833 = f32[64,8,1024]{2,1,0} dynamic-update-slice(f32[64,8,1024]{2,1,0} %param_0.205, f32[1,8,1024]{2,1,0} %reshape.2954, s32[] %param_1.443, s32[] %constant.20547, s32[] %constant.20547), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.132 (param_0.206: f32[64,8,1024], param_1.445: s32[], param_2.476: f32[8,1024]) -> f32[64,8,1024] {
  %param_0.206 = f32[64,8,1024]{2,1,0} parameter(0)
  %param_2.476 = f32[8,1024]{1,0} parameter(2)
  %reshape.2955 = f32[1,8,1024]{2,1,0} reshape(f32[8,1024]{1,0} %param_2.476), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_1.445 = s32[] parameter(1)
  %constant.20549 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.834 = f32[64,8,1024]{2,1,0} dynamic-update-slice(f32[64,8,1024]{2,1,0} %param_0.206, f32[1,8,1024]{2,1,0} %reshape.2955, s32[] %param_1.445, s32[] %constant.20549, s32[] %constant.20549), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.133 (param_0.207: f32[64,8,1024], param_1.447: s32[], param_2.480: f32[8,1024]) -> f32[64,8,1024] {
  %param_0.207 = f32[64,8,1024]{2,1,0} parameter(0)
  %constant.20552 = f32[] constant(1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %broadcast.1795 = f32[8,1024]{1,0} broadcast(f32[] %constant.20552), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %param_2.480 = f32[8,1024]{1,0} parameter(2)
  %subtract.516 = f32[8,1024]{1,0} subtract(f32[8,1024]{1,0} %broadcast.1795, f32[8,1024]{1,0} %param_2.480), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %reshape.2956 = f32[1,8,1024]{2,1,0} reshape(f32[8,1024]{1,0} %subtract.516), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_1.447 = s32[] parameter(1)
  %constant.20551 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.835 = f32[64,8,1024]{2,1,0} dynamic-update-slice(f32[64,8,1024]{2,1,0} %param_0.207, f32[1,8,1024]{2,1,0} %reshape.2956, s32[] %param_1.447, s32[] %constant.20551, s32[] %constant.20551), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.134 (param_0.208: f32[64,8,1024], param_1.449: s32[], param_2.483: f32[8,1024]) -> f32[64,8,1024] {
  %param_0.208 = f32[64,8,1024]{2,1,0} parameter(0)
  %param_2.483 = f32[8,1024]{1,0} parameter(2)
  %reshape.2957 = f32[1,8,1024]{2,1,0} reshape(f32[8,1024]{1,0} %param_2.483), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_1.449 = s32[] parameter(1)
  %constant.20553 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.836 = f32[64,8,1024]{2,1,0} dynamic-update-slice(f32[64,8,1024]{2,1,0} %param_0.208, f32[1,8,1024]{2,1,0} %reshape.2957, s32[] %param_1.449, s32[] %constant.20553, s32[] %constant.20553), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.135 (param_0.209: f32[64,8,1024], param_1.451: s32[], param_2.487: f32[8,1024]) -> f32[64,8,1024] {
  %param_0.209 = f32[64,8,1024]{2,1,0} parameter(0)
  %constant.20555 = f32[] constant(1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %broadcast.1796 = f32[8,1024]{1,0} broadcast(f32[] %constant.20555), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %param_2.487 = f32[8,1024]{1,0} parameter(2)
  %subtract.517 = f32[8,1024]{1,0} subtract(f32[8,1024]{1,0} %broadcast.1796, f32[8,1024]{1,0} %param_2.487), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %reshape.2958 = f32[1,8,1024]{2,1,0} reshape(f32[8,1024]{1,0} %subtract.517), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_1.451 = s32[] parameter(1)
  %constant.20554 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.837 = f32[64,8,1024]{2,1,0} dynamic-update-slice(f32[64,8,1024]{2,1,0} %param_0.209, f32[1,8,1024]{2,1,0} %reshape.2958, s32[] %param_1.451, s32[] %constant.20554, s32[] %constant.20554), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.136 (param_0.210: f32[64,8,2048], param_1.453: s32[], param_2.490: f32[8,2048]) -> f32[64,8,2048] {
  %param_0.210 = f32[64,8,2048]{2,1,0} parameter(0)
  %param_2.490 = f32[8,2048]{1,0} parameter(2)
  %reshape.2959 = f32[1,8,2048]{2,1,0} reshape(f32[8,2048]{1,0} %param_2.490), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 8, 2048) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_1.453 = s32[] parameter(1)
  %constant.20556 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.838 = f32[64,8,2048]{2,1,0} dynamic-update-slice(f32[64,8,2048]{2,1,0} %param_0.210, f32[1,8,2048]{2,1,0} %reshape.2959, s32[] %param_1.453, s32[] %constant.20556, s32[] %constant.20556), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.137 (param_0.211: f32[64,8,1024], param_1.455: s32[], param_2.494: f32[8,2048]) -> f32[64,8,1024] {
  %param_0.211 = f32[64,8,1024]{2,1,0} parameter(0)
  %param_2.494 = f32[8,2048]{1,0} parameter(2)
  %slice.1274 = f32[8,1024]{1,0} slice(f32[8,2048]{1,0} %param_2.494), slice={[0:8], [0:1024]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(8, 1024)\n                                                     start_indices=(0, 0)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=54}
  %reshape.2960 = f32[1,8,1024]{2,1,0} reshape(f32[8,1024]{1,0} %slice.1274), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_1.455 = s32[] parameter(1)
  %constant.20557 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.839 = f32[64,8,1024]{2,1,0} dynamic-update-slice(f32[64,8,1024]{2,1,0} %param_0.211, f32[1,8,1024]{2,1,0} %reshape.2960, s32[] %param_1.455, s32[] %constant.20557, s32[] %constant.20557), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.138 (param_0.212: f32[64,8,1024], param_1.457: s32[], param_2.497: f32[8,1024]) -> f32[64,8,1024] {
  %param_0.212 = f32[64,8,1024]{2,1,0} parameter(0)
  %param_2.497 = f32[8,1024]{1,0} parameter(2)
  %reshape.2961 = f32[1,8,1024]{2,1,0} reshape(f32[8,1024]{1,0} %param_2.497), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_1.457 = s32[] parameter(1)
  %constant.20558 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.840 = f32[64,8,1024]{2,1,0} dynamic-update-slice(f32[64,8,1024]{2,1,0} %param_0.212, f32[1,8,1024]{2,1,0} %reshape.2961, s32[] %param_1.457, s32[] %constant.20558, s32[] %constant.20558), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.139 (param_0.213: f32[64,8,1024], param_1.459: s32[], param_2.500: f32[8,1024], param_3.426: f32[8,1024]) -> f32[64,8,1024] {
  %param_0.213 = f32[64,8,1024]{2,1,0} parameter(0)
  %param_2.500 = f32[8,1024]{1,0} parameter(2)
  %param_3.426 = f32[8,1024]{1,0} parameter(3)
  %multiply.1384 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %param_2.500, f32[8,1024]{1,0} %param_3.426), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  %reshape.2962 = f32[1,8,1024]{2,1,0} reshape(f32[8,1024]{1,0} %multiply.1384), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_1.459 = s32[] parameter(1)
  %constant.20559 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.841 = f32[64,8,1024]{2,1,0} dynamic-update-slice(f32[64,8,1024]{2,1,0} %param_0.213, f32[1,8,1024]{2,1,0} %reshape.2962, s32[] %param_1.459, s32[] %constant.20559, s32[] %constant.20559), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.140 (param_0.214: f32[8,1024], param_1.461: f32[8,1024], param_2.501: f32[8,1024]) -> f32[8,2048] {
  %param_0.214 = f32[8,1024]{1,0} parameter(0)
  %param_1.461 = f32[8,1024]{1,0} parameter(1)
  %param_2.501 = f32[8,1024]{1,0} parameter(2)
  %multiply.1385 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %param_1.461, f32[8,1024]{1,0} %param_2.501), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  ROOT %concatenate.238 = f32[8,2048]{1,0} concatenate(f32[8,1024]{1,0} %param_0.214, f32[8,1024]{1,0} %multiply.1385), dimensions={1}, metadata={op_type="concatenate" op_name="pmap(_multi_device_update_fn)/scan/while/body/concatenate[ dimension=1 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=65}
}

%fused_computation.141 (param_0.216: f32[8,4096], param_1.468: f32[1,4096]) -> f32[8,1024] {
  %constant.20561 = f32[] constant(1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %broadcast.1798 = f32[8,1024]{1,0} broadcast(f32[] %constant.20561), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %param_0.216 = f32[8,4096]{1,0} parameter(0)
  %param_1.468 = f32[1,4096]{1,0} parameter(1)
  %reshape.2963 = f32[4096]{0} reshape(f32[1,4096]{1,0} %param_1.468), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %broadcast.1797 = f32[8,4096]{1,0} broadcast(f32[4096]{0} %reshape.2963), dimensions={1}, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %add.4005 = f32[8,4096]{1,0} add(f32[8,4096]{1,0} %param_0.216, f32[8,4096]{1,0} %broadcast.1797), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %slice.1275 = f32[8,1024]{1,0} slice(f32[8,4096]{1,0} %add.4005), slice={[0:8], [3072:4096]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(8, 4096)\n                                                     start_indices=(0, 3072)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  %negate.205 = f32[8,1024]{1,0} negate(f32[8,1024]{1,0} %slice.1275), metadata={op_type="neg" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/neg" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %exponential.177 = f32[8,1024]{1,0} exponential(f32[8,1024]{1,0} %negate.205), metadata={op_type="exp" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/exp" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %add.4004 = f32[8,1024]{1,0} add(f32[8,1024]{1,0} %broadcast.1798, f32[8,1024]{1,0} %exponential.177), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  ROOT %divide.181 = f32[8,1024]{1,0} divide(f32[8,1024]{1,0} %broadcast.1798, f32[8,1024]{1,0} %add.4004), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
}

%fused_computation.142 (param_0.218: f32[8,1024], param_1.471: f32[8,1024], param_2.508: f32[8,1024], param_3.428: f32[8,2048]) -> f32[8,1024] {
  %param_3.428 = f32[8,2048]{1,0} parameter(3)
  %slice.1276 = f32[8,1024]{1,0} slice(f32[8,2048]{1,0} %param_3.428), slice={[0:8], [0:1024]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(8, 1024)\n                                                     start_indices=(0, 0)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=54}
  %param_2.508 = f32[8,1024]{1,0} parameter(2)
  %multiply.1387 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %slice.1276, f32[8,1024]{1,0} %param_2.508), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %param_0.218 = f32[8,1024]{1,0} parameter(0)
  %param_1.471 = f32[8,1024]{1,0} parameter(1)
  %multiply.1386 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %param_0.218, f32[8,1024]{1,0} %param_1.471), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  ROOT %add.4006 = f32[8,1024]{1,0} add(f32[8,1024]{1,0} %multiply.1387, f32[8,1024]{1,0} %multiply.1386), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
}

%fused_computation.143 (param_0.221: f32[8,4096], param_1.474: f32[1,4096]) -> f32[8,1024] {
  %param_0.221 = f32[8,4096]{1,0} parameter(0)
  %param_1.474 = f32[1,4096]{1,0} parameter(1)
  %reshape.2964 = f32[4096]{0} reshape(f32[1,4096]{1,0} %param_1.474), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %broadcast.1799 = f32[8,4096]{1,0} broadcast(f32[4096]{0} %reshape.2964), dimensions={1}, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %add.4007 = f32[8,4096]{1,0} add(f32[8,4096]{1,0} %param_0.221, f32[8,4096]{1,0} %broadcast.1799), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %slice.1277 = f32[8,1024]{1,0} slice(f32[8,4096]{1,0} %add.4007), slice={[0:8], [1024:2048]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(8, 2048)\n                                                     start_indices=(0, 1024)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  ROOT %tanh.113 = f32[8,1024]{1,0} tanh(f32[8,1024]{1,0} %slice.1277), metadata={op_type="tanh" op_name="pmap(_multi_device_update_fn)/scan/while/body/tanh" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
}

%fused_computation.144 (param_0.223: f32[8,4096], param_1.481: f32[1,4096]) -> f32[8,1024] {
  %constant.20562 = f32[] constant(1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %broadcast.1801 = f32[8,1024]{1,0} broadcast(f32[] %constant.20562), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %param_0.223 = f32[8,4096]{1,0} parameter(0)
  %param_1.481 = f32[1,4096]{1,0} parameter(1)
  %reshape.2965 = f32[4096]{0} reshape(f32[1,4096]{1,0} %param_1.481), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %broadcast.1800 = f32[8,4096]{1,0} broadcast(f32[4096]{0} %reshape.2965), dimensions={1}, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %add.4010 = f32[8,4096]{1,0} add(f32[8,4096]{1,0} %param_0.223, f32[8,4096]{1,0} %broadcast.1800), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %slice.1278 = f32[8,1024]{1,0} slice(f32[8,4096]{1,0} %add.4010), slice={[0:8], [0:1024]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(8, 1024)\n                                                     start_indices=(0, 0)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  %negate.206 = f32[8,1024]{1,0} negate(f32[8,1024]{1,0} %slice.1278), metadata={op_type="neg" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/neg" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %exponential.178 = f32[8,1024]{1,0} exponential(f32[8,1024]{1,0} %negate.206), metadata={op_type="exp" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/exp" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %add.4008 = f32[8,1024]{1,0} add(f32[8,1024]{1,0} %broadcast.1801, f32[8,1024]{1,0} %exponential.178), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  ROOT %divide.182 = f32[8,1024]{1,0} divide(f32[8,1024]{1,0} %broadcast.1801, f32[8,1024]{1,0} %add.4008), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
}

%fused_computation.145 (param_0.225: f32[8,4096], param_1.488: f32[1,4096]) -> f32[8,1024] {
  %constant.20563 = f32[] constant(1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %broadcast.1803 = f32[8,1024]{1,0} broadcast(f32[] %constant.20563), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %param_0.225 = f32[8,4096]{1,0} parameter(0)
  %param_1.488 = f32[1,4096]{1,0} parameter(1)
  %reshape.2966 = f32[4096]{0} reshape(f32[1,4096]{1,0} %param_1.488), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %broadcast.1802 = f32[8,4096]{1,0} broadcast(f32[4096]{0} %reshape.2966), dimensions={1}, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %add.4012 = f32[8,4096]{1,0} add(f32[8,4096]{1,0} %param_0.225, f32[8,4096]{1,0} %broadcast.1802), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %slice.1279 = f32[8,1024]{1,0} slice(f32[8,4096]{1,0} %add.4012), slice={[0:8], [2048:3072]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(8, 3072)\n                                                     start_indices=(0, 2048)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  %negate.207 = f32[8,1024]{1,0} negate(f32[8,1024]{1,0} %slice.1279), metadata={op_type="neg" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/neg" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %exponential.179 = f32[8,1024]{1,0} exponential(f32[8,1024]{1,0} %negate.207), metadata={op_type="exp" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/exp" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %add.4011 = f32[8,1024]{1,0} add(f32[8,1024]{1,0} %broadcast.1803, f32[8,1024]{1,0} %exponential.179), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  ROOT %divide.183 = f32[8,1024]{1,0} divide(f32[8,1024]{1,0} %broadcast.1803, f32[8,1024]{1,0} %add.4011), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
}

%fused_computation.146 (param_0.227: f32[8,2048], param_1.492: f32[64,8,1024], param_2.517: s32[]) -> f32[8,2048] {
  %param_1.492 = f32[64,8,1024]{2,1,0} parameter(1)
  %param_2.517 = s32[] parameter(2)
  %constant.20564 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %dynamic-slice.783 = f32[1,8,1024]{2,1,0} dynamic-slice(f32[64,8,1024]{2,1,0} %param_1.492, s32[] %param_2.517, s32[] %constant.20564, s32[] %constant.20564), dynamic_slice_sizes={1,8,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %reshape.2967 = f32[8,1024]{1,0} reshape(f32[1,8,1024]{2,1,0} %dynamic-slice.783), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_0.227 = f32[8,2048]{1,0} parameter(0)
  %slice.1280 = f32[8,1024]{1,0} slice(f32[8,2048]{1,0} %param_0.227), slice={[0:8], [1024:2048]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(8, 2048)\n                                                     start_indices=(0, 1024)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=54}
  ROOT %concatenate.239 = f32[8,2048]{1,0} concatenate(f32[8,1024]{1,0} %reshape.2967, f32[8,1024]{1,0} %slice.1280), dimensions={1}, metadata={op_type="concatenate" op_name="pmap(_multi_device_update_fn)/scan/while/body/concatenate[ dimension=1 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
}

%fused_computation.147 (param_0.229: s32[]) -> s32[] {
  %param_0.229 = s32[] parameter(0)
  %constant.20567 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.2750 = pred[] compare(s32[] %param_0.229, s32[] %constant.20567), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant.20566 = s32[] constant(64), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.4013 = s32[] add(s32[] %param_0.229, s32[] %constant.20566), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %select.2639 = s32[] select(pred[] %compare.2750, s32[] %add.4013, s32[] %param_0.229), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%wide.body_computation__180.9214.clone.clone.clone.clone.clone (wide_param.181: (f32[64,8,1024], f32[2048,4096], f32[1,4096], s32[], f32[8,2048], /*index=5*/f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[64,8,2048], f32[64,8,1024], /*index=10*/f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], /*index=15*/f32[64,8,1024], f32[64,8,1024], f32[64,8,1024])) -> (f32[64,8,1024], f32[2048,4096], f32[1,4096], s32[], f32[8,2048], /*index=5*/f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[64,8,2048], f32[64,8,1024], /*index=10*/f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], /*index=15*/f32[64,8,1024], f32[64,8,1024], f32[64,8,1024]) {
  %wide_param.181 = (f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) parameter(0)
  %get-tuple-element.27284 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %wide_param.181), index=0
  %get-tuple-element.27285 = f32[2048,4096]{1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %wide_param.181), index=1
  %get-tuple-element.27286 = f32[1,4096]{1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %wide_param.181), index=2
  %get-tuple-element.27287 = s32[] get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %wide_param.181), index=3
  %copy.644 = s32[] copy(s32[] %get-tuple-element.27287)
  %constant.18905 = s32[] constant(1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.3517 = s32[] add(s32[] %copy.644, s32[] %constant.18905), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.27288 = f32[8,2048]{1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %wide_param.181), index=4
  %copy.645 = f32[8,2048]{1,0} copy(f32[8,2048]{1,0} %get-tuple-element.27288)
  %fusion.147 = s32[] fusion(s32[] %copy.644), kind=kLoop, calls=%fused_computation.147, metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %fusion.146 = f32[8,2048]{1,0} fusion(f32[8,2048]{1,0} %copy.645, f32[64,8,1024]{2,1,0} %get-tuple-element.27284, s32[] %fusion.147), kind=kLoop, calls=%fused_computation.146, metadata={op_type="concatenate" op_name="pmap(_multi_device_update_fn)/scan/while/body/concatenate[ dimension=1 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %dot.175 = f32[8,4096]{1,0} dot(f32[8,2048]{1,0} %fusion.146, f32[2048,4096]{1,0} %get-tuple-element.27285), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="dot_general" op_name="pmap(_multi_device_update_fn)/scan/while/body/dot_general[ dimension_numbers=(((1,), (0,)), ((), ()))\n                                                           precision=None\n                                                           preferred_element_type=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %fusion.144 = f32[8,1024]{1,0} fusion(f32[8,4096]{1,0} %dot.175, f32[1,4096]{1,0} %get-tuple-element.27286), kind=kLoop, calls=%fused_computation.144, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %fusion.143 = f32[8,1024]{1,0} fusion(f32[8,4096]{1,0} %dot.175, f32[1,4096]{1,0} %get-tuple-element.27286), kind=kLoop, calls=%fused_computation.143, metadata={op_type="tanh" op_name="pmap(_multi_device_update_fn)/scan/while/body/tanh" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %fusion.145 = f32[8,1024]{1,0} fusion(f32[8,4096]{1,0} %dot.175, f32[1,4096]{1,0} %get-tuple-element.27286), kind=kLoop, calls=%fused_computation.145, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %fusion.142 = f32[8,1024]{1,0} fusion(f32[8,1024]{1,0} %fusion.144, f32[8,1024]{1,0} %fusion.143, f32[8,1024]{1,0} %fusion.145, f32[8,2048]{1,0} %copy.645), kind=kLoop, calls=%fused_computation.142, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %tanh.101 = f32[8,1024]{1,0} tanh(f32[8,1024]{1,0} %fusion.142), metadata={op_type="tanh" op_name="pmap(_multi_device_update_fn)/scan/while/body/tanh" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  %fusion.141 = f32[8,1024]{1,0} fusion(f32[8,4096]{1,0} %dot.175, f32[1,4096]{1,0} %get-tuple-element.27286), kind=kLoop, calls=%fused_computation.141, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %fusion.140 = f32[8,2048]{1,0} fusion(f32[8,1024]{1,0} %fusion.142, f32[8,1024]{1,0} %tanh.101, f32[8,1024]{1,0} %fusion.141), kind=kLoop, calls=%fused_computation.140, metadata={op_type="concatenate" op_name="pmap(_multi_device_update_fn)/scan/while/body/concatenate[ dimension=1 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=65}
  %get-tuple-element.27289 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %wide_param.181), index=5
  %fusion.139 = f32[64,8,1024]{2,1,0} fusion(f32[64,8,1024]{2,1,0} %get-tuple-element.27289, s32[] %fusion.147, f32[8,1024]{1,0} %tanh.101, f32[8,1024]{1,0} %fusion.141), kind=kLoop, calls=%fused_computation.139, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.27290 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %wide_param.181), index=6
  %fusion.138 = f32[64,8,1024]{2,1,0} fusion(f32[64,8,1024]{2,1,0} %get-tuple-element.27290, s32[] %fusion.147, f32[8,1024]{1,0} %fusion.145), kind=kLoop, calls=%fused_computation.138, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.27291 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %wide_param.181), index=7
  %fusion.137 = f32[64,8,1024]{2,1,0} fusion(f32[64,8,1024]{2,1,0} %get-tuple-element.27291, s32[] %fusion.147, f32[8,2048]{1,0} %copy.645), kind=kLoop, calls=%fused_computation.137, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.27292 = f32[64,8,2048]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %wide_param.181), index=8
  %fusion.136 = f32[64,8,2048]{2,1,0} fusion(f32[64,8,2048]{2,1,0} %get-tuple-element.27292, s32[] %fusion.147, f32[8,2048]{1,0} %fusion.146), kind=kLoop, calls=%fused_computation.136, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.27293 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %wide_param.181), index=9
  %fusion.135 = f32[64,8,1024]{2,1,0} fusion(f32[64,8,1024]{2,1,0} %get-tuple-element.27293, s32[] %fusion.147, f32[8,1024]{1,0} %fusion.145), kind=kLoop, calls=%fused_computation.135, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.27294 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %wide_param.181), index=10
  %fusion.134 = f32[64,8,1024]{2,1,0} fusion(f32[64,8,1024]{2,1,0} %get-tuple-element.27294, s32[] %fusion.147, f32[8,1024]{1,0} %fusion.144), kind=kLoop, calls=%fused_computation.134, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.27295 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %wide_param.181), index=11
  %fusion.133 = f32[64,8,1024]{2,1,0} fusion(f32[64,8,1024]{2,1,0} %get-tuple-element.27295, s32[] %fusion.147, f32[8,1024]{1,0} %fusion.144), kind=kLoop, calls=%fused_computation.133, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.27296 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %wide_param.181), index=12
  %fusion.132 = f32[64,8,1024]{2,1,0} fusion(f32[64,8,1024]{2,1,0} %get-tuple-element.27296, s32[] %fusion.147, f32[8,1024]{1,0} %fusion.143), kind=kLoop, calls=%fused_computation.132, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.27297 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %wide_param.181), index=13
  %fusion.131 = f32[64,8,1024]{2,1,0} fusion(f32[64,8,1024]{2,1,0} %get-tuple-element.27297, s32[] %fusion.147, f32[8,1024]{1,0} %fusion.143), kind=kLoop, calls=%fused_computation.131, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.27298 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %wide_param.181), index=14
  %fusion.130 = f32[64,8,1024]{2,1,0} fusion(f32[64,8,1024]{2,1,0} %get-tuple-element.27298, s32[] %fusion.147, f32[8,1024]{1,0} %tanh.101), kind=kLoop, calls=%fused_computation.130, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.27299 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %wide_param.181), index=15
  %fusion.129 = f32[64,8,1024]{2,1,0} fusion(f32[64,8,1024]{2,1,0} %get-tuple-element.27299, s32[] %fusion.147, f32[8,1024]{1,0} %tanh.101), kind=kLoop, calls=%fused_computation.129, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.27300 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %wide_param.181), index=16
  %fusion.128 = f32[64,8,1024]{2,1,0} fusion(f32[64,8,1024]{2,1,0} %get-tuple-element.27300, s32[] %fusion.147, f32[8,1024]{1,0} %fusion.141), kind=kLoop, calls=%fused_computation.128, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.27301 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %wide_param.181), index=17
  %fusion.127 = f32[64,8,1024]{2,1,0} fusion(f32[64,8,1024]{2,1,0} %get-tuple-element.27301, s32[] %fusion.147, f32[8,1024]{1,0} %fusion.141), kind=kLoop, calls=%fused_computation.127, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %tuple.1310 = (f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) tuple(f32[64,8,1024]{2,1,0} %get-tuple-element.27284, f32[2048,4096]{1,0} %get-tuple-element.27285, f32[1,4096]{1,0} %get-tuple-element.27286, s32[] %add.3517, f32[8,2048]{1,0} %fusion.140, /*index=5*/f32[64,8,1024]{2,1,0} %fusion.139, f32[64,8,1024]{2,1,0} %fusion.138, f32[64,8,1024]{2,1,0} %fusion.137, f32[64,8,2048]{2,1,0} %fusion.136, f32[64,8,1024]{2,1,0} %fusion.135, /*index=10*/f32[64,8,1024]{2,1,0} %fusion.134, f32[64,8,1024]{2,1,0} %fusion.133, f32[64,8,1024]{2,1,0} %fusion.132, f32[64,8,1024]{2,1,0} %fusion.131, f32[64,8,1024]{2,1,0} %fusion.130, /*index=15*/f32[64,8,1024]{2,1,0} %fusion.129, f32[64,8,1024]{2,1,0} %fusion.128, f32[64,8,1024]{2,1,0} %fusion.127)
}

%wide.cond_computation__180.9635.clone.clone.clone.clone (wide_param.182: (f32[64,8,1024], f32[2048,4096], f32[1,4096], s32[], f32[8,2048], /*index=5*/f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[64,8,2048], f32[64,8,1024], /*index=10*/f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], /*index=15*/f32[64,8,1024], f32[64,8,1024], f32[64,8,1024])) -> pred[] {
  %wide_param.182 = (f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) parameter(0)
  %get-tuple-element.24924 = s32[] get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %wide_param.182), index=3
  %constant.18909 = s32[] constant(64), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/cond/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %compare.2530 = pred[] compare(s32[] %get-tuple-element.24924, s32[] %constant.18909), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/cond/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.148 (param_0.230: f32[64,8,1024], param_1.497: s32[], param_2.523: f32[8,1024]) -> f32[64,8,1024] {
  %param_0.230 = f32[64,8,1024]{2,1,0} parameter(0)
  %constant.20569 = f32[] constant(1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %broadcast.1804 = f32[8,1024]{1,0} broadcast(f32[] %constant.20569), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %param_2.523 = f32[8,1024]{1,0} parameter(2)
  %subtract.518 = f32[8,1024]{1,0} subtract(f32[8,1024]{1,0} %broadcast.1804, f32[8,1024]{1,0} %param_2.523), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %reshape.2968 = f32[1,8,1024]{2,1,0} reshape(f32[8,1024]{1,0} %subtract.518), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_1.497 = s32[] parameter(1)
  %constant.20568 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.842 = f32[64,8,1024]{2,1,0} dynamic-update-slice(f32[64,8,1024]{2,1,0} %param_0.230, f32[1,8,1024]{2,1,0} %reshape.2968, s32[] %param_1.497, s32[] %constant.20568, s32[] %constant.20568), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.149 (param_0.231: f32[64,8,1024], param_1.499: s32[], param_2.526: f32[8,1024]) -> f32[64,8,1024] {
  %param_0.231 = f32[64,8,1024]{2,1,0} parameter(0)
  %param_2.526 = f32[8,1024]{1,0} parameter(2)
  %reshape.2969 = f32[1,8,1024]{2,1,0} reshape(f32[8,1024]{1,0} %param_2.526), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_1.499 = s32[] parameter(1)
  %constant.20570 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.843 = f32[64,8,1024]{2,1,0} dynamic-update-slice(f32[64,8,1024]{2,1,0} %param_0.231, f32[1,8,1024]{2,1,0} %reshape.2969, s32[] %param_1.499, s32[] %constant.20570, s32[] %constant.20570), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.150 (param_0.232: f32[64,8,1024], param_1.501: s32[], param_2.530: f32[8,1024]) -> f32[64,8,1024] {
  %param_0.232 = f32[64,8,1024]{2,1,0} parameter(0)
  %constant.20573 = f32[] constant(1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %broadcast.1805 = f32[8,1024]{1,0} broadcast(f32[] %constant.20573), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %param_2.530 = f32[8,1024]{1,0} parameter(2)
  %subtract.519 = f32[8,1024]{1,0} subtract(f32[8,1024]{1,0} %broadcast.1805, f32[8,1024]{1,0} %param_2.530), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  %reshape.2970 = f32[1,8,1024]{2,1,0} reshape(f32[8,1024]{1,0} %subtract.519), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_1.501 = s32[] parameter(1)
  %constant.20572 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.844 = f32[64,8,1024]{2,1,0} dynamic-update-slice(f32[64,8,1024]{2,1,0} %param_0.232, f32[1,8,1024]{2,1,0} %reshape.2970, s32[] %param_1.501, s32[] %constant.20572, s32[] %constant.20572), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.151 (param_0.233: f32[64,8,1024], param_1.503: s32[], param_2.533: f32[8,1024]) -> f32[64,8,1024] {
  %param_0.233 = f32[64,8,1024]{2,1,0} parameter(0)
  %param_2.533 = f32[8,1024]{1,0} parameter(2)
  %reshape.2971 = f32[1,8,1024]{2,1,0} reshape(f32[8,1024]{1,0} %param_2.533), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_1.503 = s32[] parameter(1)
  %constant.20574 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.845 = f32[64,8,1024]{2,1,0} dynamic-update-slice(f32[64,8,1024]{2,1,0} %param_0.233, f32[1,8,1024]{2,1,0} %reshape.2971, s32[] %param_1.503, s32[] %constant.20574, s32[] %constant.20574), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.152 (param_0.234: f32[64,8,1024], param_1.505: s32[], param_2.537: f32[8,1024]) -> f32[64,8,1024] {
  %param_0.234 = f32[64,8,1024]{2,1,0} parameter(0)
  %constant.20577 = f32[] constant(1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %broadcast.1806 = f32[8,1024]{1,0} broadcast(f32[] %constant.20577), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %param_2.537 = f32[8,1024]{1,0} parameter(2)
  %subtract.520 = f32[8,1024]{1,0} subtract(f32[8,1024]{1,0} %broadcast.1806, f32[8,1024]{1,0} %param_2.537), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %reshape.2972 = f32[1,8,1024]{2,1,0} reshape(f32[8,1024]{1,0} %subtract.520), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_1.505 = s32[] parameter(1)
  %constant.20576 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.846 = f32[64,8,1024]{2,1,0} dynamic-update-slice(f32[64,8,1024]{2,1,0} %param_0.234, f32[1,8,1024]{2,1,0} %reshape.2972, s32[] %param_1.505, s32[] %constant.20576, s32[] %constant.20576), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.153 (param_0.235: f32[64,8,1024], param_1.507: s32[], param_2.540: f32[8,1024]) -> f32[64,8,1024] {
  %param_0.235 = f32[64,8,1024]{2,1,0} parameter(0)
  %param_2.540 = f32[8,1024]{1,0} parameter(2)
  %reshape.2973 = f32[1,8,1024]{2,1,0} reshape(f32[8,1024]{1,0} %param_2.540), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_1.507 = s32[] parameter(1)
  %constant.20578 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.847 = f32[64,8,1024]{2,1,0} dynamic-update-slice(f32[64,8,1024]{2,1,0} %param_0.235, f32[1,8,1024]{2,1,0} %reshape.2973, s32[] %param_1.507, s32[] %constant.20578, s32[] %constant.20578), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.154 (param_0.236: f32[64,8,1024], param_1.509: s32[], param_2.544: f32[8,1024]) -> f32[64,8,1024] {
  %param_0.236 = f32[64,8,1024]{2,1,0} parameter(0)
  %constant.20580 = f32[] constant(1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %broadcast.1807 = f32[8,1024]{1,0} broadcast(f32[] %constant.20580), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %param_2.544 = f32[8,1024]{1,0} parameter(2)
  %subtract.521 = f32[8,1024]{1,0} subtract(f32[8,1024]{1,0} %broadcast.1807, f32[8,1024]{1,0} %param_2.544), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %reshape.2974 = f32[1,8,1024]{2,1,0} reshape(f32[8,1024]{1,0} %subtract.521), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_1.509 = s32[] parameter(1)
  %constant.20579 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.848 = f32[64,8,1024]{2,1,0} dynamic-update-slice(f32[64,8,1024]{2,1,0} %param_0.236, f32[1,8,1024]{2,1,0} %reshape.2974, s32[] %param_1.509, s32[] %constant.20579, s32[] %constant.20579), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.155 (param_0.237: f32[64,8,1024], param_1.511: s32[], param_2.547: f32[8,1024]) -> f32[64,8,1024] {
  %param_0.237 = f32[64,8,1024]{2,1,0} parameter(0)
  %param_2.547 = f32[8,1024]{1,0} parameter(2)
  %reshape.2975 = f32[1,8,1024]{2,1,0} reshape(f32[8,1024]{1,0} %param_2.547), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_1.511 = s32[] parameter(1)
  %constant.20582 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.849 = f32[64,8,1024]{2,1,0} dynamic-update-slice(f32[64,8,1024]{2,1,0} %param_0.237, f32[1,8,1024]{2,1,0} %reshape.2975, s32[] %param_1.511, s32[] %constant.20582, s32[] %constant.20582), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.156 (param_0.238: f32[64,8,1024], param_1.513: s32[], param_2.551: f32[8,1024]) -> f32[64,8,1024] {
  %param_0.238 = f32[64,8,1024]{2,1,0} parameter(0)
  %constant.20584 = f32[] constant(1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %broadcast.1808 = f32[8,1024]{1,0} broadcast(f32[] %constant.20584), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %param_2.551 = f32[8,1024]{1,0} parameter(2)
  %subtract.522 = f32[8,1024]{1,0} subtract(f32[8,1024]{1,0} %broadcast.1808, f32[8,1024]{1,0} %param_2.551), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %reshape.2976 = f32[1,8,1024]{2,1,0} reshape(f32[8,1024]{1,0} %subtract.522), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_1.513 = s32[] parameter(1)
  %constant.20583 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.850 = f32[64,8,1024]{2,1,0} dynamic-update-slice(f32[64,8,1024]{2,1,0} %param_0.238, f32[1,8,1024]{2,1,0} %reshape.2976, s32[] %param_1.513, s32[] %constant.20583, s32[] %constant.20583), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.157 (param_0.239: f32[64,8,2048], param_1.515: s32[], param_2.554: f32[8,2048]) -> f32[64,8,2048] {
  %param_0.239 = f32[64,8,2048]{2,1,0} parameter(0)
  %param_2.554 = f32[8,2048]{1,0} parameter(2)
  %reshape.2977 = f32[1,8,2048]{2,1,0} reshape(f32[8,2048]{1,0} %param_2.554), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 8, 2048) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_1.515 = s32[] parameter(1)
  %constant.20585 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.851 = f32[64,8,2048]{2,1,0} dynamic-update-slice(f32[64,8,2048]{2,1,0} %param_0.239, f32[1,8,2048]{2,1,0} %reshape.2977, s32[] %param_1.515, s32[] %constant.20585, s32[] %constant.20585), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.158 (param_0.240: f32[64,8,1024], param_1.517: s32[], param_2.558: f32[8,2048]) -> f32[64,8,1024] {
  %param_0.240 = f32[64,8,1024]{2,1,0} parameter(0)
  %param_2.558 = f32[8,2048]{1,0} parameter(2)
  %slice.1281 = f32[8,1024]{1,0} slice(f32[8,2048]{1,0} %param_2.558), slice={[0:8], [0:1024]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(8, 1024)\n                                                     start_indices=(0, 0)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=54}
  %reshape.2978 = f32[1,8,1024]{2,1,0} reshape(f32[8,1024]{1,0} %slice.1281), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_1.517 = s32[] parameter(1)
  %constant.20587 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.852 = f32[64,8,1024]{2,1,0} dynamic-update-slice(f32[64,8,1024]{2,1,0} %param_0.240, f32[1,8,1024]{2,1,0} %reshape.2978, s32[] %param_1.517, s32[] %constant.20587, s32[] %constant.20587), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.159 (param_0.241: f32[64,8,1024], param_1.519: s32[], param_2.561: f32[8,1024]) -> f32[64,8,1024] {
  %param_0.241 = f32[64,8,1024]{2,1,0} parameter(0)
  %param_2.561 = f32[8,1024]{1,0} parameter(2)
  %reshape.2979 = f32[1,8,1024]{2,1,0} reshape(f32[8,1024]{1,0} %param_2.561), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_1.519 = s32[] parameter(1)
  %constant.20588 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.853 = f32[64,8,1024]{2,1,0} dynamic-update-slice(f32[64,8,1024]{2,1,0} %param_0.241, f32[1,8,1024]{2,1,0} %reshape.2979, s32[] %param_1.519, s32[] %constant.20588, s32[] %constant.20588), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.160 (param_0.242: f32[64,8,1024], param_1.521: s32[], param_2.564: f32[8,1024], param_3.472: f32[8,1024]) -> f32[64,8,1024] {
  %param_0.242 = f32[64,8,1024]{2,1,0} parameter(0)
  %param_2.564 = f32[8,1024]{1,0} parameter(2)
  %param_3.472 = f32[8,1024]{1,0} parameter(3)
  %multiply.1388 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %param_2.564, f32[8,1024]{1,0} %param_3.472), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  %reshape.2980 = f32[1,8,1024]{2,1,0} reshape(f32[8,1024]{1,0} %multiply.1388), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_1.521 = s32[] parameter(1)
  %constant.20589 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.854 = f32[64,8,1024]{2,1,0} dynamic-update-slice(f32[64,8,1024]{2,1,0} %param_0.242, f32[1,8,1024]{2,1,0} %reshape.2980, s32[] %param_1.521, s32[] %constant.20589, s32[] %constant.20589), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.161 (param_0.243: f32[8,1024], param_1.523: f32[8,1024], param_2.565: f32[8,1024]) -> f32[8,2048] {
  %param_0.243 = f32[8,1024]{1,0} parameter(0)
  %param_1.523 = f32[8,1024]{1,0} parameter(1)
  %param_2.565 = f32[8,1024]{1,0} parameter(2)
  %multiply.1389 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %param_1.523, f32[8,1024]{1,0} %param_2.565), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  ROOT %concatenate.240 = f32[8,2048]{1,0} concatenate(f32[8,1024]{1,0} %param_0.243, f32[8,1024]{1,0} %multiply.1389), dimensions={1}, metadata={op_type="concatenate" op_name="pmap(_multi_device_update_fn)/scan/while/body/concatenate[ dimension=1 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=65}
}

%fused_computation.162 (param_0.245: f32[8,4096], param_1.530: f32[1,4096]) -> f32[8,1024] {
  %constant.20590 = f32[] constant(1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %broadcast.1810 = f32[8,1024]{1,0} broadcast(f32[] %constant.20590), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %param_0.245 = f32[8,4096]{1,0} parameter(0)
  %param_1.530 = f32[1,4096]{1,0} parameter(1)
  %reshape.2981 = f32[4096]{0} reshape(f32[1,4096]{1,0} %param_1.530), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %broadcast.1809 = f32[8,4096]{1,0} broadcast(f32[4096]{0} %reshape.2981), dimensions={1}, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %add.4015 = f32[8,4096]{1,0} add(f32[8,4096]{1,0} %param_0.245, f32[8,4096]{1,0} %broadcast.1809), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %slice.1282 = f32[8,1024]{1,0} slice(f32[8,4096]{1,0} %add.4015), slice={[0:8], [3072:4096]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(8, 4096)\n                                                     start_indices=(0, 3072)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  %negate.208 = f32[8,1024]{1,0} negate(f32[8,1024]{1,0} %slice.1282), metadata={op_type="neg" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/neg" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %exponential.180 = f32[8,1024]{1,0} exponential(f32[8,1024]{1,0} %negate.208), metadata={op_type="exp" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/exp" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %add.4014 = f32[8,1024]{1,0} add(f32[8,1024]{1,0} %broadcast.1810, f32[8,1024]{1,0} %exponential.180), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  ROOT %divide.184 = f32[8,1024]{1,0} divide(f32[8,1024]{1,0} %broadcast.1810, f32[8,1024]{1,0} %add.4014), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
}

%fused_computation.163 (param_0.247: f32[8,1024], param_1.533: f32[8,1024], param_2.572: f32[8,1024], param_3.474: f32[8,2048]) -> f32[8,1024] {
  %param_3.474 = f32[8,2048]{1,0} parameter(3)
  %slice.1283 = f32[8,1024]{1,0} slice(f32[8,2048]{1,0} %param_3.474), slice={[0:8], [0:1024]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(8, 1024)\n                                                     start_indices=(0, 0)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=54}
  %param_2.572 = f32[8,1024]{1,0} parameter(2)
  %multiply.1391 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %slice.1283, f32[8,1024]{1,0} %param_2.572), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %param_0.247 = f32[8,1024]{1,0} parameter(0)
  %param_1.533 = f32[8,1024]{1,0} parameter(1)
  %multiply.1390 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %param_0.247, f32[8,1024]{1,0} %param_1.533), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  ROOT %add.4016 = f32[8,1024]{1,0} add(f32[8,1024]{1,0} %multiply.1391, f32[8,1024]{1,0} %multiply.1390), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
}

%fused_computation.164 (param_0.250: f32[8,4096], param_1.536: f32[1,4096]) -> f32[8,1024] {
  %param_0.250 = f32[8,4096]{1,0} parameter(0)
  %param_1.536 = f32[1,4096]{1,0} parameter(1)
  %reshape.2982 = f32[4096]{0} reshape(f32[1,4096]{1,0} %param_1.536), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %broadcast.1811 = f32[8,4096]{1,0} broadcast(f32[4096]{0} %reshape.2982), dimensions={1}, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %add.4017 = f32[8,4096]{1,0} add(f32[8,4096]{1,0} %param_0.250, f32[8,4096]{1,0} %broadcast.1811), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %slice.1284 = f32[8,1024]{1,0} slice(f32[8,4096]{1,0} %add.4017), slice={[0:8], [1024:2048]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(8, 2048)\n                                                     start_indices=(0, 1024)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  ROOT %tanh.114 = f32[8,1024]{1,0} tanh(f32[8,1024]{1,0} %slice.1284), metadata={op_type="tanh" op_name="pmap(_multi_device_update_fn)/scan/while/body/tanh" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
}

%fused_computation.165 (param_0.252: f32[8,4096], param_1.543: f32[1,4096]) -> f32[8,1024] {
  %constant.20592 = f32[] constant(1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %broadcast.1813 = f32[8,1024]{1,0} broadcast(f32[] %constant.20592), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %param_0.252 = f32[8,4096]{1,0} parameter(0)
  %param_1.543 = f32[1,4096]{1,0} parameter(1)
  %reshape.2983 = f32[4096]{0} reshape(f32[1,4096]{1,0} %param_1.543), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %broadcast.1812 = f32[8,4096]{1,0} broadcast(f32[4096]{0} %reshape.2983), dimensions={1}, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %add.4020 = f32[8,4096]{1,0} add(f32[8,4096]{1,0} %param_0.252, f32[8,4096]{1,0} %broadcast.1812), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %slice.1285 = f32[8,1024]{1,0} slice(f32[8,4096]{1,0} %add.4020), slice={[0:8], [0:1024]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(8, 1024)\n                                                     start_indices=(0, 0)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  %negate.209 = f32[8,1024]{1,0} negate(f32[8,1024]{1,0} %slice.1285), metadata={op_type="neg" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/neg" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %exponential.181 = f32[8,1024]{1,0} exponential(f32[8,1024]{1,0} %negate.209), metadata={op_type="exp" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/exp" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %add.4019 = f32[8,1024]{1,0} add(f32[8,1024]{1,0} %broadcast.1813, f32[8,1024]{1,0} %exponential.181), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  ROOT %divide.185 = f32[8,1024]{1,0} divide(f32[8,1024]{1,0} %broadcast.1813, f32[8,1024]{1,0} %add.4019), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
}

%fused_computation.166 (param_0.254: f32[8,4096], param_1.550: f32[1,4096]) -> f32[8,1024] {
  %constant.20593 = f32[] constant(1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %broadcast.1815 = f32[8,1024]{1,0} broadcast(f32[] %constant.20593), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %param_0.254 = f32[8,4096]{1,0} parameter(0)
  %param_1.550 = f32[1,4096]{1,0} parameter(1)
  %reshape.2984 = f32[4096]{0} reshape(f32[1,4096]{1,0} %param_1.550), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %broadcast.1814 = f32[8,4096]{1,0} broadcast(f32[4096]{0} %reshape.2984), dimensions={1}, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %add.4022 = f32[8,4096]{1,0} add(f32[8,4096]{1,0} %param_0.254, f32[8,4096]{1,0} %broadcast.1814), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %slice.1286 = f32[8,1024]{1,0} slice(f32[8,4096]{1,0} %add.4022), slice={[0:8], [2048:3072]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(8, 3072)\n                                                     start_indices=(0, 2048)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  %negate.210 = f32[8,1024]{1,0} negate(f32[8,1024]{1,0} %slice.1286), metadata={op_type="neg" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/neg" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %exponential.182 = f32[8,1024]{1,0} exponential(f32[8,1024]{1,0} %negate.210), metadata={op_type="exp" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/exp" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %add.4021 = f32[8,1024]{1,0} add(f32[8,1024]{1,0} %broadcast.1815, f32[8,1024]{1,0} %exponential.182), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  ROOT %divide.186 = f32[8,1024]{1,0} divide(f32[8,1024]{1,0} %broadcast.1815, f32[8,1024]{1,0} %add.4021), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
}

%fused_computation.167 (param_0.256: f32[8,2048], param_1.554: f32[64,8,1024], param_2.581: s32[]) -> f32[8,2048] {
  %param_1.554 = f32[64,8,1024]{2,1,0} parameter(1)
  %param_2.581 = s32[] parameter(2)
  %constant.20594 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %dynamic-slice.784 = f32[1,8,1024]{2,1,0} dynamic-slice(f32[64,8,1024]{2,1,0} %param_1.554, s32[] %param_2.581, s32[] %constant.20594, s32[] %constant.20594), dynamic_slice_sizes={1,8,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %reshape.2985 = f32[8,1024]{1,0} reshape(f32[1,8,1024]{2,1,0} %dynamic-slice.784), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_0.256 = f32[8,2048]{1,0} parameter(0)
  %slice.1287 = f32[8,1024]{1,0} slice(f32[8,2048]{1,0} %param_0.256), slice={[0:8], [1024:2048]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(8, 2048)\n                                                     start_indices=(0, 1024)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=54}
  ROOT %concatenate.241 = f32[8,2048]{1,0} concatenate(f32[8,1024]{1,0} %reshape.2985, f32[8,1024]{1,0} %slice.1287), dimensions={1}, metadata={op_type="concatenate" op_name="pmap(_multi_device_update_fn)/scan/while/body/concatenate[ dimension=1 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
}

%fused_computation.168 (param_0.258: s32[]) -> s32[] {
  %param_0.258 = s32[] parameter(0)
  %constant.20597 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.2751 = pred[] compare(s32[] %param_0.258, s32[] %constant.20597), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant.20595 = s32[] constant(64), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.4023 = s32[] add(s32[] %param_0.258, s32[] %constant.20595), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %select.2640 = s32[] select(pred[] %compare.2751, s32[] %add.4023, s32[] %param_0.258), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%wide.body_computation__184.10263.clone.clone.clone.clone.clone (wide_param.183: (f32[64,8,1024], f32[2048,4096], f32[1,4096], s32[], f32[8,2048], /*index=5*/f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[64,8,2048], f32[64,8,1024], /*index=10*/f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], /*index=15*/f32[64,8,1024], f32[64,8,1024], f32[64,8,1024])) -> (f32[64,8,1024], f32[2048,4096], f32[1,4096], s32[], f32[8,2048], /*index=5*/f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[64,8,2048], f32[64,8,1024], /*index=10*/f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], /*index=15*/f32[64,8,1024], f32[64,8,1024], f32[64,8,1024]) {
  %wide_param.183 = (f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) parameter(0)
  %get-tuple-element.27338 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %wide_param.183), index=0
  %get-tuple-element.27339 = f32[2048,4096]{1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %wide_param.183), index=1
  %get-tuple-element.27340 = f32[1,4096]{1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %wide_param.183), index=2
  %get-tuple-element.27341 = s32[] get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %wide_param.183), index=3
  %copy.689 = s32[] copy(s32[] %get-tuple-element.27341)
  %constant.18992 = s32[] constant(1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.3539 = s32[] add(s32[] %copy.689, s32[] %constant.18992), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.27342 = f32[8,2048]{1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %wide_param.183), index=4
  %copy.690 = f32[8,2048]{1,0} copy(f32[8,2048]{1,0} %get-tuple-element.27342)
  %fusion.168 = s32[] fusion(s32[] %copy.689), kind=kLoop, calls=%fused_computation.168, metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %fusion.167 = f32[8,2048]{1,0} fusion(f32[8,2048]{1,0} %copy.690, f32[64,8,1024]{2,1,0} %get-tuple-element.27338, s32[] %fusion.168), kind=kLoop, calls=%fused_computation.167, metadata={op_type="concatenate" op_name="pmap(_multi_device_update_fn)/scan/while/body/concatenate[ dimension=1 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %dot.176 = f32[8,4096]{1,0} dot(f32[8,2048]{1,0} %fusion.167, f32[2048,4096]{1,0} %get-tuple-element.27339), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="dot_general" op_name="pmap(_multi_device_update_fn)/scan/while/body/dot_general[ dimension_numbers=(((1,), (0,)), ((), ()))\n                                                           precision=None\n                                                           preferred_element_type=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %fusion.165 = f32[8,1024]{1,0} fusion(f32[8,4096]{1,0} %dot.176, f32[1,4096]{1,0} %get-tuple-element.27340), kind=kLoop, calls=%fused_computation.165, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %fusion.164 = f32[8,1024]{1,0} fusion(f32[8,4096]{1,0} %dot.176, f32[1,4096]{1,0} %get-tuple-element.27340), kind=kLoop, calls=%fused_computation.164, metadata={op_type="tanh" op_name="pmap(_multi_device_update_fn)/scan/while/body/tanh" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %fusion.166 = f32[8,1024]{1,0} fusion(f32[8,4096]{1,0} %dot.176, f32[1,4096]{1,0} %get-tuple-element.27340), kind=kLoop, calls=%fused_computation.166, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %fusion.163 = f32[8,1024]{1,0} fusion(f32[8,1024]{1,0} %fusion.165, f32[8,1024]{1,0} %fusion.164, f32[8,1024]{1,0} %fusion.166, f32[8,2048]{1,0} %copy.690), kind=kLoop, calls=%fused_computation.163, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %tanh.103 = f32[8,1024]{1,0} tanh(f32[8,1024]{1,0} %fusion.163), metadata={op_type="tanh" op_name="pmap(_multi_device_update_fn)/scan/while/body/tanh" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  %fusion.162 = f32[8,1024]{1,0} fusion(f32[8,4096]{1,0} %dot.176, f32[1,4096]{1,0} %get-tuple-element.27340), kind=kLoop, calls=%fused_computation.162, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %fusion.161 = f32[8,2048]{1,0} fusion(f32[8,1024]{1,0} %fusion.163, f32[8,1024]{1,0} %tanh.103, f32[8,1024]{1,0} %fusion.162), kind=kLoop, calls=%fused_computation.161, metadata={op_type="concatenate" op_name="pmap(_multi_device_update_fn)/scan/while/body/concatenate[ dimension=1 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=65}
  %get-tuple-element.27343 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %wide_param.183), index=5
  %fusion.160 = f32[64,8,1024]{2,1,0} fusion(f32[64,8,1024]{2,1,0} %get-tuple-element.27343, s32[] %fusion.168, f32[8,1024]{1,0} %tanh.103, f32[8,1024]{1,0} %fusion.162), kind=kLoop, calls=%fused_computation.160, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.27344 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %wide_param.183), index=6
  %fusion.159 = f32[64,8,1024]{2,1,0} fusion(f32[64,8,1024]{2,1,0} %get-tuple-element.27344, s32[] %fusion.168, f32[8,1024]{1,0} %fusion.166), kind=kLoop, calls=%fused_computation.159, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.27345 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %wide_param.183), index=7
  %fusion.158 = f32[64,8,1024]{2,1,0} fusion(f32[64,8,1024]{2,1,0} %get-tuple-element.27345, s32[] %fusion.168, f32[8,2048]{1,0} %copy.690), kind=kLoop, calls=%fused_computation.158, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.27346 = f32[64,8,2048]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %wide_param.183), index=8
  %fusion.157 = f32[64,8,2048]{2,1,0} fusion(f32[64,8,2048]{2,1,0} %get-tuple-element.27346, s32[] %fusion.168, f32[8,2048]{1,0} %fusion.167), kind=kLoop, calls=%fused_computation.157, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.27347 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %wide_param.183), index=9
  %fusion.156 = f32[64,8,1024]{2,1,0} fusion(f32[64,8,1024]{2,1,0} %get-tuple-element.27347, s32[] %fusion.168, f32[8,1024]{1,0} %fusion.166), kind=kLoop, calls=%fused_computation.156, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.27348 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %wide_param.183), index=10
  %fusion.155 = f32[64,8,1024]{2,1,0} fusion(f32[64,8,1024]{2,1,0} %get-tuple-element.27348, s32[] %fusion.168, f32[8,1024]{1,0} %fusion.165), kind=kLoop, calls=%fused_computation.155, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.27349 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %wide_param.183), index=11
  %fusion.154 = f32[64,8,1024]{2,1,0} fusion(f32[64,8,1024]{2,1,0} %get-tuple-element.27349, s32[] %fusion.168, f32[8,1024]{1,0} %fusion.165), kind=kLoop, calls=%fused_computation.154, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.27350 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %wide_param.183), index=12
  %fusion.153 = f32[64,8,1024]{2,1,0} fusion(f32[64,8,1024]{2,1,0} %get-tuple-element.27350, s32[] %fusion.168, f32[8,1024]{1,0} %fusion.164), kind=kLoop, calls=%fused_computation.153, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.27351 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %wide_param.183), index=13
  %fusion.152 = f32[64,8,1024]{2,1,0} fusion(f32[64,8,1024]{2,1,0} %get-tuple-element.27351, s32[] %fusion.168, f32[8,1024]{1,0} %fusion.164), kind=kLoop, calls=%fused_computation.152, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.27352 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %wide_param.183), index=14
  %fusion.151 = f32[64,8,1024]{2,1,0} fusion(f32[64,8,1024]{2,1,0} %get-tuple-element.27352, s32[] %fusion.168, f32[8,1024]{1,0} %tanh.103), kind=kLoop, calls=%fused_computation.151, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.27353 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %wide_param.183), index=15
  %fusion.150 = f32[64,8,1024]{2,1,0} fusion(f32[64,8,1024]{2,1,0} %get-tuple-element.27353, s32[] %fusion.168, f32[8,1024]{1,0} %tanh.103), kind=kLoop, calls=%fused_computation.150, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.27354 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %wide_param.183), index=16
  %fusion.149 = f32[64,8,1024]{2,1,0} fusion(f32[64,8,1024]{2,1,0} %get-tuple-element.27354, s32[] %fusion.168, f32[8,1024]{1,0} %fusion.162), kind=kLoop, calls=%fused_computation.149, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.27355 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %wide_param.183), index=17
  %fusion.148 = f32[64,8,1024]{2,1,0} fusion(f32[64,8,1024]{2,1,0} %get-tuple-element.27355, s32[] %fusion.168, f32[8,1024]{1,0} %fusion.162), kind=kLoop, calls=%fused_computation.148, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %tuple.1313 = (f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) tuple(f32[64,8,1024]{2,1,0} %get-tuple-element.27338, f32[2048,4096]{1,0} %get-tuple-element.27339, f32[1,4096]{1,0} %get-tuple-element.27340, s32[] %add.3539, f32[8,2048]{1,0} %fusion.161, /*index=5*/f32[64,8,1024]{2,1,0} %fusion.160, f32[64,8,1024]{2,1,0} %fusion.159, f32[64,8,1024]{2,1,0} %fusion.158, f32[64,8,2048]{2,1,0} %fusion.157, f32[64,8,1024]{2,1,0} %fusion.156, /*index=10*/f32[64,8,1024]{2,1,0} %fusion.155, f32[64,8,1024]{2,1,0} %fusion.154, f32[64,8,1024]{2,1,0} %fusion.153, f32[64,8,1024]{2,1,0} %fusion.152, f32[64,8,1024]{2,1,0} %fusion.151, /*index=15*/f32[64,8,1024]{2,1,0} %fusion.150, f32[64,8,1024]{2,1,0} %fusion.149, f32[64,8,1024]{2,1,0} %fusion.148)
}

%wide.cond_computation__184.10684.clone.clone.clone.clone (wide_param.184: (f32[64,8,1024], f32[2048,4096], f32[1,4096], s32[], f32[8,2048], /*index=5*/f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[64,8,2048], f32[64,8,1024], /*index=10*/f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], /*index=15*/f32[64,8,1024], f32[64,8,1024], f32[64,8,1024])) -> pred[] {
  %wide_param.184 = (f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) parameter(0)
  %get-tuple-element.25034 = s32[] get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %wide_param.184), index=3
  %constant.18995 = s32[] constant(64), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/cond/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %compare.2547 = pred[] compare(s32[] %get-tuple-element.25034, s32[] %constant.18995), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/cond/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.169 (param_0.259: f32[64,8,1024], param_1.559: s32[], param_2.587: f32[8,1024]) -> f32[64,8,1024] {
  %param_0.259 = f32[64,8,1024]{2,1,0} parameter(0)
  %constant.20599 = f32[] constant(1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %broadcast.1816 = f32[8,1024]{1,0} broadcast(f32[] %constant.20599), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %param_2.587 = f32[8,1024]{1,0} parameter(2)
  %subtract.523 = f32[8,1024]{1,0} subtract(f32[8,1024]{1,0} %broadcast.1816, f32[8,1024]{1,0} %param_2.587), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %reshape.2986 = f32[1,8,1024]{2,1,0} reshape(f32[8,1024]{1,0} %subtract.523), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_1.559 = s32[] parameter(1)
  %constant.20598 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.855 = f32[64,8,1024]{2,1,0} dynamic-update-slice(f32[64,8,1024]{2,1,0} %param_0.259, f32[1,8,1024]{2,1,0} %reshape.2986, s32[] %param_1.559, s32[] %constant.20598, s32[] %constant.20598), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.170 (param_0.260: f32[64,8,1024], param_1.561: s32[], param_2.590: f32[8,1024]) -> f32[64,8,1024] {
  %param_0.260 = f32[64,8,1024]{2,1,0} parameter(0)
  %param_2.590 = f32[8,1024]{1,0} parameter(2)
  %reshape.2987 = f32[1,8,1024]{2,1,0} reshape(f32[8,1024]{1,0} %param_2.590), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_1.561 = s32[] parameter(1)
  %constant.20600 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.856 = f32[64,8,1024]{2,1,0} dynamic-update-slice(f32[64,8,1024]{2,1,0} %param_0.260, f32[1,8,1024]{2,1,0} %reshape.2987, s32[] %param_1.561, s32[] %constant.20600, s32[] %constant.20600), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.171 (param_0.261: f32[64,8,1024], param_1.563: s32[], param_2.594: f32[8,1024]) -> f32[64,8,1024] {
  %param_0.261 = f32[64,8,1024]{2,1,0} parameter(0)
  %constant.20602 = f32[] constant(1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %broadcast.1817 = f32[8,1024]{1,0} broadcast(f32[] %constant.20602), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %param_2.594 = f32[8,1024]{1,0} parameter(2)
  %subtract.524 = f32[8,1024]{1,0} subtract(f32[8,1024]{1,0} %broadcast.1817, f32[8,1024]{1,0} %param_2.594), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  %reshape.2988 = f32[1,8,1024]{2,1,0} reshape(f32[8,1024]{1,0} %subtract.524), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_1.563 = s32[] parameter(1)
  %constant.20601 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.857 = f32[64,8,1024]{2,1,0} dynamic-update-slice(f32[64,8,1024]{2,1,0} %param_0.261, f32[1,8,1024]{2,1,0} %reshape.2988, s32[] %param_1.563, s32[] %constant.20601, s32[] %constant.20601), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.172 (param_0.262: f32[64,8,1024], param_1.565: s32[], param_2.597: f32[8,1024]) -> f32[64,8,1024] {
  %param_0.262 = f32[64,8,1024]{2,1,0} parameter(0)
  %param_2.597 = f32[8,1024]{1,0} parameter(2)
  %reshape.2989 = f32[1,8,1024]{2,1,0} reshape(f32[8,1024]{1,0} %param_2.597), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_1.565 = s32[] parameter(1)
  %constant.20603 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.858 = f32[64,8,1024]{2,1,0} dynamic-update-slice(f32[64,8,1024]{2,1,0} %param_0.262, f32[1,8,1024]{2,1,0} %reshape.2989, s32[] %param_1.565, s32[] %constant.20603, s32[] %constant.20603), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.173 (param_0.263: f32[64,8,1024], param_1.567: s32[], param_2.601: f32[8,1024]) -> f32[64,8,1024] {
  %param_0.263 = f32[64,8,1024]{2,1,0} parameter(0)
  %constant.20606 = f32[] constant(1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %broadcast.1818 = f32[8,1024]{1,0} broadcast(f32[] %constant.20606), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %param_2.601 = f32[8,1024]{1,0} parameter(2)
  %subtract.525 = f32[8,1024]{1,0} subtract(f32[8,1024]{1,0} %broadcast.1818, f32[8,1024]{1,0} %param_2.601), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %reshape.2990 = f32[1,8,1024]{2,1,0} reshape(f32[8,1024]{1,0} %subtract.525), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_1.567 = s32[] parameter(1)
  %constant.20605 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.859 = f32[64,8,1024]{2,1,0} dynamic-update-slice(f32[64,8,1024]{2,1,0} %param_0.263, f32[1,8,1024]{2,1,0} %reshape.2990, s32[] %param_1.567, s32[] %constant.20605, s32[] %constant.20605), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.174 (param_0.264: f32[64,8,1024], param_1.569: s32[], param_2.604: f32[8,1024]) -> f32[64,8,1024] {
  %param_0.264 = f32[64,8,1024]{2,1,0} parameter(0)
  %param_2.604 = f32[8,1024]{1,0} parameter(2)
  %reshape.2991 = f32[1,8,1024]{2,1,0} reshape(f32[8,1024]{1,0} %param_2.604), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_1.569 = s32[] parameter(1)
  %constant.20607 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.860 = f32[64,8,1024]{2,1,0} dynamic-update-slice(f32[64,8,1024]{2,1,0} %param_0.264, f32[1,8,1024]{2,1,0} %reshape.2991, s32[] %param_1.569, s32[] %constant.20607, s32[] %constant.20607), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.175 (param_0.265: f32[64,8,1024], param_1.571: s32[], param_2.608: f32[8,1024]) -> f32[64,8,1024] {
  %param_0.265 = f32[64,8,1024]{2,1,0} parameter(0)
  %constant.20609 = f32[] constant(1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %broadcast.1819 = f32[8,1024]{1,0} broadcast(f32[] %constant.20609), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %param_2.608 = f32[8,1024]{1,0} parameter(2)
  %subtract.526 = f32[8,1024]{1,0} subtract(f32[8,1024]{1,0} %broadcast.1819, f32[8,1024]{1,0} %param_2.608), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %reshape.2992 = f32[1,8,1024]{2,1,0} reshape(f32[8,1024]{1,0} %subtract.526), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_1.571 = s32[] parameter(1)
  %constant.20608 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.861 = f32[64,8,1024]{2,1,0} dynamic-update-slice(f32[64,8,1024]{2,1,0} %param_0.265, f32[1,8,1024]{2,1,0} %reshape.2992, s32[] %param_1.571, s32[] %constant.20608, s32[] %constant.20608), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.176 (param_0.266: f32[64,8,1024], param_1.573: s32[], param_2.611: f32[8,1024]) -> f32[64,8,1024] {
  %param_0.266 = f32[64,8,1024]{2,1,0} parameter(0)
  %param_2.611 = f32[8,1024]{1,0} parameter(2)
  %reshape.2993 = f32[1,8,1024]{2,1,0} reshape(f32[8,1024]{1,0} %param_2.611), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_1.573 = s32[] parameter(1)
  %constant.20611 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.862 = f32[64,8,1024]{2,1,0} dynamic-update-slice(f32[64,8,1024]{2,1,0} %param_0.266, f32[1,8,1024]{2,1,0} %reshape.2993, s32[] %param_1.573, s32[] %constant.20611, s32[] %constant.20611), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.177 (param_0.267: f32[64,8,1024], param_1.575: s32[], param_2.615: f32[8,1024]) -> f32[64,8,1024] {
  %param_0.267 = f32[64,8,1024]{2,1,0} parameter(0)
  %constant.20613 = f32[] constant(1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %broadcast.1820 = f32[8,1024]{1,0} broadcast(f32[] %constant.20613), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %param_2.615 = f32[8,1024]{1,0} parameter(2)
  %subtract.527 = f32[8,1024]{1,0} subtract(f32[8,1024]{1,0} %broadcast.1820, f32[8,1024]{1,0} %param_2.615), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %reshape.2994 = f32[1,8,1024]{2,1,0} reshape(f32[8,1024]{1,0} %subtract.527), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_1.575 = s32[] parameter(1)
  %constant.20612 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.863 = f32[64,8,1024]{2,1,0} dynamic-update-slice(f32[64,8,1024]{2,1,0} %param_0.267, f32[1,8,1024]{2,1,0} %reshape.2994, s32[] %param_1.575, s32[] %constant.20612, s32[] %constant.20612), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.178 (param_0.268: f32[64,8,2048], param_1.577: s32[], param_2.618: f32[8,2048]) -> f32[64,8,2048] {
  %param_0.268 = f32[64,8,2048]{2,1,0} parameter(0)
  %param_2.618 = f32[8,2048]{1,0} parameter(2)
  %reshape.2995 = f32[1,8,2048]{2,1,0} reshape(f32[8,2048]{1,0} %param_2.618), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 8, 2048) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_1.577 = s32[] parameter(1)
  %constant.20615 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.864 = f32[64,8,2048]{2,1,0} dynamic-update-slice(f32[64,8,2048]{2,1,0} %param_0.268, f32[1,8,2048]{2,1,0} %reshape.2995, s32[] %param_1.577, s32[] %constant.20615, s32[] %constant.20615), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.179 (param_0.269: f32[64,8,1024], param_1.579: s32[], param_2.622: f32[8,2048]) -> f32[64,8,1024] {
  %param_0.269 = f32[64,8,1024]{2,1,0} parameter(0)
  %param_2.622 = f32[8,2048]{1,0} parameter(2)
  %slice.1289 = f32[8,1024]{1,0} slice(f32[8,2048]{1,0} %param_2.622), slice={[0:8], [0:1024]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(8, 1024)\n                                                     start_indices=(0, 0)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=54}
  %reshape.2996 = f32[1,8,1024]{2,1,0} reshape(f32[8,1024]{1,0} %slice.1289), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_1.579 = s32[] parameter(1)
  %constant.20616 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.865 = f32[64,8,1024]{2,1,0} dynamic-update-slice(f32[64,8,1024]{2,1,0} %param_0.269, f32[1,8,1024]{2,1,0} %reshape.2996, s32[] %param_1.579, s32[] %constant.20616, s32[] %constant.20616), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.180 (param_0.270: f32[64,8,1024], param_1.581: s32[], param_2.625: f32[8,1024]) -> f32[64,8,1024] {
  %param_0.270 = f32[64,8,1024]{2,1,0} parameter(0)
  %param_2.625 = f32[8,1024]{1,0} parameter(2)
  %reshape.2997 = f32[1,8,1024]{2,1,0} reshape(f32[8,1024]{1,0} %param_2.625), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_1.581 = s32[] parameter(1)
  %constant.20618 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.866 = f32[64,8,1024]{2,1,0} dynamic-update-slice(f32[64,8,1024]{2,1,0} %param_0.270, f32[1,8,1024]{2,1,0} %reshape.2997, s32[] %param_1.581, s32[] %constant.20618, s32[] %constant.20618), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.181 (param_0.271: f32[64,8,1024], param_1.583: s32[], param_2.628: f32[8,1024], param_3.518: f32[8,1024]) -> f32[64,8,1024] {
  %param_0.271 = f32[64,8,1024]{2,1,0} parameter(0)
  %param_2.628 = f32[8,1024]{1,0} parameter(2)
  %param_3.518 = f32[8,1024]{1,0} parameter(3)
  %multiply.1392 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %param_2.628, f32[8,1024]{1,0} %param_3.518), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  %reshape.2998 = f32[1,8,1024]{2,1,0} reshape(f32[8,1024]{1,0} %multiply.1392), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_1.583 = s32[] parameter(1)
  %constant.20619 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.867 = f32[64,8,1024]{2,1,0} dynamic-update-slice(f32[64,8,1024]{2,1,0} %param_0.271, f32[1,8,1024]{2,1,0} %reshape.2998, s32[] %param_1.583, s32[] %constant.20619, s32[] %constant.20619), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.182 (param_0.272: f32[8,1024], param_1.585: f32[8,1024], param_2.629: f32[8,1024]) -> f32[8,2048] {
  %param_0.272 = f32[8,1024]{1,0} parameter(0)
  %param_1.585 = f32[8,1024]{1,0} parameter(1)
  %param_2.629 = f32[8,1024]{1,0} parameter(2)
  %multiply.1393 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %param_1.585, f32[8,1024]{1,0} %param_2.629), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  ROOT %concatenate.242 = f32[8,2048]{1,0} concatenate(f32[8,1024]{1,0} %param_0.272, f32[8,1024]{1,0} %multiply.1393), dimensions={1}, metadata={op_type="concatenate" op_name="pmap(_multi_device_update_fn)/scan/while/body/concatenate[ dimension=1 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=65}
}

%fused_computation.183 (param_0.274: f32[8,4096], param_1.592: f32[1,4096]) -> f32[8,1024] {
  %constant.20620 = f32[] constant(1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %broadcast.1822 = f32[8,1024]{1,0} broadcast(f32[] %constant.20620), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %param_0.274 = f32[8,4096]{1,0} parameter(0)
  %param_1.592 = f32[1,4096]{1,0} parameter(1)
  %reshape.2999 = f32[4096]{0} reshape(f32[1,4096]{1,0} %param_1.592), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %broadcast.1821 = f32[8,4096]{1,0} broadcast(f32[4096]{0} %reshape.2999), dimensions={1}, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %add.4025 = f32[8,4096]{1,0} add(f32[8,4096]{1,0} %param_0.274, f32[8,4096]{1,0} %broadcast.1821), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %slice.1291 = f32[8,1024]{1,0} slice(f32[8,4096]{1,0} %add.4025), slice={[0:8], [3072:4096]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(8, 4096)\n                                                     start_indices=(0, 3072)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  %negate.211 = f32[8,1024]{1,0} negate(f32[8,1024]{1,0} %slice.1291), metadata={op_type="neg" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/neg" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %exponential.183 = f32[8,1024]{1,0} exponential(f32[8,1024]{1,0} %negate.211), metadata={op_type="exp" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/exp" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %add.4024 = f32[8,1024]{1,0} add(f32[8,1024]{1,0} %broadcast.1822, f32[8,1024]{1,0} %exponential.183), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  ROOT %divide.187 = f32[8,1024]{1,0} divide(f32[8,1024]{1,0} %broadcast.1822, f32[8,1024]{1,0} %add.4024), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
}

%fused_computation.184 (param_0.276: f32[8,1024], param_1.595: f32[8,1024], param_2.636: f32[8,1024], param_3.520: f32[8,2048]) -> f32[8,1024] {
  %param_3.520 = f32[8,2048]{1,0} parameter(3)
  %slice.1292 = f32[8,1024]{1,0} slice(f32[8,2048]{1,0} %param_3.520), slice={[0:8], [0:1024]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(8, 1024)\n                                                     start_indices=(0, 0)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=54}
  %param_2.636 = f32[8,1024]{1,0} parameter(2)
  %multiply.1395 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %slice.1292, f32[8,1024]{1,0} %param_2.636), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %param_0.276 = f32[8,1024]{1,0} parameter(0)
  %param_1.595 = f32[8,1024]{1,0} parameter(1)
  %multiply.1394 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %param_0.276, f32[8,1024]{1,0} %param_1.595), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  ROOT %add.4026 = f32[8,1024]{1,0} add(f32[8,1024]{1,0} %multiply.1395, f32[8,1024]{1,0} %multiply.1394), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
}

%fused_computation.185 (param_0.279: f32[8,4096], param_1.598: f32[1,4096]) -> f32[8,1024] {
  %param_0.279 = f32[8,4096]{1,0} parameter(0)
  %param_1.598 = f32[1,4096]{1,0} parameter(1)
  %reshape.3000 = f32[4096]{0} reshape(f32[1,4096]{1,0} %param_1.598), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %broadcast.1823 = f32[8,4096]{1,0} broadcast(f32[4096]{0} %reshape.3000), dimensions={1}, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %add.4027 = f32[8,4096]{1,0} add(f32[8,4096]{1,0} %param_0.279, f32[8,4096]{1,0} %broadcast.1823), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %slice.1293 = f32[8,1024]{1,0} slice(f32[8,4096]{1,0} %add.4027), slice={[0:8], [1024:2048]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(8, 2048)\n                                                     start_indices=(0, 1024)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  ROOT %tanh.115 = f32[8,1024]{1,0} tanh(f32[8,1024]{1,0} %slice.1293), metadata={op_type="tanh" op_name="pmap(_multi_device_update_fn)/scan/while/body/tanh" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
}

%fused_computation.186 (param_0.281: f32[8,4096], param_1.605: f32[1,4096]) -> f32[8,1024] {
  %constant.20621 = f32[] constant(1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %broadcast.1825 = f32[8,1024]{1,0} broadcast(f32[] %constant.20621), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %param_0.281 = f32[8,4096]{1,0} parameter(0)
  %param_1.605 = f32[1,4096]{1,0} parameter(1)
  %reshape.3001 = f32[4096]{0} reshape(f32[1,4096]{1,0} %param_1.605), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %broadcast.1824 = f32[8,4096]{1,0} broadcast(f32[4096]{0} %reshape.3001), dimensions={1}, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %add.4031 = f32[8,4096]{1,0} add(f32[8,4096]{1,0} %param_0.281, f32[8,4096]{1,0} %broadcast.1824), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %slice.1294 = f32[8,1024]{1,0} slice(f32[8,4096]{1,0} %add.4031), slice={[0:8], [0:1024]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(8, 1024)\n                                                     start_indices=(0, 0)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  %negate.212 = f32[8,1024]{1,0} negate(f32[8,1024]{1,0} %slice.1294), metadata={op_type="neg" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/neg" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %exponential.184 = f32[8,1024]{1,0} exponential(f32[8,1024]{1,0} %negate.212), metadata={op_type="exp" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/exp" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %add.4029 = f32[8,1024]{1,0} add(f32[8,1024]{1,0} %broadcast.1825, f32[8,1024]{1,0} %exponential.184), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  ROOT %divide.188 = f32[8,1024]{1,0} divide(f32[8,1024]{1,0} %broadcast.1825, f32[8,1024]{1,0} %add.4029), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
}

%fused_computation.187 (param_0.283: f32[8,4096], param_1.612: f32[1,4096]) -> f32[8,1024] {
  %constant.20622 = f32[] constant(1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %broadcast.1827 = f32[8,1024]{1,0} broadcast(f32[] %constant.20622), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %param_0.283 = f32[8,4096]{1,0} parameter(0)
  %param_1.612 = f32[1,4096]{1,0} parameter(1)
  %reshape.3002 = f32[4096]{0} reshape(f32[1,4096]{1,0} %param_1.612), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %broadcast.1826 = f32[8,4096]{1,0} broadcast(f32[4096]{0} %reshape.3002), dimensions={1}, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %add.4034 = f32[8,4096]{1,0} add(f32[8,4096]{1,0} %param_0.283, f32[8,4096]{1,0} %broadcast.1826), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %slice.1295 = f32[8,1024]{1,0} slice(f32[8,4096]{1,0} %add.4034), slice={[0:8], [2048:3072]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(8, 3072)\n                                                     start_indices=(0, 2048)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  %negate.213 = f32[8,1024]{1,0} negate(f32[8,1024]{1,0} %slice.1295), metadata={op_type="neg" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/neg" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %exponential.185 = f32[8,1024]{1,0} exponential(f32[8,1024]{1,0} %negate.213), metadata={op_type="exp" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/exp" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %add.4033 = f32[8,1024]{1,0} add(f32[8,1024]{1,0} %broadcast.1827, f32[8,1024]{1,0} %exponential.185), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  ROOT %divide.189 = f32[8,1024]{1,0} divide(f32[8,1024]{1,0} %broadcast.1827, f32[8,1024]{1,0} %add.4033), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
}

%fused_computation.188 (param_0.285: f32[8,2048], param_1.616: f32[64,8,1024], param_2.645: s32[]) -> f32[8,2048] {
  %param_1.616 = f32[64,8,1024]{2,1,0} parameter(1)
  %param_2.645 = s32[] parameter(2)
  %constant.20624 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %dynamic-slice.785 = f32[1,8,1024]{2,1,0} dynamic-slice(f32[64,8,1024]{2,1,0} %param_1.616, s32[] %param_2.645, s32[] %constant.20624, s32[] %constant.20624), dynamic_slice_sizes={1,8,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %reshape.3003 = f32[8,1024]{1,0} reshape(f32[1,8,1024]{2,1,0} %dynamic-slice.785), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_0.285 = f32[8,2048]{1,0} parameter(0)
  %slice.1296 = f32[8,1024]{1,0} slice(f32[8,2048]{1,0} %param_0.285), slice={[0:8], [1024:2048]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(8, 2048)\n                                                     start_indices=(0, 1024)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=54}
  ROOT %concatenate.243 = f32[8,2048]{1,0} concatenate(f32[8,1024]{1,0} %reshape.3003, f32[8,1024]{1,0} %slice.1296), dimensions={1}, metadata={op_type="concatenate" op_name="pmap(_multi_device_update_fn)/scan/while/body/concatenate[ dimension=1 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
}

%fused_computation.189 (param_0.287: s32[]) -> s32[] {
  %param_0.287 = s32[] parameter(0)
  %constant.20626 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.2752 = pred[] compare(s32[] %param_0.287, s32[] %constant.20626), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant.20625 = s32[] constant(64), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.4036 = s32[] add(s32[] %param_0.287, s32[] %constant.20625), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %select.2641 = s32[] select(pred[] %compare.2752, s32[] %add.4036, s32[] %param_0.287), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%wide.body_computation__188.11312.clone.clone.clone.clone.clone (wide_param.185: (f32[64,8,1024], f32[2048,4096], f32[1,4096], s32[], f32[8,2048], /*index=5*/f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[64,8,2048], f32[64,8,1024], /*index=10*/f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], /*index=15*/f32[64,8,1024], f32[64,8,1024], f32[64,8,1024])) -> (f32[64,8,1024], f32[2048,4096], f32[1,4096], s32[], f32[8,2048], /*index=5*/f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[64,8,2048], f32[64,8,1024], /*index=10*/f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], /*index=15*/f32[64,8,1024], f32[64,8,1024], f32[64,8,1024]) {
  %wide_param.185 = (f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) parameter(0)
  %get-tuple-element.27392 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %wide_param.185), index=0
  %get-tuple-element.27393 = f32[2048,4096]{1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %wide_param.185), index=1
  %get-tuple-element.27394 = f32[1,4096]{1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %wide_param.185), index=2
  %get-tuple-element.27395 = s32[] get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %wide_param.185), index=3
  %copy.734 = s32[] copy(s32[] %get-tuple-element.27395)
  %constant.19080 = s32[] constant(1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.3562 = s32[] add(s32[] %copy.734, s32[] %constant.19080), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.27396 = f32[8,2048]{1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %wide_param.185), index=4
  %copy.735 = f32[8,2048]{1,0} copy(f32[8,2048]{1,0} %get-tuple-element.27396)
  %fusion.189 = s32[] fusion(s32[] %copy.734), kind=kLoop, calls=%fused_computation.189, metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %fusion.188 = f32[8,2048]{1,0} fusion(f32[8,2048]{1,0} %copy.735, f32[64,8,1024]{2,1,0} %get-tuple-element.27392, s32[] %fusion.189), kind=kLoop, calls=%fused_computation.188, metadata={op_type="concatenate" op_name="pmap(_multi_device_update_fn)/scan/while/body/concatenate[ dimension=1 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %dot.177 = f32[8,4096]{1,0} dot(f32[8,2048]{1,0} %fusion.188, f32[2048,4096]{1,0} %get-tuple-element.27393), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="dot_general" op_name="pmap(_multi_device_update_fn)/scan/while/body/dot_general[ dimension_numbers=(((1,), (0,)), ((), ()))\n                                                           precision=None\n                                                           preferred_element_type=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %fusion.186 = f32[8,1024]{1,0} fusion(f32[8,4096]{1,0} %dot.177, f32[1,4096]{1,0} %get-tuple-element.27394), kind=kLoop, calls=%fused_computation.186, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %fusion.185 = f32[8,1024]{1,0} fusion(f32[8,4096]{1,0} %dot.177, f32[1,4096]{1,0} %get-tuple-element.27394), kind=kLoop, calls=%fused_computation.185, metadata={op_type="tanh" op_name="pmap(_multi_device_update_fn)/scan/while/body/tanh" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %fusion.187 = f32[8,1024]{1,0} fusion(f32[8,4096]{1,0} %dot.177, f32[1,4096]{1,0} %get-tuple-element.27394), kind=kLoop, calls=%fused_computation.187, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %fusion.184 = f32[8,1024]{1,0} fusion(f32[8,1024]{1,0} %fusion.186, f32[8,1024]{1,0} %fusion.185, f32[8,1024]{1,0} %fusion.187, f32[8,2048]{1,0} %copy.735), kind=kLoop, calls=%fused_computation.184, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %tanh.105 = f32[8,1024]{1,0} tanh(f32[8,1024]{1,0} %fusion.184), metadata={op_type="tanh" op_name="pmap(_multi_device_update_fn)/scan/while/body/tanh" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  %fusion.183 = f32[8,1024]{1,0} fusion(f32[8,4096]{1,0} %dot.177, f32[1,4096]{1,0} %get-tuple-element.27394), kind=kLoop, calls=%fused_computation.183, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %fusion.182 = f32[8,2048]{1,0} fusion(f32[8,1024]{1,0} %fusion.184, f32[8,1024]{1,0} %tanh.105, f32[8,1024]{1,0} %fusion.183), kind=kLoop, calls=%fused_computation.182, metadata={op_type="concatenate" op_name="pmap(_multi_device_update_fn)/scan/while/body/concatenate[ dimension=1 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=65}
  %get-tuple-element.27397 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %wide_param.185), index=5
  %fusion.181 = f32[64,8,1024]{2,1,0} fusion(f32[64,8,1024]{2,1,0} %get-tuple-element.27397, s32[] %fusion.189, f32[8,1024]{1,0} %tanh.105, f32[8,1024]{1,0} %fusion.183), kind=kLoop, calls=%fused_computation.181, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.27398 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %wide_param.185), index=6
  %fusion.180 = f32[64,8,1024]{2,1,0} fusion(f32[64,8,1024]{2,1,0} %get-tuple-element.27398, s32[] %fusion.189, f32[8,1024]{1,0} %fusion.187), kind=kLoop, calls=%fused_computation.180, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.27399 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %wide_param.185), index=7
  %fusion.179 = f32[64,8,1024]{2,1,0} fusion(f32[64,8,1024]{2,1,0} %get-tuple-element.27399, s32[] %fusion.189, f32[8,2048]{1,0} %copy.735), kind=kLoop, calls=%fused_computation.179, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.27400 = f32[64,8,2048]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %wide_param.185), index=8
  %fusion.178 = f32[64,8,2048]{2,1,0} fusion(f32[64,8,2048]{2,1,0} %get-tuple-element.27400, s32[] %fusion.189, f32[8,2048]{1,0} %fusion.188), kind=kLoop, calls=%fused_computation.178, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.27401 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %wide_param.185), index=9
  %fusion.177 = f32[64,8,1024]{2,1,0} fusion(f32[64,8,1024]{2,1,0} %get-tuple-element.27401, s32[] %fusion.189, f32[8,1024]{1,0} %fusion.187), kind=kLoop, calls=%fused_computation.177, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.27402 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %wide_param.185), index=10
  %fusion.176 = f32[64,8,1024]{2,1,0} fusion(f32[64,8,1024]{2,1,0} %get-tuple-element.27402, s32[] %fusion.189, f32[8,1024]{1,0} %fusion.186), kind=kLoop, calls=%fused_computation.176, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.27403 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %wide_param.185), index=11
  %fusion.175 = f32[64,8,1024]{2,1,0} fusion(f32[64,8,1024]{2,1,0} %get-tuple-element.27403, s32[] %fusion.189, f32[8,1024]{1,0} %fusion.186), kind=kLoop, calls=%fused_computation.175, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.27404 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %wide_param.185), index=12
  %fusion.174 = f32[64,8,1024]{2,1,0} fusion(f32[64,8,1024]{2,1,0} %get-tuple-element.27404, s32[] %fusion.189, f32[8,1024]{1,0} %fusion.185), kind=kLoop, calls=%fused_computation.174, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.27405 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %wide_param.185), index=13
  %fusion.173 = f32[64,8,1024]{2,1,0} fusion(f32[64,8,1024]{2,1,0} %get-tuple-element.27405, s32[] %fusion.189, f32[8,1024]{1,0} %fusion.185), kind=kLoop, calls=%fused_computation.173, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.27406 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %wide_param.185), index=14
  %fusion.172 = f32[64,8,1024]{2,1,0} fusion(f32[64,8,1024]{2,1,0} %get-tuple-element.27406, s32[] %fusion.189, f32[8,1024]{1,0} %tanh.105), kind=kLoop, calls=%fused_computation.172, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.27407 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %wide_param.185), index=15
  %fusion.171 = f32[64,8,1024]{2,1,0} fusion(f32[64,8,1024]{2,1,0} %get-tuple-element.27407, s32[] %fusion.189, f32[8,1024]{1,0} %tanh.105), kind=kLoop, calls=%fused_computation.171, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.27408 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %wide_param.185), index=16
  %fusion.170 = f32[64,8,1024]{2,1,0} fusion(f32[64,8,1024]{2,1,0} %get-tuple-element.27408, s32[] %fusion.189, f32[8,1024]{1,0} %fusion.183), kind=kLoop, calls=%fused_computation.170, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.27409 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %wide_param.185), index=17
  %fusion.169 = f32[64,8,1024]{2,1,0} fusion(f32[64,8,1024]{2,1,0} %get-tuple-element.27409, s32[] %fusion.189, f32[8,1024]{1,0} %fusion.183), kind=kLoop, calls=%fused_computation.169, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %tuple.1317 = (f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) tuple(f32[64,8,1024]{2,1,0} %get-tuple-element.27392, f32[2048,4096]{1,0} %get-tuple-element.27393, f32[1,4096]{1,0} %get-tuple-element.27394, s32[] %add.3562, f32[8,2048]{1,0} %fusion.182, /*index=5*/f32[64,8,1024]{2,1,0} %fusion.181, f32[64,8,1024]{2,1,0} %fusion.180, f32[64,8,1024]{2,1,0} %fusion.179, f32[64,8,2048]{2,1,0} %fusion.178, f32[64,8,1024]{2,1,0} %fusion.177, /*index=10*/f32[64,8,1024]{2,1,0} %fusion.176, f32[64,8,1024]{2,1,0} %fusion.175, f32[64,8,1024]{2,1,0} %fusion.174, f32[64,8,1024]{2,1,0} %fusion.173, f32[64,8,1024]{2,1,0} %fusion.172, /*index=15*/f32[64,8,1024]{2,1,0} %fusion.171, f32[64,8,1024]{2,1,0} %fusion.170, f32[64,8,1024]{2,1,0} %fusion.169)
}

%wide.cond_computation__188.11733.clone.clone.clone.clone (wide_param.186: (f32[64,8,1024], f32[2048,4096], f32[1,4096], s32[], f32[8,2048], /*index=5*/f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[64,8,2048], f32[64,8,1024], /*index=10*/f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], /*index=15*/f32[64,8,1024], f32[64,8,1024], f32[64,8,1024])) -> pred[] {
  %wide_param.186 = (f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) parameter(0)
  %get-tuple-element.25144 = s32[] get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %wide_param.186), index=3
  %constant.19083 = s32[] constant(64), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/cond/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %compare.2565 = pred[] compare(s32[] %get-tuple-element.25144, s32[] %constant.19083), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/cond/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.190 (param_0.288: f32[64,8,1024], param_1.621: s32[], param_2.651: f32[8,1024]) -> f32[64,8,1024] {
  %param_0.288 = f32[64,8,1024]{2,1,0} parameter(0)
  %constant.20629 = f32[] constant(1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %broadcast.1828 = f32[8,1024]{1,0} broadcast(f32[] %constant.20629), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %param_2.651 = f32[8,1024]{1,0} parameter(2)
  %subtract.529 = f32[8,1024]{1,0} subtract(f32[8,1024]{1,0} %broadcast.1828, f32[8,1024]{1,0} %param_2.651), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %reshape.3004 = f32[1,8,1024]{2,1,0} reshape(f32[8,1024]{1,0} %subtract.529), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_1.621 = s32[] parameter(1)
  %constant.20627 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.868 = f32[64,8,1024]{2,1,0} dynamic-update-slice(f32[64,8,1024]{2,1,0} %param_0.288, f32[1,8,1024]{2,1,0} %reshape.3004, s32[] %param_1.621, s32[] %constant.20627, s32[] %constant.20627), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.191 (param_0.289: f32[64,8,1024], param_1.623: s32[], param_2.654: f32[8,1024]) -> f32[64,8,1024] {
  %param_0.289 = f32[64,8,1024]{2,1,0} parameter(0)
  %param_2.654 = f32[8,1024]{1,0} parameter(2)
  %reshape.3005 = f32[1,8,1024]{2,1,0} reshape(f32[8,1024]{1,0} %param_2.654), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_1.623 = s32[] parameter(1)
  %constant.20630 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.869 = f32[64,8,1024]{2,1,0} dynamic-update-slice(f32[64,8,1024]{2,1,0} %param_0.289, f32[1,8,1024]{2,1,0} %reshape.3005, s32[] %param_1.623, s32[] %constant.20630, s32[] %constant.20630), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.192 (param_0.290: f32[64,8,1024], param_1.625: s32[], param_2.658: f32[8,1024]) -> f32[64,8,1024] {
  %param_0.290 = f32[64,8,1024]{2,1,0} parameter(0)
  %constant.20632 = f32[] constant(1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %broadcast.1829 = f32[8,1024]{1,0} broadcast(f32[] %constant.20632), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %param_2.658 = f32[8,1024]{1,0} parameter(2)
  %subtract.530 = f32[8,1024]{1,0} subtract(f32[8,1024]{1,0} %broadcast.1829, f32[8,1024]{1,0} %param_2.658), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  %reshape.3006 = f32[1,8,1024]{2,1,0} reshape(f32[8,1024]{1,0} %subtract.530), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_1.625 = s32[] parameter(1)
  %constant.20631 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.870 = f32[64,8,1024]{2,1,0} dynamic-update-slice(f32[64,8,1024]{2,1,0} %param_0.290, f32[1,8,1024]{2,1,0} %reshape.3006, s32[] %param_1.625, s32[] %constant.20631, s32[] %constant.20631), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.193 (param_0.291: f32[64,8,1024], param_1.627: s32[], param_2.661: f32[8,1024]) -> f32[64,8,1024] {
  %param_0.291 = f32[64,8,1024]{2,1,0} parameter(0)
  %param_2.661 = f32[8,1024]{1,0} parameter(2)
  %reshape.3007 = f32[1,8,1024]{2,1,0} reshape(f32[8,1024]{1,0} %param_2.661), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_1.627 = s32[] parameter(1)
  %constant.20634 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.871 = f32[64,8,1024]{2,1,0} dynamic-update-slice(f32[64,8,1024]{2,1,0} %param_0.291, f32[1,8,1024]{2,1,0} %reshape.3007, s32[] %param_1.627, s32[] %constant.20634, s32[] %constant.20634), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.194 (param_0.292: f32[64,8,1024], param_1.629: s32[], param_2.665: f32[8,1024]) -> f32[64,8,1024] {
  %param_0.292 = f32[64,8,1024]{2,1,0} parameter(0)
  %constant.20636 = f32[] constant(1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %broadcast.1830 = f32[8,1024]{1,0} broadcast(f32[] %constant.20636), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %param_2.665 = f32[8,1024]{1,0} parameter(2)
  %subtract.531 = f32[8,1024]{1,0} subtract(f32[8,1024]{1,0} %broadcast.1830, f32[8,1024]{1,0} %param_2.665), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %reshape.3008 = f32[1,8,1024]{2,1,0} reshape(f32[8,1024]{1,0} %subtract.531), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_1.629 = s32[] parameter(1)
  %constant.20635 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.872 = f32[64,8,1024]{2,1,0} dynamic-update-slice(f32[64,8,1024]{2,1,0} %param_0.292, f32[1,8,1024]{2,1,0} %reshape.3008, s32[] %param_1.629, s32[] %constant.20635, s32[] %constant.20635), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.195 (param_0.293: f32[64,8,1024], param_1.631: s32[], param_2.668: f32[8,1024]) -> f32[64,8,1024] {
  %param_0.293 = f32[64,8,1024]{2,1,0} parameter(0)
  %param_2.668 = f32[8,1024]{1,0} parameter(2)
  %reshape.3010 = f32[1,8,1024]{2,1,0} reshape(f32[8,1024]{1,0} %param_2.668), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_1.631 = s32[] parameter(1)
  %constant.20637 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.873 = f32[64,8,1024]{2,1,0} dynamic-update-slice(f32[64,8,1024]{2,1,0} %param_0.293, f32[1,8,1024]{2,1,0} %reshape.3010, s32[] %param_1.631, s32[] %constant.20637, s32[] %constant.20637), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.196 (param_0.294: f32[64,8,1024], param_1.633: s32[], param_2.672: f32[8,1024]) -> f32[64,8,1024] {
  %param_0.294 = f32[64,8,1024]{2,1,0} parameter(0)
  %constant.20640 = f32[] constant(1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %broadcast.1831 = f32[8,1024]{1,0} broadcast(f32[] %constant.20640), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %param_2.672 = f32[8,1024]{1,0} parameter(2)
  %subtract.532 = f32[8,1024]{1,0} subtract(f32[8,1024]{1,0} %broadcast.1831, f32[8,1024]{1,0} %param_2.672), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %reshape.3012 = f32[1,8,1024]{2,1,0} reshape(f32[8,1024]{1,0} %subtract.532), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_1.633 = s32[] parameter(1)
  %constant.20638 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.874 = f32[64,8,1024]{2,1,0} dynamic-update-slice(f32[64,8,1024]{2,1,0} %param_0.294, f32[1,8,1024]{2,1,0} %reshape.3012, s32[] %param_1.633, s32[] %constant.20638, s32[] %constant.20638), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.197 (param_0.295: f32[64,8,1024], param_1.635: s32[], param_2.675: f32[8,1024]) -> f32[64,8,1024] {
  %param_0.295 = f32[64,8,1024]{2,1,0} parameter(0)
  %param_2.675 = f32[8,1024]{1,0} parameter(2)
  %reshape.3013 = f32[1,8,1024]{2,1,0} reshape(f32[8,1024]{1,0} %param_2.675), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_1.635 = s32[] parameter(1)
  %constant.20641 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.875 = f32[64,8,1024]{2,1,0} dynamic-update-slice(f32[64,8,1024]{2,1,0} %param_0.295, f32[1,8,1024]{2,1,0} %reshape.3013, s32[] %param_1.635, s32[] %constant.20641, s32[] %constant.20641), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.198 (param_0.296: f32[64,8,1024], param_1.637: s32[], param_2.679: f32[8,1024]) -> f32[64,8,1024] {
  %param_0.296 = f32[64,8,1024]{2,1,0} parameter(0)
  %constant.20643 = f32[] constant(1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %broadcast.1832 = f32[8,1024]{1,0} broadcast(f32[] %constant.20643), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %param_2.679 = f32[8,1024]{1,0} parameter(2)
  %subtract.533 = f32[8,1024]{1,0} subtract(f32[8,1024]{1,0} %broadcast.1832, f32[8,1024]{1,0} %param_2.679), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %reshape.3014 = f32[1,8,1024]{2,1,0} reshape(f32[8,1024]{1,0} %subtract.533), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_1.637 = s32[] parameter(1)
  %constant.20642 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.876 = f32[64,8,1024]{2,1,0} dynamic-update-slice(f32[64,8,1024]{2,1,0} %param_0.296, f32[1,8,1024]{2,1,0} %reshape.3014, s32[] %param_1.637, s32[] %constant.20642, s32[] %constant.20642), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.199 (param_0.297: f32[64,8,2048], param_1.639: s32[], param_2.682: f32[8,2048]) -> f32[64,8,2048] {
  %param_0.297 = f32[64,8,2048]{2,1,0} parameter(0)
  %param_2.682 = f32[8,2048]{1,0} parameter(2)
  %reshape.3015 = f32[1,8,2048]{2,1,0} reshape(f32[8,2048]{1,0} %param_2.682), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 8, 2048) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_1.639 = s32[] parameter(1)
  %constant.20644 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.877 = f32[64,8,2048]{2,1,0} dynamic-update-slice(f32[64,8,2048]{2,1,0} %param_0.297, f32[1,8,2048]{2,1,0} %reshape.3015, s32[] %param_1.639, s32[] %constant.20644, s32[] %constant.20644), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.200 (param_0.298: f32[64,8,1024], param_1.641: s32[], param_2.686: f32[8,2048]) -> f32[64,8,1024] {
  %param_0.298 = f32[64,8,1024]{2,1,0} parameter(0)
  %param_2.686 = f32[8,2048]{1,0} parameter(2)
  %slice.1297 = f32[8,1024]{1,0} slice(f32[8,2048]{1,0} %param_2.686), slice={[0:8], [0:1024]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(8, 1024)\n                                                     start_indices=(0, 0)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=54}
  %reshape.3016 = f32[1,8,1024]{2,1,0} reshape(f32[8,1024]{1,0} %slice.1297), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_1.641 = s32[] parameter(1)
  %constant.20645 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.878 = f32[64,8,1024]{2,1,0} dynamic-update-slice(f32[64,8,1024]{2,1,0} %param_0.298, f32[1,8,1024]{2,1,0} %reshape.3016, s32[] %param_1.641, s32[] %constant.20645, s32[] %constant.20645), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.201 (param_0.299: f32[64,8,1024], param_1.643: s32[], param_2.689: f32[8,1024]) -> f32[64,8,1024] {
  %param_0.299 = f32[64,8,1024]{2,1,0} parameter(0)
  %param_2.689 = f32[8,1024]{1,0} parameter(2)
  %reshape.3017 = f32[1,8,1024]{2,1,0} reshape(f32[8,1024]{1,0} %param_2.689), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_1.643 = s32[] parameter(1)
  %constant.20646 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.879 = f32[64,8,1024]{2,1,0} dynamic-update-slice(f32[64,8,1024]{2,1,0} %param_0.299, f32[1,8,1024]{2,1,0} %reshape.3017, s32[] %param_1.643, s32[] %constant.20646, s32[] %constant.20646), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.202 (param_0.300: f32[64,8,1024], param_1.645: s32[], param_2.692: f32[8,1024], param_3.564: f32[8,1024]) -> f32[64,8,1024] {
  %param_0.300 = f32[64,8,1024]{2,1,0} parameter(0)
  %param_2.692 = f32[8,1024]{1,0} parameter(2)
  %param_3.564 = f32[8,1024]{1,0} parameter(3)
  %multiply.1396 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %param_2.692, f32[8,1024]{1,0} %param_3.564), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  %reshape.3018 = f32[1,8,1024]{2,1,0} reshape(f32[8,1024]{1,0} %multiply.1396), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_1.645 = s32[] parameter(1)
  %constant.20648 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.880 = f32[64,8,1024]{2,1,0} dynamic-update-slice(f32[64,8,1024]{2,1,0} %param_0.300, f32[1,8,1024]{2,1,0} %reshape.3018, s32[] %param_1.645, s32[] %constant.20648, s32[] %constant.20648), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.203 (param_0.301: f32[8,1024], param_1.647: f32[8,1024], param_2.693: f32[8,1024]) -> f32[8,2048] {
  %param_0.301 = f32[8,1024]{1,0} parameter(0)
  %param_1.647 = f32[8,1024]{1,0} parameter(1)
  %param_2.693 = f32[8,1024]{1,0} parameter(2)
  %multiply.1397 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %param_1.647, f32[8,1024]{1,0} %param_2.693), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  ROOT %concatenate.244 = f32[8,2048]{1,0} concatenate(f32[8,1024]{1,0} %param_0.301, f32[8,1024]{1,0} %multiply.1397), dimensions={1}, metadata={op_type="concatenate" op_name="pmap(_multi_device_update_fn)/scan/while/body/concatenate[ dimension=1 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=65}
}

%fused_computation.204 (param_0.303: f32[8,4096], param_1.654: f32[1,4096]) -> f32[8,1024] {
  %constant.20649 = f32[] constant(1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %broadcast.1834 = f32[8,1024]{1,0} broadcast(f32[] %constant.20649), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %param_0.303 = f32[8,4096]{1,0} parameter(0)
  %param_1.654 = f32[1,4096]{1,0} parameter(1)
  %reshape.3019 = f32[4096]{0} reshape(f32[1,4096]{1,0} %param_1.654), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %broadcast.1833 = f32[8,4096]{1,0} broadcast(f32[4096]{0} %reshape.3019), dimensions={1}, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %add.4039 = f32[8,4096]{1,0} add(f32[8,4096]{1,0} %param_0.303, f32[8,4096]{1,0} %broadcast.1833), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %slice.1298 = f32[8,1024]{1,0} slice(f32[8,4096]{1,0} %add.4039), slice={[0:8], [3072:4096]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(8, 4096)\n                                                     start_indices=(0, 3072)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  %negate.214 = f32[8,1024]{1,0} negate(f32[8,1024]{1,0} %slice.1298), metadata={op_type="neg" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/neg" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %exponential.186 = f32[8,1024]{1,0} exponential(f32[8,1024]{1,0} %negate.214), metadata={op_type="exp" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/exp" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %add.4038 = f32[8,1024]{1,0} add(f32[8,1024]{1,0} %broadcast.1834, f32[8,1024]{1,0} %exponential.186), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  ROOT %divide.190 = f32[8,1024]{1,0} divide(f32[8,1024]{1,0} %broadcast.1834, f32[8,1024]{1,0} %add.4038), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
}

%fused_computation.205 (param_0.305: f32[8,1024], param_1.657: f32[8,1024], param_2.700: f32[8,1024], param_3.566: f32[8,2048]) -> f32[8,1024] {
  %param_3.566 = f32[8,2048]{1,0} parameter(3)
  %slice.1299 = f32[8,1024]{1,0} slice(f32[8,2048]{1,0} %param_3.566), slice={[0:8], [0:1024]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(8, 1024)\n                                                     start_indices=(0, 0)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=54}
  %param_2.700 = f32[8,1024]{1,0} parameter(2)
  %multiply.1399 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %slice.1299, f32[8,1024]{1,0} %param_2.700), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %param_0.305 = f32[8,1024]{1,0} parameter(0)
  %param_1.657 = f32[8,1024]{1,0} parameter(1)
  %multiply.1398 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %param_0.305, f32[8,1024]{1,0} %param_1.657), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  ROOT %add.4040 = f32[8,1024]{1,0} add(f32[8,1024]{1,0} %multiply.1399, f32[8,1024]{1,0} %multiply.1398), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
}

%fused_computation.206 (param_0.308: f32[8,4096], param_1.660: f32[1,4096]) -> f32[8,1024] {
  %param_0.308 = f32[8,4096]{1,0} parameter(0)
  %param_1.660 = f32[1,4096]{1,0} parameter(1)
  %reshape.3020 = f32[4096]{0} reshape(f32[1,4096]{1,0} %param_1.660), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %broadcast.1835 = f32[8,4096]{1,0} broadcast(f32[4096]{0} %reshape.3020), dimensions={1}, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %add.4041 = f32[8,4096]{1,0} add(f32[8,4096]{1,0} %param_0.308, f32[8,4096]{1,0} %broadcast.1835), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %slice.1301 = f32[8,1024]{1,0} slice(f32[8,4096]{1,0} %add.4041), slice={[0:8], [1024:2048]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(8, 2048)\n                                                     start_indices=(0, 1024)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  ROOT %tanh.116 = f32[8,1024]{1,0} tanh(f32[8,1024]{1,0} %slice.1301), metadata={op_type="tanh" op_name="pmap(_multi_device_update_fn)/scan/while/body/tanh" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
}

%fused_computation.207 (param_0.310: f32[8,4096], param_1.667: f32[1,4096]) -> f32[8,1024] {
  %constant.20650 = f32[] constant(1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %broadcast.1837 = f32[8,1024]{1,0} broadcast(f32[] %constant.20650), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %param_0.310 = f32[8,4096]{1,0} parameter(0)
  %param_1.667 = f32[1,4096]{1,0} parameter(1)
  %reshape.3021 = f32[4096]{0} reshape(f32[1,4096]{1,0} %param_1.667), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %broadcast.1836 = f32[8,4096]{1,0} broadcast(f32[4096]{0} %reshape.3021), dimensions={1}, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %add.4043 = f32[8,4096]{1,0} add(f32[8,4096]{1,0} %param_0.310, f32[8,4096]{1,0} %broadcast.1836), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %slice.1303 = f32[8,1024]{1,0} slice(f32[8,4096]{1,0} %add.4043), slice={[0:8], [0:1024]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(8, 1024)\n                                                     start_indices=(0, 0)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  %negate.215 = f32[8,1024]{1,0} negate(f32[8,1024]{1,0} %slice.1303), metadata={op_type="neg" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/neg" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %exponential.187 = f32[8,1024]{1,0} exponential(f32[8,1024]{1,0} %negate.215), metadata={op_type="exp" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/exp" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %add.4042 = f32[8,1024]{1,0} add(f32[8,1024]{1,0} %broadcast.1837, f32[8,1024]{1,0} %exponential.187), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  ROOT %divide.191 = f32[8,1024]{1,0} divide(f32[8,1024]{1,0} %broadcast.1837, f32[8,1024]{1,0} %add.4042), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
}

%fused_computation.208 (param_0.312: f32[8,4096], param_1.674: f32[1,4096]) -> f32[8,1024] {
  %constant.20651 = f32[] constant(1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %broadcast.1839 = f32[8,1024]{1,0} broadcast(f32[] %constant.20651), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %param_0.312 = f32[8,4096]{1,0} parameter(0)
  %param_1.674 = f32[1,4096]{1,0} parameter(1)
  %reshape.3022 = f32[4096]{0} reshape(f32[1,4096]{1,0} %param_1.674), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %broadcast.1838 = f32[8,4096]{1,0} broadcast(f32[4096]{0} %reshape.3022), dimensions={1}, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %add.4045 = f32[8,4096]{1,0} add(f32[8,4096]{1,0} %param_0.312, f32[8,4096]{1,0} %broadcast.1838), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %slice.1304 = f32[8,1024]{1,0} slice(f32[8,4096]{1,0} %add.4045), slice={[0:8], [2048:3072]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(8, 3072)\n                                                     start_indices=(0, 2048)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  %negate.216 = f32[8,1024]{1,0} negate(f32[8,1024]{1,0} %slice.1304), metadata={op_type="neg" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/neg" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %exponential.188 = f32[8,1024]{1,0} exponential(f32[8,1024]{1,0} %negate.216), metadata={op_type="exp" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/exp" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %add.4044 = f32[8,1024]{1,0} add(f32[8,1024]{1,0} %broadcast.1839, f32[8,1024]{1,0} %exponential.188), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  ROOT %divide.192 = f32[8,1024]{1,0} divide(f32[8,1024]{1,0} %broadcast.1839, f32[8,1024]{1,0} %add.4044), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
}

%fused_computation.209 (param_0.314: f32[8,2048], param_1.678: f32[64,8,1024], param_2.709: s32[]) -> f32[8,2048] {
  %param_1.678 = f32[64,8,1024]{2,1,0} parameter(1)
  %param_2.709 = s32[] parameter(2)
  %constant.20652 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %dynamic-slice.786 = f32[1,8,1024]{2,1,0} dynamic-slice(f32[64,8,1024]{2,1,0} %param_1.678, s32[] %param_2.709, s32[] %constant.20652, s32[] %constant.20652), dynamic_slice_sizes={1,8,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %reshape.3023 = f32[8,1024]{1,0} reshape(f32[1,8,1024]{2,1,0} %dynamic-slice.786), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_0.314 = f32[8,2048]{1,0} parameter(0)
  %slice.1305 = f32[8,1024]{1,0} slice(f32[8,2048]{1,0} %param_0.314), slice={[0:8], [1024:2048]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(8, 2048)\n                                                     start_indices=(0, 1024)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=54}
  ROOT %concatenate.245 = f32[8,2048]{1,0} concatenate(f32[8,1024]{1,0} %reshape.3023, f32[8,1024]{1,0} %slice.1305), dimensions={1}, metadata={op_type="concatenate" op_name="pmap(_multi_device_update_fn)/scan/while/body/concatenate[ dimension=1 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
}

%fused_computation.210 (param_0.316: s32[]) -> s32[] {
  %param_0.316 = s32[] parameter(0)
  %constant.20655 = s32[] constant(0), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.2753 = pred[] compare(s32[] %param_0.316, s32[] %constant.20655), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant.20654 = s32[] constant(64), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.4046 = s32[] add(s32[] %param_0.316, s32[] %constant.20654), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %select.2642 = s32[] select(pred[] %compare.2753, s32[] %add.4046, s32[] %param_0.316), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%wide.body_computation__192.12361.clone.clone.clone.clone.clone (wide_param.187: (f32[64,8,1024], f32[2048,4096], f32[1,4096], s32[], f32[8,2048], /*index=5*/f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[64,8,2048], f32[64,8,1024], /*index=10*/f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], /*index=15*/f32[64,8,1024], f32[64,8,1024], f32[64,8,1024])) -> (f32[64,8,1024], f32[2048,4096], f32[1,4096], s32[], f32[8,2048], /*index=5*/f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[64,8,2048], f32[64,8,1024], /*index=10*/f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], /*index=15*/f32[64,8,1024], f32[64,8,1024], f32[64,8,1024]) {
  %wide_param.187 = (f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) parameter(0)
  %get-tuple-element.27446 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %wide_param.187), index=0
  %get-tuple-element.27447 = f32[2048,4096]{1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %wide_param.187), index=1
  %get-tuple-element.27448 = f32[1,4096]{1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %wide_param.187), index=2
  %get-tuple-element.27449 = s32[] get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %wide_param.187), index=3
  %copy.779 = s32[] copy(s32[] %get-tuple-element.27449)
  %constant.19165 = s32[] constant(1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.3583 = s32[] add(s32[] %copy.779, s32[] %constant.19165), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.27450 = f32[8,2048]{1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %wide_param.187), index=4
  %copy.780 = f32[8,2048]{1,0} copy(f32[8,2048]{1,0} %get-tuple-element.27450)
  %fusion.210 = s32[] fusion(s32[] %copy.779), kind=kLoop, calls=%fused_computation.210, metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %fusion.209 = f32[8,2048]{1,0} fusion(f32[8,2048]{1,0} %copy.780, f32[64,8,1024]{2,1,0} %get-tuple-element.27446, s32[] %fusion.210), kind=kLoop, calls=%fused_computation.209, metadata={op_type="concatenate" op_name="pmap(_multi_device_update_fn)/scan/while/body/concatenate[ dimension=1 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %dot.178 = f32[8,4096]{1,0} dot(f32[8,2048]{1,0} %fusion.209, f32[2048,4096]{1,0} %get-tuple-element.27447), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="dot_general" op_name="pmap(_multi_device_update_fn)/scan/while/body/dot_general[ dimension_numbers=(((1,), (0,)), ((), ()))\n                                                           precision=None\n                                                           preferred_element_type=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %fusion.207 = f32[8,1024]{1,0} fusion(f32[8,4096]{1,0} %dot.178, f32[1,4096]{1,0} %get-tuple-element.27448), kind=kLoop, calls=%fused_computation.207, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %fusion.206 = f32[8,1024]{1,0} fusion(f32[8,4096]{1,0} %dot.178, f32[1,4096]{1,0} %get-tuple-element.27448), kind=kLoop, calls=%fused_computation.206, metadata={op_type="tanh" op_name="pmap(_multi_device_update_fn)/scan/while/body/tanh" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %fusion.208 = f32[8,1024]{1,0} fusion(f32[8,4096]{1,0} %dot.178, f32[1,4096]{1,0} %get-tuple-element.27448), kind=kLoop, calls=%fused_computation.208, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %fusion.205 = f32[8,1024]{1,0} fusion(f32[8,1024]{1,0} %fusion.207, f32[8,1024]{1,0} %fusion.206, f32[8,1024]{1,0} %fusion.208, f32[8,2048]{1,0} %copy.780), kind=kLoop, calls=%fused_computation.205, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %tanh.107 = f32[8,1024]{1,0} tanh(f32[8,1024]{1,0} %fusion.205), metadata={op_type="tanh" op_name="pmap(_multi_device_update_fn)/scan/while/body/tanh" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  %fusion.204 = f32[8,1024]{1,0} fusion(f32[8,4096]{1,0} %dot.178, f32[1,4096]{1,0} %get-tuple-element.27448), kind=kLoop, calls=%fused_computation.204, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/scan/while/body/custom_jvp_call_jaxpr/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %fusion.203 = f32[8,2048]{1,0} fusion(f32[8,1024]{1,0} %fusion.205, f32[8,1024]{1,0} %tanh.107, f32[8,1024]{1,0} %fusion.204), kind=kLoop, calls=%fused_computation.203, metadata={op_type="concatenate" op_name="pmap(_multi_device_update_fn)/scan/while/body/concatenate[ dimension=1 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=65}
  %get-tuple-element.27451 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %wide_param.187), index=5
  %fusion.202 = f32[64,8,1024]{2,1,0} fusion(f32[64,8,1024]{2,1,0} %get-tuple-element.27451, s32[] %fusion.210, f32[8,1024]{1,0} %tanh.107, f32[8,1024]{1,0} %fusion.204), kind=kLoop, calls=%fused_computation.202, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.27452 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %wide_param.187), index=6
  %fusion.201 = f32[64,8,1024]{2,1,0} fusion(f32[64,8,1024]{2,1,0} %get-tuple-element.27452, s32[] %fusion.210, f32[8,1024]{1,0} %fusion.208), kind=kLoop, calls=%fused_computation.201, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.27453 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %wide_param.187), index=7
  %fusion.200 = f32[64,8,1024]{2,1,0} fusion(f32[64,8,1024]{2,1,0} %get-tuple-element.27453, s32[] %fusion.210, f32[8,2048]{1,0} %copy.780), kind=kLoop, calls=%fused_computation.200, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.27454 = f32[64,8,2048]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %wide_param.187), index=8
  %fusion.199 = f32[64,8,2048]{2,1,0} fusion(f32[64,8,2048]{2,1,0} %get-tuple-element.27454, s32[] %fusion.210, f32[8,2048]{1,0} %fusion.209), kind=kLoop, calls=%fused_computation.199, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.27455 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %wide_param.187), index=9
  %fusion.198 = f32[64,8,1024]{2,1,0} fusion(f32[64,8,1024]{2,1,0} %get-tuple-element.27455, s32[] %fusion.210, f32[8,1024]{1,0} %fusion.208), kind=kLoop, calls=%fused_computation.198, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.27456 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %wide_param.187), index=10
  %fusion.197 = f32[64,8,1024]{2,1,0} fusion(f32[64,8,1024]{2,1,0} %get-tuple-element.27456, s32[] %fusion.210, f32[8,1024]{1,0} %fusion.207), kind=kLoop, calls=%fused_computation.197, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.27457 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %wide_param.187), index=11
  %fusion.196 = f32[64,8,1024]{2,1,0} fusion(f32[64,8,1024]{2,1,0} %get-tuple-element.27457, s32[] %fusion.210, f32[8,1024]{1,0} %fusion.207), kind=kLoop, calls=%fused_computation.196, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.27458 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %wide_param.187), index=12
  %fusion.195 = f32[64,8,1024]{2,1,0} fusion(f32[64,8,1024]{2,1,0} %get-tuple-element.27458, s32[] %fusion.210, f32[8,1024]{1,0} %fusion.206), kind=kLoop, calls=%fused_computation.195, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.27459 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %wide_param.187), index=13
  %fusion.194 = f32[64,8,1024]{2,1,0} fusion(f32[64,8,1024]{2,1,0} %get-tuple-element.27459, s32[] %fusion.210, f32[8,1024]{1,0} %fusion.206), kind=kLoop, calls=%fused_computation.194, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.27460 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %wide_param.187), index=14
  %fusion.193 = f32[64,8,1024]{2,1,0} fusion(f32[64,8,1024]{2,1,0} %get-tuple-element.27460, s32[] %fusion.210, f32[8,1024]{1,0} %tanh.107), kind=kLoop, calls=%fused_computation.193, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.27461 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %wide_param.187), index=15
  %fusion.192 = f32[64,8,1024]{2,1,0} fusion(f32[64,8,1024]{2,1,0} %get-tuple-element.27461, s32[] %fusion.210, f32[8,1024]{1,0} %tanh.107), kind=kLoop, calls=%fused_computation.192, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.27462 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %wide_param.187), index=16
  %fusion.191 = f32[64,8,1024]{2,1,0} fusion(f32[64,8,1024]{2,1,0} %get-tuple-element.27462, s32[] %fusion.210, f32[8,1024]{1,0} %fusion.204), kind=kLoop, calls=%fused_computation.191, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.27463 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %wide_param.187), index=17
  %fusion.190 = f32[64,8,1024]{2,1,0} fusion(f32[64,8,1024]{2,1,0} %get-tuple-element.27463, s32[] %fusion.210, f32[8,1024]{1,0} %fusion.204), kind=kLoop, calls=%fused_computation.190, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %tuple.1320 = (f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) tuple(f32[64,8,1024]{2,1,0} %get-tuple-element.27446, f32[2048,4096]{1,0} %get-tuple-element.27447, f32[1,4096]{1,0} %get-tuple-element.27448, s32[] %add.3583, f32[8,2048]{1,0} %fusion.203, /*index=5*/f32[64,8,1024]{2,1,0} %fusion.202, f32[64,8,1024]{2,1,0} %fusion.201, f32[64,8,1024]{2,1,0} %fusion.200, f32[64,8,2048]{2,1,0} %fusion.199, f32[64,8,1024]{2,1,0} %fusion.198, /*index=10*/f32[64,8,1024]{2,1,0} %fusion.197, f32[64,8,1024]{2,1,0} %fusion.196, f32[64,8,1024]{2,1,0} %fusion.195, f32[64,8,1024]{2,1,0} %fusion.194, f32[64,8,1024]{2,1,0} %fusion.193, /*index=15*/f32[64,8,1024]{2,1,0} %fusion.192, f32[64,8,1024]{2,1,0} %fusion.191, f32[64,8,1024]{2,1,0} %fusion.190)
}

%wide.cond_computation__192.12782.clone.clone.clone.clone (wide_param.188: (f32[64,8,1024], f32[2048,4096], f32[1,4096], s32[], f32[8,2048], /*index=5*/f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[64,8,2048], f32[64,8,1024], /*index=10*/f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], /*index=15*/f32[64,8,1024], f32[64,8,1024], f32[64,8,1024])) -> pred[] {
  %wide_param.188 = (f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) parameter(0)
  %get-tuple-element.25254 = s32[] get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %wide_param.188), index=3
  %constant.19169 = s32[] constant(64), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/cond/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %compare.2582 = pred[] compare(s32[] %get-tuple-element.25254, s32[] %constant.19169), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/cond/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%primitive_computation_add__1.13294 (parameter.13295: f32[], parameter.13296: f32[]) -> f32[] {
  %parameter.13295 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.13296 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.13297 = f32[] add(f32[] %parameter.13295, f32[] %parameter.13296), metadata={op_type="add" op_name="add"}
}

%fused_computation.211 (param_0.317: f32[64,8,1024], param_1.683: s32[], param_2.714: f32[8,2048]) -> f32[64,8,1024] {
  %param_0.317 = f32[64,8,1024]{2,1,0} parameter(0)
  %param_2.714 = f32[8,2048]{1,0} parameter(2)
  %slice.1306 = f32[8,1024]{1,0} slice(f32[8,2048]{1,0} %param_2.714), slice={[0:8], [0:1024]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(8, 1024)\n                                                     start_indices=(0, 0)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %reshape.3024 = f32[1,8,1024]{2,1,0} reshape(f32[8,1024]{1,0} %slice.1306), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_1.683 = s32[] parameter(1)
  %constant.20656 = s32[] constant(0), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.881 = f32[64,8,1024]{2,1,0} dynamic-update-slice(f32[64,8,1024]{2,1,0} %param_0.317, f32[1,8,1024]{2,1,0} %reshape.3024, s32[] %param_1.683, s32[] %constant.20656, s32[] %constant.20656), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.212 (param_0.320: f32[8,2048], param_1.689: f32[64,8,1024], param_2.720: s32[], param_3.578: f32[64,8,1024], param_4.304: f32[8,2048], param_5.268: f32[64,8,1024], param_6.178: f32[64,8,1024], param_7.97: f32[64,8,1024]) -> f32[8,2048] {
  %param_0.320 = f32[8,2048]{1,0} parameter(0)
  %slice.1307 = f32[8,1024]{1,0} slice(f32[8,2048]{1,0} %param_0.320), slice={[0:8], [1024:2048]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(8, 2048)\n                                                     start_indices=(0, 1024)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %constant.20657 = f32[] constant(0), metadata={op_type="pad" op_name="pmap(_multi_device_update_fn)/scan/while/body/pad[ padding_config=((0, 0, 0), (2048, 1024, 0)) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  %pad.339 = f32[8,2048]{1,0} pad(f32[8,1024]{1,0} %slice.1307, f32[] %constant.20657), padding=0_0x1024_0, metadata={op_type="pad" op_name="pmap(_multi_device_update_fn)/scan/while/body/pad[ padding_config=((0, 0, 0), (1024, 0, 0)) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=54}
  %param_4.304 = f32[8,2048]{1,0} parameter(4)
  %slice.1308 = f32[8,1024]{1,0} slice(f32[8,2048]{1,0} %param_4.304), slice={[0:8], [0:1024]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(8, 1024)\n                                                     start_indices=(0, 0)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=65}
  %param_6.178 = f32[64,8,1024]{2,1,0} parameter(6)
  %param_2.720 = s32[] parameter(2)
  %constant.20658 = s32[] constant(0), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %dynamic-slice.790 = f32[1,8,1024]{2,1,0} dynamic-slice(f32[64,8,1024]{2,1,0} %param_6.178, s32[] %param_2.720, s32[] %constant.20658, s32[] %constant.20658), dynamic_slice_sizes={1,8,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %reshape.3028 = f32[8,1024]{1,0} reshape(f32[1,8,1024]{2,1,0} %dynamic-slice.790), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %slice.1309 = f32[8,1024]{1,0} slice(f32[8,2048]{1,0} %param_4.304), slice={[0:8], [1024:2048]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(8, 2048)\n                                                     start_indices=(0, 1024)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=65}
  %add.4050 = f32[8,1024]{1,0} add(f32[8,1024]{1,0} %reshape.3028, f32[8,1024]{1,0} %slice.1309), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %param_5.268 = f32[64,8,1024]{2,1,0} parameter(5)
  %dynamic-slice.789 = f32[1,8,1024]{2,1,0} dynamic-slice(f32[64,8,1024]{2,1,0} %param_5.268, s32[] %param_2.720, s32[] %constant.20658, s32[] %constant.20658), dynamic_slice_sizes={1,8,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %reshape.3027 = f32[8,1024]{1,0} reshape(f32[1,8,1024]{2,1,0} %dynamic-slice.789), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.1403 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %add.4050, f32[8,1024]{1,0} %reshape.3027), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  %param_3.578 = f32[64,8,1024]{2,1,0} parameter(3)
  %dynamic-slice.788 = f32[1,8,1024]{2,1,0} dynamic-slice(f32[64,8,1024]{2,1,0} %param_3.578, s32[] %param_2.720, s32[] %constant.20658, s32[] %constant.20658), dynamic_slice_sizes={1,8,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %reshape.3026 = f32[8,1024]{1,0} reshape(f32[1,8,1024]{2,1,0} %dynamic-slice.788), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.1402 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %multiply.1403, f32[8,1024]{1,0} %reshape.3026), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  %add.4049 = f32[8,1024]{1,0} add(f32[8,1024]{1,0} %slice.1308, f32[8,1024]{1,0} %multiply.1402), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %param_7.97 = f32[64,8,1024]{2,1,0} parameter(7)
  %dynamic-slice.791 = f32[1,8,1024]{2,1,0} dynamic-slice(f32[64,8,1024]{2,1,0} %param_7.97, s32[] %param_2.720, s32[] %constant.20658, s32[] %constant.20658), dynamic_slice_sizes={1,8,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %reshape.3029 = f32[8,1024]{1,0} reshape(f32[1,8,1024]{2,1,0} %dynamic-slice.791), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.1401 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %multiply.1402, f32[8,1024]{1,0} %reshape.3029), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  %add.4048 = f32[8,1024]{1,0} add(f32[8,1024]{1,0} %add.4049, f32[8,1024]{1,0} %multiply.1401), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %param_1.689 = f32[64,8,1024]{2,1,0} parameter(1)
  %dynamic-slice.787 = f32[1,8,1024]{2,1,0} dynamic-slice(f32[64,8,1024]{2,1,0} %param_1.689, s32[] %param_2.720, s32[] %constant.20658, s32[] %constant.20658), dynamic_slice_sizes={1,8,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %reshape.3025 = f32[8,1024]{1,0} reshape(f32[1,8,1024]{2,1,0} %dynamic-slice.787), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.1400 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %add.4048, f32[8,1024]{1,0} %reshape.3025), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %pad.338 = f32[8,2048]{1,0} pad(f32[8,1024]{1,0} %multiply.1400, f32[] %constant.20657), padding=0_0x0_1024, metadata={op_type="pad" op_name="pmap(_multi_device_update_fn)/scan/while/body/pad[ padding_config=((0, 0, 0), (0, 1024, 0)) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=54}
  ROOT %add.4047 = f32[8,2048]{1,0} add(f32[8,2048]{1,0} %pad.339, f32[8,2048]{1,0} %pad.338), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
}

%fused_computation.213 (param_0.323: f32[64,8,1024], param_1.694: s32[], param_2.725: s32[], param_3.584: f32[64,8,1024], param_4.308: f32[64,8,1024], param_5.274: f32[64,8,1024], param_6.187: f32[64,8,1024], param_7.106: f32[64,8,1024], param_8.22: f32[64,8,1024], param_9.12: f32[8,2048], param_10.12: f32[64,8,1024], param_11.15: f32[64,8,1024], param_12.14: f32[64,8,1024], param_13.11: f32[64,8,1024], param_14.17: f32[64,8,1024]) -> f32[8,4096] {
  %param_14.17 = f32[64,8,1024]{2,1,0} parameter(14)
  %param_1.694 = s32[] parameter(1)
  %param_2.725 = s32[] parameter(2)
  %dynamic-slice.803 = f32[1,8,1024]{2,1,0} dynamic-slice(f32[64,8,1024]{2,1,0} %param_14.17, s32[] %param_1.694, s32[] %param_2.725, s32[] %param_2.725), dynamic_slice_sizes={1,8,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %reshape.3041 = f32[8,1024]{1,0} reshape(f32[1,8,1024]{2,1,0} %dynamic-slice.803), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_13.11 = f32[64,8,1024]{2,1,0} parameter(13)
  %dynamic-slice.802 = f32[1,8,1024]{2,1,0} dynamic-slice(f32[64,8,1024]{2,1,0} %param_13.11, s32[] %param_1.694, s32[] %param_2.725, s32[] %param_2.725), dynamic_slice_sizes={1,8,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %reshape.3040 = f32[8,1024]{1,0} reshape(f32[1,8,1024]{2,1,0} %dynamic-slice.802), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_9.12 = f32[8,2048]{1,0} parameter(9)
  %slice.1311 = f32[8,1024]{1,0} slice(f32[8,2048]{1,0} %param_9.12), slice={[0:8], [1024:2048]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(8, 2048)\n                                                     start_indices=(0, 1024)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=65}
  %add.4057 = f32[8,1024]{1,0} add(f32[8,1024]{1,0} %reshape.3040, f32[8,1024]{1,0} %slice.1311), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %multiply.1418 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %reshape.3041, f32[8,1024]{1,0} %add.4057), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  %param_12.14 = f32[64,8,1024]{2,1,0} parameter(12)
  %dynamic-slice.801 = f32[1,8,1024]{2,1,0} dynamic-slice(f32[64,8,1024]{2,1,0} %param_12.14, s32[] %param_1.694, s32[] %param_2.725, s32[] %param_2.725), dynamic_slice_sizes={1,8,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %reshape.3039 = f32[8,1024]{1,0} reshape(f32[1,8,1024]{2,1,0} %dynamic-slice.801), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.1417 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %multiply.1418, f32[8,1024]{1,0} %reshape.3039), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %param_11.15 = f32[64,8,1024]{2,1,0} parameter(11)
  %dynamic-slice.800 = f32[1,8,1024]{2,1,0} dynamic-slice(f32[64,8,1024]{2,1,0} %param_11.15, s32[] %param_1.694, s32[] %param_2.725, s32[] %param_2.725), dynamic_slice_sizes={1,8,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %reshape.3038 = f32[8,1024]{1,0} reshape(f32[1,8,1024]{2,1,0} %dynamic-slice.800), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.1416 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %multiply.1417, f32[8,1024]{1,0} %reshape.3038), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %constant.20660 = f32[] constant(0), metadata={op_type="pad" op_name="pmap(_multi_device_update_fn)/scan/while/body/pad[ padding_config=((0, 0, 0), (2048, 1024, 0)) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  %pad.343 = f32[8,4096]{1,0} pad(f32[8,1024]{1,0} %multiply.1416, f32[] %constant.20660), padding=0_0x3072_0, metadata={op_type="pad" op_name="pmap(_multi_device_update_fn)/scan/while/body/pad[ padding_config=((0, 0, 0), (3072, 0, 0)) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  %param_10.12 = f32[64,8,1024]{2,1,0} parameter(10)
  %dynamic-slice.799 = f32[1,8,1024]{2,1,0} dynamic-slice(f32[64,8,1024]{2,1,0} %param_10.12, s32[] %param_1.694, s32[] %param_2.725, s32[] %param_2.725), dynamic_slice_sizes={1,8,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %reshape.3037 = f32[8,1024]{1,0} reshape(f32[1,8,1024]{2,1,0} %dynamic-slice.799), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %slice.1310 = f32[8,1024]{1,0} slice(f32[8,2048]{1,0} %param_9.12), slice={[0:8], [0:1024]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(8, 1024)\n                                                     start_indices=(0, 0)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=65}
  %multiply.1415 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %add.4057, f32[8,1024]{1,0} %reshape.3038), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  %param_8.22 = f32[64,8,1024]{2,1,0} parameter(8)
  %dynamic-slice.798 = f32[1,8,1024]{2,1,0} dynamic-slice(f32[64,8,1024]{2,1,0} %param_8.22, s32[] %param_1.694, s32[] %param_2.725, s32[] %param_2.725), dynamic_slice_sizes={1,8,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %reshape.3036 = f32[8,1024]{1,0} reshape(f32[1,8,1024]{2,1,0} %dynamic-slice.798), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.1414 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %multiply.1415, f32[8,1024]{1,0} %reshape.3036), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  %add.4056 = f32[8,1024]{1,0} add(f32[8,1024]{1,0} %slice.1310, f32[8,1024]{1,0} %multiply.1414), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %multiply.1413 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %multiply.1414, f32[8,1024]{1,0} %reshape.3041), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  %add.4055 = f32[8,1024]{1,0} add(f32[8,1024]{1,0} %add.4056, f32[8,1024]{1,0} %multiply.1413), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %multiply.1412 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %reshape.3037, f32[8,1024]{1,0} %add.4055), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %param_7.106 = f32[64,8,1024]{2,1,0} parameter(7)
  %dynamic-slice.797 = f32[1,8,1024]{2,1,0} dynamic-slice(f32[64,8,1024]{2,1,0} %param_7.106, s32[] %param_1.694, s32[] %param_2.725, s32[] %param_2.725), dynamic_slice_sizes={1,8,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %reshape.3035 = f32[8,1024]{1,0} reshape(f32[1,8,1024]{2,1,0} %dynamic-slice.797), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.1411 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %multiply.1412, f32[8,1024]{1,0} %reshape.3035), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %param_6.187 = f32[64,8,1024]{2,1,0} parameter(6)
  %dynamic-slice.796 = f32[1,8,1024]{2,1,0} dynamic-slice(f32[64,8,1024]{2,1,0} %param_6.187, s32[] %param_1.694, s32[] %param_2.725, s32[] %param_2.725), dynamic_slice_sizes={1,8,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %reshape.3034 = f32[8,1024]{1,0} reshape(f32[1,8,1024]{2,1,0} %dynamic-slice.796), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.1410 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %multiply.1411, f32[8,1024]{1,0} %reshape.3034), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %add.4054 = f32[8,1024]{1,0} add(f32[8,1024]{1,0} %multiply.1411, f32[8,1024]{1,0} %multiply.1410), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %pad.342 = f32[8,4096]{1,0} pad(f32[8,1024]{1,0} %add.4054, f32[] %constant.20660), padding=0_0x1024_2048, metadata={op_type="pad" op_name="pmap(_multi_device_update_fn)/scan/while/body/pad[ padding_config=((0, 0, 0), (1024, 2048, 0)) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  %add.4053 = f32[8,4096]{1,0} add(f32[8,4096]{1,0} %pad.343, f32[8,4096]{1,0} %pad.342), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %multiply.1409 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %add.4055, f32[8,1024]{1,0} %reshape.3034), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %param_5.274 = f32[64,8,1024]{2,1,0} parameter(5)
  %dynamic-slice.795 = f32[1,8,1024]{2,1,0} dynamic-slice(f32[64,8,1024]{2,1,0} %param_5.274, s32[] %param_1.694, s32[] %param_2.725, s32[] %param_2.725), dynamic_slice_sizes={1,8,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %reshape.3033 = f32[8,1024]{1,0} reshape(f32[1,8,1024]{2,1,0} %dynamic-slice.795), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.1408 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %multiply.1409, f32[8,1024]{1,0} %reshape.3033), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %multiply.1407 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %multiply.1408, f32[8,1024]{1,0} %reshape.3037), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %pad.341 = f32[8,4096]{1,0} pad(f32[8,1024]{1,0} %multiply.1407, f32[] %constant.20660), padding=0_0x0_3072, metadata={op_type="pad" op_name="pmap(_multi_device_update_fn)/scan/while/body/pad[ padding_config=((0, 0, 0), (0, 3072, 0)) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  %add.4052 = f32[8,4096]{1,0} add(f32[8,4096]{1,0} %add.4053, f32[8,4096]{1,0} %pad.341), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %param_4.308 = f32[64,8,1024]{2,1,0} parameter(4)
  %dynamic-slice.794 = f32[1,8,1024]{2,1,0} dynamic-slice(f32[64,8,1024]{2,1,0} %param_4.308, s32[] %param_1.694, s32[] %param_2.725, s32[] %param_2.725), dynamic_slice_sizes={1,8,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %reshape.3032 = f32[8,1024]{1,0} reshape(f32[1,8,1024]{2,1,0} %dynamic-slice.794), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.1406 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %reshape.3032, f32[8,1024]{1,0} %add.4055), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %param_3.584 = f32[64,8,1024]{2,1,0} parameter(3)
  %dynamic-slice.793 = f32[1,8,1024]{2,1,0} dynamic-slice(f32[64,8,1024]{2,1,0} %param_3.584, s32[] %param_1.694, s32[] %param_2.725, s32[] %param_2.725), dynamic_slice_sizes={1,8,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %reshape.3031 = f32[8,1024]{1,0} reshape(f32[1,8,1024]{2,1,0} %dynamic-slice.793), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.1405 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %multiply.1406, f32[8,1024]{1,0} %reshape.3031), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %param_0.323 = f32[64,8,1024]{2,1,0} parameter(0)
  %dynamic-slice.792 = f32[1,8,1024]{2,1,0} dynamic-slice(f32[64,8,1024]{2,1,0} %param_0.323, s32[] %param_1.694, s32[] %param_2.725, s32[] %param_2.725), dynamic_slice_sizes={1,8,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %reshape.3030 = f32[8,1024]{1,0} reshape(f32[1,8,1024]{2,1,0} %dynamic-slice.792), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.1404 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %multiply.1405, f32[8,1024]{1,0} %reshape.3030), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %pad.340 = f32[8,4096]{1,0} pad(f32[8,1024]{1,0} %multiply.1404, f32[] %constant.20660), padding=0_0x2048_1024, metadata={op_type="pad" op_name="pmap(_multi_device_update_fn)/scan/while/body/pad[ padding_config=((0, 0, 0), (2048, 1024, 0)) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  ROOT %add.4051 = f32[8,4096]{1,0} add(f32[8,4096]{1,0} %add.4052, f32[8,4096]{1,0} %pad.340), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
}

%fused_computation.214 (param_0.325: f32[64,8,2048], param_1.695: s32[]) -> f32[8,2048] {
  %param_0.325 = f32[64,8,2048]{2,1,0} parameter(0)
  %param_1.695 = s32[] parameter(1)
  %constant.20661 = s32[] constant(0), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %dynamic-slice.804 = f32[1,8,2048]{2,1,0} dynamic-slice(f32[64,8,2048]{2,1,0} %param_0.325, s32[] %param_1.695, s32[] %constant.20661, s32[] %constant.20661), dynamic_slice_sizes={1,8,2048}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 8, 2048) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %reshape.3042 = f32[8,2048]{1,0} reshape(f32[1,8,2048]{2,1,0} %dynamic-slice.804), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.215 (param_0.330: s32[]) -> s32[] {
  %constant.20665 = s32[] constant(64), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_0.330 = s32[] parameter(0)
  %subtract.534 = s32[] subtract(s32[] %constant.20665, s32[] %param_0.330), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant.20664 = s32[] constant(-1)
  %add.4059 = s32[] add(s32[] %subtract.534, s32[] %constant.20664), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant.20663 = s32[] constant(0), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.2754 = pred[] compare(s32[] %add.4059, s32[] %constant.20663), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant.20662 = s32[] constant(63)
  %add.4058 = s32[] add(s32[] %subtract.534, s32[] %constant.20662), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %select.2643 = s32[] select(pred[] %compare.2754, s32[] %add.4058, s32[] %add.4059), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%parallel_add.3612 (p.71: f32[2048,4096], p.72: f32[2048,4096]) -> f32[2048,4096] {
  %p.71 = f32[2048,4096]{1,0} parameter(0)
  %p.72 = f32[2048,4096]{1,0} parameter(1)
  ROOT %add.3612.clone = f32[2048,4096]{1,0} add(f32[2048,4096]{1,0} %p.71, f32[2048,4096]{1,0} %p.72), outer_dimension_partitions={9}, metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
}

%wide.wide.body_computation__194.13302.clone.clone.clone.clone (wide_param.189: (f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[64,8,2048], f32[64,8,1024], /*index=5*/f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], /*index=10*/f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[2048,4096], s32[], /*index=15*/f32[2048,4096], f32[4096], f32[8,2048], f32[64,8,1024])) -> (f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[64,8,2048], f32[64,8,1024], /*index=5*/f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], /*index=10*/f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[2048,4096], s32[], /*index=15*/f32[2048,4096], f32[4096], f32[8,2048], f32[64,8,1024]) {
  %wide_param.189 = (f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) parameter(0)
  %get-tuple-element.27501 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.189), index=0
  %get-tuple-element.27502 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.189), index=1
  %get-tuple-element.27503 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.189), index=2
  %get-tuple-element.27504 = f32[64,8,2048]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.189), index=3
  %get-tuple-element.27505 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.189), index=4
  %get-tuple-element.27506 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.189), index=5
  %get-tuple-element.27507 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.189), index=6
  %get-tuple-element.27508 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.189), index=7
  %get-tuple-element.27509 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.189), index=8
  %get-tuple-element.27510 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.189), index=9
  %get-tuple-element.27511 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.189), index=10
  %get-tuple-element.27512 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.189), index=11
  %get-tuple-element.27513 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.189), index=12
  %get-tuple-element.27514 = f32[2048,4096]{1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.189), index=13
  %get-tuple-element.27515 = s32[] get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.189), index=14
  %copy.814 = s32[] copy(s32[] %get-tuple-element.27515)
  %constant.19266 = s32[] constant(1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.3613 = s32[] add(s32[] %copy.814, s32[] %constant.19266), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.27516 = f32[2048,4096]{1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.189), index=15
  %fusion.215 = s32[] fusion(s32[] %copy.814), kind=kLoop, calls=%fused_computation.215, metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %fusion.214 = f32[8,2048]{1,0} fusion(f32[64,8,2048]{2,1,0} %get-tuple-element.27504, s32[] %fusion.215), kind=kLoop, calls=%fused_computation.214, metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant.19187 = s32[] constant(0), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.27518 = f32[8,2048]{1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.189), index=17
  %fusion.213 = f32[8,4096]{1,0} fusion(f32[64,8,1024]{2,1,0} %get-tuple-element.27502, s32[] %fusion.215, s32[] %constant.19187, f32[64,8,1024]{2,1,0} %get-tuple-element.27505, f32[64,8,1024]{2,1,0} %get-tuple-element.27503, /*index=5*/f32[64,8,1024]{2,1,0} %get-tuple-element.27507, f32[64,8,1024]{2,1,0} %get-tuple-element.27508, f32[64,8,1024]{2,1,0} %get-tuple-element.27509, f32[64,8,1024]{2,1,0} %get-tuple-element.27511, f32[8,2048]{1,0} %get-tuple-element.27518, /*index=10*/f32[64,8,1024]{2,1,0} %get-tuple-element.27506, f32[64,8,1024]{2,1,0} %get-tuple-element.27512, f32[64,8,1024]{2,1,0} %get-tuple-element.27513, f32[64,8,1024]{2,1,0} %get-tuple-element.27501, f32[64,8,1024]{2,1,0} %get-tuple-element.27510), kind=kLoop, calls=%fused_computation.213, metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %dot.180 = f32[2048,4096]{1,0} dot(f32[8,2048]{1,0} %fusion.214, f32[8,4096]{1,0} %fusion.213), lhs_contracting_dims={0}, rhs_contracting_dims={0}, metadata={op_type="transpose" op_name="pmap(_multi_device_update_fn)/scan/while/body/transpose[ permutation=(1, 0) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %call.100 = f32[2048,4096]{1,0} call(f32[2048,4096]{1,0} %get-tuple-element.27516, f32[2048,4096]{1,0} %dot.180), to_apply=%parallel_add.3612
  %get-tuple-element.27517 = f32[4096]{0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.189), index=16
  %constant.19194 = f32[] constant(0), metadata={op_type="pad" op_name="pmap(_multi_device_update_fn)/scan/while/body/pad[ padding_config=((0, 0, 0), (2048, 1024, 0)) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  %reduce.272 = f32[4096]{0} reduce(f32[8,4096]{1,0} %fusion.213, f32[] %constant.19194), dimensions={0}, to_apply=%primitive_computation_add__1.13294, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/scan/while/body/reduce_sum[ axes=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %add.3610 = f32[4096]{0} add(f32[4096]{0} %get-tuple-element.27517, f32[4096]{0} %reduce.272), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %dot.179 = f32[8,2048]{1,0} dot(f32[8,4096]{1,0} %fusion.213, f32[2048,4096]{1,0} %get-tuple-element.27514), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_type="dot_general" op_name="pmap(_multi_device_update_fn)/scan/while/body/dot_general[ dimension_numbers=(((1,), (1,)), ((), ()))\n                                                           precision=None\n                                                           preferred_element_type=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %fusion.212 = f32[8,2048]{1,0} fusion(f32[8,2048]{1,0} %dot.179, f32[64,8,1024]{2,1,0} %get-tuple-element.27502, s32[] %fusion.215, f32[64,8,1024]{2,1,0} %get-tuple-element.27511, f32[8,2048]{1,0} %get-tuple-element.27518, /*index=5*/f32[64,8,1024]{2,1,0} %get-tuple-element.27512, f32[64,8,1024]{2,1,0} %get-tuple-element.27501, f32[64,8,1024]{2,1,0} %get-tuple-element.27510), kind=kLoop, calls=%fused_computation.212, metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %copy.822 = f32[8,2048]{1,0} copy(f32[8,2048]{1,0} %fusion.212)
  %get-tuple-element.27519 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.189), index=18
  %fusion.211 = f32[64,8,1024]{2,1,0} fusion(f32[64,8,1024]{2,1,0} %get-tuple-element.27519, s32[] %fusion.215, f32[8,2048]{1,0} %dot.179), kind=kLoop, calls=%fused_computation.211, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %tuple.1323 = (f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) tuple(f32[64,8,1024]{2,1,0} %get-tuple-element.27501, f32[64,8,1024]{2,1,0} %get-tuple-element.27502, f32[64,8,1024]{2,1,0} %get-tuple-element.27503, f32[64,8,2048]{2,1,0} %get-tuple-element.27504, f32[64,8,1024]{2,1,0} %get-tuple-element.27505, /*index=5*/f32[64,8,1024]{2,1,0} %get-tuple-element.27506, f32[64,8,1024]{2,1,0} %get-tuple-element.27507, f32[64,8,1024]{2,1,0} %get-tuple-element.27508, f32[64,8,1024]{2,1,0} %get-tuple-element.27509, f32[64,8,1024]{2,1,0} %get-tuple-element.27510, /*index=10*/f32[64,8,1024]{2,1,0} %get-tuple-element.27511, f32[64,8,1024]{2,1,0} %get-tuple-element.27512, f32[64,8,1024]{2,1,0} %get-tuple-element.27513, f32[2048,4096]{1,0} %get-tuple-element.27514, s32[] %add.3613, /*index=15*/f32[2048,4096]{1,0} %call.100, f32[4096]{0} %add.3610, f32[8,2048]{1,0} %copy.822, f32[64,8,1024]{2,1,0} %fusion.211)
}

%wide.wide.cond_computation__194.13713.clone.clone.clone.clone (wide_param.190: (f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[64,8,2048], f32[64,8,1024], /*index=5*/f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], /*index=10*/f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[2048,4096], s32[], /*index=15*/f32[2048,4096], f32[4096], f32[8,2048], f32[64,8,1024])) -> pred[] {
  %wide_param.190 = (f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) parameter(0)
  %get-tuple-element.25384 = s32[] get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.190), index=14
  %constant.19301 = s32[] constant(64), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/cond/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %compare.2599 = pred[] compare(s32[] %get-tuple-element.25384, s32[] %constant.19301), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/cond/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%primitive_computation_add__1.13806 (parameter.13807: f32[], parameter.13808: f32[]) -> f32[] {
  %parameter.13807 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.13808 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.13809 = f32[] add(f32[] %parameter.13807, f32[] %parameter.13808), metadata={op_type="add" op_name="add"}
}

%fused_computation.216 (param_0.331: f32[64,8,1024], param_1.702: s32[], param_2.732: f32[8,2048]) -> f32[64,8,1024] {
  %param_0.331 = f32[64,8,1024]{2,1,0} parameter(0)
  %param_2.732 = f32[8,2048]{1,0} parameter(2)
  %slice.1312 = f32[8,1024]{1,0} slice(f32[8,2048]{1,0} %param_2.732), slice={[0:8], [0:1024]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(8, 1024)\n                                                     start_indices=(0, 0)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %reshape.3043 = f32[1,8,1024]{2,1,0} reshape(f32[8,1024]{1,0} %slice.1312), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_1.702 = s32[] parameter(1)
  %constant.20667 = s32[] constant(0), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.882 = f32[64,8,1024]{2,1,0} dynamic-update-slice(f32[64,8,1024]{2,1,0} %param_0.331, f32[1,8,1024]{2,1,0} %reshape.3043, s32[] %param_1.702, s32[] %constant.20667, s32[] %constant.20667), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.217 (param_0.334: f32[8,2048], param_1.708: f32[64,8,1024], param_2.738: s32[], param_3.596: f32[64,8,1024], param_4.313: f32[8,2048], param_5.281: f32[64,8,1024], param_6.196: f32[64,8,1024], param_7.116: f32[64,8,1024]) -> f32[8,2048] {
  %param_0.334 = f32[8,2048]{1,0} parameter(0)
  %slice.1313 = f32[8,1024]{1,0} slice(f32[8,2048]{1,0} %param_0.334), slice={[0:8], [1024:2048]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(8, 2048)\n                                                     start_indices=(0, 1024)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %constant.20668 = f32[] constant(0), metadata={op_type="pad" op_name="pmap(_multi_device_update_fn)/scan/while/body/pad[ padding_config=((0, 0, 0), (2048, 1024, 0)) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  %pad.345 = f32[8,2048]{1,0} pad(f32[8,1024]{1,0} %slice.1313, f32[] %constant.20668), padding=0_0x1024_0, metadata={op_type="pad" op_name="pmap(_multi_device_update_fn)/scan/while/body/pad[ padding_config=((0, 0, 0), (1024, 0, 0)) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=54}
  %param_4.313 = f32[8,2048]{1,0} parameter(4)
  %slice.1314 = f32[8,1024]{1,0} slice(f32[8,2048]{1,0} %param_4.313), slice={[0:8], [0:1024]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(8, 1024)\n                                                     start_indices=(0, 0)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=65}
  %param_6.196 = f32[64,8,1024]{2,1,0} parameter(6)
  %param_2.738 = s32[] parameter(2)
  %constant.20669 = s32[] constant(0), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %dynamic-slice.808 = f32[1,8,1024]{2,1,0} dynamic-slice(f32[64,8,1024]{2,1,0} %param_6.196, s32[] %param_2.738, s32[] %constant.20669, s32[] %constant.20669), dynamic_slice_sizes={1,8,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %reshape.3047 = f32[8,1024]{1,0} reshape(f32[1,8,1024]{2,1,0} %dynamic-slice.808), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %slice.1315 = f32[8,1024]{1,0} slice(f32[8,2048]{1,0} %param_4.313), slice={[0:8], [1024:2048]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(8, 2048)\n                                                     start_indices=(0, 1024)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=65}
  %add.4063 = f32[8,1024]{1,0} add(f32[8,1024]{1,0} %reshape.3047, f32[8,1024]{1,0} %slice.1315), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %param_5.281 = f32[64,8,1024]{2,1,0} parameter(5)
  %dynamic-slice.807 = f32[1,8,1024]{2,1,0} dynamic-slice(f32[64,8,1024]{2,1,0} %param_5.281, s32[] %param_2.738, s32[] %constant.20669, s32[] %constant.20669), dynamic_slice_sizes={1,8,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %reshape.3046 = f32[8,1024]{1,0} reshape(f32[1,8,1024]{2,1,0} %dynamic-slice.807), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.1422 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %add.4063, f32[8,1024]{1,0} %reshape.3046), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  %param_3.596 = f32[64,8,1024]{2,1,0} parameter(3)
  %dynamic-slice.806 = f32[1,8,1024]{2,1,0} dynamic-slice(f32[64,8,1024]{2,1,0} %param_3.596, s32[] %param_2.738, s32[] %constant.20669, s32[] %constant.20669), dynamic_slice_sizes={1,8,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %reshape.3045 = f32[8,1024]{1,0} reshape(f32[1,8,1024]{2,1,0} %dynamic-slice.806), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.1421 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %multiply.1422, f32[8,1024]{1,0} %reshape.3045), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  %add.4062 = f32[8,1024]{1,0} add(f32[8,1024]{1,0} %slice.1314, f32[8,1024]{1,0} %multiply.1421), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %param_7.116 = f32[64,8,1024]{2,1,0} parameter(7)
  %dynamic-slice.809 = f32[1,8,1024]{2,1,0} dynamic-slice(f32[64,8,1024]{2,1,0} %param_7.116, s32[] %param_2.738, s32[] %constant.20669, s32[] %constant.20669), dynamic_slice_sizes={1,8,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %reshape.3048 = f32[8,1024]{1,0} reshape(f32[1,8,1024]{2,1,0} %dynamic-slice.809), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.1420 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %multiply.1421, f32[8,1024]{1,0} %reshape.3048), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  %add.4061 = f32[8,1024]{1,0} add(f32[8,1024]{1,0} %add.4062, f32[8,1024]{1,0} %multiply.1420), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %param_1.708 = f32[64,8,1024]{2,1,0} parameter(1)
  %dynamic-slice.805 = f32[1,8,1024]{2,1,0} dynamic-slice(f32[64,8,1024]{2,1,0} %param_1.708, s32[] %param_2.738, s32[] %constant.20669, s32[] %constant.20669), dynamic_slice_sizes={1,8,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %reshape.3044 = f32[8,1024]{1,0} reshape(f32[1,8,1024]{2,1,0} %dynamic-slice.805), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.1419 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %add.4061, f32[8,1024]{1,0} %reshape.3044), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %pad.344 = f32[8,2048]{1,0} pad(f32[8,1024]{1,0} %multiply.1419, f32[] %constant.20668), padding=0_0x0_1024, metadata={op_type="pad" op_name="pmap(_multi_device_update_fn)/scan/while/body/pad[ padding_config=((0, 0, 0), (0, 1024, 0)) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=54}
  ROOT %add.4060 = f32[8,2048]{1,0} add(f32[8,2048]{1,0} %pad.345, f32[8,2048]{1,0} %pad.344), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
}

%fused_computation.218 (param_0.337: f32[64,8,1024], param_1.713: s32[], param_2.743: s32[], param_3.602: f32[64,8,1024], param_4.317: f32[64,8,1024], param_5.287: f32[64,8,1024], param_6.205: f32[64,8,1024], param_7.125: f32[64,8,1024], param_8.45: f32[64,8,1024], param_9.25: f32[8,2048], param_10.25: f32[64,8,1024], param_11.31: f32[64,8,1024], param_12.29: f32[64,8,1024], param_13.23: f32[64,8,1024], param_14.35: f32[64,8,1024]) -> f32[8,4096] {
  %param_14.35 = f32[64,8,1024]{2,1,0} parameter(14)
  %param_1.713 = s32[] parameter(1)
  %param_2.743 = s32[] parameter(2)
  %dynamic-slice.821 = f32[1,8,1024]{2,1,0} dynamic-slice(f32[64,8,1024]{2,1,0} %param_14.35, s32[] %param_1.713, s32[] %param_2.743, s32[] %param_2.743), dynamic_slice_sizes={1,8,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %reshape.3060 = f32[8,1024]{1,0} reshape(f32[1,8,1024]{2,1,0} %dynamic-slice.821), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_13.23 = f32[64,8,1024]{2,1,0} parameter(13)
  %dynamic-slice.820 = f32[1,8,1024]{2,1,0} dynamic-slice(f32[64,8,1024]{2,1,0} %param_13.23, s32[] %param_1.713, s32[] %param_2.743, s32[] %param_2.743), dynamic_slice_sizes={1,8,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %reshape.3059 = f32[8,1024]{1,0} reshape(f32[1,8,1024]{2,1,0} %dynamic-slice.820), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_9.25 = f32[8,2048]{1,0} parameter(9)
  %slice.1317 = f32[8,1024]{1,0} slice(f32[8,2048]{1,0} %param_9.25), slice={[0:8], [1024:2048]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(8, 2048)\n                                                     start_indices=(0, 1024)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=65}
  %add.4071 = f32[8,1024]{1,0} add(f32[8,1024]{1,0} %reshape.3059, f32[8,1024]{1,0} %slice.1317), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %multiply.1438 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %reshape.3060, f32[8,1024]{1,0} %add.4071), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  %param_12.29 = f32[64,8,1024]{2,1,0} parameter(12)
  %dynamic-slice.819 = f32[1,8,1024]{2,1,0} dynamic-slice(f32[64,8,1024]{2,1,0} %param_12.29, s32[] %param_1.713, s32[] %param_2.743, s32[] %param_2.743), dynamic_slice_sizes={1,8,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %reshape.3058 = f32[8,1024]{1,0} reshape(f32[1,8,1024]{2,1,0} %dynamic-slice.819), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.1437 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %multiply.1438, f32[8,1024]{1,0} %reshape.3058), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %param_11.31 = f32[64,8,1024]{2,1,0} parameter(11)
  %dynamic-slice.818 = f32[1,8,1024]{2,1,0} dynamic-slice(f32[64,8,1024]{2,1,0} %param_11.31, s32[] %param_1.713, s32[] %param_2.743, s32[] %param_2.743), dynamic_slice_sizes={1,8,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %reshape.3057 = f32[8,1024]{1,0} reshape(f32[1,8,1024]{2,1,0} %dynamic-slice.818), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.1436 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %multiply.1437, f32[8,1024]{1,0} %reshape.3057), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %constant.20670 = f32[] constant(0), metadata={op_type="pad" op_name="pmap(_multi_device_update_fn)/scan/while/body/pad[ padding_config=((0, 0, 0), (2048, 1024, 0)) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  %pad.349 = f32[8,4096]{1,0} pad(f32[8,1024]{1,0} %multiply.1436, f32[] %constant.20670), padding=0_0x3072_0, metadata={op_type="pad" op_name="pmap(_multi_device_update_fn)/scan/while/body/pad[ padding_config=((0, 0, 0), (3072, 0, 0)) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  %param_10.25 = f32[64,8,1024]{2,1,0} parameter(10)
  %dynamic-slice.817 = f32[1,8,1024]{2,1,0} dynamic-slice(f32[64,8,1024]{2,1,0} %param_10.25, s32[] %param_1.713, s32[] %param_2.743, s32[] %param_2.743), dynamic_slice_sizes={1,8,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %reshape.3056 = f32[8,1024]{1,0} reshape(f32[1,8,1024]{2,1,0} %dynamic-slice.817), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %slice.1316 = f32[8,1024]{1,0} slice(f32[8,2048]{1,0} %param_9.25), slice={[0:8], [0:1024]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(8, 1024)\n                                                     start_indices=(0, 0)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=65}
  %multiply.1435 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %add.4071, f32[8,1024]{1,0} %reshape.3057), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  %param_8.45 = f32[64,8,1024]{2,1,0} parameter(8)
  %dynamic-slice.816 = f32[1,8,1024]{2,1,0} dynamic-slice(f32[64,8,1024]{2,1,0} %param_8.45, s32[] %param_1.713, s32[] %param_2.743, s32[] %param_2.743), dynamic_slice_sizes={1,8,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %reshape.3055 = f32[8,1024]{1,0} reshape(f32[1,8,1024]{2,1,0} %dynamic-slice.816), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.1434 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %multiply.1435, f32[8,1024]{1,0} %reshape.3055), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  %add.4069 = f32[8,1024]{1,0} add(f32[8,1024]{1,0} %slice.1316, f32[8,1024]{1,0} %multiply.1434), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %multiply.1433 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %multiply.1434, f32[8,1024]{1,0} %reshape.3060), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  %add.4068 = f32[8,1024]{1,0} add(f32[8,1024]{1,0} %add.4069, f32[8,1024]{1,0} %multiply.1433), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %multiply.1432 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %reshape.3056, f32[8,1024]{1,0} %add.4068), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %param_7.125 = f32[64,8,1024]{2,1,0} parameter(7)
  %dynamic-slice.815 = f32[1,8,1024]{2,1,0} dynamic-slice(f32[64,8,1024]{2,1,0} %param_7.125, s32[] %param_1.713, s32[] %param_2.743, s32[] %param_2.743), dynamic_slice_sizes={1,8,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %reshape.3054 = f32[8,1024]{1,0} reshape(f32[1,8,1024]{2,1,0} %dynamic-slice.815), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.1431 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %multiply.1432, f32[8,1024]{1,0} %reshape.3054), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %param_6.205 = f32[64,8,1024]{2,1,0} parameter(6)
  %dynamic-slice.814 = f32[1,8,1024]{2,1,0} dynamic-slice(f32[64,8,1024]{2,1,0} %param_6.205, s32[] %param_1.713, s32[] %param_2.743, s32[] %param_2.743), dynamic_slice_sizes={1,8,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %reshape.3053 = f32[8,1024]{1,0} reshape(f32[1,8,1024]{2,1,0} %dynamic-slice.814), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.1430 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %multiply.1431, f32[8,1024]{1,0} %reshape.3053), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %add.4067 = f32[8,1024]{1,0} add(f32[8,1024]{1,0} %multiply.1431, f32[8,1024]{1,0} %multiply.1430), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %pad.348 = f32[8,4096]{1,0} pad(f32[8,1024]{1,0} %add.4067, f32[] %constant.20670), padding=0_0x1024_2048, metadata={op_type="pad" op_name="pmap(_multi_device_update_fn)/scan/while/body/pad[ padding_config=((0, 0, 0), (1024, 2048, 0)) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  %add.4066 = f32[8,4096]{1,0} add(f32[8,4096]{1,0} %pad.349, f32[8,4096]{1,0} %pad.348), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %multiply.1429 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %add.4068, f32[8,1024]{1,0} %reshape.3053), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %param_5.287 = f32[64,8,1024]{2,1,0} parameter(5)
  %dynamic-slice.813 = f32[1,8,1024]{2,1,0} dynamic-slice(f32[64,8,1024]{2,1,0} %param_5.287, s32[] %param_1.713, s32[] %param_2.743, s32[] %param_2.743), dynamic_slice_sizes={1,8,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %reshape.3052 = f32[8,1024]{1,0} reshape(f32[1,8,1024]{2,1,0} %dynamic-slice.813), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.1428 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %multiply.1429, f32[8,1024]{1,0} %reshape.3052), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %multiply.1426 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %multiply.1428, f32[8,1024]{1,0} %reshape.3056), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %pad.347 = f32[8,4096]{1,0} pad(f32[8,1024]{1,0} %multiply.1426, f32[] %constant.20670), padding=0_0x0_3072, metadata={op_type="pad" op_name="pmap(_multi_device_update_fn)/scan/while/body/pad[ padding_config=((0, 0, 0), (0, 3072, 0)) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  %add.4065 = f32[8,4096]{1,0} add(f32[8,4096]{1,0} %add.4066, f32[8,4096]{1,0} %pad.347), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %param_4.317 = f32[64,8,1024]{2,1,0} parameter(4)
  %dynamic-slice.812 = f32[1,8,1024]{2,1,0} dynamic-slice(f32[64,8,1024]{2,1,0} %param_4.317, s32[] %param_1.713, s32[] %param_2.743, s32[] %param_2.743), dynamic_slice_sizes={1,8,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %reshape.3051 = f32[8,1024]{1,0} reshape(f32[1,8,1024]{2,1,0} %dynamic-slice.812), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.1425 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %reshape.3051, f32[8,1024]{1,0} %add.4068), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %param_3.602 = f32[64,8,1024]{2,1,0} parameter(3)
  %dynamic-slice.811 = f32[1,8,1024]{2,1,0} dynamic-slice(f32[64,8,1024]{2,1,0} %param_3.602, s32[] %param_1.713, s32[] %param_2.743, s32[] %param_2.743), dynamic_slice_sizes={1,8,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %reshape.3050 = f32[8,1024]{1,0} reshape(f32[1,8,1024]{2,1,0} %dynamic-slice.811), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.1424 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %multiply.1425, f32[8,1024]{1,0} %reshape.3050), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %param_0.337 = f32[64,8,1024]{2,1,0} parameter(0)
  %dynamic-slice.810 = f32[1,8,1024]{2,1,0} dynamic-slice(f32[64,8,1024]{2,1,0} %param_0.337, s32[] %param_1.713, s32[] %param_2.743, s32[] %param_2.743), dynamic_slice_sizes={1,8,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %reshape.3049 = f32[8,1024]{1,0} reshape(f32[1,8,1024]{2,1,0} %dynamic-slice.810), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.1423 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %multiply.1424, f32[8,1024]{1,0} %reshape.3049), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %pad.346 = f32[8,4096]{1,0} pad(f32[8,1024]{1,0} %multiply.1423, f32[] %constant.20670), padding=0_0x2048_1024, metadata={op_type="pad" op_name="pmap(_multi_device_update_fn)/scan/while/body/pad[ padding_config=((0, 0, 0), (2048, 1024, 0)) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  ROOT %add.4064 = f32[8,4096]{1,0} add(f32[8,4096]{1,0} %add.4065, f32[8,4096]{1,0} %pad.346), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
}

%fused_computation.219 (param_0.339: f32[64,8,2048], param_1.714: s32[]) -> f32[8,2048] {
  %param_0.339 = f32[64,8,2048]{2,1,0} parameter(0)
  %param_1.714 = s32[] parameter(1)
  %constant.20671 = s32[] constant(0), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %dynamic-slice.822 = f32[1,8,2048]{2,1,0} dynamic-slice(f32[64,8,2048]{2,1,0} %param_0.339, s32[] %param_1.714, s32[] %constant.20671, s32[] %constant.20671), dynamic_slice_sizes={1,8,2048}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 8, 2048) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %reshape.3061 = f32[8,2048]{1,0} reshape(f32[1,8,2048]{2,1,0} %dynamic-slice.822), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.220 (param_0.344: s32[]) -> s32[] {
  %constant.20676 = s32[] constant(64), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_0.344 = s32[] parameter(0)
  %subtract.535 = s32[] subtract(s32[] %constant.20676, s32[] %param_0.344), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant.20675 = s32[] constant(-1)
  %add.4074 = s32[] add(s32[] %subtract.535, s32[] %constant.20675), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant.20673 = s32[] constant(0), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.2755 = pred[] compare(s32[] %add.4074, s32[] %constant.20673), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant.20672 = s32[] constant(63)
  %add.4073 = s32[] add(s32[] %subtract.535, s32[] %constant.20672), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %select.2644 = s32[] select(pred[] %compare.2755, s32[] %add.4073, s32[] %add.4074), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%parallel_add.3642 (p.73: f32[2048,4096], p.74: f32[2048,4096]) -> f32[2048,4096] {
  %p.73 = f32[2048,4096]{1,0} parameter(0)
  %p.74 = f32[2048,4096]{1,0} parameter(1)
  ROOT %add.3642.clone = f32[2048,4096]{1,0} add(f32[2048,4096]{1,0} %p.73, f32[2048,4096]{1,0} %p.74), outer_dimension_partitions={9}, metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
}

%wide.wide.body_computation__195.13814.clone.clone.clone.clone (wide_param.191: (f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[64,8,2048], f32[64,8,1024], /*index=5*/f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], /*index=10*/f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[2048,4096], s32[], /*index=15*/f32[2048,4096], f32[4096], f32[8,2048], f32[64,8,1024])) -> (f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[64,8,2048], f32[64,8,1024], /*index=5*/f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], /*index=10*/f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[2048,4096], s32[], /*index=15*/f32[2048,4096], f32[4096], f32[8,2048], f32[64,8,1024]) {
  %wide_param.191 = (f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) parameter(0)
  %get-tuple-element.27558 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.191), index=0
  %get-tuple-element.27559 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.191), index=1
  %get-tuple-element.27560 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.191), index=2
  %get-tuple-element.27561 = f32[64,8,2048]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.191), index=3
  %get-tuple-element.27562 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.191), index=4
  %get-tuple-element.27563 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.191), index=5
  %get-tuple-element.27564 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.191), index=6
  %get-tuple-element.27565 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.191), index=7
  %get-tuple-element.27566 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.191), index=8
  %get-tuple-element.27567 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.191), index=9
  %get-tuple-element.27568 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.191), index=10
  %get-tuple-element.27569 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.191), index=11
  %get-tuple-element.27570 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.191), index=12
  %get-tuple-element.27571 = f32[2048,4096]{1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.191), index=13
  %get-tuple-element.27572 = s32[] get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.191), index=14
  %copy.829 = s32[] copy(s32[] %get-tuple-element.27572)
  %constant.19397 = s32[] constant(1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.3643 = s32[] add(s32[] %copy.829, s32[] %constant.19397), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.27573 = f32[2048,4096]{1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.191), index=15
  %fusion.220 = s32[] fusion(s32[] %copy.829), kind=kLoop, calls=%fused_computation.220, metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %fusion.219 = f32[8,2048]{1,0} fusion(f32[64,8,2048]{2,1,0} %get-tuple-element.27561, s32[] %fusion.220), kind=kLoop, calls=%fused_computation.219, metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant.19319 = s32[] constant(0), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.27575 = f32[8,2048]{1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.191), index=17
  %fusion.218 = f32[8,4096]{1,0} fusion(f32[64,8,1024]{2,1,0} %get-tuple-element.27559, s32[] %fusion.220, s32[] %constant.19319, f32[64,8,1024]{2,1,0} %get-tuple-element.27562, f32[64,8,1024]{2,1,0} %get-tuple-element.27560, /*index=5*/f32[64,8,1024]{2,1,0} %get-tuple-element.27564, f32[64,8,1024]{2,1,0} %get-tuple-element.27565, f32[64,8,1024]{2,1,0} %get-tuple-element.27566, f32[64,8,1024]{2,1,0} %get-tuple-element.27568, f32[8,2048]{1,0} %get-tuple-element.27575, /*index=10*/f32[64,8,1024]{2,1,0} %get-tuple-element.27563, f32[64,8,1024]{2,1,0} %get-tuple-element.27569, f32[64,8,1024]{2,1,0} %get-tuple-element.27570, f32[64,8,1024]{2,1,0} %get-tuple-element.27558, f32[64,8,1024]{2,1,0} %get-tuple-element.27567), kind=kLoop, calls=%fused_computation.218, metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %dot.182 = f32[2048,4096]{1,0} dot(f32[8,2048]{1,0} %fusion.219, f32[8,4096]{1,0} %fusion.218), lhs_contracting_dims={0}, rhs_contracting_dims={0}, metadata={op_type="transpose" op_name="pmap(_multi_device_update_fn)/scan/while/body/transpose[ permutation=(1, 0) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %call.101 = f32[2048,4096]{1,0} call(f32[2048,4096]{1,0} %get-tuple-element.27573, f32[2048,4096]{1,0} %dot.182), to_apply=%parallel_add.3642
  %get-tuple-element.27574 = f32[4096]{0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.191), index=16
  %constant.19326 = f32[] constant(0), metadata={op_type="pad" op_name="pmap(_multi_device_update_fn)/scan/while/body/pad[ padding_config=((0, 0, 0), (2048, 1024, 0)) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  %reduce.273 = f32[4096]{0} reduce(f32[8,4096]{1,0} %fusion.218, f32[] %constant.19326), dimensions={0}, to_apply=%primitive_computation_add__1.13806, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/scan/while/body/reduce_sum[ axes=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %add.3640 = f32[4096]{0} add(f32[4096]{0} %get-tuple-element.27574, f32[4096]{0} %reduce.273), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %dot.181 = f32[8,2048]{1,0} dot(f32[8,4096]{1,0} %fusion.218, f32[2048,4096]{1,0} %get-tuple-element.27571), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_type="dot_general" op_name="pmap(_multi_device_update_fn)/scan/while/body/dot_general[ dimension_numbers=(((1,), (1,)), ((), ()))\n                                                           precision=None\n                                                           preferred_element_type=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %fusion.217 = f32[8,2048]{1,0} fusion(f32[8,2048]{1,0} %dot.181, f32[64,8,1024]{2,1,0} %get-tuple-element.27559, s32[] %fusion.220, f32[64,8,1024]{2,1,0} %get-tuple-element.27568, f32[8,2048]{1,0} %get-tuple-element.27575, /*index=5*/f32[64,8,1024]{2,1,0} %get-tuple-element.27569, f32[64,8,1024]{2,1,0} %get-tuple-element.27558, f32[64,8,1024]{2,1,0} %get-tuple-element.27567), kind=kLoop, calls=%fused_computation.217, metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %copy.837 = f32[8,2048]{1,0} copy(f32[8,2048]{1,0} %fusion.217)
  %get-tuple-element.27576 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.191), index=18
  %fusion.216 = f32[64,8,1024]{2,1,0} fusion(f32[64,8,1024]{2,1,0} %get-tuple-element.27576, s32[] %fusion.220, f32[8,2048]{1,0} %dot.181), kind=kLoop, calls=%fused_computation.216, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %tuple.1326 = (f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) tuple(f32[64,8,1024]{2,1,0} %get-tuple-element.27558, f32[64,8,1024]{2,1,0} %get-tuple-element.27559, f32[64,8,1024]{2,1,0} %get-tuple-element.27560, f32[64,8,2048]{2,1,0} %get-tuple-element.27561, f32[64,8,1024]{2,1,0} %get-tuple-element.27562, /*index=5*/f32[64,8,1024]{2,1,0} %get-tuple-element.27563, f32[64,8,1024]{2,1,0} %get-tuple-element.27564, f32[64,8,1024]{2,1,0} %get-tuple-element.27565, f32[64,8,1024]{2,1,0} %get-tuple-element.27566, f32[64,8,1024]{2,1,0} %get-tuple-element.27567, /*index=10*/f32[64,8,1024]{2,1,0} %get-tuple-element.27568, f32[64,8,1024]{2,1,0} %get-tuple-element.27569, f32[64,8,1024]{2,1,0} %get-tuple-element.27570, f32[2048,4096]{1,0} %get-tuple-element.27571, s32[] %add.3643, /*index=15*/f32[2048,4096]{1,0} %call.101, f32[4096]{0} %add.3640, f32[8,2048]{1,0} %copy.837, f32[64,8,1024]{2,1,0} %fusion.216)
}

%wide.wide.cond_computation__195.14225.clone.clone.clone.clone (wide_param.192: (f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[64,8,2048], f32[64,8,1024], /*index=5*/f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], /*index=10*/f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[2048,4096], s32[], /*index=15*/f32[2048,4096], f32[4096], f32[8,2048], f32[64,8,1024])) -> pred[] {
  %wide_param.192 = (f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) parameter(0)
  %get-tuple-element.25527 = s32[] get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.192), index=14
  %constant.19432 = s32[] constant(64), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/cond/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %compare.2616 = pred[] compare(s32[] %get-tuple-element.25527, s32[] %constant.19432), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/cond/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%primitive_computation_add__1.14318 (parameter.14319: f32[], parameter.14320: f32[]) -> f32[] {
  %parameter.14319 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.14320 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.14321 = f32[] add(f32[] %parameter.14319, f32[] %parameter.14320), metadata={op_type="add" op_name="add"}
}

%fused_computation.221 (param_0.345: f32[64,8,1024], param_1.721: s32[], param_2.750: f32[8,2048]) -> f32[64,8,1024] {
  %param_0.345 = f32[64,8,1024]{2,1,0} parameter(0)
  %param_2.750 = f32[8,2048]{1,0} parameter(2)
  %slice.1318 = f32[8,1024]{1,0} slice(f32[8,2048]{1,0} %param_2.750), slice={[0:8], [0:1024]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(8, 1024)\n                                                     start_indices=(0, 0)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %reshape.3062 = f32[1,8,1024]{2,1,0} reshape(f32[8,1024]{1,0} %slice.1318), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_1.721 = s32[] parameter(1)
  %constant.20677 = s32[] constant(0), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.883 = f32[64,8,1024]{2,1,0} dynamic-update-slice(f32[64,8,1024]{2,1,0} %param_0.345, f32[1,8,1024]{2,1,0} %reshape.3062, s32[] %param_1.721, s32[] %constant.20677, s32[] %constant.20677), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.222 (param_0.348: f32[8,2048], param_1.727: f32[64,8,1024], param_2.756: s32[], param_3.614: f32[64,8,1024], param_4.322: f32[8,2048], param_5.294: f32[64,8,1024], param_6.214: f32[64,8,1024], param_7.135: f32[64,8,1024]) -> f32[8,2048] {
  %param_0.348 = f32[8,2048]{1,0} parameter(0)
  %slice.1319 = f32[8,1024]{1,0} slice(f32[8,2048]{1,0} %param_0.348), slice={[0:8], [1024:2048]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(8, 2048)\n                                                     start_indices=(0, 1024)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %constant.20678 = f32[] constant(0), metadata={op_type="pad" op_name="pmap(_multi_device_update_fn)/scan/while/body/pad[ padding_config=((0, 0, 0), (2048, 1024, 0)) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  %pad.351 = f32[8,2048]{1,0} pad(f32[8,1024]{1,0} %slice.1319, f32[] %constant.20678), padding=0_0x1024_0, metadata={op_type="pad" op_name="pmap(_multi_device_update_fn)/scan/while/body/pad[ padding_config=((0, 0, 0), (1024, 0, 0)) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=54}
  %param_4.322 = f32[8,2048]{1,0} parameter(4)
  %slice.1320 = f32[8,1024]{1,0} slice(f32[8,2048]{1,0} %param_4.322), slice={[0:8], [0:1024]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(8, 1024)\n                                                     start_indices=(0, 0)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=65}
  %param_6.214 = f32[64,8,1024]{2,1,0} parameter(6)
  %param_2.756 = s32[] parameter(2)
  %constant.20680 = s32[] constant(0), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %dynamic-slice.826 = f32[1,8,1024]{2,1,0} dynamic-slice(f32[64,8,1024]{2,1,0} %param_6.214, s32[] %param_2.756, s32[] %constant.20680, s32[] %constant.20680), dynamic_slice_sizes={1,8,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %reshape.3066 = f32[8,1024]{1,0} reshape(f32[1,8,1024]{2,1,0} %dynamic-slice.826), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %slice.1321 = f32[8,1024]{1,0} slice(f32[8,2048]{1,0} %param_4.322), slice={[0:8], [1024:2048]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(8, 2048)\n                                                     start_indices=(0, 1024)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=65}
  %add.4078 = f32[8,1024]{1,0} add(f32[8,1024]{1,0} %reshape.3066, f32[8,1024]{1,0} %slice.1321), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %param_5.294 = f32[64,8,1024]{2,1,0} parameter(5)
  %dynamic-slice.825 = f32[1,8,1024]{2,1,0} dynamic-slice(f32[64,8,1024]{2,1,0} %param_5.294, s32[] %param_2.756, s32[] %constant.20680, s32[] %constant.20680), dynamic_slice_sizes={1,8,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %reshape.3065 = f32[8,1024]{1,0} reshape(f32[1,8,1024]{2,1,0} %dynamic-slice.825), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.1443 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %add.4078, f32[8,1024]{1,0} %reshape.3065), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  %param_3.614 = f32[64,8,1024]{2,1,0} parameter(3)
  %dynamic-slice.824 = f32[1,8,1024]{2,1,0} dynamic-slice(f32[64,8,1024]{2,1,0} %param_3.614, s32[] %param_2.756, s32[] %constant.20680, s32[] %constant.20680), dynamic_slice_sizes={1,8,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %reshape.3064 = f32[8,1024]{1,0} reshape(f32[1,8,1024]{2,1,0} %dynamic-slice.824), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.1441 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %multiply.1443, f32[8,1024]{1,0} %reshape.3064), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  %add.4077 = f32[8,1024]{1,0} add(f32[8,1024]{1,0} %slice.1320, f32[8,1024]{1,0} %multiply.1441), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %param_7.135 = f32[64,8,1024]{2,1,0} parameter(7)
  %dynamic-slice.827 = f32[1,8,1024]{2,1,0} dynamic-slice(f32[64,8,1024]{2,1,0} %param_7.135, s32[] %param_2.756, s32[] %constant.20680, s32[] %constant.20680), dynamic_slice_sizes={1,8,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %reshape.3067 = f32[8,1024]{1,0} reshape(f32[1,8,1024]{2,1,0} %dynamic-slice.827), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.1440 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %multiply.1441, f32[8,1024]{1,0} %reshape.3067), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  %add.4076 = f32[8,1024]{1,0} add(f32[8,1024]{1,0} %add.4077, f32[8,1024]{1,0} %multiply.1440), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %param_1.727 = f32[64,8,1024]{2,1,0} parameter(1)
  %dynamic-slice.823 = f32[1,8,1024]{2,1,0} dynamic-slice(f32[64,8,1024]{2,1,0} %param_1.727, s32[] %param_2.756, s32[] %constant.20680, s32[] %constant.20680), dynamic_slice_sizes={1,8,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %reshape.3063 = f32[8,1024]{1,0} reshape(f32[1,8,1024]{2,1,0} %dynamic-slice.823), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.1439 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %add.4076, f32[8,1024]{1,0} %reshape.3063), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %pad.350 = f32[8,2048]{1,0} pad(f32[8,1024]{1,0} %multiply.1439, f32[] %constant.20678), padding=0_0x0_1024, metadata={op_type="pad" op_name="pmap(_multi_device_update_fn)/scan/while/body/pad[ padding_config=((0, 0, 0), (0, 1024, 0)) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=54}
  ROOT %add.4075 = f32[8,2048]{1,0} add(f32[8,2048]{1,0} %pad.351, f32[8,2048]{1,0} %pad.350), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
}

%fused_computation.223 (param_0.351: f32[64,8,1024], param_1.732: s32[], param_2.761: s32[], param_3.620: f32[64,8,1024], param_4.326: f32[64,8,1024], param_5.300: f32[64,8,1024], param_6.223: f32[64,8,1024], param_7.144: f32[64,8,1024], param_8.68: f32[64,8,1024], param_9.38: f32[8,2048], param_10.38: f32[64,8,1024], param_11.47: f32[64,8,1024], param_12.44: f32[64,8,1024], param_13.35: f32[64,8,1024], param_14.53: f32[64,8,1024]) -> f32[8,4096] {
  %param_14.53 = f32[64,8,1024]{2,1,0} parameter(14)
  %param_1.732 = s32[] parameter(1)
  %param_2.761 = s32[] parameter(2)
  %dynamic-slice.839 = f32[1,8,1024]{2,1,0} dynamic-slice(f32[64,8,1024]{2,1,0} %param_14.53, s32[] %param_1.732, s32[] %param_2.761, s32[] %param_2.761), dynamic_slice_sizes={1,8,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %reshape.3083 = f32[8,1024]{1,0} reshape(f32[1,8,1024]{2,1,0} %dynamic-slice.839), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_13.35 = f32[64,8,1024]{2,1,0} parameter(13)
  %dynamic-slice.838 = f32[1,8,1024]{2,1,0} dynamic-slice(f32[64,8,1024]{2,1,0} %param_13.35, s32[] %param_1.732, s32[] %param_2.761, s32[] %param_2.761), dynamic_slice_sizes={1,8,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %reshape.3082 = f32[8,1024]{1,0} reshape(f32[1,8,1024]{2,1,0} %dynamic-slice.838), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_9.38 = f32[8,2048]{1,0} parameter(9)
  %slice.1323 = f32[8,1024]{1,0} slice(f32[8,2048]{1,0} %param_9.38), slice={[0:8], [1024:2048]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(8, 2048)\n                                                     start_indices=(0, 1024)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=65}
  %add.4085 = f32[8,1024]{1,0} add(f32[8,1024]{1,0} %reshape.3082, f32[8,1024]{1,0} %slice.1323), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %multiply.1459 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %reshape.3083, f32[8,1024]{1,0} %add.4085), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  %param_12.44 = f32[64,8,1024]{2,1,0} parameter(12)
  %dynamic-slice.837 = f32[1,8,1024]{2,1,0} dynamic-slice(f32[64,8,1024]{2,1,0} %param_12.44, s32[] %param_1.732, s32[] %param_2.761, s32[] %param_2.761), dynamic_slice_sizes={1,8,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %reshape.3081 = f32[8,1024]{1,0} reshape(f32[1,8,1024]{2,1,0} %dynamic-slice.837), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.1458 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %multiply.1459, f32[8,1024]{1,0} %reshape.3081), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %param_11.47 = f32[64,8,1024]{2,1,0} parameter(11)
  %dynamic-slice.836 = f32[1,8,1024]{2,1,0} dynamic-slice(f32[64,8,1024]{2,1,0} %param_11.47, s32[] %param_1.732, s32[] %param_2.761, s32[] %param_2.761), dynamic_slice_sizes={1,8,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %reshape.3080 = f32[8,1024]{1,0} reshape(f32[1,8,1024]{2,1,0} %dynamic-slice.836), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.1456 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %multiply.1458, f32[8,1024]{1,0} %reshape.3080), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %constant.20681 = f32[] constant(0), metadata={op_type="pad" op_name="pmap(_multi_device_update_fn)/scan/while/body/pad[ padding_config=((0, 0, 0), (2048, 1024, 0)) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  %pad.355 = f32[8,4096]{1,0} pad(f32[8,1024]{1,0} %multiply.1456, f32[] %constant.20681), padding=0_0x3072_0, metadata={op_type="pad" op_name="pmap(_multi_device_update_fn)/scan/while/body/pad[ padding_config=((0, 0, 0), (3072, 0, 0)) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  %param_10.38 = f32[64,8,1024]{2,1,0} parameter(10)
  %dynamic-slice.835 = f32[1,8,1024]{2,1,0} dynamic-slice(f32[64,8,1024]{2,1,0} %param_10.38, s32[] %param_1.732, s32[] %param_2.761, s32[] %param_2.761), dynamic_slice_sizes={1,8,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %reshape.3079 = f32[8,1024]{1,0} reshape(f32[1,8,1024]{2,1,0} %dynamic-slice.835), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %slice.1322 = f32[8,1024]{1,0} slice(f32[8,2048]{1,0} %param_9.38), slice={[0:8], [0:1024]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(8, 1024)\n                                                     start_indices=(0, 0)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=65}
  %multiply.1455 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %add.4085, f32[8,1024]{1,0} %reshape.3080), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  %param_8.68 = f32[64,8,1024]{2,1,0} parameter(8)
  %dynamic-slice.834 = f32[1,8,1024]{2,1,0} dynamic-slice(f32[64,8,1024]{2,1,0} %param_8.68, s32[] %param_1.732, s32[] %param_2.761, s32[] %param_2.761), dynamic_slice_sizes={1,8,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %reshape.3078 = f32[8,1024]{1,0} reshape(f32[1,8,1024]{2,1,0} %dynamic-slice.834), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.1454 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %multiply.1455, f32[8,1024]{1,0} %reshape.3078), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  %add.4084 = f32[8,1024]{1,0} add(f32[8,1024]{1,0} %slice.1322, f32[8,1024]{1,0} %multiply.1454), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %multiply.1453 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %multiply.1454, f32[8,1024]{1,0} %reshape.3083), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  %add.4083 = f32[8,1024]{1,0} add(f32[8,1024]{1,0} %add.4084, f32[8,1024]{1,0} %multiply.1453), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %multiply.1452 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %reshape.3079, f32[8,1024]{1,0} %add.4083), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %param_7.144 = f32[64,8,1024]{2,1,0} parameter(7)
  %dynamic-slice.833 = f32[1,8,1024]{2,1,0} dynamic-slice(f32[64,8,1024]{2,1,0} %param_7.144, s32[] %param_1.732, s32[] %param_2.761, s32[] %param_2.761), dynamic_slice_sizes={1,8,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %reshape.3076 = f32[8,1024]{1,0} reshape(f32[1,8,1024]{2,1,0} %dynamic-slice.833), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.1451 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %multiply.1452, f32[8,1024]{1,0} %reshape.3076), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %param_6.223 = f32[64,8,1024]{2,1,0} parameter(6)
  %dynamic-slice.832 = f32[1,8,1024]{2,1,0} dynamic-slice(f32[64,8,1024]{2,1,0} %param_6.223, s32[] %param_1.732, s32[] %param_2.761, s32[] %param_2.761), dynamic_slice_sizes={1,8,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %reshape.3074 = f32[8,1024]{1,0} reshape(f32[1,8,1024]{2,1,0} %dynamic-slice.832), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.1450 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %multiply.1451, f32[8,1024]{1,0} %reshape.3074), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %add.4082 = f32[8,1024]{1,0} add(f32[8,1024]{1,0} %multiply.1451, f32[8,1024]{1,0} %multiply.1450), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %pad.354 = f32[8,4096]{1,0} pad(f32[8,1024]{1,0} %add.4082, f32[] %constant.20681), padding=0_0x1024_2048, metadata={op_type="pad" op_name="pmap(_multi_device_update_fn)/scan/while/body/pad[ padding_config=((0, 0, 0), (1024, 2048, 0)) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  %add.4081 = f32[8,4096]{1,0} add(f32[8,4096]{1,0} %pad.355, f32[8,4096]{1,0} %pad.354), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %multiply.1449 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %add.4083, f32[8,1024]{1,0} %reshape.3074), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %param_5.300 = f32[64,8,1024]{2,1,0} parameter(5)
  %dynamic-slice.831 = f32[1,8,1024]{2,1,0} dynamic-slice(f32[64,8,1024]{2,1,0} %param_5.300, s32[] %param_1.732, s32[] %param_2.761, s32[] %param_2.761), dynamic_slice_sizes={1,8,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %reshape.3072 = f32[8,1024]{1,0} reshape(f32[1,8,1024]{2,1,0} %dynamic-slice.831), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.1448 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %multiply.1449, f32[8,1024]{1,0} %reshape.3072), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %multiply.1447 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %multiply.1448, f32[8,1024]{1,0} %reshape.3079), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %pad.353 = f32[8,4096]{1,0} pad(f32[8,1024]{1,0} %multiply.1447, f32[] %constant.20681), padding=0_0x0_3072, metadata={op_type="pad" op_name="pmap(_multi_device_update_fn)/scan/while/body/pad[ padding_config=((0, 0, 0), (0, 3072, 0)) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  %add.4080 = f32[8,4096]{1,0} add(f32[8,4096]{1,0} %add.4081, f32[8,4096]{1,0} %pad.353), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %param_4.326 = f32[64,8,1024]{2,1,0} parameter(4)
  %dynamic-slice.830 = f32[1,8,1024]{2,1,0} dynamic-slice(f32[64,8,1024]{2,1,0} %param_4.326, s32[] %param_1.732, s32[] %param_2.761, s32[] %param_2.761), dynamic_slice_sizes={1,8,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %reshape.3071 = f32[8,1024]{1,0} reshape(f32[1,8,1024]{2,1,0} %dynamic-slice.830), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.1446 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %reshape.3071, f32[8,1024]{1,0} %add.4083), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %param_3.620 = f32[64,8,1024]{2,1,0} parameter(3)
  %dynamic-slice.829 = f32[1,8,1024]{2,1,0} dynamic-slice(f32[64,8,1024]{2,1,0} %param_3.620, s32[] %param_1.732, s32[] %param_2.761, s32[] %param_2.761), dynamic_slice_sizes={1,8,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %reshape.3070 = f32[8,1024]{1,0} reshape(f32[1,8,1024]{2,1,0} %dynamic-slice.829), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.1445 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %multiply.1446, f32[8,1024]{1,0} %reshape.3070), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %param_0.351 = f32[64,8,1024]{2,1,0} parameter(0)
  %dynamic-slice.828 = f32[1,8,1024]{2,1,0} dynamic-slice(f32[64,8,1024]{2,1,0} %param_0.351, s32[] %param_1.732, s32[] %param_2.761, s32[] %param_2.761), dynamic_slice_sizes={1,8,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %reshape.3069 = f32[8,1024]{1,0} reshape(f32[1,8,1024]{2,1,0} %dynamic-slice.828), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.1444 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %multiply.1445, f32[8,1024]{1,0} %reshape.3069), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %pad.352 = f32[8,4096]{1,0} pad(f32[8,1024]{1,0} %multiply.1444, f32[] %constant.20681), padding=0_0x2048_1024, metadata={op_type="pad" op_name="pmap(_multi_device_update_fn)/scan/while/body/pad[ padding_config=((0, 0, 0), (2048, 1024, 0)) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  ROOT %add.4079 = f32[8,4096]{1,0} add(f32[8,4096]{1,0} %add.4080, f32[8,4096]{1,0} %pad.352), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
}

%fused_computation.224 (param_0.353: f32[64,8,2048], param_1.733: s32[]) -> f32[8,2048] {
  %param_0.353 = f32[64,8,2048]{2,1,0} parameter(0)
  %param_1.733 = s32[] parameter(1)
  %constant.20682 = s32[] constant(0), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %dynamic-slice.840 = f32[1,8,2048]{2,1,0} dynamic-slice(f32[64,8,2048]{2,1,0} %param_0.353, s32[] %param_1.733, s32[] %constant.20682, s32[] %constant.20682), dynamic_slice_sizes={1,8,2048}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 8, 2048) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %reshape.3084 = f32[8,2048]{1,0} reshape(f32[1,8,2048]{2,1,0} %dynamic-slice.840), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.225 (param_0.358: s32[]) -> s32[] {
  %constant.20686 = s32[] constant(64), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_0.358 = s32[] parameter(0)
  %subtract.536 = s32[] subtract(s32[] %constant.20686, s32[] %param_0.358), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant.20685 = s32[] constant(-1)
  %add.4087 = s32[] add(s32[] %subtract.536, s32[] %constant.20685), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant.20684 = s32[] constant(0), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.2756 = pred[] compare(s32[] %add.4087, s32[] %constant.20684), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant.20683 = s32[] constant(63)
  %add.4086 = s32[] add(s32[] %subtract.536, s32[] %constant.20683), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %select.2646 = s32[] select(pred[] %compare.2756, s32[] %add.4086, s32[] %add.4087), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%parallel_add.3672 (p.75: f32[2048,4096], p.76: f32[2048,4096]) -> f32[2048,4096] {
  %p.75 = f32[2048,4096]{1,0} parameter(0)
  %p.76 = f32[2048,4096]{1,0} parameter(1)
  ROOT %add.3672.clone = f32[2048,4096]{1,0} add(f32[2048,4096]{1,0} %p.75, f32[2048,4096]{1,0} %p.76), outer_dimension_partitions={9}, metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
}

%wide.wide.body_computation__196.14326.clone.clone.clone.clone (wide_param.193: (f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[64,8,2048], f32[64,8,1024], /*index=5*/f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], /*index=10*/f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[2048,4096], s32[], /*index=15*/f32[2048,4096], f32[4096], f32[8,2048], f32[64,8,1024])) -> (f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[64,8,2048], f32[64,8,1024], /*index=5*/f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], /*index=10*/f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[2048,4096], s32[], /*index=15*/f32[2048,4096], f32[4096], f32[8,2048], f32[64,8,1024]) {
  %wide_param.193 = (f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) parameter(0)
  %get-tuple-element.27615 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.193), index=0
  %get-tuple-element.27616 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.193), index=1
  %get-tuple-element.27617 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.193), index=2
  %get-tuple-element.27618 = f32[64,8,2048]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.193), index=3
  %get-tuple-element.27619 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.193), index=4
  %get-tuple-element.27620 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.193), index=5
  %get-tuple-element.27621 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.193), index=6
  %get-tuple-element.27622 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.193), index=7
  %get-tuple-element.27623 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.193), index=8
  %get-tuple-element.27624 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.193), index=9
  %get-tuple-element.27625 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.193), index=10
  %get-tuple-element.27626 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.193), index=11
  %get-tuple-element.27627 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.193), index=12
  %get-tuple-element.27628 = f32[2048,4096]{1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.193), index=13
  %get-tuple-element.27629 = s32[] get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.193), index=14
  %copy.844 = s32[] copy(s32[] %get-tuple-element.27629)
  %constant.19529 = s32[] constant(1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.3673 = s32[] add(s32[] %copy.844, s32[] %constant.19529), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.27630 = f32[2048,4096]{1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.193), index=15
  %fusion.225 = s32[] fusion(s32[] %copy.844), kind=kLoop, calls=%fused_computation.225, metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %fusion.224 = f32[8,2048]{1,0} fusion(f32[64,8,2048]{2,1,0} %get-tuple-element.27618, s32[] %fusion.225), kind=kLoop, calls=%fused_computation.224, metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant.19451 = s32[] constant(0), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.27632 = f32[8,2048]{1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.193), index=17
  %fusion.223 = f32[8,4096]{1,0} fusion(f32[64,8,1024]{2,1,0} %get-tuple-element.27616, s32[] %fusion.225, s32[] %constant.19451, f32[64,8,1024]{2,1,0} %get-tuple-element.27619, f32[64,8,1024]{2,1,0} %get-tuple-element.27617, /*index=5*/f32[64,8,1024]{2,1,0} %get-tuple-element.27621, f32[64,8,1024]{2,1,0} %get-tuple-element.27622, f32[64,8,1024]{2,1,0} %get-tuple-element.27623, f32[64,8,1024]{2,1,0} %get-tuple-element.27625, f32[8,2048]{1,0} %get-tuple-element.27632, /*index=10*/f32[64,8,1024]{2,1,0} %get-tuple-element.27620, f32[64,8,1024]{2,1,0} %get-tuple-element.27626, f32[64,8,1024]{2,1,0} %get-tuple-element.27627, f32[64,8,1024]{2,1,0} %get-tuple-element.27615, f32[64,8,1024]{2,1,0} %get-tuple-element.27624), kind=kLoop, calls=%fused_computation.223, metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %dot.184 = f32[2048,4096]{1,0} dot(f32[8,2048]{1,0} %fusion.224, f32[8,4096]{1,0} %fusion.223), lhs_contracting_dims={0}, rhs_contracting_dims={0}, metadata={op_type="transpose" op_name="pmap(_multi_device_update_fn)/scan/while/body/transpose[ permutation=(1, 0) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %call.102 = f32[2048,4096]{1,0} call(f32[2048,4096]{1,0} %get-tuple-element.27630, f32[2048,4096]{1,0} %dot.184), to_apply=%parallel_add.3672
  %get-tuple-element.27631 = f32[4096]{0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.193), index=16
  %constant.19457 = f32[] constant(0), metadata={op_type="pad" op_name="pmap(_multi_device_update_fn)/scan/while/body/pad[ padding_config=((0, 0, 0), (2048, 1024, 0)) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  %reduce.274 = f32[4096]{0} reduce(f32[8,4096]{1,0} %fusion.223, f32[] %constant.19457), dimensions={0}, to_apply=%primitive_computation_add__1.14318, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/scan/while/body/reduce_sum[ axes=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %add.3669 = f32[4096]{0} add(f32[4096]{0} %get-tuple-element.27631, f32[4096]{0} %reduce.274), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %dot.183 = f32[8,2048]{1,0} dot(f32[8,4096]{1,0} %fusion.223, f32[2048,4096]{1,0} %get-tuple-element.27628), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_type="dot_general" op_name="pmap(_multi_device_update_fn)/scan/while/body/dot_general[ dimension_numbers=(((1,), (1,)), ((), ()))\n                                                           precision=None\n                                                           preferred_element_type=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %fusion.222 = f32[8,2048]{1,0} fusion(f32[8,2048]{1,0} %dot.183, f32[64,8,1024]{2,1,0} %get-tuple-element.27616, s32[] %fusion.225, f32[64,8,1024]{2,1,0} %get-tuple-element.27625, f32[8,2048]{1,0} %get-tuple-element.27632, /*index=5*/f32[64,8,1024]{2,1,0} %get-tuple-element.27626, f32[64,8,1024]{2,1,0} %get-tuple-element.27615, f32[64,8,1024]{2,1,0} %get-tuple-element.27624), kind=kLoop, calls=%fused_computation.222, metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %copy.852 = f32[8,2048]{1,0} copy(f32[8,2048]{1,0} %fusion.222)
  %get-tuple-element.27633 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.193), index=18
  %fusion.221 = f32[64,8,1024]{2,1,0} fusion(f32[64,8,1024]{2,1,0} %get-tuple-element.27633, s32[] %fusion.225, f32[8,2048]{1,0} %dot.183), kind=kLoop, calls=%fused_computation.221, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %tuple.1329 = (f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) tuple(f32[64,8,1024]{2,1,0} %get-tuple-element.27615, f32[64,8,1024]{2,1,0} %get-tuple-element.27616, f32[64,8,1024]{2,1,0} %get-tuple-element.27617, f32[64,8,2048]{2,1,0} %get-tuple-element.27618, f32[64,8,1024]{2,1,0} %get-tuple-element.27619, /*index=5*/f32[64,8,1024]{2,1,0} %get-tuple-element.27620, f32[64,8,1024]{2,1,0} %get-tuple-element.27621, f32[64,8,1024]{2,1,0} %get-tuple-element.27622, f32[64,8,1024]{2,1,0} %get-tuple-element.27623, f32[64,8,1024]{2,1,0} %get-tuple-element.27624, /*index=10*/f32[64,8,1024]{2,1,0} %get-tuple-element.27625, f32[64,8,1024]{2,1,0} %get-tuple-element.27626, f32[64,8,1024]{2,1,0} %get-tuple-element.27627, f32[2048,4096]{1,0} %get-tuple-element.27628, s32[] %add.3673, /*index=15*/f32[2048,4096]{1,0} %call.102, f32[4096]{0} %add.3669, f32[8,2048]{1,0} %copy.852, f32[64,8,1024]{2,1,0} %fusion.221)
}

%wide.wide.cond_computation__196.14737.clone.clone.clone.clone (wide_param.194: (f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[64,8,2048], f32[64,8,1024], /*index=5*/f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], /*index=10*/f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[2048,4096], s32[], /*index=15*/f32[2048,4096], f32[4096], f32[8,2048], f32[64,8,1024])) -> pred[] {
  %wide_param.194 = (f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) parameter(0)
  %get-tuple-element.25670 = s32[] get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.194), index=14
  %constant.19563 = s32[] constant(64), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/cond/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %compare.2634 = pred[] compare(s32[] %get-tuple-element.25670, s32[] %constant.19563), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/cond/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%primitive_computation_add__1.14830 (parameter.14831: f32[], parameter.14832: f32[]) -> f32[] {
  %parameter.14831 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.14832 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.14833 = f32[] add(f32[] %parameter.14831, f32[] %parameter.14832), metadata={op_type="add" op_name="add"}
}

%fused_computation.226 (param_0.359: f32[64,8,1024], param_1.740: s32[], param_2.768: f32[8,2048]) -> f32[64,8,1024] {
  %param_0.359 = f32[64,8,1024]{2,1,0} parameter(0)
  %param_2.768 = f32[8,2048]{1,0} parameter(2)
  %slice.1324 = f32[8,1024]{1,0} slice(f32[8,2048]{1,0} %param_2.768), slice={[0:8], [0:1024]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(8, 1024)\n                                                     start_indices=(0, 0)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %reshape.3085 = f32[1,8,1024]{2,1,0} reshape(f32[8,1024]{1,0} %slice.1324), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_1.740 = s32[] parameter(1)
  %constant.20687 = s32[] constant(0), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.884 = f32[64,8,1024]{2,1,0} dynamic-update-slice(f32[64,8,1024]{2,1,0} %param_0.359, f32[1,8,1024]{2,1,0} %reshape.3085, s32[] %param_1.740, s32[] %constant.20687, s32[] %constant.20687), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.227 (param_0.362: f32[8,2048], param_1.746: f32[64,8,1024], param_2.774: s32[], param_3.632: f32[64,8,1024], param_4.331: f32[8,2048], param_5.307: f32[64,8,1024], param_6.232: f32[64,8,1024], param_7.154: f32[64,8,1024]) -> f32[8,2048] {
  %param_0.362 = f32[8,2048]{1,0} parameter(0)
  %slice.1325 = f32[8,1024]{1,0} slice(f32[8,2048]{1,0} %param_0.362), slice={[0:8], [1024:2048]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(8, 2048)\n                                                     start_indices=(0, 1024)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %constant.20688 = f32[] constant(0), metadata={op_type="pad" op_name="pmap(_multi_device_update_fn)/scan/while/body/pad[ padding_config=((0, 0, 0), (2048, 1024, 0)) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  %pad.357 = f32[8,2048]{1,0} pad(f32[8,1024]{1,0} %slice.1325, f32[] %constant.20688), padding=0_0x1024_0, metadata={op_type="pad" op_name="pmap(_multi_device_update_fn)/scan/while/body/pad[ padding_config=((0, 0, 0), (1024, 0, 0)) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=54}
  %param_4.331 = f32[8,2048]{1,0} parameter(4)
  %slice.1326 = f32[8,1024]{1,0} slice(f32[8,2048]{1,0} %param_4.331), slice={[0:8], [0:1024]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(8, 1024)\n                                                     start_indices=(0, 0)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=65}
  %param_6.232 = f32[64,8,1024]{2,1,0} parameter(6)
  %param_2.774 = s32[] parameter(2)
  %constant.20689 = s32[] constant(0), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %dynamic-slice.844 = f32[1,8,1024]{2,1,0} dynamic-slice(f32[64,8,1024]{2,1,0} %param_6.232, s32[] %param_2.774, s32[] %constant.20689, s32[] %constant.20689), dynamic_slice_sizes={1,8,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %reshape.3089 = f32[8,1024]{1,0} reshape(f32[1,8,1024]{2,1,0} %dynamic-slice.844), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %slice.1327 = f32[8,1024]{1,0} slice(f32[8,2048]{1,0} %param_4.331), slice={[0:8], [1024:2048]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(8, 2048)\n                                                     start_indices=(0, 1024)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=65}
  %add.4091 = f32[8,1024]{1,0} add(f32[8,1024]{1,0} %reshape.3089, f32[8,1024]{1,0} %slice.1327), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %param_5.307 = f32[64,8,1024]{2,1,0} parameter(5)
  %dynamic-slice.843 = f32[1,8,1024]{2,1,0} dynamic-slice(f32[64,8,1024]{2,1,0} %param_5.307, s32[] %param_2.774, s32[] %constant.20689, s32[] %constant.20689), dynamic_slice_sizes={1,8,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %reshape.3088 = f32[8,1024]{1,0} reshape(f32[1,8,1024]{2,1,0} %dynamic-slice.843), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.1463 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %add.4091, f32[8,1024]{1,0} %reshape.3088), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  %param_3.632 = f32[64,8,1024]{2,1,0} parameter(3)
  %dynamic-slice.842 = f32[1,8,1024]{2,1,0} dynamic-slice(f32[64,8,1024]{2,1,0} %param_3.632, s32[] %param_2.774, s32[] %constant.20689, s32[] %constant.20689), dynamic_slice_sizes={1,8,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %reshape.3087 = f32[8,1024]{1,0} reshape(f32[1,8,1024]{2,1,0} %dynamic-slice.842), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.1462 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %multiply.1463, f32[8,1024]{1,0} %reshape.3087), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  %add.4090 = f32[8,1024]{1,0} add(f32[8,1024]{1,0} %slice.1326, f32[8,1024]{1,0} %multiply.1462), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %param_7.154 = f32[64,8,1024]{2,1,0} parameter(7)
  %dynamic-slice.845 = f32[1,8,1024]{2,1,0} dynamic-slice(f32[64,8,1024]{2,1,0} %param_7.154, s32[] %param_2.774, s32[] %constant.20689, s32[] %constant.20689), dynamic_slice_sizes={1,8,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %reshape.3090 = f32[8,1024]{1,0} reshape(f32[1,8,1024]{2,1,0} %dynamic-slice.845), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.1461 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %multiply.1462, f32[8,1024]{1,0} %reshape.3090), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  %add.4089 = f32[8,1024]{1,0} add(f32[8,1024]{1,0} %add.4090, f32[8,1024]{1,0} %multiply.1461), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %param_1.746 = f32[64,8,1024]{2,1,0} parameter(1)
  %dynamic-slice.841 = f32[1,8,1024]{2,1,0} dynamic-slice(f32[64,8,1024]{2,1,0} %param_1.746, s32[] %param_2.774, s32[] %constant.20689, s32[] %constant.20689), dynamic_slice_sizes={1,8,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %reshape.3086 = f32[8,1024]{1,0} reshape(f32[1,8,1024]{2,1,0} %dynamic-slice.841), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.1460 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %add.4089, f32[8,1024]{1,0} %reshape.3086), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %pad.356 = f32[8,2048]{1,0} pad(f32[8,1024]{1,0} %multiply.1460, f32[] %constant.20688), padding=0_0x0_1024, metadata={op_type="pad" op_name="pmap(_multi_device_update_fn)/scan/while/body/pad[ padding_config=((0, 0, 0), (0, 1024, 0)) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=54}
  ROOT %add.4088 = f32[8,2048]{1,0} add(f32[8,2048]{1,0} %pad.357, f32[8,2048]{1,0} %pad.356), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
}

%fused_computation.228 (param_0.365: f32[64,8,1024], param_1.751: s32[], param_2.779: s32[], param_3.638: f32[64,8,1024], param_4.335: f32[64,8,1024], param_5.313: f32[64,8,1024], param_6.241: f32[64,8,1024], param_7.163: f32[64,8,1024], param_8.91: f32[64,8,1024], param_9.51: f32[8,2048], param_10.51: f32[64,8,1024], param_11.63: f32[64,8,1024], param_12.59: f32[64,8,1024], param_13.47: f32[64,8,1024], param_14.71: f32[64,8,1024]) -> f32[8,4096] {
  %param_14.71 = f32[64,8,1024]{2,1,0} parameter(14)
  %param_1.751 = s32[] parameter(1)
  %param_2.779 = s32[] parameter(2)
  %dynamic-slice.857 = f32[1,8,1024]{2,1,0} dynamic-slice(f32[64,8,1024]{2,1,0} %param_14.71, s32[] %param_1.751, s32[] %param_2.779, s32[] %param_2.779), dynamic_slice_sizes={1,8,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %reshape.3106 = f32[8,1024]{1,0} reshape(f32[1,8,1024]{2,1,0} %dynamic-slice.857), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_13.47 = f32[64,8,1024]{2,1,0} parameter(13)
  %dynamic-slice.856 = f32[1,8,1024]{2,1,0} dynamic-slice(f32[64,8,1024]{2,1,0} %param_13.47, s32[] %param_1.751, s32[] %param_2.779, s32[] %param_2.779), dynamic_slice_sizes={1,8,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %reshape.3105 = f32[8,1024]{1,0} reshape(f32[1,8,1024]{2,1,0} %dynamic-slice.856), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_9.51 = f32[8,2048]{1,0} parameter(9)
  %slice.1329 = f32[8,1024]{1,0} slice(f32[8,2048]{1,0} %param_9.51), slice={[0:8], [1024:2048]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(8, 2048)\n                                                     start_indices=(0, 1024)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=65}
  %add.4098 = f32[8,1024]{1,0} add(f32[8,1024]{1,0} %reshape.3105, f32[8,1024]{1,0} %slice.1329), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %multiply.1478 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %reshape.3106, f32[8,1024]{1,0} %add.4098), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  %param_12.59 = f32[64,8,1024]{2,1,0} parameter(12)
  %dynamic-slice.855 = f32[1,8,1024]{2,1,0} dynamic-slice(f32[64,8,1024]{2,1,0} %param_12.59, s32[] %param_1.751, s32[] %param_2.779, s32[] %param_2.779), dynamic_slice_sizes={1,8,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %reshape.3104 = f32[8,1024]{1,0} reshape(f32[1,8,1024]{2,1,0} %dynamic-slice.855), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.1477 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %multiply.1478, f32[8,1024]{1,0} %reshape.3104), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %param_11.63 = f32[64,8,1024]{2,1,0} parameter(11)
  %dynamic-slice.854 = f32[1,8,1024]{2,1,0} dynamic-slice(f32[64,8,1024]{2,1,0} %param_11.63, s32[] %param_1.751, s32[] %param_2.779, s32[] %param_2.779), dynamic_slice_sizes={1,8,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %reshape.3103 = f32[8,1024]{1,0} reshape(f32[1,8,1024]{2,1,0} %dynamic-slice.854), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.1476 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %multiply.1477, f32[8,1024]{1,0} %reshape.3103), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %constant.20690 = f32[] constant(0), metadata={op_type="pad" op_name="pmap(_multi_device_update_fn)/scan/while/body/pad[ padding_config=((0, 0, 0), (2048, 1024, 0)) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  %pad.361 = f32[8,4096]{1,0} pad(f32[8,1024]{1,0} %multiply.1476, f32[] %constant.20690), padding=0_0x3072_0, metadata={op_type="pad" op_name="pmap(_multi_device_update_fn)/scan/while/body/pad[ padding_config=((0, 0, 0), (3072, 0, 0)) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  %param_10.51 = f32[64,8,1024]{2,1,0} parameter(10)
  %dynamic-slice.853 = f32[1,8,1024]{2,1,0} dynamic-slice(f32[64,8,1024]{2,1,0} %param_10.51, s32[] %param_1.751, s32[] %param_2.779, s32[] %param_2.779), dynamic_slice_sizes={1,8,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %reshape.3102 = f32[8,1024]{1,0} reshape(f32[1,8,1024]{2,1,0} %dynamic-slice.853), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %slice.1328 = f32[8,1024]{1,0} slice(f32[8,2048]{1,0} %param_9.51), slice={[0:8], [0:1024]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(8, 1024)\n                                                     start_indices=(0, 0)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=65}
  %multiply.1475 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %add.4098, f32[8,1024]{1,0} %reshape.3103), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  %param_8.91 = f32[64,8,1024]{2,1,0} parameter(8)
  %dynamic-slice.852 = f32[1,8,1024]{2,1,0} dynamic-slice(f32[64,8,1024]{2,1,0} %param_8.91, s32[] %param_1.751, s32[] %param_2.779, s32[] %param_2.779), dynamic_slice_sizes={1,8,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %reshape.3101 = f32[8,1024]{1,0} reshape(f32[1,8,1024]{2,1,0} %dynamic-slice.852), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.1474 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %multiply.1475, f32[8,1024]{1,0} %reshape.3101), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  %add.4097 = f32[8,1024]{1,0} add(f32[8,1024]{1,0} %slice.1328, f32[8,1024]{1,0} %multiply.1474), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %multiply.1473 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %multiply.1474, f32[8,1024]{1,0} %reshape.3106), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  %add.4096 = f32[8,1024]{1,0} add(f32[8,1024]{1,0} %add.4097, f32[8,1024]{1,0} %multiply.1473), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %multiply.1472 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %reshape.3102, f32[8,1024]{1,0} %add.4096), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %param_7.163 = f32[64,8,1024]{2,1,0} parameter(7)
  %dynamic-slice.851 = f32[1,8,1024]{2,1,0} dynamic-slice(f32[64,8,1024]{2,1,0} %param_7.163, s32[] %param_1.751, s32[] %param_2.779, s32[] %param_2.779), dynamic_slice_sizes={1,8,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %reshape.3100 = f32[8,1024]{1,0} reshape(f32[1,8,1024]{2,1,0} %dynamic-slice.851), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.1471 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %multiply.1472, f32[8,1024]{1,0} %reshape.3100), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %param_6.241 = f32[64,8,1024]{2,1,0} parameter(6)
  %dynamic-slice.850 = f32[1,8,1024]{2,1,0} dynamic-slice(f32[64,8,1024]{2,1,0} %param_6.241, s32[] %param_1.751, s32[] %param_2.779, s32[] %param_2.779), dynamic_slice_sizes={1,8,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %reshape.3098 = f32[8,1024]{1,0} reshape(f32[1,8,1024]{2,1,0} %dynamic-slice.850), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.1470 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %multiply.1471, f32[8,1024]{1,0} %reshape.3098), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %add.4095 = f32[8,1024]{1,0} add(f32[8,1024]{1,0} %multiply.1471, f32[8,1024]{1,0} %multiply.1470), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %pad.360 = f32[8,4096]{1,0} pad(f32[8,1024]{1,0} %add.4095, f32[] %constant.20690), padding=0_0x1024_2048, metadata={op_type="pad" op_name="pmap(_multi_device_update_fn)/scan/while/body/pad[ padding_config=((0, 0, 0), (1024, 2048, 0)) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  %add.4094 = f32[8,4096]{1,0} add(f32[8,4096]{1,0} %pad.361, f32[8,4096]{1,0} %pad.360), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %multiply.1469 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %add.4096, f32[8,1024]{1,0} %reshape.3098), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %param_5.313 = f32[64,8,1024]{2,1,0} parameter(5)
  %dynamic-slice.849 = f32[1,8,1024]{2,1,0} dynamic-slice(f32[64,8,1024]{2,1,0} %param_5.313, s32[] %param_1.751, s32[] %param_2.779, s32[] %param_2.779), dynamic_slice_sizes={1,8,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %reshape.3096 = f32[8,1024]{1,0} reshape(f32[1,8,1024]{2,1,0} %dynamic-slice.849), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.1468 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %multiply.1469, f32[8,1024]{1,0} %reshape.3096), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %multiply.1467 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %multiply.1468, f32[8,1024]{1,0} %reshape.3102), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %pad.359 = f32[8,4096]{1,0} pad(f32[8,1024]{1,0} %multiply.1467, f32[] %constant.20690), padding=0_0x0_3072, metadata={op_type="pad" op_name="pmap(_multi_device_update_fn)/scan/while/body/pad[ padding_config=((0, 0, 0), (0, 3072, 0)) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  %add.4093 = f32[8,4096]{1,0} add(f32[8,4096]{1,0} %add.4094, f32[8,4096]{1,0} %pad.359), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %param_4.335 = f32[64,8,1024]{2,1,0} parameter(4)
  %dynamic-slice.848 = f32[1,8,1024]{2,1,0} dynamic-slice(f32[64,8,1024]{2,1,0} %param_4.335, s32[] %param_1.751, s32[] %param_2.779, s32[] %param_2.779), dynamic_slice_sizes={1,8,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %reshape.3094 = f32[8,1024]{1,0} reshape(f32[1,8,1024]{2,1,0} %dynamic-slice.848), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.1466 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %reshape.3094, f32[8,1024]{1,0} %add.4096), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %param_3.638 = f32[64,8,1024]{2,1,0} parameter(3)
  %dynamic-slice.847 = f32[1,8,1024]{2,1,0} dynamic-slice(f32[64,8,1024]{2,1,0} %param_3.638, s32[] %param_1.751, s32[] %param_2.779, s32[] %param_2.779), dynamic_slice_sizes={1,8,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %reshape.3092 = f32[8,1024]{1,0} reshape(f32[1,8,1024]{2,1,0} %dynamic-slice.847), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.1465 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %multiply.1466, f32[8,1024]{1,0} %reshape.3092), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %param_0.365 = f32[64,8,1024]{2,1,0} parameter(0)
  %dynamic-slice.846 = f32[1,8,1024]{2,1,0} dynamic-slice(f32[64,8,1024]{2,1,0} %param_0.365, s32[] %param_1.751, s32[] %param_2.779, s32[] %param_2.779), dynamic_slice_sizes={1,8,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %reshape.3091 = f32[8,1024]{1,0} reshape(f32[1,8,1024]{2,1,0} %dynamic-slice.846), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.1464 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %multiply.1465, f32[8,1024]{1,0} %reshape.3091), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %pad.358 = f32[8,4096]{1,0} pad(f32[8,1024]{1,0} %multiply.1464, f32[] %constant.20690), padding=0_0x2048_1024, metadata={op_type="pad" op_name="pmap(_multi_device_update_fn)/scan/while/body/pad[ padding_config=((0, 0, 0), (2048, 1024, 0)) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  ROOT %add.4092 = f32[8,4096]{1,0} add(f32[8,4096]{1,0} %add.4093, f32[8,4096]{1,0} %pad.358), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
}

%fused_computation.229 (param_0.367: f32[64,8,2048], param_1.752: s32[]) -> f32[8,2048] {
  %param_0.367 = f32[64,8,2048]{2,1,0} parameter(0)
  %param_1.752 = s32[] parameter(1)
  %constant.20692 = s32[] constant(0), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %dynamic-slice.858 = f32[1,8,2048]{2,1,0} dynamic-slice(f32[64,8,2048]{2,1,0} %param_0.367, s32[] %param_1.752, s32[] %constant.20692, s32[] %constant.20692), dynamic_slice_sizes={1,8,2048}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 8, 2048) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %reshape.3107 = f32[8,2048]{1,0} reshape(f32[1,8,2048]{2,1,0} %dynamic-slice.858), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.230 (param_0.372: s32[]) -> s32[] {
  %constant.20696 = s32[] constant(64), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_0.372 = s32[] parameter(0)
  %subtract.538 = s32[] subtract(s32[] %constant.20696, s32[] %param_0.372), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant.20695 = s32[] constant(-1)
  %add.4100 = s32[] add(s32[] %subtract.538, s32[] %constant.20695), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant.20694 = s32[] constant(0), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.2758 = pred[] compare(s32[] %add.4100, s32[] %constant.20694), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant.20693 = s32[] constant(63)
  %add.4099 = s32[] add(s32[] %subtract.538, s32[] %constant.20693), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %select.2647 = s32[] select(pred[] %compare.2758, s32[] %add.4099, s32[] %add.4100), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%parallel_add.3702 (p.77: f32[2048,4096], p.78: f32[2048,4096]) -> f32[2048,4096] {
  %p.77 = f32[2048,4096]{1,0} parameter(0)
  %p.78 = f32[2048,4096]{1,0} parameter(1)
  ROOT %add.3702.clone = f32[2048,4096]{1,0} add(f32[2048,4096]{1,0} %p.77, f32[2048,4096]{1,0} %p.78), outer_dimension_partitions={9}, metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
}

%wide.wide.body_computation__197.14838.clone.clone.clone.clone (wide_param.195: (f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[64,8,2048], f32[64,8,1024], /*index=5*/f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], /*index=10*/f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[2048,4096], s32[], /*index=15*/f32[2048,4096], f32[4096], f32[8,2048], f32[64,8,1024])) -> (f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[64,8,2048], f32[64,8,1024], /*index=5*/f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], /*index=10*/f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[2048,4096], s32[], /*index=15*/f32[2048,4096], f32[4096], f32[8,2048], f32[64,8,1024]) {
  %wide_param.195 = (f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) parameter(0)
  %get-tuple-element.27672 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.195), index=0
  %get-tuple-element.27673 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.195), index=1
  %get-tuple-element.27674 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.195), index=2
  %get-tuple-element.27675 = f32[64,8,2048]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.195), index=3
  %get-tuple-element.27676 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.195), index=4
  %get-tuple-element.27677 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.195), index=5
  %get-tuple-element.27678 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.195), index=6
  %get-tuple-element.27679 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.195), index=7
  %get-tuple-element.27680 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.195), index=8
  %get-tuple-element.27681 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.195), index=9
  %get-tuple-element.27682 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.195), index=10
  %get-tuple-element.27683 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.195), index=11
  %get-tuple-element.27684 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.195), index=12
  %get-tuple-element.27685 = f32[2048,4096]{1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.195), index=13
  %get-tuple-element.27686 = s32[] get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.195), index=14
  %copy.859 = s32[] copy(s32[] %get-tuple-element.27686)
  %constant.19660 = s32[] constant(1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.3703 = s32[] add(s32[] %copy.859, s32[] %constant.19660), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.27687 = f32[2048,4096]{1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.195), index=15
  %fusion.230 = s32[] fusion(s32[] %copy.859), kind=kLoop, calls=%fused_computation.230, metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %fusion.229 = f32[8,2048]{1,0} fusion(f32[64,8,2048]{2,1,0} %get-tuple-element.27675, s32[] %fusion.230), kind=kLoop, calls=%fused_computation.229, metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant.19581 = s32[] constant(0), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.27689 = f32[8,2048]{1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.195), index=17
  %fusion.228 = f32[8,4096]{1,0} fusion(f32[64,8,1024]{2,1,0} %get-tuple-element.27673, s32[] %fusion.230, s32[] %constant.19581, f32[64,8,1024]{2,1,0} %get-tuple-element.27676, f32[64,8,1024]{2,1,0} %get-tuple-element.27674, /*index=5*/f32[64,8,1024]{2,1,0} %get-tuple-element.27678, f32[64,8,1024]{2,1,0} %get-tuple-element.27679, f32[64,8,1024]{2,1,0} %get-tuple-element.27680, f32[64,8,1024]{2,1,0} %get-tuple-element.27682, f32[8,2048]{1,0} %get-tuple-element.27689, /*index=10*/f32[64,8,1024]{2,1,0} %get-tuple-element.27677, f32[64,8,1024]{2,1,0} %get-tuple-element.27683, f32[64,8,1024]{2,1,0} %get-tuple-element.27684, f32[64,8,1024]{2,1,0} %get-tuple-element.27672, f32[64,8,1024]{2,1,0} %get-tuple-element.27681), kind=kLoop, calls=%fused_computation.228, metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %dot.186 = f32[2048,4096]{1,0} dot(f32[8,2048]{1,0} %fusion.229, f32[8,4096]{1,0} %fusion.228), lhs_contracting_dims={0}, rhs_contracting_dims={0}, metadata={op_type="transpose" op_name="pmap(_multi_device_update_fn)/scan/while/body/transpose[ permutation=(1, 0) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %call.103 = f32[2048,4096]{1,0} call(f32[2048,4096]{1,0} %get-tuple-element.27687, f32[2048,4096]{1,0} %dot.186), to_apply=%parallel_add.3702
  %get-tuple-element.27688 = f32[4096]{0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.195), index=16
  %constant.19588 = f32[] constant(0), metadata={op_type="pad" op_name="pmap(_multi_device_update_fn)/scan/while/body/pad[ padding_config=((0, 0, 0), (2048, 1024, 0)) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  %reduce.275 = f32[4096]{0} reduce(f32[8,4096]{1,0} %fusion.228, f32[] %constant.19588), dimensions={0}, to_apply=%primitive_computation_add__1.14830, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/scan/while/body/reduce_sum[ axes=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %add.3699 = f32[4096]{0} add(f32[4096]{0} %get-tuple-element.27688, f32[4096]{0} %reduce.275), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %dot.185 = f32[8,2048]{1,0} dot(f32[8,4096]{1,0} %fusion.228, f32[2048,4096]{1,0} %get-tuple-element.27685), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_type="dot_general" op_name="pmap(_multi_device_update_fn)/scan/while/body/dot_general[ dimension_numbers=(((1,), (1,)), ((), ()))\n                                                           precision=None\n                                                           preferred_element_type=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %fusion.227 = f32[8,2048]{1,0} fusion(f32[8,2048]{1,0} %dot.185, f32[64,8,1024]{2,1,0} %get-tuple-element.27673, s32[] %fusion.230, f32[64,8,1024]{2,1,0} %get-tuple-element.27682, f32[8,2048]{1,0} %get-tuple-element.27689, /*index=5*/f32[64,8,1024]{2,1,0} %get-tuple-element.27683, f32[64,8,1024]{2,1,0} %get-tuple-element.27672, f32[64,8,1024]{2,1,0} %get-tuple-element.27681), kind=kLoop, calls=%fused_computation.227, metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %copy.867 = f32[8,2048]{1,0} copy(f32[8,2048]{1,0} %fusion.227)
  %get-tuple-element.27690 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.195), index=18
  %fusion.226 = f32[64,8,1024]{2,1,0} fusion(f32[64,8,1024]{2,1,0} %get-tuple-element.27690, s32[] %fusion.230, f32[8,2048]{1,0} %dot.185), kind=kLoop, calls=%fused_computation.226, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %tuple.1332 = (f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) tuple(f32[64,8,1024]{2,1,0} %get-tuple-element.27672, f32[64,8,1024]{2,1,0} %get-tuple-element.27673, f32[64,8,1024]{2,1,0} %get-tuple-element.27674, f32[64,8,2048]{2,1,0} %get-tuple-element.27675, f32[64,8,1024]{2,1,0} %get-tuple-element.27676, /*index=5*/f32[64,8,1024]{2,1,0} %get-tuple-element.27677, f32[64,8,1024]{2,1,0} %get-tuple-element.27678, f32[64,8,1024]{2,1,0} %get-tuple-element.27679, f32[64,8,1024]{2,1,0} %get-tuple-element.27680, f32[64,8,1024]{2,1,0} %get-tuple-element.27681, /*index=10*/f32[64,8,1024]{2,1,0} %get-tuple-element.27682, f32[64,8,1024]{2,1,0} %get-tuple-element.27683, f32[64,8,1024]{2,1,0} %get-tuple-element.27684, f32[2048,4096]{1,0} %get-tuple-element.27685, s32[] %add.3703, /*index=15*/f32[2048,4096]{1,0} %call.103, f32[4096]{0} %add.3699, f32[8,2048]{1,0} %copy.867, f32[64,8,1024]{2,1,0} %fusion.226)
}

%wide.wide.cond_computation__197.15249.clone.clone.clone.clone (wide_param.196: (f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[64,8,2048], f32[64,8,1024], /*index=5*/f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], /*index=10*/f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[2048,4096], s32[], /*index=15*/f32[2048,4096], f32[4096], f32[8,2048], f32[64,8,1024])) -> pred[] {
  %wide_param.196 = (f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) parameter(0)
  %get-tuple-element.25813 = s32[] get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.196), index=14
  %constant.19694 = s32[] constant(64), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/cond/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %compare.2651 = pred[] compare(s32[] %get-tuple-element.25813, s32[] %constant.19694), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/cond/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%primitive_computation_add__1.15456 (parameter.15457: f32[], parameter.15458: f32[]) -> f32[] {
  %parameter.15457 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.15458 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.15459 = f32[] add(f32[] %parameter.15457, f32[] %parameter.15458), metadata={op_type="add" op_name="add"}
}

%fused_computation.231 (param_0.373: f32[64,8,1024], param_1.759: s32[], param_2.786: f32[8,2048]) -> f32[64,8,1024] {
  %param_0.373 = f32[64,8,1024]{2,1,0} parameter(0)
  %param_2.786 = f32[8,2048]{1,0} parameter(2)
  %slice.1330 = f32[8,1024]{1,0} slice(f32[8,2048]{1,0} %param_2.786), slice={[0:8], [0:1024]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(8, 1024)\n                                                     start_indices=(0, 0)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %reshape.3108 = f32[1,8,1024]{2,1,0} reshape(f32[8,1024]{1,0} %slice.1330), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_1.759 = s32[] parameter(1)
  %constant.20698 = s32[] constant(0), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.885 = f32[64,8,1024]{2,1,0} dynamic-update-slice(f32[64,8,1024]{2,1,0} %param_0.373, f32[1,8,1024]{2,1,0} %reshape.3108, s32[] %param_1.759, s32[] %constant.20698, s32[] %constant.20698), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.232 (param_0.376: f32[8,2048], param_1.765: f32[64,8,1024], param_2.792: s32[], param_3.650: f32[64,8,1024], param_4.340: f32[8,2048], param_5.320: f32[64,8,1024], param_6.250: f32[64,8,1024], param_7.173: f32[64,8,1024]) -> f32[8,2048] {
  %param_0.376 = f32[8,2048]{1,0} parameter(0)
  %slice.1331 = f32[8,1024]{1,0} slice(f32[8,2048]{1,0} %param_0.376), slice={[0:8], [1024:2048]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(8, 2048)\n                                                     start_indices=(0, 1024)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %constant.20699 = f32[] constant(0), metadata={op_type="pad" op_name="pmap(_multi_device_update_fn)/scan/while/body/pad[ padding_config=((0, 0, 0), (2048, 1024, 0)) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  %pad.363 = f32[8,2048]{1,0} pad(f32[8,1024]{1,0} %slice.1331, f32[] %constant.20699), padding=0_0x1024_0, metadata={op_type="pad" op_name="pmap(_multi_device_update_fn)/scan/while/body/pad[ padding_config=((0, 0, 0), (1024, 0, 0)) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=54}
  %param_4.340 = f32[8,2048]{1,0} parameter(4)
  %slice.1332 = f32[8,1024]{1,0} slice(f32[8,2048]{1,0} %param_4.340), slice={[0:8], [0:1024]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(8, 1024)\n                                                     start_indices=(0, 0)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=65}
  %param_6.250 = f32[64,8,1024]{2,1,0} parameter(6)
  %param_2.792 = s32[] parameter(2)
  %constant.20700 = s32[] constant(0), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %dynamic-slice.862 = f32[1,8,1024]{2,1,0} dynamic-slice(f32[64,8,1024]{2,1,0} %param_6.250, s32[] %param_2.792, s32[] %constant.20700, s32[] %constant.20700), dynamic_slice_sizes={1,8,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %reshape.3112 = f32[8,1024]{1,0} reshape(f32[1,8,1024]{2,1,0} %dynamic-slice.862), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %slice.1333 = f32[8,1024]{1,0} slice(f32[8,2048]{1,0} %param_4.340), slice={[0:8], [1024:2048]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(8, 2048)\n                                                     start_indices=(0, 1024)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=65}
  %add.4104 = f32[8,1024]{1,0} add(f32[8,1024]{1,0} %reshape.3112, f32[8,1024]{1,0} %slice.1333), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %param_5.320 = f32[64,8,1024]{2,1,0} parameter(5)
  %dynamic-slice.861 = f32[1,8,1024]{2,1,0} dynamic-slice(f32[64,8,1024]{2,1,0} %param_5.320, s32[] %param_2.792, s32[] %constant.20700, s32[] %constant.20700), dynamic_slice_sizes={1,8,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %reshape.3111 = f32[8,1024]{1,0} reshape(f32[1,8,1024]{2,1,0} %dynamic-slice.861), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.1482 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %add.4104, f32[8,1024]{1,0} %reshape.3111), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  %param_3.650 = f32[64,8,1024]{2,1,0} parameter(3)
  %dynamic-slice.860 = f32[1,8,1024]{2,1,0} dynamic-slice(f32[64,8,1024]{2,1,0} %param_3.650, s32[] %param_2.792, s32[] %constant.20700, s32[] %constant.20700), dynamic_slice_sizes={1,8,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %reshape.3110 = f32[8,1024]{1,0} reshape(f32[1,8,1024]{2,1,0} %dynamic-slice.860), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.1481 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %multiply.1482, f32[8,1024]{1,0} %reshape.3110), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  %add.4103 = f32[8,1024]{1,0} add(f32[8,1024]{1,0} %slice.1332, f32[8,1024]{1,0} %multiply.1481), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %param_7.173 = f32[64,8,1024]{2,1,0} parameter(7)
  %dynamic-slice.863 = f32[1,8,1024]{2,1,0} dynamic-slice(f32[64,8,1024]{2,1,0} %param_7.173, s32[] %param_2.792, s32[] %constant.20700, s32[] %constant.20700), dynamic_slice_sizes={1,8,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %reshape.3113 = f32[8,1024]{1,0} reshape(f32[1,8,1024]{2,1,0} %dynamic-slice.863), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.1480 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %multiply.1481, f32[8,1024]{1,0} %reshape.3113), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  %add.4102 = f32[8,1024]{1,0} add(f32[8,1024]{1,0} %add.4103, f32[8,1024]{1,0} %multiply.1480), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %param_1.765 = f32[64,8,1024]{2,1,0} parameter(1)
  %dynamic-slice.859 = f32[1,8,1024]{2,1,0} dynamic-slice(f32[64,8,1024]{2,1,0} %param_1.765, s32[] %param_2.792, s32[] %constant.20700, s32[] %constant.20700), dynamic_slice_sizes={1,8,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %reshape.3109 = f32[8,1024]{1,0} reshape(f32[1,8,1024]{2,1,0} %dynamic-slice.859), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.1479 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %add.4102, f32[8,1024]{1,0} %reshape.3109), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %pad.362 = f32[8,2048]{1,0} pad(f32[8,1024]{1,0} %multiply.1479, f32[] %constant.20699), padding=0_0x0_1024, metadata={op_type="pad" op_name="pmap(_multi_device_update_fn)/scan/while/body/pad[ padding_config=((0, 0, 0), (0, 1024, 0)) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=54}
  ROOT %add.4101 = f32[8,2048]{1,0} add(f32[8,2048]{1,0} %pad.363, f32[8,2048]{1,0} %pad.362), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
}

%fused_computation.233 (param_0.379: f32[64,8,1024], param_1.770: s32[], param_2.797: s32[], param_3.656: f32[64,8,1024], param_4.344: f32[64,8,1024], param_5.326: f32[64,8,1024], param_6.259: f32[64,8,1024], param_7.182: f32[64,8,1024], param_8.114: f32[64,8,1024], param_9.64: f32[8,2048], param_10.64: f32[64,8,1024], param_11.79: f32[64,8,1024], param_12.74: f32[64,8,1024], param_13.59: f32[64,8,1024], param_14.89: f32[64,8,1024]) -> f32[8,4096] {
  %param_14.89 = f32[64,8,1024]{2,1,0} parameter(14)
  %param_1.770 = s32[] parameter(1)
  %param_2.797 = s32[] parameter(2)
  %dynamic-slice.875 = f32[1,8,1024]{2,1,0} dynamic-slice(f32[64,8,1024]{2,1,0} %param_14.89, s32[] %param_1.770, s32[] %param_2.797, s32[] %param_2.797), dynamic_slice_sizes={1,8,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %reshape.3125 = f32[8,1024]{1,0} reshape(f32[1,8,1024]{2,1,0} %dynamic-slice.875), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_13.59 = f32[64,8,1024]{2,1,0} parameter(13)
  %dynamic-slice.874 = f32[1,8,1024]{2,1,0} dynamic-slice(f32[64,8,1024]{2,1,0} %param_13.59, s32[] %param_1.770, s32[] %param_2.797, s32[] %param_2.797), dynamic_slice_sizes={1,8,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %reshape.3124 = f32[8,1024]{1,0} reshape(f32[1,8,1024]{2,1,0} %dynamic-slice.874), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_9.64 = f32[8,2048]{1,0} parameter(9)
  %slice.1335 = f32[8,1024]{1,0} slice(f32[8,2048]{1,0} %param_9.64), slice={[0:8], [1024:2048]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(8, 2048)\n                                                     start_indices=(0, 1024)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=65}
  %add.4111 = f32[8,1024]{1,0} add(f32[8,1024]{1,0} %reshape.3124, f32[8,1024]{1,0} %slice.1335), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %multiply.1497 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %reshape.3125, f32[8,1024]{1,0} %add.4111), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  %param_12.74 = f32[64,8,1024]{2,1,0} parameter(12)
  %dynamic-slice.873 = f32[1,8,1024]{2,1,0} dynamic-slice(f32[64,8,1024]{2,1,0} %param_12.74, s32[] %param_1.770, s32[] %param_2.797, s32[] %param_2.797), dynamic_slice_sizes={1,8,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %reshape.3123 = f32[8,1024]{1,0} reshape(f32[1,8,1024]{2,1,0} %dynamic-slice.873), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.1496 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %multiply.1497, f32[8,1024]{1,0} %reshape.3123), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %param_11.79 = f32[64,8,1024]{2,1,0} parameter(11)
  %dynamic-slice.872 = f32[1,8,1024]{2,1,0} dynamic-slice(f32[64,8,1024]{2,1,0} %param_11.79, s32[] %param_1.770, s32[] %param_2.797, s32[] %param_2.797), dynamic_slice_sizes={1,8,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %reshape.3122 = f32[8,1024]{1,0} reshape(f32[1,8,1024]{2,1,0} %dynamic-slice.872), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.1495 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %multiply.1496, f32[8,1024]{1,0} %reshape.3122), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %constant.20702 = f32[] constant(0), metadata={op_type="pad" op_name="pmap(_multi_device_update_fn)/scan/while/body/pad[ padding_config=((0, 0, 0), (2048, 1024, 0)) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  %pad.367 = f32[8,4096]{1,0} pad(f32[8,1024]{1,0} %multiply.1495, f32[] %constant.20702), padding=0_0x3072_0, metadata={op_type="pad" op_name="pmap(_multi_device_update_fn)/scan/while/body/pad[ padding_config=((0, 0, 0), (3072, 0, 0)) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  %param_10.64 = f32[64,8,1024]{2,1,0} parameter(10)
  %dynamic-slice.871 = f32[1,8,1024]{2,1,0} dynamic-slice(f32[64,8,1024]{2,1,0} %param_10.64, s32[] %param_1.770, s32[] %param_2.797, s32[] %param_2.797), dynamic_slice_sizes={1,8,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %reshape.3121 = f32[8,1024]{1,0} reshape(f32[1,8,1024]{2,1,0} %dynamic-slice.871), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %slice.1334 = f32[8,1024]{1,0} slice(f32[8,2048]{1,0} %param_9.64), slice={[0:8], [0:1024]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(8, 1024)\n                                                     start_indices=(0, 0)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=65}
  %multiply.1494 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %add.4111, f32[8,1024]{1,0} %reshape.3122), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  %param_8.114 = f32[64,8,1024]{2,1,0} parameter(8)
  %dynamic-slice.870 = f32[1,8,1024]{2,1,0} dynamic-slice(f32[64,8,1024]{2,1,0} %param_8.114, s32[] %param_1.770, s32[] %param_2.797, s32[] %param_2.797), dynamic_slice_sizes={1,8,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %reshape.3120 = f32[8,1024]{1,0} reshape(f32[1,8,1024]{2,1,0} %dynamic-slice.870), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.1493 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %multiply.1494, f32[8,1024]{1,0} %reshape.3120), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  %add.4110 = f32[8,1024]{1,0} add(f32[8,1024]{1,0} %slice.1334, f32[8,1024]{1,0} %multiply.1493), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %multiply.1492 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %multiply.1493, f32[8,1024]{1,0} %reshape.3125), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  %add.4109 = f32[8,1024]{1,0} add(f32[8,1024]{1,0} %add.4110, f32[8,1024]{1,0} %multiply.1492), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %multiply.1491 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %reshape.3121, f32[8,1024]{1,0} %add.4109), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %param_7.182 = f32[64,8,1024]{2,1,0} parameter(7)
  %dynamic-slice.869 = f32[1,8,1024]{2,1,0} dynamic-slice(f32[64,8,1024]{2,1,0} %param_7.182, s32[] %param_1.770, s32[] %param_2.797, s32[] %param_2.797), dynamic_slice_sizes={1,8,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %reshape.3119 = f32[8,1024]{1,0} reshape(f32[1,8,1024]{2,1,0} %dynamic-slice.869), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.1490 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %multiply.1491, f32[8,1024]{1,0} %reshape.3119), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %param_6.259 = f32[64,8,1024]{2,1,0} parameter(6)
  %dynamic-slice.868 = f32[1,8,1024]{2,1,0} dynamic-slice(f32[64,8,1024]{2,1,0} %param_6.259, s32[] %param_1.770, s32[] %param_2.797, s32[] %param_2.797), dynamic_slice_sizes={1,8,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %reshape.3118 = f32[8,1024]{1,0} reshape(f32[1,8,1024]{2,1,0} %dynamic-slice.868), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.1489 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %multiply.1490, f32[8,1024]{1,0} %reshape.3118), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %add.4108 = f32[8,1024]{1,0} add(f32[8,1024]{1,0} %multiply.1490, f32[8,1024]{1,0} %multiply.1489), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %pad.366 = f32[8,4096]{1,0} pad(f32[8,1024]{1,0} %add.4108, f32[] %constant.20702), padding=0_0x1024_2048, metadata={op_type="pad" op_name="pmap(_multi_device_update_fn)/scan/while/body/pad[ padding_config=((0, 0, 0), (1024, 2048, 0)) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  %add.4107 = f32[8,4096]{1,0} add(f32[8,4096]{1,0} %pad.367, f32[8,4096]{1,0} %pad.366), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %multiply.1488 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %add.4109, f32[8,1024]{1,0} %reshape.3118), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %param_5.326 = f32[64,8,1024]{2,1,0} parameter(5)
  %dynamic-slice.867 = f32[1,8,1024]{2,1,0} dynamic-slice(f32[64,8,1024]{2,1,0} %param_5.326, s32[] %param_1.770, s32[] %param_2.797, s32[] %param_2.797), dynamic_slice_sizes={1,8,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %reshape.3117 = f32[8,1024]{1,0} reshape(f32[1,8,1024]{2,1,0} %dynamic-slice.867), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.1487 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %multiply.1488, f32[8,1024]{1,0} %reshape.3117), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %multiply.1486 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %multiply.1487, f32[8,1024]{1,0} %reshape.3121), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %pad.365 = f32[8,4096]{1,0} pad(f32[8,1024]{1,0} %multiply.1486, f32[] %constant.20702), padding=0_0x0_3072, metadata={op_type="pad" op_name="pmap(_multi_device_update_fn)/scan/while/body/pad[ padding_config=((0, 0, 0), (0, 3072, 0)) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  %add.4106 = f32[8,4096]{1,0} add(f32[8,4096]{1,0} %add.4107, f32[8,4096]{1,0} %pad.365), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %param_4.344 = f32[64,8,1024]{2,1,0} parameter(4)
  %dynamic-slice.866 = f32[1,8,1024]{2,1,0} dynamic-slice(f32[64,8,1024]{2,1,0} %param_4.344, s32[] %param_1.770, s32[] %param_2.797, s32[] %param_2.797), dynamic_slice_sizes={1,8,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %reshape.3116 = f32[8,1024]{1,0} reshape(f32[1,8,1024]{2,1,0} %dynamic-slice.866), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.1485 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %reshape.3116, f32[8,1024]{1,0} %add.4109), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %param_3.656 = f32[64,8,1024]{2,1,0} parameter(3)
  %dynamic-slice.865 = f32[1,8,1024]{2,1,0} dynamic-slice(f32[64,8,1024]{2,1,0} %param_3.656, s32[] %param_1.770, s32[] %param_2.797, s32[] %param_2.797), dynamic_slice_sizes={1,8,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %reshape.3115 = f32[8,1024]{1,0} reshape(f32[1,8,1024]{2,1,0} %dynamic-slice.865), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.1484 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %multiply.1485, f32[8,1024]{1,0} %reshape.3115), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %param_0.379 = f32[64,8,1024]{2,1,0} parameter(0)
  %dynamic-slice.864 = f32[1,8,1024]{2,1,0} dynamic-slice(f32[64,8,1024]{2,1,0} %param_0.379, s32[] %param_1.770, s32[] %param_2.797, s32[] %param_2.797), dynamic_slice_sizes={1,8,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %reshape.3114 = f32[8,1024]{1,0} reshape(f32[1,8,1024]{2,1,0} %dynamic-slice.864), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.1483 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %multiply.1484, f32[8,1024]{1,0} %reshape.3114), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %pad.364 = f32[8,4096]{1,0} pad(f32[8,1024]{1,0} %multiply.1483, f32[] %constant.20702), padding=0_0x2048_1024, metadata={op_type="pad" op_name="pmap(_multi_device_update_fn)/scan/while/body/pad[ padding_config=((0, 0, 0), (2048, 1024, 0)) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  ROOT %add.4105 = f32[8,4096]{1,0} add(f32[8,4096]{1,0} %add.4106, f32[8,4096]{1,0} %pad.364), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
}

%fused_computation.234 (param_0.381: f32[64,8,2048], param_1.771: s32[]) -> f32[8,2048] {
  %param_0.381 = f32[64,8,2048]{2,1,0} parameter(0)
  %param_1.771 = s32[] parameter(1)
  %constant.20703 = s32[] constant(0), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %dynamic-slice.876 = f32[1,8,2048]{2,1,0} dynamic-slice(f32[64,8,2048]{2,1,0} %param_0.381, s32[] %param_1.771, s32[] %constant.20703, s32[] %constant.20703), dynamic_slice_sizes={1,8,2048}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 8, 2048) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %reshape.3126 = f32[8,2048]{1,0} reshape(f32[1,8,2048]{2,1,0} %dynamic-slice.876), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.235 (param_0.386: s32[]) -> s32[] {
  %constant.20708 = s32[] constant(64), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_0.386 = s32[] parameter(0)
  %subtract.539 = s32[] subtract(s32[] %constant.20708, s32[] %param_0.386), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant.20706 = s32[] constant(-1)
  %add.4113 = s32[] add(s32[] %subtract.539, s32[] %constant.20706), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant.20705 = s32[] constant(0), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.2759 = pred[] compare(s32[] %add.4113, s32[] %constant.20705), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant.20704 = s32[] constant(63)
  %add.4112 = s32[] add(s32[] %subtract.539, s32[] %constant.20704), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %select.2648 = s32[] select(pred[] %compare.2759, s32[] %add.4112, s32[] %add.4113), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%parallel_add.3732 (p.79: f32[2048,4096], p.80: f32[2048,4096]) -> f32[2048,4096] {
  %p.79 = f32[2048,4096]{1,0} parameter(0)
  %p.80 = f32[2048,4096]{1,0} parameter(1)
  ROOT %add.3732.clone = f32[2048,4096]{1,0} add(f32[2048,4096]{1,0} %p.79, f32[2048,4096]{1,0} %p.80), outer_dimension_partitions={9}, metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
}

%wide.wide.body_computation__198.15464.clone.clone.clone.clone (wide_param.197: (f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[64,8,2048], f32[64,8,1024], /*index=5*/f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], /*index=10*/f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[2048,4096], s32[], /*index=15*/f32[2048,4096], f32[4096], f32[8,2048], f32[64,8,1024])) -> (f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[64,8,2048], f32[64,8,1024], /*index=5*/f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], /*index=10*/f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[2048,4096], s32[], /*index=15*/f32[2048,4096], f32[4096], f32[8,2048], f32[64,8,1024]) {
  %wide_param.197 = (f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) parameter(0)
  %get-tuple-element.27729 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.197), index=0
  %get-tuple-element.27730 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.197), index=1
  %get-tuple-element.27731 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.197), index=2
  %get-tuple-element.27732 = f32[64,8,2048]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.197), index=3
  %get-tuple-element.27733 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.197), index=4
  %get-tuple-element.27734 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.197), index=5
  %get-tuple-element.27735 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.197), index=6
  %get-tuple-element.27736 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.197), index=7
  %get-tuple-element.27737 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.197), index=8
  %get-tuple-element.27738 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.197), index=9
  %get-tuple-element.27739 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.197), index=10
  %get-tuple-element.27740 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.197), index=11
  %get-tuple-element.27741 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.197), index=12
  %get-tuple-element.27742 = f32[2048,4096]{1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.197), index=13
  %get-tuple-element.27743 = s32[] get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.197), index=14
  %copy.874 = s32[] copy(s32[] %get-tuple-element.27743)
  %constant.19791 = s32[] constant(1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.3733 = s32[] add(s32[] %copy.874, s32[] %constant.19791), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.27744 = f32[2048,4096]{1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.197), index=15
  %fusion.235 = s32[] fusion(s32[] %copy.874), kind=kLoop, calls=%fused_computation.235, metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %fusion.234 = f32[8,2048]{1,0} fusion(f32[64,8,2048]{2,1,0} %get-tuple-element.27732, s32[] %fusion.235), kind=kLoop, calls=%fused_computation.234, metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant.19712 = s32[] constant(0), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.27746 = f32[8,2048]{1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.197), index=17
  %fusion.233 = f32[8,4096]{1,0} fusion(f32[64,8,1024]{2,1,0} %get-tuple-element.27730, s32[] %fusion.235, s32[] %constant.19712, f32[64,8,1024]{2,1,0} %get-tuple-element.27733, f32[64,8,1024]{2,1,0} %get-tuple-element.27731, /*index=5*/f32[64,8,1024]{2,1,0} %get-tuple-element.27735, f32[64,8,1024]{2,1,0} %get-tuple-element.27736, f32[64,8,1024]{2,1,0} %get-tuple-element.27737, f32[64,8,1024]{2,1,0} %get-tuple-element.27739, f32[8,2048]{1,0} %get-tuple-element.27746, /*index=10*/f32[64,8,1024]{2,1,0} %get-tuple-element.27734, f32[64,8,1024]{2,1,0} %get-tuple-element.27740, f32[64,8,1024]{2,1,0} %get-tuple-element.27741, f32[64,8,1024]{2,1,0} %get-tuple-element.27729, f32[64,8,1024]{2,1,0} %get-tuple-element.27738), kind=kLoop, calls=%fused_computation.233, metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %dot.188 = f32[2048,4096]{1,0} dot(f32[8,2048]{1,0} %fusion.234, f32[8,4096]{1,0} %fusion.233), lhs_contracting_dims={0}, rhs_contracting_dims={0}, metadata={op_type="transpose" op_name="pmap(_multi_device_update_fn)/scan/while/body/transpose[ permutation=(1, 0) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %call.104 = f32[2048,4096]{1,0} call(f32[2048,4096]{1,0} %get-tuple-element.27744, f32[2048,4096]{1,0} %dot.188), to_apply=%parallel_add.3732
  %get-tuple-element.27745 = f32[4096]{0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.197), index=16
  %constant.19719 = f32[] constant(0), metadata={op_type="pad" op_name="pmap(_multi_device_update_fn)/scan/while/body/pad[ padding_config=((0, 0, 0), (2048, 1024, 0)) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  %reduce.276 = f32[4096]{0} reduce(f32[8,4096]{1,0} %fusion.233, f32[] %constant.19719), dimensions={0}, to_apply=%primitive_computation_add__1.15456, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/scan/while/body/reduce_sum[ axes=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %add.3729 = f32[4096]{0} add(f32[4096]{0} %get-tuple-element.27745, f32[4096]{0} %reduce.276), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %dot.187 = f32[8,2048]{1,0} dot(f32[8,4096]{1,0} %fusion.233, f32[2048,4096]{1,0} %get-tuple-element.27742), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_type="dot_general" op_name="pmap(_multi_device_update_fn)/scan/while/body/dot_general[ dimension_numbers=(((1,), (1,)), ((), ()))\n                                                           precision=None\n                                                           preferred_element_type=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %fusion.232 = f32[8,2048]{1,0} fusion(f32[8,2048]{1,0} %dot.187, f32[64,8,1024]{2,1,0} %get-tuple-element.27730, s32[] %fusion.235, f32[64,8,1024]{2,1,0} %get-tuple-element.27739, f32[8,2048]{1,0} %get-tuple-element.27746, /*index=5*/f32[64,8,1024]{2,1,0} %get-tuple-element.27740, f32[64,8,1024]{2,1,0} %get-tuple-element.27729, f32[64,8,1024]{2,1,0} %get-tuple-element.27738), kind=kLoop, calls=%fused_computation.232, metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %copy.882 = f32[8,2048]{1,0} copy(f32[8,2048]{1,0} %fusion.232)
  %get-tuple-element.27747 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.197), index=18
  %fusion.231 = f32[64,8,1024]{2,1,0} fusion(f32[64,8,1024]{2,1,0} %get-tuple-element.27747, s32[] %fusion.235, f32[8,2048]{1,0} %dot.187), kind=kLoop, calls=%fused_computation.231, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %tuple.1335 = (f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) tuple(f32[64,8,1024]{2,1,0} %get-tuple-element.27729, f32[64,8,1024]{2,1,0} %get-tuple-element.27730, f32[64,8,1024]{2,1,0} %get-tuple-element.27731, f32[64,8,2048]{2,1,0} %get-tuple-element.27732, f32[64,8,1024]{2,1,0} %get-tuple-element.27733, /*index=5*/f32[64,8,1024]{2,1,0} %get-tuple-element.27734, f32[64,8,1024]{2,1,0} %get-tuple-element.27735, f32[64,8,1024]{2,1,0} %get-tuple-element.27736, f32[64,8,1024]{2,1,0} %get-tuple-element.27737, f32[64,8,1024]{2,1,0} %get-tuple-element.27738, /*index=10*/f32[64,8,1024]{2,1,0} %get-tuple-element.27739, f32[64,8,1024]{2,1,0} %get-tuple-element.27740, f32[64,8,1024]{2,1,0} %get-tuple-element.27741, f32[2048,4096]{1,0} %get-tuple-element.27742, s32[] %add.3733, /*index=15*/f32[2048,4096]{1,0} %call.104, f32[4096]{0} %add.3729, f32[8,2048]{1,0} %copy.882, f32[64,8,1024]{2,1,0} %fusion.231)
}

%wide.wide.cond_computation__198.15875.clone.clone.clone.clone (wide_param.198: (f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[64,8,2048], f32[64,8,1024], /*index=5*/f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], /*index=10*/f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[2048,4096], s32[], /*index=15*/f32[2048,4096], f32[4096], f32[8,2048], f32[64,8,1024])) -> pred[] {
  %wide_param.198 = (f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) parameter(0)
  %get-tuple-element.25956 = s32[] get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.198), index=14
  %constant.19827 = s32[] constant(64), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/cond/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %compare.2668 = pred[] compare(s32[] %get-tuple-element.25956, s32[] %constant.19827), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/cond/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%primitive_computation_add__1.15968 (parameter.15969: f32[], parameter.15970: f32[]) -> f32[] {
  %parameter.15969 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.15970 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.15971 = f32[] add(f32[] %parameter.15969, f32[] %parameter.15970), metadata={op_type="add" op_name="add"}
}

%fused_computation.236 (param_0.387: f32[64,8,1024], param_1.778: s32[], param_2.804: f32[8,2048]) -> f32[64,8,1024] {
  %param_0.387 = f32[64,8,1024]{2,1,0} parameter(0)
  %param_2.804 = f32[8,2048]{1,0} parameter(2)
  %slice.1336 = f32[8,1024]{1,0} slice(f32[8,2048]{1,0} %param_2.804), slice={[0:8], [0:1024]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(8, 1024)\n                                                     start_indices=(0, 0)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %reshape.3127 = f32[1,8,1024]{2,1,0} reshape(f32[8,1024]{1,0} %slice.1336), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_1.778 = s32[] parameter(1)
  %constant.20709 = s32[] constant(0), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.886 = f32[64,8,1024]{2,1,0} dynamic-update-slice(f32[64,8,1024]{2,1,0} %param_0.387, f32[1,8,1024]{2,1,0} %reshape.3127, s32[] %param_1.778, s32[] %constant.20709, s32[] %constant.20709), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.237 (param_0.390: f32[8,2048], param_1.784: f32[64,8,1024], param_2.810: s32[], param_3.668: f32[64,8,1024], param_4.349: f32[8,2048], param_5.333: f32[64,8,1024], param_6.268: f32[64,8,1024], param_7.192: f32[64,8,1024]) -> f32[8,2048] {
  %param_0.390 = f32[8,2048]{1,0} parameter(0)
  %slice.1337 = f32[8,1024]{1,0} slice(f32[8,2048]{1,0} %param_0.390), slice={[0:8], [1024:2048]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(8, 2048)\n                                                     start_indices=(0, 1024)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %constant.20710 = f32[] constant(0), metadata={op_type="pad" op_name="pmap(_multi_device_update_fn)/scan/while/body/pad[ padding_config=((0, 0, 0), (2048, 1024, 0)) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  %pad.369 = f32[8,2048]{1,0} pad(f32[8,1024]{1,0} %slice.1337, f32[] %constant.20710), padding=0_0x1024_0, metadata={op_type="pad" op_name="pmap(_multi_device_update_fn)/scan/while/body/pad[ padding_config=((0, 0, 0), (1024, 0, 0)) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=54}
  %param_4.349 = f32[8,2048]{1,0} parameter(4)
  %slice.1338 = f32[8,1024]{1,0} slice(f32[8,2048]{1,0} %param_4.349), slice={[0:8], [0:1024]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(8, 1024)\n                                                     start_indices=(0, 0)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=65}
  %param_6.268 = f32[64,8,1024]{2,1,0} parameter(6)
  %param_2.810 = s32[] parameter(2)
  %constant.20711 = s32[] constant(0), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %dynamic-slice.880 = f32[1,8,1024]{2,1,0} dynamic-slice(f32[64,8,1024]{2,1,0} %param_6.268, s32[] %param_2.810, s32[] %constant.20711, s32[] %constant.20711), dynamic_slice_sizes={1,8,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %reshape.3131 = f32[8,1024]{1,0} reshape(f32[1,8,1024]{2,1,0} %dynamic-slice.880), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %slice.1339 = f32[8,1024]{1,0} slice(f32[8,2048]{1,0} %param_4.349), slice={[0:8], [1024:2048]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(8, 2048)\n                                                     start_indices=(0, 1024)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=65}
  %add.4117 = f32[8,1024]{1,0} add(f32[8,1024]{1,0} %reshape.3131, f32[8,1024]{1,0} %slice.1339), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %param_5.333 = f32[64,8,1024]{2,1,0} parameter(5)
  %dynamic-slice.879 = f32[1,8,1024]{2,1,0} dynamic-slice(f32[64,8,1024]{2,1,0} %param_5.333, s32[] %param_2.810, s32[] %constant.20711, s32[] %constant.20711), dynamic_slice_sizes={1,8,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %reshape.3130 = f32[8,1024]{1,0} reshape(f32[1,8,1024]{2,1,0} %dynamic-slice.879), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.1501 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %add.4117, f32[8,1024]{1,0} %reshape.3130), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  %param_3.668 = f32[64,8,1024]{2,1,0} parameter(3)
  %dynamic-slice.878 = f32[1,8,1024]{2,1,0} dynamic-slice(f32[64,8,1024]{2,1,0} %param_3.668, s32[] %param_2.810, s32[] %constant.20711, s32[] %constant.20711), dynamic_slice_sizes={1,8,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %reshape.3129 = f32[8,1024]{1,0} reshape(f32[1,8,1024]{2,1,0} %dynamic-slice.878), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.1500 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %multiply.1501, f32[8,1024]{1,0} %reshape.3129), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  %add.4116 = f32[8,1024]{1,0} add(f32[8,1024]{1,0} %slice.1338, f32[8,1024]{1,0} %multiply.1500), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %param_7.192 = f32[64,8,1024]{2,1,0} parameter(7)
  %dynamic-slice.881 = f32[1,8,1024]{2,1,0} dynamic-slice(f32[64,8,1024]{2,1,0} %param_7.192, s32[] %param_2.810, s32[] %constant.20711, s32[] %constant.20711), dynamic_slice_sizes={1,8,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %reshape.3132 = f32[8,1024]{1,0} reshape(f32[1,8,1024]{2,1,0} %dynamic-slice.881), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.1499 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %multiply.1500, f32[8,1024]{1,0} %reshape.3132), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  %add.4115 = f32[8,1024]{1,0} add(f32[8,1024]{1,0} %add.4116, f32[8,1024]{1,0} %multiply.1499), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %param_1.784 = f32[64,8,1024]{2,1,0} parameter(1)
  %dynamic-slice.877 = f32[1,8,1024]{2,1,0} dynamic-slice(f32[64,8,1024]{2,1,0} %param_1.784, s32[] %param_2.810, s32[] %constant.20711, s32[] %constant.20711), dynamic_slice_sizes={1,8,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %reshape.3128 = f32[8,1024]{1,0} reshape(f32[1,8,1024]{2,1,0} %dynamic-slice.877), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.1498 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %add.4115, f32[8,1024]{1,0} %reshape.3128), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %pad.368 = f32[8,2048]{1,0} pad(f32[8,1024]{1,0} %multiply.1498, f32[] %constant.20710), padding=0_0x0_1024, metadata={op_type="pad" op_name="pmap(_multi_device_update_fn)/scan/while/body/pad[ padding_config=((0, 0, 0), (0, 1024, 0)) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=54}
  ROOT %add.4114 = f32[8,2048]{1,0} add(f32[8,2048]{1,0} %pad.369, f32[8,2048]{1,0} %pad.368), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
}

%fused_computation.238 (param_0.393: f32[64,8,1024], param_1.789: s32[], param_2.815: s32[], param_3.674: f32[64,8,1024], param_4.353: f32[64,8,1024], param_5.339: f32[64,8,1024], param_6.277: f32[64,8,1024], param_7.201: f32[64,8,1024], param_8.137: f32[64,8,1024], param_9.77: f32[8,2048], param_10.77: f32[64,8,1024], param_11.95: f32[64,8,1024], param_12.89: f32[64,8,1024], param_13.71: f32[64,8,1024], param_14.107: f32[64,8,1024]) -> f32[8,4096] {
  %param_14.107 = f32[64,8,1024]{2,1,0} parameter(14)
  %param_1.789 = s32[] parameter(1)
  %param_2.815 = s32[] parameter(2)
  %dynamic-slice.893 = f32[1,8,1024]{2,1,0} dynamic-slice(f32[64,8,1024]{2,1,0} %param_14.107, s32[] %param_1.789, s32[] %param_2.815, s32[] %param_2.815), dynamic_slice_sizes={1,8,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %reshape.3144 = f32[8,1024]{1,0} reshape(f32[1,8,1024]{2,1,0} %dynamic-slice.893), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_13.71 = f32[64,8,1024]{2,1,0} parameter(13)
  %dynamic-slice.892 = f32[1,8,1024]{2,1,0} dynamic-slice(f32[64,8,1024]{2,1,0} %param_13.71, s32[] %param_1.789, s32[] %param_2.815, s32[] %param_2.815), dynamic_slice_sizes={1,8,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %reshape.3143 = f32[8,1024]{1,0} reshape(f32[1,8,1024]{2,1,0} %dynamic-slice.892), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_9.77 = f32[8,2048]{1,0} parameter(9)
  %slice.1341 = f32[8,1024]{1,0} slice(f32[8,2048]{1,0} %param_9.77), slice={[0:8], [1024:2048]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(8, 2048)\n                                                     start_indices=(0, 1024)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=65}
  %add.4124 = f32[8,1024]{1,0} add(f32[8,1024]{1,0} %reshape.3143, f32[8,1024]{1,0} %slice.1341), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %multiply.1516 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %reshape.3144, f32[8,1024]{1,0} %add.4124), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  %param_12.89 = f32[64,8,1024]{2,1,0} parameter(12)
  %dynamic-slice.891 = f32[1,8,1024]{2,1,0} dynamic-slice(f32[64,8,1024]{2,1,0} %param_12.89, s32[] %param_1.789, s32[] %param_2.815, s32[] %param_2.815), dynamic_slice_sizes={1,8,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %reshape.3142 = f32[8,1024]{1,0} reshape(f32[1,8,1024]{2,1,0} %dynamic-slice.891), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.1515 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %multiply.1516, f32[8,1024]{1,0} %reshape.3142), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %param_11.95 = f32[64,8,1024]{2,1,0} parameter(11)
  %dynamic-slice.890 = f32[1,8,1024]{2,1,0} dynamic-slice(f32[64,8,1024]{2,1,0} %param_11.95, s32[] %param_1.789, s32[] %param_2.815, s32[] %param_2.815), dynamic_slice_sizes={1,8,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %reshape.3141 = f32[8,1024]{1,0} reshape(f32[1,8,1024]{2,1,0} %dynamic-slice.890), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.1514 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %multiply.1515, f32[8,1024]{1,0} %reshape.3141), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %constant.20713 = f32[] constant(0), metadata={op_type="pad" op_name="pmap(_multi_device_update_fn)/scan/while/body/pad[ padding_config=((0, 0, 0), (2048, 1024, 0)) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  %pad.373 = f32[8,4096]{1,0} pad(f32[8,1024]{1,0} %multiply.1514, f32[] %constant.20713), padding=0_0x3072_0, metadata={op_type="pad" op_name="pmap(_multi_device_update_fn)/scan/while/body/pad[ padding_config=((0, 0, 0), (3072, 0, 0)) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  %param_10.77 = f32[64,8,1024]{2,1,0} parameter(10)
  %dynamic-slice.889 = f32[1,8,1024]{2,1,0} dynamic-slice(f32[64,8,1024]{2,1,0} %param_10.77, s32[] %param_1.789, s32[] %param_2.815, s32[] %param_2.815), dynamic_slice_sizes={1,8,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %reshape.3140 = f32[8,1024]{1,0} reshape(f32[1,8,1024]{2,1,0} %dynamic-slice.889), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %slice.1340 = f32[8,1024]{1,0} slice(f32[8,2048]{1,0} %param_9.77), slice={[0:8], [0:1024]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(8, 1024)\n                                                     start_indices=(0, 0)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=65}
  %multiply.1513 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %add.4124, f32[8,1024]{1,0} %reshape.3141), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  %param_8.137 = f32[64,8,1024]{2,1,0} parameter(8)
  %dynamic-slice.888 = f32[1,8,1024]{2,1,0} dynamic-slice(f32[64,8,1024]{2,1,0} %param_8.137, s32[] %param_1.789, s32[] %param_2.815, s32[] %param_2.815), dynamic_slice_sizes={1,8,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %reshape.3139 = f32[8,1024]{1,0} reshape(f32[1,8,1024]{2,1,0} %dynamic-slice.888), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.1512 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %multiply.1513, f32[8,1024]{1,0} %reshape.3139), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  %add.4123 = f32[8,1024]{1,0} add(f32[8,1024]{1,0} %slice.1340, f32[8,1024]{1,0} %multiply.1512), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %multiply.1511 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %multiply.1512, f32[8,1024]{1,0} %reshape.3144), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  %add.4122 = f32[8,1024]{1,0} add(f32[8,1024]{1,0} %add.4123, f32[8,1024]{1,0} %multiply.1511), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %multiply.1510 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %reshape.3140, f32[8,1024]{1,0} %add.4122), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %param_7.201 = f32[64,8,1024]{2,1,0} parameter(7)
  %dynamic-slice.887 = f32[1,8,1024]{2,1,0} dynamic-slice(f32[64,8,1024]{2,1,0} %param_7.201, s32[] %param_1.789, s32[] %param_2.815, s32[] %param_2.815), dynamic_slice_sizes={1,8,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %reshape.3138 = f32[8,1024]{1,0} reshape(f32[1,8,1024]{2,1,0} %dynamic-slice.887), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.1509 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %multiply.1510, f32[8,1024]{1,0} %reshape.3138), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %param_6.277 = f32[64,8,1024]{2,1,0} parameter(6)
  %dynamic-slice.886 = f32[1,8,1024]{2,1,0} dynamic-slice(f32[64,8,1024]{2,1,0} %param_6.277, s32[] %param_1.789, s32[] %param_2.815, s32[] %param_2.815), dynamic_slice_sizes={1,8,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %reshape.3137 = f32[8,1024]{1,0} reshape(f32[1,8,1024]{2,1,0} %dynamic-slice.886), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.1508 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %multiply.1509, f32[8,1024]{1,0} %reshape.3137), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %add.4121 = f32[8,1024]{1,0} add(f32[8,1024]{1,0} %multiply.1509, f32[8,1024]{1,0} %multiply.1508), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %pad.372 = f32[8,4096]{1,0} pad(f32[8,1024]{1,0} %add.4121, f32[] %constant.20713), padding=0_0x1024_2048, metadata={op_type="pad" op_name="pmap(_multi_device_update_fn)/scan/while/body/pad[ padding_config=((0, 0, 0), (1024, 2048, 0)) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  %add.4120 = f32[8,4096]{1,0} add(f32[8,4096]{1,0} %pad.373, f32[8,4096]{1,0} %pad.372), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %multiply.1507 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %add.4122, f32[8,1024]{1,0} %reshape.3137), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %param_5.339 = f32[64,8,1024]{2,1,0} parameter(5)
  %dynamic-slice.885 = f32[1,8,1024]{2,1,0} dynamic-slice(f32[64,8,1024]{2,1,0} %param_5.339, s32[] %param_1.789, s32[] %param_2.815, s32[] %param_2.815), dynamic_slice_sizes={1,8,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %reshape.3136 = f32[8,1024]{1,0} reshape(f32[1,8,1024]{2,1,0} %dynamic-slice.885), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.1506 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %multiply.1507, f32[8,1024]{1,0} %reshape.3136), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %multiply.1505 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %multiply.1506, f32[8,1024]{1,0} %reshape.3140), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %pad.371 = f32[8,4096]{1,0} pad(f32[8,1024]{1,0} %multiply.1505, f32[] %constant.20713), padding=0_0x0_3072, metadata={op_type="pad" op_name="pmap(_multi_device_update_fn)/scan/while/body/pad[ padding_config=((0, 0, 0), (0, 3072, 0)) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  %add.4119 = f32[8,4096]{1,0} add(f32[8,4096]{1,0} %add.4120, f32[8,4096]{1,0} %pad.371), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %param_4.353 = f32[64,8,1024]{2,1,0} parameter(4)
  %dynamic-slice.884 = f32[1,8,1024]{2,1,0} dynamic-slice(f32[64,8,1024]{2,1,0} %param_4.353, s32[] %param_1.789, s32[] %param_2.815, s32[] %param_2.815), dynamic_slice_sizes={1,8,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %reshape.3135 = f32[8,1024]{1,0} reshape(f32[1,8,1024]{2,1,0} %dynamic-slice.884), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.1504 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %reshape.3135, f32[8,1024]{1,0} %add.4122), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %param_3.674 = f32[64,8,1024]{2,1,0} parameter(3)
  %dynamic-slice.883 = f32[1,8,1024]{2,1,0} dynamic-slice(f32[64,8,1024]{2,1,0} %param_3.674, s32[] %param_1.789, s32[] %param_2.815, s32[] %param_2.815), dynamic_slice_sizes={1,8,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %reshape.3134 = f32[8,1024]{1,0} reshape(f32[1,8,1024]{2,1,0} %dynamic-slice.883), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.1503 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %multiply.1504, f32[8,1024]{1,0} %reshape.3134), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %param_0.393 = f32[64,8,1024]{2,1,0} parameter(0)
  %dynamic-slice.882 = f32[1,8,1024]{2,1,0} dynamic-slice(f32[64,8,1024]{2,1,0} %param_0.393, s32[] %param_1.789, s32[] %param_2.815, s32[] %param_2.815), dynamic_slice_sizes={1,8,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %reshape.3133 = f32[8,1024]{1,0} reshape(f32[1,8,1024]{2,1,0} %dynamic-slice.882), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.1502 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %multiply.1503, f32[8,1024]{1,0} %reshape.3133), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %pad.370 = f32[8,4096]{1,0} pad(f32[8,1024]{1,0} %multiply.1502, f32[] %constant.20713), padding=0_0x2048_1024, metadata={op_type="pad" op_name="pmap(_multi_device_update_fn)/scan/while/body/pad[ padding_config=((0, 0, 0), (2048, 1024, 0)) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  ROOT %add.4118 = f32[8,4096]{1,0} add(f32[8,4096]{1,0} %add.4119, f32[8,4096]{1,0} %pad.370), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
}

%fused_computation.239 (param_0.395: f32[64,8,2048], param_1.790: s32[]) -> f32[8,2048] {
  %param_0.395 = f32[64,8,2048]{2,1,0} parameter(0)
  %param_1.790 = s32[] parameter(1)
  %constant.20714 = s32[] constant(0), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %dynamic-slice.894 = f32[1,8,2048]{2,1,0} dynamic-slice(f32[64,8,2048]{2,1,0} %param_0.395, s32[] %param_1.790, s32[] %constant.20714, s32[] %constant.20714), dynamic_slice_sizes={1,8,2048}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 8, 2048) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %reshape.3145 = f32[8,2048]{1,0} reshape(f32[1,8,2048]{2,1,0} %dynamic-slice.894), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.240 (param_0.400: s32[]) -> s32[] {
  %constant.20719 = s32[] constant(64), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_0.400 = s32[] parameter(0)
  %subtract.540 = s32[] subtract(s32[] %constant.20719, s32[] %param_0.400), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant.20718 = s32[] constant(-1)
  %add.4126 = s32[] add(s32[] %subtract.540, s32[] %constant.20718), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant.20716 = s32[] constant(0), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.2760 = pred[] compare(s32[] %add.4126, s32[] %constant.20716), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant.20715 = s32[] constant(63)
  %add.4125 = s32[] add(s32[] %subtract.540, s32[] %constant.20715), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %select.2649 = s32[] select(pred[] %compare.2760, s32[] %add.4125, s32[] %add.4126), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%parallel_add.3761 (p.81: f32[2048,4096], p.82: f32[2048,4096]) -> f32[2048,4096] {
  %p.81 = f32[2048,4096]{1,0} parameter(0)
  %p.82 = f32[2048,4096]{1,0} parameter(1)
  ROOT %add.3761.clone = f32[2048,4096]{1,0} add(f32[2048,4096]{1,0} %p.81, f32[2048,4096]{1,0} %p.82), outer_dimension_partitions={9}, metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
}

%wide.wide.body_computation__199.15976.clone.clone.clone.clone (wide_param.199: (f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[64,8,2048], f32[64,8,1024], /*index=5*/f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], /*index=10*/f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[2048,4096], s32[], /*index=15*/f32[2048,4096], f32[4096], f32[8,2048], f32[64,8,1024])) -> (f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[64,8,2048], f32[64,8,1024], /*index=5*/f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], /*index=10*/f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[2048,4096], s32[], /*index=15*/f32[2048,4096], f32[4096], f32[8,2048], f32[64,8,1024]) {
  %wide_param.199 = (f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) parameter(0)
  %get-tuple-element.27786 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.199), index=0
  %get-tuple-element.27787 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.199), index=1
  %get-tuple-element.27788 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.199), index=2
  %get-tuple-element.27789 = f32[64,8,2048]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.199), index=3
  %get-tuple-element.27790 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.199), index=4
  %get-tuple-element.27791 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.199), index=5
  %get-tuple-element.27792 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.199), index=6
  %get-tuple-element.27793 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.199), index=7
  %get-tuple-element.27794 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.199), index=8
  %get-tuple-element.27795 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.199), index=9
  %get-tuple-element.27796 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.199), index=10
  %get-tuple-element.27797 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.199), index=11
  %get-tuple-element.27798 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.199), index=12
  %get-tuple-element.27799 = f32[2048,4096]{1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.199), index=13
  %get-tuple-element.27800 = s32[] get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.199), index=14
  %copy.889 = s32[] copy(s32[] %get-tuple-element.27800)
  %constant.19922 = s32[] constant(1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.3763 = s32[] add(s32[] %copy.889, s32[] %constant.19922), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.27801 = f32[2048,4096]{1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.199), index=15
  %fusion.240 = s32[] fusion(s32[] %copy.889), kind=kLoop, calls=%fused_computation.240, metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %fusion.239 = f32[8,2048]{1,0} fusion(f32[64,8,2048]{2,1,0} %get-tuple-element.27789, s32[] %fusion.240), kind=kLoop, calls=%fused_computation.239, metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant.19845 = s32[] constant(0), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.27803 = f32[8,2048]{1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.199), index=17
  %fusion.238 = f32[8,4096]{1,0} fusion(f32[64,8,1024]{2,1,0} %get-tuple-element.27787, s32[] %fusion.240, s32[] %constant.19845, f32[64,8,1024]{2,1,0} %get-tuple-element.27790, f32[64,8,1024]{2,1,0} %get-tuple-element.27788, /*index=5*/f32[64,8,1024]{2,1,0} %get-tuple-element.27792, f32[64,8,1024]{2,1,0} %get-tuple-element.27793, f32[64,8,1024]{2,1,0} %get-tuple-element.27794, f32[64,8,1024]{2,1,0} %get-tuple-element.27796, f32[8,2048]{1,0} %get-tuple-element.27803, /*index=10*/f32[64,8,1024]{2,1,0} %get-tuple-element.27791, f32[64,8,1024]{2,1,0} %get-tuple-element.27797, f32[64,8,1024]{2,1,0} %get-tuple-element.27798, f32[64,8,1024]{2,1,0} %get-tuple-element.27786, f32[64,8,1024]{2,1,0} %get-tuple-element.27795), kind=kLoop, calls=%fused_computation.238, metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %dot.190 = f32[2048,4096]{1,0} dot(f32[8,2048]{1,0} %fusion.239, f32[8,4096]{1,0} %fusion.238), lhs_contracting_dims={0}, rhs_contracting_dims={0}, metadata={op_type="transpose" op_name="pmap(_multi_device_update_fn)/scan/while/body/transpose[ permutation=(1, 0) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %call.105 = f32[2048,4096]{1,0} call(f32[2048,4096]{1,0} %get-tuple-element.27801, f32[2048,4096]{1,0} %dot.190), to_apply=%parallel_add.3761
  %get-tuple-element.27802 = f32[4096]{0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.199), index=16
  %constant.19852 = f32[] constant(0), metadata={op_type="pad" op_name="pmap(_multi_device_update_fn)/scan/while/body/pad[ padding_config=((0, 0, 0), (2048, 1024, 0)) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  %reduce.277 = f32[4096]{0} reduce(f32[8,4096]{1,0} %fusion.238, f32[] %constant.19852), dimensions={0}, to_apply=%primitive_computation_add__1.15968, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/scan/while/body/reduce_sum[ axes=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %add.3759 = f32[4096]{0} add(f32[4096]{0} %get-tuple-element.27802, f32[4096]{0} %reduce.277), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %dot.189 = f32[8,2048]{1,0} dot(f32[8,4096]{1,0} %fusion.238, f32[2048,4096]{1,0} %get-tuple-element.27799), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_type="dot_general" op_name="pmap(_multi_device_update_fn)/scan/while/body/dot_general[ dimension_numbers=(((1,), (1,)), ((), ()))\n                                                           precision=None\n                                                           preferred_element_type=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %fusion.237 = f32[8,2048]{1,0} fusion(f32[8,2048]{1,0} %dot.189, f32[64,8,1024]{2,1,0} %get-tuple-element.27787, s32[] %fusion.240, f32[64,8,1024]{2,1,0} %get-tuple-element.27796, f32[8,2048]{1,0} %get-tuple-element.27803, /*index=5*/f32[64,8,1024]{2,1,0} %get-tuple-element.27797, f32[64,8,1024]{2,1,0} %get-tuple-element.27786, f32[64,8,1024]{2,1,0} %get-tuple-element.27795), kind=kLoop, calls=%fused_computation.237, metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %copy.897 = f32[8,2048]{1,0} copy(f32[8,2048]{1,0} %fusion.237)
  %get-tuple-element.27804 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.199), index=18
  %fusion.236 = f32[64,8,1024]{2,1,0} fusion(f32[64,8,1024]{2,1,0} %get-tuple-element.27804, s32[] %fusion.240, f32[8,2048]{1,0} %dot.189), kind=kLoop, calls=%fused_computation.236, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %tuple.1338 = (f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) tuple(f32[64,8,1024]{2,1,0} %get-tuple-element.27786, f32[64,8,1024]{2,1,0} %get-tuple-element.27787, f32[64,8,1024]{2,1,0} %get-tuple-element.27788, f32[64,8,2048]{2,1,0} %get-tuple-element.27789, f32[64,8,1024]{2,1,0} %get-tuple-element.27790, /*index=5*/f32[64,8,1024]{2,1,0} %get-tuple-element.27791, f32[64,8,1024]{2,1,0} %get-tuple-element.27792, f32[64,8,1024]{2,1,0} %get-tuple-element.27793, f32[64,8,1024]{2,1,0} %get-tuple-element.27794, f32[64,8,1024]{2,1,0} %get-tuple-element.27795, /*index=10*/f32[64,8,1024]{2,1,0} %get-tuple-element.27796, f32[64,8,1024]{2,1,0} %get-tuple-element.27797, f32[64,8,1024]{2,1,0} %get-tuple-element.27798, f32[2048,4096]{1,0} %get-tuple-element.27799, s32[] %add.3763, /*index=15*/f32[2048,4096]{1,0} %call.105, f32[4096]{0} %add.3759, f32[8,2048]{1,0} %copy.897, f32[64,8,1024]{2,1,0} %fusion.236)
}

%wide.wide.cond_computation__199.16387.clone.clone.clone.clone (wide_param.200: (f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[64,8,2048], f32[64,8,1024], /*index=5*/f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], /*index=10*/f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[2048,4096], s32[], /*index=15*/f32[2048,4096], f32[4096], f32[8,2048], f32[64,8,1024])) -> pred[] {
  %wide_param.200 = (f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) parameter(0)
  %get-tuple-element.26099 = s32[] get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.200), index=14
  %constant.19957 = s32[] constant(64), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/cond/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %compare.2685 = pred[] compare(s32[] %get-tuple-element.26099, s32[] %constant.19957), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/cond/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%primitive_computation_add__1.16480 (parameter.16481: f32[], parameter.16482: f32[]) -> f32[] {
  %parameter.16481 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.16482 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.16483 = f32[] add(f32[] %parameter.16481, f32[] %parameter.16482), metadata={op_type="add" op_name="add"}
}

%fused_computation.241 (param_0.401: f32[64,8,1024], param_1.797: s32[], param_2.822: f32[8,2048]) -> f32[64,8,1024] {
  %param_0.401 = f32[64,8,1024]{2,1,0} parameter(0)
  %param_2.822 = f32[8,2048]{1,0} parameter(2)
  %slice.1342 = f32[8,1024]{1,0} slice(f32[8,2048]{1,0} %param_2.822), slice={[0:8], [0:1024]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(8, 1024)\n                                                     start_indices=(0, 0)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %reshape.3146 = f32[1,8,1024]{2,1,0} reshape(f32[8,1024]{1,0} %slice.1342), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_1.797 = s32[] parameter(1)
  %constant.20720 = s32[] constant(0), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.887 = f32[64,8,1024]{2,1,0} dynamic-update-slice(f32[64,8,1024]{2,1,0} %param_0.401, f32[1,8,1024]{2,1,0} %reshape.3146, s32[] %param_1.797, s32[] %constant.20720, s32[] %constant.20720), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.242 (param_0.404: f32[8,2048], param_1.803: f32[64,8,1024], param_2.828: s32[], param_3.686: f32[64,8,1024], param_4.358: f32[8,2048], param_5.346: f32[64,8,1024], param_6.286: f32[64,8,1024], param_7.211: f32[64,8,1024]) -> f32[8,2048] {
  %param_0.404 = f32[8,2048]{1,0} parameter(0)
  %slice.1343 = f32[8,1024]{1,0} slice(f32[8,2048]{1,0} %param_0.404), slice={[0:8], [1024:2048]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(8, 2048)\n                                                     start_indices=(0, 1024)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %constant.20721 = f32[] constant(0), metadata={op_type="pad" op_name="pmap(_multi_device_update_fn)/scan/while/body/pad[ padding_config=((0, 0, 0), (2048, 1024, 0)) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  %pad.375 = f32[8,2048]{1,0} pad(f32[8,1024]{1,0} %slice.1343, f32[] %constant.20721), padding=0_0x1024_0, metadata={op_type="pad" op_name="pmap(_multi_device_update_fn)/scan/while/body/pad[ padding_config=((0, 0, 0), (1024, 0, 0)) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=54}
  %param_4.358 = f32[8,2048]{1,0} parameter(4)
  %slice.1344 = f32[8,1024]{1,0} slice(f32[8,2048]{1,0} %param_4.358), slice={[0:8], [0:1024]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(8, 1024)\n                                                     start_indices=(0, 0)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=65}
  %param_6.286 = f32[64,8,1024]{2,1,0} parameter(6)
  %param_2.828 = s32[] parameter(2)
  %constant.20723 = s32[] constant(0), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %dynamic-slice.898 = f32[1,8,1024]{2,1,0} dynamic-slice(f32[64,8,1024]{2,1,0} %param_6.286, s32[] %param_2.828, s32[] %constant.20723, s32[] %constant.20723), dynamic_slice_sizes={1,8,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %reshape.3150 = f32[8,1024]{1,0} reshape(f32[1,8,1024]{2,1,0} %dynamic-slice.898), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %slice.1345 = f32[8,1024]{1,0} slice(f32[8,2048]{1,0} %param_4.358), slice={[0:8], [1024:2048]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(8, 2048)\n                                                     start_indices=(0, 1024)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=65}
  %add.4130 = f32[8,1024]{1,0} add(f32[8,1024]{1,0} %reshape.3150, f32[8,1024]{1,0} %slice.1345), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %param_5.346 = f32[64,8,1024]{2,1,0} parameter(5)
  %dynamic-slice.897 = f32[1,8,1024]{2,1,0} dynamic-slice(f32[64,8,1024]{2,1,0} %param_5.346, s32[] %param_2.828, s32[] %constant.20723, s32[] %constant.20723), dynamic_slice_sizes={1,8,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %reshape.3149 = f32[8,1024]{1,0} reshape(f32[1,8,1024]{2,1,0} %dynamic-slice.897), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.1520 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %add.4130, f32[8,1024]{1,0} %reshape.3149), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  %param_3.686 = f32[64,8,1024]{2,1,0} parameter(3)
  %dynamic-slice.896 = f32[1,8,1024]{2,1,0} dynamic-slice(f32[64,8,1024]{2,1,0} %param_3.686, s32[] %param_2.828, s32[] %constant.20723, s32[] %constant.20723), dynamic_slice_sizes={1,8,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %reshape.3148 = f32[8,1024]{1,0} reshape(f32[1,8,1024]{2,1,0} %dynamic-slice.896), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.1519 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %multiply.1520, f32[8,1024]{1,0} %reshape.3148), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  %add.4129 = f32[8,1024]{1,0} add(f32[8,1024]{1,0} %slice.1344, f32[8,1024]{1,0} %multiply.1519), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %param_7.211 = f32[64,8,1024]{2,1,0} parameter(7)
  %dynamic-slice.899 = f32[1,8,1024]{2,1,0} dynamic-slice(f32[64,8,1024]{2,1,0} %param_7.211, s32[] %param_2.828, s32[] %constant.20723, s32[] %constant.20723), dynamic_slice_sizes={1,8,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %reshape.3151 = f32[8,1024]{1,0} reshape(f32[1,8,1024]{2,1,0} %dynamic-slice.899), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.1518 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %multiply.1519, f32[8,1024]{1,0} %reshape.3151), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  %add.4128 = f32[8,1024]{1,0} add(f32[8,1024]{1,0} %add.4129, f32[8,1024]{1,0} %multiply.1518), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %param_1.803 = f32[64,8,1024]{2,1,0} parameter(1)
  %dynamic-slice.895 = f32[1,8,1024]{2,1,0} dynamic-slice(f32[64,8,1024]{2,1,0} %param_1.803, s32[] %param_2.828, s32[] %constant.20723, s32[] %constant.20723), dynamic_slice_sizes={1,8,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %reshape.3147 = f32[8,1024]{1,0} reshape(f32[1,8,1024]{2,1,0} %dynamic-slice.895), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.1517 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %add.4128, f32[8,1024]{1,0} %reshape.3147), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %pad.374 = f32[8,2048]{1,0} pad(f32[8,1024]{1,0} %multiply.1517, f32[] %constant.20721), padding=0_0x0_1024, metadata={op_type="pad" op_name="pmap(_multi_device_update_fn)/scan/while/body/pad[ padding_config=((0, 0, 0), (0, 1024, 0)) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=54}
  ROOT %add.4127 = f32[8,2048]{1,0} add(f32[8,2048]{1,0} %pad.375, f32[8,2048]{1,0} %pad.374), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
}

%fused_computation.243 (param_0.407: f32[64,8,1024], param_1.808: s32[], param_2.833: s32[], param_3.692: f32[64,8,1024], param_4.362: f32[64,8,1024], param_5.352: f32[64,8,1024], param_6.295: f32[64,8,1024], param_7.220: f32[64,8,1024], param_8.160: f32[64,8,1024], param_9.90: f32[8,2048], param_10.90: f32[64,8,1024], param_11.111: f32[64,8,1024], param_12.104: f32[64,8,1024], param_13.83: f32[64,8,1024], param_14.125: f32[64,8,1024]) -> f32[8,4096] {
  %param_14.125 = f32[64,8,1024]{2,1,0} parameter(14)
  %param_1.808 = s32[] parameter(1)
  %param_2.833 = s32[] parameter(2)
  %dynamic-slice.911 = f32[1,8,1024]{2,1,0} dynamic-slice(f32[64,8,1024]{2,1,0} %param_14.125, s32[] %param_1.808, s32[] %param_2.833, s32[] %param_2.833), dynamic_slice_sizes={1,8,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %reshape.3163 = f32[8,1024]{1,0} reshape(f32[1,8,1024]{2,1,0} %dynamic-slice.911), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_13.83 = f32[64,8,1024]{2,1,0} parameter(13)
  %dynamic-slice.910 = f32[1,8,1024]{2,1,0} dynamic-slice(f32[64,8,1024]{2,1,0} %param_13.83, s32[] %param_1.808, s32[] %param_2.833, s32[] %param_2.833), dynamic_slice_sizes={1,8,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %reshape.3162 = f32[8,1024]{1,0} reshape(f32[1,8,1024]{2,1,0} %dynamic-slice.910), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_9.90 = f32[8,2048]{1,0} parameter(9)
  %slice.1347 = f32[8,1024]{1,0} slice(f32[8,2048]{1,0} %param_9.90), slice={[0:8], [1024:2048]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(8, 2048)\n                                                     start_indices=(0, 1024)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=65}
  %add.4137 = f32[8,1024]{1,0} add(f32[8,1024]{1,0} %reshape.3162, f32[8,1024]{1,0} %slice.1347), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %multiply.1535 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %reshape.3163, f32[8,1024]{1,0} %add.4137), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  %param_12.104 = f32[64,8,1024]{2,1,0} parameter(12)
  %dynamic-slice.909 = f32[1,8,1024]{2,1,0} dynamic-slice(f32[64,8,1024]{2,1,0} %param_12.104, s32[] %param_1.808, s32[] %param_2.833, s32[] %param_2.833), dynamic_slice_sizes={1,8,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %reshape.3161 = f32[8,1024]{1,0} reshape(f32[1,8,1024]{2,1,0} %dynamic-slice.909), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.1534 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %multiply.1535, f32[8,1024]{1,0} %reshape.3161), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %param_11.111 = f32[64,8,1024]{2,1,0} parameter(11)
  %dynamic-slice.908 = f32[1,8,1024]{2,1,0} dynamic-slice(f32[64,8,1024]{2,1,0} %param_11.111, s32[] %param_1.808, s32[] %param_2.833, s32[] %param_2.833), dynamic_slice_sizes={1,8,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %reshape.3160 = f32[8,1024]{1,0} reshape(f32[1,8,1024]{2,1,0} %dynamic-slice.908), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.1533 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %multiply.1534, f32[8,1024]{1,0} %reshape.3160), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %constant.20724 = f32[] constant(0), metadata={op_type="pad" op_name="pmap(_multi_device_update_fn)/scan/while/body/pad[ padding_config=((0, 0, 0), (2048, 1024, 0)) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  %pad.379 = f32[8,4096]{1,0} pad(f32[8,1024]{1,0} %multiply.1533, f32[] %constant.20724), padding=0_0x3072_0, metadata={op_type="pad" op_name="pmap(_multi_device_update_fn)/scan/while/body/pad[ padding_config=((0, 0, 0), (3072, 0, 0)) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  %param_10.90 = f32[64,8,1024]{2,1,0} parameter(10)
  %dynamic-slice.907 = f32[1,8,1024]{2,1,0} dynamic-slice(f32[64,8,1024]{2,1,0} %param_10.90, s32[] %param_1.808, s32[] %param_2.833, s32[] %param_2.833), dynamic_slice_sizes={1,8,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %reshape.3159 = f32[8,1024]{1,0} reshape(f32[1,8,1024]{2,1,0} %dynamic-slice.907), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %slice.1346 = f32[8,1024]{1,0} slice(f32[8,2048]{1,0} %param_9.90), slice={[0:8], [0:1024]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(8, 1024)\n                                                     start_indices=(0, 0)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=65}
  %multiply.1532 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %add.4137, f32[8,1024]{1,0} %reshape.3160), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  %param_8.160 = f32[64,8,1024]{2,1,0} parameter(8)
  %dynamic-slice.906 = f32[1,8,1024]{2,1,0} dynamic-slice(f32[64,8,1024]{2,1,0} %param_8.160, s32[] %param_1.808, s32[] %param_2.833, s32[] %param_2.833), dynamic_slice_sizes={1,8,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %reshape.3158 = f32[8,1024]{1,0} reshape(f32[1,8,1024]{2,1,0} %dynamic-slice.906), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.1531 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %multiply.1532, f32[8,1024]{1,0} %reshape.3158), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  %add.4136 = f32[8,1024]{1,0} add(f32[8,1024]{1,0} %slice.1346, f32[8,1024]{1,0} %multiply.1531), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %multiply.1530 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %multiply.1531, f32[8,1024]{1,0} %reshape.3163), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  %add.4135 = f32[8,1024]{1,0} add(f32[8,1024]{1,0} %add.4136, f32[8,1024]{1,0} %multiply.1530), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %multiply.1529 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %reshape.3159, f32[8,1024]{1,0} %add.4135), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %param_7.220 = f32[64,8,1024]{2,1,0} parameter(7)
  %dynamic-slice.905 = f32[1,8,1024]{2,1,0} dynamic-slice(f32[64,8,1024]{2,1,0} %param_7.220, s32[] %param_1.808, s32[] %param_2.833, s32[] %param_2.833), dynamic_slice_sizes={1,8,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %reshape.3157 = f32[8,1024]{1,0} reshape(f32[1,8,1024]{2,1,0} %dynamic-slice.905), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.1528 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %multiply.1529, f32[8,1024]{1,0} %reshape.3157), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %param_6.295 = f32[64,8,1024]{2,1,0} parameter(6)
  %dynamic-slice.904 = f32[1,8,1024]{2,1,0} dynamic-slice(f32[64,8,1024]{2,1,0} %param_6.295, s32[] %param_1.808, s32[] %param_2.833, s32[] %param_2.833), dynamic_slice_sizes={1,8,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %reshape.3156 = f32[8,1024]{1,0} reshape(f32[1,8,1024]{2,1,0} %dynamic-slice.904), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.1527 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %multiply.1528, f32[8,1024]{1,0} %reshape.3156), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %add.4134 = f32[8,1024]{1,0} add(f32[8,1024]{1,0} %multiply.1528, f32[8,1024]{1,0} %multiply.1527), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %pad.378 = f32[8,4096]{1,0} pad(f32[8,1024]{1,0} %add.4134, f32[] %constant.20724), padding=0_0x1024_2048, metadata={op_type="pad" op_name="pmap(_multi_device_update_fn)/scan/while/body/pad[ padding_config=((0, 0, 0), (1024, 2048, 0)) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  %add.4133 = f32[8,4096]{1,0} add(f32[8,4096]{1,0} %pad.379, f32[8,4096]{1,0} %pad.378), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %multiply.1526 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %add.4135, f32[8,1024]{1,0} %reshape.3156), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %param_5.352 = f32[64,8,1024]{2,1,0} parameter(5)
  %dynamic-slice.903 = f32[1,8,1024]{2,1,0} dynamic-slice(f32[64,8,1024]{2,1,0} %param_5.352, s32[] %param_1.808, s32[] %param_2.833, s32[] %param_2.833), dynamic_slice_sizes={1,8,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %reshape.3155 = f32[8,1024]{1,0} reshape(f32[1,8,1024]{2,1,0} %dynamic-slice.903), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.1525 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %multiply.1526, f32[8,1024]{1,0} %reshape.3155), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %multiply.1524 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %multiply.1525, f32[8,1024]{1,0} %reshape.3159), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %pad.377 = f32[8,4096]{1,0} pad(f32[8,1024]{1,0} %multiply.1524, f32[] %constant.20724), padding=0_0x0_3072, metadata={op_type="pad" op_name="pmap(_multi_device_update_fn)/scan/while/body/pad[ padding_config=((0, 0, 0), (0, 3072, 0)) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  %add.4132 = f32[8,4096]{1,0} add(f32[8,4096]{1,0} %add.4133, f32[8,4096]{1,0} %pad.377), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %param_4.362 = f32[64,8,1024]{2,1,0} parameter(4)
  %dynamic-slice.902 = f32[1,8,1024]{2,1,0} dynamic-slice(f32[64,8,1024]{2,1,0} %param_4.362, s32[] %param_1.808, s32[] %param_2.833, s32[] %param_2.833), dynamic_slice_sizes={1,8,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %reshape.3154 = f32[8,1024]{1,0} reshape(f32[1,8,1024]{2,1,0} %dynamic-slice.902), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.1523 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %reshape.3154, f32[8,1024]{1,0} %add.4135), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %param_3.692 = f32[64,8,1024]{2,1,0} parameter(3)
  %dynamic-slice.901 = f32[1,8,1024]{2,1,0} dynamic-slice(f32[64,8,1024]{2,1,0} %param_3.692, s32[] %param_1.808, s32[] %param_2.833, s32[] %param_2.833), dynamic_slice_sizes={1,8,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %reshape.3153 = f32[8,1024]{1,0} reshape(f32[1,8,1024]{2,1,0} %dynamic-slice.901), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.1522 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %multiply.1523, f32[8,1024]{1,0} %reshape.3153), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %param_0.407 = f32[64,8,1024]{2,1,0} parameter(0)
  %dynamic-slice.900 = f32[1,8,1024]{2,1,0} dynamic-slice(f32[64,8,1024]{2,1,0} %param_0.407, s32[] %param_1.808, s32[] %param_2.833, s32[] %param_2.833), dynamic_slice_sizes={1,8,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %reshape.3152 = f32[8,1024]{1,0} reshape(f32[1,8,1024]{2,1,0} %dynamic-slice.900), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.1521 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %multiply.1522, f32[8,1024]{1,0} %reshape.3152), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %pad.376 = f32[8,4096]{1,0} pad(f32[8,1024]{1,0} %multiply.1521, f32[] %constant.20724), padding=0_0x2048_1024, metadata={op_type="pad" op_name="pmap(_multi_device_update_fn)/scan/while/body/pad[ padding_config=((0, 0, 0), (2048, 1024, 0)) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  ROOT %add.4131 = f32[8,4096]{1,0} add(f32[8,4096]{1,0} %add.4132, f32[8,4096]{1,0} %pad.376), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
}

%fused_computation.244 (param_0.409: f32[64,8,2048], param_1.809: s32[]) -> f32[8,2048] {
  %param_0.409 = f32[64,8,2048]{2,1,0} parameter(0)
  %param_1.809 = s32[] parameter(1)
  %constant.20725 = s32[] constant(0), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %dynamic-slice.912 = f32[1,8,2048]{2,1,0} dynamic-slice(f32[64,8,2048]{2,1,0} %param_0.409, s32[] %param_1.809, s32[] %constant.20725, s32[] %constant.20725), dynamic_slice_sizes={1,8,2048}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 8, 2048) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %reshape.3164 = f32[8,2048]{1,0} reshape(f32[1,8,2048]{2,1,0} %dynamic-slice.912), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.245 (param_0.414: s32[]) -> s32[] {
  %constant.20729 = s32[] constant(64), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_0.414 = s32[] parameter(0)
  %subtract.541 = s32[] subtract(s32[] %constant.20729, s32[] %param_0.414), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant.20728 = s32[] constant(-1)
  %add.4139 = s32[] add(s32[] %subtract.541, s32[] %constant.20728), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant.20727 = s32[] constant(0), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.2761 = pred[] compare(s32[] %add.4139, s32[] %constant.20727), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant.20726 = s32[] constant(63)
  %add.4138 = s32[] add(s32[] %subtract.541, s32[] %constant.20726), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %select.2650 = s32[] select(pred[] %compare.2761, s32[] %add.4138, s32[] %add.4139), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%parallel_add.3791 (p.83: f32[2048,4096], p.84: f32[2048,4096]) -> f32[2048,4096] {
  %p.83 = f32[2048,4096]{1,0} parameter(0)
  %p.84 = f32[2048,4096]{1,0} parameter(1)
  ROOT %add.3791.clone = f32[2048,4096]{1,0} add(f32[2048,4096]{1,0} %p.83, f32[2048,4096]{1,0} %p.84), outer_dimension_partitions={9}, metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
}

%wide.wide.body_computation__200.16488.clone.clone.clone.clone (wide_param.201: (f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[64,8,2048], f32[64,8,1024], /*index=5*/f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], /*index=10*/f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[2048,4096], s32[], /*index=15*/f32[2048,4096], f32[4096], f32[8,2048], f32[64,8,1024])) -> (f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[64,8,2048], f32[64,8,1024], /*index=5*/f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], /*index=10*/f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[2048,4096], s32[], /*index=15*/f32[2048,4096], f32[4096], f32[8,2048], f32[64,8,1024]) {
  %wide_param.201 = (f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) parameter(0)
  %get-tuple-element.27843 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.201), index=0
  %get-tuple-element.27844 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.201), index=1
  %get-tuple-element.27845 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.201), index=2
  %get-tuple-element.27846 = f32[64,8,2048]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.201), index=3
  %get-tuple-element.27847 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.201), index=4
  %get-tuple-element.27848 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.201), index=5
  %get-tuple-element.27849 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.201), index=6
  %get-tuple-element.27850 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.201), index=7
  %get-tuple-element.27851 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.201), index=8
  %get-tuple-element.27852 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.201), index=9
  %get-tuple-element.27853 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.201), index=10
  %get-tuple-element.27854 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.201), index=11
  %get-tuple-element.27855 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.201), index=12
  %get-tuple-element.27856 = f32[2048,4096]{1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.201), index=13
  %get-tuple-element.27857 = s32[] get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.201), index=14
  %copy.904 = s32[] copy(s32[] %get-tuple-element.27857)
  %constant.20055 = s32[] constant(1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.3793 = s32[] add(s32[] %copy.904, s32[] %constant.20055), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.27858 = f32[2048,4096]{1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.201), index=15
  %fusion.245 = s32[] fusion(s32[] %copy.904), kind=kLoop, calls=%fused_computation.245, metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %fusion.244 = f32[8,2048]{1,0} fusion(f32[64,8,2048]{2,1,0} %get-tuple-element.27846, s32[] %fusion.245), kind=kLoop, calls=%fused_computation.244, metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant.19976 = s32[] constant(0), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.27860 = f32[8,2048]{1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.201), index=17
  %fusion.243 = f32[8,4096]{1,0} fusion(f32[64,8,1024]{2,1,0} %get-tuple-element.27844, s32[] %fusion.245, s32[] %constant.19976, f32[64,8,1024]{2,1,0} %get-tuple-element.27847, f32[64,8,1024]{2,1,0} %get-tuple-element.27845, /*index=5*/f32[64,8,1024]{2,1,0} %get-tuple-element.27849, f32[64,8,1024]{2,1,0} %get-tuple-element.27850, f32[64,8,1024]{2,1,0} %get-tuple-element.27851, f32[64,8,1024]{2,1,0} %get-tuple-element.27853, f32[8,2048]{1,0} %get-tuple-element.27860, /*index=10*/f32[64,8,1024]{2,1,0} %get-tuple-element.27848, f32[64,8,1024]{2,1,0} %get-tuple-element.27854, f32[64,8,1024]{2,1,0} %get-tuple-element.27855, f32[64,8,1024]{2,1,0} %get-tuple-element.27843, f32[64,8,1024]{2,1,0} %get-tuple-element.27852), kind=kLoop, calls=%fused_computation.243, metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %dot.192 = f32[2048,4096]{1,0} dot(f32[8,2048]{1,0} %fusion.244, f32[8,4096]{1,0} %fusion.243), lhs_contracting_dims={0}, rhs_contracting_dims={0}, metadata={op_type="transpose" op_name="pmap(_multi_device_update_fn)/scan/while/body/transpose[ permutation=(1, 0) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %call.106 = f32[2048,4096]{1,0} call(f32[2048,4096]{1,0} %get-tuple-element.27858, f32[2048,4096]{1,0} %dot.192), to_apply=%parallel_add.3791
  %get-tuple-element.27859 = f32[4096]{0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.201), index=16
  %constant.19983 = f32[] constant(0), metadata={op_type="pad" op_name="pmap(_multi_device_update_fn)/scan/while/body/pad[ padding_config=((0, 0, 0), (2048, 1024, 0)) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  %reduce.278 = f32[4096]{0} reduce(f32[8,4096]{1,0} %fusion.243, f32[] %constant.19983), dimensions={0}, to_apply=%primitive_computation_add__1.16480, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/scan/while/body/reduce_sum[ axes=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %add.3789 = f32[4096]{0} add(f32[4096]{0} %get-tuple-element.27859, f32[4096]{0} %reduce.278), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %dot.191 = f32[8,2048]{1,0} dot(f32[8,4096]{1,0} %fusion.243, f32[2048,4096]{1,0} %get-tuple-element.27856), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_type="dot_general" op_name="pmap(_multi_device_update_fn)/scan/while/body/dot_general[ dimension_numbers=(((1,), (1,)), ((), ()))\n                                                           precision=None\n                                                           preferred_element_type=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %fusion.242 = f32[8,2048]{1,0} fusion(f32[8,2048]{1,0} %dot.191, f32[64,8,1024]{2,1,0} %get-tuple-element.27844, s32[] %fusion.245, f32[64,8,1024]{2,1,0} %get-tuple-element.27853, f32[8,2048]{1,0} %get-tuple-element.27860, /*index=5*/f32[64,8,1024]{2,1,0} %get-tuple-element.27854, f32[64,8,1024]{2,1,0} %get-tuple-element.27843, f32[64,8,1024]{2,1,0} %get-tuple-element.27852), kind=kLoop, calls=%fused_computation.242, metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %copy.912 = f32[8,2048]{1,0} copy(f32[8,2048]{1,0} %fusion.242)
  %get-tuple-element.27861 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.201), index=18
  %fusion.241 = f32[64,8,1024]{2,1,0} fusion(f32[64,8,1024]{2,1,0} %get-tuple-element.27861, s32[] %fusion.245, f32[8,2048]{1,0} %dot.191), kind=kLoop, calls=%fused_computation.241, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %tuple.1341 = (f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) tuple(f32[64,8,1024]{2,1,0} %get-tuple-element.27843, f32[64,8,1024]{2,1,0} %get-tuple-element.27844, f32[64,8,1024]{2,1,0} %get-tuple-element.27845, f32[64,8,2048]{2,1,0} %get-tuple-element.27846, f32[64,8,1024]{2,1,0} %get-tuple-element.27847, /*index=5*/f32[64,8,1024]{2,1,0} %get-tuple-element.27848, f32[64,8,1024]{2,1,0} %get-tuple-element.27849, f32[64,8,1024]{2,1,0} %get-tuple-element.27850, f32[64,8,1024]{2,1,0} %get-tuple-element.27851, f32[64,8,1024]{2,1,0} %get-tuple-element.27852, /*index=10*/f32[64,8,1024]{2,1,0} %get-tuple-element.27853, f32[64,8,1024]{2,1,0} %get-tuple-element.27854, f32[64,8,1024]{2,1,0} %get-tuple-element.27855, f32[2048,4096]{1,0} %get-tuple-element.27856, s32[] %add.3793, /*index=15*/f32[2048,4096]{1,0} %call.106, f32[4096]{0} %add.3789, f32[8,2048]{1,0} %copy.912, f32[64,8,1024]{2,1,0} %fusion.241)
}

%wide.wide.cond_computation__200.16899.clone.clone.clone.clone (wide_param.202: (f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[64,8,2048], f32[64,8,1024], /*index=5*/f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], /*index=10*/f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[2048,4096], s32[], /*index=15*/f32[2048,4096], f32[4096], f32[8,2048], f32[64,8,1024])) -> pred[] {
  %wide_param.202 = (f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) parameter(0)
  %get-tuple-element.26242 = s32[] get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.202), index=14
  %constant.20088 = s32[] constant(64), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/cond/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %compare.2703 = pred[] compare(s32[] %get-tuple-element.26242, s32[] %constant.20088), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/cond/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%primitive_computation_add__1.16992 (parameter.16993: f32[], parameter.16994: f32[]) -> f32[] {
  %parameter.16993 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.16994 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.16995 = f32[] add(f32[] %parameter.16993, f32[] %parameter.16994), metadata={op_type="add" op_name="add"}
}

%fused_computation.246 (param_0.415: f32[64,8,1024], param_1.816: s32[], param_2.840: f32[8,2048]) -> f32[64,8,1024] {
  %param_0.415 = f32[64,8,1024]{2,1,0} parameter(0)
  %param_2.840 = f32[8,2048]{1,0} parameter(2)
  %slice.1348 = f32[8,1024]{1,0} slice(f32[8,2048]{1,0} %param_2.840), slice={[0:8], [0:1024]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(8, 1024)\n                                                     start_indices=(0, 0)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %reshape.3165 = f32[1,8,1024]{2,1,0} reshape(f32[8,1024]{1,0} %slice.1348), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_1.816 = s32[] parameter(1)
  %constant.20731 = s32[] constant(0), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.888 = f32[64,8,1024]{2,1,0} dynamic-update-slice(f32[64,8,1024]{2,1,0} %param_0.415, f32[1,8,1024]{2,1,0} %reshape.3165, s32[] %param_1.816, s32[] %constant.20731, s32[] %constant.20731), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.247 (param_0.418: f32[8,2048], param_1.822: f32[64,8,1024], param_2.846: s32[], param_3.704: f32[64,8,1024], param_4.367: f32[8,2048], param_5.359: f32[64,8,1024], param_6.304: f32[64,8,1024], param_7.230: f32[64,8,1024]) -> f32[8,2048] {
  %param_0.418 = f32[8,2048]{1,0} parameter(0)
  %slice.1349 = f32[8,1024]{1,0} slice(f32[8,2048]{1,0} %param_0.418), slice={[0:8], [1024:2048]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(8, 2048)\n                                                     start_indices=(0, 1024)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %constant.20732 = f32[] constant(0), metadata={op_type="pad" op_name="pmap(_multi_device_update_fn)/scan/while/body/pad[ padding_config=((0, 0, 0), (2048, 1024, 0)) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  %pad.381 = f32[8,2048]{1,0} pad(f32[8,1024]{1,0} %slice.1349, f32[] %constant.20732), padding=0_0x1024_0, metadata={op_type="pad" op_name="pmap(_multi_device_update_fn)/scan/while/body/pad[ padding_config=((0, 0, 0), (1024, 0, 0)) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=54}
  %param_4.367 = f32[8,2048]{1,0} parameter(4)
  %slice.1350 = f32[8,1024]{1,0} slice(f32[8,2048]{1,0} %param_4.367), slice={[0:8], [0:1024]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(8, 1024)\n                                                     start_indices=(0, 0)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=65}
  %param_6.304 = f32[64,8,1024]{2,1,0} parameter(6)
  %param_2.846 = s32[] parameter(2)
  %constant.20733 = s32[] constant(0), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %dynamic-slice.916 = f32[1,8,1024]{2,1,0} dynamic-slice(f32[64,8,1024]{2,1,0} %param_6.304, s32[] %param_2.846, s32[] %constant.20733, s32[] %constant.20733), dynamic_slice_sizes={1,8,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %reshape.3171 = f32[8,1024]{1,0} reshape(f32[1,8,1024]{2,1,0} %dynamic-slice.916), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %slice.1351 = f32[8,1024]{1,0} slice(f32[8,2048]{1,0} %param_4.367), slice={[0:8], [1024:2048]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(8, 2048)\n                                                     start_indices=(0, 1024)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=65}
  %add.4144 = f32[8,1024]{1,0} add(f32[8,1024]{1,0} %reshape.3171, f32[8,1024]{1,0} %slice.1351), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %param_5.359 = f32[64,8,1024]{2,1,0} parameter(5)
  %dynamic-slice.915 = f32[1,8,1024]{2,1,0} dynamic-slice(f32[64,8,1024]{2,1,0} %param_5.359, s32[] %param_2.846, s32[] %constant.20733, s32[] %constant.20733), dynamic_slice_sizes={1,8,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %reshape.3170 = f32[8,1024]{1,0} reshape(f32[1,8,1024]{2,1,0} %dynamic-slice.915), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.1539 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %add.4144, f32[8,1024]{1,0} %reshape.3170), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  %param_3.704 = f32[64,8,1024]{2,1,0} parameter(3)
  %dynamic-slice.914 = f32[1,8,1024]{2,1,0} dynamic-slice(f32[64,8,1024]{2,1,0} %param_3.704, s32[] %param_2.846, s32[] %constant.20733, s32[] %constant.20733), dynamic_slice_sizes={1,8,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %reshape.3168 = f32[8,1024]{1,0} reshape(f32[1,8,1024]{2,1,0} %dynamic-slice.914), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.1538 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %multiply.1539, f32[8,1024]{1,0} %reshape.3168), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  %add.4143 = f32[8,1024]{1,0} add(f32[8,1024]{1,0} %slice.1350, f32[8,1024]{1,0} %multiply.1538), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %param_7.230 = f32[64,8,1024]{2,1,0} parameter(7)
  %dynamic-slice.917 = f32[1,8,1024]{2,1,0} dynamic-slice(f32[64,8,1024]{2,1,0} %param_7.230, s32[] %param_2.846, s32[] %constant.20733, s32[] %constant.20733), dynamic_slice_sizes={1,8,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %reshape.3172 = f32[8,1024]{1,0} reshape(f32[1,8,1024]{2,1,0} %dynamic-slice.917), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.1537 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %multiply.1538, f32[8,1024]{1,0} %reshape.3172), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  %add.4142 = f32[8,1024]{1,0} add(f32[8,1024]{1,0} %add.4143, f32[8,1024]{1,0} %multiply.1537), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %param_1.822 = f32[64,8,1024]{2,1,0} parameter(1)
  %dynamic-slice.913 = f32[1,8,1024]{2,1,0} dynamic-slice(f32[64,8,1024]{2,1,0} %param_1.822, s32[] %param_2.846, s32[] %constant.20733, s32[] %constant.20733), dynamic_slice_sizes={1,8,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %reshape.3166 = f32[8,1024]{1,0} reshape(f32[1,8,1024]{2,1,0} %dynamic-slice.913), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.1536 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %add.4142, f32[8,1024]{1,0} %reshape.3166), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %pad.380 = f32[8,2048]{1,0} pad(f32[8,1024]{1,0} %multiply.1536, f32[] %constant.20732), padding=0_0x0_1024, metadata={op_type="pad" op_name="pmap(_multi_device_update_fn)/scan/while/body/pad[ padding_config=((0, 0, 0), (0, 1024, 0)) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=54}
  ROOT %add.4141 = f32[8,2048]{1,0} add(f32[8,2048]{1,0} %pad.381, f32[8,2048]{1,0} %pad.380), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
}

%fused_computation.248 (param_0.421: f32[64,8,1024], param_1.827: s32[], param_2.851: s32[], param_3.710: f32[64,8,1024], param_4.371: f32[64,8,1024], param_5.365: f32[64,8,1024], param_6.313: f32[64,8,1024], param_7.239: f32[64,8,1024], param_8.183: f32[64,8,1024], param_9.103: f32[8,2048], param_10.103: f32[64,8,1024], param_11.127: f32[64,8,1024], param_12.119: f32[64,8,1024], param_13.95: f32[64,8,1024], param_14.143: f32[64,8,1024]) -> f32[8,4096] {
  %param_14.143 = f32[64,8,1024]{2,1,0} parameter(14)
  %param_1.827 = s32[] parameter(1)
  %param_2.851 = s32[] parameter(2)
  %dynamic-slice.929 = f32[1,8,1024]{2,1,0} dynamic-slice(f32[64,8,1024]{2,1,0} %param_14.143, s32[] %param_1.827, s32[] %param_2.851, s32[] %param_2.851), dynamic_slice_sizes={1,8,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %reshape.3184 = f32[8,1024]{1,0} reshape(f32[1,8,1024]{2,1,0} %dynamic-slice.929), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_13.95 = f32[64,8,1024]{2,1,0} parameter(13)
  %dynamic-slice.928 = f32[1,8,1024]{2,1,0} dynamic-slice(f32[64,8,1024]{2,1,0} %param_13.95, s32[] %param_1.827, s32[] %param_2.851, s32[] %param_2.851), dynamic_slice_sizes={1,8,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %reshape.3183 = f32[8,1024]{1,0} reshape(f32[1,8,1024]{2,1,0} %dynamic-slice.928), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_9.103 = f32[8,2048]{1,0} parameter(9)
  %slice.1353 = f32[8,1024]{1,0} slice(f32[8,2048]{1,0} %param_9.103), slice={[0:8], [1024:2048]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(8, 2048)\n                                                     start_indices=(0, 1024)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=65}
  %add.4152 = f32[8,1024]{1,0} add(f32[8,1024]{1,0} %reshape.3183, f32[8,1024]{1,0} %slice.1353), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %multiply.1554 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %reshape.3184, f32[8,1024]{1,0} %add.4152), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  %param_12.119 = f32[64,8,1024]{2,1,0} parameter(12)
  %dynamic-slice.927 = f32[1,8,1024]{2,1,0} dynamic-slice(f32[64,8,1024]{2,1,0} %param_12.119, s32[] %param_1.827, s32[] %param_2.851, s32[] %param_2.851), dynamic_slice_sizes={1,8,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %reshape.3182 = f32[8,1024]{1,0} reshape(f32[1,8,1024]{2,1,0} %dynamic-slice.927), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.1553 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %multiply.1554, f32[8,1024]{1,0} %reshape.3182), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %param_11.127 = f32[64,8,1024]{2,1,0} parameter(11)
  %dynamic-slice.926 = f32[1,8,1024]{2,1,0} dynamic-slice(f32[64,8,1024]{2,1,0} %param_11.127, s32[] %param_1.827, s32[] %param_2.851, s32[] %param_2.851), dynamic_slice_sizes={1,8,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %reshape.3181 = f32[8,1024]{1,0} reshape(f32[1,8,1024]{2,1,0} %dynamic-slice.926), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.1552 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %multiply.1553, f32[8,1024]{1,0} %reshape.3181), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %constant.20734 = f32[] constant(0), metadata={op_type="pad" op_name="pmap(_multi_device_update_fn)/scan/while/body/pad[ padding_config=((0, 0, 0), (2048, 1024, 0)) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  %pad.385 = f32[8,4096]{1,0} pad(f32[8,1024]{1,0} %multiply.1552, f32[] %constant.20734), padding=0_0x3072_0, metadata={op_type="pad" op_name="pmap(_multi_device_update_fn)/scan/while/body/pad[ padding_config=((0, 0, 0), (3072, 0, 0)) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  %param_10.103 = f32[64,8,1024]{2,1,0} parameter(10)
  %dynamic-slice.925 = f32[1,8,1024]{2,1,0} dynamic-slice(f32[64,8,1024]{2,1,0} %param_10.103, s32[] %param_1.827, s32[] %param_2.851, s32[] %param_2.851), dynamic_slice_sizes={1,8,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %reshape.3180 = f32[8,1024]{1,0} reshape(f32[1,8,1024]{2,1,0} %dynamic-slice.925), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %slice.1352 = f32[8,1024]{1,0} slice(f32[8,2048]{1,0} %param_9.103), slice={[0:8], [0:1024]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(8, 1024)\n                                                     start_indices=(0, 0)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=65}
  %multiply.1551 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %add.4152, f32[8,1024]{1,0} %reshape.3181), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  %param_8.183 = f32[64,8,1024]{2,1,0} parameter(8)
  %dynamic-slice.924 = f32[1,8,1024]{2,1,0} dynamic-slice(f32[64,8,1024]{2,1,0} %param_8.183, s32[] %param_1.827, s32[] %param_2.851, s32[] %param_2.851), dynamic_slice_sizes={1,8,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %reshape.3179 = f32[8,1024]{1,0} reshape(f32[1,8,1024]{2,1,0} %dynamic-slice.924), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.1550 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %multiply.1551, f32[8,1024]{1,0} %reshape.3179), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  %add.4151 = f32[8,1024]{1,0} add(f32[8,1024]{1,0} %slice.1352, f32[8,1024]{1,0} %multiply.1550), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %multiply.1549 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %multiply.1550, f32[8,1024]{1,0} %reshape.3184), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  %add.4150 = f32[8,1024]{1,0} add(f32[8,1024]{1,0} %add.4151, f32[8,1024]{1,0} %multiply.1549), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %multiply.1548 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %reshape.3180, f32[8,1024]{1,0} %add.4150), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %param_7.239 = f32[64,8,1024]{2,1,0} parameter(7)
  %dynamic-slice.923 = f32[1,8,1024]{2,1,0} dynamic-slice(f32[64,8,1024]{2,1,0} %param_7.239, s32[] %param_1.827, s32[] %param_2.851, s32[] %param_2.851), dynamic_slice_sizes={1,8,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %reshape.3178 = f32[8,1024]{1,0} reshape(f32[1,8,1024]{2,1,0} %dynamic-slice.923), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.1547 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %multiply.1548, f32[8,1024]{1,0} %reshape.3178), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %param_6.313 = f32[64,8,1024]{2,1,0} parameter(6)
  %dynamic-slice.922 = f32[1,8,1024]{2,1,0} dynamic-slice(f32[64,8,1024]{2,1,0} %param_6.313, s32[] %param_1.827, s32[] %param_2.851, s32[] %param_2.851), dynamic_slice_sizes={1,8,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %reshape.3177 = f32[8,1024]{1,0} reshape(f32[1,8,1024]{2,1,0} %dynamic-slice.922), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.1546 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %multiply.1547, f32[8,1024]{1,0} %reshape.3177), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %add.4148 = f32[8,1024]{1,0} add(f32[8,1024]{1,0} %multiply.1547, f32[8,1024]{1,0} %multiply.1546), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %pad.384 = f32[8,4096]{1,0} pad(f32[8,1024]{1,0} %add.4148, f32[] %constant.20734), padding=0_0x1024_2048, metadata={op_type="pad" op_name="pmap(_multi_device_update_fn)/scan/while/body/pad[ padding_config=((0, 0, 0), (1024, 2048, 0)) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  %add.4147 = f32[8,4096]{1,0} add(f32[8,4096]{1,0} %pad.385, f32[8,4096]{1,0} %pad.384), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %multiply.1545 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %add.4150, f32[8,1024]{1,0} %reshape.3177), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %param_5.365 = f32[64,8,1024]{2,1,0} parameter(5)
  %dynamic-slice.921 = f32[1,8,1024]{2,1,0} dynamic-slice(f32[64,8,1024]{2,1,0} %param_5.365, s32[] %param_1.827, s32[] %param_2.851, s32[] %param_2.851), dynamic_slice_sizes={1,8,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %reshape.3176 = f32[8,1024]{1,0} reshape(f32[1,8,1024]{2,1,0} %dynamic-slice.921), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.1544 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %multiply.1545, f32[8,1024]{1,0} %reshape.3176), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %multiply.1543 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %multiply.1544, f32[8,1024]{1,0} %reshape.3180), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %pad.383 = f32[8,4096]{1,0} pad(f32[8,1024]{1,0} %multiply.1543, f32[] %constant.20734), padding=0_0x0_3072, metadata={op_type="pad" op_name="pmap(_multi_device_update_fn)/scan/while/body/pad[ padding_config=((0, 0, 0), (0, 3072, 0)) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  %add.4146 = f32[8,4096]{1,0} add(f32[8,4096]{1,0} %add.4147, f32[8,4096]{1,0} %pad.383), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %param_4.371 = f32[64,8,1024]{2,1,0} parameter(4)
  %dynamic-slice.920 = f32[1,8,1024]{2,1,0} dynamic-slice(f32[64,8,1024]{2,1,0} %param_4.371, s32[] %param_1.827, s32[] %param_2.851, s32[] %param_2.851), dynamic_slice_sizes={1,8,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %reshape.3175 = f32[8,1024]{1,0} reshape(f32[1,8,1024]{2,1,0} %dynamic-slice.920), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.1542 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %reshape.3175, f32[8,1024]{1,0} %add.4150), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %param_3.710 = f32[64,8,1024]{2,1,0} parameter(3)
  %dynamic-slice.919 = f32[1,8,1024]{2,1,0} dynamic-slice(f32[64,8,1024]{2,1,0} %param_3.710, s32[] %param_1.827, s32[] %param_2.851, s32[] %param_2.851), dynamic_slice_sizes={1,8,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %reshape.3174 = f32[8,1024]{1,0} reshape(f32[1,8,1024]{2,1,0} %dynamic-slice.919), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.1541 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %multiply.1542, f32[8,1024]{1,0} %reshape.3174), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %param_0.421 = f32[64,8,1024]{2,1,0} parameter(0)
  %dynamic-slice.918 = f32[1,8,1024]{2,1,0} dynamic-slice(f32[64,8,1024]{2,1,0} %param_0.421, s32[] %param_1.827, s32[] %param_2.851, s32[] %param_2.851), dynamic_slice_sizes={1,8,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %reshape.3173 = f32[8,1024]{1,0} reshape(f32[1,8,1024]{2,1,0} %dynamic-slice.918), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.1540 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %multiply.1541, f32[8,1024]{1,0} %reshape.3173), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %pad.382 = f32[8,4096]{1,0} pad(f32[8,1024]{1,0} %multiply.1540, f32[] %constant.20734), padding=0_0x2048_1024, metadata={op_type="pad" op_name="pmap(_multi_device_update_fn)/scan/while/body/pad[ padding_config=((0, 0, 0), (2048, 1024, 0)) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  ROOT %add.4145 = f32[8,4096]{1,0} add(f32[8,4096]{1,0} %add.4146, f32[8,4096]{1,0} %pad.382), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
}

%fused_computation.249 (param_0.423: f32[64,8,2048], param_1.828: s32[]) -> f32[8,2048] {
  %param_0.423 = f32[64,8,2048]{2,1,0} parameter(0)
  %param_1.828 = s32[] parameter(1)
  %constant.20735 = s32[] constant(0), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %dynamic-slice.930 = f32[1,8,2048]{2,1,0} dynamic-slice(f32[64,8,2048]{2,1,0} %param_0.423, s32[] %param_1.828, s32[] %constant.20735, s32[] %constant.20735), dynamic_slice_sizes={1,8,2048}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 8, 2048) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %reshape.3185 = f32[8,2048]{1,0} reshape(f32[1,8,2048]{2,1,0} %dynamic-slice.930), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.250 (param_0.428: s32[]) -> s32[] {
  %constant.20741 = s32[] constant(64), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_0.428 = s32[] parameter(0)
  %subtract.542 = s32[] subtract(s32[] %constant.20741, s32[] %param_0.428), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant.20739 = s32[] constant(-1)
  %add.4154 = s32[] add(s32[] %subtract.542, s32[] %constant.20739), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant.20738 = s32[] constant(0), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.2762 = pred[] compare(s32[] %add.4154, s32[] %constant.20738), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant.20737 = s32[] constant(63)
  %add.4153 = s32[] add(s32[] %subtract.542, s32[] %constant.20737), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %select.2651 = s32[] select(pred[] %compare.2762, s32[] %add.4153, s32[] %add.4154), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%parallel_add.3821 (p.85: f32[2048,4096], p.86: f32[2048,4096]) -> f32[2048,4096] {
  %p.85 = f32[2048,4096]{1,0} parameter(0)
  %p.86 = f32[2048,4096]{1,0} parameter(1)
  ROOT %add.3821.clone = f32[2048,4096]{1,0} add(f32[2048,4096]{1,0} %p.85, f32[2048,4096]{1,0} %p.86), outer_dimension_partitions={9}, metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
}

%wide.wide.body_computation__201.17000.clone.clone.clone.clone (wide_param.203: (f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[64,8,2048], f32[64,8,1024], /*index=5*/f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], /*index=10*/f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[2048,4096], s32[], /*index=15*/f32[2048,4096], f32[4096], f32[8,2048], f32[64,8,1024])) -> (f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[64,8,2048], f32[64,8,1024], /*index=5*/f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], /*index=10*/f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[2048,4096], s32[], /*index=15*/f32[2048,4096], f32[4096], f32[8,2048], f32[64,8,1024]) {
  %wide_param.203 = (f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) parameter(0)
  %get-tuple-element.27900 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.203), index=0
  %get-tuple-element.27901 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.203), index=1
  %get-tuple-element.27902 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.203), index=2
  %get-tuple-element.27903 = f32[64,8,2048]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.203), index=3
  %get-tuple-element.27904 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.203), index=4
  %get-tuple-element.27905 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.203), index=5
  %get-tuple-element.27906 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.203), index=6
  %get-tuple-element.27907 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.203), index=7
  %get-tuple-element.27908 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.203), index=8
  %get-tuple-element.27909 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.203), index=9
  %get-tuple-element.27910 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.203), index=10
  %get-tuple-element.27911 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.203), index=11
  %get-tuple-element.27912 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.203), index=12
  %get-tuple-element.27913 = f32[2048,4096]{1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.203), index=13
  %get-tuple-element.27914 = s32[] get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.203), index=14
  %copy.919 = s32[] copy(s32[] %get-tuple-element.27914)
  %constant.20186 = s32[] constant(1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.3822 = s32[] add(s32[] %copy.919, s32[] %constant.20186), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.27915 = f32[2048,4096]{1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.203), index=15
  %fusion.250 = s32[] fusion(s32[] %copy.919), kind=kLoop, calls=%fused_computation.250, metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %fusion.249 = f32[8,2048]{1,0} fusion(f32[64,8,2048]{2,1,0} %get-tuple-element.27903, s32[] %fusion.250), kind=kLoop, calls=%fused_computation.249, metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant.20107 = s32[] constant(0), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.27917 = f32[8,2048]{1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.203), index=17
  %fusion.248 = f32[8,4096]{1,0} fusion(f32[64,8,1024]{2,1,0} %get-tuple-element.27901, s32[] %fusion.250, s32[] %constant.20107, f32[64,8,1024]{2,1,0} %get-tuple-element.27904, f32[64,8,1024]{2,1,0} %get-tuple-element.27902, /*index=5*/f32[64,8,1024]{2,1,0} %get-tuple-element.27906, f32[64,8,1024]{2,1,0} %get-tuple-element.27907, f32[64,8,1024]{2,1,0} %get-tuple-element.27908, f32[64,8,1024]{2,1,0} %get-tuple-element.27910, f32[8,2048]{1,0} %get-tuple-element.27917, /*index=10*/f32[64,8,1024]{2,1,0} %get-tuple-element.27905, f32[64,8,1024]{2,1,0} %get-tuple-element.27911, f32[64,8,1024]{2,1,0} %get-tuple-element.27912, f32[64,8,1024]{2,1,0} %get-tuple-element.27900, f32[64,8,1024]{2,1,0} %get-tuple-element.27909), kind=kLoop, calls=%fused_computation.248, metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %dot.194 = f32[2048,4096]{1,0} dot(f32[8,2048]{1,0} %fusion.249, f32[8,4096]{1,0} %fusion.248), lhs_contracting_dims={0}, rhs_contracting_dims={0}, metadata={op_type="transpose" op_name="pmap(_multi_device_update_fn)/scan/while/body/transpose[ permutation=(1, 0) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %call.107 = f32[2048,4096]{1,0} call(f32[2048,4096]{1,0} %get-tuple-element.27915, f32[2048,4096]{1,0} %dot.194), to_apply=%parallel_add.3821
  %get-tuple-element.27916 = f32[4096]{0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.203), index=16
  %constant.20114 = f32[] constant(0), metadata={op_type="pad" op_name="pmap(_multi_device_update_fn)/scan/while/body/pad[ padding_config=((0, 0, 0), (2048, 1024, 0)) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  %reduce.279 = f32[4096]{0} reduce(f32[8,4096]{1,0} %fusion.248, f32[] %constant.20114), dimensions={0}, to_apply=%primitive_computation_add__1.16992, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/scan/while/body/reduce_sum[ axes=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %add.3819 = f32[4096]{0} add(f32[4096]{0} %get-tuple-element.27916, f32[4096]{0} %reduce.279), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %dot.193 = f32[8,2048]{1,0} dot(f32[8,4096]{1,0} %fusion.248, f32[2048,4096]{1,0} %get-tuple-element.27913), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_type="dot_general" op_name="pmap(_multi_device_update_fn)/scan/while/body/dot_general[ dimension_numbers=(((1,), (1,)), ((), ()))\n                                                           precision=None\n                                                           preferred_element_type=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %fusion.247 = f32[8,2048]{1,0} fusion(f32[8,2048]{1,0} %dot.193, f32[64,8,1024]{2,1,0} %get-tuple-element.27901, s32[] %fusion.250, f32[64,8,1024]{2,1,0} %get-tuple-element.27910, f32[8,2048]{1,0} %get-tuple-element.27917, /*index=5*/f32[64,8,1024]{2,1,0} %get-tuple-element.27911, f32[64,8,1024]{2,1,0} %get-tuple-element.27900, f32[64,8,1024]{2,1,0} %get-tuple-element.27909), kind=kLoop, calls=%fused_computation.247, metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %copy.927 = f32[8,2048]{1,0} copy(f32[8,2048]{1,0} %fusion.247)
  %get-tuple-element.27918 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.203), index=18
  %fusion.246 = f32[64,8,1024]{2,1,0} fusion(f32[64,8,1024]{2,1,0} %get-tuple-element.27918, s32[] %fusion.250, f32[8,2048]{1,0} %dot.193), kind=kLoop, calls=%fused_computation.246, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %tuple.1344 = (f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) tuple(f32[64,8,1024]{2,1,0} %get-tuple-element.27900, f32[64,8,1024]{2,1,0} %get-tuple-element.27901, f32[64,8,1024]{2,1,0} %get-tuple-element.27902, f32[64,8,2048]{2,1,0} %get-tuple-element.27903, f32[64,8,1024]{2,1,0} %get-tuple-element.27904, /*index=5*/f32[64,8,1024]{2,1,0} %get-tuple-element.27905, f32[64,8,1024]{2,1,0} %get-tuple-element.27906, f32[64,8,1024]{2,1,0} %get-tuple-element.27907, f32[64,8,1024]{2,1,0} %get-tuple-element.27908, f32[64,8,1024]{2,1,0} %get-tuple-element.27909, /*index=10*/f32[64,8,1024]{2,1,0} %get-tuple-element.27910, f32[64,8,1024]{2,1,0} %get-tuple-element.27911, f32[64,8,1024]{2,1,0} %get-tuple-element.27912, f32[2048,4096]{1,0} %get-tuple-element.27913, s32[] %add.3822, /*index=15*/f32[2048,4096]{1,0} %call.107, f32[4096]{0} %add.3819, f32[8,2048]{1,0} %copy.927, f32[64,8,1024]{2,1,0} %fusion.246)
}

%wide.wide.cond_computation__201.17411.clone.clone.clone.clone (wide_param.204: (f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[64,8,2048], f32[64,8,1024], /*index=5*/f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], /*index=10*/f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[2048,4096], s32[], /*index=15*/f32[2048,4096], f32[4096], f32[8,2048], f32[64,8,1024])) -> pred[] {
  %wide_param.204 = (f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) parameter(0)
  %get-tuple-element.26385 = s32[] get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.204), index=14
  %constant.20222 = s32[] constant(64), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/cond/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %compare.2720 = pred[] compare(s32[] %get-tuple-element.26385, s32[] %constant.20222), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/cond/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%primitive_computation_add__1.17533 (parameter.17534: f32[], parameter.17535: f32[]) -> f32[] {
  %parameter.17534 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.17535 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.17536 = f32[] add(f32[] %parameter.17534, f32[] %parameter.17535), metadata={op_type="add" op_name="add"}
}

%fused_computation.251 (param_0.429: f32[64,8,1024], param_1.835: s32[], param_2.858: f32[8,2048]) -> f32[64,8,1024] {
  %param_0.429 = f32[64,8,1024]{2,1,0} parameter(0)
  %param_2.858 = f32[8,2048]{1,0} parameter(2)
  %slice.1354 = f32[8,1024]{1,0} slice(f32[8,2048]{1,0} %param_2.858), slice={[0:8], [0:1024]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(8, 1024)\n                                                     start_indices=(0, 0)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %reshape.3186 = f32[1,8,1024]{2,1,0} reshape(f32[8,1024]{1,0} %slice.1354), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/while/body/broadcast_in_dim[ broadcast_dimensions=(1, 2)\n                                                                shape=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_1.835 = s32[] parameter(1)
  %constant.20742 = s32[] constant(0), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %dynamic-update-slice.889 = f32[64,8,1024]{2,1,0} dynamic-update-slice(f32[64,8,1024]{2,1,0} %param_0.429, f32[1,8,1024]{2,1,0} %reshape.3186, s32[] %param_1.835, s32[] %constant.20742, s32[] %constant.20742), metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.252 (param_0.432: f32[8,2048], param_1.841: f32[64,8,1024], param_2.864: s32[], param_3.722: f32[64,8,1024], param_4.376: f32[8,2048], param_5.372: f32[64,8,1024], param_6.322: f32[64,8,1024], param_7.249: f32[64,8,1024]) -> f32[8,2048] {
  %param_0.432 = f32[8,2048]{1,0} parameter(0)
  %slice.1355 = f32[8,1024]{1,0} slice(f32[8,2048]{1,0} %param_0.432), slice={[0:8], [1024:2048]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(8, 2048)\n                                                     start_indices=(0, 1024)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %constant.20744 = f32[] constant(0), metadata={op_type="pad" op_name="pmap(_multi_device_update_fn)/scan/while/body/pad[ padding_config=((0, 0, 0), (2048, 1024, 0)) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  %pad.387 = f32[8,2048]{1,0} pad(f32[8,1024]{1,0} %slice.1355, f32[] %constant.20744), padding=0_0x1024_0, metadata={op_type="pad" op_name="pmap(_multi_device_update_fn)/scan/while/body/pad[ padding_config=((0, 0, 0), (1024, 0, 0)) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=54}
  %param_4.376 = f32[8,2048]{1,0} parameter(4)
  %slice.1356 = f32[8,1024]{1,0} slice(f32[8,2048]{1,0} %param_4.376), slice={[0:8], [0:1024]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(8, 1024)\n                                                     start_indices=(0, 0)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=65}
  %param_6.322 = f32[64,8,1024]{2,1,0} parameter(6)
  %param_2.864 = s32[] parameter(2)
  %constant.20745 = s32[] constant(0), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %dynamic-slice.934 = f32[1,8,1024]{2,1,0} dynamic-slice(f32[64,8,1024]{2,1,0} %param_6.322, s32[] %param_2.864, s32[] %constant.20745, s32[] %constant.20745), dynamic_slice_sizes={1,8,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %reshape.3190 = f32[8,1024]{1,0} reshape(f32[1,8,1024]{2,1,0} %dynamic-slice.934), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %slice.1357 = f32[8,1024]{1,0} slice(f32[8,2048]{1,0} %param_4.376), slice={[0:8], [1024:2048]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(8, 2048)\n                                                     start_indices=(0, 1024)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=65}
  %add.4159 = f32[8,1024]{1,0} add(f32[8,1024]{1,0} %reshape.3190, f32[8,1024]{1,0} %slice.1357), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %param_5.372 = f32[64,8,1024]{2,1,0} parameter(5)
  %dynamic-slice.933 = f32[1,8,1024]{2,1,0} dynamic-slice(f32[64,8,1024]{2,1,0} %param_5.372, s32[] %param_2.864, s32[] %constant.20745, s32[] %constant.20745), dynamic_slice_sizes={1,8,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %reshape.3189 = f32[8,1024]{1,0} reshape(f32[1,8,1024]{2,1,0} %dynamic-slice.933), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.1558 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %add.4159, f32[8,1024]{1,0} %reshape.3189), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  %param_3.722 = f32[64,8,1024]{2,1,0} parameter(3)
  %dynamic-slice.932 = f32[1,8,1024]{2,1,0} dynamic-slice(f32[64,8,1024]{2,1,0} %param_3.722, s32[] %param_2.864, s32[] %constant.20745, s32[] %constant.20745), dynamic_slice_sizes={1,8,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %reshape.3188 = f32[8,1024]{1,0} reshape(f32[1,8,1024]{2,1,0} %dynamic-slice.932), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.1557 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %multiply.1558, f32[8,1024]{1,0} %reshape.3188), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  %add.4157 = f32[8,1024]{1,0} add(f32[8,1024]{1,0} %slice.1356, f32[8,1024]{1,0} %multiply.1557), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %param_7.249 = f32[64,8,1024]{2,1,0} parameter(7)
  %dynamic-slice.935 = f32[1,8,1024]{2,1,0} dynamic-slice(f32[64,8,1024]{2,1,0} %param_7.249, s32[] %param_2.864, s32[] %constant.20745, s32[] %constant.20745), dynamic_slice_sizes={1,8,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %reshape.3191 = f32[8,1024]{1,0} reshape(f32[1,8,1024]{2,1,0} %dynamic-slice.935), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.1556 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %multiply.1557, f32[8,1024]{1,0} %reshape.3191), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  %add.4156 = f32[8,1024]{1,0} add(f32[8,1024]{1,0} %add.4157, f32[8,1024]{1,0} %multiply.1556), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %param_1.841 = f32[64,8,1024]{2,1,0} parameter(1)
  %dynamic-slice.931 = f32[1,8,1024]{2,1,0} dynamic-slice(f32[64,8,1024]{2,1,0} %param_1.841, s32[] %param_2.864, s32[] %constant.20745, s32[] %constant.20745), dynamic_slice_sizes={1,8,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %reshape.3187 = f32[8,1024]{1,0} reshape(f32[1,8,1024]{2,1,0} %dynamic-slice.931), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.1555 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %add.4156, f32[8,1024]{1,0} %reshape.3187), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %pad.386 = f32[8,2048]{1,0} pad(f32[8,1024]{1,0} %multiply.1555, f32[] %constant.20744), padding=0_0x0_1024, metadata={op_type="pad" op_name="pmap(_multi_device_update_fn)/scan/while/body/pad[ padding_config=((0, 0, 0), (0, 1024, 0)) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=54}
  ROOT %add.4155 = f32[8,2048]{1,0} add(f32[8,2048]{1,0} %pad.387, f32[8,2048]{1,0} %pad.386), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
}

%fused_computation.253 (param_0.435: f32[64,8,1024], param_1.846: s32[], param_2.869: s32[], param_3.728: f32[64,8,1024], param_4.380: f32[64,8,1024], param_5.378: f32[64,8,1024], param_6.331: f32[64,8,1024], param_7.258: f32[64,8,1024], param_8.206: f32[64,8,1024], param_9.116: f32[8,2048], param_10.116: f32[64,8,1024], param_11.143: f32[64,8,1024], param_12.134: f32[64,8,1024], param_13.107: f32[64,8,1024], param_14.161: f32[64,8,1024]) -> f32[8,4096] {
  %param_14.161 = f32[64,8,1024]{2,1,0} parameter(14)
  %param_1.846 = s32[] parameter(1)
  %param_2.869 = s32[] parameter(2)
  %dynamic-slice.947 = f32[1,8,1024]{2,1,0} dynamic-slice(f32[64,8,1024]{2,1,0} %param_14.161, s32[] %param_1.846, s32[] %param_2.869, s32[] %param_2.869), dynamic_slice_sizes={1,8,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %reshape.3203 = f32[8,1024]{1,0} reshape(f32[1,8,1024]{2,1,0} %dynamic-slice.947), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_13.107 = f32[64,8,1024]{2,1,0} parameter(13)
  %dynamic-slice.946 = f32[1,8,1024]{2,1,0} dynamic-slice(f32[64,8,1024]{2,1,0} %param_13.107, s32[] %param_1.846, s32[] %param_2.869, s32[] %param_2.869), dynamic_slice_sizes={1,8,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %reshape.3202 = f32[8,1024]{1,0} reshape(f32[1,8,1024]{2,1,0} %dynamic-slice.946), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_9.116 = f32[8,2048]{1,0} parameter(9)
  %slice.1359 = f32[8,1024]{1,0} slice(f32[8,2048]{1,0} %param_9.116), slice={[0:8], [1024:2048]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(8, 2048)\n                                                     start_indices=(0, 1024)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=65}
  %add.4166 = f32[8,1024]{1,0} add(f32[8,1024]{1,0} %reshape.3202, f32[8,1024]{1,0} %slice.1359), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %multiply.1573 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %reshape.3203, f32[8,1024]{1,0} %add.4166), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  %param_12.134 = f32[64,8,1024]{2,1,0} parameter(12)
  %dynamic-slice.945 = f32[1,8,1024]{2,1,0} dynamic-slice(f32[64,8,1024]{2,1,0} %param_12.134, s32[] %param_1.846, s32[] %param_2.869, s32[] %param_2.869), dynamic_slice_sizes={1,8,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %reshape.3201 = f32[8,1024]{1,0} reshape(f32[1,8,1024]{2,1,0} %dynamic-slice.945), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.1572 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %multiply.1573, f32[8,1024]{1,0} %reshape.3201), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %param_11.143 = f32[64,8,1024]{2,1,0} parameter(11)
  %dynamic-slice.944 = f32[1,8,1024]{2,1,0} dynamic-slice(f32[64,8,1024]{2,1,0} %param_11.143, s32[] %param_1.846, s32[] %param_2.869, s32[] %param_2.869), dynamic_slice_sizes={1,8,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %reshape.3200 = f32[8,1024]{1,0} reshape(f32[1,8,1024]{2,1,0} %dynamic-slice.944), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.1571 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %multiply.1572, f32[8,1024]{1,0} %reshape.3200), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %constant.20746 = f32[] constant(0), metadata={op_type="pad" op_name="pmap(_multi_device_update_fn)/scan/while/body/pad[ padding_config=((0, 0, 0), (2048, 1024, 0)) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  %pad.391 = f32[8,4096]{1,0} pad(f32[8,1024]{1,0} %multiply.1571, f32[] %constant.20746), padding=0_0x3072_0, metadata={op_type="pad" op_name="pmap(_multi_device_update_fn)/scan/while/body/pad[ padding_config=((0, 0, 0), (3072, 0, 0)) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  %param_10.116 = f32[64,8,1024]{2,1,0} parameter(10)
  %dynamic-slice.943 = f32[1,8,1024]{2,1,0} dynamic-slice(f32[64,8,1024]{2,1,0} %param_10.116, s32[] %param_1.846, s32[] %param_2.869, s32[] %param_2.869), dynamic_slice_sizes={1,8,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %reshape.3199 = f32[8,1024]{1,0} reshape(f32[1,8,1024]{2,1,0} %dynamic-slice.943), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %slice.1358 = f32[8,1024]{1,0} slice(f32[8,2048]{1,0} %param_9.116), slice={[0:8], [0:1024]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/slice[ limit_indices=(8, 1024)\n                                                     start_indices=(0, 0)\n                                                     strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=65}
  %multiply.1570 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %add.4166, f32[8,1024]{1,0} %reshape.3200), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  %param_8.206 = f32[64,8,1024]{2,1,0} parameter(8)
  %dynamic-slice.942 = f32[1,8,1024]{2,1,0} dynamic-slice(f32[64,8,1024]{2,1,0} %param_8.206, s32[] %param_1.846, s32[] %param_2.869, s32[] %param_2.869), dynamic_slice_sizes={1,8,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %reshape.3198 = f32[8,1024]{1,0} reshape(f32[1,8,1024]{2,1,0} %dynamic-slice.942), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.1569 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %multiply.1570, f32[8,1024]{1,0} %reshape.3198), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  %add.4165 = f32[8,1024]{1,0} add(f32[8,1024]{1,0} %slice.1358, f32[8,1024]{1,0} %multiply.1569), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %multiply.1568 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %multiply.1569, f32[8,1024]{1,0} %reshape.3203), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=64}
  %add.4164 = f32[8,1024]{1,0} add(f32[8,1024]{1,0} %add.4165, f32[8,1024]{1,0} %multiply.1568), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %multiply.1567 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %reshape.3199, f32[8,1024]{1,0} %add.4164), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %param_7.258 = f32[64,8,1024]{2,1,0} parameter(7)
  %dynamic-slice.941 = f32[1,8,1024]{2,1,0} dynamic-slice(f32[64,8,1024]{2,1,0} %param_7.258, s32[] %param_1.846, s32[] %param_2.869, s32[] %param_2.869), dynamic_slice_sizes={1,8,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %reshape.3197 = f32[8,1024]{1,0} reshape(f32[1,8,1024]{2,1,0} %dynamic-slice.941), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.1566 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %multiply.1567, f32[8,1024]{1,0} %reshape.3197), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %param_6.331 = f32[64,8,1024]{2,1,0} parameter(6)
  %dynamic-slice.940 = f32[1,8,1024]{2,1,0} dynamic-slice(f32[64,8,1024]{2,1,0} %param_6.331, s32[] %param_1.846, s32[] %param_2.869, s32[] %param_2.869), dynamic_slice_sizes={1,8,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %reshape.3196 = f32[8,1024]{1,0} reshape(f32[1,8,1024]{2,1,0} %dynamic-slice.940), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.1565 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %multiply.1566, f32[8,1024]{1,0} %reshape.3196), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %add.4163 = f32[8,1024]{1,0} add(f32[8,1024]{1,0} %multiply.1566, f32[8,1024]{1,0} %multiply.1565), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %pad.390 = f32[8,4096]{1,0} pad(f32[8,1024]{1,0} %add.4163, f32[] %constant.20746), padding=0_0x1024_2048, metadata={op_type="pad" op_name="pmap(_multi_device_update_fn)/scan/while/body/pad[ padding_config=((0, 0, 0), (1024, 2048, 0)) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  %add.4162 = f32[8,4096]{1,0} add(f32[8,4096]{1,0} %pad.391, f32[8,4096]{1,0} %pad.390), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %multiply.1564 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %add.4164, f32[8,1024]{1,0} %reshape.3196), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %param_5.378 = f32[64,8,1024]{2,1,0} parameter(5)
  %dynamic-slice.939 = f32[1,8,1024]{2,1,0} dynamic-slice(f32[64,8,1024]{2,1,0} %param_5.378, s32[] %param_1.846, s32[] %param_2.869, s32[] %param_2.869), dynamic_slice_sizes={1,8,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %reshape.3195 = f32[8,1024]{1,0} reshape(f32[1,8,1024]{2,1,0} %dynamic-slice.939), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.1563 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %multiply.1564, f32[8,1024]{1,0} %reshape.3195), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %multiply.1562 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %multiply.1563, f32[8,1024]{1,0} %reshape.3199), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %pad.389 = f32[8,4096]{1,0} pad(f32[8,1024]{1,0} %multiply.1562, f32[] %constant.20746), padding=0_0x0_3072, metadata={op_type="pad" op_name="pmap(_multi_device_update_fn)/scan/while/body/pad[ padding_config=((0, 0, 0), (0, 3072, 0)) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  %add.4161 = f32[8,4096]{1,0} add(f32[8,4096]{1,0} %add.4162, f32[8,4096]{1,0} %pad.389), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %param_4.380 = f32[64,8,1024]{2,1,0} parameter(4)
  %dynamic-slice.938 = f32[1,8,1024]{2,1,0} dynamic-slice(f32[64,8,1024]{2,1,0} %param_4.380, s32[] %param_1.846, s32[] %param_2.869, s32[] %param_2.869), dynamic_slice_sizes={1,8,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %reshape.3194 = f32[8,1024]{1,0} reshape(f32[1,8,1024]{2,1,0} %dynamic-slice.938), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.1561 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %reshape.3194, f32[8,1024]{1,0} %add.4164), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=63}
  %param_3.728 = f32[64,8,1024]{2,1,0} parameter(3)
  %dynamic-slice.937 = f32[1,8,1024]{2,1,0} dynamic-slice(f32[64,8,1024]{2,1,0} %param_3.728, s32[] %param_1.846, s32[] %param_2.869, s32[] %param_2.869), dynamic_slice_sizes={1,8,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %reshape.3193 = f32[8,1024]{1,0} reshape(f32[1,8,1024]{2,1,0} %dynamic-slice.937), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.1560 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %multiply.1561, f32[8,1024]{1,0} %reshape.3193), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %param_0.435 = f32[64,8,1024]{2,1,0} parameter(0)
  %dynamic-slice.936 = f32[1,8,1024]{2,1,0} dynamic-slice(f32[64,8,1024]{2,1,0} %param_0.435, s32[] %param_1.846, s32[] %param_2.869, s32[] %param_2.869), dynamic_slice_sizes={1,8,1024}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %reshape.3192 = f32[8,1024]{1,0} reshape(f32[1,8,1024]{2,1,0} %dynamic-slice.936), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %multiply.1559 = f32[8,1024]{1,0} multiply(f32[8,1024]{1,0} %multiply.1560, f32[8,1024]{1,0} %reshape.3192), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/scan/while/body/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=104}
  %pad.388 = f32[8,4096]{1,0} pad(f32[8,1024]{1,0} %multiply.1559, f32[] %constant.20746), padding=0_0x2048_1024, metadata={op_type="pad" op_name="pmap(_multi_device_update_fn)/scan/while/body/pad[ padding_config=((0, 0, 0), (2048, 1024, 0)) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  ROOT %add.4160 = f32[8,4096]{1,0} add(f32[8,4096]{1,0} %add.4161, f32[8,4096]{1,0} %pad.388), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
}

%fused_computation.254 (param_0.437: f32[64,8,2048], param_1.847: s32[]) -> f32[8,2048] {
  %param_0.437 = f32[64,8,2048]{2,1,0} parameter(0)
  %param_1.847 = s32[] parameter(1)
  %constant.20747 = s32[] constant(0), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %dynamic-slice.948 = f32[1,8,2048]{2,1,0} dynamic-slice(f32[64,8,2048]{2,1,0} %param_0.437, s32[] %param_1.847, s32[] %constant.20747, s32[] %constant.20747), dynamic_slice_sizes={1,8,2048}, metadata={op_type="dynamic_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_slice[ slice_sizes=(1, 8, 2048) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %reshape.3204 = f32[8,2048]{1,0} reshape(f32[1,8,2048]{2,1,0} %dynamic-slice.948), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.255 (param_0.442: s32[]) -> s32[] {
  %constant.20752 = s32[] constant(64), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %param_0.442 = s32[] parameter(0)
  %subtract.543 = s32[] subtract(s32[] %constant.20752, s32[] %param_0.442), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant.20751 = s32[] constant(-1)
  %add.4169 = s32[] add(s32[] %subtract.543, s32[] %constant.20751), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/scan/while/body/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant.20750 = s32[] constant(0), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %compare.2764 = pred[] compare(s32[] %add.4169, s32[] %constant.20750), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/body/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant.20748 = s32[] constant(63)
  %add.4168 = s32[] add(s32[] %subtract.543, s32[] %constant.20748), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %select.2652 = s32[] select(pred[] %compare.2764, s32[] %add.4168, s32[] %add.4169), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%parallel_add.3851 (p.87: f32[2048,4096], p.88: f32[2048,4096]) -> f32[2048,4096] {
  %p.87 = f32[2048,4096]{1,0} parameter(0)
  %p.88 = f32[2048,4096]{1,0} parameter(1)
  ROOT %add.3851.clone = f32[2048,4096]{1,0} add(f32[2048,4096]{1,0} %p.87, f32[2048,4096]{1,0} %p.88), outer_dimension_partitions={9}, metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
}

%wide.wide.body_computation__202.17541.clone.clone.clone.clone (wide_param.205: (f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[64,8,2048], f32[64,8,1024], /*index=5*/f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], /*index=10*/f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[2048,4096], s32[], /*index=15*/f32[2048,4096], f32[4096], f32[8,2048], f32[64,8,1024])) -> (f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[64,8,2048], f32[64,8,1024], /*index=5*/f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], /*index=10*/f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[2048,4096], s32[], /*index=15*/f32[2048,4096], f32[4096], f32[8,2048], f32[64,8,1024]) {
  %wide_param.205 = (f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) parameter(0)
  %get-tuple-element.27969 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.205), index=0
  %get-tuple-element.27970 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.205), index=1
  %get-tuple-element.27971 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.205), index=2
  %get-tuple-element.27972 = f32[64,8,2048]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.205), index=3
  %get-tuple-element.27973 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.205), index=4
  %get-tuple-element.27974 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.205), index=5
  %get-tuple-element.27975 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.205), index=6
  %get-tuple-element.27976 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.205), index=7
  %get-tuple-element.27977 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.205), index=8
  %get-tuple-element.27978 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.205), index=9
  %get-tuple-element.27979 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.205), index=10
  %get-tuple-element.27980 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.205), index=11
  %get-tuple-element.27981 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.205), index=12
  %get-tuple-element.27982 = f32[2048,4096]{1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.205), index=13
  %get-tuple-element.27983 = s32[] get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.205), index=14
  %copy.940 = s32[] copy(s32[] %get-tuple-element.27983)
  %constant.20317 = s32[] constant(1), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %add.3852 = s32[] add(s32[] %copy.940, s32[] %constant.20317), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/scan/while/body/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.27984 = f32[2048,4096]{1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.205), index=15
  %fusion.255 = s32[] fusion(s32[] %copy.940), kind=kLoop, calls=%fused_computation.255, metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %fusion.254 = f32[8,2048]{1,0} fusion(f32[64,8,2048]{2,1,0} %get-tuple-element.27972, s32[] %fusion.255), kind=kLoop, calls=%fused_computation.254, metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/scan/while/body/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant.20240 = s32[] constant(0), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/scan/while/body/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.27986 = f32[8,2048]{1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.205), index=17
  %fusion.253 = f32[8,4096]{1,0} fusion(f32[64,8,1024]{2,1,0} %get-tuple-element.27970, s32[] %fusion.255, s32[] %constant.20240, f32[64,8,1024]{2,1,0} %get-tuple-element.27973, f32[64,8,1024]{2,1,0} %get-tuple-element.27971, /*index=5*/f32[64,8,1024]{2,1,0} %get-tuple-element.27975, f32[64,8,1024]{2,1,0} %get-tuple-element.27976, f32[64,8,1024]{2,1,0} %get-tuple-element.27977, f32[64,8,1024]{2,1,0} %get-tuple-element.27979, f32[8,2048]{1,0} %get-tuple-element.27986, /*index=10*/f32[64,8,1024]{2,1,0} %get-tuple-element.27974, f32[64,8,1024]{2,1,0} %get-tuple-element.27980, f32[64,8,1024]{2,1,0} %get-tuple-element.27981, f32[64,8,1024]{2,1,0} %get-tuple-element.27969, f32[64,8,1024]{2,1,0} %get-tuple-element.27978), kind=kLoop, calls=%fused_computation.253, metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %dot.196 = f32[2048,4096]{1,0} dot(f32[8,2048]{1,0} %fusion.254, f32[8,4096]{1,0} %fusion.253), lhs_contracting_dims={0}, rhs_contracting_dims={0}, metadata={op_type="transpose" op_name="pmap(_multi_device_update_fn)/scan/while/body/transpose[ permutation=(1, 0) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %call.108 = f32[2048,4096]{1,0} call(f32[2048,4096]{1,0} %get-tuple-element.27984, f32[2048,4096]{1,0} %dot.196), to_apply=%parallel_add.3851
  %get-tuple-element.27985 = f32[4096]{0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.205), index=16
  %constant.20247 = f32[] constant(0), metadata={op_type="pad" op_name="pmap(_multi_device_update_fn)/scan/while/body/pad[ padding_config=((0, 0, 0), (2048, 1024, 0)) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=61}
  %reduce.280 = f32[4096]{0} reduce(f32[8,4096]{1,0} %fusion.253, f32[] %constant.20247), dimensions={0}, to_apply=%primitive_computation_add__1.17533, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/scan/while/body/reduce_sum[ axes=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %add.3849 = f32[4096]{0} add(f32[4096]{0} %get-tuple-element.27985, f32[4096]{0} %reduce.280), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %dot.195 = f32[8,2048]{1,0} dot(f32[8,4096]{1,0} %fusion.253, f32[2048,4096]{1,0} %get-tuple-element.27982), lhs_contracting_dims={1}, rhs_contracting_dims={1}, metadata={op_type="dot_general" op_name="pmap(_multi_device_update_fn)/scan/while/body/dot_general[ dimension_numbers=(((1,), (1,)), ((), ()))\n                                                           precision=None\n                                                           preferred_element_type=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %fusion.252 = f32[8,2048]{1,0} fusion(f32[8,2048]{1,0} %dot.195, f32[64,8,1024]{2,1,0} %get-tuple-element.27970, s32[] %fusion.255, f32[64,8,1024]{2,1,0} %get-tuple-element.27979, f32[8,2048]{1,0} %get-tuple-element.27986, /*index=5*/f32[64,8,1024]{2,1,0} %get-tuple-element.27980, f32[64,8,1024]{2,1,0} %get-tuple-element.27969, f32[64,8,1024]{2,1,0} %get-tuple-element.27978), kind=kLoop, calls=%fused_computation.252, metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/scan/while/body/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=144}
  %copy.948 = f32[8,2048]{1,0} copy(f32[8,2048]{1,0} %fusion.252)
  %get-tuple-element.27987 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.205), index=18
  %fusion.251 = f32[64,8,1024]{2,1,0} fusion(f32[64,8,1024]{2,1,0} %get-tuple-element.27987, s32[] %fusion.255, f32[8,2048]{1,0} %dot.195), kind=kLoop, calls=%fused_computation.251, metadata={op_type="dynamic_update_slice" op_name="pmap(_multi_device_update_fn)/scan/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %tuple.1350 = (f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) tuple(f32[64,8,1024]{2,1,0} %get-tuple-element.27969, f32[64,8,1024]{2,1,0} %get-tuple-element.27970, f32[64,8,1024]{2,1,0} %get-tuple-element.27971, f32[64,8,2048]{2,1,0} %get-tuple-element.27972, f32[64,8,1024]{2,1,0} %get-tuple-element.27973, /*index=5*/f32[64,8,1024]{2,1,0} %get-tuple-element.27974, f32[64,8,1024]{2,1,0} %get-tuple-element.27975, f32[64,8,1024]{2,1,0} %get-tuple-element.27976, f32[64,8,1024]{2,1,0} %get-tuple-element.27977, f32[64,8,1024]{2,1,0} %get-tuple-element.27978, /*index=10*/f32[64,8,1024]{2,1,0} %get-tuple-element.27979, f32[64,8,1024]{2,1,0} %get-tuple-element.27980, f32[64,8,1024]{2,1,0} %get-tuple-element.27981, f32[2048,4096]{1,0} %get-tuple-element.27982, s32[] %add.3852, /*index=15*/f32[2048,4096]{1,0} %call.108, f32[4096]{0} %add.3849, f32[8,2048]{1,0} %copy.948, f32[64,8,1024]{2,1,0} %fusion.251)
}

%wide.wide.cond_computation__202.17952.clone.clone.clone.clone (wide_param.206: (f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[64,8,2048], f32[64,8,1024], /*index=5*/f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], /*index=10*/f32[64,8,1024], f32[64,8,1024], f32[64,8,1024], f32[2048,4096], s32[], /*index=15*/f32[2048,4096], f32[4096], f32[8,2048], f32[64,8,1024])) -> pred[] {
  %wide_param.206 = (f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) parameter(0)
  %get-tuple-element.26528 = s32[] get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %wide_param.206), index=14
  %constant.20352 = s32[] constant(64), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/cond/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %compare.2737 = pred[] compare(s32[] %get-tuple-element.26528, s32[] %constant.20352), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/scan/while/cond/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.256 (param_0.443: f32[], param_1.854: f32[256]) -> f32[] {
  %param_0.443 = f32[] parameter(0)
  %param_1.854 = f32[256]{0} parameter(1)
  %dot.202 = f32[] dot(f32[256]{0} %param_1.854, f32[256]{0} %param_1.854), lhs_contracting_dims={0}, rhs_contracting_dims={0}, metadata={op_type="dot_general" op_name="pmap(_multi_device_update_fn)/dot_general[ dimension_numbers=(((0,), (0,)), ((), ()))\n                                           precision=None\n                                           preferred_element_type=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  ROOT %add.4170 = f32[] add(f32[] %param_0.443, f32[] %dot.202), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
}

%fused_computation.257 (param_0.444: f32[], param_1.856: f32[262144]) -> f32[] {
  %param_0.444 = f32[] parameter(0)
  %param_1.856 = f32[262144]{0} parameter(1)
  %dot.203 = f32[] dot(f32[262144]{0} %param_1.856, f32[262144]{0} %param_1.856), lhs_contracting_dims={0}, rhs_contracting_dims={0}, metadata={op_type="dot_general" op_name="pmap(_multi_device_update_fn)/dot_general[ dimension_numbers=(((0,), (0,)), ((), ()))\n                                           precision=None\n                                           preferred_element_type=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  ROOT %add.4171 = f32[] add(f32[] %param_0.444, f32[] %dot.203), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
}

%fused_computation.258 (param_0.445: f32[], param_1.858: f32[4096]) -> f32[] {
  %param_0.445 = f32[] parameter(0)
  %param_1.858 = f32[4096]{0} parameter(1)
  %dot.204 = f32[] dot(f32[4096]{0} %param_1.858, f32[4096]{0} %param_1.858), lhs_contracting_dims={0}, rhs_contracting_dims={0}, metadata={op_type="dot_general" op_name="pmap(_multi_device_update_fn)/dot_general[ dimension_numbers=(((0,), (0,)), ((), ()))\n                                           precision=None\n                                           preferred_element_type=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  ROOT %add.4172 = f32[] add(f32[] %param_0.445, f32[] %dot.204), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
}

%fused_computation.259 (param_0.446: f32[], param_1.860: f32[8388608]) -> f32[] {
  %param_0.446 = f32[] parameter(0)
  %param_1.860 = f32[8388608]{0} parameter(1)
  %dot.205 = f32[] dot(f32[8388608]{0} %param_1.860, f32[8388608]{0} %param_1.860), lhs_contracting_dims={0}, rhs_contracting_dims={0}, metadata={op_type="dot_general" op_name="pmap(_multi_device_update_fn)/dot_general[ dimension_numbers=(((0,), (0,)), ((), ()))\n                                           precision=None\n                                           preferred_element_type=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  ROOT %add.4173 = f32[] add(f32[] %param_0.446, f32[] %dot.205), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
}

%fused_computation.260 (param_0.447: f32[], param_1.862: f32[4096]) -> f32[] {
  %param_0.447 = f32[] parameter(0)
  %param_1.862 = f32[4096]{0} parameter(1)
  %dot.206 = f32[] dot(f32[4096]{0} %param_1.862, f32[4096]{0} %param_1.862), lhs_contracting_dims={0}, rhs_contracting_dims={0}, metadata={op_type="dot_general" op_name="pmap(_multi_device_update_fn)/dot_general[ dimension_numbers=(((0,), (0,)), ((), ()))\n                                           precision=None\n                                           preferred_element_type=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  ROOT %add.4174 = f32[] add(f32[] %param_0.447, f32[] %dot.206), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
}

%fused_computation.261 (param_0.448: f32[], param_1.864: f32[8388608]) -> f32[] {
  %param_0.448 = f32[] parameter(0)
  %param_1.864 = f32[8388608]{0} parameter(1)
  %dot.207 = f32[] dot(f32[8388608]{0} %param_1.864, f32[8388608]{0} %param_1.864), lhs_contracting_dims={0}, rhs_contracting_dims={0}, metadata={op_type="dot_general" op_name="pmap(_multi_device_update_fn)/dot_general[ dimension_numbers=(((0,), (0,)), ((), ()))\n                                           precision=None\n                                           preferred_element_type=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  ROOT %add.4175 = f32[] add(f32[] %param_0.448, f32[] %dot.207), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
}

%fused_computation.262 (param_0.449: f32[], param_1.866: f32[4096]) -> f32[] {
  %param_0.449 = f32[] parameter(0)
  %param_1.866 = f32[4096]{0} parameter(1)
  %dot.208 = f32[] dot(f32[4096]{0} %param_1.866, f32[4096]{0} %param_1.866), lhs_contracting_dims={0}, rhs_contracting_dims={0}, metadata={op_type="dot_general" op_name="pmap(_multi_device_update_fn)/dot_general[ dimension_numbers=(((0,), (0,)), ((), ()))\n                                           precision=None\n                                           preferred_element_type=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  ROOT %add.4177 = f32[] add(f32[] %param_0.449, f32[] %dot.208), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
}

%fused_computation.263 (param_0.450: f32[], param_1.868: f32[8388608]) -> f32[] {
  %param_0.450 = f32[] parameter(0)
  %param_1.868 = f32[8388608]{0} parameter(1)
  %dot.209 = f32[] dot(f32[8388608]{0} %param_1.868, f32[8388608]{0} %param_1.868), lhs_contracting_dims={0}, rhs_contracting_dims={0}, metadata={op_type="dot_general" op_name="pmap(_multi_device_update_fn)/dot_general[ dimension_numbers=(((0,), (0,)), ((), ()))\n                                           precision=None\n                                           preferred_element_type=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  ROOT %add.4178 = f32[] add(f32[] %param_0.450, f32[] %dot.209), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
}

%fused_computation.264 (param_0.451: f32[], param_1.870: f32[4096]) -> f32[] {
  %param_0.451 = f32[] parameter(0)
  %param_1.870 = f32[4096]{0} parameter(1)
  %dot.210 = f32[] dot(f32[4096]{0} %param_1.870, f32[4096]{0} %param_1.870), lhs_contracting_dims={0}, rhs_contracting_dims={0}, metadata={op_type="dot_general" op_name="pmap(_multi_device_update_fn)/dot_general[ dimension_numbers=(((0,), (0,)), ((), ()))\n                                           precision=None\n                                           preferred_element_type=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  ROOT %add.4179 = f32[] add(f32[] %param_0.451, f32[] %dot.210), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
}

%fused_computation.265 (param_0.452: f32[], param_1.872: f32[8388608]) -> f32[] {
  %param_0.452 = f32[] parameter(0)
  %param_1.872 = f32[8388608]{0} parameter(1)
  %dot.211 = f32[] dot(f32[8388608]{0} %param_1.872, f32[8388608]{0} %param_1.872), lhs_contracting_dims={0}, rhs_contracting_dims={0}, metadata={op_type="dot_general" op_name="pmap(_multi_device_update_fn)/dot_general[ dimension_numbers=(((0,), (0,)), ((), ()))\n                                           precision=None\n                                           preferred_element_type=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  ROOT %add.4180 = f32[] add(f32[] %param_0.452, f32[] %dot.211), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
}

%fused_computation.266 (param_0.453: f32[], param_1.874: f32[1024]) -> f32[] {
  %param_0.453 = f32[] parameter(0)
  %param_1.874 = f32[1024]{0} parameter(1)
  %dot.212 = f32[] dot(f32[1024]{0} %param_1.874, f32[1024]{0} %param_1.874), lhs_contracting_dims={0}, rhs_contracting_dims={0}, metadata={op_type="dot_general" op_name="pmap(_multi_device_update_fn)/dot_general[ dimension_numbers=(((0,), (0,)), ((), ()))\n                                           precision=None\n                                           preferred_element_type=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  ROOT %add.4181 = f32[] add(f32[] %param_0.453, f32[] %dot.212), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
}

%fused_computation.267 (param_0.454: f32[], param_1.876: f32[1048576]) -> f32[] {
  %param_0.454 = f32[] parameter(0)
  %param_1.876 = f32[1048576]{0} parameter(1)
  %dot.213 = f32[] dot(f32[1048576]{0} %param_1.876, f32[1048576]{0} %param_1.876), lhs_contracting_dims={0}, rhs_contracting_dims={0}, metadata={op_type="dot_general" op_name="pmap(_multi_device_update_fn)/dot_general[ dimension_numbers=(((0,), (0,)), ((), ()))\n                                           precision=None\n                                           preferred_element_type=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  ROOT %add.4182 = f32[] add(f32[] %param_0.454, f32[] %dot.213), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
}

%fused_computation.268 (param_0.455: f32[], param_1.878: f32[1024]) -> f32[] {
  %param_0.455 = f32[] parameter(0)
  %param_1.878 = f32[1024]{0} parameter(1)
  %dot.214 = f32[] dot(f32[1024]{0} %param_1.878, f32[1024]{0} %param_1.878), lhs_contracting_dims={0}, rhs_contracting_dims={0}, metadata={op_type="dot_general" op_name="pmap(_multi_device_update_fn)/dot_general[ dimension_numbers=(((0,), (0,)), ((), ()))\n                                           precision=None\n                                           preferred_element_type=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  ROOT %add.4183 = f32[] add(f32[] %param_0.455, f32[] %dot.214), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
}

%fused_computation.269 (param_0.456: f32[], param_1.880: f32[1048576]) -> f32[] {
  %param_0.456 = f32[] parameter(0)
  %param_1.880 = f32[1048576]{0} parameter(1)
  %dot.215 = f32[] dot(f32[1048576]{0} %param_1.880, f32[1048576]{0} %param_1.880), lhs_contracting_dims={0}, rhs_contracting_dims={0}, metadata={op_type="dot_general" op_name="pmap(_multi_device_update_fn)/dot_general[ dimension_numbers=(((0,), (0,)), ((), ()))\n                                           precision=None\n                                           preferred_element_type=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  ROOT %add.4184 = f32[] add(f32[] %param_0.456, f32[] %dot.215), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
}

%fused_computation.270 (param_0.457: f32[], param_1.882: f32[1024]) -> f32[] {
  %param_0.457 = f32[] parameter(0)
  %param_1.882 = f32[1024]{0} parameter(1)
  %dot.216 = f32[] dot(f32[1024]{0} %param_1.882, f32[1024]{0} %param_1.882), lhs_contracting_dims={0}, rhs_contracting_dims={0}, metadata={op_type="dot_general" op_name="pmap(_multi_device_update_fn)/dot_general[ dimension_numbers=(((0,), (0,)), ((), ()))\n                                           precision=None\n                                           preferred_element_type=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  ROOT %add.4185 = f32[] add(f32[] %param_0.457, f32[] %dot.216), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
}

%fused_computation.271 (param_0.458: f32[], param_1.884: f32[1048576]) -> f32[] {
  %param_0.458 = f32[] parameter(0)
  %param_1.884 = f32[1048576]{0} parameter(1)
  %dot.217 = f32[] dot(f32[1048576]{0} %param_1.884, f32[1048576]{0} %param_1.884), lhs_contracting_dims={0}, rhs_contracting_dims={0}, metadata={op_type="dot_general" op_name="pmap(_multi_device_update_fn)/dot_general[ dimension_numbers=(((0,), (0,)), ((), ()))\n                                           precision=None\n                                           preferred_element_type=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  ROOT %add.4187 = f32[] add(f32[] %param_0.458, f32[] %dot.217), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
}

%fused_computation.272 (param_0.459: f32[], param_1.886: f32[1024]) -> f32[] {
  %param_0.459 = f32[] parameter(0)
  %param_1.886 = f32[1024]{0} parameter(1)
  %dot.218 = f32[] dot(f32[1024]{0} %param_1.886, f32[1024]{0} %param_1.886), lhs_contracting_dims={0}, rhs_contracting_dims={0}, metadata={op_type="dot_general" op_name="pmap(_multi_device_update_fn)/dot_general[ dimension_numbers=(((0,), (0,)), ((), ()))\n                                           precision=None\n                                           preferred_element_type=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  ROOT %add.4189 = f32[] add(f32[] %param_0.459, f32[] %dot.218), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
}

%fused_computation.273 (param_0.460: f32[], param_1.888: f32[1048576]) -> f32[] {
  %param_0.460 = f32[] parameter(0)
  %param_1.888 = f32[1048576]{0} parameter(1)
  %dot.219 = f32[] dot(f32[1048576]{0} %param_1.888, f32[1048576]{0} %param_1.888), lhs_contracting_dims={0}, rhs_contracting_dims={0}, metadata={op_type="dot_general" op_name="pmap(_multi_device_update_fn)/dot_general[ dimension_numbers=(((0,), (0,)), ((), ()))\n                                           precision=None\n                                           preferred_element_type=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  ROOT %add.4191 = f32[] add(f32[] %param_0.460, f32[] %dot.219), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
}

%fused_computation.274 (param_0.461: f32[], param_1.890: f32[4096]) -> f32[] {
  %param_0.461 = f32[] parameter(0)
  %param_1.890 = f32[4096]{0} parameter(1)
  %dot.220 = f32[] dot(f32[4096]{0} %param_1.890, f32[4096]{0} %param_1.890), lhs_contracting_dims={0}, rhs_contracting_dims={0}, metadata={op_type="dot_general" op_name="pmap(_multi_device_update_fn)/dot_general[ dimension_numbers=(((0,), (0,)), ((), ()))\n                                           precision=None\n                                           preferred_element_type=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  ROOT %add.4192 = f32[] add(f32[] %param_0.461, f32[] %dot.220), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
}

%fused_computation.275 (param_0.462: f32[], param_1.892: f32[8388608]) -> f32[] {
  %param_0.462 = f32[] parameter(0)
  %param_1.892 = f32[8388608]{0} parameter(1)
  %dot.221 = f32[] dot(f32[8388608]{0} %param_1.892, f32[8388608]{0} %param_1.892), lhs_contracting_dims={0}, rhs_contracting_dims={0}, metadata={op_type="dot_general" op_name="pmap(_multi_device_update_fn)/dot_general[ dimension_numbers=(((0,), (0,)), ((), ()))\n                                           precision=None\n                                           preferred_element_type=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  ROOT %add.4194 = f32[] add(f32[] %param_0.462, f32[] %dot.221), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
}

%fused_computation.276 (param_0.463: f32[], param_1.894: f32[262144]) -> f32[] {
  %param_0.463 = f32[] parameter(0)
  %param_1.894 = f32[262144]{0} parameter(1)
  %dot.222 = f32[] dot(f32[262144]{0} %param_1.894, f32[262144]{0} %param_1.894), lhs_contracting_dims={0}, rhs_contracting_dims={0}, metadata={op_type="dot_general" op_name="pmap(_multi_device_update_fn)/dot_general[ dimension_numbers=(((0,), (0,)), ((), ()))\n                                           precision=None\n                                           preferred_element_type=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  ROOT %add.4196 = f32[] add(f32[] %param_0.463, f32[] %dot.222), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
}

%fused_computation.277 (param_0.464: f32[], param_1.896: f32[4096]) -> f32[] {
  %param_0.464 = f32[] parameter(0)
  %param_1.896 = f32[4096]{0} parameter(1)
  %dot.223 = f32[] dot(f32[4096]{0} %param_1.896, f32[4096]{0} %param_1.896), lhs_contracting_dims={0}, rhs_contracting_dims={0}, metadata={op_type="dot_general" op_name="pmap(_multi_device_update_fn)/dot_general[ dimension_numbers=(((0,), (0,)), ((), ()))\n                                           precision=None\n                                           preferred_element_type=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  ROOT %add.4197 = f32[] add(f32[] %param_0.464, f32[] %dot.223), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
}

%fused_computation.278 (param_0.465: f32[], param_1.898: f32[8388608]) -> f32[] {
  %param_0.465 = f32[] parameter(0)
  %param_1.898 = f32[8388608]{0} parameter(1)
  %dot.224 = f32[] dot(f32[8388608]{0} %param_1.898, f32[8388608]{0} %param_1.898), lhs_contracting_dims={0}, rhs_contracting_dims={0}, metadata={op_type="dot_general" op_name="pmap(_multi_device_update_fn)/dot_general[ dimension_numbers=(((0,), (0,)), ((), ()))\n                                           precision=None\n                                           preferred_element_type=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  ROOT %add.4198 = f32[] add(f32[] %param_0.465, f32[] %dot.224), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
}

%fused_computation.279 (param_0.466: f32[], param_1.900: f32[4096]) -> f32[] {
  %param_0.466 = f32[] parameter(0)
  %param_1.900 = f32[4096]{0} parameter(1)
  %dot.225 = f32[] dot(f32[4096]{0} %param_1.900, f32[4096]{0} %param_1.900), lhs_contracting_dims={0}, rhs_contracting_dims={0}, metadata={op_type="dot_general" op_name="pmap(_multi_device_update_fn)/dot_general[ dimension_numbers=(((0,), (0,)), ((), ()))\n                                           precision=None\n                                           preferred_element_type=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  ROOT %add.4199 = f32[] add(f32[] %param_0.466, f32[] %dot.225), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
}

%fused_computation.280 (param_0.467: f32[], param_1.902: f32[8388608]) -> f32[] {
  %param_0.467 = f32[] parameter(0)
  %param_1.902 = f32[8388608]{0} parameter(1)
  %dot.226 = f32[] dot(f32[8388608]{0} %param_1.902, f32[8388608]{0} %param_1.902), lhs_contracting_dims={0}, rhs_contracting_dims={0}, metadata={op_type="dot_general" op_name="pmap(_multi_device_update_fn)/dot_general[ dimension_numbers=(((0,), (0,)), ((), ()))\n                                           precision=None\n                                           preferred_element_type=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  ROOT %add.4200 = f32[] add(f32[] %param_0.467, f32[] %dot.226), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
}

%fused_computation.281 (param_0.468: f32[], param_1.904: f32[4096]) -> f32[] {
  %param_0.468 = f32[] parameter(0)
  %param_1.904 = f32[4096]{0} parameter(1)
  %dot.227 = f32[] dot(f32[4096]{0} %param_1.904, f32[4096]{0} %param_1.904), lhs_contracting_dims={0}, rhs_contracting_dims={0}, metadata={op_type="dot_general" op_name="pmap(_multi_device_update_fn)/dot_general[ dimension_numbers=(((0,), (0,)), ((), ()))\n                                           precision=None\n                                           preferred_element_type=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  ROOT %add.4201 = f32[] add(f32[] %param_0.468, f32[] %dot.227), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
}

%fused_computation.282 (param_0.469: f32[], param_1.906: f32[8388608]) -> f32[] {
  %param_0.469 = f32[] parameter(0)
  %param_1.906 = f32[8388608]{0} parameter(1)
  %dot.228 = f32[] dot(f32[8388608]{0} %param_1.906, f32[8388608]{0} %param_1.906), lhs_contracting_dims={0}, rhs_contracting_dims={0}, metadata={op_type="dot_general" op_name="pmap(_multi_device_update_fn)/dot_general[ dimension_numbers=(((0,), (0,)), ((), ()))\n                                           precision=None\n                                           preferred_element_type=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  ROOT %add.4202 = f32[] add(f32[] %param_0.469, f32[] %dot.228), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
}

%fused_computation.283 (param_0.470: f32[], param_1.908: f32[4096]) -> f32[] {
  %param_0.470 = f32[] parameter(0)
  %param_1.908 = f32[4096]{0} parameter(1)
  %dot.229 = f32[] dot(f32[4096]{0} %param_1.908, f32[4096]{0} %param_1.908), lhs_contracting_dims={0}, rhs_contracting_dims={0}, metadata={op_type="dot_general" op_name="pmap(_multi_device_update_fn)/dot_general[ dimension_numbers=(((0,), (0,)), ((), ()))\n                                           precision=None\n                                           preferred_element_type=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  ROOT %add.4203 = f32[] add(f32[] %param_0.470, f32[] %dot.229), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
}

%fused_computation.284 (param_0.471: f32[], param_1.910: f32[8388608]) -> f32[] {
  %param_0.471 = f32[] parameter(0)
  %param_1.910 = f32[8388608]{0} parameter(1)
  %dot.230 = f32[] dot(f32[8388608]{0} %param_1.910, f32[8388608]{0} %param_1.910), lhs_contracting_dims={0}, rhs_contracting_dims={0}, metadata={op_type="dot_general" op_name="pmap(_multi_device_update_fn)/dot_general[ dimension_numbers=(((0,), (0,)), ((), ()))\n                                           precision=None\n                                           preferred_element_type=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  ROOT %add.4204 = f32[] add(f32[] %param_0.471, f32[] %dot.230), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
}

%primitive_computation_add__1.13196 (parameter.13197: f32[], parameter.13198: f32[]) -> f32[] {
  %parameter.13197 = f32[] parameter(0), metadata={op_type="add" op_name="add"}
  %parameter.13198 = f32[] parameter(1), metadata={op_type="add" op_name="add"}
  ROOT %add.13199 = f32[] add(f32[] %parameter.13197, f32[] %parameter.13198), metadata={op_type="add" op_name="add"}
}

%fused_computation.285 (param_0.475: f32[8,64], param_1.915: f32[8,64,8], param_2.878: f32[]) -> f32[] {
  %param_1.915 = f32[8,64,8]{2,1,0} parameter(1)
  %constant.20756 = f32[] constant(0)
  %reduce.284 = f32[8,64]{1,0} reduce(f32[8,64,8]{2,1,0} %param_1.915, f32[] %constant.20756), dimensions={2}, to_apply=%primitive_computation_add__1.13186, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(2,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/metrics.py" source_line=581}
  %constant.20753 = f32[] constant(-1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/metrics.py" source_line=581}
  %broadcast.1840 = f32[8,64]{1,0} broadcast(f32[] %constant.20753), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/metrics.py" source_line=581}
  %multiply.1575 = f32[8,64]{1,0} multiply(f32[8,64]{1,0} %reduce.284, f32[8,64]{1,0} %broadcast.1840), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/metrics.py" source_line=581}
  %param_0.475 = f32[8,64]{1,0} parameter(0)
  %multiply.1574 = f32[8,64]{1,0} multiply(f32[8,64]{1,0} %multiply.1575, f32[8,64]{1,0} %param_0.475), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/metrics.py" source_line=617}
  %reduce.283 = f32[] reduce(f32[8,64]{1,0} %multiply.1574, f32[] %constant.20756), dimensions={0,1}, to_apply=%primitive_computation_add__1.13196, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0, 1) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/metrics.py" source_line=617}
  %param_2.878 = f32[] parameter(2)
  %constant.20755 = f32[] constant(0.0625)
  %multiply.1576 = f32[] multiply(f32[] %param_2.878, f32[] %constant.20755), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/metrics.py" source_line=108}
  ROOT %divide.193 = f32[] divide(f32[] %reduce.283, f32[] %multiply.1576), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/metrics.py" source_line=617}
}

%fused_computation.287 (param_0.478: f32[], param_1.921: f32[256]) -> f32[] {
  %param_0.478 = f32[] parameter(0)
  %param_1.921 = f32[256]{0} parameter(1)
  %dot.231 = f32[] dot(f32[256]{0} %param_1.921, f32[256]{0} %param_1.921), lhs_contracting_dims={0}, rhs_contracting_dims={0}, metadata={op_type="dot_general" op_name="pmap(_multi_device_update_fn)/dot_general[ dimension_numbers=(((0,), (0,)), ((), ()))\n                                           precision=None\n                                           preferred_element_type=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  ROOT %add.4208 = f32[] add(f32[] %param_0.478, f32[] %dot.231), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
}

%fused_computation.288 (param_0.479: f32[], param_1.923: f32[262144]) -> f32[] {
  %param_0.479 = f32[] parameter(0)
  %param_1.923 = f32[262144]{0} parameter(1)
  %dot.232 = f32[] dot(f32[262144]{0} %param_1.923, f32[262144]{0} %param_1.923), lhs_contracting_dims={0}, rhs_contracting_dims={0}, metadata={op_type="dot_general" op_name="pmap(_multi_device_update_fn)/dot_general[ dimension_numbers=(((0,), (0,)), ((), ()))\n                                           precision=None\n                                           preferred_element_type=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  ROOT %add.4209 = f32[] add(f32[] %param_0.479, f32[] %dot.232), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
}

%fused_computation.290 (param_0.482: f32[], param_1.927: f32[4096]) -> f32[] {
  %param_0.482 = f32[] parameter(0)
  %param_1.927 = f32[4096]{0} parameter(1)
  %dot.233 = f32[] dot(f32[4096]{0} %param_1.927, f32[4096]{0} %param_1.927), lhs_contracting_dims={0}, rhs_contracting_dims={0}, metadata={op_type="dot_general" op_name="pmap(_multi_device_update_fn)/dot_general[ dimension_numbers=(((0,), (0,)), ((), ()))\n                                           precision=None\n                                           preferred_element_type=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  ROOT %add.4210 = f32[] add(f32[] %param_0.482, f32[] %dot.233), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
}

%fused_computation.291 (param_0.483: f32[], param_1.929: f32[8388608]) -> f32[] {
  %param_0.483 = f32[] parameter(0)
  %param_1.929 = f32[8388608]{0} parameter(1)
  %dot.234 = f32[] dot(f32[8388608]{0} %param_1.929, f32[8388608]{0} %param_1.929), lhs_contracting_dims={0}, rhs_contracting_dims={0}, metadata={op_type="dot_general" op_name="pmap(_multi_device_update_fn)/dot_general[ dimension_numbers=(((0,), (0,)), ((), ()))\n                                           precision=None\n                                           preferred_element_type=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  ROOT %add.4211 = f32[] add(f32[] %param_0.483, f32[] %dot.234), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
}

%fused_computation.293 (param_0.486: f32[], param_1.933: f32[4096]) -> f32[] {
  %param_0.486 = f32[] parameter(0)
  %param_1.933 = f32[4096]{0} parameter(1)
  %dot.235 = f32[] dot(f32[4096]{0} %param_1.933, f32[4096]{0} %param_1.933), lhs_contracting_dims={0}, rhs_contracting_dims={0}, metadata={op_type="dot_general" op_name="pmap(_multi_device_update_fn)/dot_general[ dimension_numbers=(((0,), (0,)), ((), ()))\n                                           precision=None\n                                           preferred_element_type=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  ROOT %add.4212 = f32[] add(f32[] %param_0.486, f32[] %dot.235), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
}

%fused_computation.294 (param_0.487: f32[], param_1.935: f32[8388608]) -> f32[] {
  %param_0.487 = f32[] parameter(0)
  %param_1.935 = f32[8388608]{0} parameter(1)
  %dot.236 = f32[] dot(f32[8388608]{0} %param_1.935, f32[8388608]{0} %param_1.935), lhs_contracting_dims={0}, rhs_contracting_dims={0}, metadata={op_type="dot_general" op_name="pmap(_multi_device_update_fn)/dot_general[ dimension_numbers=(((0,), (0,)), ((), ()))\n                                           precision=None\n                                           preferred_element_type=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  ROOT %add.4213 = f32[] add(f32[] %param_0.487, f32[] %dot.236), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
}

%fused_computation.296 (param_0.490: f32[], param_1.939: f32[4096]) -> f32[] {
  %param_0.490 = f32[] parameter(0)
  %param_1.939 = f32[4096]{0} parameter(1)
  %dot.237 = f32[] dot(f32[4096]{0} %param_1.939, f32[4096]{0} %param_1.939), lhs_contracting_dims={0}, rhs_contracting_dims={0}, metadata={op_type="dot_general" op_name="pmap(_multi_device_update_fn)/dot_general[ dimension_numbers=(((0,), (0,)), ((), ()))\n                                           precision=None\n                                           preferred_element_type=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  ROOT %add.4214 = f32[] add(f32[] %param_0.490, f32[] %dot.237), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
}

%fused_computation.297 (param_0.491: f32[], param_1.941: f32[8388608]) -> f32[] {
  %param_0.491 = f32[] parameter(0)
  %param_1.941 = f32[8388608]{0} parameter(1)
  %dot.238 = f32[] dot(f32[8388608]{0} %param_1.941, f32[8388608]{0} %param_1.941), lhs_contracting_dims={0}, rhs_contracting_dims={0}, metadata={op_type="dot_general" op_name="pmap(_multi_device_update_fn)/dot_general[ dimension_numbers=(((0,), (0,)), ((), ()))\n                                           precision=None\n                                           preferred_element_type=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  ROOT %add.4215 = f32[] add(f32[] %param_0.491, f32[] %dot.238), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
}

%fused_computation.299 (param_0.494: f32[], param_1.945: f32[4096]) -> f32[] {
  %param_0.494 = f32[] parameter(0)
  %param_1.945 = f32[4096]{0} parameter(1)
  %dot.239 = f32[] dot(f32[4096]{0} %param_1.945, f32[4096]{0} %param_1.945), lhs_contracting_dims={0}, rhs_contracting_dims={0}, metadata={op_type="dot_general" op_name="pmap(_multi_device_update_fn)/dot_general[ dimension_numbers=(((0,), (0,)), ((), ()))\n                                           precision=None\n                                           preferred_element_type=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  ROOT %add.4216 = f32[] add(f32[] %param_0.494, f32[] %dot.239), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
}

%fused_computation.300 (param_0.495: f32[], param_1.947: f32[8388608]) -> f32[] {
  %param_0.495 = f32[] parameter(0)
  %param_1.947 = f32[8388608]{0} parameter(1)
  %dot.240 = f32[] dot(f32[8388608]{0} %param_1.947, f32[8388608]{0} %param_1.947), lhs_contracting_dims={0}, rhs_contracting_dims={0}, metadata={op_type="dot_general" op_name="pmap(_multi_device_update_fn)/dot_general[ dimension_numbers=(((0,), (0,)), ((), ()))\n                                           precision=None\n                                           preferred_element_type=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  ROOT %add.4217 = f32[] add(f32[] %param_0.495, f32[] %dot.240), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
}

%fused_computation.302 (param_0.498: f32[], param_1.951: f32[1024]) -> f32[] {
  %param_0.498 = f32[] parameter(0)
  %param_1.951 = f32[1024]{0} parameter(1)
  %dot.241 = f32[] dot(f32[1024]{0} %param_1.951, f32[1024]{0} %param_1.951), lhs_contracting_dims={0}, rhs_contracting_dims={0}, metadata={op_type="dot_general" op_name="pmap(_multi_device_update_fn)/dot_general[ dimension_numbers=(((0,), (0,)), ((), ()))\n                                           precision=None\n                                           preferred_element_type=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  ROOT %add.4218 = f32[] add(f32[] %param_0.498, f32[] %dot.241), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
}

%fused_computation.303 (param_0.499: f32[], param_1.953: f32[1048576]) -> f32[] {
  %param_0.499 = f32[] parameter(0)
  %param_1.953 = f32[1048576]{0} parameter(1)
  %dot.242 = f32[] dot(f32[1048576]{0} %param_1.953, f32[1048576]{0} %param_1.953), lhs_contracting_dims={0}, rhs_contracting_dims={0}, metadata={op_type="dot_general" op_name="pmap(_multi_device_update_fn)/dot_general[ dimension_numbers=(((0,), (0,)), ((), ()))\n                                           precision=None\n                                           preferred_element_type=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  ROOT %add.4219 = f32[] add(f32[] %param_0.499, f32[] %dot.242), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
}

%fused_computation.305 (param_0.502: f32[], param_1.957: f32[1024]) -> f32[] {
  %param_0.502 = f32[] parameter(0)
  %param_1.957 = f32[1024]{0} parameter(1)
  %dot.243 = f32[] dot(f32[1024]{0} %param_1.957, f32[1024]{0} %param_1.957), lhs_contracting_dims={0}, rhs_contracting_dims={0}, metadata={op_type="dot_general" op_name="pmap(_multi_device_update_fn)/dot_general[ dimension_numbers=(((0,), (0,)), ((), ()))\n                                           precision=None\n                                           preferred_element_type=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  ROOT %add.4220 = f32[] add(f32[] %param_0.502, f32[] %dot.243), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
}

%fused_computation.306 (param_0.503: f32[], param_1.959: f32[1048576]) -> f32[] {
  %param_0.503 = f32[] parameter(0)
  %param_1.959 = f32[1048576]{0} parameter(1)
  %dot.244 = f32[] dot(f32[1048576]{0} %param_1.959, f32[1048576]{0} %param_1.959), lhs_contracting_dims={0}, rhs_contracting_dims={0}, metadata={op_type="dot_general" op_name="pmap(_multi_device_update_fn)/dot_general[ dimension_numbers=(((0,), (0,)), ((), ()))\n                                           precision=None\n                                           preferred_element_type=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  ROOT %add.4221 = f32[] add(f32[] %param_0.503, f32[] %dot.244), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
}

%fused_computation.308 (param_0.506: f32[], param_1.963: f32[1024]) -> f32[] {
  %param_0.506 = f32[] parameter(0)
  %param_1.963 = f32[1024]{0} parameter(1)
  %dot.245 = f32[] dot(f32[1024]{0} %param_1.963, f32[1024]{0} %param_1.963), lhs_contracting_dims={0}, rhs_contracting_dims={0}, metadata={op_type="dot_general" op_name="pmap(_multi_device_update_fn)/dot_general[ dimension_numbers=(((0,), (0,)), ((), ()))\n                                           precision=None\n                                           preferred_element_type=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  ROOT %add.4222 = f32[] add(f32[] %param_0.506, f32[] %dot.245), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
}

%fused_computation.309 (param_0.507: f32[], param_1.965: f32[1048576]) -> f32[] {
  %param_0.507 = f32[] parameter(0)
  %param_1.965 = f32[1048576]{0} parameter(1)
  %dot.246 = f32[] dot(f32[1048576]{0} %param_1.965, f32[1048576]{0} %param_1.965), lhs_contracting_dims={0}, rhs_contracting_dims={0}, metadata={op_type="dot_general" op_name="pmap(_multi_device_update_fn)/dot_general[ dimension_numbers=(((0,), (0,)), ((), ()))\n                                           precision=None\n                                           preferred_element_type=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  ROOT %add.4223 = f32[] add(f32[] %param_0.507, f32[] %dot.246), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
}

%fused_computation.311 (param_0.510: f32[], param_1.969: f32[1024]) -> f32[] {
  %param_0.510 = f32[] parameter(0)
  %param_1.969 = f32[1024]{0} parameter(1)
  %dot.247 = f32[] dot(f32[1024]{0} %param_1.969, f32[1024]{0} %param_1.969), lhs_contracting_dims={0}, rhs_contracting_dims={0}, metadata={op_type="dot_general" op_name="pmap(_multi_device_update_fn)/dot_general[ dimension_numbers=(((0,), (0,)), ((), ()))\n                                           precision=None\n                                           preferred_element_type=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  ROOT %add.4224 = f32[] add(f32[] %param_0.510, f32[] %dot.247), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
}

%fused_computation.312 (param_0.511: f32[], param_1.971: f32[1048576]) -> f32[] {
  %param_0.511 = f32[] parameter(0)
  %param_1.971 = f32[1048576]{0} parameter(1)
  %dot.248 = f32[] dot(f32[1048576]{0} %param_1.971, f32[1048576]{0} %param_1.971), lhs_contracting_dims={0}, rhs_contracting_dims={0}, metadata={op_type="dot_general" op_name="pmap(_multi_device_update_fn)/dot_general[ dimension_numbers=(((0,), (0,)), ((), ()))\n                                           precision=None\n                                           preferred_element_type=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  ROOT %add.4225 = f32[] add(f32[] %param_0.511, f32[] %dot.248), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
}

%fused_computation.314 (param_0.514: f32[], param_1.975: f32[4096]) -> f32[] {
  %param_0.514 = f32[] parameter(0)
  %param_1.975 = f32[4096]{0} parameter(1)
  %dot.249 = f32[] dot(f32[4096]{0} %param_1.975, f32[4096]{0} %param_1.975), lhs_contracting_dims={0}, rhs_contracting_dims={0}, metadata={op_type="dot_general" op_name="pmap(_multi_device_update_fn)/dot_general[ dimension_numbers=(((0,), (0,)), ((), ()))\n                                           precision=None\n                                           preferred_element_type=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  ROOT %add.4226 = f32[] add(f32[] %param_0.514, f32[] %dot.249), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
}

%fused_computation.315 (param_0.515: f32[], param_1.977: f32[8388608]) -> f32[] {
  %param_0.515 = f32[] parameter(0)
  %param_1.977 = f32[8388608]{0} parameter(1)
  %dot.250 = f32[] dot(f32[8388608]{0} %param_1.977, f32[8388608]{0} %param_1.977), lhs_contracting_dims={0}, rhs_contracting_dims={0}, metadata={op_type="dot_general" op_name="pmap(_multi_device_update_fn)/dot_general[ dimension_numbers=(((0,), (0,)), ((), ()))\n                                           precision=None\n                                           preferred_element_type=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  ROOT %add.4227 = f32[] add(f32[] %param_0.515, f32[] %dot.250), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
}

%fused_computation.317 (param_0.518: f32[], param_1.981: f32[262144]) -> f32[] {
  %param_0.518 = f32[] parameter(0)
  %param_1.981 = f32[262144]{0} parameter(1)
  %dot.251 = f32[] dot(f32[262144]{0} %param_1.981, f32[262144]{0} %param_1.981), lhs_contracting_dims={0}, rhs_contracting_dims={0}, metadata={op_type="dot_general" op_name="pmap(_multi_device_update_fn)/dot_general[ dimension_numbers=(((0,), (0,)), ((), ()))\n                                           precision=None\n                                           preferred_element_type=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  ROOT %add.4229 = f32[] add(f32[] %param_0.518, f32[] %dot.251), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
}

%fused_computation.319 (param_0.521: f32[], param_1.985: f32[4096]) -> f32[] {
  %param_0.521 = f32[] parameter(0)
  %param_1.985 = f32[4096]{0} parameter(1)
  %dot.252 = f32[] dot(f32[4096]{0} %param_1.985, f32[4096]{0} %param_1.985), lhs_contracting_dims={0}, rhs_contracting_dims={0}, metadata={op_type="dot_general" op_name="pmap(_multi_device_update_fn)/dot_general[ dimension_numbers=(((0,), (0,)), ((), ()))\n                                           precision=None\n                                           preferred_element_type=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  ROOT %add.4231 = f32[] add(f32[] %param_0.521, f32[] %dot.252), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
}

%fused_computation.320 (param_0.522: f32[], param_1.987: f32[8388608]) -> f32[] {
  %param_0.522 = f32[] parameter(0)
  %param_1.987 = f32[8388608]{0} parameter(1)
  %dot.253 = f32[] dot(f32[8388608]{0} %param_1.987, f32[8388608]{0} %param_1.987), lhs_contracting_dims={0}, rhs_contracting_dims={0}, metadata={op_type="dot_general" op_name="pmap(_multi_device_update_fn)/dot_general[ dimension_numbers=(((0,), (0,)), ((), ()))\n                                           precision=None\n                                           preferred_element_type=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  ROOT %add.4232 = f32[] add(f32[] %param_0.522, f32[] %dot.253), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
}

%fused_computation.322 (param_0.525: f32[], param_1.991: f32[4096]) -> f32[] {
  %param_0.525 = f32[] parameter(0)
  %param_1.991 = f32[4096]{0} parameter(1)
  %dot.254 = f32[] dot(f32[4096]{0} %param_1.991, f32[4096]{0} %param_1.991), lhs_contracting_dims={0}, rhs_contracting_dims={0}, metadata={op_type="dot_general" op_name="pmap(_multi_device_update_fn)/dot_general[ dimension_numbers=(((0,), (0,)), ((), ()))\n                                           precision=None\n                                           preferred_element_type=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  ROOT %add.4233 = f32[] add(f32[] %param_0.525, f32[] %dot.254), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
}

%fused_computation.323 (param_0.526: f32[], param_1.993: f32[8388608]) -> f32[] {
  %param_0.526 = f32[] parameter(0)
  %param_1.993 = f32[8388608]{0} parameter(1)
  %dot.255 = f32[] dot(f32[8388608]{0} %param_1.993, f32[8388608]{0} %param_1.993), lhs_contracting_dims={0}, rhs_contracting_dims={0}, metadata={op_type="dot_general" op_name="pmap(_multi_device_update_fn)/dot_general[ dimension_numbers=(((0,), (0,)), ((), ()))\n                                           precision=None\n                                           preferred_element_type=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  ROOT %add.4234 = f32[] add(f32[] %param_0.526, f32[] %dot.255), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
}

%fused_computation.325 (param_0.529: f32[], param_1.997: f32[4096]) -> f32[] {
  %param_0.529 = f32[] parameter(0)
  %param_1.997 = f32[4096]{0} parameter(1)
  %dot.256 = f32[] dot(f32[4096]{0} %param_1.997, f32[4096]{0} %param_1.997), lhs_contracting_dims={0}, rhs_contracting_dims={0}, metadata={op_type="dot_general" op_name="pmap(_multi_device_update_fn)/dot_general[ dimension_numbers=(((0,), (0,)), ((), ()))\n                                           precision=None\n                                           preferred_element_type=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  ROOT %add.4235 = f32[] add(f32[] %param_0.529, f32[] %dot.256), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
}

%fused_computation.326 (param_0.530: f32[], param_1.999: f32[8388608]) -> f32[] {
  %param_0.530 = f32[] parameter(0)
  %param_1.999 = f32[8388608]{0} parameter(1)
  %dot.257 = f32[] dot(f32[8388608]{0} %param_1.999, f32[8388608]{0} %param_1.999), lhs_contracting_dims={0}, rhs_contracting_dims={0}, metadata={op_type="dot_general" op_name="pmap(_multi_device_update_fn)/dot_general[ dimension_numbers=(((0,), (0,)), ((), ()))\n                                           precision=None\n                                           preferred_element_type=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  ROOT %add.4236 = f32[] add(f32[] %param_0.530, f32[] %dot.257), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
}

%fused_computation.328 (param_0.533: f32[], param_1.1003: f32[4096]) -> f32[] {
  %param_0.533 = f32[] parameter(0)
  %param_1.1003 = f32[4096]{0} parameter(1)
  %dot.258 = f32[] dot(f32[4096]{0} %param_1.1003, f32[4096]{0} %param_1.1003), lhs_contracting_dims={0}, rhs_contracting_dims={0}, metadata={op_type="dot_general" op_name="pmap(_multi_device_update_fn)/dot_general[ dimension_numbers=(((0,), (0,)), ((), ()))\n                                           precision=None\n                                           preferred_element_type=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  ROOT %add.4237 = f32[] add(f32[] %param_0.533, f32[] %dot.258), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
}

%fused_computation.329 (param_0.534: f32[], param_1.1005: f32[8388608]) -> f32[] {
  %param_0.534 = f32[] parameter(0)
  %param_1.1005 = f32[8388608]{0} parameter(1)
  %dot.259 = f32[] dot(f32[8388608]{0} %param_1.1005, f32[8388608]{0} %param_1.1005), lhs_contracting_dims={0}, rhs_contracting_dims={0}, metadata={op_type="dot_general" op_name="pmap(_multi_device_update_fn)/dot_general[ dimension_numbers=(((0,), (0,)), ((), ()))\n                                           precision=None\n                                           preferred_element_type=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  ROOT %add.4238 = f32[] add(f32[] %param_0.534, f32[] %dot.259), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
}

%fused_computation.332 (param_0.540: f32[256], param_1.1014: f32[], param_2.888: f32[], param_3.748: f32[], param_4.396: f32[], param_5.390: f32[256], param_6.343: f32[], param_7.270: f32[], param_8.210: s32[]) -> f32[256] {
  %constant.20778 = f32[] constant(1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/metrics.py" source_line=617}
  %param_8.210 = s32[] parameter(8)
  %constant.20777 = s32[] constant(1), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=113}
  %compare.2766 = pred[] compare(s32[] %param_8.210, s32[] %constant.20777), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=113}
  %param_6.343 = f32[] parameter(6)
  %param_7.270 = f32[] parameter(7)
  %select.2655 = f32[] select(pred[] %compare.2766, f32[] %param_6.343, f32[] %param_7.270), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/jit(_where)/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=112}
  %subtract.548 = f32[] subtract(f32[] %constant.20778, f32[] %select.2655), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  %broadcast.1864 = f32[256]{0} broadcast(f32[] %subtract.548), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  %param_5.390 = f32[256]{0} parameter(5)
  %multiply.1595 = f32[256]{0} multiply(f32[256]{0} %broadcast.1864, f32[256]{0} %param_5.390), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  %param_2.888 = f32[] parameter(2)
  %param_3.748 = f32[] parameter(3)
  %param_4.396 = f32[] parameter(4)
  %maximum.4 = f32[] maximum(f32[] %param_3.748, f32[] %param_4.396), metadata={op_type="max" op_name="pmap(_multi_device_update_fn)/max" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=122}
  %multiply.1594 = f32[] multiply(f32[] %param_2.888, f32[] %maximum.4), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=122}
  %broadcast.1863 = f32[256]{0} broadcast(f32[] %multiply.1594), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=152}
  %param_0.540 = f32[256]{0} parameter(0)
  %param_1.1014 = f32[] parameter(1)
  %maximum.3 = f32[] maximum(f32[] %constant.20778, f32[] %param_1.1014), metadata={op_type="max" op_name="pmap(_multi_device_update_fn)/max" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %broadcast.1862 = f32[256]{0} broadcast(f32[] %maximum.3), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=150}
  %divide.194 = f32[256]{0} divide(f32[256]{0} %param_0.540, f32[256]{0} %broadcast.1862), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=150}
  %multiply.1593 = f32[256]{0} multiply(f32[256]{0} %broadcast.1863, f32[256]{0} %divide.194), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=152}
  ROOT %subtract.547 = f32[256]{0} subtract(f32[256]{0} %multiply.1595, f32[256]{0} %multiply.1593), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
}

%fused_computation.333 (param_0.542: f32[], param_1.1019: f32[8]) -> f32[] {
  %param_1.1019 = f32[8]{0} parameter(1)
  %constant.20781 = f32[] constant(0)
  %reduce.285 = f32[] reduce(f32[8]{0} %param_1.1019, f32[] %constant.20781), dimensions={0}, to_apply=%primitive_computation_add__1.21586, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %constant.20780 = f32[] constant(0.00390625)
  %multiply.1596 = f32[] multiply(f32[] %reduce.285, f32[] %constant.20780), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %sqrt.0 = f32[] sqrt(f32[] %multiply.1596), metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %param_0.542 = f32[] parameter(0)
  ROOT %divide.195 = f32[] divide(f32[] %sqrt.0, f32[] %param_0.542), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
}

%fused_computation.334 (param_0.545: f32[256], param_1.1025: f32[256], param_2.898: f32[]) -> f32[256] {
  %param_1.1025 = f32[256]{0} parameter(1)
  %constant.20783 = f32[] constant(0.0625)
  %broadcast.1866 = f32[256]{0} broadcast(f32[] %constant.20783), dimensions={}
  %multiply.1598 = f32[256]{0} multiply(f32[256]{0} %param_1.1025, f32[256]{0} %broadcast.1866), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=200}
  %param_0.545 = f32[256]{0} parameter(0)
  %param_2.898 = f32[] parameter(2)
  %broadcast.1867 = f32[256]{0} broadcast(f32[] %param_2.898), dimensions={}, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  %add.4239 = f32[256]{0} add(f32[256]{0} %param_0.545, f32[256]{0} %broadcast.1867), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=145}
  %constant.20782 = f32[] constant(-0.5), metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
  %broadcast.1865 = f32[256]{0} broadcast(f32[] %constant.20782), dimensions={}, metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
  %power.0 = f32[256]{0} power(f32[256]{0} %add.4239, f32[256]{0} %broadcast.1865), metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=145}
  ROOT %multiply.1597 = f32[256]{0} multiply(f32[256]{0} %multiply.1598, f32[256]{0} %power.0), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=145}
}

%fused_computation.335 (param_0.549: f32[256], param_1.1032: f32[256], param_2.907: f32[]) -> f32[256] {
  %constant.20786 = f32[] constant(1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/metrics.py" source_line=617}
  %param_2.907 = f32[] parameter(2)
  %subtract.550 = f32[] subtract(f32[] %constant.20786, f32[] %param_2.907), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=85}
  %broadcast.1870 = f32[256]{0} broadcast(f32[] %subtract.550), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=131}
  %param_0.549 = f32[256]{0} parameter(0)
  %multiply.1601 = f32[256]{0} multiply(f32[256]{0} %broadcast.1870, f32[256]{0} %param_0.549), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=143}
  %subtract.549 = f32[] subtract(f32[] %constant.20786, f32[] %subtract.550), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=124}
  %broadcast.1868 = f32[256]{0} broadcast(f32[] %subtract.549), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=143}
  %param_1.1032 = f32[256]{0} parameter(1)
  %constant.20784 = f32[] constant(0.0625)
  %broadcast.1869 = f32[256]{0} broadcast(f32[] %constant.20784), dimensions={}
  %multiply.1602 = f32[256]{0} multiply(f32[256]{0} %param_1.1032, f32[256]{0} %broadcast.1869), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=200}
  %multiply.1600 = f32[256]{0} multiply(f32[256]{0} %multiply.1602, f32[256]{0} %multiply.1602), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=126}
  %multiply.1599 = f32[256]{0} multiply(f32[256]{0} %broadcast.1868, f32[256]{0} %multiply.1600), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=143}
  ROOT %add.4240 = f32[256]{0} add(f32[256]{0} %multiply.1601, f32[256]{0} %multiply.1599), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=143}
}

%fused_computation.336 (param_0.550: f32[256]) -> f32[256] {
  %param_0.550 = f32[256]{0} parameter(0)
  %constant.20787 = f32[] constant(0.0625)
  %broadcast.1871 = f32[256]{0} broadcast(f32[] %constant.20787), dimensions={}
  ROOT %multiply.1603 = f32[256]{0} multiply(f32[256]{0} %param_0.550, f32[256]{0} %broadcast.1871), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=200}
}

%fused_computation.337 (param_0.554: f32[8]) -> f32[] {
  %param_0.554 = f32[8]{0} parameter(0)
  %constant.20789 = f32[] constant(0)
  %reduce.286 = f32[] reduce(f32[8]{0} %param_0.554, f32[] %constant.20789), dimensions={0}, to_apply=%primitive_computation_add__1.21560, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %constant.20788 = f32[] constant(0.00390625)
  %multiply.1604 = f32[] multiply(f32[] %reduce.286, f32[] %constant.20788), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  ROOT %sqrt.1 = f32[] sqrt(f32[] %multiply.1604), metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
}

%fused_computation.339 (param_0.559: f32[], param_1.1047: f32[32,8]) -> f32[] {
  %param_1.1047 = f32[32,8]{1,0} parameter(1)
  %constant.20796 = f32[] constant(0)
  %reduce.287 = f32[] reduce(f32[32,8]{1,0} %param_1.1047, f32[] %constant.20796), dimensions={0,1}, to_apply=%primitive_computation_add__1.21508, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0, 1) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %constant.20794 = f32[] constant(3.81469727e-06)
  %multiply.1611 = f32[] multiply(f32[] %reduce.287, f32[] %constant.20794), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %sqrt.2 = f32[] sqrt(f32[] %multiply.1611), metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %param_0.559 = f32[] parameter(0)
  ROOT %divide.197 = f32[] divide(f32[] %sqrt.2, f32[] %param_0.559), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
}

%fused_computation.341 (param_0.565: f32[256], param_1.1054: f32[]) -> f32[256] {
  %param_0.565 = f32[256]{0} parameter(0)
  %param_1.1054 = f32[] parameter(1)
  %broadcast.1882 = f32[256]{0} broadcast(f32[] %param_1.1054), dimensions={}, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  %add.4241 = f32[256]{0} add(f32[256]{0} %param_0.565, f32[256]{0} %broadcast.1882), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
  %constant.20798 = f32[] constant(-0.5), metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
  %broadcast.1881 = f32[256]{0} broadcast(f32[] %constant.20798), dimensions={}, metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
  ROOT %power.1 = f32[256]{0} power(f32[256]{0} %add.4241, f32[256]{0} %broadcast.1881), metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
}

%fused_computation.342 (param_0.567: f32[1,256], param_1.1059: f32[256], param_2.929: f32[]) -> f32[256] {
  %constant.20801 = f32[] constant(1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/metrics.py" source_line=617}
  %param_2.929 = f32[] parameter(2)
  %subtract.554 = f32[] subtract(f32[] %constant.20801, f32[] %param_2.929), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=85}
  %broadcast.1884 = f32[256]{0} broadcast(f32[] %subtract.554), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=131}
  %param_1.1059 = f32[256]{0} parameter(1)
  %multiply.1617 = f32[256]{0} multiply(f32[256]{0} %broadcast.1884, f32[256]{0} %param_1.1059), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
  %param_0.567 = f32[1,256]{1,0} parameter(0)
  %subtract.553 = f32[] subtract(f32[] %constant.20801, f32[] %subtract.554), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=124}
  %constant.20799 = f32[] constant(0.0009765625)
  %multiply.1618 = f32[] multiply(f32[] %subtract.553, f32[] %constant.20799)
  %broadcast.1883 = f32[1,256]{1,0} broadcast(f32[] %multiply.1618), dimensions={}
  %multiply.1616 = f32[1,256]{1,0} multiply(f32[1,256]{1,0} %param_0.567, f32[1,256]{1,0} %broadcast.1883), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
  %reshape.3227 = f32[256]{0} reshape(f32[1,256]{1,0} %multiply.1616), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
  ROOT %add.4242 = f32[256]{0} add(f32[256]{0} %multiply.1617, f32[256]{0} %reshape.3227), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
}

%fused_computation.343 (param_0.570: f32[1024], param_1.1064: f32[1], param_2.935: f32[]) -> f32[1024] {
  %param_1.1064 = f32[1]{0} parameter(1)
  %constant.20802 = f32[1]{0} constant({0.0009765625})
  %multiply.1619 = f32[1]{0} multiply(f32[1]{0} %param_1.1064, f32[1]{0} %constant.20802), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=135}
  %reshape.3228 = f32[] reshape(f32[1]{0} %multiply.1619), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  %broadcast.1885 = f32[1024]{0} broadcast(f32[] %reshape.3228), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  %param_0.570 = f32[1024]{0} parameter(0)
  %param_2.935 = f32[] parameter(2)
  %broadcast.1887 = f32[1024]{0} broadcast(f32[] %param_2.935), dimensions={}, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
  %add.4243 = f32[1024]{0} add(f32[1024]{0} %param_0.570, f32[1024]{0} %broadcast.1887), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  %divide.198 = f32[1024]{0} divide(f32[1024]{0} %broadcast.1885, f32[1024]{0} %add.4243), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  %constant.20803 = f32[] constant(0.5), metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  %broadcast.1886 = f32[1024]{0} broadcast(f32[] %constant.20803), dimensions={}, metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  ROOT %power.2 = f32[1024]{0} power(f32[1024]{0} %divide.198, f32[1024]{0} %broadcast.1886), metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
}

%fused_computation.344 (param_0.573: f32[1024,8], param_1.1070: f32[1024], param_2.942: f32[]) -> f32[1024] {
  %constant.20806 = f32[] constant(1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/metrics.py" source_line=617}
  %param_2.942 = f32[] parameter(2)
  %subtract.557 = f32[] subtract(f32[] %constant.20806, f32[] %param_2.942), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=85}
  %broadcast.1889 = f32[1024]{0} broadcast(f32[] %subtract.557), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
  %param_1.1070 = f32[1024]{0} parameter(1)
  %multiply.1621 = f32[1024]{0} multiply(f32[1024]{0} %broadcast.1889, f32[1024]{0} %param_1.1070), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=131}
  %param_0.573 = f32[1024,8]{1,0} parameter(0)
  %constant.20805 = f32[] constant(0)
  %reduce.288 = f32[1024]{0} reduce(f32[1024,8]{1,0} %param_0.573, f32[] %constant.20805), dimensions={1}, to_apply=%primitive_computation_add__1.21450, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(1,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=131}
  %subtract.556 = f32[] subtract(f32[] %constant.20806, f32[] %subtract.557), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=124}
  %constant.20804 = f32[] constant(0.00390625)
  %multiply.1622 = f32[] multiply(f32[] %subtract.556, f32[] %constant.20804)
  %broadcast.1888 = f32[1024]{0} broadcast(f32[] %multiply.1622), dimensions={}
  %multiply.1620 = f32[1024]{0} multiply(f32[1024]{0} %reduce.288, f32[1024]{0} %broadcast.1888), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=131}
  ROOT %add.4244 = f32[1024]{0} add(f32[1024]{0} %multiply.1621, f32[1024]{0} %multiply.1620), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=131}
}

%fused_computation.347 (param_0.581: f32[32,8]) -> f32[] {
  %param_0.581 = f32[32,8]{1,0} parameter(0)
  %constant.20810 = f32[] constant(0)
  %reduce.289 = f32[] reduce(f32[32,8]{1,0} %param_0.581, f32[] %constant.20810), dimensions={0,1}, to_apply=%primitive_computation_add__1.21434, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0, 1) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %constant.20809 = f32[] constant(3.81469727e-06)
  %multiply.1625 = f32[] multiply(f32[] %reduce.289, f32[] %constant.20809), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  ROOT %sqrt.3 = f32[] sqrt(f32[] %multiply.1625), metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
}

%fused_computation.348 (param_0.583: f32[4096], param_1.1080: f32[], param_2.948: f32[], param_3.796: f32[], param_4.425: f32[], param_5.402: f32[4096], param_6.354: f32[], param_7.282: f32[], param_8.218: s32[]) -> f32[4096] {
  %constant.20812 = f32[] constant(1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/metrics.py" source_line=617}
  %param_8.218 = s32[] parameter(8)
  %constant.20811 = s32[] constant(1), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=113}
  %compare.2768 = pred[] compare(s32[] %param_8.218, s32[] %constant.20811), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=113}
  %param_6.354 = f32[] parameter(6)
  %param_7.282 = f32[] parameter(7)
  %select.2657 = f32[] select(pred[] %compare.2768, f32[] %param_6.354, f32[] %param_7.282), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/jit(_where)/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=112}
  %subtract.559 = f32[] subtract(f32[] %constant.20812, f32[] %select.2657), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  %broadcast.1893 = f32[4096]{0} broadcast(f32[] %subtract.559), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  %param_5.402 = f32[4096]{0} parameter(5)
  %multiply.1628 = f32[4096]{0} multiply(f32[4096]{0} %broadcast.1893, f32[4096]{0} %param_5.402), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  %param_2.948 = f32[] parameter(2)
  %param_3.796 = f32[] parameter(3)
  %param_4.425 = f32[] parameter(4)
  %maximum.8 = f32[] maximum(f32[] %param_3.796, f32[] %param_4.425), metadata={op_type="max" op_name="pmap(_multi_device_update_fn)/max" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=122}
  %multiply.1627 = f32[] multiply(f32[] %param_2.948, f32[] %maximum.8), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=122}
  %broadcast.1892 = f32[4096]{0} broadcast(f32[] %multiply.1627), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=152}
  %param_0.583 = f32[4096]{0} parameter(0)
  %param_1.1080 = f32[] parameter(1)
  %maximum.7 = f32[] maximum(f32[] %constant.20812, f32[] %param_1.1080), metadata={op_type="max" op_name="pmap(_multi_device_update_fn)/max" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %broadcast.1891 = f32[4096]{0} broadcast(f32[] %maximum.7), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=150}
  %divide.199 = f32[4096]{0} divide(f32[4096]{0} %param_0.583, f32[4096]{0} %broadcast.1891), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=150}
  %multiply.1626 = f32[4096]{0} multiply(f32[4096]{0} %broadcast.1892, f32[4096]{0} %divide.199), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=152}
  ROOT %subtract.558 = f32[4096]{0} subtract(f32[4096]{0} %multiply.1628, f32[4096]{0} %multiply.1626), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
}

%fused_computation.349 (param_0.585: f32[], param_1.1085: f32[4]) -> f32[] {
  %param_1.1085 = f32[4]{0} parameter(1)
  %constant.20815 = f32[] constant(0)
  %reduce.290 = f32[] reduce(f32[4]{0} %param_1.1085, f32[] %constant.20815), dimensions={0}, to_apply=%primitive_computation_add__1.21382, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %constant.20813 = f32[] constant(0.000244140625)
  %multiply.1629 = f32[] multiply(f32[] %reduce.290, f32[] %constant.20813), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %sqrt.4 = f32[] sqrt(f32[] %multiply.1629), metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %param_0.585 = f32[] parameter(0)
  ROOT %divide.200 = f32[] divide(f32[] %sqrt.4, f32[] %param_0.585), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
}

%fused_computation.350 (param_0.588: f32[4096], param_1.1091: f32[4096], param_2.957: f32[]) -> f32[4096] {
  %param_1.1091 = f32[4096]{0} parameter(1)
  %constant.20817 = f32[] constant(0.0625)
  %broadcast.1895 = f32[4096]{0} broadcast(f32[] %constant.20817), dimensions={}
  %multiply.1631 = f32[4096]{0} multiply(f32[4096]{0} %param_1.1091, f32[4096]{0} %broadcast.1895), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=200}
  %param_0.588 = f32[4096]{0} parameter(0)
  %param_2.957 = f32[] parameter(2)
  %broadcast.1897 = f32[4096]{0} broadcast(f32[] %param_2.957), dimensions={}, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
  %add.4245 = f32[4096]{0} add(f32[4096]{0} %param_0.588, f32[4096]{0} %broadcast.1897), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=145}
  %constant.20816 = f32[] constant(-0.5), metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
  %broadcast.1896 = f32[4096]{0} broadcast(f32[] %constant.20816), dimensions={}, metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
  %power.3 = f32[4096]{0} power(f32[4096]{0} %add.4245, f32[4096]{0} %broadcast.1896), metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=145}
  ROOT %multiply.1630 = f32[4096]{0} multiply(f32[4096]{0} %multiply.1631, f32[4096]{0} %power.3), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=145}
}

%fused_computation.351 (param_0.592: f32[4096], param_1.1097: f32[4096], param_2.966: f32[]) -> f32[4096] {
  %constant.20820 = f32[] constant(1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/metrics.py" source_line=617}
  %param_2.966 = f32[] parameter(2)
  %subtract.561 = f32[] subtract(f32[] %constant.20820, f32[] %param_2.966), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=85}
  %broadcast.1901 = f32[4096]{0} broadcast(f32[] %subtract.561), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
  %param_0.592 = f32[4096]{0} parameter(0)
  %multiply.1634 = f32[4096]{0} multiply(f32[4096]{0} %broadcast.1901, f32[4096]{0} %param_0.592), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=143}
  %subtract.560 = f32[] subtract(f32[] %constant.20820, f32[] %subtract.561), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=124}
  %broadcast.1899 = f32[4096]{0} broadcast(f32[] %subtract.560), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=143}
  %param_1.1097 = f32[4096]{0} parameter(1)
  %constant.20819 = f32[] constant(0.0625)
  %broadcast.1900 = f32[4096]{0} broadcast(f32[] %constant.20819), dimensions={}
  %multiply.1635 = f32[4096]{0} multiply(f32[4096]{0} %param_1.1097, f32[4096]{0} %broadcast.1900), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=200}
  %multiply.1633 = f32[4096]{0} multiply(f32[4096]{0} %multiply.1635, f32[4096]{0} %multiply.1635), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=126}
  %multiply.1632 = f32[4096]{0} multiply(f32[4096]{0} %broadcast.1899, f32[4096]{0} %multiply.1633), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=143}
  ROOT %add.4246 = f32[4096]{0} add(f32[4096]{0} %multiply.1634, f32[4096]{0} %multiply.1632), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=143}
}

%fused_computation.352 (param_0.593: f32[4096]) -> f32[4096] {
  %param_0.593 = f32[4096]{0} parameter(0)
  %constant.20822 = f32[] constant(0.0625)
  %broadcast.1902 = f32[4096]{0} broadcast(f32[] %constant.20822), dimensions={}
  ROOT %multiply.1636 = f32[4096]{0} multiply(f32[4096]{0} %param_0.593, f32[4096]{0} %broadcast.1902), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=200}
}

%fused_computation.353 (param_0.597: f32[4]) -> f32[] {
  %param_0.597 = f32[4]{0} parameter(0)
  %constant.20824 = f32[] constant(0)
  %reduce.291 = f32[] reduce(f32[4]{0} %param_0.597, f32[] %constant.20824), dimensions={0}, to_apply=%primitive_computation_add__1.21356, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %constant.20823 = f32[] constant(0.000244140625)
  %multiply.1637 = f32[] multiply(f32[] %reduce.291, f32[] %constant.20823), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  ROOT %sqrt.5 = f32[] sqrt(f32[] %multiply.1637), metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
}

%fused_computation.355 (param_0.602: f32[], param_1.1112: f32[2,4]) -> f32[] {
  %param_1.1112 = f32[2,4]{1,0} parameter(1)
  %constant.20830 = f32[] constant(0)
  %reduce.292 = f32[] reduce(f32[2,4]{1,0} %param_1.1112, f32[] %constant.20830), dimensions={0,1}, to_apply=%primitive_computation_add__1.21304, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0, 1) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %constant.20829 = f32[] constant(1.1920929e-07)
  %multiply.1644 = f32[] multiply(f32[] %reduce.292, f32[] %constant.20829), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %sqrt.6 = f32[] sqrt(f32[] %multiply.1644), metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %param_0.602 = f32[] parameter(0)
  ROOT %divide.202 = f32[] divide(f32[] %sqrt.6, f32[] %param_0.602), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
}

%fused_computation.357 (param_0.608: f32[4096], param_1.1120: f32[]) -> f32[4096] {
  %param_0.608 = f32[4096]{0} parameter(0)
  %param_1.1120 = f32[] parameter(1)
  %broadcast.1917 = f32[4096]{0} broadcast(f32[] %param_1.1120), dimensions={}, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
  %add.4247 = f32[4096]{0} add(f32[4096]{0} %param_0.608, f32[4096]{0} %broadcast.1917), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
  %constant.20833 = f32[] constant(-0.5), metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
  %broadcast.1915 = f32[4096]{0} broadcast(f32[] %constant.20833), dimensions={}, metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
  ROOT %power.4 = f32[4096]{0} power(f32[4096]{0} %add.4247, f32[4096]{0} %broadcast.1915), metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
}

%fused_computation.358 (param_0.610: f32[4096], param_1.1125: f32[4096], param_2.989: f32[]) -> f32[4096] {
  %constant.20835 = f32[] constant(1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/metrics.py" source_line=617}
  %param_2.989 = f32[] parameter(2)
  %subtract.565 = f32[] subtract(f32[] %constant.20835, f32[] %param_2.989), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=85}
  %broadcast.1919 = f32[4096]{0} broadcast(f32[] %subtract.565), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
  %param_1.1125 = f32[4096]{0} parameter(1)
  %multiply.1650 = f32[4096]{0} multiply(f32[4096]{0} %broadcast.1919, f32[4096]{0} %param_1.1125), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
  %param_0.610 = f32[4096]{0} parameter(0)
  %subtract.564 = f32[] subtract(f32[] %constant.20835, f32[] %subtract.565), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=124}
  %constant.20834 = f32[] constant(0.00048828125)
  %multiply.1651 = f32[] multiply(f32[] %subtract.564, f32[] %constant.20834)
  %broadcast.1918 = f32[4096]{0} broadcast(f32[] %multiply.1651), dimensions={}
  %multiply.1649 = f32[4096]{0} multiply(f32[4096]{0} %param_0.610, f32[4096]{0} %broadcast.1918), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
  ROOT %add.4248 = f32[4096]{0} add(f32[4096]{0} %multiply.1650, f32[4096]{0} %multiply.1649), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
}

%fused_computation.359 (param_0.613: f32[2048], param_1.1130: f32[], param_2.996: f32[]) -> f32[2048] {
  %param_1.1130 = f32[] parameter(1)
  %constant.20836 = f32[] constant(0.00048828125)
  %multiply.1652 = f32[] multiply(f32[] %param_1.1130, f32[] %constant.20836), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=135}
  %broadcast.1920 = f32[2048]{0} broadcast(f32[] %multiply.1652), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  %param_0.613 = f32[2048]{0} parameter(0)
  %param_2.996 = f32[] parameter(2)
  %broadcast.1923 = f32[2048]{0} broadcast(f32[] %param_2.996), dimensions={}, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  %add.4249 = f32[2048]{0} add(f32[2048]{0} %param_0.613, f32[2048]{0} %broadcast.1923), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  %divide.203 = f32[2048]{0} divide(f32[2048]{0} %broadcast.1920, f32[2048]{0} %add.4249), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  %constant.20838 = f32[] constant(0.5), metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  %broadcast.1922 = f32[2048]{0} broadcast(f32[] %constant.20838), dimensions={}, metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  ROOT %power.5 = f32[2048]{0} power(f32[2048]{0} %divide.203, f32[2048]{0} %broadcast.1922), metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
}

%fused_computation.360 (param_0.616: f32[2048,4], param_1.1136: f32[2048], param_2.1003: f32[]) -> f32[2048] {
  %constant.20841 = f32[] constant(1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/metrics.py" source_line=617}
  %param_2.1003 = f32[] parameter(2)
  %subtract.567 = f32[] subtract(f32[] %constant.20841, f32[] %param_2.1003), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=85}
  %broadcast.1926 = f32[2048]{0} broadcast(f32[] %subtract.567), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=131}
  %param_1.1136 = f32[2048]{0} parameter(1)
  %multiply.1654 = f32[2048]{0} multiply(f32[2048]{0} %broadcast.1926, f32[2048]{0} %param_1.1136), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=131}
  %param_0.616 = f32[2048,4]{1,0} parameter(0)
  %constant.20840 = f32[] constant(0)
  %reduce.293 = f32[2048]{0} reduce(f32[2048,4]{1,0} %param_0.616, f32[] %constant.20840), dimensions={1}, to_apply=%primitive_computation_add__1.21246, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(1,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=131}
  %subtract.566 = f32[] subtract(f32[] %constant.20841, f32[] %subtract.567), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=124}
  %constant.20839 = f32[] constant(0.000244140625)
  %multiply.1655 = f32[] multiply(f32[] %subtract.566, f32[] %constant.20839)
  %broadcast.1924 = f32[2048]{0} broadcast(f32[] %multiply.1655), dimensions={}
  %multiply.1653 = f32[2048]{0} multiply(f32[2048]{0} %reduce.293, f32[2048]{0} %broadcast.1924), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=131}
  ROOT %add.4250 = f32[2048]{0} add(f32[2048]{0} %multiply.1654, f32[2048]{0} %multiply.1653), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=131}
}

%fused_computation.362 (param_0.622: f32[2,4]) -> f32[] {
  %param_0.622 = f32[2,4]{1,0} parameter(0)
  %constant.20845 = f32[] constant(0)
  %reduce.294 = f32[] reduce(f32[2,4]{1,0} %param_0.622, f32[] %constant.20845), dimensions={0,1}, to_apply=%primitive_computation_add__1.21230, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0, 1) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %constant.20844 = f32[] constant(1.1920929e-07)
  %multiply.1658 = f32[] multiply(f32[] %reduce.294, f32[] %constant.20844), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  ROOT %sqrt.7 = f32[] sqrt(f32[] %multiply.1658), metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
}

%fused_computation.363 (param_0.624: f32[4096], param_1.1146: f32[], param_2.1009: f32[], param_3.846: f32[], param_4.457: f32[], param_5.414: f32[4096], param_6.365: f32[], param_7.294: f32[], param_8.227: s32[]) -> f32[4096] {
  %constant.20847 = f32[] constant(1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/metrics.py" source_line=617}
  %param_8.227 = s32[] parameter(8)
  %constant.20846 = s32[] constant(1), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=113}
  %compare.2770 = pred[] compare(s32[] %param_8.227, s32[] %constant.20846), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=113}
  %param_6.365 = f32[] parameter(6)
  %param_7.294 = f32[] parameter(7)
  %select.2659 = f32[] select(pred[] %compare.2770, f32[] %param_6.365, f32[] %param_7.294), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/jit(_where)/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=112}
  %subtract.569 = f32[] subtract(f32[] %constant.20847, f32[] %select.2659), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  %broadcast.1932 = f32[4096]{0} broadcast(f32[] %subtract.569), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  %param_5.414 = f32[4096]{0} parameter(5)
  %multiply.1661 = f32[4096]{0} multiply(f32[4096]{0} %broadcast.1932, f32[4096]{0} %param_5.414), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  %param_2.1009 = f32[] parameter(2)
  %param_3.846 = f32[] parameter(3)
  %param_4.457 = f32[] parameter(4)
  %maximum.12 = f32[] maximum(f32[] %param_3.846, f32[] %param_4.457), metadata={op_type="max" op_name="pmap(_multi_device_update_fn)/max" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=122}
  %multiply.1660 = f32[] multiply(f32[] %param_2.1009, f32[] %maximum.12), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=122}
  %broadcast.1930 = f32[4096]{0} broadcast(f32[] %multiply.1660), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=152}
  %param_0.624 = f32[4096]{0} parameter(0)
  %param_1.1146 = f32[] parameter(1)
  %maximum.11 = f32[] maximum(f32[] %constant.20847, f32[] %param_1.1146), metadata={op_type="max" op_name="pmap(_multi_device_update_fn)/max" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %broadcast.1928 = f32[4096]{0} broadcast(f32[] %maximum.11), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=150}
  %divide.204 = f32[4096]{0} divide(f32[4096]{0} %param_0.624, f32[4096]{0} %broadcast.1928), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=150}
  %multiply.1659 = f32[4096]{0} multiply(f32[4096]{0} %broadcast.1930, f32[4096]{0} %divide.204), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=152}
  ROOT %subtract.568 = f32[4096]{0} subtract(f32[4096]{0} %multiply.1661, f32[4096]{0} %multiply.1659), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
}

%fused_computation.364 (param_0.626: f32[], param_1.1151: f32[4]) -> f32[] {
  %param_1.1151 = f32[4]{0} parameter(1)
  %constant.20849 = f32[] constant(0)
  %reduce.295 = f32[] reduce(f32[4]{0} %param_1.1151, f32[] %constant.20849), dimensions={0}, to_apply=%primitive_computation_add__1.21178, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %constant.20848 = f32[] constant(0.000244140625)
  %multiply.1662 = f32[] multiply(f32[] %reduce.295, f32[] %constant.20848), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %sqrt.8 = f32[] sqrt(f32[] %multiply.1662), metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %param_0.626 = f32[] parameter(0)
  ROOT %divide.205 = f32[] divide(f32[] %sqrt.8, f32[] %param_0.626), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
}

%fused_computation.365 (param_0.629: f32[4096], param_1.1157: f32[4096], param_2.1018: f32[]) -> f32[4096] {
  %param_1.1157 = f32[4096]{0} parameter(1)
  %constant.20852 = f32[] constant(0.0625)
  %broadcast.1933 = f32[4096]{0} broadcast(f32[] %constant.20852), dimensions={}
  %multiply.1664 = f32[4096]{0} multiply(f32[4096]{0} %param_1.1157, f32[4096]{0} %broadcast.1933), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=200}
  %param_0.629 = f32[4096]{0} parameter(0)
  %param_2.1018 = f32[] parameter(2)
  %broadcast.1935 = f32[4096]{0} broadcast(f32[] %param_2.1018), dimensions={}, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
  %add.4251 = f32[4096]{0} add(f32[4096]{0} %param_0.629, f32[4096]{0} %broadcast.1935), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=145}
  %constant.20850 = f32[] constant(-0.5), metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
  %broadcast.1934 = f32[4096]{0} broadcast(f32[] %constant.20850), dimensions={}, metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
  %power.6 = f32[4096]{0} power(f32[4096]{0} %add.4251, f32[4096]{0} %broadcast.1934), metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=145}
  ROOT %multiply.1663 = f32[4096]{0} multiply(f32[4096]{0} %multiply.1664, f32[4096]{0} %power.6), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=145}
}

%fused_computation.366 (param_0.633: f32[4096], param_1.1163: f32[4096], param_2.1027: f32[]) -> f32[4096] {
  %constant.20854 = f32[] constant(1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/metrics.py" source_line=617}
  %param_2.1027 = f32[] parameter(2)
  %subtract.571 = f32[] subtract(f32[] %constant.20854, f32[] %param_2.1027), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=85}
  %broadcast.1939 = f32[4096]{0} broadcast(f32[] %subtract.571), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
  %param_0.633 = f32[4096]{0} parameter(0)
  %multiply.1667 = f32[4096]{0} multiply(f32[4096]{0} %broadcast.1939, f32[4096]{0} %param_0.633), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=143}
  %subtract.570 = f32[] subtract(f32[] %constant.20854, f32[] %subtract.571), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=124}
  %broadcast.1937 = f32[4096]{0} broadcast(f32[] %subtract.570), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=143}
  %param_1.1163 = f32[4096]{0} parameter(1)
  %constant.20853 = f32[] constant(0.0625)
  %broadcast.1938 = f32[4096]{0} broadcast(f32[] %constant.20853), dimensions={}
  %multiply.1668 = f32[4096]{0} multiply(f32[4096]{0} %param_1.1163, f32[4096]{0} %broadcast.1938), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=200}
  %multiply.1666 = f32[4096]{0} multiply(f32[4096]{0} %multiply.1668, f32[4096]{0} %multiply.1668), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=126}
  %multiply.1665 = f32[4096]{0} multiply(f32[4096]{0} %broadcast.1937, f32[4096]{0} %multiply.1666), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=143}
  ROOT %add.4252 = f32[4096]{0} add(f32[4096]{0} %multiply.1667, f32[4096]{0} %multiply.1665), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=143}
}

%fused_computation.367 (param_0.634: f32[4096]) -> f32[4096] {
  %param_0.634 = f32[4096]{0} parameter(0)
  %constant.20855 = f32[] constant(0.0625)
  %broadcast.1940 = f32[4096]{0} broadcast(f32[] %constant.20855), dimensions={}
  ROOT %multiply.1669 = f32[4096]{0} multiply(f32[4096]{0} %param_0.634, f32[4096]{0} %broadcast.1940), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=200}
}

%fused_computation.368 (param_0.638: f32[4]) -> f32[] {
  %param_0.638 = f32[4]{0} parameter(0)
  %constant.20858 = f32[] constant(0)
  %reduce.296 = f32[] reduce(f32[4]{0} %param_0.638, f32[] %constant.20858), dimensions={0}, to_apply=%primitive_computation_add__1.21152, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %constant.20856 = f32[] constant(0.000244140625)
  %multiply.1670 = f32[] multiply(f32[] %reduce.296, f32[] %constant.20856), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  ROOT %sqrt.9 = f32[] sqrt(f32[] %multiply.1670), metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
}

%fused_computation.370 (param_0.643: f32[], param_1.1178: f32[2,4]) -> f32[] {
  %param_1.1178 = f32[2,4]{1,0} parameter(1)
  %constant.20864 = f32[] constant(0)
  %reduce.297 = f32[] reduce(f32[2,4]{1,0} %param_1.1178, f32[] %constant.20864), dimensions={0,1}, to_apply=%primitive_computation_add__1.21100, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0, 1) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %constant.20862 = f32[] constant(1.1920929e-07)
  %multiply.1677 = f32[] multiply(f32[] %reduce.297, f32[] %constant.20862), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %sqrt.10 = f32[] sqrt(f32[] %multiply.1677), metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %param_0.643 = f32[] parameter(0)
  ROOT %divide.207 = f32[] divide(f32[] %sqrt.10, f32[] %param_0.643), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
}

%fused_computation.372 (param_0.649: f32[4096], param_1.1186: f32[]) -> f32[4096] {
  %param_0.649 = f32[4096]{0} parameter(0)
  %param_1.1186 = f32[] parameter(1)
  %broadcast.1951 = f32[4096]{0} broadcast(f32[] %param_1.1186), dimensions={}, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
  %add.4253 = f32[4096]{0} add(f32[4096]{0} %param_0.649, f32[4096]{0} %broadcast.1951), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
  %constant.20866 = f32[] constant(-0.5), metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
  %broadcast.1950 = f32[4096]{0} broadcast(f32[] %constant.20866), dimensions={}, metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
  ROOT %power.7 = f32[4096]{0} power(f32[4096]{0} %add.4253, f32[4096]{0} %broadcast.1950), metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
}

%fused_computation.373 (param_0.651: f32[4096], param_1.1191: f32[4096], param_2.1050: f32[]) -> f32[4096] {
  %constant.20868 = f32[] constant(1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/metrics.py" source_line=617}
  %param_2.1050 = f32[] parameter(2)
  %subtract.575 = f32[] subtract(f32[] %constant.20868, f32[] %param_2.1050), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=85}
  %broadcast.1953 = f32[4096]{0} broadcast(f32[] %subtract.575), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
  %param_1.1191 = f32[4096]{0} parameter(1)
  %multiply.1683 = f32[4096]{0} multiply(f32[4096]{0} %broadcast.1953, f32[4096]{0} %param_1.1191), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
  %param_0.651 = f32[4096]{0} parameter(0)
  %subtract.574 = f32[] subtract(f32[] %constant.20868, f32[] %subtract.575), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=124}
  %constant.20867 = f32[] constant(0.00048828125)
  %multiply.1684 = f32[] multiply(f32[] %subtract.574, f32[] %constant.20867)
  %broadcast.1952 = f32[4096]{0} broadcast(f32[] %multiply.1684), dimensions={}
  %multiply.1682 = f32[4096]{0} multiply(f32[4096]{0} %param_0.651, f32[4096]{0} %broadcast.1952), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
  ROOT %add.4254 = f32[4096]{0} add(f32[4096]{0} %multiply.1683, f32[4096]{0} %multiply.1682), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
}

%fused_computation.374 (param_0.654: f32[2048], param_1.1196: f32[], param_2.1057: f32[]) -> f32[2048] {
  %param_1.1196 = f32[] parameter(1)
  %constant.20869 = f32[] constant(0.00048828125)
  %multiply.1685 = f32[] multiply(f32[] %param_1.1196, f32[] %constant.20869), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=135}
  %broadcast.1954 = f32[2048]{0} broadcast(f32[] %multiply.1685), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  %param_0.654 = f32[2048]{0} parameter(0)
  %param_2.1057 = f32[] parameter(2)
  %broadcast.1956 = f32[2048]{0} broadcast(f32[] %param_2.1057), dimensions={}, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  %add.4255 = f32[2048]{0} add(f32[2048]{0} %param_0.654, f32[2048]{0} %broadcast.1956), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  %divide.208 = f32[2048]{0} divide(f32[2048]{0} %broadcast.1954, f32[2048]{0} %add.4255), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  %constant.20871 = f32[] constant(0.5), metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  %broadcast.1955 = f32[2048]{0} broadcast(f32[] %constant.20871), dimensions={}, metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  ROOT %power.8 = f32[2048]{0} power(f32[2048]{0} %divide.208, f32[2048]{0} %broadcast.1955), metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
}

%fused_computation.375 (param_0.657: f32[2048,4], param_1.1202: f32[2048], param_2.1064: f32[]) -> f32[2048] {
  %constant.20874 = f32[] constant(1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/metrics.py" source_line=617}
  %param_2.1064 = f32[] parameter(2)
  %subtract.577 = f32[] subtract(f32[] %constant.20874, f32[] %param_2.1064), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=85}
  %broadcast.1958 = f32[2048]{0} broadcast(f32[] %subtract.577), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=131}
  %param_1.1202 = f32[2048]{0} parameter(1)
  %multiply.1687 = f32[2048]{0} multiply(f32[2048]{0} %broadcast.1958, f32[2048]{0} %param_1.1202), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=131}
  %param_0.657 = f32[2048,4]{1,0} parameter(0)
  %constant.20873 = f32[] constant(0)
  %reduce.298 = f32[2048]{0} reduce(f32[2048,4]{1,0} %param_0.657, f32[] %constant.20873), dimensions={1}, to_apply=%primitive_computation_add__1.21042, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(1,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=131}
  %subtract.576 = f32[] subtract(f32[] %constant.20874, f32[] %subtract.577), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=124}
  %constant.20872 = f32[] constant(0.000244140625)
  %multiply.1688 = f32[] multiply(f32[] %subtract.576, f32[] %constant.20872)
  %broadcast.1957 = f32[2048]{0} broadcast(f32[] %multiply.1688), dimensions={}
  %multiply.1686 = f32[2048]{0} multiply(f32[2048]{0} %reduce.298, f32[2048]{0} %broadcast.1957), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=131}
  ROOT %add.4256 = f32[2048]{0} add(f32[2048]{0} %multiply.1687, f32[2048]{0} %multiply.1686), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=131}
}

%fused_computation.377 (param_0.663: f32[2,4]) -> f32[] {
  %param_0.663 = f32[2,4]{1,0} parameter(0)
  %constant.20877 = f32[] constant(0)
  %reduce.299 = f32[] reduce(f32[2,4]{1,0} %param_0.663, f32[] %constant.20877), dimensions={0,1}, to_apply=%primitive_computation_add__1.21026, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0, 1) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %constant.20876 = f32[] constant(1.1920929e-07)
  %multiply.1691 = f32[] multiply(f32[] %reduce.299, f32[] %constant.20876), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  ROOT %sqrt.11 = f32[] sqrt(f32[] %multiply.1691), metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
}

%fused_computation.378 (param_0.665: f32[4096], param_1.1212: f32[], param_2.1070: f32[], param_3.896: f32[], param_4.489: f32[], param_5.426: f32[4096], param_6.376: f32[], param_7.306: f32[], param_8.236: s32[]) -> f32[4096] {
  %constant.20880 = f32[] constant(1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/metrics.py" source_line=617}
  %param_8.236 = s32[] parameter(8)
  %constant.20879 = s32[] constant(1), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=113}
  %compare.2773 = pred[] compare(s32[] %param_8.236, s32[] %constant.20879), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=113}
  %param_6.376 = f32[] parameter(6)
  %param_7.306 = f32[] parameter(7)
  %select.2662 = f32[] select(pred[] %compare.2773, f32[] %param_6.376, f32[] %param_7.306), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/jit(_where)/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=112}
  %subtract.579 = f32[] subtract(f32[] %constant.20880, f32[] %select.2662), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  %broadcast.1962 = f32[4096]{0} broadcast(f32[] %subtract.579), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  %param_5.426 = f32[4096]{0} parameter(5)
  %multiply.1694 = f32[4096]{0} multiply(f32[4096]{0} %broadcast.1962, f32[4096]{0} %param_5.426), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  %param_2.1070 = f32[] parameter(2)
  %param_3.896 = f32[] parameter(3)
  %param_4.489 = f32[] parameter(4)
  %maximum.16 = f32[] maximum(f32[] %param_3.896, f32[] %param_4.489), metadata={op_type="max" op_name="pmap(_multi_device_update_fn)/max" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=122}
  %multiply.1693 = f32[] multiply(f32[] %param_2.1070, f32[] %maximum.16), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=122}
  %broadcast.1961 = f32[4096]{0} broadcast(f32[] %multiply.1693), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=152}
  %param_0.665 = f32[4096]{0} parameter(0)
  %param_1.1212 = f32[] parameter(1)
  %maximum.15 = f32[] maximum(f32[] %constant.20880, f32[] %param_1.1212), metadata={op_type="max" op_name="pmap(_multi_device_update_fn)/max" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %broadcast.1960 = f32[4096]{0} broadcast(f32[] %maximum.15), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=150}
  %divide.209 = f32[4096]{0} divide(f32[4096]{0} %param_0.665, f32[4096]{0} %broadcast.1960), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=150}
  %multiply.1692 = f32[4096]{0} multiply(f32[4096]{0} %broadcast.1961, f32[4096]{0} %divide.209), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=152}
  ROOT %subtract.578 = f32[4096]{0} subtract(f32[4096]{0} %multiply.1694, f32[4096]{0} %multiply.1692), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
}

%fused_computation.379 (param_0.667: f32[], param_1.1217: f32[4]) -> f32[] {
  %param_1.1217 = f32[4]{0} parameter(1)
  %constant.20882 = f32[] constant(0)
  %reduce.300 = f32[] reduce(f32[4]{0} %param_1.1217, f32[] %constant.20882), dimensions={0}, to_apply=%primitive_computation_add__1.20974, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %constant.20881 = f32[] constant(0.000244140625)
  %multiply.1695 = f32[] multiply(f32[] %reduce.300, f32[] %constant.20881), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %sqrt.12 = f32[] sqrt(f32[] %multiply.1695), metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %param_0.667 = f32[] parameter(0)
  ROOT %divide.210 = f32[] divide(f32[] %sqrt.12, f32[] %param_0.667), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
}

%fused_computation.380 (param_0.670: f32[4096], param_1.1223: f32[4096], param_2.1079: f32[]) -> f32[4096] {
  %param_1.1223 = f32[4096]{0} parameter(1)
  %constant.20885 = f32[] constant(0.0625)
  %broadcast.1963 = f32[4096]{0} broadcast(f32[] %constant.20885), dimensions={}
  %multiply.1697 = f32[4096]{0} multiply(f32[4096]{0} %param_1.1223, f32[4096]{0} %broadcast.1963), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=200}
  %param_0.670 = f32[4096]{0} parameter(0)
  %param_2.1079 = f32[] parameter(2)
  %broadcast.1965 = f32[4096]{0} broadcast(f32[] %param_2.1079), dimensions={}, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
  %add.4257 = f32[4096]{0} add(f32[4096]{0} %param_0.670, f32[4096]{0} %broadcast.1965), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=145}
  %constant.20884 = f32[] constant(-0.5), metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
  %broadcast.1964 = f32[4096]{0} broadcast(f32[] %constant.20884), dimensions={}, metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
  %power.9 = f32[4096]{0} power(f32[4096]{0} %add.4257, f32[4096]{0} %broadcast.1964), metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=145}
  ROOT %multiply.1696 = f32[4096]{0} multiply(f32[4096]{0} %multiply.1697, f32[4096]{0} %power.9), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=145}
}

%fused_computation.381 (param_0.674: f32[4096], param_1.1229: f32[4096], param_2.1088: f32[]) -> f32[4096] {
  %constant.20887 = f32[] constant(1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/metrics.py" source_line=617}
  %param_2.1088 = f32[] parameter(2)
  %subtract.581 = f32[] subtract(f32[] %constant.20887, f32[] %param_2.1088), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=85}
  %broadcast.1968 = f32[4096]{0} broadcast(f32[] %subtract.581), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
  %param_0.674 = f32[4096]{0} parameter(0)
  %multiply.1700 = f32[4096]{0} multiply(f32[4096]{0} %broadcast.1968, f32[4096]{0} %param_0.674), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=143}
  %subtract.580 = f32[] subtract(f32[] %constant.20887, f32[] %subtract.581), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=124}
  %broadcast.1966 = f32[4096]{0} broadcast(f32[] %subtract.580), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=143}
  %param_1.1229 = f32[4096]{0} parameter(1)
  %constant.20886 = f32[] constant(0.0625)
  %broadcast.1967 = f32[4096]{0} broadcast(f32[] %constant.20886), dimensions={}
  %multiply.1701 = f32[4096]{0} multiply(f32[4096]{0} %param_1.1229, f32[4096]{0} %broadcast.1967), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=200}
  %multiply.1699 = f32[4096]{0} multiply(f32[4096]{0} %multiply.1701, f32[4096]{0} %multiply.1701), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=126}
  %multiply.1698 = f32[4096]{0} multiply(f32[4096]{0} %broadcast.1966, f32[4096]{0} %multiply.1699), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=143}
  ROOT %add.4258 = f32[4096]{0} add(f32[4096]{0} %multiply.1700, f32[4096]{0} %multiply.1698), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=143}
}

%fused_computation.382 (param_0.675: f32[4096]) -> f32[4096] {
  %param_0.675 = f32[4096]{0} parameter(0)
  %constant.20888 = f32[] constant(0.0625)
  %broadcast.1969 = f32[4096]{0} broadcast(f32[] %constant.20888), dimensions={}
  ROOT %multiply.1702 = f32[4096]{0} multiply(f32[4096]{0} %param_0.675, f32[4096]{0} %broadcast.1969), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=200}
}

%fused_computation.383 (param_0.679: f32[4]) -> f32[] {
  %param_0.679 = f32[4]{0} parameter(0)
  %constant.20890 = f32[] constant(0)
  %reduce.301 = f32[] reduce(f32[4]{0} %param_0.679, f32[] %constant.20890), dimensions={0}, to_apply=%primitive_computation_add__1.20948, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %constant.20889 = f32[] constant(0.000244140625)
  %multiply.1703 = f32[] multiply(f32[] %reduce.301, f32[] %constant.20889), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  ROOT %sqrt.13 = f32[] sqrt(f32[] %multiply.1703), metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
}

%fused_computation.385 (param_0.684: f32[], param_1.1244: f32[2,4]) -> f32[] {
  %param_1.1244 = f32[2,4]{1,0} parameter(1)
  %constant.20896 = f32[] constant(0)
  %reduce.302 = f32[] reduce(f32[2,4]{1,0} %param_1.1244, f32[] %constant.20896), dimensions={0,1}, to_apply=%primitive_computation_add__1.20896, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0, 1) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %constant.20894 = f32[] constant(1.1920929e-07)
  %multiply.1710 = f32[] multiply(f32[] %reduce.302, f32[] %constant.20894), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %sqrt.14 = f32[] sqrt(f32[] %multiply.1710), metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %param_0.684 = f32[] parameter(0)
  ROOT %divide.212 = f32[] divide(f32[] %sqrt.14, f32[] %param_0.684), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
}

%fused_computation.387 (param_0.690: f32[4096], param_1.1252: f32[]) -> f32[4096] {
  %param_0.690 = f32[4096]{0} parameter(0)
  %param_1.1252 = f32[] parameter(1)
  %broadcast.1982 = f32[4096]{0} broadcast(f32[] %param_1.1252), dimensions={}, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
  %add.4259 = f32[4096]{0} add(f32[4096]{0} %param_0.690, f32[4096]{0} %broadcast.1982), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
  %constant.20898 = f32[] constant(-0.5), metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
  %broadcast.1981 = f32[4096]{0} broadcast(f32[] %constant.20898), dimensions={}, metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
  ROOT %power.10 = f32[4096]{0} power(f32[4096]{0} %add.4259, f32[4096]{0} %broadcast.1981), metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
}

%fused_computation.388 (param_0.692: f32[4096], param_1.1257: f32[4096], param_2.1111: f32[]) -> f32[4096] {
  %constant.20900 = f32[] constant(1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/metrics.py" source_line=617}
  %param_2.1111 = f32[] parameter(2)
  %subtract.585 = f32[] subtract(f32[] %constant.20900, f32[] %param_2.1111), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=85}
  %broadcast.1984 = f32[4096]{0} broadcast(f32[] %subtract.585), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
  %param_1.1257 = f32[4096]{0} parameter(1)
  %multiply.1716 = f32[4096]{0} multiply(f32[4096]{0} %broadcast.1984, f32[4096]{0} %param_1.1257), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
  %param_0.692 = f32[4096]{0} parameter(0)
  %subtract.584 = f32[] subtract(f32[] %constant.20900, f32[] %subtract.585), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=124}
  %constant.20899 = f32[] constant(0.00048828125)
  %multiply.1717 = f32[] multiply(f32[] %subtract.584, f32[] %constant.20899)
  %broadcast.1983 = f32[4096]{0} broadcast(f32[] %multiply.1717), dimensions={}
  %multiply.1715 = f32[4096]{0} multiply(f32[4096]{0} %param_0.692, f32[4096]{0} %broadcast.1983), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
  ROOT %add.4260 = f32[4096]{0} add(f32[4096]{0} %multiply.1716, f32[4096]{0} %multiply.1715), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
}

%fused_computation.389 (param_0.695: f32[2048], param_1.1262: f32[], param_2.1118: f32[]) -> f32[2048] {
  %param_1.1262 = f32[] parameter(1)
  %constant.20902 = f32[] constant(0.00048828125)
  %multiply.1718 = f32[] multiply(f32[] %param_1.1262, f32[] %constant.20902), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=135}
  %broadcast.1985 = f32[2048]{0} broadcast(f32[] %multiply.1718), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  %param_0.695 = f32[2048]{0} parameter(0)
  %param_2.1118 = f32[] parameter(2)
  %broadcast.1987 = f32[2048]{0} broadcast(f32[] %param_2.1118), dimensions={}, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  %add.4261 = f32[2048]{0} add(f32[2048]{0} %param_0.695, f32[2048]{0} %broadcast.1987), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  %divide.213 = f32[2048]{0} divide(f32[2048]{0} %broadcast.1985, f32[2048]{0} %add.4261), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  %constant.20903 = f32[] constant(0.5), metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  %broadcast.1986 = f32[2048]{0} broadcast(f32[] %constant.20903), dimensions={}, metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  ROOT %power.11 = f32[2048]{0} power(f32[2048]{0} %divide.213, f32[2048]{0} %broadcast.1986), metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
}

%fused_computation.390 (param_0.698: f32[2048,4], param_1.1268: f32[2048], param_2.1125: f32[]) -> f32[2048] {
  %constant.20907 = f32[] constant(1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/metrics.py" source_line=617}
  %param_2.1125 = f32[] parameter(2)
  %subtract.587 = f32[] subtract(f32[] %constant.20907, f32[] %param_2.1125), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=85}
  %broadcast.1989 = f32[2048]{0} broadcast(f32[] %subtract.587), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=131}
  %param_1.1268 = f32[2048]{0} parameter(1)
  %multiply.1720 = f32[2048]{0} multiply(f32[2048]{0} %broadcast.1989, f32[2048]{0} %param_1.1268), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=131}
  %param_0.698 = f32[2048,4]{1,0} parameter(0)
  %constant.20906 = f32[] constant(0)
  %reduce.303 = f32[2048]{0} reduce(f32[2048,4]{1,0} %param_0.698, f32[] %constant.20906), dimensions={1}, to_apply=%primitive_computation_add__1.20838, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(1,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=131}
  %subtract.586 = f32[] subtract(f32[] %constant.20907, f32[] %subtract.587), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=124}
  %constant.20904 = f32[] constant(0.000244140625)
  %multiply.1721 = f32[] multiply(f32[] %subtract.586, f32[] %constant.20904)
  %broadcast.1988 = f32[2048]{0} broadcast(f32[] %multiply.1721), dimensions={}
  %multiply.1719 = f32[2048]{0} multiply(f32[2048]{0} %reduce.303, f32[2048]{0} %broadcast.1988), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=131}
  ROOT %add.4262 = f32[2048]{0} add(f32[2048]{0} %multiply.1720, f32[2048]{0} %multiply.1719), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=131}
}

%fused_computation.392 (param_0.704: f32[2,4]) -> f32[] {
  %param_0.704 = f32[2,4]{1,0} parameter(0)
  %constant.20910 = f32[] constant(0)
  %reduce.304 = f32[] reduce(f32[2,4]{1,0} %param_0.704, f32[] %constant.20910), dimensions={0,1}, to_apply=%primitive_computation_add__1.20822, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0, 1) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %constant.20909 = f32[] constant(1.1920929e-07)
  %multiply.1724 = f32[] multiply(f32[] %reduce.304, f32[] %constant.20909), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  ROOT %sqrt.15 = f32[] sqrt(f32[] %multiply.1724), metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
}

%fused_computation.393 (param_0.706: f32[4096], param_1.1278: f32[], param_2.1131: f32[], param_3.946: f32[], param_4.521: f32[], param_5.438: f32[4096], param_6.387: f32[], param_7.318: f32[], param_8.245: s32[]) -> f32[4096] {
  %constant.20913 = f32[] constant(1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/metrics.py" source_line=617}
  %param_8.245 = s32[] parameter(8)
  %constant.20912 = s32[] constant(1), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=113}
  %compare.2775 = pred[] compare(s32[] %param_8.245, s32[] %constant.20912), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=113}
  %param_6.387 = f32[] parameter(6)
  %param_7.318 = f32[] parameter(7)
  %select.2664 = f32[] select(pred[] %compare.2775, f32[] %param_6.387, f32[] %param_7.318), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/jit(_where)/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=112}
  %subtract.589 = f32[] subtract(f32[] %constant.20913, f32[] %select.2664), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  %broadcast.1993 = f32[4096]{0} broadcast(f32[] %subtract.589), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  %param_5.438 = f32[4096]{0} parameter(5)
  %multiply.1727 = f32[4096]{0} multiply(f32[4096]{0} %broadcast.1993, f32[4096]{0} %param_5.438), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  %param_2.1131 = f32[] parameter(2)
  %param_3.946 = f32[] parameter(3)
  %param_4.521 = f32[] parameter(4)
  %maximum.20 = f32[] maximum(f32[] %param_3.946, f32[] %param_4.521), metadata={op_type="max" op_name="pmap(_multi_device_update_fn)/max" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=122}
  %multiply.1726 = f32[] multiply(f32[] %param_2.1131, f32[] %maximum.20), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=122}
  %broadcast.1992 = f32[4096]{0} broadcast(f32[] %multiply.1726), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=152}
  %param_0.706 = f32[4096]{0} parameter(0)
  %param_1.1278 = f32[] parameter(1)
  %maximum.19 = f32[] maximum(f32[] %constant.20913, f32[] %param_1.1278), metadata={op_type="max" op_name="pmap(_multi_device_update_fn)/max" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %broadcast.1991 = f32[4096]{0} broadcast(f32[] %maximum.19), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=150}
  %divide.214 = f32[4096]{0} divide(f32[4096]{0} %param_0.706, f32[4096]{0} %broadcast.1991), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=150}
  %multiply.1725 = f32[4096]{0} multiply(f32[4096]{0} %broadcast.1992, f32[4096]{0} %divide.214), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=152}
  ROOT %subtract.588 = f32[4096]{0} subtract(f32[4096]{0} %multiply.1727, f32[4096]{0} %multiply.1725), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
}

%fused_computation.394 (param_0.708: f32[], param_1.1283: f32[4]) -> f32[] {
  %param_1.1283 = f32[4]{0} parameter(1)
  %constant.20915 = f32[] constant(0)
  %reduce.305 = f32[] reduce(f32[4]{0} %param_1.1283, f32[] %constant.20915), dimensions={0}, to_apply=%primitive_computation_add__1.20770, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %constant.20914 = f32[] constant(0.000244140625)
  %multiply.1728 = f32[] multiply(f32[] %reduce.305, f32[] %constant.20914), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %sqrt.16 = f32[] sqrt(f32[] %multiply.1728), metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %param_0.708 = f32[] parameter(0)
  ROOT %divide.215 = f32[] divide(f32[] %sqrt.16, f32[] %param_0.708), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
}

%fused_computation.395 (param_0.711: f32[4096], param_1.1289: f32[4096], param_2.1140: f32[]) -> f32[4096] {
  %param_1.1289 = f32[4096]{0} parameter(1)
  %constant.20918 = f32[] constant(0.0625)
  %broadcast.1994 = f32[4096]{0} broadcast(f32[] %constant.20918), dimensions={}
  %multiply.1730 = f32[4096]{0} multiply(f32[4096]{0} %param_1.1289, f32[4096]{0} %broadcast.1994), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=200}
  %param_0.711 = f32[4096]{0} parameter(0)
  %param_2.1140 = f32[] parameter(2)
  %broadcast.1996 = f32[4096]{0} broadcast(f32[] %param_2.1140), dimensions={}, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
  %add.4263 = f32[4096]{0} add(f32[4096]{0} %param_0.711, f32[4096]{0} %broadcast.1996), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=145}
  %constant.20917 = f32[] constant(-0.5), metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
  %broadcast.1995 = f32[4096]{0} broadcast(f32[] %constant.20917), dimensions={}, metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
  %power.12 = f32[4096]{0} power(f32[4096]{0} %add.4263, f32[4096]{0} %broadcast.1995), metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=145}
  ROOT %multiply.1729 = f32[4096]{0} multiply(f32[4096]{0} %multiply.1730, f32[4096]{0} %power.12), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=145}
}

%fused_computation.396 (param_0.715: f32[4096], param_1.1295: f32[4096], param_2.1149: f32[]) -> f32[4096] {
  %constant.20920 = f32[] constant(1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/metrics.py" source_line=617}
  %param_2.1149 = f32[] parameter(2)
  %subtract.591 = f32[] subtract(f32[] %constant.20920, f32[] %param_2.1149), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=85}
  %broadcast.1999 = f32[4096]{0} broadcast(f32[] %subtract.591), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
  %param_0.715 = f32[4096]{0} parameter(0)
  %multiply.1733 = f32[4096]{0} multiply(f32[4096]{0} %broadcast.1999, f32[4096]{0} %param_0.715), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=143}
  %subtract.590 = f32[] subtract(f32[] %constant.20920, f32[] %subtract.591), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=124}
  %broadcast.1997 = f32[4096]{0} broadcast(f32[] %subtract.590), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=143}
  %param_1.1295 = f32[4096]{0} parameter(1)
  %constant.20919 = f32[] constant(0.0625)
  %broadcast.1998 = f32[4096]{0} broadcast(f32[] %constant.20919), dimensions={}
  %multiply.1734 = f32[4096]{0} multiply(f32[4096]{0} %param_1.1295, f32[4096]{0} %broadcast.1998), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=200}
  %multiply.1732 = f32[4096]{0} multiply(f32[4096]{0} %multiply.1734, f32[4096]{0} %multiply.1734), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=126}
  %multiply.1731 = f32[4096]{0} multiply(f32[4096]{0} %broadcast.1997, f32[4096]{0} %multiply.1732), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=143}
  ROOT %add.4264 = f32[4096]{0} add(f32[4096]{0} %multiply.1733, f32[4096]{0} %multiply.1731), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=143}
}

%fused_computation.397 (param_0.716: f32[4096]) -> f32[4096] {
  %param_0.716 = f32[4096]{0} parameter(0)
  %constant.20922 = f32[] constant(0.0625)
  %broadcast.2000 = f32[4096]{0} broadcast(f32[] %constant.20922), dimensions={}
  ROOT %multiply.1735 = f32[4096]{0} multiply(f32[4096]{0} %param_0.716, f32[4096]{0} %broadcast.2000), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=200}
}

%fused_computation.398 (param_0.720: f32[4]) -> f32[] {
  %param_0.720 = f32[4]{0} parameter(0)
  %constant.20924 = f32[] constant(0)
  %reduce.306 = f32[] reduce(f32[4]{0} %param_0.720, f32[] %constant.20924), dimensions={0}, to_apply=%primitive_computation_add__1.20744, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %constant.20923 = f32[] constant(0.000244140625)
  %multiply.1736 = f32[] multiply(f32[] %reduce.306, f32[] %constant.20923), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  ROOT %sqrt.17 = f32[] sqrt(f32[] %multiply.1736), metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
}

%fused_computation.400 (param_0.725: f32[], param_1.1310: f32[2,4]) -> f32[] {
  %param_1.1310 = f32[2,4]{1,0} parameter(1)
  %constant.20930 = f32[] constant(0)
  %reduce.307 = f32[] reduce(f32[2,4]{1,0} %param_1.1310, f32[] %constant.20930), dimensions={0,1}, to_apply=%primitive_computation_add__1.20692, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0, 1) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %constant.20929 = f32[] constant(1.1920929e-07)
  %multiply.1743 = f32[] multiply(f32[] %reduce.307, f32[] %constant.20929), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %sqrt.18 = f32[] sqrt(f32[] %multiply.1743), metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %param_0.725 = f32[] parameter(0)
  ROOT %divide.217 = f32[] divide(f32[] %sqrt.18, f32[] %param_0.725), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
}

%fused_computation.402 (param_0.731: f32[4096], param_1.1318: f32[]) -> f32[4096] {
  %param_0.731 = f32[4096]{0} parameter(0)
  %param_1.1318 = f32[] parameter(1)
  %broadcast.2011 = f32[4096]{0} broadcast(f32[] %param_1.1318), dimensions={}, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
  %add.4265 = f32[4096]{0} add(f32[4096]{0} %param_0.731, f32[4096]{0} %broadcast.2011), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
  %constant.20932 = f32[] constant(-0.5), metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
  %broadcast.2010 = f32[4096]{0} broadcast(f32[] %constant.20932), dimensions={}, metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
  ROOT %power.13 = f32[4096]{0} power(f32[4096]{0} %add.4265, f32[4096]{0} %broadcast.2010), metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
}

%fused_computation.403 (param_0.733: f32[4096], param_1.1323: f32[4096], param_2.1172: f32[]) -> f32[4096] {
  %constant.20935 = f32[] constant(1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/metrics.py" source_line=617}
  %param_2.1172 = f32[] parameter(2)
  %subtract.595 = f32[] subtract(f32[] %constant.20935, f32[] %param_2.1172), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=85}
  %broadcast.2013 = f32[4096]{0} broadcast(f32[] %subtract.595), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
  %param_1.1323 = f32[4096]{0} parameter(1)
  %multiply.1749 = f32[4096]{0} multiply(f32[4096]{0} %broadcast.2013, f32[4096]{0} %param_1.1323), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
  %param_0.733 = f32[4096]{0} parameter(0)
  %subtract.594 = f32[] subtract(f32[] %constant.20935, f32[] %subtract.595), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=124}
  %constant.20933 = f32[] constant(0.00048828125)
  %multiply.1750 = f32[] multiply(f32[] %subtract.594, f32[] %constant.20933)
  %broadcast.2012 = f32[4096]{0} broadcast(f32[] %multiply.1750), dimensions={}
  %multiply.1748 = f32[4096]{0} multiply(f32[4096]{0} %param_0.733, f32[4096]{0} %broadcast.2012), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
  ROOT %add.4266 = f32[4096]{0} add(f32[4096]{0} %multiply.1749, f32[4096]{0} %multiply.1748), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
}

%fused_computation.404 (param_0.736: f32[2048], param_1.1328: f32[], param_2.1179: f32[]) -> f32[2048] {
  %param_1.1328 = f32[] parameter(1)
  %constant.20936 = f32[] constant(0.00048828125)
  %multiply.1751 = f32[] multiply(f32[] %param_1.1328, f32[] %constant.20936), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=135}
  %broadcast.2014 = f32[2048]{0} broadcast(f32[] %multiply.1751), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  %param_0.736 = f32[2048]{0} parameter(0)
  %param_2.1179 = f32[] parameter(2)
  %broadcast.2016 = f32[2048]{0} broadcast(f32[] %param_2.1179), dimensions={}, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  %add.4267 = f32[2048]{0} add(f32[2048]{0} %param_0.736, f32[2048]{0} %broadcast.2016), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  %divide.218 = f32[2048]{0} divide(f32[2048]{0} %broadcast.2014, f32[2048]{0} %add.4267), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  %constant.20937 = f32[] constant(0.5), metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  %broadcast.2015 = f32[2048]{0} broadcast(f32[] %constant.20937), dimensions={}, metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  ROOT %power.14 = f32[2048]{0} power(f32[2048]{0} %divide.218, f32[2048]{0} %broadcast.2015), metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
}

%fused_computation.405 (param_0.739: f32[2048,4], param_1.1334: f32[2048], param_2.1186: f32[]) -> f32[2048] {
  %constant.20941 = f32[] constant(1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/metrics.py" source_line=617}
  %param_2.1186 = f32[] parameter(2)
  %subtract.597 = f32[] subtract(f32[] %constant.20941, f32[] %param_2.1186), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=85}
  %broadcast.2018 = f32[2048]{0} broadcast(f32[] %subtract.597), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=131}
  %param_1.1334 = f32[2048]{0} parameter(1)
  %multiply.1753 = f32[2048]{0} multiply(f32[2048]{0} %broadcast.2018, f32[2048]{0} %param_1.1334), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=131}
  %param_0.739 = f32[2048,4]{1,0} parameter(0)
  %constant.20939 = f32[] constant(0)
  %reduce.308 = f32[2048]{0} reduce(f32[2048,4]{1,0} %param_0.739, f32[] %constant.20939), dimensions={1}, to_apply=%primitive_computation_add__1.20634, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(1,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=131}
  %subtract.596 = f32[] subtract(f32[] %constant.20941, f32[] %subtract.597), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=124}
  %constant.20938 = f32[] constant(0.000244140625)
  %multiply.1754 = f32[] multiply(f32[] %subtract.596, f32[] %constant.20938)
  %broadcast.2017 = f32[2048]{0} broadcast(f32[] %multiply.1754), dimensions={}
  %multiply.1752 = f32[2048]{0} multiply(f32[2048]{0} %reduce.308, f32[2048]{0} %broadcast.2017), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=131}
  ROOT %add.4268 = f32[2048]{0} add(f32[2048]{0} %multiply.1753, f32[2048]{0} %multiply.1752), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=131}
}

%fused_computation.407 (param_0.745: f32[2,4]) -> f32[] {
  %param_0.745 = f32[2,4]{1,0} parameter(0)
  %constant.20945 = f32[] constant(0)
  %reduce.309 = f32[] reduce(f32[2,4]{1,0} %param_0.745, f32[] %constant.20945), dimensions={0,1}, to_apply=%primitive_computation_add__1.20618, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0, 1) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %constant.20943 = f32[] constant(1.1920929e-07)
  %multiply.1757 = f32[] multiply(f32[] %reduce.309, f32[] %constant.20943), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  ROOT %sqrt.19 = f32[] sqrt(f32[] %multiply.1757), metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
}

%fused_computation.408 (param_0.747: f32[1024], param_1.1344: f32[], param_2.1192: f32[], param_3.996: f32[], param_4.553: f32[], param_5.450: f32[1024], param_6.398: f32[], param_7.330: f32[], param_8.254: s32[]) -> f32[1024] {
  %constant.20948 = f32[] constant(1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/metrics.py" source_line=617}
  %param_8.254 = s32[] parameter(8)
  %constant.20946 = s32[] constant(1), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=113}
  %compare.2777 = pred[] compare(s32[] %param_8.254, s32[] %constant.20946), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=113}
  %param_6.398 = f32[] parameter(6)
  %param_7.330 = f32[] parameter(7)
  %select.2666 = f32[] select(pred[] %compare.2777, f32[] %param_6.398, f32[] %param_7.330), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/jit(_where)/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=112}
  %subtract.599 = f32[] subtract(f32[] %constant.20948, f32[] %select.2666), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  %broadcast.2022 = f32[1024]{0} broadcast(f32[] %subtract.599), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  %param_5.450 = f32[1024]{0} parameter(5)
  %multiply.1760 = f32[1024]{0} multiply(f32[1024]{0} %broadcast.2022, f32[1024]{0} %param_5.450), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  %param_2.1192 = f32[] parameter(2)
  %param_3.996 = f32[] parameter(3)
  %param_4.553 = f32[] parameter(4)
  %maximum.24 = f32[] maximum(f32[] %param_3.996, f32[] %param_4.553), metadata={op_type="max" op_name="pmap(_multi_device_update_fn)/max" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=122}
  %multiply.1759 = f32[] multiply(f32[] %param_2.1192, f32[] %maximum.24), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=122}
  %broadcast.2021 = f32[1024]{0} broadcast(f32[] %multiply.1759), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=152}
  %param_0.747 = f32[1024]{0} parameter(0)
  %param_1.1344 = f32[] parameter(1)
  %maximum.23 = f32[] maximum(f32[] %constant.20948, f32[] %param_1.1344), metadata={op_type="max" op_name="pmap(_multi_device_update_fn)/max" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %broadcast.2020 = f32[1024]{0} broadcast(f32[] %maximum.23), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=150}
  %divide.219 = f32[1024]{0} divide(f32[1024]{0} %param_0.747, f32[1024]{0} %broadcast.2020), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=150}
  %multiply.1758 = f32[1024]{0} multiply(f32[1024]{0} %broadcast.2021, f32[1024]{0} %divide.219), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=152}
  ROOT %subtract.598 = f32[1024]{0} subtract(f32[1024]{0} %multiply.1760, f32[1024]{0} %multiply.1758), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
}

%fused_computation.409 (param_0.749: f32[], param_1.1349: f32[1]) -> f32[] {
  %param_1.1349 = f32[1]{0} parameter(1)
  %reshape.3230 = f32[] reshape(f32[1]{0} %param_1.1349), metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %constant.20949 = f32[] constant(0.0009765625)
  %multiply.1761 = f32[] multiply(f32[] %reshape.3230, f32[] %constant.20949), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %sqrt.20 = f32[] sqrt(f32[] %multiply.1761), metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %param_0.749 = f32[] parameter(0)
  ROOT %divide.220 = f32[] divide(f32[] %sqrt.20, f32[] %param_0.749), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
}

%fused_computation.410 (param_0.752: f32[1024], param_1.1355: f32[1024], param_2.1200: f32[]) -> f32[1024] {
  %param_1.1355 = f32[1024]{0} parameter(1)
  %constant.20951 = f32[] constant(0.0625)
  %broadcast.2023 = f32[1024]{0} broadcast(f32[] %constant.20951), dimensions={}
  %multiply.1763 = f32[1024]{0} multiply(f32[1024]{0} %param_1.1355, f32[1024]{0} %broadcast.2023), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=200}
  %param_0.752 = f32[1024]{0} parameter(0)
  %param_2.1200 = f32[] parameter(2)
  %broadcast.2025 = f32[1024]{0} broadcast(f32[] %param_2.1200), dimensions={}, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
  %add.4269 = f32[1024]{0} add(f32[1024]{0} %param_0.752, f32[1024]{0} %broadcast.2025), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=145}
  %constant.20950 = f32[] constant(-0.5), metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
  %broadcast.2024 = f32[1024]{0} broadcast(f32[] %constant.20950), dimensions={}, metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
  %power.15 = f32[1024]{0} power(f32[1024]{0} %add.4269, f32[1024]{0} %broadcast.2024), metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=145}
  ROOT %multiply.1762 = f32[1024]{0} multiply(f32[1024]{0} %multiply.1763, f32[1024]{0} %power.15), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=145}
}

%fused_computation.411 (param_0.756: f32[1024], param_1.1361: f32[1024], param_2.1209: f32[]) -> f32[1024] {
  %constant.20954 = f32[] constant(1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/metrics.py" source_line=617}
  %param_2.1209 = f32[] parameter(2)
  %subtract.601 = f32[] subtract(f32[] %constant.20954, f32[] %param_2.1209), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=85}
  %broadcast.2028 = f32[1024]{0} broadcast(f32[] %subtract.601), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
  %param_0.756 = f32[1024]{0} parameter(0)
  %multiply.1766 = f32[1024]{0} multiply(f32[1024]{0} %broadcast.2028, f32[1024]{0} %param_0.756), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=143}
  %subtract.600 = f32[] subtract(f32[] %constant.20954, f32[] %subtract.601), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=124}
  %broadcast.2026 = f32[1024]{0} broadcast(f32[] %subtract.600), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=143}
  %param_1.1361 = f32[1024]{0} parameter(1)
  %constant.20952 = f32[] constant(0.0625)
  %broadcast.2027 = f32[1024]{0} broadcast(f32[] %constant.20952), dimensions={}
  %multiply.1767 = f32[1024]{0} multiply(f32[1024]{0} %param_1.1361, f32[1024]{0} %broadcast.2027), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=200}
  %multiply.1765 = f32[1024]{0} multiply(f32[1024]{0} %multiply.1767, f32[1024]{0} %multiply.1767), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=126}
  %multiply.1764 = f32[1024]{0} multiply(f32[1024]{0} %broadcast.2026, f32[1024]{0} %multiply.1765), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=143}
  ROOT %add.4270 = f32[1024]{0} add(f32[1024]{0} %multiply.1766, f32[1024]{0} %multiply.1764), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=143}
}

%fused_computation.412 (param_0.757: f32[1024]) -> f32[1024] {
  %param_0.757 = f32[1024]{0} parameter(0)
  %constant.20955 = f32[] constant(0.0625)
  %broadcast.2029 = f32[1024]{0} broadcast(f32[] %constant.20955), dimensions={}
  ROOT %multiply.1768 = f32[1024]{0} multiply(f32[1024]{0} %param_0.757, f32[1024]{0} %broadcast.2029), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=200}
}

%fused_computation.413 (param_0.761: f32[1]) -> f32[] {
  %param_0.761 = f32[1]{0} parameter(0)
  %reshape.3232 = f32[] reshape(f32[1]{0} %param_0.761), metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %constant.20956 = f32[] constant(0.0009765625)
  %multiply.1769 = f32[] multiply(f32[] %reshape.3232, f32[] %constant.20956), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  ROOT %sqrt.21 = f32[] sqrt(f32[] %multiply.1769), metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
}

%fused_computation.415 (param_0.766: f32[], param_1.1375: f32[1,1]) -> f32[] {
  %param_1.1375 = f32[1,1]{1,0} parameter(1)
  %reshape.3234 = f32[] reshape(f32[1,1]{1,0} %param_1.1375), metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0, 1) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %constant.20961 = f32[] constant(9.53674316e-07)
  %multiply.1776 = f32[] multiply(f32[] %reshape.3234, f32[] %constant.20961), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %sqrt.22 = f32[] sqrt(f32[] %multiply.1776), metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %param_0.766 = f32[] parameter(0)
  ROOT %divide.222 = f32[] divide(f32[] %sqrt.22, f32[] %param_0.766), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
}

%fused_computation.417 (param_0.772: f32[1024], param_1.1382: f32[]) -> f32[1024] {
  %param_0.772 = f32[1024]{0} parameter(0)
  %param_1.1382 = f32[] parameter(1)
  %broadcast.2040 = f32[1024]{0} broadcast(f32[] %param_1.1382), dimensions={}, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
  %add.4271 = f32[1024]{0} add(f32[1024]{0} %param_0.772, f32[1024]{0} %broadcast.2040), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
  %constant.20963 = f32[] constant(-0.5), metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
  %broadcast.2039 = f32[1024]{0} broadcast(f32[] %constant.20963), dimensions={}, metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
  ROOT %power.16 = f32[1024]{0} power(f32[1024]{0} %add.4271, f32[1024]{0} %broadcast.2039), metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
}

%fused_computation.418 (param_0.774: f32[1,1024], param_1.1388: f32[1024], param_2.1229: f32[]) -> f32[1024] {
  %constant.20965 = f32[] constant(1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/metrics.py" source_line=617}
  %param_2.1229 = f32[] parameter(2)
  %subtract.605 = f32[] subtract(f32[] %constant.20965, f32[] %param_2.1229), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=85}
  %broadcast.2042 = f32[1024]{0} broadcast(f32[] %subtract.605), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
  %param_1.1388 = f32[1024]{0} parameter(1)
  %multiply.1782 = f32[1024]{0} multiply(f32[1024]{0} %broadcast.2042, f32[1024]{0} %param_1.1388), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
  %param_0.774 = f32[1,1024]{1,0} parameter(0)
  %subtract.604 = f32[] subtract(f32[] %constant.20965, f32[] %subtract.605), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=124}
  %constant.20964 = f32[] constant(0.0009765625)
  %multiply.1783 = f32[] multiply(f32[] %subtract.604, f32[] %constant.20964)
  %broadcast.2041 = f32[1,1024]{1,0} broadcast(f32[] %multiply.1783), dimensions={}
  %multiply.1781 = f32[1,1024]{1,0} multiply(f32[1,1024]{1,0} %param_0.774, f32[1,1024]{1,0} %broadcast.2041), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
  %reshape.3235 = f32[1024]{0} reshape(f32[1,1024]{1,0} %multiply.1781), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
  ROOT %add.4272 = f32[1024]{0} add(f32[1024]{0} %multiply.1782, f32[1024]{0} %reshape.3235), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
}

%fused_computation.419 (param_0.777: f32[1024], param_1.1393: f32[1], param_2.1235: f32[]) -> f32[1024] {
  %param_1.1393 = f32[1]{0} parameter(1)
  %constant.20966 = f32[1]{0} constant({0.0009765625})
  %multiply.1784 = f32[1]{0} multiply(f32[1]{0} %param_1.1393, f32[1]{0} %constant.20966), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=135}
  %reshape.3236 = f32[] reshape(f32[1]{0} %multiply.1784), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  %broadcast.2043 = f32[1024]{0} broadcast(f32[] %reshape.3236), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  %param_0.777 = f32[1024]{0} parameter(0)
  %param_2.1235 = f32[] parameter(2)
  %broadcast.2045 = f32[1024]{0} broadcast(f32[] %param_2.1235), dimensions={}, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
  %add.4273 = f32[1024]{0} add(f32[1024]{0} %param_0.777, f32[1024]{0} %broadcast.2045), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  %divide.223 = f32[1024]{0} divide(f32[1024]{0} %broadcast.2043, f32[1024]{0} %add.4273), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  %constant.20967 = f32[] constant(0.5), metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  %broadcast.2044 = f32[1024]{0} broadcast(f32[] %constant.20967), dimensions={}, metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  ROOT %power.17 = f32[1024]{0} power(f32[1024]{0} %divide.223, f32[1024]{0} %broadcast.2044), metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
}

%fused_computation.420 (param_0.779: f32[1024,1], param_1.1399: f32[1024], param_2.1242: f32[]) -> f32[1024] {
  %constant.20970 = f32[] constant(1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/metrics.py" source_line=617}
  %param_2.1242 = f32[] parameter(2)
  %subtract.607 = f32[] subtract(f32[] %constant.20970, f32[] %param_2.1242), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=85}
  %broadcast.2047 = f32[1024]{0} broadcast(f32[] %subtract.607), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
  %param_1.1399 = f32[1024]{0} parameter(1)
  %multiply.1786 = f32[1024]{0} multiply(f32[1024]{0} %broadcast.2047, f32[1024]{0} %param_1.1399), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=131}
  %param_0.779 = f32[1024,1]{1,0} parameter(0)
  %subtract.606 = f32[] subtract(f32[] %constant.20970, f32[] %subtract.607), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=124}
  %constant.20969 = f32[] constant(0.0009765625)
  %multiply.1787 = f32[] multiply(f32[] %subtract.606, f32[] %constant.20969)
  %broadcast.2046 = f32[1024,1]{1,0} broadcast(f32[] %multiply.1787), dimensions={}
  %multiply.1785 = f32[1024,1]{1,0} multiply(f32[1024,1]{1,0} %param_0.779, f32[1024,1]{1,0} %broadcast.2046), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=131}
  %reshape.3237 = f32[1024]{0} reshape(f32[1024,1]{1,0} %multiply.1785), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=131}
  ROOT %add.4274 = f32[1024]{0} add(f32[1024]{0} %multiply.1786, f32[1024]{0} %reshape.3237), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=131}
}

%fused_computation.423 (param_0.788: f32[1,1]) -> f32[] {
  %param_0.788 = f32[1,1]{1,0} parameter(0)
  %reshape.3239 = f32[] reshape(f32[1,1]{1,0} %param_0.788), metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0, 1) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %constant.20972 = f32[] constant(9.53674316e-07)
  %multiply.1790 = f32[] multiply(f32[] %reshape.3239, f32[] %constant.20972), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  ROOT %sqrt.23 = f32[] sqrt(f32[] %multiply.1790), metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
}

%fused_computation.424 (param_0.790: f32[1024], param_1.1408: f32[], param_2.1247: f32[], param_3.1042: f32[], param_4.577: f32[], param_5.461: f32[1024], param_6.409: f32[], param_7.342: f32[], param_8.263: s32[]) -> f32[1024] {
  %constant.20975 = f32[] constant(1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/metrics.py" source_line=617}
  %param_8.263 = s32[] parameter(8)
  %constant.20974 = s32[] constant(1), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=113}
  %compare.2779 = pred[] compare(s32[] %param_8.263, s32[] %constant.20974), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=113}
  %param_6.409 = f32[] parameter(6)
  %param_7.342 = f32[] parameter(7)
  %select.2669 = f32[] select(pred[] %compare.2779, f32[] %param_6.409, f32[] %param_7.342), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/jit(_where)/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=112}
  %subtract.609 = f32[] subtract(f32[] %constant.20975, f32[] %select.2669), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  %broadcast.2051 = f32[1024]{0} broadcast(f32[] %subtract.609), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  %param_5.461 = f32[1024]{0} parameter(5)
  %multiply.1793 = f32[1024]{0} multiply(f32[1024]{0} %broadcast.2051, f32[1024]{0} %param_5.461), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  %param_2.1247 = f32[] parameter(2)
  %param_3.1042 = f32[] parameter(3)
  %param_4.577 = f32[] parameter(4)
  %maximum.28 = f32[] maximum(f32[] %param_3.1042, f32[] %param_4.577), metadata={op_type="max" op_name="pmap(_multi_device_update_fn)/max" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=122}
  %multiply.1792 = f32[] multiply(f32[] %param_2.1247, f32[] %maximum.28), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=122}
  %broadcast.2050 = f32[1024]{0} broadcast(f32[] %multiply.1792), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=152}
  %param_0.790 = f32[1024]{0} parameter(0)
  %param_1.1408 = f32[] parameter(1)
  %maximum.27 = f32[] maximum(f32[] %constant.20975, f32[] %param_1.1408), metadata={op_type="max" op_name="pmap(_multi_device_update_fn)/max" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %broadcast.2049 = f32[1024]{0} broadcast(f32[] %maximum.27), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=150}
  %divide.224 = f32[1024]{0} divide(f32[1024]{0} %param_0.790, f32[1024]{0} %broadcast.2049), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=150}
  %multiply.1791 = f32[1024]{0} multiply(f32[1024]{0} %broadcast.2050, f32[1024]{0} %divide.224), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=152}
  ROOT %subtract.608 = f32[1024]{0} subtract(f32[1024]{0} %multiply.1793, f32[1024]{0} %multiply.1791), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
}

%fused_computation.425 (param_0.792: f32[], param_1.1413: f32[1]) -> f32[] {
  %param_1.1413 = f32[1]{0} parameter(1)
  %reshape.3240 = f32[] reshape(f32[1]{0} %param_1.1413), metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %constant.20976 = f32[] constant(0.0009765625)
  %multiply.1794 = f32[] multiply(f32[] %reshape.3240, f32[] %constant.20976), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %sqrt.24 = f32[] sqrt(f32[] %multiply.1794), metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %param_0.792 = f32[] parameter(0)
  ROOT %divide.225 = f32[] divide(f32[] %sqrt.24, f32[] %param_0.792), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
}

%fused_computation.426 (param_0.795: f32[1024], param_1.1419: f32[1024], param_2.1255: f32[]) -> f32[1024] {
  %param_1.1419 = f32[1024]{0} parameter(1)
  %constant.20978 = f32[] constant(0.0625)
  %broadcast.2053 = f32[1024]{0} broadcast(f32[] %constant.20978), dimensions={}
  %multiply.1796 = f32[1024]{0} multiply(f32[1024]{0} %param_1.1419, f32[1024]{0} %broadcast.2053), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=200}
  %param_0.795 = f32[1024]{0} parameter(0)
  %param_2.1255 = f32[] parameter(2)
  %broadcast.2055 = f32[1024]{0} broadcast(f32[] %param_2.1255), dimensions={}, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
  %add.4275 = f32[1024]{0} add(f32[1024]{0} %param_0.795, f32[1024]{0} %broadcast.2055), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=145}
  %constant.20977 = f32[] constant(-0.5), metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
  %broadcast.2054 = f32[1024]{0} broadcast(f32[] %constant.20977), dimensions={}, metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
  %power.18 = f32[1024]{0} power(f32[1024]{0} %add.4275, f32[1024]{0} %broadcast.2054), metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=145}
  ROOT %multiply.1795 = f32[1024]{0} multiply(f32[1024]{0} %multiply.1796, f32[1024]{0} %power.18), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=145}
}

%fused_computation.427 (param_0.799: f32[1024], param_1.1425: f32[1024], param_2.1264: f32[]) -> f32[1024] {
  %constant.20981 = f32[] constant(1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/metrics.py" source_line=617}
  %param_2.1264 = f32[] parameter(2)
  %subtract.611 = f32[] subtract(f32[] %constant.20981, f32[] %param_2.1264), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=85}
  %broadcast.2059 = f32[1024]{0} broadcast(f32[] %subtract.611), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
  %param_0.799 = f32[1024]{0} parameter(0)
  %multiply.1799 = f32[1024]{0} multiply(f32[1024]{0} %broadcast.2059, f32[1024]{0} %param_0.799), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=143}
  %subtract.610 = f32[] subtract(f32[] %constant.20981, f32[] %subtract.611), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=124}
  %broadcast.2057 = f32[1024]{0} broadcast(f32[] %subtract.610), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=143}
  %param_1.1425 = f32[1024]{0} parameter(1)
  %constant.20980 = f32[] constant(0.0625)
  %broadcast.2058 = f32[1024]{0} broadcast(f32[] %constant.20980), dimensions={}
  %multiply.1800 = f32[1024]{0} multiply(f32[1024]{0} %param_1.1425, f32[1024]{0} %broadcast.2058), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=200}
  %multiply.1798 = f32[1024]{0} multiply(f32[1024]{0} %multiply.1800, f32[1024]{0} %multiply.1800), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=126}
  %multiply.1797 = f32[1024]{0} multiply(f32[1024]{0} %broadcast.2057, f32[1024]{0} %multiply.1798), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=143}
  ROOT %add.4276 = f32[1024]{0} add(f32[1024]{0} %multiply.1799, f32[1024]{0} %multiply.1797), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=143}
}

%fused_computation.428 (param_0.800: f32[1024]) -> f32[1024] {
  %param_0.800 = f32[1024]{0} parameter(0)
  %constant.20982 = f32[] constant(0.0625)
  %broadcast.2060 = f32[1024]{0} broadcast(f32[] %constant.20982), dimensions={}
  ROOT %multiply.1801 = f32[1024]{0} multiply(f32[1024]{0} %param_0.800, f32[1024]{0} %broadcast.2060), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=200}
}

%fused_computation.429 (param_0.804: f32[1]) -> f32[] {
  %param_0.804 = f32[1]{0} parameter(0)
  %reshape.3241 = f32[] reshape(f32[1]{0} %param_0.804), metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %constant.20984 = f32[] constant(0.0009765625)
  %multiply.1802 = f32[] multiply(f32[] %reshape.3241, f32[] %constant.20984), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  ROOT %sqrt.25 = f32[] sqrt(f32[] %multiply.1802), metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
}

%fused_computation.431 (param_0.809: f32[], param_1.1439: f32[1,1]) -> f32[] {
  %param_1.1439 = f32[1,1]{1,0} parameter(1)
  %reshape.3242 = f32[] reshape(f32[1,1]{1,0} %param_1.1439), metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0, 1) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %constant.20988 = f32[] constant(9.53674316e-07)
  %multiply.1809 = f32[] multiply(f32[] %reshape.3242, f32[] %constant.20988), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %sqrt.26 = f32[] sqrt(f32[] %multiply.1809), metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %param_0.809 = f32[] parameter(0)
  ROOT %divide.227 = f32[] divide(f32[] %sqrt.26, f32[] %param_0.809), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
}

%fused_computation.433 (param_0.815: f32[1024], param_1.1446: f32[]) -> f32[1024] {
  %param_0.815 = f32[1024]{0} parameter(0)
  %param_1.1446 = f32[] parameter(1)
  %broadcast.2075 = f32[1024]{0} broadcast(f32[] %param_1.1446), dimensions={}, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
  %add.4277 = f32[1024]{0} add(f32[1024]{0} %param_0.815, f32[1024]{0} %broadcast.2075), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
  %constant.20991 = f32[] constant(-0.5), metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
  %broadcast.2073 = f32[1024]{0} broadcast(f32[] %constant.20991), dimensions={}, metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
  ROOT %power.19 = f32[1024]{0} power(f32[1024]{0} %add.4277, f32[1024]{0} %broadcast.2073), metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
}

%fused_computation.434 (param_0.817: f32[1,1024], param_1.1452: f32[1024], param_2.1284: f32[]) -> f32[1024] {
  %constant.20993 = f32[] constant(1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/metrics.py" source_line=617}
  %param_2.1284 = f32[] parameter(2)
  %subtract.615 = f32[] subtract(f32[] %constant.20993, f32[] %param_2.1284), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=85}
  %broadcast.2077 = f32[1024]{0} broadcast(f32[] %subtract.615), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
  %param_1.1452 = f32[1024]{0} parameter(1)
  %multiply.1815 = f32[1024]{0} multiply(f32[1024]{0} %broadcast.2077, f32[1024]{0} %param_1.1452), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
  %param_0.817 = f32[1,1024]{1,0} parameter(0)
  %subtract.614 = f32[] subtract(f32[] %constant.20993, f32[] %subtract.615), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=124}
  %constant.20992 = f32[] constant(0.0009765625)
  %multiply.1816 = f32[] multiply(f32[] %subtract.614, f32[] %constant.20992)
  %broadcast.2076 = f32[1,1024]{1,0} broadcast(f32[] %multiply.1816), dimensions={}
  %multiply.1814 = f32[1,1024]{1,0} multiply(f32[1,1024]{1,0} %param_0.817, f32[1,1024]{1,0} %broadcast.2076), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
  %reshape.3243 = f32[1024]{0} reshape(f32[1,1024]{1,0} %multiply.1814), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
  ROOT %add.4278 = f32[1024]{0} add(f32[1024]{0} %multiply.1815, f32[1024]{0} %reshape.3243), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
}

%fused_computation.435 (param_0.820: f32[1024], param_1.1457: f32[1], param_2.1290: f32[]) -> f32[1024] {
  %param_1.1457 = f32[1]{0} parameter(1)
  %constant.20995 = f32[1]{0} constant({0.0009765625})
  %multiply.1817 = f32[1]{0} multiply(f32[1]{0} %param_1.1457, f32[1]{0} %constant.20995), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=135}
  %reshape.3244 = f32[] reshape(f32[1]{0} %multiply.1817), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  %broadcast.2078 = f32[1024]{0} broadcast(f32[] %reshape.3244), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  %param_0.820 = f32[1024]{0} parameter(0)
  %param_2.1290 = f32[] parameter(2)
  %broadcast.2081 = f32[1024]{0} broadcast(f32[] %param_2.1290), dimensions={}, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
  %add.4279 = f32[1024]{0} add(f32[1024]{0} %param_0.820, f32[1024]{0} %broadcast.2081), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  %divide.228 = f32[1024]{0} divide(f32[1024]{0} %broadcast.2078, f32[1024]{0} %add.4279), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  %constant.20996 = f32[] constant(0.5), metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  %broadcast.2080 = f32[1024]{0} broadcast(f32[] %constant.20996), dimensions={}, metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  ROOT %power.20 = f32[1024]{0} power(f32[1024]{0} %divide.228, f32[1024]{0} %broadcast.2080), metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
}

%fused_computation.436 (param_0.822: f32[1024,1], param_1.1463: f32[1024], param_2.1297: f32[]) -> f32[1024] {
  %constant.20998 = f32[] constant(1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/metrics.py" source_line=617}
  %param_2.1297 = f32[] parameter(2)
  %subtract.617 = f32[] subtract(f32[] %constant.20998, f32[] %param_2.1297), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=85}
  %broadcast.2084 = f32[1024]{0} broadcast(f32[] %subtract.617), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
  %param_1.1463 = f32[1024]{0} parameter(1)
  %multiply.1819 = f32[1024]{0} multiply(f32[1024]{0} %broadcast.2084, f32[1024]{0} %param_1.1463), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=131}
  %param_0.822 = f32[1024,1]{1,0} parameter(0)
  %subtract.616 = f32[] subtract(f32[] %constant.20998, f32[] %subtract.617), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=124}
  %constant.20997 = f32[] constant(0.0009765625)
  %multiply.1820 = f32[] multiply(f32[] %subtract.616, f32[] %constant.20997)
  %broadcast.2082 = f32[1024,1]{1,0} broadcast(f32[] %multiply.1820), dimensions={}
  %multiply.1818 = f32[1024,1]{1,0} multiply(f32[1024,1]{1,0} %param_0.822, f32[1024,1]{1,0} %broadcast.2082), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=131}
  %reshape.3245 = f32[1024]{0} reshape(f32[1024,1]{1,0} %multiply.1818), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=131}
  ROOT %add.4280 = f32[1024]{0} add(f32[1024]{0} %multiply.1819, f32[1024]{0} %reshape.3245), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=131}
}

%fused_computation.439 (param_0.833: f32[1,1]) -> f32[] {
  %param_0.833 = f32[1,1]{1,0} parameter(0)
  %reshape.3250 = f32[] reshape(f32[1,1]{1,0} %param_0.833), metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0, 1) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %constant.21001 = f32[] constant(9.53674316e-07)
  %multiply.1823 = f32[] multiply(f32[] %reshape.3250, f32[] %constant.21001), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  ROOT %sqrt.27 = f32[] sqrt(f32[] %multiply.1823), metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
}

%fused_computation.440 (param_0.835: f32[1024], param_1.1472: f32[], param_2.1302: f32[], param_3.1088: f32[], param_4.601: f32[], param_5.472: f32[1024], param_6.420: f32[], param_7.354: f32[], param_8.272: s32[]) -> f32[1024] {
  %constant.21003 = f32[] constant(1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/metrics.py" source_line=617}
  %param_8.272 = s32[] parameter(8)
  %constant.21002 = s32[] constant(1), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=113}
  %compare.2782 = pred[] compare(s32[] %param_8.272, s32[] %constant.21002), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=113}
  %param_6.420 = f32[] parameter(6)
  %param_7.354 = f32[] parameter(7)
  %select.2671 = f32[] select(pred[] %compare.2782, f32[] %param_6.420, f32[] %param_7.354), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/jit(_where)/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=112}
  %subtract.619 = f32[] subtract(f32[] %constant.21003, f32[] %select.2671), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  %broadcast.2090 = f32[1024]{0} broadcast(f32[] %subtract.619), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  %param_5.472 = f32[1024]{0} parameter(5)
  %multiply.1826 = f32[1024]{0} multiply(f32[1024]{0} %broadcast.2090, f32[1024]{0} %param_5.472), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  %param_2.1302 = f32[] parameter(2)
  %param_3.1088 = f32[] parameter(3)
  %param_4.601 = f32[] parameter(4)
  %maximum.32 = f32[] maximum(f32[] %param_3.1088, f32[] %param_4.601), metadata={op_type="max" op_name="pmap(_multi_device_update_fn)/max" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=122}
  %multiply.1825 = f32[] multiply(f32[] %param_2.1302, f32[] %maximum.32), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=122}
  %broadcast.2088 = f32[1024]{0} broadcast(f32[] %multiply.1825), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=152}
  %param_0.835 = f32[1024]{0} parameter(0)
  %param_1.1472 = f32[] parameter(1)
  %maximum.31 = f32[] maximum(f32[] %constant.21003, f32[] %param_1.1472), metadata={op_type="max" op_name="pmap(_multi_device_update_fn)/max" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %broadcast.2086 = f32[1024]{0} broadcast(f32[] %maximum.31), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=150}
  %divide.229 = f32[1024]{0} divide(f32[1024]{0} %param_0.835, f32[1024]{0} %broadcast.2086), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=150}
  %multiply.1824 = f32[1024]{0} multiply(f32[1024]{0} %broadcast.2088, f32[1024]{0} %divide.229), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=152}
  ROOT %subtract.618 = f32[1024]{0} subtract(f32[1024]{0} %multiply.1826, f32[1024]{0} %multiply.1824), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
}

%fused_computation.441 (param_0.837: f32[], param_1.1477: f32[1]) -> f32[] {
  %param_1.1477 = f32[1]{0} parameter(1)
  %reshape.3252 = f32[] reshape(f32[1]{0} %param_1.1477), metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %constant.21005 = f32[] constant(0.0009765625)
  %multiply.1827 = f32[] multiply(f32[] %reshape.3252, f32[] %constant.21005), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %sqrt.28 = f32[] sqrt(f32[] %multiply.1827), metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %param_0.837 = f32[] parameter(0)
  ROOT %divide.230 = f32[] divide(f32[] %sqrt.28, f32[] %param_0.837), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
}

%fused_computation.442 (param_0.840: f32[1024], param_1.1483: f32[1024], param_2.1310: f32[]) -> f32[1024] {
  %param_1.1483 = f32[1024]{0} parameter(1)
  %constant.21007 = f32[] constant(0.0625)
  %broadcast.2091 = f32[1024]{0} broadcast(f32[] %constant.21007), dimensions={}
  %multiply.1829 = f32[1024]{0} multiply(f32[1024]{0} %param_1.1483, f32[1024]{0} %broadcast.2091), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=200}
  %param_0.840 = f32[1024]{0} parameter(0)
  %param_2.1310 = f32[] parameter(2)
  %broadcast.2093 = f32[1024]{0} broadcast(f32[] %param_2.1310), dimensions={}, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
  %add.4281 = f32[1024]{0} add(f32[1024]{0} %param_0.840, f32[1024]{0} %broadcast.2093), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=145}
  %constant.21006 = f32[] constant(-0.5), metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
  %broadcast.2092 = f32[1024]{0} broadcast(f32[] %constant.21006), dimensions={}, metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
  %power.21 = f32[1024]{0} power(f32[1024]{0} %add.4281, f32[1024]{0} %broadcast.2092), metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=145}
  ROOT %multiply.1828 = f32[1024]{0} multiply(f32[1024]{0} %multiply.1829, f32[1024]{0} %power.21), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=145}
}

%fused_computation.443 (param_0.844: f32[1024], param_1.1489: f32[1024], param_2.1319: f32[]) -> f32[1024] {
  %constant.21009 = f32[] constant(1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/metrics.py" source_line=617}
  %param_2.1319 = f32[] parameter(2)
  %subtract.621 = f32[] subtract(f32[] %constant.21009, f32[] %param_2.1319), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=85}
  %broadcast.2097 = f32[1024]{0} broadcast(f32[] %subtract.621), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
  %param_0.844 = f32[1024]{0} parameter(0)
  %multiply.1832 = f32[1024]{0} multiply(f32[1024]{0} %broadcast.2097, f32[1024]{0} %param_0.844), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=143}
  %subtract.620 = f32[] subtract(f32[] %constant.21009, f32[] %subtract.621), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=124}
  %broadcast.2095 = f32[1024]{0} broadcast(f32[] %subtract.620), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=143}
  %param_1.1489 = f32[1024]{0} parameter(1)
  %constant.21008 = f32[] constant(0.0625)
  %broadcast.2096 = f32[1024]{0} broadcast(f32[] %constant.21008), dimensions={}
  %multiply.1833 = f32[1024]{0} multiply(f32[1024]{0} %param_1.1489, f32[1024]{0} %broadcast.2096), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=200}
  %multiply.1831 = f32[1024]{0} multiply(f32[1024]{0} %multiply.1833, f32[1024]{0} %multiply.1833), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=126}
  %multiply.1830 = f32[1024]{0} multiply(f32[1024]{0} %broadcast.2095, f32[1024]{0} %multiply.1831), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=143}
  ROOT %add.4282 = f32[1024]{0} add(f32[1024]{0} %multiply.1832, f32[1024]{0} %multiply.1830), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=143}
}

%fused_computation.444 (param_0.845: f32[1024]) -> f32[1024] {
  %param_0.845 = f32[1024]{0} parameter(0)
  %constant.21010 = f32[] constant(0.0625)
  %broadcast.2098 = f32[1024]{0} broadcast(f32[] %constant.21010), dimensions={}
  ROOT %multiply.1834 = f32[1024]{0} multiply(f32[1024]{0} %param_0.845, f32[1024]{0} %broadcast.2098), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=200}
}

%fused_computation.445 (param_0.849: f32[1]) -> f32[] {
  %param_0.849 = f32[1]{0} parameter(0)
  %reshape.3254 = f32[] reshape(f32[1]{0} %param_0.849), metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %constant.21011 = f32[] constant(0.0009765625)
  %multiply.1835 = f32[] multiply(f32[] %reshape.3254, f32[] %constant.21011), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  ROOT %sqrt.29 = f32[] sqrt(f32[] %multiply.1835), metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
}

%fused_computation.447 (param_0.854: f32[], param_1.1503: f32[1,1]) -> f32[] {
  %param_1.1503 = f32[1,1]{1,0} parameter(1)
  %reshape.3256 = f32[] reshape(f32[1,1]{1,0} %param_1.1503), metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0, 1) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %constant.21016 = f32[] constant(9.53674316e-07)
  %multiply.1842 = f32[] multiply(f32[] %reshape.3256, f32[] %constant.21016), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %sqrt.30 = f32[] sqrt(f32[] %multiply.1842), metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %param_0.854 = f32[] parameter(0)
  ROOT %divide.232 = f32[] divide(f32[] %sqrt.30, f32[] %param_0.854), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
}

%fused_computation.449 (param_0.860: f32[1024], param_1.1510: f32[]) -> f32[1024] {
  %param_0.860 = f32[1024]{0} parameter(0)
  %param_1.1510 = f32[] parameter(1)
  %broadcast.2109 = f32[1024]{0} broadcast(f32[] %param_1.1510), dimensions={}, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
  %add.4283 = f32[1024]{0} add(f32[1024]{0} %param_0.860, f32[1024]{0} %broadcast.2109), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
  %constant.21019 = f32[] constant(-0.5), metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
  %broadcast.2108 = f32[1024]{0} broadcast(f32[] %constant.21019), dimensions={}, metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
  ROOT %power.22 = f32[1024]{0} power(f32[1024]{0} %add.4283, f32[1024]{0} %broadcast.2108), metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
}

%fused_computation.450 (param_0.862: f32[1,1024], param_1.1516: f32[1024], param_2.1339: f32[]) -> f32[1024] {
  %constant.21021 = f32[] constant(1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/metrics.py" source_line=617}
  %param_2.1339 = f32[] parameter(2)
  %subtract.625 = f32[] subtract(f32[] %constant.21021, f32[] %param_2.1339), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=85}
  %broadcast.2111 = f32[1024]{0} broadcast(f32[] %subtract.625), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
  %param_1.1516 = f32[1024]{0} parameter(1)
  %multiply.1848 = f32[1024]{0} multiply(f32[1024]{0} %broadcast.2111, f32[1024]{0} %param_1.1516), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
  %param_0.862 = f32[1,1024]{1,0} parameter(0)
  %subtract.624 = f32[] subtract(f32[] %constant.21021, f32[] %subtract.625), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=124}
  %constant.21020 = f32[] constant(0.0009765625)
  %multiply.1849 = f32[] multiply(f32[] %subtract.624, f32[] %constant.21020)
  %broadcast.2110 = f32[1,1024]{1,0} broadcast(f32[] %multiply.1849), dimensions={}
  %multiply.1847 = f32[1,1024]{1,0} multiply(f32[1,1024]{1,0} %param_0.862, f32[1,1024]{1,0} %broadcast.2110), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
  %reshape.3257 = f32[1024]{0} reshape(f32[1,1024]{1,0} %multiply.1847), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
  ROOT %add.4284 = f32[1024]{0} add(f32[1024]{0} %multiply.1848, f32[1024]{0} %reshape.3257), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
}

%fused_computation.451 (param_0.865: f32[1024], param_1.1521: f32[1], param_2.1345: f32[]) -> f32[1024] {
  %param_1.1521 = f32[1]{0} parameter(1)
  %constant.21023 = f32[1]{0} constant({0.0009765625})
  %multiply.1850 = f32[1]{0} multiply(f32[1]{0} %param_1.1521, f32[1]{0} %constant.21023), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=135}
  %reshape.3258 = f32[] reshape(f32[1]{0} %multiply.1850), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  %broadcast.2112 = f32[1024]{0} broadcast(f32[] %reshape.3258), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  %param_0.865 = f32[1024]{0} parameter(0)
  %param_2.1345 = f32[] parameter(2)
  %broadcast.2114 = f32[1024]{0} broadcast(f32[] %param_2.1345), dimensions={}, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
  %add.4285 = f32[1024]{0} add(f32[1024]{0} %param_0.865, f32[1024]{0} %broadcast.2114), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  %divide.233 = f32[1024]{0} divide(f32[1024]{0} %broadcast.2112, f32[1024]{0} %add.4285), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  %constant.21024 = f32[] constant(0.5), metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  %broadcast.2113 = f32[1024]{0} broadcast(f32[] %constant.21024), dimensions={}, metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  ROOT %power.23 = f32[1024]{0} power(f32[1024]{0} %divide.233, f32[1024]{0} %broadcast.2113), metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
}

%fused_computation.452 (param_0.867: f32[1024,1], param_1.1527: f32[1024], param_2.1352: f32[]) -> f32[1024] {
  %constant.21027 = f32[] constant(1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/metrics.py" source_line=617}
  %param_2.1352 = f32[] parameter(2)
  %subtract.627 = f32[] subtract(f32[] %constant.21027, f32[] %param_2.1352), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=85}
  %broadcast.2116 = f32[1024]{0} broadcast(f32[] %subtract.627), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
  %param_1.1527 = f32[1024]{0} parameter(1)
  %multiply.1852 = f32[1024]{0} multiply(f32[1024]{0} %broadcast.2116, f32[1024]{0} %param_1.1527), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=131}
  %param_0.867 = f32[1024,1]{1,0} parameter(0)
  %subtract.626 = f32[] subtract(f32[] %constant.21027, f32[] %subtract.627), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=124}
  %constant.21026 = f32[] constant(0.0009765625)
  %multiply.1853 = f32[] multiply(f32[] %subtract.626, f32[] %constant.21026)
  %broadcast.2115 = f32[1024,1]{1,0} broadcast(f32[] %multiply.1853), dimensions={}
  %multiply.1851 = f32[1024,1]{1,0} multiply(f32[1024,1]{1,0} %param_0.867, f32[1024,1]{1,0} %broadcast.2115), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=131}
  %reshape.3259 = f32[1024]{0} reshape(f32[1024,1]{1,0} %multiply.1851), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=131}
  ROOT %add.4286 = f32[1024]{0} add(f32[1024]{0} %multiply.1852, f32[1024]{0} %reshape.3259), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=131}
}

%fused_computation.455 (param_0.875: f32[1,1]) -> f32[] {
  %param_0.875 = f32[1,1]{1,0} parameter(0)
  %reshape.3261 = f32[] reshape(f32[1,1]{1,0} %param_0.875), metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0, 1) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %constant.21029 = f32[] constant(9.53674316e-07)
  %multiply.1856 = f32[] multiply(f32[] %reshape.3261, f32[] %constant.21029), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  ROOT %sqrt.31 = f32[] sqrt(f32[] %multiply.1856), metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
}

%fused_computation.456 (param_0.877: f32[1024], param_1.1536: f32[], param_2.1357: f32[], param_3.1134: f32[], param_4.625: f32[], param_5.483: f32[1024], param_6.431: f32[], param_7.366: f32[], param_8.281: s32[]) -> f32[1024] {
  %constant.21032 = f32[] constant(1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/metrics.py" source_line=617}
  %param_8.281 = s32[] parameter(8)
  %constant.21030 = s32[] constant(1), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=113}
  %compare.2784 = pred[] compare(s32[] %param_8.281, s32[] %constant.21030), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=113}
  %param_6.431 = f32[] parameter(6)
  %param_7.366 = f32[] parameter(7)
  %select.2673 = f32[] select(pred[] %compare.2784, f32[] %param_6.431, f32[] %param_7.366), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/jit(_where)/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=112}
  %subtract.629 = f32[] subtract(f32[] %constant.21032, f32[] %select.2673), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  %broadcast.2120 = f32[1024]{0} broadcast(f32[] %subtract.629), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  %param_5.483 = f32[1024]{0} parameter(5)
  %multiply.1859 = f32[1024]{0} multiply(f32[1024]{0} %broadcast.2120, f32[1024]{0} %param_5.483), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  %param_2.1357 = f32[] parameter(2)
  %param_3.1134 = f32[] parameter(3)
  %param_4.625 = f32[] parameter(4)
  %maximum.36 = f32[] maximum(f32[] %param_3.1134, f32[] %param_4.625), metadata={op_type="max" op_name="pmap(_multi_device_update_fn)/max" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=122}
  %multiply.1858 = f32[] multiply(f32[] %param_2.1357, f32[] %maximum.36), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=122}
  %broadcast.2119 = f32[1024]{0} broadcast(f32[] %multiply.1858), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=152}
  %param_0.877 = f32[1024]{0} parameter(0)
  %param_1.1536 = f32[] parameter(1)
  %maximum.35 = f32[] maximum(f32[] %constant.21032, f32[] %param_1.1536), metadata={op_type="max" op_name="pmap(_multi_device_update_fn)/max" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %broadcast.2118 = f32[1024]{0} broadcast(f32[] %maximum.35), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=150}
  %divide.234 = f32[1024]{0} divide(f32[1024]{0} %param_0.877, f32[1024]{0} %broadcast.2118), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=150}
  %multiply.1857 = f32[1024]{0} multiply(f32[1024]{0} %broadcast.2119, f32[1024]{0} %divide.234), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=152}
  ROOT %subtract.628 = f32[1024]{0} subtract(f32[1024]{0} %multiply.1859, f32[1024]{0} %multiply.1857), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
}

%fused_computation.457 (param_0.879: f32[], param_1.1541: f32[1]) -> f32[] {
  %param_1.1541 = f32[1]{0} parameter(1)
  %reshape.3262 = f32[] reshape(f32[1]{0} %param_1.1541), metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %constant.21033 = f32[] constant(0.0009765625)
  %multiply.1860 = f32[] multiply(f32[] %reshape.3262, f32[] %constant.21033), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %sqrt.32 = f32[] sqrt(f32[] %multiply.1860), metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %param_0.879 = f32[] parameter(0)
  ROOT %divide.235 = f32[] divide(f32[] %sqrt.32, f32[] %param_0.879), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
}

%fused_computation.458 (param_0.882: f32[1024], param_1.1547: f32[1024], param_2.1365: f32[]) -> f32[1024] {
  %param_1.1547 = f32[1024]{0} parameter(1)
  %constant.21035 = f32[] constant(0.0625)
  %broadcast.2121 = f32[1024]{0} broadcast(f32[] %constant.21035), dimensions={}
  %multiply.1862 = f32[1024]{0} multiply(f32[1024]{0} %param_1.1547, f32[1024]{0} %broadcast.2121), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=200}
  %param_0.882 = f32[1024]{0} parameter(0)
  %param_2.1365 = f32[] parameter(2)
  %broadcast.2123 = f32[1024]{0} broadcast(f32[] %param_2.1365), dimensions={}, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
  %add.4287 = f32[1024]{0} add(f32[1024]{0} %param_0.882, f32[1024]{0} %broadcast.2123), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=145}
  %constant.21034 = f32[] constant(-0.5), metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
  %broadcast.2122 = f32[1024]{0} broadcast(f32[] %constant.21034), dimensions={}, metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
  %power.24 = f32[1024]{0} power(f32[1024]{0} %add.4287, f32[1024]{0} %broadcast.2122), metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=145}
  ROOT %multiply.1861 = f32[1024]{0} multiply(f32[1024]{0} %multiply.1862, f32[1024]{0} %power.24), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=145}
}

%fused_computation.459 (param_0.886: f32[1024], param_1.1554: f32[1024], param_2.1374: f32[]) -> f32[1024] {
  %constant.21038 = f32[] constant(1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/metrics.py" source_line=617}
  %param_2.1374 = f32[] parameter(2)
  %subtract.631 = f32[] subtract(f32[] %constant.21038, f32[] %param_2.1374), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=85}
  %broadcast.2126 = f32[1024]{0} broadcast(f32[] %subtract.631), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
  %param_0.886 = f32[1024]{0} parameter(0)
  %multiply.1865 = f32[1024]{0} multiply(f32[1024]{0} %broadcast.2126, f32[1024]{0} %param_0.886), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=143}
  %subtract.630 = f32[] subtract(f32[] %constant.21038, f32[] %subtract.631), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=124}
  %broadcast.2124 = f32[1024]{0} broadcast(f32[] %subtract.630), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=143}
  %param_1.1554 = f32[1024]{0} parameter(1)
  %constant.21037 = f32[] constant(0.0625)
  %broadcast.2125 = f32[1024]{0} broadcast(f32[] %constant.21037), dimensions={}
  %multiply.1866 = f32[1024]{0} multiply(f32[1024]{0} %param_1.1554, f32[1024]{0} %broadcast.2125), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=200}
  %multiply.1864 = f32[1024]{0} multiply(f32[1024]{0} %multiply.1866, f32[1024]{0} %multiply.1866), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=126}
  %multiply.1863 = f32[1024]{0} multiply(f32[1024]{0} %broadcast.2124, f32[1024]{0} %multiply.1864), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=143}
  ROOT %add.4288 = f32[1024]{0} add(f32[1024]{0} %multiply.1865, f32[1024]{0} %multiply.1863), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=143}
}

%fused_computation.460 (param_0.887: f32[1024]) -> f32[1024] {
  %param_0.887 = f32[1024]{0} parameter(0)
  %constant.21039 = f32[] constant(0.0625)
  %broadcast.2127 = f32[1024]{0} broadcast(f32[] %constant.21039), dimensions={}
  ROOT %multiply.1867 = f32[1024]{0} multiply(f32[1024]{0} %param_0.887, f32[1024]{0} %broadcast.2127), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=200}
}

%fused_computation.461 (param_0.891: f32[1]) -> f32[] {
  %param_0.891 = f32[1]{0} parameter(0)
  %reshape.3263 = f32[] reshape(f32[1]{0} %param_0.891), metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %constant.21040 = f32[] constant(0.0009765625)
  %multiply.1868 = f32[] multiply(f32[] %reshape.3263, f32[] %constant.21040), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  ROOT %sqrt.33 = f32[] sqrt(f32[] %multiply.1868), metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
}

%fused_computation.463 (param_0.896: f32[], param_1.1568: f32[1,1]) -> f32[] {
  %param_1.1568 = f32[1,1]{1,0} parameter(1)
  %reshape.3264 = f32[] reshape(f32[1,1]{1,0} %param_1.1568), metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0, 1) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %constant.21045 = f32[] constant(9.53674316e-07)
  %multiply.1875 = f32[] multiply(f32[] %reshape.3264, f32[] %constant.21045), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %sqrt.34 = f32[] sqrt(f32[] %multiply.1875), metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %param_0.896 = f32[] parameter(0)
  ROOT %divide.237 = f32[] divide(f32[] %sqrt.34, f32[] %param_0.896), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
}

%fused_computation.465 (param_0.902: f32[1024], param_1.1575: f32[]) -> f32[1024] {
  %param_0.902 = f32[1024]{0} parameter(0)
  %param_1.1575 = f32[] parameter(1)
  %broadcast.2140 = f32[1024]{0} broadcast(f32[] %param_1.1575), dimensions={}, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
  %add.4289 = f32[1024]{0} add(f32[1024]{0} %param_0.902, f32[1024]{0} %broadcast.2140), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
  %constant.21048 = f32[] constant(-0.5), metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
  %broadcast.2139 = f32[1024]{0} broadcast(f32[] %constant.21048), dimensions={}, metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
  ROOT %power.25 = f32[1024]{0} power(f32[1024]{0} %add.4289, f32[1024]{0} %broadcast.2139), metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
}

%fused_computation.466 (param_0.904: f32[1,1024], param_1.1580: f32[1024], param_2.1394: f32[]) -> f32[1024] {
  %constant.21050 = f32[] constant(1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/metrics.py" source_line=617}
  %param_2.1394 = f32[] parameter(2)
  %subtract.635 = f32[] subtract(f32[] %constant.21050, f32[] %param_2.1394), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=85}
  %broadcast.2142 = f32[1024]{0} broadcast(f32[] %subtract.635), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
  %param_1.1580 = f32[1024]{0} parameter(1)
  %multiply.1881 = f32[1024]{0} multiply(f32[1024]{0} %broadcast.2142, f32[1024]{0} %param_1.1580), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
  %param_0.904 = f32[1,1024]{1,0} parameter(0)
  %subtract.634 = f32[] subtract(f32[] %constant.21050, f32[] %subtract.635), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=124}
  %constant.21049 = f32[] constant(0.0009765625)
  %multiply.1882 = f32[] multiply(f32[] %subtract.634, f32[] %constant.21049)
  %broadcast.2141 = f32[1,1024]{1,0} broadcast(f32[] %multiply.1882), dimensions={}
  %multiply.1880 = f32[1,1024]{1,0} multiply(f32[1,1024]{1,0} %param_0.904, f32[1,1024]{1,0} %broadcast.2141), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
  %reshape.3265 = f32[1024]{0} reshape(f32[1,1024]{1,0} %multiply.1880), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
  ROOT %add.4290 = f32[1024]{0} add(f32[1024]{0} %multiply.1881, f32[1024]{0} %reshape.3265), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
}

%fused_computation.467 (param_0.907: f32[1024], param_1.1585: f32[1], param_2.1399: f32[]) -> f32[1024] {
  %param_1.1585 = f32[1]{0} parameter(1)
  %constant.21051 = f32[1]{0} constant({0.0009765625})
  %multiply.1883 = f32[1]{0} multiply(f32[1]{0} %param_1.1585, f32[1]{0} %constant.21051), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=135}
  %reshape.3266 = f32[] reshape(f32[1]{0} %multiply.1883), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  %broadcast.2144 = f32[1024]{0} broadcast(f32[] %reshape.3266), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  %param_0.907 = f32[1024]{0} parameter(0)
  %param_2.1399 = f32[] parameter(2)
  %broadcast.2145 = f32[1024]{0} broadcast(f32[] %param_2.1399), dimensions={}, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
  %add.4291 = f32[1024]{0} add(f32[1024]{0} %param_0.907, f32[1024]{0} %broadcast.2145), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  %divide.238 = f32[1024]{0} divide(f32[1024]{0} %broadcast.2144, f32[1024]{0} %add.4291), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  %constant.21052 = f32[] constant(0.5), metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  %broadcast.2143 = f32[1024]{0} broadcast(f32[] %constant.21052), dimensions={}, metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  ROOT %power.26 = f32[1024]{0} power(f32[1024]{0} %divide.238, f32[1024]{0} %broadcast.2143), metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
}

%fused_computation.468 (param_0.909: f32[1024,1], param_1.1590: f32[1024], param_2.1406: f32[]) -> f32[1024] {
  %constant.21054 = f32[] constant(1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/metrics.py" source_line=617}
  %param_2.1406 = f32[] parameter(2)
  %subtract.637 = f32[] subtract(f32[] %constant.21054, f32[] %param_2.1406), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=85}
  %broadcast.2147 = f32[1024]{0} broadcast(f32[] %subtract.637), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
  %param_1.1590 = f32[1024]{0} parameter(1)
  %multiply.1885 = f32[1024]{0} multiply(f32[1024]{0} %broadcast.2147, f32[1024]{0} %param_1.1590), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=131}
  %param_0.909 = f32[1024,1]{1,0} parameter(0)
  %subtract.636 = f32[] subtract(f32[] %constant.21054, f32[] %subtract.637), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=124}
  %constant.21053 = f32[] constant(0.0009765625)
  %multiply.1886 = f32[] multiply(f32[] %subtract.636, f32[] %constant.21053)
  %broadcast.2146 = f32[1024,1]{1,0} broadcast(f32[] %multiply.1886), dimensions={}
  %multiply.1884 = f32[1024,1]{1,0} multiply(f32[1024,1]{1,0} %param_0.909, f32[1024,1]{1,0} %broadcast.2146), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=131}
  %reshape.3267 = f32[1024]{0} reshape(f32[1024,1]{1,0} %multiply.1884), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=131}
  ROOT %add.4292 = f32[1024]{0} add(f32[1024]{0} %multiply.1885, f32[1024]{0} %reshape.3267), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=131}
}

%fused_computation.471 (param_0.916: f32[1,1]) -> f32[] {
  %param_0.916 = f32[1,1]{1,0} parameter(0)
  %reshape.3269 = f32[] reshape(f32[1,1]{1,0} %param_0.916), metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0, 1) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %constant.21057 = f32[] constant(9.53674316e-07)
  %multiply.1889 = f32[] multiply(f32[] %reshape.3269, f32[] %constant.21057), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  ROOT %sqrt.35 = f32[] sqrt(f32[] %multiply.1889), metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
}

%fused_computation.472 (param_0.918: f32[4096], param_1.1598: f32[], param_2.1411: f32[], param_3.1174: f32[], param_4.647: f32[], param_5.494: f32[4096], param_6.442: f32[], param_7.379: f32[], param_8.289: s32[]) -> f32[4096] {
  %constant.21059 = f32[] constant(1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/metrics.py" source_line=617}
  %param_8.289 = s32[] parameter(8)
  %constant.21058 = s32[] constant(1), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=113}
  %compare.2787 = pred[] compare(s32[] %param_8.289, s32[] %constant.21058), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=113}
  %param_6.442 = f32[] parameter(6)
  %param_7.379 = f32[] parameter(7)
  %select.2675 = f32[] select(pred[] %compare.2787, f32[] %param_6.442, f32[] %param_7.379), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/jit(_where)/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=112}
  %subtract.639 = f32[] subtract(f32[] %constant.21059, f32[] %select.2675), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  %broadcast.2151 = f32[4096]{0} broadcast(f32[] %subtract.639), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  %param_5.494 = f32[4096]{0} parameter(5)
  %multiply.1892 = f32[4096]{0} multiply(f32[4096]{0} %broadcast.2151, f32[4096]{0} %param_5.494), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  %param_2.1411 = f32[] parameter(2)
  %param_3.1174 = f32[] parameter(3)
  %param_4.647 = f32[] parameter(4)
  %maximum.40 = f32[] maximum(f32[] %param_3.1174, f32[] %param_4.647), metadata={op_type="max" op_name="pmap(_multi_device_update_fn)/max" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=122}
  %multiply.1891 = f32[] multiply(f32[] %param_2.1411, f32[] %maximum.40), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=122}
  %broadcast.2150 = f32[4096]{0} broadcast(f32[] %multiply.1891), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=152}
  %param_0.918 = f32[4096]{0} parameter(0)
  %param_1.1598 = f32[] parameter(1)
  %maximum.39 = f32[] maximum(f32[] %constant.21059, f32[] %param_1.1598), metadata={op_type="max" op_name="pmap(_multi_device_update_fn)/max" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %broadcast.2149 = f32[4096]{0} broadcast(f32[] %maximum.39), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=150}
  %divide.239 = f32[4096]{0} divide(f32[4096]{0} %param_0.918, f32[4096]{0} %broadcast.2149), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=150}
  %multiply.1890 = f32[4096]{0} multiply(f32[4096]{0} %broadcast.2150, f32[4096]{0} %divide.239), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=152}
  ROOT %subtract.638 = f32[4096]{0} subtract(f32[4096]{0} %multiply.1892, f32[4096]{0} %multiply.1890), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
}

%fused_computation.473 (param_0.920: f32[], param_1.1603: f32[4]) -> f32[] {
  %param_1.1603 = f32[4]{0} parameter(1)
  %constant.21062 = f32[] constant(0)
  %reduce.310 = f32[] reduce(f32[4]{0} %param_1.1603, f32[] %constant.21062), dimensions={0}, to_apply=%primitive_computation_add__1.19750, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %constant.21060 = f32[] constant(0.000244140625)
  %multiply.1893 = f32[] multiply(f32[] %reduce.310, f32[] %constant.21060), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %sqrt.36 = f32[] sqrt(f32[] %multiply.1893), metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %param_0.920 = f32[] parameter(0)
  ROOT %divide.240 = f32[] divide(f32[] %sqrt.36, f32[] %param_0.920), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
}

%fused_computation.474 (param_0.923: f32[4096], param_1.1609: f32[4096], param_2.1420: f32[]) -> f32[4096] {
  %param_1.1609 = f32[4096]{0} parameter(1)
  %constant.21064 = f32[] constant(0.0625)
  %broadcast.2152 = f32[4096]{0} broadcast(f32[] %constant.21064), dimensions={}
  %multiply.1895 = f32[4096]{0} multiply(f32[4096]{0} %param_1.1609, f32[4096]{0} %broadcast.2152), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=200}
  %param_0.923 = f32[4096]{0} parameter(0)
  %param_2.1420 = f32[] parameter(2)
  %broadcast.2154 = f32[4096]{0} broadcast(f32[] %param_2.1420), dimensions={}, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
  %add.4293 = f32[4096]{0} add(f32[4096]{0} %param_0.923, f32[4096]{0} %broadcast.2154), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=145}
  %constant.21063 = f32[] constant(-0.5), metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
  %broadcast.2153 = f32[4096]{0} broadcast(f32[] %constant.21063), dimensions={}, metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
  %power.27 = f32[4096]{0} power(f32[4096]{0} %add.4293, f32[4096]{0} %broadcast.2153), metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=145}
  ROOT %multiply.1894 = f32[4096]{0} multiply(f32[4096]{0} %multiply.1895, f32[4096]{0} %power.27), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=145}
}

%fused_computation.475 (param_0.927: f32[4096], param_1.1615: f32[4096], param_2.1429: f32[]) -> f32[4096] {
  %constant.21066 = f32[] constant(1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/metrics.py" source_line=617}
  %param_2.1429 = f32[] parameter(2)
  %subtract.641 = f32[] subtract(f32[] %constant.21066, f32[] %param_2.1429), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=85}
  %broadcast.2157 = f32[4096]{0} broadcast(f32[] %subtract.641), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
  %param_0.927 = f32[4096]{0} parameter(0)
  %multiply.1898 = f32[4096]{0} multiply(f32[4096]{0} %broadcast.2157, f32[4096]{0} %param_0.927), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=143}
  %subtract.640 = f32[] subtract(f32[] %constant.21066, f32[] %subtract.641), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=124}
  %broadcast.2155 = f32[4096]{0} broadcast(f32[] %subtract.640), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=143}
  %param_1.1615 = f32[4096]{0} parameter(1)
  %constant.21065 = f32[] constant(0.0625)
  %broadcast.2156 = f32[4096]{0} broadcast(f32[] %constant.21065), dimensions={}
  %multiply.1899 = f32[4096]{0} multiply(f32[4096]{0} %param_1.1615, f32[4096]{0} %broadcast.2156), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=200}
  %multiply.1897 = f32[4096]{0} multiply(f32[4096]{0} %multiply.1899, f32[4096]{0} %multiply.1899), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=126}
  %multiply.1896 = f32[4096]{0} multiply(f32[4096]{0} %broadcast.2155, f32[4096]{0} %multiply.1897), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=143}
  ROOT %add.4294 = f32[4096]{0} add(f32[4096]{0} %multiply.1898, f32[4096]{0} %multiply.1896), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=143}
}

%fused_computation.476 (param_0.928: f32[4096]) -> f32[4096] {
  %param_0.928 = f32[4096]{0} parameter(0)
  %constant.21068 = f32[] constant(0.0625)
  %broadcast.2158 = f32[4096]{0} broadcast(f32[] %constant.21068), dimensions={}
  ROOT %multiply.1900 = f32[4096]{0} multiply(f32[4096]{0} %param_0.928, f32[4096]{0} %broadcast.2158), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=200}
}

%fused_computation.477 (param_0.932: f32[4]) -> f32[] {
  %param_0.932 = f32[4]{0} parameter(0)
  %constant.21070 = f32[] constant(0)
  %reduce.311 = f32[] reduce(f32[4]{0} %param_0.932, f32[] %constant.21070), dimensions={0}, to_apply=%primitive_computation_add__1.19724, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %constant.21069 = f32[] constant(0.000244140625)
  %multiply.1901 = f32[] multiply(f32[] %reduce.311, f32[] %constant.21069), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  ROOT %sqrt.37 = f32[] sqrt(f32[] %multiply.1901), metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
}

%fused_computation.479 (param_0.937: f32[], param_1.1630: f32[2,4]) -> f32[] {
  %param_1.1630 = f32[2,4]{1,0} parameter(1)
  %constant.21076 = f32[] constant(0)
  %reduce.312 = f32[] reduce(f32[2,4]{1,0} %param_1.1630, f32[] %constant.21076), dimensions={0,1}, to_apply=%primitive_computation_add__1.19672, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0, 1) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %constant.21075 = f32[] constant(1.1920929e-07)
  %multiply.1908 = f32[] multiply(f32[] %reduce.312, f32[] %constant.21075), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %sqrt.38 = f32[] sqrt(f32[] %multiply.1908), metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %param_0.937 = f32[] parameter(0)
  ROOT %divide.242 = f32[] divide(f32[] %sqrt.38, f32[] %param_0.937), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
}

%fused_computation.481 (param_0.943: f32[4096], param_1.1638: f32[]) -> f32[4096] {
  %param_0.943 = f32[4096]{0} parameter(0)
  %param_1.1638 = f32[] parameter(1)
  %broadcast.2169 = f32[4096]{0} broadcast(f32[] %param_1.1638), dimensions={}, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
  %add.4295 = f32[4096]{0} add(f32[4096]{0} %param_0.943, f32[4096]{0} %broadcast.2169), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
  %constant.21078 = f32[] constant(-0.5), metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
  %broadcast.2168 = f32[4096]{0} broadcast(f32[] %constant.21078), dimensions={}, metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
  ROOT %power.28 = f32[4096]{0} power(f32[4096]{0} %add.4295, f32[4096]{0} %broadcast.2168), metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
}

%fused_computation.482 (param_0.945: f32[4096], param_1.1643: f32[4096], param_2.1452: f32[]) -> f32[4096] {
  %constant.21080 = f32[] constant(1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/metrics.py" source_line=617}
  %param_2.1452 = f32[] parameter(2)
  %subtract.645 = f32[] subtract(f32[] %constant.21080, f32[] %param_2.1452), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=85}
  %broadcast.2171 = f32[4096]{0} broadcast(f32[] %subtract.645), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
  %param_1.1643 = f32[4096]{0} parameter(1)
  %multiply.1914 = f32[4096]{0} multiply(f32[4096]{0} %broadcast.2171, f32[4096]{0} %param_1.1643), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
  %param_0.945 = f32[4096]{0} parameter(0)
  %subtract.644 = f32[] subtract(f32[] %constant.21080, f32[] %subtract.645), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=124}
  %constant.21079 = f32[] constant(0.00048828125)
  %multiply.1915 = f32[] multiply(f32[] %subtract.644, f32[] %constant.21079)
  %broadcast.2170 = f32[4096]{0} broadcast(f32[] %multiply.1915), dimensions={}
  %multiply.1913 = f32[4096]{0} multiply(f32[4096]{0} %param_0.945, f32[4096]{0} %broadcast.2170), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
  ROOT %add.4297 = f32[4096]{0} add(f32[4096]{0} %multiply.1914, f32[4096]{0} %multiply.1913), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
}

%fused_computation.483 (param_0.948: f32[2048], param_1.1648: f32[], param_2.1459: f32[]) -> f32[2048] {
  %param_1.1648 = f32[] parameter(1)
  %constant.21081 = f32[] constant(0.00048828125)
  %multiply.1916 = f32[] multiply(f32[] %param_1.1648, f32[] %constant.21081), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=135}
  %broadcast.2172 = f32[2048]{0} broadcast(f32[] %multiply.1916), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  %param_0.948 = f32[2048]{0} parameter(0)
  %param_2.1459 = f32[] parameter(2)
  %broadcast.2174 = f32[2048]{0} broadcast(f32[] %param_2.1459), dimensions={}, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  %add.4298 = f32[2048]{0} add(f32[2048]{0} %param_0.948, f32[2048]{0} %broadcast.2174), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  %divide.243 = f32[2048]{0} divide(f32[2048]{0} %broadcast.2172, f32[2048]{0} %add.4298), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  %constant.21083 = f32[] constant(0.5), metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  %broadcast.2173 = f32[2048]{0} broadcast(f32[] %constant.21083), dimensions={}, metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  ROOT %power.29 = f32[2048]{0} power(f32[2048]{0} %divide.243, f32[2048]{0} %broadcast.2173), metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
}

%fused_computation.484 (param_0.951: f32[2048,4], param_1.1654: f32[2048], param_2.1466: f32[]) -> f32[2048] {
  %constant.21086 = f32[] constant(1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/metrics.py" source_line=617}
  %param_2.1466 = f32[] parameter(2)
  %subtract.647 = f32[] subtract(f32[] %constant.21086, f32[] %param_2.1466), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=85}
  %broadcast.2176 = f32[2048]{0} broadcast(f32[] %subtract.647), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=131}
  %param_1.1654 = f32[2048]{0} parameter(1)
  %multiply.1918 = f32[2048]{0} multiply(f32[2048]{0} %broadcast.2176, f32[2048]{0} %param_1.1654), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=131}
  %param_0.951 = f32[2048,4]{1,0} parameter(0)
  %constant.21085 = f32[] constant(0)
  %reduce.313 = f32[2048]{0} reduce(f32[2048,4]{1,0} %param_0.951, f32[] %constant.21085), dimensions={1}, to_apply=%primitive_computation_add__1.19614, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(1,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=131}
  %subtract.646 = f32[] subtract(f32[] %constant.21086, f32[] %subtract.647), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=124}
  %constant.21084 = f32[] constant(0.000244140625)
  %multiply.1919 = f32[] multiply(f32[] %subtract.646, f32[] %constant.21084)
  %broadcast.2175 = f32[2048]{0} broadcast(f32[] %multiply.1919), dimensions={}
  %multiply.1917 = f32[2048]{0} multiply(f32[2048]{0} %reduce.313, f32[2048]{0} %broadcast.2175), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=131}
  ROOT %add.4299 = f32[2048]{0} add(f32[2048]{0} %multiply.1918, f32[2048]{0} %multiply.1917), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=131}
}

%fused_computation.486 (param_0.957: f32[2,4]) -> f32[] {
  %param_0.957 = f32[2,4]{1,0} parameter(0)
  %constant.21090 = f32[] constant(0)
  %reduce.314 = f32[] reduce(f32[2,4]{1,0} %param_0.957, f32[] %constant.21090), dimensions={0,1}, to_apply=%primitive_computation_add__1.19598, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0, 1) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %constant.21089 = f32[] constant(1.1920929e-07)
  %multiply.1922 = f32[] multiply(f32[] %reduce.314, f32[] %constant.21089), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  ROOT %sqrt.39 = f32[] sqrt(f32[] %multiply.1922), metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
}

%fused_computation.488 (param_0.962: f32[], param_1.1669: f32[8,32]) -> f32[] {
  %param_1.1669 = f32[8,32]{1,0} parameter(1)
  %constant.21095 = f32[] constant(0)
  %reduce.315 = f32[] reduce(f32[8,32]{1,0} %param_1.1669, f32[] %constant.21095), dimensions={0,1}, to_apply=%primitive_computation_add__1.19546, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0, 1) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %constant.21094 = f32[] constant(3.81469727e-06)
  %multiply.1929 = f32[] multiply(f32[] %reduce.315, f32[] %constant.21094), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %sqrt.40 = f32[] sqrt(f32[] %multiply.1929), metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %param_0.962 = f32[] parameter(0)
  ROOT %divide.245 = f32[] divide(f32[] %sqrt.40, f32[] %param_0.962), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
}

%fused_computation.490 (param_0.968: f32[1024], param_1.1676: f32[]) -> f32[1024] {
  %param_0.968 = f32[1024]{0} parameter(0)
  %param_1.1676 = f32[] parameter(1)
  %broadcast.2188 = f32[1024]{0} broadcast(f32[] %param_1.1676), dimensions={}, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
  %add.4300 = f32[1024]{0} add(f32[1024]{0} %param_0.968, f32[1024]{0} %broadcast.2188), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
  %constant.21097 = f32[] constant(-0.5), metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
  %broadcast.2187 = f32[1024]{0} broadcast(f32[] %constant.21097), dimensions={}, metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
  ROOT %power.30 = f32[1024]{0} power(f32[1024]{0} %add.4300, f32[1024]{0} %broadcast.2187), metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
}

%fused_computation.491 (param_0.970: f32[1024], param_1.1680: f32[1024], param_2.1490: f32[]) -> f32[1024] {
  %constant.21100 = f32[] constant(1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/metrics.py" source_line=617}
  %param_2.1490 = f32[] parameter(2)
  %subtract.651 = f32[] subtract(f32[] %constant.21100, f32[] %param_2.1490), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=85}
  %broadcast.2190 = f32[1024]{0} broadcast(f32[] %subtract.651), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
  %param_1.1680 = f32[1024]{0} parameter(1)
  %multiply.1936 = f32[1024]{0} multiply(f32[1024]{0} %broadcast.2190, f32[1024]{0} %param_1.1680), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
  %param_0.970 = f32[1024]{0} parameter(0)
  %subtract.650 = f32[] subtract(f32[] %constant.21100, f32[] %subtract.651), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=124}
  %constant.21098 = f32[] constant(0.00390625)
  %multiply.1935 = f32[] multiply(f32[] %subtract.650, f32[] %constant.21098)
  %broadcast.2189 = f32[1024]{0} broadcast(f32[] %multiply.1935), dimensions={}
  %multiply.1934 = f32[1024]{0} multiply(f32[1024]{0} %param_0.970, f32[1024]{0} %broadcast.2189), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
  ROOT %add.4301 = f32[1024]{0} add(f32[1024]{0} %multiply.1936, f32[1024]{0} %multiply.1934), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
}

%fused_computation.492 (param_0.973: f32[256], param_1.1685: f32[], param_2.1494: f32[]) -> f32[256] {
  %param_2.1494 = f32[] parameter(2)
  %constant.21101 = f32[] constant(0.00390625)
  %multiply.1937 = f32[] multiply(f32[] %param_2.1494, f32[] %constant.21101), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=135}
  %broadcast.2193 = f32[256]{0} broadcast(f32[] %multiply.1937), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  %param_0.973 = f32[256]{0} parameter(0)
  %param_1.1685 = f32[] parameter(1)
  %broadcast.2192 = f32[256]{0} broadcast(f32[] %param_1.1685), dimensions={}, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  %add.4302 = f32[256]{0} add(f32[256]{0} %param_0.973, f32[256]{0} %broadcast.2192), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  %divide.246 = f32[256]{0} divide(f32[256]{0} %broadcast.2193, f32[256]{0} %add.4302), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  %constant.21102 = f32[] constant(0.5), metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  %broadcast.2191 = f32[256]{0} broadcast(f32[] %constant.21102), dimensions={}, metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  ROOT %power.31 = f32[256]{0} power(f32[256]{0} %divide.246, f32[256]{0} %broadcast.2191), metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
}

%fused_computation.493 (param_0.975: f32[256,1], param_1.1690: f32[256], param_2.1501: f32[]) -> f32[256] {
  %constant.21104 = f32[] constant(1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/metrics.py" source_line=617}
  %param_2.1501 = f32[] parameter(2)
  %subtract.653 = f32[] subtract(f32[] %constant.21104, f32[] %param_2.1501), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=85}
  %broadcast.2195 = f32[256]{0} broadcast(f32[] %subtract.653), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=131}
  %param_1.1690 = f32[256]{0} parameter(1)
  %multiply.1939 = f32[256]{0} multiply(f32[256]{0} %broadcast.2195, f32[256]{0} %param_1.1690), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=131}
  %param_0.975 = f32[256,1]{1,0} parameter(0)
  %subtract.652 = f32[] subtract(f32[] %constant.21104, f32[] %subtract.653), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=124}
  %constant.21103 = f32[] constant(0.0009765625)
  %multiply.1940 = f32[] multiply(f32[] %subtract.652, f32[] %constant.21103)
  %broadcast.2194 = f32[256,1]{1,0} broadcast(f32[] %multiply.1940), dimensions={}
  %multiply.1938 = f32[256,1]{1,0} multiply(f32[256,1]{1,0} %param_0.975, f32[256,1]{1,0} %broadcast.2194), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=131}
  %reshape.3270 = f32[256]{0} reshape(f32[256,1]{1,0} %multiply.1938), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=131}
  ROOT %add.4303 = f32[256]{0} add(f32[256]{0} %multiply.1939, f32[256]{0} %reshape.3270), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=131}
}

%fused_computation.497 (param_0.987: f32[8,1,64,64], param_1.1700: f32[8,1,64,64], param_2.1506: f32[8,1,64], param_3.1249: s32[8,64]) -> f32[8,64,64] {
  %param_3.1249 = s32[8,64]{1,0} parameter(3)
  %constant.21108 = s32[] constant(0), metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %broadcast.2202 = s32[8,64]{1,0} broadcast(s32[] %constant.21108), dimensions={}, metadata={op_type="ne" op_name="pmap(_multi_device_update_fn)/ne" source_file="/usr/local/lib/python3.8/dist-packages/trax/models/rnn.py" source_line=205}
  %compare.2791 = pred[8,64]{1,0} compare(s32[8,64]{1,0} %param_3.1249, s32[8,64]{1,0} %broadcast.2202), direction=NE, metadata={op_type="ne" op_name="pmap(_multi_device_update_fn)/ne" source_file="/usr/local/lib/python3.8/dist-packages/trax/models/rnn.py" source_line=205}
  %convert.74 = f32[8,64]{1,0} convert(pred[8,64]{1,0} %compare.2791), metadata={op_type="convert_element_type" op_name="pmap(_multi_device_update_fn)/convert_element_type[ new_dtype=float32\n                                                    weak_type=False ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/models/rnn.py" source_line=209}
  %constant.21110 = f32[] constant(0)
  %broadcast.2201 = f32[8,64]{1,0} broadcast(f32[] %constant.21110), dimensions={}, metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/jit(jvp(_where))/broadcast_in_dim[ broadcast_dimensions=(  )\n                                                                 shape=(8, 1, 64, 64) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/attention.py" source_line=283}
  %compare.2790 = pred[8,64]{1,0} compare(f32[8,64]{1,0} %convert.74, f32[8,64]{1,0} %broadcast.2201), direction=NE, metadata={op_type="ne" op_name="pmap(_multi_device_update_fn)/jit(jvp(_where))/ne" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/attention.py" source_line=283}
  %broadcast.2200 = pred[8,1,64,64]{3,2,1,0} broadcast(pred[8,64]{1,0} %compare.2790), dimensions={0,3}, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/models/rnn.py" source_line=209}
  %param_0.987 = f32[8,1,64,64]{3,2,1,0} parameter(0)
  %param_2.1506 = f32[8,1,64]{2,1,0} parameter(2)
  %reshape.3274 = f32[8,64]{1,0} reshape(f32[8,1,64]{2,1,0} %param_2.1506), metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(1, 3) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=94}
  %broadcast.2198 = f32[8,1,64,64]{3,2,1,0} broadcast(f32[8,64]{1,0} %reshape.3274), dimensions={0,2}, metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/broadcast_in_dim[ broadcast_dimensions=(0, 1, 2)\n                                                shape=(8, 1, 64, 64) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=94}
  %param_1.1700 = f32[8,1,64,64]{3,2,1,0} parameter(1)
  %multiply.1944 = f32[8,1,64,64]{3,2,1,0} multiply(f32[8,1,64,64]{3,2,1,0} %broadcast.2198, f32[8,1,64,64]{3,2,1,0} %param_1.1700), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=94}
  %add.4306 = f32[8,1,64,64]{3,2,1,0} add(f32[8,1,64,64]{3,2,1,0} %param_0.987, f32[8,1,64,64]{3,2,1,0} %multiply.1944), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=238}
  %broadcast.2199 = f32[8,1,64,64]{3,2,1,0} broadcast(f32[] %constant.21110), dimensions={}, metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/broadcast_in_dim[ broadcast_dimensions=(  )\n                                                shape=(8, 1, 64, 64) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/attention.py" source_line=292}
  %select.2679 = f32[8,1,64,64]{3,2,1,0} select(pred[8,1,64,64]{3,2,1,0} %broadcast.2200, f32[8,1,64,64]{3,2,1,0} %add.4306, f32[8,1,64,64]{3,2,1,0} %broadcast.2199), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/jit(transpose(jvp(_where)))/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/attention.py" source_line=283}
  %constant.21107 = f32[] constant(0.03125)
  %broadcast.2197 = f32[8,1,64,64]{3,2,1,0} broadcast(f32[] %constant.21107), dimensions={}
  %multiply.1943 = f32[8,1,64,64]{3,2,1,0} multiply(f32[8,1,64,64]{3,2,1,0} %select.2679, f32[8,1,64,64]{3,2,1,0} %broadcast.2197), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/attention.py" source_line=281}
  ROOT %reshape.3273 = f32[8,64,64]{2,1,0} reshape(f32[8,1,64,64]{3,2,1,0} %multiply.1943)
}

%fused_computation.498 (param_0.989: s32[8,65]) -> s32[512] {
  %param_0.989 = s32[8,65]{1,0} parameter(0)
  %slice.1360 = s32[8,64]{1,0} slice(s32[8,65]{1,0} %param_0.989), slice={[0:8], [0:64]}, metadata={op_type="gather" op_name="pmap(_multi_device_update_fn)/gather[ dimension_numbers=GatherDimensionNumbers(offset_dims=(0, 1), collapsed_slice_dims=(), start_index_map=(1,))\n                                      indices_are_sorted=True\n                                      slice_sizes=(8, 64)\n                                      unique_indices=True ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/attention.py" source_line=556}
  ROOT %reshape.3275 = s32[512]{0} reshape(s32[8,64]{1,0} %slice.1360)
}

%fused_computation.499 (param_0.992: f32[8,32]) -> f32[] {
  %param_0.992 = f32[8,32]{1,0} parameter(0)
  %constant.21112 = f32[] constant(0)
  %reduce.316 = f32[] reduce(f32[8,32]{1,0} %param_0.992, f32[] %constant.21112), dimensions={0,1}, to_apply=%primitive_computation_add__1.19472, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0, 1) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %constant.21111 = f32[] constant(3.81469727e-06)
  %multiply.1945 = f32[] multiply(f32[] %reduce.316, f32[] %constant.21111), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  ROOT %sqrt.41 = f32[] sqrt(f32[] %multiply.1945), metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
}

%fused_computation.500 (param_0.994: f32[4096], param_1.1707: f32[], param_2.1511: f32[], param_3.1255: f32[], param_4.697: f32[], param_5.520: f32[4096], param_6.460: f32[], param_7.398: f32[], param_8.303: s32[]) -> f32[4096] {
  %constant.21114 = f32[] constant(1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/metrics.py" source_line=617}
  %param_8.303 = s32[] parameter(8)
  %constant.21113 = s32[] constant(1), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=113}
  %compare.2792 = pred[] compare(s32[] %param_8.303, s32[] %constant.21113), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=113}
  %param_6.460 = f32[] parameter(6)
  %param_7.398 = f32[] parameter(7)
  %select.2680 = f32[] select(pred[] %compare.2792, f32[] %param_6.460, f32[] %param_7.398), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/jit(_where)/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=112}
  %subtract.655 = f32[] subtract(f32[] %constant.21114, f32[] %select.2680), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  %broadcast.2205 = f32[4096]{0} broadcast(f32[] %subtract.655), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  %param_5.520 = f32[4096]{0} parameter(5)
  %multiply.1948 = f32[4096]{0} multiply(f32[4096]{0} %broadcast.2205, f32[4096]{0} %param_5.520), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  %param_2.1511 = f32[] parameter(2)
  %param_3.1255 = f32[] parameter(3)
  %param_4.697 = f32[] parameter(4)
  %maximum.46 = f32[] maximum(f32[] %param_3.1255, f32[] %param_4.697), metadata={op_type="max" op_name="pmap(_multi_device_update_fn)/max" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=122}
  %multiply.1947 = f32[] multiply(f32[] %param_2.1511, f32[] %maximum.46), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=122}
  %broadcast.2204 = f32[4096]{0} broadcast(f32[] %multiply.1947), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=152}
  %param_0.994 = f32[4096]{0} parameter(0)
  %param_1.1707 = f32[] parameter(1)
  %maximum.45 = f32[] maximum(f32[] %constant.21114, f32[] %param_1.1707), metadata={op_type="max" op_name="pmap(_multi_device_update_fn)/max" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %broadcast.2203 = f32[4096]{0} broadcast(f32[] %maximum.45), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=150}
  %divide.247 = f32[4096]{0} divide(f32[4096]{0} %param_0.994, f32[4096]{0} %broadcast.2203), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=150}
  %multiply.1946 = f32[4096]{0} multiply(f32[4096]{0} %broadcast.2204, f32[4096]{0} %divide.247), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=152}
  ROOT %subtract.654 = f32[4096]{0} subtract(f32[4096]{0} %multiply.1948, f32[4096]{0} %multiply.1946), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
}

%fused_computation.501 (param_0.996: f32[], param_1.1712: f32[4]) -> f32[] {
  %param_1.1712 = f32[4]{0} parameter(1)
  %constant.21117 = f32[] constant(0)
  %reduce.317 = f32[] reduce(f32[4]{0} %param_1.1712, f32[] %constant.21117), dimensions={0}, to_apply=%primitive_computation_add__1.19420, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %constant.21116 = f32[] constant(0.000244140625)
  %multiply.1949 = f32[] multiply(f32[] %reduce.317, f32[] %constant.21116), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %sqrt.42 = f32[] sqrt(f32[] %multiply.1949), metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %param_0.996 = f32[] parameter(0)
  ROOT %divide.248 = f32[] divide(f32[] %sqrt.42, f32[] %param_0.996), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
}

%fused_computation.502 (param_0.999: f32[4096], param_1.1718: f32[4096], param_2.1520: f32[]) -> f32[4096] {
  %param_1.1718 = f32[4096]{0} parameter(1)
  %constant.21119 = f32[] constant(0.0625)
  %broadcast.2206 = f32[4096]{0} broadcast(f32[] %constant.21119), dimensions={}
  %multiply.1951 = f32[4096]{0} multiply(f32[4096]{0} %param_1.1718, f32[4096]{0} %broadcast.2206), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=200}
  %param_0.999 = f32[4096]{0} parameter(0)
  %param_2.1520 = f32[] parameter(2)
  %broadcast.2209 = f32[4096]{0} broadcast(f32[] %param_2.1520), dimensions={}, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
  %add.4307 = f32[4096]{0} add(f32[4096]{0} %param_0.999, f32[4096]{0} %broadcast.2209), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=145}
  %constant.21118 = f32[] constant(-0.5), metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
  %broadcast.2207 = f32[4096]{0} broadcast(f32[] %constant.21118), dimensions={}, metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
  %power.32 = f32[4096]{0} power(f32[4096]{0} %add.4307, f32[4096]{0} %broadcast.2207), metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=145}
  ROOT %multiply.1950 = f32[4096]{0} multiply(f32[4096]{0} %multiply.1951, f32[4096]{0} %power.32), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=145}
}

%fused_computation.503 (param_0.1003: f32[4096], param_1.1724: f32[4096], param_2.1529: f32[]) -> f32[4096] {
  %constant.21122 = f32[] constant(1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/metrics.py" source_line=617}
  %param_2.1529 = f32[] parameter(2)
  %subtract.657 = f32[] subtract(f32[] %constant.21122, f32[] %param_2.1529), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=85}
  %broadcast.2213 = f32[4096]{0} broadcast(f32[] %subtract.657), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
  %param_0.1003 = f32[4096]{0} parameter(0)
  %multiply.1954 = f32[4096]{0} multiply(f32[4096]{0} %broadcast.2213, f32[4096]{0} %param_0.1003), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=143}
  %subtract.656 = f32[] subtract(f32[] %constant.21122, f32[] %subtract.657), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=124}
  %broadcast.2210 = f32[4096]{0} broadcast(f32[] %subtract.656), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=143}
  %param_1.1724 = f32[4096]{0} parameter(1)
  %constant.21121 = f32[] constant(0.0625)
  %broadcast.2211 = f32[4096]{0} broadcast(f32[] %constant.21121), dimensions={}
  %multiply.1955 = f32[4096]{0} multiply(f32[4096]{0} %param_1.1724, f32[4096]{0} %broadcast.2211), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=200}
  %multiply.1953 = f32[4096]{0} multiply(f32[4096]{0} %multiply.1955, f32[4096]{0} %multiply.1955), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=126}
  %multiply.1952 = f32[4096]{0} multiply(f32[4096]{0} %broadcast.2210, f32[4096]{0} %multiply.1953), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=143}
  ROOT %add.4308 = f32[4096]{0} add(f32[4096]{0} %multiply.1954, f32[4096]{0} %multiply.1952), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=143}
}

%fused_computation.504 (param_0.1004: f32[4096]) -> f32[4096] {
  %param_0.1004 = f32[4096]{0} parameter(0)
  %constant.21123 = f32[] constant(0.0625)
  %broadcast.2214 = f32[4096]{0} broadcast(f32[] %constant.21123), dimensions={}
  ROOT %multiply.1956 = f32[4096]{0} multiply(f32[4096]{0} %param_0.1004, f32[4096]{0} %broadcast.2214), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=200}
}

%fused_computation.505 (param_0.1008: f32[4]) -> f32[] {
  %param_0.1008 = f32[4]{0} parameter(0)
  %constant.21126 = f32[] constant(0)
  %reduce.318 = f32[] reduce(f32[4]{0} %param_0.1008, f32[] %constant.21126), dimensions={0}, to_apply=%primitive_computation_add__1.19394, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %constant.21124 = f32[] constant(0.000244140625)
  %multiply.1957 = f32[] multiply(f32[] %reduce.318, f32[] %constant.21124), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  ROOT %sqrt.43 = f32[] sqrt(f32[] %multiply.1957), metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
}

%fused_computation.507 (param_0.1013: f32[], param_1.1739: f32[2,4]) -> f32[] {
  %param_1.1739 = f32[2,4]{1,0} parameter(1)
  %constant.21132 = f32[] constant(0)
  %reduce.319 = f32[] reduce(f32[2,4]{1,0} %param_1.1739, f32[] %constant.21132), dimensions={0,1}, to_apply=%primitive_computation_add__1.19342, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0, 1) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %constant.21131 = f32[] constant(1.1920929e-07)
  %multiply.1964 = f32[] multiply(f32[] %reduce.319, f32[] %constant.21131), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %sqrt.44 = f32[] sqrt(f32[] %multiply.1964), metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %param_0.1013 = f32[] parameter(0)
  ROOT %divide.250 = f32[] divide(f32[] %sqrt.44, f32[] %param_0.1013), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
}

%fused_computation.509 (param_0.1019: f32[4096], param_1.1747: f32[]) -> f32[4096] {
  %param_0.1019 = f32[4096]{0} parameter(0)
  %param_1.1747 = f32[] parameter(1)
  %broadcast.2228 = f32[4096]{0} broadcast(f32[] %param_1.1747), dimensions={}, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
  %add.4309 = f32[4096]{0} add(f32[4096]{0} %param_0.1019, f32[4096]{0} %broadcast.2228), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
  %constant.21134 = f32[] constant(-0.5), metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
  %broadcast.2227 = f32[4096]{0} broadcast(f32[] %constant.21134), dimensions={}, metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
  ROOT %power.33 = f32[4096]{0} power(f32[4096]{0} %add.4309, f32[4096]{0} %broadcast.2227), metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
}

%fused_computation.510 (param_0.1021: f32[4096], param_1.1752: f32[4096], param_2.1552: f32[]) -> f32[4096] {
  %constant.21136 = f32[] constant(1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/metrics.py" source_line=617}
  %param_2.1552 = f32[] parameter(2)
  %subtract.661 = f32[] subtract(f32[] %constant.21136, f32[] %param_2.1552), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=85}
  %broadcast.2231 = f32[4096]{0} broadcast(f32[] %subtract.661), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
  %param_1.1752 = f32[4096]{0} parameter(1)
  %multiply.1970 = f32[4096]{0} multiply(f32[4096]{0} %broadcast.2231, f32[4096]{0} %param_1.1752), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
  %param_0.1021 = f32[4096]{0} parameter(0)
  %subtract.660 = f32[] subtract(f32[] %constant.21136, f32[] %subtract.661), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=124}
  %constant.21135 = f32[] constant(0.00048828125)
  %multiply.1971 = f32[] multiply(f32[] %subtract.660, f32[] %constant.21135)
  %broadcast.2229 = f32[4096]{0} broadcast(f32[] %multiply.1971), dimensions={}
  %multiply.1969 = f32[4096]{0} multiply(f32[4096]{0} %param_0.1021, f32[4096]{0} %broadcast.2229), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
  ROOT %add.4310 = f32[4096]{0} add(f32[4096]{0} %multiply.1970, f32[4096]{0} %multiply.1969), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
}

%fused_computation.511 (param_0.1024: f32[2048], param_1.1757: f32[], param_2.1559: f32[]) -> f32[2048] {
  %param_1.1757 = f32[] parameter(1)
  %constant.21137 = f32[] constant(0.00048828125)
  %multiply.1972 = f32[] multiply(f32[] %param_1.1757, f32[] %constant.21137), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=135}
  %broadcast.2232 = f32[2048]{0} broadcast(f32[] %multiply.1972), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  %param_0.1024 = f32[2048]{0} parameter(0)
  %param_2.1559 = f32[] parameter(2)
  %broadcast.2234 = f32[2048]{0} broadcast(f32[] %param_2.1559), dimensions={}, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  %add.4311 = f32[2048]{0} add(f32[2048]{0} %param_0.1024, f32[2048]{0} %broadcast.2234), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  %divide.251 = f32[2048]{0} divide(f32[2048]{0} %broadcast.2232, f32[2048]{0} %add.4311), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  %constant.21139 = f32[] constant(0.5), metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  %broadcast.2233 = f32[2048]{0} broadcast(f32[] %constant.21139), dimensions={}, metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  ROOT %power.34 = f32[2048]{0} power(f32[2048]{0} %divide.251, f32[2048]{0} %broadcast.2233), metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
}

%fused_computation.512 (param_0.1027: f32[2048,4], param_1.1763: f32[2048], param_2.1566: f32[]) -> f32[2048] {
  %constant.21142 = f32[] constant(1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/metrics.py" source_line=617}
  %param_2.1566 = f32[] parameter(2)
  %subtract.663 = f32[] subtract(f32[] %constant.21142, f32[] %param_2.1566), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=85}
  %broadcast.2237 = f32[2048]{0} broadcast(f32[] %subtract.663), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=131}
  %param_1.1763 = f32[2048]{0} parameter(1)
  %multiply.1974 = f32[2048]{0} multiply(f32[2048]{0} %broadcast.2237, f32[2048]{0} %param_1.1763), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=131}
  %param_0.1027 = f32[2048,4]{1,0} parameter(0)
  %constant.21141 = f32[] constant(0)
  %reduce.320 = f32[2048]{0} reduce(f32[2048,4]{1,0} %param_0.1027, f32[] %constant.21141), dimensions={1}, to_apply=%primitive_computation_add__1.19284, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(1,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=131}
  %subtract.662 = f32[] subtract(f32[] %constant.21142, f32[] %subtract.663), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=124}
  %constant.21140 = f32[] constant(0.000244140625)
  %multiply.1975 = f32[] multiply(f32[] %subtract.662, f32[] %constant.21140)
  %broadcast.2236 = f32[2048]{0} broadcast(f32[] %multiply.1975), dimensions={}
  %multiply.1973 = f32[2048]{0} multiply(f32[2048]{0} %reduce.320, f32[2048]{0} %broadcast.2236), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=131}
  ROOT %add.4312 = f32[2048]{0} add(f32[2048]{0} %multiply.1974, f32[2048]{0} %multiply.1973), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=131}
}

%fused_computation.514 (param_0.1033: f32[2,4]) -> f32[] {
  %param_0.1033 = f32[2,4]{1,0} parameter(0)
  %constant.21146 = f32[] constant(0)
  %reduce.321 = f32[] reduce(f32[2,4]{1,0} %param_0.1033, f32[] %constant.21146), dimensions={0,1}, to_apply=%primitive_computation_add__1.19268, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0, 1) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %constant.21145 = f32[] constant(1.1920929e-07)
  %multiply.1978 = f32[] multiply(f32[] %reduce.321, f32[] %constant.21145), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  ROOT %sqrt.45 = f32[] sqrt(f32[] %multiply.1978), metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
}

%fused_computation.515 (param_0.1035: f32[4096], param_1.1773: f32[], param_2.1572: f32[], param_3.1305: f32[], param_4.729: f32[], param_5.532: f32[4096], param_6.471: f32[], param_7.410: f32[], param_8.312: s32[]) -> f32[4096] {
  %constant.21149 = f32[] constant(1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/metrics.py" source_line=617}
  %param_8.312 = s32[] parameter(8)
  %constant.21147 = s32[] constant(1), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=113}
  %compare.2795 = pred[] compare(s32[] %param_8.312, s32[] %constant.21147), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=113}
  %param_6.471 = f32[] parameter(6)
  %param_7.410 = f32[] parameter(7)
  %select.2682 = f32[] select(pred[] %compare.2795, f32[] %param_6.471, f32[] %param_7.410), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/jit(_where)/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=112}
  %subtract.665 = f32[] subtract(f32[] %constant.21149, f32[] %select.2682), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  %broadcast.2242 = f32[4096]{0} broadcast(f32[] %subtract.665), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  %param_5.532 = f32[4096]{0} parameter(5)
  %multiply.1981 = f32[4096]{0} multiply(f32[4096]{0} %broadcast.2242, f32[4096]{0} %param_5.532), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  %param_2.1572 = f32[] parameter(2)
  %param_3.1305 = f32[] parameter(3)
  %param_4.729 = f32[] parameter(4)
  %maximum.50 = f32[] maximum(f32[] %param_3.1305, f32[] %param_4.729), metadata={op_type="max" op_name="pmap(_multi_device_update_fn)/max" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=122}
  %multiply.1980 = f32[] multiply(f32[] %param_2.1572, f32[] %maximum.50), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=122}
  %broadcast.2241 = f32[4096]{0} broadcast(f32[] %multiply.1980), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=152}
  %param_0.1035 = f32[4096]{0} parameter(0)
  %param_1.1773 = f32[] parameter(1)
  %maximum.49 = f32[] maximum(f32[] %constant.21149, f32[] %param_1.1773), metadata={op_type="max" op_name="pmap(_multi_device_update_fn)/max" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %broadcast.2240 = f32[4096]{0} broadcast(f32[] %maximum.49), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=150}
  %divide.252 = f32[4096]{0} divide(f32[4096]{0} %param_0.1035, f32[4096]{0} %broadcast.2240), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=150}
  %multiply.1979 = f32[4096]{0} multiply(f32[4096]{0} %broadcast.2241, f32[4096]{0} %divide.252), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=152}
  ROOT %subtract.664 = f32[4096]{0} subtract(f32[4096]{0} %multiply.1981, f32[4096]{0} %multiply.1979), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
}

%fused_computation.516 (param_0.1037: f32[], param_1.1778: f32[4]) -> f32[] {
  %param_1.1778 = f32[4]{0} parameter(1)
  %constant.21152 = f32[] constant(0)
  %reduce.322 = f32[] reduce(f32[4]{0} %param_1.1778, f32[] %constant.21152), dimensions={0}, to_apply=%primitive_computation_add__1.19216, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %constant.21150 = f32[] constant(0.000244140625)
  %multiply.1982 = f32[] multiply(f32[] %reduce.322, f32[] %constant.21150), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %sqrt.46 = f32[] sqrt(f32[] %multiply.1982), metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %param_0.1037 = f32[] parameter(0)
  ROOT %divide.253 = f32[] divide(f32[] %sqrt.46, f32[] %param_0.1037), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
}

%fused_computation.517 (param_0.1040: f32[4096], param_1.1784: f32[4096], param_2.1581: f32[]) -> f32[4096] {
  %param_1.1784 = f32[4096]{0} parameter(1)
  %constant.21154 = f32[] constant(0.0625)
  %broadcast.2244 = f32[4096]{0} broadcast(f32[] %constant.21154), dimensions={}
  %multiply.1984 = f32[4096]{0} multiply(f32[4096]{0} %param_1.1784, f32[4096]{0} %broadcast.2244), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=200}
  %param_0.1040 = f32[4096]{0} parameter(0)
  %param_2.1581 = f32[] parameter(2)
  %broadcast.2247 = f32[4096]{0} broadcast(f32[] %param_2.1581), dimensions={}, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
  %add.4313 = f32[4096]{0} add(f32[4096]{0} %param_0.1040, f32[4096]{0} %broadcast.2247), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=145}
  %constant.21153 = f32[] constant(-0.5), metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
  %broadcast.2246 = f32[4096]{0} broadcast(f32[] %constant.21153), dimensions={}, metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
  %power.35 = f32[4096]{0} power(f32[4096]{0} %add.4313, f32[4096]{0} %broadcast.2246), metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=145}
  ROOT %multiply.1983 = f32[4096]{0} multiply(f32[4096]{0} %multiply.1984, f32[4096]{0} %power.35), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=145}
}

%fused_computation.518 (param_0.1044: f32[4096], param_1.1790: f32[4096], param_2.1590: f32[]) -> f32[4096] {
  %constant.21156 = f32[] constant(1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/metrics.py" source_line=617}
  %param_2.1590 = f32[] parameter(2)
  %subtract.667 = f32[] subtract(f32[] %constant.21156, f32[] %param_2.1590), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=85}
  %broadcast.2251 = f32[4096]{0} broadcast(f32[] %subtract.667), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
  %param_0.1044 = f32[4096]{0} parameter(0)
  %multiply.1987 = f32[4096]{0} multiply(f32[4096]{0} %broadcast.2251, f32[4096]{0} %param_0.1044), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=143}
  %subtract.666 = f32[] subtract(f32[] %constant.21156, f32[] %subtract.667), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=124}
  %broadcast.2248 = f32[4096]{0} broadcast(f32[] %subtract.666), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=143}
  %param_1.1790 = f32[4096]{0} parameter(1)
  %constant.21155 = f32[] constant(0.0625)
  %broadcast.2249 = f32[4096]{0} broadcast(f32[] %constant.21155), dimensions={}
  %multiply.1988 = f32[4096]{0} multiply(f32[4096]{0} %param_1.1790, f32[4096]{0} %broadcast.2249), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=200}
  %multiply.1986 = f32[4096]{0} multiply(f32[4096]{0} %multiply.1988, f32[4096]{0} %multiply.1988), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=126}
  %multiply.1985 = f32[4096]{0} multiply(f32[4096]{0} %broadcast.2248, f32[4096]{0} %multiply.1986), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=143}
  ROOT %add.4315 = f32[4096]{0} add(f32[4096]{0} %multiply.1987, f32[4096]{0} %multiply.1985), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=143}
}

%fused_computation.519 (param_0.1045: f32[4096]) -> f32[4096] {
  %param_0.1045 = f32[4096]{0} parameter(0)
  %constant.21158 = f32[] constant(0.0625)
  %broadcast.2252 = f32[4096]{0} broadcast(f32[] %constant.21158), dimensions={}
  ROOT %multiply.1989 = f32[4096]{0} multiply(f32[4096]{0} %param_0.1045, f32[4096]{0} %broadcast.2252), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=200}
}

%fused_computation.520 (param_0.1049: f32[4]) -> f32[] {
  %param_0.1049 = f32[4]{0} parameter(0)
  %constant.21160 = f32[] constant(0)
  %reduce.323 = f32[] reduce(f32[4]{0} %param_0.1049, f32[] %constant.21160), dimensions={0}, to_apply=%primitive_computation_add__1.19190, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %constant.21159 = f32[] constant(0.000244140625)
  %multiply.1990 = f32[] multiply(f32[] %reduce.323, f32[] %constant.21159), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  ROOT %sqrt.47 = f32[] sqrt(f32[] %multiply.1990), metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
}

%fused_computation.522 (param_0.1054: f32[], param_1.1805: f32[2,4]) -> f32[] {
  %param_1.1805 = f32[2,4]{1,0} parameter(1)
  %constant.21166 = f32[] constant(0)
  %reduce.324 = f32[] reduce(f32[2,4]{1,0} %param_1.1805, f32[] %constant.21166), dimensions={0,1}, to_apply=%primitive_computation_add__1.19138, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0, 1) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %constant.21165 = f32[] constant(1.1920929e-07)
  %multiply.1997 = f32[] multiply(f32[] %reduce.324, f32[] %constant.21165), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %sqrt.48 = f32[] sqrt(f32[] %multiply.1997), metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %param_0.1054 = f32[] parameter(0)
  ROOT %divide.255 = f32[] divide(f32[] %sqrt.48, f32[] %param_0.1054), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
}

%fused_computation.524 (param_0.1060: f32[4096], param_1.1813: f32[]) -> f32[4096] {
  %param_0.1060 = f32[4096]{0} parameter(0)
  %param_1.1813 = f32[] parameter(1)
  %broadcast.2263 = f32[4096]{0} broadcast(f32[] %param_1.1813), dimensions={}, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
  %add.4316 = f32[4096]{0} add(f32[4096]{0} %param_0.1060, f32[4096]{0} %broadcast.2263), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
  %constant.21168 = f32[] constant(-0.5), metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
  %broadcast.2262 = f32[4096]{0} broadcast(f32[] %constant.21168), dimensions={}, metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
  ROOT %power.36 = f32[4096]{0} power(f32[4096]{0} %add.4316, f32[4096]{0} %broadcast.2262), metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
}

%fused_computation.525 (param_0.1062: f32[4096], param_1.1818: f32[4096], param_2.1613: f32[]) -> f32[4096] {
  %constant.21170 = f32[] constant(1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/metrics.py" source_line=617}
  %param_2.1613 = f32[] parameter(2)
  %subtract.671 = f32[] subtract(f32[] %constant.21170, f32[] %param_2.1613), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=85}
  %broadcast.2265 = f32[4096]{0} broadcast(f32[] %subtract.671), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
  %param_1.1818 = f32[4096]{0} parameter(1)
  %multiply.2003 = f32[4096]{0} multiply(f32[4096]{0} %broadcast.2265, f32[4096]{0} %param_1.1818), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
  %param_0.1062 = f32[4096]{0} parameter(0)
  %subtract.670 = f32[] subtract(f32[] %constant.21170, f32[] %subtract.671), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=124}
  %constant.21169 = f32[] constant(0.00048828125)
  %multiply.2004 = f32[] multiply(f32[] %subtract.670, f32[] %constant.21169)
  %broadcast.2264 = f32[4096]{0} broadcast(f32[] %multiply.2004), dimensions={}
  %multiply.2002 = f32[4096]{0} multiply(f32[4096]{0} %param_0.1062, f32[4096]{0} %broadcast.2264), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
  ROOT %add.4317 = f32[4096]{0} add(f32[4096]{0} %multiply.2003, f32[4096]{0} %multiply.2002), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
}

%fused_computation.526 (param_0.1065: f32[2048], param_1.1823: f32[], param_2.1620: f32[]) -> f32[2048] {
  %param_1.1823 = f32[] parameter(1)
  %constant.21171 = f32[] constant(0.00048828125)
  %multiply.2005 = f32[] multiply(f32[] %param_1.1823, f32[] %constant.21171), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=135}
  %broadcast.2266 = f32[2048]{0} broadcast(f32[] %multiply.2005), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  %param_0.1065 = f32[2048]{0} parameter(0)
  %param_2.1620 = f32[] parameter(2)
  %broadcast.2268 = f32[2048]{0} broadcast(f32[] %param_2.1620), dimensions={}, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  %add.4318 = f32[2048]{0} add(f32[2048]{0} %param_0.1065, f32[2048]{0} %broadcast.2268), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  %divide.256 = f32[2048]{0} divide(f32[2048]{0} %broadcast.2266, f32[2048]{0} %add.4318), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  %constant.21173 = f32[] constant(0.5), metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  %broadcast.2267 = f32[2048]{0} broadcast(f32[] %constant.21173), dimensions={}, metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  ROOT %power.37 = f32[2048]{0} power(f32[2048]{0} %divide.256, f32[2048]{0} %broadcast.2267), metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
}

%fused_computation.527 (param_0.1068: f32[2048,4], param_1.1829: f32[2048], param_2.1627: f32[]) -> f32[2048] {
  %constant.21176 = f32[] constant(1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/metrics.py" source_line=617}
  %param_2.1627 = f32[] parameter(2)
  %subtract.673 = f32[] subtract(f32[] %constant.21176, f32[] %param_2.1627), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=85}
  %broadcast.2270 = f32[2048]{0} broadcast(f32[] %subtract.673), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=131}
  %param_1.1829 = f32[2048]{0} parameter(1)
  %multiply.2007 = f32[2048]{0} multiply(f32[2048]{0} %broadcast.2270, f32[2048]{0} %param_1.1829), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=131}
  %param_0.1068 = f32[2048,4]{1,0} parameter(0)
  %constant.21175 = f32[] constant(0)
  %reduce.325 = f32[2048]{0} reduce(f32[2048,4]{1,0} %param_0.1068, f32[] %constant.21175), dimensions={1}, to_apply=%primitive_computation_add__1.19080, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(1,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=131}
  %subtract.672 = f32[] subtract(f32[] %constant.21176, f32[] %subtract.673), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=124}
  %constant.21174 = f32[] constant(0.000244140625)
  %multiply.2008 = f32[] multiply(f32[] %subtract.672, f32[] %constant.21174)
  %broadcast.2269 = f32[2048]{0} broadcast(f32[] %multiply.2008), dimensions={}
  %multiply.2006 = f32[2048]{0} multiply(f32[2048]{0} %reduce.325, f32[2048]{0} %broadcast.2269), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=131}
  ROOT %add.4319 = f32[2048]{0} add(f32[2048]{0} %multiply.2007, f32[2048]{0} %multiply.2006), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=131}
}

%fused_computation.529 (param_0.1074: f32[2,4]) -> f32[] {
  %param_0.1074 = f32[2,4]{1,0} parameter(0)
  %constant.21180 = f32[] constant(0)
  %reduce.326 = f32[] reduce(f32[2,4]{1,0} %param_0.1074, f32[] %constant.21180), dimensions={0,1}, to_apply=%primitive_computation_add__1.19064, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0, 1) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %constant.21179 = f32[] constant(1.1920929e-07)
  %multiply.2011 = f32[] multiply(f32[] %reduce.326, f32[] %constant.21179), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  ROOT %sqrt.49 = f32[] sqrt(f32[] %multiply.2011), metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
}

%fused_computation.530 (param_0.1076: f32[4096], param_1.1839: f32[], param_2.1633: f32[], param_3.1355: f32[], param_4.761: f32[], param_5.544: f32[4096], param_6.482: f32[], param_7.422: f32[], param_8.321: s32[]) -> f32[4096] {
  %constant.21182 = f32[] constant(1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/metrics.py" source_line=617}
  %param_8.321 = s32[] parameter(8)
  %constant.21181 = s32[] constant(1), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=113}
  %compare.2797 = pred[] compare(s32[] %param_8.321, s32[] %constant.21181), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=113}
  %param_6.482 = f32[] parameter(6)
  %param_7.422 = f32[] parameter(7)
  %select.2685 = f32[] select(pred[] %compare.2797, f32[] %param_6.482, f32[] %param_7.422), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/jit(_where)/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=112}
  %subtract.675 = f32[] subtract(f32[] %constant.21182, f32[] %select.2685), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  %broadcast.2274 = f32[4096]{0} broadcast(f32[] %subtract.675), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  %param_5.544 = f32[4096]{0} parameter(5)
  %multiply.2014 = f32[4096]{0} multiply(f32[4096]{0} %broadcast.2274, f32[4096]{0} %param_5.544), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  %param_2.1633 = f32[] parameter(2)
  %param_3.1355 = f32[] parameter(3)
  %param_4.761 = f32[] parameter(4)
  %maximum.54 = f32[] maximum(f32[] %param_3.1355, f32[] %param_4.761), metadata={op_type="max" op_name="pmap(_multi_device_update_fn)/max" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=122}
  %multiply.2013 = f32[] multiply(f32[] %param_2.1633, f32[] %maximum.54), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=122}
  %broadcast.2273 = f32[4096]{0} broadcast(f32[] %multiply.2013), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=152}
  %param_0.1076 = f32[4096]{0} parameter(0)
  %param_1.1839 = f32[] parameter(1)
  %maximum.53 = f32[] maximum(f32[] %constant.21182, f32[] %param_1.1839), metadata={op_type="max" op_name="pmap(_multi_device_update_fn)/max" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %broadcast.2272 = f32[4096]{0} broadcast(f32[] %maximum.53), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=150}
  %divide.257 = f32[4096]{0} divide(f32[4096]{0} %param_0.1076, f32[4096]{0} %broadcast.2272), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=150}
  %multiply.2012 = f32[4096]{0} multiply(f32[4096]{0} %broadcast.2273, f32[4096]{0} %divide.257), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=152}
  ROOT %subtract.674 = f32[4096]{0} subtract(f32[4096]{0} %multiply.2014, f32[4096]{0} %multiply.2012), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
}

%fused_computation.531 (param_0.1078: f32[], param_1.1844: f32[4]) -> f32[] {
  %param_1.1844 = f32[4]{0} parameter(1)
  %constant.21185 = f32[] constant(0)
  %reduce.327 = f32[] reduce(f32[4]{0} %param_1.1844, f32[] %constant.21185), dimensions={0}, to_apply=%primitive_computation_add__1.19012, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %constant.21184 = f32[] constant(0.000244140625)
  %multiply.2015 = f32[] multiply(f32[] %reduce.327, f32[] %constant.21184), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %sqrt.50 = f32[] sqrt(f32[] %multiply.2015), metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %param_0.1078 = f32[] parameter(0)
  ROOT %divide.258 = f32[] divide(f32[] %sqrt.50, f32[] %param_0.1078), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
}

%fused_computation.532 (param_0.1081: f32[4096], param_1.1850: f32[4096], param_2.1642: f32[]) -> f32[4096] {
  %param_1.1850 = f32[4096]{0} parameter(1)
  %constant.21188 = f32[] constant(0.0625)
  %broadcast.2275 = f32[4096]{0} broadcast(f32[] %constant.21188), dimensions={}
  %multiply.2017 = f32[4096]{0} multiply(f32[4096]{0} %param_1.1850, f32[4096]{0} %broadcast.2275), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=200}
  %param_0.1081 = f32[4096]{0} parameter(0)
  %param_2.1642 = f32[] parameter(2)
  %broadcast.2277 = f32[4096]{0} broadcast(f32[] %param_2.1642), dimensions={}, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
  %add.4320 = f32[4096]{0} add(f32[4096]{0} %param_0.1081, f32[4096]{0} %broadcast.2277), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=145}
  %constant.21186 = f32[] constant(-0.5), metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
  %broadcast.2276 = f32[4096]{0} broadcast(f32[] %constant.21186), dimensions={}, metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
  %power.38 = f32[4096]{0} power(f32[4096]{0} %add.4320, f32[4096]{0} %broadcast.2276), metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=145}
  ROOT %multiply.2016 = f32[4096]{0} multiply(f32[4096]{0} %multiply.2017, f32[4096]{0} %power.38), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=145}
}

%fused_computation.533 (param_0.1085: f32[4096], param_1.1856: f32[4096], param_2.1651: f32[]) -> f32[4096] {
  %constant.21190 = f32[] constant(1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/metrics.py" source_line=617}
  %param_2.1651 = f32[] parameter(2)
  %subtract.677 = f32[] subtract(f32[] %constant.21190, f32[] %param_2.1651), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=85}
  %broadcast.2280 = f32[4096]{0} broadcast(f32[] %subtract.677), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
  %param_0.1085 = f32[4096]{0} parameter(0)
  %multiply.2020 = f32[4096]{0} multiply(f32[4096]{0} %broadcast.2280, f32[4096]{0} %param_0.1085), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=143}
  %subtract.676 = f32[] subtract(f32[] %constant.21190, f32[] %subtract.677), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=124}
  %broadcast.2278 = f32[4096]{0} broadcast(f32[] %subtract.676), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=143}
  %param_1.1856 = f32[4096]{0} parameter(1)
  %constant.21189 = f32[] constant(0.0625)
  %broadcast.2279 = f32[4096]{0} broadcast(f32[] %constant.21189), dimensions={}
  %multiply.2021 = f32[4096]{0} multiply(f32[4096]{0} %param_1.1856, f32[4096]{0} %broadcast.2279), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=200}
  %multiply.2019 = f32[4096]{0} multiply(f32[4096]{0} %multiply.2021, f32[4096]{0} %multiply.2021), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=126}
  %multiply.2018 = f32[4096]{0} multiply(f32[4096]{0} %broadcast.2278, f32[4096]{0} %multiply.2019), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=143}
  ROOT %add.4321 = f32[4096]{0} add(f32[4096]{0} %multiply.2020, f32[4096]{0} %multiply.2018), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=143}
}

%fused_computation.534 (param_0.1086: f32[4096]) -> f32[4096] {
  %param_0.1086 = f32[4096]{0} parameter(0)
  %constant.21191 = f32[] constant(0.0625)
  %broadcast.2281 = f32[4096]{0} broadcast(f32[] %constant.21191), dimensions={}
  ROOT %multiply.2022 = f32[4096]{0} multiply(f32[4096]{0} %param_0.1086, f32[4096]{0} %broadcast.2281), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=200}
}

%fused_computation.535 (param_0.1090: f32[4]) -> f32[] {
  %param_0.1090 = f32[4]{0} parameter(0)
  %constant.21194 = f32[] constant(0)
  %reduce.328 = f32[] reduce(f32[4]{0} %param_0.1090, f32[] %constant.21194), dimensions={0}, to_apply=%primitive_computation_add__1.18986, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %constant.21192 = f32[] constant(0.000244140625)
  %multiply.2023 = f32[] multiply(f32[] %reduce.328, f32[] %constant.21192), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  ROOT %sqrt.51 = f32[] sqrt(f32[] %multiply.2023), metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
}

%fused_computation.537 (param_0.1095: f32[], param_1.1871: f32[2,4]) -> f32[] {
  %param_1.1871 = f32[2,4]{1,0} parameter(1)
  %constant.21200 = f32[] constant(0)
  %reduce.329 = f32[] reduce(f32[2,4]{1,0} %param_1.1871, f32[] %constant.21200), dimensions={0,1}, to_apply=%primitive_computation_add__1.18934, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0, 1) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %constant.21199 = f32[] constant(1.1920929e-07)
  %multiply.2030 = f32[] multiply(f32[] %reduce.329, f32[] %constant.21199), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %sqrt.52 = f32[] sqrt(f32[] %multiply.2030), metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %param_0.1095 = f32[] parameter(0)
  ROOT %divide.260 = f32[] divide(f32[] %sqrt.52, f32[] %param_0.1095), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
}

%fused_computation.539 (param_0.1101: f32[4096], param_1.1879: f32[]) -> f32[4096] {
  %param_0.1101 = f32[4096]{0} parameter(0)
  %param_1.1879 = f32[] parameter(1)
  %broadcast.2294 = f32[4096]{0} broadcast(f32[] %param_1.1879), dimensions={}, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
  %add.4322 = f32[4096]{0} add(f32[4096]{0} %param_0.1101, f32[4096]{0} %broadcast.2294), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
  %constant.21202 = f32[] constant(-0.5), metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
  %broadcast.2293 = f32[4096]{0} broadcast(f32[] %constant.21202), dimensions={}, metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
  ROOT %power.39 = f32[4096]{0} power(f32[4096]{0} %add.4322, f32[4096]{0} %broadcast.2293), metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
}

%fused_computation.540 (param_0.1103: f32[4096], param_1.1884: f32[4096], param_2.1674: f32[]) -> f32[4096] {
  %constant.21205 = f32[] constant(1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/metrics.py" source_line=617}
  %param_2.1674 = f32[] parameter(2)
  %subtract.681 = f32[] subtract(f32[] %constant.21205, f32[] %param_2.1674), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=85}
  %broadcast.2296 = f32[4096]{0} broadcast(f32[] %subtract.681), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
  %param_1.1884 = f32[4096]{0} parameter(1)
  %multiply.2036 = f32[4096]{0} multiply(f32[4096]{0} %broadcast.2296, f32[4096]{0} %param_1.1884), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
  %param_0.1103 = f32[4096]{0} parameter(0)
  %subtract.680 = f32[] subtract(f32[] %constant.21205, f32[] %subtract.681), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=124}
  %constant.21204 = f32[] constant(0.00048828125)
  %multiply.2037 = f32[] multiply(f32[] %subtract.680, f32[] %constant.21204)
  %broadcast.2295 = f32[4096]{0} broadcast(f32[] %multiply.2037), dimensions={}
  %multiply.2035 = f32[4096]{0} multiply(f32[4096]{0} %param_0.1103, f32[4096]{0} %broadcast.2295), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
  ROOT %add.4324 = f32[4096]{0} add(f32[4096]{0} %multiply.2036, f32[4096]{0} %multiply.2035), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
}

%fused_computation.541 (param_0.1106: f32[2048], param_1.1889: f32[], param_2.1681: f32[]) -> f32[2048] {
  %param_1.1889 = f32[] parameter(1)
  %constant.21206 = f32[] constant(0.00048828125)
  %multiply.2038 = f32[] multiply(f32[] %param_1.1889, f32[] %constant.21206), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=135}
  %broadcast.2297 = f32[2048]{0} broadcast(f32[] %multiply.2038), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  %param_0.1106 = f32[2048]{0} parameter(0)
  %param_2.1681 = f32[] parameter(2)
  %broadcast.2299 = f32[2048]{0} broadcast(f32[] %param_2.1681), dimensions={}, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  %add.4325 = f32[2048]{0} add(f32[2048]{0} %param_0.1106, f32[2048]{0} %broadcast.2299), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  %divide.261 = f32[2048]{0} divide(f32[2048]{0} %broadcast.2297, f32[2048]{0} %add.4325), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  %constant.21207 = f32[] constant(0.5), metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  %broadcast.2298 = f32[2048]{0} broadcast(f32[] %constant.21207), dimensions={}, metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  ROOT %power.40 = f32[2048]{0} power(f32[2048]{0} %divide.261, f32[2048]{0} %broadcast.2298), metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
}

%fused_computation.542 (param_0.1109: f32[2048,4], param_1.1895: f32[2048], param_2.1688: f32[]) -> f32[2048] {
  %constant.21211 = f32[] constant(1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/metrics.py" source_line=617}
  %param_2.1688 = f32[] parameter(2)
  %subtract.683 = f32[] subtract(f32[] %constant.21211, f32[] %param_2.1688), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=85}
  %broadcast.2301 = f32[2048]{0} broadcast(f32[] %subtract.683), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=131}
  %param_1.1895 = f32[2048]{0} parameter(1)
  %multiply.2040 = f32[2048]{0} multiply(f32[2048]{0} %broadcast.2301, f32[2048]{0} %param_1.1895), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=131}
  %param_0.1109 = f32[2048,4]{1,0} parameter(0)
  %constant.21210 = f32[] constant(0)
  %reduce.330 = f32[2048]{0} reduce(f32[2048,4]{1,0} %param_0.1109, f32[] %constant.21210), dimensions={1}, to_apply=%primitive_computation_add__1.18876, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(1,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=131}
  %subtract.682 = f32[] subtract(f32[] %constant.21211, f32[] %subtract.683), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=124}
  %constant.21209 = f32[] constant(0.000244140625)
  %multiply.2041 = f32[] multiply(f32[] %subtract.682, f32[] %constant.21209)
  %broadcast.2300 = f32[2048]{0} broadcast(f32[] %multiply.2041), dimensions={}
  %multiply.2039 = f32[2048]{0} multiply(f32[2048]{0} %reduce.330, f32[2048]{0} %broadcast.2300), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=131}
  ROOT %add.4326 = f32[2048]{0} add(f32[2048]{0} %multiply.2040, f32[2048]{0} %multiply.2039), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=131}
}

%fused_computation.544 (param_0.1115: f32[2,4]) -> f32[] {
  %param_0.1115 = f32[2,4]{1,0} parameter(0)
  %constant.21214 = f32[] constant(0)
  %reduce.331 = f32[] reduce(f32[2,4]{1,0} %param_0.1115, f32[] %constant.21214), dimensions={0,1}, to_apply=%primitive_computation_add__1.18860, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0, 1) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %constant.21213 = f32[] constant(1.1920929e-07)
  %multiply.2044 = f32[] multiply(f32[] %reduce.331, f32[] %constant.21213), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  ROOT %sqrt.53 = f32[] sqrt(f32[] %multiply.2044), metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
}

%fused_computation.545 (param_0.1117: f32[4096], param_1.1905: f32[], param_2.1694: f32[], param_3.1405: f32[], param_4.793: f32[], param_5.556: f32[4096], param_6.493: f32[], param_7.434: f32[], param_8.330: s32[]) -> f32[4096] {
  %constant.21217 = f32[] constant(1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/metrics.py" source_line=617}
  %param_8.330 = s32[] parameter(8)
  %constant.21215 = s32[] constant(1), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=113}
  %compare.2799 = pred[] compare(s32[] %param_8.330, s32[] %constant.21215), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=113}
  %param_6.493 = f32[] parameter(6)
  %param_7.434 = f32[] parameter(7)
  %select.2687 = f32[] select(pred[] %compare.2799, f32[] %param_6.493, f32[] %param_7.434), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/jit(_where)/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=112}
  %subtract.686 = f32[] subtract(f32[] %constant.21217, f32[] %select.2687), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  %broadcast.2305 = f32[4096]{0} broadcast(f32[] %subtract.686), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  %param_5.556 = f32[4096]{0} parameter(5)
  %multiply.2047 = f32[4096]{0} multiply(f32[4096]{0} %broadcast.2305, f32[4096]{0} %param_5.556), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  %param_2.1694 = f32[] parameter(2)
  %param_3.1405 = f32[] parameter(3)
  %param_4.793 = f32[] parameter(4)
  %maximum.58 = f32[] maximum(f32[] %param_3.1405, f32[] %param_4.793), metadata={op_type="max" op_name="pmap(_multi_device_update_fn)/max" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=122}
  %multiply.2046 = f32[] multiply(f32[] %param_2.1694, f32[] %maximum.58), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=122}
  %broadcast.2304 = f32[4096]{0} broadcast(f32[] %multiply.2046), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=152}
  %param_0.1117 = f32[4096]{0} parameter(0)
  %param_1.1905 = f32[] parameter(1)
  %maximum.57 = f32[] maximum(f32[] %constant.21217, f32[] %param_1.1905), metadata={op_type="max" op_name="pmap(_multi_device_update_fn)/max" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %broadcast.2303 = f32[4096]{0} broadcast(f32[] %maximum.57), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=150}
  %divide.262 = f32[4096]{0} divide(f32[4096]{0} %param_0.1117, f32[4096]{0} %broadcast.2303), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=150}
  %multiply.2045 = f32[4096]{0} multiply(f32[4096]{0} %broadcast.2304, f32[4096]{0} %divide.262), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=152}
  ROOT %subtract.685 = f32[4096]{0} subtract(f32[4096]{0} %multiply.2047, f32[4096]{0} %multiply.2045), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
}

%fused_computation.546 (param_0.1119: f32[], param_1.1910: f32[4]) -> f32[] {
  %param_1.1910 = f32[4]{0} parameter(1)
  %constant.21219 = f32[] constant(0)
  %reduce.332 = f32[] reduce(f32[4]{0} %param_1.1910, f32[] %constant.21219), dimensions={0}, to_apply=%primitive_computation_add__1.18808, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %constant.21218 = f32[] constant(0.000244140625)
  %multiply.2048 = f32[] multiply(f32[] %reduce.332, f32[] %constant.21218), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %sqrt.54 = f32[] sqrt(f32[] %multiply.2048), metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %param_0.1119 = f32[] parameter(0)
  ROOT %divide.263 = f32[] divide(f32[] %sqrt.54, f32[] %param_0.1119), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
}

%fused_computation.547 (param_0.1122: f32[4096], param_1.1916: f32[4096], param_2.1703: f32[]) -> f32[4096] {
  %param_1.1916 = f32[4096]{0} parameter(1)
  %constant.21221 = f32[] constant(0.0625)
  %broadcast.2306 = f32[4096]{0} broadcast(f32[] %constant.21221), dimensions={}
  %multiply.2050 = f32[4096]{0} multiply(f32[4096]{0} %param_1.1916, f32[4096]{0} %broadcast.2306), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=200}
  %param_0.1122 = f32[4096]{0} parameter(0)
  %param_2.1703 = f32[] parameter(2)
  %broadcast.2308 = f32[4096]{0} broadcast(f32[] %param_2.1703), dimensions={}, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
  %add.4327 = f32[4096]{0} add(f32[4096]{0} %param_0.1122, f32[4096]{0} %broadcast.2308), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=145}
  %constant.21220 = f32[] constant(-0.5), metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
  %broadcast.2307 = f32[4096]{0} broadcast(f32[] %constant.21220), dimensions={}, metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
  %power.41 = f32[4096]{0} power(f32[4096]{0} %add.4327, f32[4096]{0} %broadcast.2307), metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=145}
  ROOT %multiply.2049 = f32[4096]{0} multiply(f32[4096]{0} %multiply.2050, f32[4096]{0} %power.41), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=145}
}

%fused_computation.548 (param_0.1126: f32[4096], param_1.1923: f32[4096], param_2.1712: f32[]) -> f32[4096] {
  %constant.21224 = f32[] constant(1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/metrics.py" source_line=617}
  %param_2.1712 = f32[] parameter(2)
  %subtract.688 = f32[] subtract(f32[] %constant.21224, f32[] %param_2.1712), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=85}
  %broadcast.2311 = f32[4096]{0} broadcast(f32[] %subtract.688), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
  %param_0.1126 = f32[4096]{0} parameter(0)
  %multiply.2053 = f32[4096]{0} multiply(f32[4096]{0} %broadcast.2311, f32[4096]{0} %param_0.1126), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=143}
  %subtract.687 = f32[] subtract(f32[] %constant.21224, f32[] %subtract.688), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=124}
  %broadcast.2309 = f32[4096]{0} broadcast(f32[] %subtract.687), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=143}
  %param_1.1923 = f32[4096]{0} parameter(1)
  %constant.21223 = f32[] constant(0.0625)
  %broadcast.2310 = f32[4096]{0} broadcast(f32[] %constant.21223), dimensions={}
  %multiply.2054 = f32[4096]{0} multiply(f32[4096]{0} %param_1.1923, f32[4096]{0} %broadcast.2310), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=200}
  %multiply.2052 = f32[4096]{0} multiply(f32[4096]{0} %multiply.2054, f32[4096]{0} %multiply.2054), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=126}
  %multiply.2051 = f32[4096]{0} multiply(f32[4096]{0} %broadcast.2309, f32[4096]{0} %multiply.2052), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=143}
  ROOT %add.4328 = f32[4096]{0} add(f32[4096]{0} %multiply.2053, f32[4096]{0} %multiply.2051), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=143}
}

%fused_computation.549 (param_0.1127: f32[4096]) -> f32[4096] {
  %param_0.1127 = f32[4096]{0} parameter(0)
  %constant.21225 = f32[] constant(0.0625)
  %broadcast.2312 = f32[4096]{0} broadcast(f32[] %constant.21225), dimensions={}
  ROOT %multiply.2055 = f32[4096]{0} multiply(f32[4096]{0} %param_0.1127, f32[4096]{0} %broadcast.2312), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=200}
}

%fused_computation.550 (param_0.1131: f32[4]) -> f32[] {
  %param_0.1131 = f32[4]{0} parameter(0)
  %constant.21228 = f32[] constant(0)
  %reduce.333 = f32[] reduce(f32[4]{0} %param_0.1131, f32[] %constant.21228), dimensions={0}, to_apply=%primitive_computation_add__1.18782, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %constant.21227 = f32[] constant(0.000244140625)
  %multiply.2056 = f32[] multiply(f32[] %reduce.333, f32[] %constant.21227), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  ROOT %sqrt.55 = f32[] sqrt(f32[] %multiply.2056), metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
}

%fused_computation.552 (param_0.1136: f32[], param_1.1938: f32[2,4]) -> f32[] {
  %param_1.1938 = f32[2,4]{1,0} parameter(1)
  %constant.21234 = f32[] constant(0)
  %reduce.334 = f32[] reduce(f32[2,4]{1,0} %param_1.1938, f32[] %constant.21234), dimensions={0,1}, to_apply=%primitive_computation_add__1.18730, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0, 1) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %constant.21233 = f32[] constant(1.1920929e-07)
  %multiply.2063 = f32[] multiply(f32[] %reduce.334, f32[] %constant.21233), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %sqrt.56 = f32[] sqrt(f32[] %multiply.2063), metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %param_0.1136 = f32[] parameter(0)
  ROOT %divide.265 = f32[] divide(f32[] %sqrt.56, f32[] %param_0.1136), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
}

%fused_computation.554 (param_0.1142: f32[4096], param_1.1945: f32[]) -> f32[4096] {
  %param_0.1142 = f32[4096]{0} parameter(0)
  %param_1.1945 = f32[] parameter(1)
  %broadcast.2323 = f32[4096]{0} broadcast(f32[] %param_1.1945), dimensions={}, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
  %add.4329 = f32[4096]{0} add(f32[4096]{0} %param_0.1142, f32[4096]{0} %broadcast.2323), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
  %constant.21237 = f32[] constant(-0.5), metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
  %broadcast.2322 = f32[4096]{0} broadcast(f32[] %constant.21237), dimensions={}, metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
  ROOT %power.42 = f32[4096]{0} power(f32[4096]{0} %add.4329, f32[4096]{0} %broadcast.2322), metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
}

%fused_computation.555 (param_0.1144: f32[4096], param_1.1949: f32[4096], param_2.1735: f32[]) -> f32[4096] {
  %constant.21239 = f32[] constant(1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/metrics.py" source_line=617}
  %param_2.1735 = f32[] parameter(2)
  %subtract.692 = f32[] subtract(f32[] %constant.21239, f32[] %param_2.1735), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=85}
  %broadcast.2325 = f32[4096]{0} broadcast(f32[] %subtract.692), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
  %param_1.1949 = f32[4096]{0} parameter(1)
  %multiply.2070 = f32[4096]{0} multiply(f32[4096]{0} %broadcast.2325, f32[4096]{0} %param_1.1949), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
  %param_0.1144 = f32[4096]{0} parameter(0)
  %subtract.691 = f32[] subtract(f32[] %constant.21239, f32[] %subtract.692), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=124}
  %constant.21238 = f32[] constant(0.00048828125)
  %multiply.2069 = f32[] multiply(f32[] %subtract.691, f32[] %constant.21238)
  %broadcast.2324 = f32[4096]{0} broadcast(f32[] %multiply.2069), dimensions={}
  %multiply.2068 = f32[4096]{0} multiply(f32[4096]{0} %param_0.1144, f32[4096]{0} %broadcast.2324), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
  ROOT %add.4330 = f32[4096]{0} add(f32[4096]{0} %multiply.2070, f32[4096]{0} %multiply.2068), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
}

%fused_computation.556 (param_0.1147: f32[2048], param_1.1954: f32[], param_2.1739: f32[]) -> f32[2048] {
  %param_2.1739 = f32[] parameter(2)
  %constant.21241 = f32[] constant(0.00048828125)
  %multiply.2071 = f32[] multiply(f32[] %param_2.1739, f32[] %constant.21241), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=135}
  %broadcast.2328 = f32[2048]{0} broadcast(f32[] %multiply.2071), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  %param_0.1147 = f32[2048]{0} parameter(0)
  %param_1.1954 = f32[] parameter(1)
  %broadcast.2327 = f32[2048]{0} broadcast(f32[] %param_1.1954), dimensions={}, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  %add.4331 = f32[2048]{0} add(f32[2048]{0} %param_0.1147, f32[2048]{0} %broadcast.2327), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  %divide.266 = f32[2048]{0} divide(f32[2048]{0} %broadcast.2328, f32[2048]{0} %add.4331), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  %constant.21242 = f32[] constant(0.5), metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  %broadcast.2326 = f32[2048]{0} broadcast(f32[] %constant.21242), dimensions={}, metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  ROOT %power.43 = f32[2048]{0} power(f32[2048]{0} %divide.266, f32[2048]{0} %broadcast.2326), metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
}

%fused_computation.557 (param_0.1150: f32[2048,4], param_1.1960: f32[2048], param_2.1747: f32[]) -> f32[2048] {
  %constant.21246 = f32[] constant(1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/metrics.py" source_line=617}
  %param_2.1747 = f32[] parameter(2)
  %subtract.695 = f32[] subtract(f32[] %constant.21246, f32[] %param_2.1747), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=85}
  %broadcast.2330 = f32[2048]{0} broadcast(f32[] %subtract.695), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=131}
  %param_1.1960 = f32[2048]{0} parameter(1)
  %multiply.2074 = f32[2048]{0} multiply(f32[2048]{0} %broadcast.2330, f32[2048]{0} %param_1.1960), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=131}
  %param_0.1150 = f32[2048,4]{1,0} parameter(0)
  %constant.21244 = f32[] constant(0)
  %reduce.335 = f32[2048]{0} reduce(f32[2048,4]{1,0} %param_0.1150, f32[] %constant.21244), dimensions={1}, to_apply=%primitive_computation_add__1.18672, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(1,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=131}
  %subtract.694 = f32[] subtract(f32[] %constant.21246, f32[] %subtract.695), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=124}
  %constant.21243 = f32[] constant(0.000244140625)
  %multiply.2073 = f32[] multiply(f32[] %subtract.694, f32[] %constant.21243)
  %broadcast.2329 = f32[2048]{0} broadcast(f32[] %multiply.2073), dimensions={}
  %multiply.2072 = f32[2048]{0} multiply(f32[2048]{0} %reduce.335, f32[2048]{0} %broadcast.2329), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=131}
  ROOT %add.4333 = f32[2048]{0} add(f32[2048]{0} %multiply.2074, f32[2048]{0} %multiply.2072), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=131}
}

%fused_computation.559 (param_0.1155: f32[2,4]) -> f32[] {
  %param_0.1155 = f32[2,4]{1,0} parameter(0)
  %constant.21249 = f32[] constant(0)
  %reduce.336 = f32[] reduce(f32[2,4]{1,0} %param_0.1155, f32[] %constant.21249), dimensions={0,1}, to_apply=%primitive_computation_add__1.18656, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0, 1) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %constant.21248 = f32[] constant(1.1920929e-07)
  %multiply.2077 = f32[] multiply(f32[] %reduce.336, f32[] %constant.21248), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  ROOT %sqrt.57 = f32[] sqrt(f32[] %multiply.2077), metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
}

%fused_computation.561 (param_0.1160: f32[], param_1.1974: f32[32,1]) -> f32[] {
  %param_1.1974 = f32[32,1]{1,0} parameter(1)
  %constant.21255 = f32[] constant(0)
  %reduce.337 = f32[] reduce(f32[32,1]{1,0} %param_1.1974, f32[] %constant.21255), dimensions={0,1}, to_apply=%primitive_computation_add__1.18604, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0, 1) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %constant.21254 = f32[] constant(3.05175796e-08)
  %multiply.2084 = f32[] multiply(f32[] %reduce.337, f32[] %constant.21254), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %sqrt.58 = f32[] sqrt(f32[] %multiply.2084), metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %param_0.1160 = f32[] parameter(0)
  ROOT %divide.268 = f32[] divide(f32[] %sqrt.58, f32[] %param_0.1160), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
}

%fused_computation.563 (param_0.1165: f32[1024], param_1.1981: f32[]) -> f32[1024] {
  %param_0.1165 = f32[1024]{0} parameter(0)
  %param_1.1981 = f32[] parameter(1)
  %broadcast.2343 = f32[1024]{0} broadcast(f32[] %param_1.1981), dimensions={}, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
  %add.4334 = f32[1024]{0} add(f32[1024]{0} %param_0.1165, f32[1024]{0} %broadcast.2343), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
  %constant.21257 = f32[] constant(-0.5), metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
  %broadcast.2341 = f32[1024]{0} broadcast(f32[] %constant.21257), dimensions={}, metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
  ROOT %power.44 = f32[1024]{0} power(f32[1024]{0} %add.4334, f32[1024]{0} %broadcast.2341), metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
}

%fused_computation.564 (param_0.1167: f32[1,1024], param_1.1986: f32[1024], param_2.1767: f32[]) -> f32[1024] {
  %constant.21260 = f32[] constant(1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/metrics.py" source_line=617}
  %param_2.1767 = f32[] parameter(2)
  %subtract.699 = f32[] subtract(f32[] %constant.21260, f32[] %param_2.1767), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=85}
  %broadcast.2345 = f32[1024]{0} broadcast(f32[] %subtract.699), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
  %param_1.1986 = f32[1024]{0} parameter(1)
  %multiply.2091 = f32[1024]{0} multiply(f32[1024]{0} %broadcast.2345, f32[1024]{0} %param_1.1986), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
  %param_0.1167 = f32[1,1024]{1,0} parameter(0)
  %subtract.698 = f32[] subtract(f32[] %constant.21260, f32[] %subtract.699), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=124}
  %constant.21258 = f32[] constant(3.125e-05)
  %multiply.2090 = f32[] multiply(f32[] %subtract.698, f32[] %constant.21258)
  %broadcast.2344 = f32[1,1024]{1,0} broadcast(f32[] %multiply.2090), dimensions={}
  %multiply.2089 = f32[1,1024]{1,0} multiply(f32[1,1024]{1,0} %param_0.1167, f32[1,1024]{1,0} %broadcast.2344), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
  %reshape.3276 = f32[1024]{0} reshape(f32[1,1024]{1,0} %multiply.2089), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
  ROOT %add.4335 = f32[1024]{0} add(f32[1024]{0} %multiply.2091, f32[1024]{0} %reshape.3276), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
}

%fused_computation.565 (param_0.1170: f32[32000], param_1.1991: f32[], param_2.1772: f32[1]) -> f32[32000] {
  %param_2.1772 = f32[1]{0} parameter(2)
  %reshape.3277 = f32[] reshape(f32[1]{0} %param_2.1772), metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=135}
  %constant.21262 = f32[] constant(3.125e-05)
  %multiply.2092 = f32[] multiply(f32[] %reshape.3277, f32[] %constant.21262), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=135}
  %broadcast.2348 = f32[32000]{0} broadcast(f32[] %multiply.2092), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  %param_0.1170 = f32[32000]{0} parameter(0)
  %param_1.1991 = f32[] parameter(1)
  %broadcast.2347 = f32[32000]{0} broadcast(f32[] %param_1.1991), dimensions={}, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  %add.4336 = f32[32000]{0} add(f32[32000]{0} %param_0.1170, f32[32000]{0} %broadcast.2347), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  %divide.269 = f32[32000]{0} divide(f32[32000]{0} %broadcast.2348, f32[32000]{0} %add.4336), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  %constant.21261 = f32[] constant(0.5), metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  %broadcast.2346 = f32[32000]{0} broadcast(f32[] %constant.21261), dimensions={}, metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  ROOT %power.45 = f32[32000]{0} power(f32[32000]{0} %divide.269, f32[32000]{0} %broadcast.2346), metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
}

%fused_computation.566 (param_0.1172: f32[32000,1], param_1.1996: f32[32000], param_2.1779: f32[]) -> f32[32000] {
  %constant.21264 = f32[] constant(1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/metrics.py" source_line=617}
  %param_2.1779 = f32[] parameter(2)
  %subtract.701 = f32[] subtract(f32[] %constant.21264, f32[] %param_2.1779), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=85}
  %broadcast.2350 = f32[32000]{0} broadcast(f32[] %subtract.701), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=131}
  %param_1.1996 = f32[32000]{0} parameter(1)
  %multiply.2095 = f32[32000]{0} multiply(f32[32000]{0} %broadcast.2350, f32[32000]{0} %param_1.1996), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=131}
  %param_0.1172 = f32[32000,1]{1,0} parameter(0)
  %subtract.700 = f32[] subtract(f32[] %constant.21264, f32[] %subtract.701), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=124}
  %constant.21263 = f32[] constant(0.0009765625)
  %multiply.2094 = f32[] multiply(f32[] %subtract.700, f32[] %constant.21263)
  %broadcast.2349 = f32[32000,1]{1,0} broadcast(f32[] %multiply.2094), dimensions={}
  %multiply.2093 = f32[32000,1]{1,0} multiply(f32[32000,1]{1,0} %param_0.1172, f32[32000,1]{1,0} %broadcast.2349), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=131}
  %reshape.3278 = f32[32000]{0} reshape(f32[32000,1]{1,0} %multiply.2093), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=131}
  ROOT %add.4337 = f32[32000]{0} add(f32[32000]{0} %multiply.2095, f32[32000]{0} %reshape.3278), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=131}
}

%fused_computation.568 (param_0.1176: f32[], param_1.2003: s32[]) -> f32[] {
  %param_1.2003 = s32[] parameter(1)
  %convert.75 = f32[] convert(s32[] %param_1.2003), metadata={op_type="convert_element_type" op_name="pmap(_multi_device_update_fn)/convert_element_type[ new_dtype=float32\n                                                    weak_type=False ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=84}
  %constant.21267 = f32[] constant(1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/metrics.py" source_line=617}
  %add.4338 = f32[] add(f32[] %convert.75, f32[] %constant.21267), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=84}
  %param_0.1176 = f32[] parameter(0)
  %negate.217 = f32[] negate(f32[] %param_0.1176), metadata={op_type="neg" op_name="pmap(_multi_device_update_fn)/neg" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=85}
  ROOT %power.46 = f32[] power(f32[] %add.4338, f32[] %negate.217), metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=85}
}

%fused_computation.571 (param_0.1189: f32[8,1,64,64], param_1.2009: f32[8,1,64,64], param_2.1786: f32[8,1,64], param_3.1472: s32[8,64]) -> f32[8,64,64] {
  %param_3.1472 = s32[8,64]{1,0} parameter(3)
  %constant.21269 = s32[] constant(0), metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %broadcast.2357 = s32[8,64]{1,0} broadcast(s32[] %constant.21269), dimensions={}, metadata={op_type="ne" op_name="pmap(_multi_device_update_fn)/ne" source_file="/usr/local/lib/python3.8/dist-packages/trax/models/rnn.py" source_line=205}
  %compare.2804 = pred[8,64]{1,0} compare(s32[8,64]{1,0} %param_3.1472, s32[8,64]{1,0} %broadcast.2357), direction=NE, metadata={op_type="ne" op_name="pmap(_multi_device_update_fn)/ne" source_file="/usr/local/lib/python3.8/dist-packages/trax/models/rnn.py" source_line=205}
  %convert.76 = f32[8,64]{1,0} convert(pred[8,64]{1,0} %compare.2804), metadata={op_type="convert_element_type" op_name="pmap(_multi_device_update_fn)/convert_element_type[ new_dtype=float32\n                                                    weak_type=False ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/models/rnn.py" source_line=209}
  %constant.21270 = f32[] constant(0)
  %broadcast.2356 = f32[8,64]{1,0} broadcast(f32[] %constant.21270), dimensions={}, metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/jit(jvp(_where))/broadcast_in_dim[ broadcast_dimensions=(  )\n                                                                 shape=(8, 1, 64, 64) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/attention.py" source_line=283}
  %compare.2802 = pred[8,64]{1,0} compare(f32[8,64]{1,0} %convert.76, f32[8,64]{1,0} %broadcast.2356), direction=NE, metadata={op_type="ne" op_name="pmap(_multi_device_update_fn)/jit(jvp(_where))/ne" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/attention.py" source_line=283}
  %broadcast.2355 = pred[8,1,64,64]{3,2,1,0} broadcast(pred[8,64]{1,0} %compare.2802), dimensions={0,3}, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/models/rnn.py" source_line=209}
  %param_0.1189 = f32[8,1,64,64]{3,2,1,0} parameter(0)
  %param_2.1786 = f32[8,1,64]{2,1,0} parameter(2)
  %reshape.3283 = f32[8,64]{1,0} reshape(f32[8,1,64]{2,1,0} %param_2.1786), metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(1, 3) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=94}
  %broadcast.2353 = f32[8,1,64,64]{3,2,1,0} broadcast(f32[8,64]{1,0} %reshape.3283), dimensions={0,2}, metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/broadcast_in_dim[ broadcast_dimensions=(0, 1, 2)\n                                                shape=(8, 1, 64, 64) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=94}
  %param_1.2009 = f32[8,1,64,64]{3,2,1,0} parameter(1)
  %multiply.2099 = f32[8,1,64,64]{3,2,1,0} multiply(f32[8,1,64,64]{3,2,1,0} %broadcast.2353, f32[8,1,64,64]{3,2,1,0} %param_1.2009), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=94}
  %add.4340 = f32[8,1,64,64]{3,2,1,0} add(f32[8,1,64,64]{3,2,1,0} %param_0.1189, f32[8,1,64,64]{3,2,1,0} %multiply.2099), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=238}
  %broadcast.2354 = f32[8,1,64,64]{3,2,1,0} broadcast(f32[] %constant.21270), dimensions={}, metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/broadcast_in_dim[ broadcast_dimensions=(  )\n                                                shape=(8, 1, 64, 64) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/attention.py" source_line=292}
  %select.2690 = f32[8,1,64,64]{3,2,1,0} select(pred[8,1,64,64]{3,2,1,0} %broadcast.2355, f32[8,1,64,64]{3,2,1,0} %add.4340, f32[8,1,64,64]{3,2,1,0} %broadcast.2354), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/jit(transpose(jvp(_where)))/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/attention.py" source_line=283}
  %constant.21268 = f32[] constant(0.03125)
  %broadcast.2352 = f32[8,1,64,64]{3,2,1,0} broadcast(f32[] %constant.21268), dimensions={}
  %multiply.2098 = f32[8,1,64,64]{3,2,1,0} multiply(f32[8,1,64,64]{3,2,1,0} %select.2690, f32[8,1,64,64]{3,2,1,0} %broadcast.2352), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/attention.py" source_line=281}
  %reshape.3282 = f32[8,64,1,64]{3,1,0,2} reshape(f32[8,1,64,64]{3,2,1,0} %multiply.2098), metadata={op_type="transpose" op_name="pmap(_multi_device_update_fn)/transpose[ permutation=(0, 2, 1, 3) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/attention.py" source_line=281}
  %copy.53 = f32[8,64,1,64]{3,2,1,0} copy(f32[8,64,1,64]{3,1,0,2} %reshape.3282), metadata={op_type="transpose" op_name="pmap(_multi_device_update_fn)/transpose[ permutation=(0, 2, 1, 3) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/attention.py" source_line=281}
  %transpose.102 = f32[8,1,64,64]{3,2,1,0} transpose(f32[8,64,1,64]{3,2,1,0} %copy.53), dimensions={0,2,3,1}
  ROOT %reshape.3281 = f32[8,64,64]{2,1,0} reshape(f32[8,1,64,64]{3,2,1,0} %transpose.102)
}

%fused_computation.572 (param_0.1191: f32[8,1,64], param_1.2011: f32[8,1,64,2]) -> f32[8,1,64] {
  %param_1.2011 = f32[8,1,64,2]{3,2,1,0} parameter(1)
  %constant.21272 = f32[] constant(0)
  %reduce.338 = f32[8,1,64]{2,1,0} reduce(f32[8,1,64,2]{3,2,1,0} %param_1.2011, f32[] %constant.21272), dimensions={3}, to_apply=%primitive_computation_add__1.15389, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(3,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/attention.py" source_line=287}
  %param_0.1191 = f32[8,1,64]{2,1,0} parameter(0)
  ROOT %divide.270 = f32[8,1,64]{2,1,0} divide(f32[8,1,64]{2,1,0} %reduce.338, f32[8,1,64]{2,1,0} %param_0.1191), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=94}
}

%fused_computation.573 (param_0.1193: f32[8,1,64,64], param_1.2016: f32[8,64,64], param_2.1792: u32[32768]) -> f32[8,1,64,64] {
  %constant.21279 = f32[] constant(0)
  %broadcast.2364 = f32[32768]{0} broadcast(f32[] %constant.21279), dimensions={}, metadata={op_type="max" op_name="pmap(_multi_device_update_fn)/jit(_bernoulli)/jit(_uniform)/max" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=86}
  %param_2.1792 = u32[32768]{0} parameter(2)
  %constant.21276 = u32[] constant(9), metadata={op_type="shift_right_logical" op_name="pmap(_multi_device_update_fn)/jit(_bernoulli)/jit(_uniform)/shift_right_logical" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=86}
  %broadcast.2363 = u32[32768]{0} broadcast(u32[] %constant.21276), dimensions={}, metadata={op_type="shift_right_logical" op_name="pmap(_multi_device_update_fn)/jit(_bernoulli)/jit(_uniform)/shift_right_logical" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=86}
  %shift-right-logical.171 = u32[32768]{0} shift-right-logical(u32[32768]{0} %param_2.1792, u32[32768]{0} %broadcast.2363), metadata={op_type="shift_right_logical" op_name="pmap(_multi_device_update_fn)/jit(_bernoulli)/jit(_uniform)/shift_right_logical" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=86}
  %constant.21275 = u32[] constant(1065353216), metadata={op_type="or" op_name="pmap(_multi_device_update_fn)/jit(_bernoulli)/jit(_uniform)/or" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=86}
  %broadcast.2362 = u32[32768]{0} broadcast(u32[] %constant.21275), dimensions={}, metadata={op_type="or" op_name="pmap(_multi_device_update_fn)/jit(_bernoulli)/jit(_uniform)/or" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=86}
  %or.155 = u32[32768]{0} or(u32[32768]{0} %shift-right-logical.171, u32[32768]{0} %broadcast.2362), metadata={op_type="or" op_name="pmap(_multi_device_update_fn)/jit(_bernoulli)/jit(_uniform)/or" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=86}
  %bitcast-convert.3 = f32[32768]{0} bitcast-convert(u32[32768]{0} %or.155), metadata={op_type="bitcast_convert_type" op_name="pmap(_multi_device_update_fn)/jit(_bernoulli)/jit(_uniform)/bitcast_convert_type[ new_dtype=float32 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=86}
  %constant.21277 = f32[] constant(-1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/metrics.py" source_line=581}
  %broadcast.2361 = f32[32768]{0} broadcast(f32[] %constant.21277), dimensions={}
  %add.4341 = f32[32768]{0} add(f32[32768]{0} %bitcast-convert.3, f32[32768]{0} %broadcast.2361), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/jit(_bernoulli)/jit(_uniform)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=86}
  %maximum.63 = f32[32768]{0} maximum(f32[32768]{0} %broadcast.2364, f32[32768]{0} %add.4341), metadata={op_type="max" op_name="pmap(_multi_device_update_fn)/jit(_bernoulli)/jit(_uniform)/max" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=86}
  %constant.21274 = f32[] constant(0.8), metadata={op_type="xla_call" op_name="pmap(_multi_device_update_fn)/xla_call[ backend=None\n                                        device=None\n                                        donated_invars=(False, False)\n                                        inline=False\n                                        name=_bernoulli ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=86}
  %broadcast.2360 = f32[32768]{0} broadcast(f32[] %constant.21274), dimensions={}, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/jit(_bernoulli)/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=86}
  %compare.2805 = pred[32768]{0} compare(f32[32768]{0} %maximum.63, f32[32768]{0} %broadcast.2360), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/jit(_bernoulli)/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=86}
  %reshape.3285 = pred[8,1,64,64]{3,2,1,0} reshape(pred[32768]{0} %compare.2805), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/jit(_bernoulli)/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=86}
  %param_1.2016 = f32[8,64,64]{2,1,0} parameter(1)
  %reshape.3284 = f32[8,1,64,64]{3,2,0,1} reshape(f32[8,64,64]{2,1,0} %param_1.2016), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/broadcast_in_dim[ broadcast_dimensions=(0, 2, 3)\n                                                shape=(8, 1, 64, 64) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/attention.py" source_line=293}
  %copy.54 = f32[8,1,64,64]{3,2,1,0} copy(f32[8,1,64,64]{3,2,0,1} %reshape.3284), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/broadcast_in_dim[ broadcast_dimensions=(0, 2, 3)\n                                                shape=(8, 1, 64, 64) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/attention.py" source_line=293}
  %broadcast.2358 = f32[8,1,64,64]{3,2,1,0} broadcast(f32[] %constant.21279), dimensions={}, metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/broadcast_in_dim[ broadcast_dimensions=(  )\n                                                shape=(8, 1, 64, 64) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/attention.py" source_line=292}
  %select.2692 = f32[8,1,64,64]{3,2,1,0} select(pred[8,1,64,64]{3,2,1,0} %reshape.3285, f32[8,1,64,64]{3,2,1,0} %copy.54, f32[8,1,64,64]{3,2,1,0} %broadcast.2358), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/jit(transpose(jvp(_where)))/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/attention.py" source_line=290}
  %constant.21273 = f32[] constant(1.25)
  %broadcast.2359 = f32[8,1,64,64]{3,2,1,0} broadcast(f32[] %constant.21273), dimensions={}
  %multiply.2101 = f32[8,1,64,64]{3,2,1,0} multiply(f32[8,1,64,64]{3,2,1,0} %select.2692, f32[8,1,64,64]{3,2,1,0} %broadcast.2359), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/attention.py" source_line=291}
  %param_0.1193 = f32[8,1,64,64]{3,2,1,0} parameter(0)
  ROOT %multiply.2100 = f32[8,1,64,64]{3,2,1,0} multiply(f32[8,1,64,64]{3,2,1,0} %multiply.2101, f32[8,1,64,64]{3,2,1,0} %param_0.1193), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/attention.py" source_line=287}
}

%fused_computation.580 (param_0.1213: f32[8,64], param_1.2024: f32[8,64,8]) -> f32[8,64] {
  %param_1.2024 = f32[8,64,8]{2,1,0} parameter(1)
  %constant.21280 = f32[] constant(0)
  %reduce.339 = f32[8,64]{1,0} reduce(f32[8,64,8]{2,1,0} %param_1.2024, f32[] %constant.21280), dimensions={2}, to_apply=%primitive_computation_add__1.13247, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(2,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/core.py" source_line=794}
  %param_0.1213 = f32[8,64]{1,0} parameter(0)
  ROOT %divide.271 = f32[8,64]{1,0} divide(f32[8,64]{1,0} %reduce.339, f32[8,64]{1,0} %param_0.1213), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=94}
}

%fused_computation.582 (param_0.1217: f32[8,64], param_1.2030: f32[8,64,8]) -> f32[8,64] {
  %param_1.2030 = f32[8,64,8]{2,1,0} parameter(1)
  %constant.21283 = f32[] constant(0)
  %reduce.340 = f32[8,64]{1,0} reduce(f32[8,64,8]{2,1,0} %param_1.2030, f32[] %constant.21283), dimensions={2}, to_apply=%primitive_computation_add__1.13228, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(2,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/core.py" source_line=794}
  %param_0.1217 = f32[8,64]{1,0} parameter(0)
  ROOT %divide.272 = f32[8,64]{1,0} divide(f32[8,64]{1,0} %reduce.340, f32[8,64]{1,0} %param_0.1217), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=94}
}

%fused_computation.584 (param_0.1223: f32[8,64]) -> f32[8,64,1] {
  %param_0.1223 = f32[8,64]{1,0} parameter(0)
  %reshape.3299 = f32[8,64,1]{1,0,2} reshape(f32[8,64]{1,0} %param_0.1223), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/broadcast_in_dim[ broadcast_dimensions=(0, 1)\n                                                shape=(8, 64, 1) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=94}
  %copy.59 = f32[8,64,1]{2,1,0} copy(f32[8,64,1]{1,0,2} %reshape.3299), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/broadcast_in_dim[ broadcast_dimensions=(0, 1)\n                                                shape=(8, 64, 1) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=94}
  %is-finite.0 = pred[8,64,1]{2,1,0} is-finite(f32[8,64,1]{2,1,0} %copy.59), metadata={op_type="is_finite" op_name="pmap(_multi_device_update_fn)/is_finite" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=94}
  %constant.21284 = f32[] constant(0)
  %broadcast.2377 = f32[8,64,1]{2,1,0} broadcast(f32[] %constant.21284), dimensions={}, metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/broadcast_in_dim[ broadcast_dimensions=(  )\n                                                shape=(8, 64, 1) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=94}
  ROOT %select.2694 = f32[8,64,1]{2,1,0} select(pred[8,64,1]{2,1,0} %is-finite.0, f32[8,64,1]{2,1,0} %copy.59, f32[8,64,1]{2,1,0} %broadcast.2377), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=94}
}

%fused_computation.587 (param_0.1231: f32[8,64]) -> f32[8,64,1] {
  %param_0.1231 = f32[8,64]{1,0} parameter(0)
  %reshape.3305 = f32[8,64,1]{1,0,2} reshape(f32[8,64]{1,0} %param_0.1231), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/broadcast_in_dim[ broadcast_dimensions=(0, 1)\n                                                shape=(8, 64, 1) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=94}
  %copy.62 = f32[8,64,1]{2,1,0} copy(f32[8,64,1]{1,0,2} %reshape.3305), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/broadcast_in_dim[ broadcast_dimensions=(0, 1)\n                                                shape=(8, 64, 1) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=94}
  %is-finite.1 = pred[8,64,1]{2,1,0} is-finite(f32[8,64,1]{2,1,0} %copy.62), metadata={op_type="is_finite" op_name="pmap(_multi_device_update_fn)/is_finite" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=94}
  %constant.21285 = f32[] constant(0)
  %broadcast.2385 = f32[8,64,1]{2,1,0} broadcast(f32[] %constant.21285), dimensions={}, metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/broadcast_in_dim[ broadcast_dimensions=(  )\n                                                shape=(8, 64, 1) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=94}
  ROOT %select.2695 = f32[8,64,1]{2,1,0} select(pred[8,64,1]{2,1,0} %is-finite.1, f32[8,64,1]{2,1,0} %copy.62, f32[8,64,1]{2,1,0} %broadcast.2385), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=94}
}

%fused_computation.592 (param_0.1244: f32[8,1,64,64], param_1.2069: u32[32768]) -> f32[8,64,64] {
  %constant.21293 = f32[] constant(0)
  %broadcast.2405 = f32[32768]{0} broadcast(f32[] %constant.21293), dimensions={}, metadata={op_type="max" op_name="pmap(_multi_device_update_fn)/jit(_bernoulli)/jit(_uniform)/max" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=86}
  %param_1.2069 = u32[32768]{0} parameter(1)
  %constant.21290 = u32[] constant(9), metadata={op_type="shift_right_logical" op_name="pmap(_multi_device_update_fn)/jit(_bernoulli)/jit(_uniform)/shift_right_logical" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=86}
  %broadcast.2403 = u32[32768]{0} broadcast(u32[] %constant.21290), dimensions={}, metadata={op_type="shift_right_logical" op_name="pmap(_multi_device_update_fn)/jit(_bernoulli)/jit(_uniform)/shift_right_logical" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=86}
  %shift-right-logical.172 = u32[32768]{0} shift-right-logical(u32[32768]{0} %param_1.2069, u32[32768]{0} %broadcast.2403), metadata={op_type="shift_right_logical" op_name="pmap(_multi_device_update_fn)/jit(_bernoulli)/jit(_uniform)/shift_right_logical" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=86}
  %constant.21289 = u32[] constant(1065353216), metadata={op_type="or" op_name="pmap(_multi_device_update_fn)/jit(_bernoulli)/jit(_uniform)/or" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=86}
  %broadcast.2401 = u32[32768]{0} broadcast(u32[] %constant.21289), dimensions={}, metadata={op_type="or" op_name="pmap(_multi_device_update_fn)/jit(_bernoulli)/jit(_uniform)/or" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=86}
  %or.156 = u32[32768]{0} or(u32[32768]{0} %shift-right-logical.172, u32[32768]{0} %broadcast.2401), metadata={op_type="or" op_name="pmap(_multi_device_update_fn)/jit(_bernoulli)/jit(_uniform)/or" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=86}
  %bitcast-convert.4 = f32[32768]{0} bitcast-convert(u32[32768]{0} %or.156), metadata={op_type="bitcast_convert_type" op_name="pmap(_multi_device_update_fn)/jit(_bernoulli)/jit(_uniform)/bitcast_convert_type[ new_dtype=float32 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=86}
  %constant.21292 = f32[] constant(-1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/metrics.py" source_line=581}
  %broadcast.2399 = f32[32768]{0} broadcast(f32[] %constant.21292), dimensions={}
  %add.4359 = f32[32768]{0} add(f32[32768]{0} %bitcast-convert.4, f32[32768]{0} %broadcast.2399), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/jit(_bernoulli)/jit(_uniform)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=86}
  %maximum.64 = f32[32768]{0} maximum(f32[32768]{0} %broadcast.2405, f32[32768]{0} %add.4359), metadata={op_type="max" op_name="pmap(_multi_device_update_fn)/jit(_bernoulli)/jit(_uniform)/max" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=86}
  %constant.21288 = f32[] constant(0.8), metadata={op_type="xla_call" op_name="pmap(_multi_device_update_fn)/xla_call[ backend=None\n                                        device=None\n                                        donated_invars=(False, False)\n                                        inline=False\n                                        name=_bernoulli ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=86}
  %broadcast.2397 = f32[32768]{0} broadcast(f32[] %constant.21288), dimensions={}, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/jit(_bernoulli)/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=86}
  %compare.2807 = pred[32768]{0} compare(f32[32768]{0} %maximum.64, f32[32768]{0} %broadcast.2397), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/jit(_bernoulli)/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=86}
  %reshape.3311 = pred[8,1,64,64]{3,2,1,0} reshape(pred[32768]{0} %compare.2807), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/jit(_bernoulli)/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=86}
  %param_0.1244 = f32[8,1,64,64]{3,2,1,0} parameter(0)
  %constant.21287 = f32[] constant(1.25)
  %broadcast.2395 = f32[8,1,64,64]{3,2,1,0} broadcast(f32[] %constant.21287), dimensions={}
  %multiply.2106 = f32[8,1,64,64]{3,2,1,0} multiply(f32[8,1,64,64]{3,2,1,0} %param_0.1244, f32[8,1,64,64]{3,2,1,0} %broadcast.2395), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/attention.py" source_line=291}
  %broadcast.2393 = f32[8,1,64,64]{3,2,1,0} broadcast(f32[] %constant.21293), dimensions={}, metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/broadcast_in_dim[ broadcast_dimensions=(  )\n                                                shape=(8, 1, 64, 64) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/attention.py" source_line=292}
  %select.2696 = f32[8,1,64,64]{3,2,1,0} select(pred[8,1,64,64]{3,2,1,0} %reshape.3311, f32[8,1,64,64]{3,2,1,0} %multiply.2106, f32[8,1,64,64]{3,2,1,0} %broadcast.2393), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/jit(jvp(_where))/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/attention.py" source_line=290}
  ROOT %reshape.3310 = f32[8,64,64]{2,1,0} reshape(f32[8,1,64,64]{3,2,1,0} %select.2696), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/squeeze[ dimensions=(1,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/attention.py" source_line=293}
}

%fused_computation.593 (param_0.1247: f32[8,1,64,1], param_1.2075: f32[8,1,64], param_2.1839: f32[8,64,64], param_3.1509: s32[8,64]) -> f32[8,1,64,64] {
  %param_3.1509 = s32[8,64]{1,0} parameter(3)
  %constant.21296 = s32[] constant(0), metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %broadcast.2411 = s32[8,64]{1,0} broadcast(s32[] %constant.21296), dimensions={}, metadata={op_type="ne" op_name="pmap(_multi_device_update_fn)/ne" source_file="/usr/local/lib/python3.8/dist-packages/trax/models/rnn.py" source_line=205}
  %compare.2810 = pred[8,64]{1,0} compare(s32[8,64]{1,0} %param_3.1509, s32[8,64]{1,0} %broadcast.2411), direction=NE, metadata={op_type="ne" op_name="pmap(_multi_device_update_fn)/ne" source_file="/usr/local/lib/python3.8/dist-packages/trax/models/rnn.py" source_line=205}
  %convert.77 = f32[8,64]{1,0} convert(pred[8,64]{1,0} %compare.2810), metadata={op_type="convert_element_type" op_name="pmap(_multi_device_update_fn)/convert_element_type[ new_dtype=float32\n                                                    weak_type=False ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/models/rnn.py" source_line=209}
  %constant.21297 = f32[] constant(0)
  %broadcast.2410 = f32[8,64]{1,0} broadcast(f32[] %constant.21297), dimensions={}, metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/jit(jvp(_where))/broadcast_in_dim[ broadcast_dimensions=(  )\n                                                                 shape=(8, 1, 64, 64) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/attention.py" source_line=283}
  %compare.2808 = pred[8,64]{1,0} compare(f32[8,64]{1,0} %convert.77, f32[8,64]{1,0} %broadcast.2410), direction=NE, metadata={op_type="ne" op_name="pmap(_multi_device_update_fn)/jit(jvp(_where))/ne" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/attention.py" source_line=283}
  %broadcast.2409 = pred[8,1,64,64]{3,2,1,0} broadcast(pred[8,64]{1,0} %compare.2808), dimensions={0,3}, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/models/rnn.py" source_line=209}
  %param_2.1839 = f32[8,64,64]{2,1,0} parameter(2)
  %constant.21295 = f32[] constant(0.03125)
  %broadcast.2408 = f32[8,64,64]{2,1,0} broadcast(f32[] %constant.21295), dimensions={}
  %multiply.2107 = f32[8,64,64]{2,1,0} multiply(f32[8,64,64]{2,1,0} %param_2.1839, f32[8,64,64]{2,1,0} %broadcast.2408), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/attention.py" source_line=281}
  %reshape.3314 = f32[8,1,64,64]{3,2,0,1} reshape(f32[8,64,64]{2,1,0} %multiply.2107), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/attention.py" source_line=281}
  %copy.64 = f32[8,1,64,64]{3,2,1,0} copy(f32[8,1,64,64]{3,2,0,1} %reshape.3314), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/attention.py" source_line=281}
  %constant.21294 = f32[] constant(-1e+09), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/broadcast_in_dim[ broadcast_dimensions=(  )\n                                                shape=(8, 1, 64, 64) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/attention.py" source_line=285}
  %broadcast.2407 = f32[8,1,64,64]{3,2,1,0} broadcast(f32[] %constant.21294), dimensions={}, metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/broadcast_in_dim[ broadcast_dimensions=(  )\n                                                shape=(8, 1, 64, 64) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/attention.py" source_line=285}
  %select.2697 = f32[8,1,64,64]{3,2,1,0} select(pred[8,1,64,64]{3,2,1,0} %broadcast.2409, f32[8,1,64,64]{3,2,1,0} %copy.64, f32[8,1,64,64]{3,2,1,0} %broadcast.2407), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/jit(jvp(_where))/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/attention.py" source_line=283}
  %param_1.2075 = f32[8,1,64]{2,1,0} parameter(1)
  %reshape.3313 = f32[8,1,64,1]{2,0,3,1} reshape(f32[8,1,64]{2,1,0} %param_1.2075), metadata={op_type="log" op_name="pmap(_multi_device_update_fn)/log" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=94}
  %copy.63 = f32[8,1,64,1]{3,2,1,0} copy(f32[8,1,64,1]{2,0,3,1} %reshape.3313), metadata={op_type="log" op_name="pmap(_multi_device_update_fn)/log" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=94}
  %param_0.1247 = f32[8,1,64,1]{3,2,1,0} parameter(0)
  %add.4360 = f32[8,1,64,1]{3,2,1,0} add(f32[8,1,64,1]{3,2,1,0} %copy.63, f32[8,1,64,1]{3,2,1,0} %param_0.1247), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=94}
  %reshape.3312 = f32[8,64]{1,0} reshape(f32[8,1,64,1]{3,2,1,0} %add.4360)
  %broadcast.2406 = f32[8,1,64,64]{3,2,1,0} broadcast(f32[8,64]{1,0} %reshape.3312), dimensions={0,2}, metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/attention.py" source_line=287}
  %subtract.707 = f32[8,1,64,64]{3,2,1,0} subtract(f32[8,1,64,64]{3,2,1,0} %select.2697, f32[8,1,64,64]{3,2,1,0} %broadcast.2406), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/attention.py" source_line=287}
  ROOT %exponential.191 = f32[8,1,64,64]{3,2,1,0} exponential(f32[8,1,64,64]{3,2,1,0} %subtract.707), metadata={op_type="exp" op_name="pmap(_multi_device_update_fn)/exp" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/attention.py" source_line=287}
}

%fused_computation.594 (param_0.1250: f32[8,1,64,1], param_1.2080: f32[8,64,64], param_2.1847: s32[8,64]) -> f32[8,1,64,64] {
  %param_2.1847 = s32[8,64]{1,0} parameter(2)
  %constant.21300 = s32[] constant(0), metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %broadcast.2417 = s32[8,64]{1,0} broadcast(s32[] %constant.21300), dimensions={}, metadata={op_type="ne" op_name="pmap(_multi_device_update_fn)/ne" source_file="/usr/local/lib/python3.8/dist-packages/trax/models/rnn.py" source_line=205}
  %compare.2812 = pred[8,64]{1,0} compare(s32[8,64]{1,0} %param_2.1847, s32[8,64]{1,0} %broadcast.2417), direction=NE, metadata={op_type="ne" op_name="pmap(_multi_device_update_fn)/ne" source_file="/usr/local/lib/python3.8/dist-packages/trax/models/rnn.py" source_line=205}
  %convert.78 = f32[8,64]{1,0} convert(pred[8,64]{1,0} %compare.2812), metadata={op_type="convert_element_type" op_name="pmap(_multi_device_update_fn)/convert_element_type[ new_dtype=float32\n                                                    weak_type=False ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/models/rnn.py" source_line=209}
  %constant.21301 = f32[] constant(0)
  %broadcast.2416 = f32[8,64]{1,0} broadcast(f32[] %constant.21301), dimensions={}, metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/jit(jvp(_where))/broadcast_in_dim[ broadcast_dimensions=(  )\n                                                                 shape=(8, 1, 64, 64) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/attention.py" source_line=283}
  %compare.2811 = pred[8,64]{1,0} compare(f32[8,64]{1,0} %convert.78, f32[8,64]{1,0} %broadcast.2416), direction=NE, metadata={op_type="ne" op_name="pmap(_multi_device_update_fn)/jit(jvp(_where))/ne" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/attention.py" source_line=283}
  %broadcast.2415 = pred[8,1,64,64]{3,2,1,0} broadcast(pred[8,64]{1,0} %compare.2811), dimensions={0,3}, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/models/rnn.py" source_line=209}
  %param_1.2080 = f32[8,64,64]{2,1,0} parameter(1)
  %constant.21299 = f32[] constant(0.03125)
  %broadcast.2414 = f32[8,64,64]{2,1,0} broadcast(f32[] %constant.21299), dimensions={}
  %multiply.2108 = f32[8,64,64]{2,1,0} multiply(f32[8,64,64]{2,1,0} %param_1.2080, f32[8,64,64]{2,1,0} %broadcast.2414), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/attention.py" source_line=281}
  %reshape.3316 = f32[8,1,64,64]{3,2,0,1} reshape(f32[8,64,64]{2,1,0} %multiply.2108), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/attention.py" source_line=281}
  %copy.65 = f32[8,1,64,64]{3,2,1,0} copy(f32[8,1,64,64]{3,2,0,1} %reshape.3316), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/attention.py" source_line=281}
  %constant.21298 = f32[] constant(-1e+09), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/broadcast_in_dim[ broadcast_dimensions=(  )\n                                                shape=(8, 1, 64, 64) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/attention.py" source_line=285}
  %broadcast.2413 = f32[8,1,64,64]{3,2,1,0} broadcast(f32[] %constant.21298), dimensions={}, metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/broadcast_in_dim[ broadcast_dimensions=(  )\n                                                shape=(8, 1, 64, 64) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/attention.py" source_line=285}
  %select.2698 = f32[8,1,64,64]{3,2,1,0} select(pred[8,1,64,64]{3,2,1,0} %broadcast.2415, f32[8,1,64,64]{3,2,1,0} %copy.65, f32[8,1,64,64]{3,2,1,0} %broadcast.2413), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/jit(jvp(_where))/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/attention.py" source_line=283}
  %param_0.1250 = f32[8,1,64,1]{3,2,1,0} parameter(0)
  %reshape.3315 = f32[8,64]{1,0} reshape(f32[8,1,64,1]{3,2,1,0} %param_0.1250)
  %broadcast.2412 = f32[8,1,64,64]{3,2,1,0} broadcast(f32[8,64]{1,0} %reshape.3315), dimensions={0,2}, metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=94}
  %subtract.708 = f32[8,1,64,64]{3,2,1,0} subtract(f32[8,1,64,64]{3,2,1,0} %select.2698, f32[8,1,64,64]{3,2,1,0} %broadcast.2412), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=94}
  ROOT %exponential.192 = f32[8,1,64,64]{3,2,1,0} exponential(f32[8,1,64,64]{3,2,1,0} %subtract.708), metadata={op_type="exp" op_name="pmap(_multi_device_update_fn)/exp" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=94}
}

%fused_computation.595 (param_0.1253: f32[8,1,64]) -> f32[8,1,64,1] {
  %param_0.1253 = f32[8,1,64]{2,1,0} parameter(0)
  %reshape.3317 = f32[8,1,64,1]{2,0,3,1} reshape(f32[8,1,64]{2,1,0} %param_0.1253), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/broadcast_in_dim[ broadcast_dimensions=(0, 1, 2)\n                                                shape=(8, 1, 64, 1) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=94}
  %copy.67 = f32[8,1,64,1]{3,2,1,0} copy(f32[8,1,64,1]{2,0,3,1} %reshape.3317), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/broadcast_in_dim[ broadcast_dimensions=(0, 1, 2)\n                                                shape=(8, 1, 64, 1) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=94}
  %is-finite.2 = pred[8,1,64,1]{3,2,1,0} is-finite(f32[8,1,64,1]{3,2,1,0} %copy.67), metadata={op_type="is_finite" op_name="pmap(_multi_device_update_fn)/is_finite" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=94}
  %constant.21302 = f32[] constant(0)
  %broadcast.2418 = f32[8,1,64,1]{3,2,1,0} broadcast(f32[] %constant.21302), dimensions={}, metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/broadcast_in_dim[ broadcast_dimensions=(  )\n                                                shape=(8, 1, 64, 1) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=94}
  ROOT %select.2700 = f32[8,1,64,1]{3,2,1,0} select(pred[8,1,64,1]{3,2,1,0} %is-finite.2, f32[8,1,64,1]{3,2,1,0} %copy.67, f32[8,1,64,1]{3,2,1,0} %broadcast.2418), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=94}
}

%fused_computation.596 (param_0.1255: f32[8,64,64], param_1.2092: s32[8,64]) -> f32[8,1,64,64] {
  %param_1.2092 = s32[8,64]{1,0} parameter(1)
  %constant.21306 = s32[] constant(0), metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %broadcast.2423 = s32[8,64]{1,0} broadcast(s32[] %constant.21306), dimensions={}, metadata={op_type="ne" op_name="pmap(_multi_device_update_fn)/ne" source_file="/usr/local/lib/python3.8/dist-packages/trax/models/rnn.py" source_line=205}
  %compare.2814 = pred[8,64]{1,0} compare(s32[8,64]{1,0} %param_1.2092, s32[8,64]{1,0} %broadcast.2423), direction=NE, metadata={op_type="ne" op_name="pmap(_multi_device_update_fn)/ne" source_file="/usr/local/lib/python3.8/dist-packages/trax/models/rnn.py" source_line=205}
  %convert.79 = f32[8,64]{1,0} convert(pred[8,64]{1,0} %compare.2814), metadata={op_type="convert_element_type" op_name="pmap(_multi_device_update_fn)/convert_element_type[ new_dtype=float32\n                                                    weak_type=False ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/models/rnn.py" source_line=209}
  %constant.21307 = f32[] constant(0)
  %broadcast.2422 = f32[8,64]{1,0} broadcast(f32[] %constant.21307), dimensions={}, metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/jit(jvp(_where))/broadcast_in_dim[ broadcast_dimensions=(  )\n                                                                 shape=(8, 1, 64, 64) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/attention.py" source_line=283}
  %compare.2813 = pred[8,64]{1,0} compare(f32[8,64]{1,0} %convert.79, f32[8,64]{1,0} %broadcast.2422), direction=NE, metadata={op_type="ne" op_name="pmap(_multi_device_update_fn)/jit(jvp(_where))/ne" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/attention.py" source_line=283}
  %broadcast.2421 = pred[8,1,64,64]{3,2,1,0} broadcast(pred[8,64]{1,0} %compare.2813), dimensions={0,3}, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/models/rnn.py" source_line=209}
  %param_0.1255 = f32[8,64,64]{2,1,0} parameter(0)
  %constant.21305 = f32[] constant(0.03125)
  %broadcast.2420 = f32[8,64,64]{2,1,0} broadcast(f32[] %constant.21305), dimensions={}
  %multiply.2109 = f32[8,64,64]{2,1,0} multiply(f32[8,64,64]{2,1,0} %param_0.1255, f32[8,64,64]{2,1,0} %broadcast.2420), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/attention.py" source_line=281}
  %reshape.3318 = f32[8,1,64,64]{3,2,0,1} reshape(f32[8,64,64]{2,1,0} %multiply.2109), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/attention.py" source_line=281}
  %copy.68 = f32[8,1,64,64]{3,2,1,0} copy(f32[8,1,64,64]{3,2,0,1} %reshape.3318), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/attention.py" source_line=281}
  %constant.21304 = f32[] constant(-1e+09), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/broadcast_in_dim[ broadcast_dimensions=(  )\n                                                shape=(8, 1, 64, 64) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/attention.py" source_line=285}
  %broadcast.2419 = f32[8,1,64,64]{3,2,1,0} broadcast(f32[] %constant.21304), dimensions={}, metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/broadcast_in_dim[ broadcast_dimensions=(  )\n                                                shape=(8, 1, 64, 64) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/attention.py" source_line=285}
  ROOT %select.2701 = f32[8,1,64,64]{3,2,1,0} select(pred[8,1,64,64]{3,2,1,0} %broadcast.2421, f32[8,1,64,64]{3,2,1,0} %copy.68, f32[8,1,64,64]{3,2,1,0} %broadcast.2419), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/jit(jvp(_where))/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/attention.py" source_line=283}
}

%fused_computation.603 (param_0.1275: u32[6]) -> u32[] {
  %param_0.1275 = u32[6]{0} parameter(0)
  %reshape.3332 = u32[3,2]{1,0} reshape(u32[6]{0} %param_0.1275), metadata={op_type="reshape" op_name="pmap(_multi_device_update_fn)/jit(_split)/reshape[ dimensions=None\n                                                   new_sizes=(3, 2) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %slice.1363 = u32[1,1]{1,0} slice(u32[3,2]{1,0} %reshape.3332), slice={[1:2], [0:1]}
  %reshape.3331 = u32[] reshape(u32[1,1]{1,0} %slice.1363), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/jit(_bernoulli)/jit(_uniform)/jit(_random_bits)/jit(threefry_2x32)/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=86}
  %slice.1362 = u32[1,2]{1,0} slice(u32[3,2]{1,0} %reshape.3332), slice={[1:2], [0:2]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/slice[ limit_indices=(2, 2)\n                                     start_indices=(1, 0)\n                                     strides=(1, 1) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/combinators.py" source_line=86}
  %reshape.3330 = u32[2]{0} reshape(u32[1,2]{1,0} %slice.1362), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/combinators.py" source_line=86}
  %slice.1361 = u32[1]{0} slice(u32[2]{0} %reshape.3330), slice={[1:2]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/jit(_bernoulli)/jit(_uniform)/jit(_random_bits)/jit(threefry_2x32)/slice[ limit_indices=(2,)\n                                                                                                        start_indices=(1,)\n                                                                                                        strides=(1,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=86}
  %reshape.3329 = u32[] reshape(u32[1]{0} %slice.1361), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/jit(_bernoulli)/jit(_uniform)/jit(_random_bits)/jit(threefry_2x32)/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=86}
  %xor.343 = u32[] xor(u32[] %reshape.3331, u32[] %reshape.3329), metadata={op_type="xor" op_name="xor" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant.21308 = u32[] constant(466688986), metadata={op_type="xor" op_name="xor" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %xor.342 = u32[] xor(u32[] %xor.343, u32[] %constant.21308), metadata={op_type="xor" op_name="xor" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.604 (param_0.1279: u32[6]) -> u32[16384] {
  %iota.50 = u32[32768]{0} iota(), iota_dimension=0, metadata={op_type="iota" op_name="pmap(_multi_device_update_fn)/jit(_bernoulli)/jit(_uniform)/jit(_random_bits)/iota[ dimension=0\n                                                                                    dtype=uint32\n                                                                                    shape=(32768,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=86}
  %slice.1366 = u32[16384]{0} slice(u32[32768]{0} %iota.50), slice={[16384:32768]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/jit(_bernoulli)/jit(_uniform)/jit(_random_bits)/jit(threefry_2x32)/slice[ limit_indices=(32768,)\n                                                                                                        start_indices=(16384,)\n                                                                                                        strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=86}
  %param_0.1279 = u32[6]{0} parameter(0)
  %reshape.3335 = u32[3,2]{1,0} reshape(u32[6]{0} %param_0.1279), metadata={op_type="reshape" op_name="pmap(_multi_device_update_fn)/jit(_split)/reshape[ dimensions=None\n                                                   new_sizes=(3, 2) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %slice.1365 = u32[1,2]{1,0} slice(u32[3,2]{1,0} %reshape.3335), slice={[1:2], [0:2]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/slice[ limit_indices=(2, 2)\n                                     start_indices=(1, 0)\n                                     strides=(1, 1) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/combinators.py" source_line=86}
  %reshape.3334 = u32[2]{0} reshape(u32[1,2]{1,0} %slice.1365), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/combinators.py" source_line=86}
  %slice.1364 = u32[1]{0} slice(u32[2]{0} %reshape.3334), slice={[1:2]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/jit(_bernoulli)/jit(_uniform)/jit(_random_bits)/jit(threefry_2x32)/slice[ limit_indices=(2,)\n                                                                                                        start_indices=(1,)\n                                                                                                        strides=(1,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=86}
  %reshape.3333 = u32[] reshape(u32[1]{0} %slice.1364), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/jit(_bernoulli)/jit(_uniform)/jit(_random_bits)/jit(threefry_2x32)/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=86}
  %broadcast.2427 = u32[16384]{0} broadcast(u32[] %reshape.3333), dimensions={}, metadata={op_type="add" op_name="add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %add.4364 = u32[16384]{0} add(u32[16384]{0} %slice.1366, u32[16384]{0} %broadcast.2427), metadata={op_type="add" op_name="add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.605 (param_0.1284: u32[6]) -> u32[] {
  %param_0.1284 = u32[6]{0} parameter(0)
  %reshape.3338 = u32[3,2]{1,0} reshape(u32[6]{0} %param_0.1284), metadata={op_type="reshape" op_name="pmap(_multi_device_update_fn)/jit(_split)/reshape[ dimensions=None\n                                                   new_sizes=(3, 2) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %slice.1368 = u32[1,2]{1,0} slice(u32[3,2]{1,0} %reshape.3338), slice={[1:2], [0:2]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/slice[ limit_indices=(2, 2)\n                                     start_indices=(1, 0)\n                                     strides=(1, 1) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/combinators.py" source_line=86}
  %reshape.3337 = u32[2]{0} reshape(u32[1,2]{1,0} %slice.1368), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/combinators.py" source_line=86}
  %slice.1367 = u32[1]{0} slice(u32[2]{0} %reshape.3337), slice={[1:2]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/jit(_bernoulli)/jit(_uniform)/jit(_random_bits)/jit(threefry_2x32)/slice[ limit_indices=(2,)\n                                                                                                        start_indices=(1,)\n                                                                                                        strides=(1,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=86}
  ROOT %reshape.3336 = u32[] reshape(u32[1]{0} %slice.1367), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/jit(_bernoulli)/jit(_uniform)/jit(_random_bits)/jit(threefry_2x32)/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=86}
}

%fused_computation.606 (param_0.1286: u32[6]) -> u32[16384] {
  %iota.51 = u32[32768]{0} iota(), iota_dimension=0, metadata={op_type="iota" op_name="pmap(_multi_device_update_fn)/jit(_bernoulli)/jit(_uniform)/jit(_random_bits)/iota[ dimension=0\n                                                                                    dtype=uint32\n                                                                                    shape=(32768,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=86}
  %slice.1370 = u32[16384]{0} slice(u32[32768]{0} %iota.51), slice={[0:16384]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/jit(_bernoulli)/jit(_uniform)/jit(_random_bits)/jit(threefry_2x32)/slice[ limit_indices=(16384,)\n                                                                                                        start_indices=(0,)\n                                                                                                        strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=86}
  %param_0.1286 = u32[6]{0} parameter(0)
  %reshape.3340 = u32[3,2]{1,0} reshape(u32[6]{0} %param_0.1286), metadata={op_type="reshape" op_name="pmap(_multi_device_update_fn)/jit(_split)/reshape[ dimensions=None\n                                                   new_sizes=(3, 2) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %slice.1369 = u32[1,1]{1,0} slice(u32[3,2]{1,0} %reshape.3340), slice={[1:2], [0:1]}
  %reshape.3339 = u32[] reshape(u32[1,1]{1,0} %slice.1369), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/jit(_bernoulli)/jit(_uniform)/jit(_random_bits)/jit(threefry_2x32)/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=86}
  %broadcast.2428 = u32[16384]{0} broadcast(u32[] %reshape.3339), dimensions={}, metadata={op_type="add" op_name="add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %add.4365 = u32[16384]{0} add(u32[16384]{0} %slice.1370, u32[16384]{0} %broadcast.2428), metadata={op_type="add" op_name="add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.607 (param_0.1289: u32[6]) -> u32[] {
  %param_0.1289 = u32[6]{0} parameter(0)
  %reshape.3342 = u32[3,2]{1,0} reshape(u32[6]{0} %param_0.1289), metadata={op_type="reshape" op_name="pmap(_multi_device_update_fn)/jit(_split)/reshape[ dimensions=None\n                                                   new_sizes=(3, 2) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %slice.1371 = u32[1,1]{1,0} slice(u32[3,2]{1,0} %reshape.3342), slice={[1:2], [0:1]}
  ROOT %reshape.3341 = u32[] reshape(u32[1,1]{1,0} %slice.1371), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/jit(_bernoulli)/jit(_uniform)/jit(_random_bits)/jit(threefry_2x32)/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=86}
}

%fused_computation.608 (param_0.1292: u32[6]) -> u32[] {
  %param_0.1292 = u32[6]{0} parameter(0)
  %reshape.3346 = u32[3,2]{1,0} reshape(u32[6]{0} %param_0.1292), metadata={op_type="reshape" op_name="pmap(_multi_device_update_fn)/jit(_split)/reshape[ dimensions=None\n                                                   new_sizes=(3, 2) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %slice.1374 = u32[1,1]{1,0} slice(u32[3,2]{1,0} %reshape.3346), slice={[1:2], [0:1]}
  %reshape.3345 = u32[] reshape(u32[1,1]{1,0} %slice.1374), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %slice.1373 = u32[1,2]{1,0} slice(u32[3,2]{1,0} %reshape.3346), slice={[1:2], [0:2]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/slice[ limit_indices=(2, 2)\n                                     start_indices=(1, 0)\n                                     strides=(1, 1) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/combinators.py" source_line=86}
  %reshape.3344 = u32[2]{0} reshape(u32[1,2]{1,0} %slice.1373), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/combinators.py" source_line=86}
  %slice.1372 = u32[1]{0} slice(u32[2]{0} %reshape.3344), slice={[1:2]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/slice[ limit_indices=(2,)\n                                                                    start_indices=(1,)\n                                                                    strides=(1,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %reshape.3343 = u32[] reshape(u32[1]{0} %slice.1372), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %xor.345 = u32[] xor(u32[] %reshape.3345, u32[] %reshape.3343), metadata={op_type="xor" op_name="xor" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant.21310 = u32[] constant(466688986), metadata={op_type="xor" op_name="xor" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %xor.344 = u32[] xor(u32[] %xor.345, u32[] %constant.21310), metadata={op_type="xor" op_name="xor" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.609 (param_0.1296: u32[6]) -> u32[3] {
  %iota.52 = u32[6]{0} iota(), iota_dimension=0, metadata={op_type="iota" op_name="pmap(_multi_device_update_fn)/jit(_split)/iota[ dimension=0\n                                                dtype=uint32\n                                                shape=(6,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %slice.1377 = u32[3]{0} slice(u32[6]{0} %iota.52), slice={[3:6]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/slice[ limit_indices=(6,)\n                                                                    start_indices=(3,)\n                                                                    strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %param_0.1296 = u32[6]{0} parameter(0)
  %reshape.3349 = u32[3,2]{1,0} reshape(u32[6]{0} %param_0.1296), metadata={op_type="reshape" op_name="pmap(_multi_device_update_fn)/jit(_split)/reshape[ dimensions=None\n                                                   new_sizes=(3, 2) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %slice.1376 = u32[1,2]{1,0} slice(u32[3,2]{1,0} %reshape.3349), slice={[1:2], [0:2]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/slice[ limit_indices=(2, 2)\n                                     start_indices=(1, 0)\n                                     strides=(1, 1) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/combinators.py" source_line=86}
  %reshape.3348 = u32[2]{0} reshape(u32[1,2]{1,0} %slice.1376), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/combinators.py" source_line=86}
  %slice.1375 = u32[1]{0} slice(u32[2]{0} %reshape.3348), slice={[1:2]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/slice[ limit_indices=(2,)\n                                                                    start_indices=(1,)\n                                                                    strides=(1,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %reshape.3347 = u32[] reshape(u32[1]{0} %slice.1375), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %broadcast.2429 = u32[3]{0} broadcast(u32[] %reshape.3347), dimensions={}, metadata={op_type="add" op_name="add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %add.4366 = u32[3]{0} add(u32[3]{0} %slice.1377, u32[3]{0} %broadcast.2429), metadata={op_type="add" op_name="add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.610 (param_0.1301: u32[6]) -> u32[] {
  %param_0.1301 = u32[6]{0} parameter(0)
  %reshape.3352 = u32[3,2]{1,0} reshape(u32[6]{0} %param_0.1301), metadata={op_type="reshape" op_name="pmap(_multi_device_update_fn)/jit(_split)/reshape[ dimensions=None\n                                                   new_sizes=(3, 2) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %slice.1379 = u32[1,2]{1,0} slice(u32[3,2]{1,0} %reshape.3352), slice={[1:2], [0:2]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/slice[ limit_indices=(2, 2)\n                                     start_indices=(1, 0)\n                                     strides=(1, 1) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/combinators.py" source_line=86}
  %reshape.3351 = u32[2]{0} reshape(u32[1,2]{1,0} %slice.1379), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/combinators.py" source_line=86}
  %slice.1378 = u32[1]{0} slice(u32[2]{0} %reshape.3351), slice={[1:2]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/slice[ limit_indices=(2,)\n                                                                    start_indices=(1,)\n                                                                    strides=(1,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  ROOT %reshape.3350 = u32[] reshape(u32[1]{0} %slice.1378), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
}

%fused_computation.611 (param_0.1303: u32[6]) -> u32[3] {
  %iota.53 = u32[6]{0} iota(), iota_dimension=0, metadata={op_type="iota" op_name="pmap(_multi_device_update_fn)/jit(_split)/iota[ dimension=0\n                                                dtype=uint32\n                                                shape=(6,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %slice.1381 = u32[3]{0} slice(u32[6]{0} %iota.53), slice={[0:3]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/slice[ limit_indices=(3,)\n                                                                    start_indices=(0,)\n                                                                    strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %param_0.1303 = u32[6]{0} parameter(0)
  %reshape.3354 = u32[3,2]{1,0} reshape(u32[6]{0} %param_0.1303), metadata={op_type="reshape" op_name="pmap(_multi_device_update_fn)/jit(_split)/reshape[ dimensions=None\n                                                   new_sizes=(3, 2) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %slice.1380 = u32[1,1]{1,0} slice(u32[3,2]{1,0} %reshape.3354), slice={[1:2], [0:1]}
  %reshape.3353 = u32[] reshape(u32[1,1]{1,0} %slice.1380), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %broadcast.2430 = u32[3]{0} broadcast(u32[] %reshape.3353), dimensions={}, metadata={op_type="add" op_name="add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %add.4367 = u32[3]{0} add(u32[3]{0} %slice.1381, u32[3]{0} %broadcast.2430), metadata={op_type="add" op_name="add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.612 (param_0.1306: u32[6]) -> u32[] {
  %param_0.1306 = u32[6]{0} parameter(0)
  %reshape.3356 = u32[3,2]{1,0} reshape(u32[6]{0} %param_0.1306), metadata={op_type="reshape" op_name="pmap(_multi_device_update_fn)/jit(_split)/reshape[ dimensions=None\n                                                   new_sizes=(3, 2) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %slice.1382 = u32[1,1]{1,0} slice(u32[3,2]{1,0} %reshape.3356), slice={[1:2], [0:1]}
  ROOT %reshape.3355 = u32[] reshape(u32[1,1]{1,0} %slice.1382), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
}

%fused_computation.613 (param_0.1309: u32[4]) -> u32[] {
  %param_0.1309 = u32[4]{0} parameter(0)
  %reshape.3360 = u32[2,2]{1,0} reshape(u32[4]{0} %param_0.1309), metadata={op_type="reshape" op_name="pmap(_multi_device_update_fn)/jit(_split)/reshape[ dimensions=None\n                                                   new_sizes=(2, 2) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %slice.1385 = u32[1,1]{1,0} slice(u32[2,2]{1,0} %reshape.3360), slice={[1:2], [0:1]}
  %reshape.3359 = u32[] reshape(u32[1,1]{1,0} %slice.1385), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %slice.1384 = u32[1,2]{1,0} slice(u32[2,2]{1,0} %reshape.3360), slice={[1:2], [0:2]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/slice[ limit_indices=(2, 2)\n                                     start_indices=(1, 0)\n                                     strides=(1, 1) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/combinators.py" source_line=209}
  %reshape.3358 = u32[2]{0} reshape(u32[1,2]{1,0} %slice.1384), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/combinators.py" source_line=209}
  %slice.1383 = u32[1]{0} slice(u32[2]{0} %reshape.3358), slice={[1:2]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/slice[ limit_indices=(2,)\n                                                                    start_indices=(1,)\n                                                                    strides=(1,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %reshape.3357 = u32[] reshape(u32[1]{0} %slice.1383), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %xor.347 = u32[] xor(u32[] %reshape.3359, u32[] %reshape.3357), metadata={op_type="xor" op_name="xor" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant.21311 = u32[] constant(466688986), metadata={op_type="xor" op_name="xor" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %xor.346 = u32[] xor(u32[] %xor.347, u32[] %constant.21311), metadata={op_type="xor" op_name="xor" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.614 (param_0.1313: u32[4]) -> u32[3] {
  %iota.54 = u32[6]{0} iota(), iota_dimension=0, metadata={op_type="iota" op_name="pmap(_multi_device_update_fn)/jit(_split)/iota[ dimension=0\n                                                dtype=uint32\n                                                shape=(6,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %slice.1388 = u32[3]{0} slice(u32[6]{0} %iota.54), slice={[3:6]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/slice[ limit_indices=(6,)\n                                                                    start_indices=(3,)\n                                                                    strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %param_0.1313 = u32[4]{0} parameter(0)
  %reshape.3363 = u32[2,2]{1,0} reshape(u32[4]{0} %param_0.1313), metadata={op_type="reshape" op_name="pmap(_multi_device_update_fn)/jit(_split)/reshape[ dimensions=None\n                                                   new_sizes=(2, 2) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %slice.1387 = u32[1,2]{1,0} slice(u32[2,2]{1,0} %reshape.3363), slice={[1:2], [0:2]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/slice[ limit_indices=(2, 2)\n                                     start_indices=(1, 0)\n                                     strides=(1, 1) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/combinators.py" source_line=209}
  %reshape.3362 = u32[2]{0} reshape(u32[1,2]{1,0} %slice.1387), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/combinators.py" source_line=209}
  %slice.1386 = u32[1]{0} slice(u32[2]{0} %reshape.3362), slice={[1:2]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/slice[ limit_indices=(2,)\n                                                                    start_indices=(1,)\n                                                                    strides=(1,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %reshape.3361 = u32[] reshape(u32[1]{0} %slice.1386), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %broadcast.2431 = u32[3]{0} broadcast(u32[] %reshape.3361), dimensions={}, metadata={op_type="add" op_name="add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %add.4368 = u32[3]{0} add(u32[3]{0} %slice.1388, u32[3]{0} %broadcast.2431), metadata={op_type="add" op_name="add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.615 (param_0.1318: u32[4]) -> u32[] {
  %param_0.1318 = u32[4]{0} parameter(0)
  %reshape.3366 = u32[2,2]{1,0} reshape(u32[4]{0} %param_0.1318), metadata={op_type="reshape" op_name="pmap(_multi_device_update_fn)/jit(_split)/reshape[ dimensions=None\n                                                   new_sizes=(2, 2) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %slice.1390 = u32[1,2]{1,0} slice(u32[2,2]{1,0} %reshape.3366), slice={[1:2], [0:2]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/slice[ limit_indices=(2, 2)\n                                     start_indices=(1, 0)\n                                     strides=(1, 1) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/combinators.py" source_line=209}
  %reshape.3365 = u32[2]{0} reshape(u32[1,2]{1,0} %slice.1390), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/combinators.py" source_line=209}
  %slice.1389 = u32[1]{0} slice(u32[2]{0} %reshape.3365), slice={[1:2]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/slice[ limit_indices=(2,)\n                                                                    start_indices=(1,)\n                                                                    strides=(1,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  ROOT %reshape.3364 = u32[] reshape(u32[1]{0} %slice.1389), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
}

%fused_computation.616 (param_0.1320: u32[4]) -> u32[3] {
  %iota.55 = u32[6]{0} iota(), iota_dimension=0, metadata={op_type="iota" op_name="pmap(_multi_device_update_fn)/jit(_split)/iota[ dimension=0\n                                                dtype=uint32\n                                                shape=(6,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %slice.1392 = u32[3]{0} slice(u32[6]{0} %iota.55), slice={[0:3]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/slice[ limit_indices=(3,)\n                                                                    start_indices=(0,)\n                                                                    strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %param_0.1320 = u32[4]{0} parameter(0)
  %reshape.3368 = u32[2,2]{1,0} reshape(u32[4]{0} %param_0.1320), metadata={op_type="reshape" op_name="pmap(_multi_device_update_fn)/jit(_split)/reshape[ dimensions=None\n                                                   new_sizes=(2, 2) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %slice.1391 = u32[1,1]{1,0} slice(u32[2,2]{1,0} %reshape.3368), slice={[1:2], [0:1]}
  %reshape.3367 = u32[] reshape(u32[1,1]{1,0} %slice.1391), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %broadcast.2432 = u32[3]{0} broadcast(u32[] %reshape.3367), dimensions={}, metadata={op_type="add" op_name="add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %add.4369 = u32[3]{0} add(u32[3]{0} %slice.1392, u32[3]{0} %broadcast.2432), metadata={op_type="add" op_name="add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.617 (param_0.1323: u32[4]) -> u32[] {
  %param_0.1323 = u32[4]{0} parameter(0)
  %reshape.3370 = u32[2,2]{1,0} reshape(u32[4]{0} %param_0.1323), metadata={op_type="reshape" op_name="pmap(_multi_device_update_fn)/jit(_split)/reshape[ dimensions=None\n                                                   new_sizes=(2, 2) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %slice.1393 = u32[1,1]{1,0} slice(u32[2,2]{1,0} %reshape.3370), slice={[1:2], [0:1]}
  ROOT %reshape.3369 = u32[] reshape(u32[1,1]{1,0} %slice.1393), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
}

%fused_computation.618 (param_0.1326: u32[4]) -> u32[] {
  %param_0.1326 = u32[4]{0} parameter(0)
  %reshape.3374 = u32[2,2]{1,0} reshape(u32[4]{0} %param_0.1326), metadata={op_type="reshape" op_name="pmap(_multi_device_update_fn)/jit(_split)/reshape[ dimensions=None\n                                                   new_sizes=(2, 2) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %slice.1396 = u32[1,1]{1,0} slice(u32[2,2]{1,0} %reshape.3374), slice={[1:2], [0:1]}
  %reshape.3373 = u32[] reshape(u32[1,1]{1,0} %slice.1396), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %slice.1395 = u32[1,2]{1,0} slice(u32[2,2]{1,0} %reshape.3374), slice={[1:2], [0:2]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/slice[ limit_indices=(2, 2)\n                                     start_indices=(1, 0)\n                                     strides=(1, 1) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/combinators.py" source_line=86}
  %reshape.3372 = u32[2]{0} reshape(u32[1,2]{1,0} %slice.1395), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/combinators.py" source_line=86}
  %slice.1394 = u32[1]{0} slice(u32[2]{0} %reshape.3372), slice={[1:2]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/slice[ limit_indices=(2,)\n                                                                    start_indices=(1,)\n                                                                    strides=(1,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %reshape.3371 = u32[] reshape(u32[1]{0} %slice.1394), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %xor.349 = u32[] xor(u32[] %reshape.3373, u32[] %reshape.3371), metadata={op_type="xor" op_name="xor" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant.21312 = u32[] constant(466688986), metadata={op_type="xor" op_name="xor" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %xor.348 = u32[] xor(u32[] %xor.349, u32[] %constant.21312), metadata={op_type="xor" op_name="xor" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.619 (param_0.1330: u32[4]) -> u32[2] {
  %iota.56 = u32[4]{0} iota(), iota_dimension=0, metadata={op_type="iota" op_name="pmap(_multi_device_update_fn)/jit(_split)/iota[ dimension=0\n                                                dtype=uint32\n                                                shape=(4,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %slice.1399 = u32[2]{0} slice(u32[4]{0} %iota.56), slice={[2:4]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/slice[ limit_indices=(4,)\n                                                                    start_indices=(2,)\n                                                                    strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %param_0.1330 = u32[4]{0} parameter(0)
  %reshape.3377 = u32[2,2]{1,0} reshape(u32[4]{0} %param_0.1330), metadata={op_type="reshape" op_name="pmap(_multi_device_update_fn)/jit(_split)/reshape[ dimensions=None\n                                                   new_sizes=(2, 2) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %slice.1398 = u32[1,2]{1,0} slice(u32[2,2]{1,0} %reshape.3377), slice={[1:2], [0:2]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/slice[ limit_indices=(2, 2)\n                                     start_indices=(1, 0)\n                                     strides=(1, 1) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/combinators.py" source_line=86}
  %reshape.3376 = u32[2]{0} reshape(u32[1,2]{1,0} %slice.1398), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/combinators.py" source_line=86}
  %slice.1397 = u32[1]{0} slice(u32[2]{0} %reshape.3376), slice={[1:2]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/slice[ limit_indices=(2,)\n                                                                    start_indices=(1,)\n                                                                    strides=(1,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %reshape.3375 = u32[] reshape(u32[1]{0} %slice.1397), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %broadcast.2433 = u32[2]{0} broadcast(u32[] %reshape.3375), dimensions={}, metadata={op_type="add" op_name="add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %add.4370 = u32[2]{0} add(u32[2]{0} %slice.1399, u32[2]{0} %broadcast.2433), metadata={op_type="add" op_name="add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.620 (param_0.1335: u32[4]) -> u32[] {
  %param_0.1335 = u32[4]{0} parameter(0)
  %reshape.3380 = u32[2,2]{1,0} reshape(u32[4]{0} %param_0.1335), metadata={op_type="reshape" op_name="pmap(_multi_device_update_fn)/jit(_split)/reshape[ dimensions=None\n                                                   new_sizes=(2, 2) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %slice.1401 = u32[1,2]{1,0} slice(u32[2,2]{1,0} %reshape.3380), slice={[1:2], [0:2]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/slice[ limit_indices=(2, 2)\n                                     start_indices=(1, 0)\n                                     strides=(1, 1) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/combinators.py" source_line=86}
  %reshape.3379 = u32[2]{0} reshape(u32[1,2]{1,0} %slice.1401), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/combinators.py" source_line=86}
  %slice.1400 = u32[1]{0} slice(u32[2]{0} %reshape.3379), slice={[1:2]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/slice[ limit_indices=(2,)\n                                                                    start_indices=(1,)\n                                                                    strides=(1,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  ROOT %reshape.3378 = u32[] reshape(u32[1]{0} %slice.1400), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
}

%fused_computation.621 (param_0.1337: u32[4]) -> u32[2] {
  %iota.57 = u32[4]{0} iota(), iota_dimension=0, metadata={op_type="iota" op_name="pmap(_multi_device_update_fn)/jit(_split)/iota[ dimension=0\n                                                dtype=uint32\n                                                shape=(4,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %slice.1403 = u32[2]{0} slice(u32[4]{0} %iota.57), slice={[0:2]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/slice[ limit_indices=(2,)\n                                                                    start_indices=(0,)\n                                                                    strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %param_0.1337 = u32[4]{0} parameter(0)
  %reshape.3383 = u32[2,2]{1,0} reshape(u32[4]{0} %param_0.1337), metadata={op_type="reshape" op_name="pmap(_multi_device_update_fn)/jit(_split)/reshape[ dimensions=None\n                                                   new_sizes=(2, 2) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %slice.1402 = u32[1,1]{1,0} slice(u32[2,2]{1,0} %reshape.3383), slice={[1:2], [0:1]}
  %reshape.3381 = u32[] reshape(u32[1,1]{1,0} %slice.1402), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %broadcast.2434 = u32[2]{0} broadcast(u32[] %reshape.3381), dimensions={}, metadata={op_type="add" op_name="add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %add.4371 = u32[2]{0} add(u32[2]{0} %slice.1403, u32[2]{0} %broadcast.2434), metadata={op_type="add" op_name="add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.622 (param_0.1340: u32[4]) -> u32[] {
  %param_0.1340 = u32[4]{0} parameter(0)
  %reshape.3385 = u32[2,2]{1,0} reshape(u32[4]{0} %param_0.1340), metadata={op_type="reshape" op_name="pmap(_multi_device_update_fn)/jit(_split)/reshape[ dimensions=None\n                                                   new_sizes=(2, 2) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %slice.1404 = u32[1,1]{1,0} slice(u32[2,2]{1,0} %reshape.3385), slice={[1:2], [0:1]}
  ROOT %reshape.3384 = u32[] reshape(u32[1,1]{1,0} %slice.1404), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
}

%fused_computation.623 (param_0.1343: u32[2]) -> u32[] {
  %param_0.1343 = u32[2]{0} parameter(0)
  %slice.1406 = u32[1]{0} slice(u32[2]{0} %param_0.1343), slice={[0:1]}
  %reshape.3388 = u32[] reshape(u32[1]{0} %slice.1406), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %slice.1405 = u32[1]{0} slice(u32[2]{0} %param_0.1343), slice={[1:2]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/slice[ limit_indices=(2,)\n                                                                    start_indices=(1,)\n                                                                    strides=(1,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %reshape.3386 = u32[] reshape(u32[1]{0} %slice.1405), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %xor.351 = u32[] xor(u32[] %reshape.3388, u32[] %reshape.3386), metadata={op_type="xor" op_name="xor" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant.21314 = u32[] constant(466688986), metadata={op_type="xor" op_name="xor" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %xor.350 = u32[] xor(u32[] %xor.351, u32[] %constant.21314), metadata={op_type="xor" op_name="xor" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.624 (param_0.1345: u32[2]) -> u32[2] {
  %iota.58 = u32[4]{0} iota(), iota_dimension=0, metadata={op_type="iota" op_name="pmap(_multi_device_update_fn)/jit(_split)/iota[ dimension=0\n                                                dtype=uint32\n                                                shape=(4,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %slice.1410 = u32[2]{0} slice(u32[4]{0} %iota.58), slice={[2:4]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/slice[ limit_indices=(4,)\n                                                                    start_indices=(2,)\n                                                                    strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %param_0.1345 = u32[2]{0} parameter(0)
  %slice.1407 = u32[1]{0} slice(u32[2]{0} %param_0.1345), slice={[1:2]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/slice[ limit_indices=(2,)\n                                                                    start_indices=(1,)\n                                                                    strides=(1,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %reshape.3390 = u32[] reshape(u32[1]{0} %slice.1407), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %broadcast.2435 = u32[2]{0} broadcast(u32[] %reshape.3390), dimensions={}, metadata={op_type="add" op_name="add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %add.4372 = u32[2]{0} add(u32[2]{0} %slice.1410, u32[2]{0} %broadcast.2435), metadata={op_type="add" op_name="add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.625 (param_0.1347: u32[2]) -> u32[] {
  %param_0.1347 = u32[2]{0} parameter(0)
  %slice.1411 = u32[1]{0} slice(u32[2]{0} %param_0.1347), slice={[1:2]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/slice[ limit_indices=(2,)\n                                                                    start_indices=(1,)\n                                                                    strides=(1,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  ROOT %reshape.3391 = u32[] reshape(u32[1]{0} %slice.1411), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
}

%fused_computation.626 (param_0.1349: u32[2]) -> u32[2] {
  %iota.59 = u32[4]{0} iota(), iota_dimension=0, metadata={op_type="iota" op_name="pmap(_multi_device_update_fn)/jit(_split)/iota[ dimension=0\n                                                dtype=uint32\n                                                shape=(4,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %slice.1413 = u32[2]{0} slice(u32[4]{0} %iota.59), slice={[0:2]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/slice[ limit_indices=(2,)\n                                                                    start_indices=(0,)\n                                                                    strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %param_0.1349 = u32[2]{0} parameter(0)
  %slice.1412 = u32[1]{0} slice(u32[2]{0} %param_0.1349), slice={[0:1]}
  %reshape.3392 = u32[] reshape(u32[1]{0} %slice.1412), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %broadcast.2436 = u32[2]{0} broadcast(u32[] %reshape.3392), dimensions={}, metadata={op_type="add" op_name="add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %add.4373 = u32[2]{0} add(u32[2]{0} %slice.1413, u32[2]{0} %broadcast.2436), metadata={op_type="add" op_name="add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.627 (param_0.1351: u32[2]) -> u32[] {
  %param_0.1351 = u32[2]{0} parameter(0)
  %slice.1414 = u32[1]{0} slice(u32[2]{0} %param_0.1351), slice={[0:1]}
  ROOT %reshape.3393 = u32[] reshape(u32[1]{0} %slice.1414), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
}

%fused_computation.628 (param_0.1354: u32[22]) -> u32[] {
  %param_0.1354 = u32[22]{0} parameter(0)
  %reshape.3397 = u32[11,2]{1,0} reshape(u32[22]{0} %param_0.1354), metadata={op_type="reshape" op_name="pmap(_multi_device_update_fn)/jit(_split)/reshape[ dimensions=None\n                                                   new_sizes=(11, 2) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %slice.1418 = u32[1,1]{1,0} slice(u32[11,2]{1,0} %reshape.3397), slice={[3:4], [0:1]}
  %reshape.3396 = u32[] reshape(u32[1,1]{1,0} %slice.1418), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %slice.1417 = u32[1,2]{1,0} slice(u32[11,2]{1,0} %reshape.3397), slice={[3:4], [0:2]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/slice[ limit_indices=(4, 2)\n                                     start_indices=(3, 0)\n                                     strides=(1, 1) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/combinators.py" source_line=86}
  %reshape.3395 = u32[2]{0} reshape(u32[1,2]{1,0} %slice.1417), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/combinators.py" source_line=86}
  %slice.1416 = u32[1]{0} slice(u32[2]{0} %reshape.3395), slice={[1:2]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/slice[ limit_indices=(2,)\n                                                                    start_indices=(1,)\n                                                                    strides=(1,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %reshape.3394 = u32[] reshape(u32[1]{0} %slice.1416), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %xor.353 = u32[] xor(u32[] %reshape.3396, u32[] %reshape.3394), metadata={op_type="xor" op_name="xor" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant.21315 = u32[] constant(466688986), metadata={op_type="xor" op_name="xor" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %xor.352 = u32[] xor(u32[] %xor.353, u32[] %constant.21315), metadata={op_type="xor" op_name="xor" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.629 (param_0.1358: u32[22]) -> u32[2] {
  %iota.60 = u32[4]{0} iota(), iota_dimension=0, metadata={op_type="iota" op_name="pmap(_multi_device_update_fn)/jit(_split)/iota[ dimension=0\n                                                dtype=uint32\n                                                shape=(4,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %slice.1421 = u32[2]{0} slice(u32[4]{0} %iota.60), slice={[2:4]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/slice[ limit_indices=(4,)\n                                                                    start_indices=(2,)\n                                                                    strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %param_0.1358 = u32[22]{0} parameter(0)
  %reshape.3402 = u32[11,2]{1,0} reshape(u32[22]{0} %param_0.1358), metadata={op_type="reshape" op_name="pmap(_multi_device_update_fn)/jit(_split)/reshape[ dimensions=None\n                                                   new_sizes=(11, 2) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %slice.1420 = u32[1,2]{1,0} slice(u32[11,2]{1,0} %reshape.3402), slice={[3:4], [0:2]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/slice[ limit_indices=(4, 2)\n                                     start_indices=(3, 0)\n                                     strides=(1, 1) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/combinators.py" source_line=86}
  %reshape.3400 = u32[2]{0} reshape(u32[1,2]{1,0} %slice.1420), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/combinators.py" source_line=86}
  %slice.1419 = u32[1]{0} slice(u32[2]{0} %reshape.3400), slice={[1:2]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/slice[ limit_indices=(2,)\n                                                                    start_indices=(1,)\n                                                                    strides=(1,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %reshape.3398 = u32[] reshape(u32[1]{0} %slice.1419), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %broadcast.2437 = u32[2]{0} broadcast(u32[] %reshape.3398), dimensions={}, metadata={op_type="add" op_name="add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %add.4374 = u32[2]{0} add(u32[2]{0} %slice.1421, u32[2]{0} %broadcast.2437), metadata={op_type="add" op_name="add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.630 (param_0.1363: u32[22]) -> u32[] {
  %param_0.1363 = u32[22]{0} parameter(0)
  %reshape.3405 = u32[11,2]{1,0} reshape(u32[22]{0} %param_0.1363), metadata={op_type="reshape" op_name="pmap(_multi_device_update_fn)/jit(_split)/reshape[ dimensions=None\n                                                   new_sizes=(11, 2) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %slice.1423 = u32[1,2]{1,0} slice(u32[11,2]{1,0} %reshape.3405), slice={[3:4], [0:2]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/slice[ limit_indices=(4, 2)\n                                     start_indices=(3, 0)\n                                     strides=(1, 1) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/combinators.py" source_line=86}
  %reshape.3404 = u32[2]{0} reshape(u32[1,2]{1,0} %slice.1423), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/combinators.py" source_line=86}
  %slice.1422 = u32[1]{0} slice(u32[2]{0} %reshape.3404), slice={[1:2]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/slice[ limit_indices=(2,)\n                                                                    start_indices=(1,)\n                                                                    strides=(1,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  ROOT %reshape.3403 = u32[] reshape(u32[1]{0} %slice.1422), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
}

%fused_computation.631 (param_0.1365: u32[22]) -> u32[2] {
  %iota.61 = u32[4]{0} iota(), iota_dimension=0, metadata={op_type="iota" op_name="pmap(_multi_device_update_fn)/jit(_split)/iota[ dimension=0\n                                                dtype=uint32\n                                                shape=(4,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %slice.1425 = u32[2]{0} slice(u32[4]{0} %iota.61), slice={[0:2]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/slice[ limit_indices=(2,)\n                                                                    start_indices=(0,)\n                                                                    strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %param_0.1365 = u32[22]{0} parameter(0)
  %reshape.3407 = u32[11,2]{1,0} reshape(u32[22]{0} %param_0.1365), metadata={op_type="reshape" op_name="pmap(_multi_device_update_fn)/jit(_split)/reshape[ dimensions=None\n                                                   new_sizes=(11, 2) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %slice.1424 = u32[1,1]{1,0} slice(u32[11,2]{1,0} %reshape.3407), slice={[3:4], [0:1]}
  %reshape.3406 = u32[] reshape(u32[1,1]{1,0} %slice.1424), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %broadcast.2438 = u32[2]{0} broadcast(u32[] %reshape.3406), dimensions={}, metadata={op_type="add" op_name="add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %add.4375 = u32[2]{0} add(u32[2]{0} %slice.1425, u32[2]{0} %broadcast.2438), metadata={op_type="add" op_name="add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.632 (param_0.1368: u32[22]) -> u32[] {
  %param_0.1368 = u32[22]{0} parameter(0)
  %reshape.3409 = u32[11,2]{1,0} reshape(u32[22]{0} %param_0.1368), metadata={op_type="reshape" op_name="pmap(_multi_device_update_fn)/jit(_split)/reshape[ dimensions=None\n                                                   new_sizes=(11, 2) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %slice.1426 = u32[1,1]{1,0} slice(u32[11,2]{1,0} %reshape.3409), slice={[3:4], [0:1]}
  ROOT %reshape.3408 = u32[] reshape(u32[1,1]{1,0} %slice.1426), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
}

%fused_computation.633 (param_0.1371: u32[2]) -> u32[] {
  %param_0.1371 = u32[2]{0} parameter(0)
  %slice.1429 = u32[1]{0} slice(u32[2]{0} %param_0.1371), slice={[0:1]}
  %reshape.3411 = u32[] reshape(u32[1]{0} %slice.1429), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %slice.1427 = u32[1]{0} slice(u32[2]{0} %param_0.1371), slice={[1:2]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/slice[ limit_indices=(2,)\n                                                                    start_indices=(1,)\n                                                                    strides=(1,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %reshape.3410 = u32[] reshape(u32[1]{0} %slice.1427), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %xor.355 = u32[] xor(u32[] %reshape.3411, u32[] %reshape.3410), metadata={op_type="xor" op_name="xor" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant.21316 = u32[] constant(466688986), metadata={op_type="xor" op_name="xor" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %xor.354 = u32[] xor(u32[] %xor.355, u32[] %constant.21316), metadata={op_type="xor" op_name="xor" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.634 (param_0.1373: u32[2]) -> u32[11] {
  %iota.62 = u32[22]{0} iota(), iota_dimension=0, metadata={op_type="iota" op_name="pmap(_multi_device_update_fn)/jit(_split)/iota[ dimension=0\n                                                dtype=uint32\n                                                shape=(22,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %slice.1431 = u32[11]{0} slice(u32[22]{0} %iota.62), slice={[11:22]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/slice[ limit_indices=(22,)\n                                                                    start_indices=(11,)\n                                                                    strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %param_0.1373 = u32[2]{0} parameter(0)
  %slice.1430 = u32[1]{0} slice(u32[2]{0} %param_0.1373), slice={[1:2]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/slice[ limit_indices=(2,)\n                                                                    start_indices=(1,)\n                                                                    strides=(1,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %reshape.3412 = u32[] reshape(u32[1]{0} %slice.1430), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %broadcast.2439 = u32[11]{0} broadcast(u32[] %reshape.3412), dimensions={}, metadata={op_type="add" op_name="add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %add.4376 = u32[11]{0} add(u32[11]{0} %slice.1431, u32[11]{0} %broadcast.2439), metadata={op_type="add" op_name="add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.635 (param_0.1375: u32[2]) -> u32[] {
  %param_0.1375 = u32[2]{0} parameter(0)
  %slice.1432 = u32[1]{0} slice(u32[2]{0} %param_0.1375), slice={[1:2]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/slice[ limit_indices=(2,)\n                                                                    start_indices=(1,)\n                                                                    strides=(1,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  ROOT %reshape.3413 = u32[] reshape(u32[1]{0} %slice.1432), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
}

%fused_computation.636 (param_0.1377: u32[2]) -> u32[11] {
  %iota.63 = u32[22]{0} iota(), iota_dimension=0, metadata={op_type="iota" op_name="pmap(_multi_device_update_fn)/jit(_split)/iota[ dimension=0\n                                                dtype=uint32\n                                                shape=(22,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %slice.1434 = u32[11]{0} slice(u32[22]{0} %iota.63), slice={[0:11]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/slice[ limit_indices=(11,)\n                                                                    start_indices=(0,)\n                                                                    strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %param_0.1377 = u32[2]{0} parameter(0)
  %slice.1433 = u32[1]{0} slice(u32[2]{0} %param_0.1377), slice={[0:1]}
  %reshape.3414 = u32[] reshape(u32[1]{0} %slice.1433), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %broadcast.2440 = u32[11]{0} broadcast(u32[] %reshape.3414), dimensions={}, metadata={op_type="add" op_name="add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %add.4377 = u32[11]{0} add(u32[11]{0} %slice.1434, u32[11]{0} %broadcast.2440), metadata={op_type="add" op_name="add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.637 (param_0.1379: u32[2]) -> u32[] {
  %param_0.1379 = u32[2]{0} parameter(0)
  %slice.1435 = u32[1]{0} slice(u32[2]{0} %param_0.1379), slice={[0:1]}
  ROOT %reshape.3415 = u32[] reshape(u32[1]{0} %slice.1435), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
}

%fused_computation.638 (param_0.1383: u32[2]) -> u32[] {
  %param_0.1383 = u32[2]{0} parameter(0)
  %slice.1437 = u32[1]{0} slice(u32[2]{0} %param_0.1383), slice={[0:1]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/slice[ limit_indices=(1,)\n                                                                    start_indices=(0,)\n                                                                    strides=(1,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %reshape.3417 = u32[] reshape(u32[1]{0} %slice.1437), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %slice.1436 = u32[1]{0} slice(u32[2]{0} %param_0.1383), slice={[1:2]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/slice[ limit_indices=(2,)\n                                                                    start_indices=(1,)\n                                                                    strides=(1,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %reshape.3416 = u32[] reshape(u32[1]{0} %slice.1436), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %xor.357 = u32[] xor(u32[] %reshape.3417, u32[] %reshape.3416), metadata={op_type="xor" op_name="xor" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %constant.21317 = u32[] constant(466688986), metadata={op_type="xor" op_name="xor" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %xor.356 = u32[] xor(u32[] %xor.357, u32[] %constant.21317), metadata={op_type="xor" op_name="xor" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.639 (param_0.1385: u32[2]) -> u32[2] {
  %iota.64 = u32[4]{0} iota(), iota_dimension=0, metadata={op_type="iota" op_name="pmap(_multi_device_update_fn)/jit(_split)/iota[ dimension=0\n                                                dtype=uint32\n                                                shape=(4,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %slice.1439 = u32[2]{0} slice(u32[4]{0} %iota.64), slice={[2:4]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/slice[ limit_indices=(4,)\n                                                                    start_indices=(2,)\n                                                                    strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %param_0.1385 = u32[2]{0} parameter(0)
  %slice.1438 = u32[1]{0} slice(u32[2]{0} %param_0.1385), slice={[1:2]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/slice[ limit_indices=(2,)\n                                                                    start_indices=(1,)\n                                                                    strides=(1,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %reshape.3418 = u32[] reshape(u32[1]{0} %slice.1438), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %broadcast.2441 = u32[2]{0} broadcast(u32[] %reshape.3418), dimensions={}, metadata={op_type="add" op_name="add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %add.4378 = u32[2]{0} add(u32[2]{0} %slice.1439, u32[2]{0} %broadcast.2441), metadata={op_type="add" op_name="add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.640 (param_0.1387: u32[2]) -> u32[] {
  %param_0.1387 = u32[2]{0} parameter(0)
  %slice.1441 = u32[1]{0} slice(u32[2]{0} %param_0.1387), slice={[1:2]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/slice[ limit_indices=(2,)\n                                                                    start_indices=(1,)\n                                                                    strides=(1,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  ROOT %reshape.3419 = u32[] reshape(u32[1]{0} %slice.1441), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
}

%fused_computation.641 (param_0.1389: u32[2]) -> u32[2] {
  %iota.65 = u32[4]{0} iota(), iota_dimension=0, metadata={op_type="iota" op_name="pmap(_multi_device_update_fn)/jit(_split)/iota[ dimension=0\n                                                dtype=uint32\n                                                shape=(4,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %slice.1443 = u32[2]{0} slice(u32[4]{0} %iota.65), slice={[0:2]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/slice[ limit_indices=(2,)\n                                                                    start_indices=(0,)\n                                                                    strides=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %param_0.1389 = u32[2]{0} parameter(0)
  %slice.1442 = u32[1]{0} slice(u32[2]{0} %param_0.1389), slice={[0:1]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/slice[ limit_indices=(1,)\n                                                                    start_indices=(0,)\n                                                                    strides=(1,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %reshape.3420 = u32[] reshape(u32[1]{0} %slice.1442), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %broadcast.2442 = u32[2]{0} broadcast(u32[] %reshape.3420), dimensions={}, metadata={op_type="add" op_name="add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  ROOT %add.4379 = u32[2]{0} add(u32[2]{0} %slice.1443, u32[2]{0} %broadcast.2442), metadata={op_type="add" op_name="add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%fused_computation.642 (param_0.1391: u32[2]) -> u32[] {
  %param_0.1391 = u32[2]{0} parameter(0)
  %slice.1444 = u32[1]{0} slice(u32[2]{0} %param_0.1391), slice={[0:1]}, metadata={op_type="slice" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/slice[ limit_indices=(1,)\n                                                                    start_indices=(0,)\n                                                                    strides=(1,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  ROOT %reshape.3421 = u32[] reshape(u32[1]{0} %slice.1444), metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
}

%fused_computation.645 (param_0.1399: f32[]) -> f32[] {
  %constant.21322 = f32[] constant(1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/metrics.py" source_line=617}
  %param_0.1399 = f32[] parameter(0)
  %constant.21321 = f32[] constant(0.0625)
  %multiply.2112 = f32[] multiply(f32[] %param_0.1399, f32[] %constant.21321), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/metrics.py" source_line=108}
  ROOT %divide.273 = f32[] divide(f32[] %constant.21322, f32[] %multiply.2112), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/metrics.py" source_line=617}
}

%fused_computation.646 (param_0.1402: f32[32,1]) -> f32[] {
  %param_0.1402 = f32[32,1]{1,0} parameter(0)
  %constant.21325 = f32[] constant(0)
  %reduce.341 = f32[] reduce(f32[32,1]{1,0} %param_0.1402, f32[] %constant.21325), dimensions={0,1}, to_apply=%primitive_computation_add__1.18530, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0, 1) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %constant.21323 = f32[] constant(3.05175796e-08)
  %multiply.2113 = f32[] multiply(f32[] %reduce.341, f32[] %constant.21323), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  ROOT %sqrt.59 = f32[] sqrt(f32[] %multiply.2113), metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
}

%fused_computation.647 (param_0.1405: s32[], param_1.2253: f32[], param_2.1913: s32[]) -> f32[] {
  %param_1.2253 = f32[] parameter(1)
  %param_0.1405 = s32[] parameter(0)
  %param_2.1913 = s32[] parameter(2)
  %subtract.709 = s32[] subtract(s32[] %param_0.1405, s32[] %param_2.1913), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=115}
  %convert.81 = f32[] convert(s32[] %subtract.709), metadata={op_type="convert_element_type" op_name="pmap(_multi_device_update_fn)/convert_element_type[ new_dtype=float32\n                                                    weak_type=True ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=115}
  %constant.21326 = f32[] constant(0)
  %maximum.66 = f32[] maximum(f32[] %convert.81, f32[] %constant.21326), metadata={op_type="max" op_name="pmap(_multi_device_update_fn)/max" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=115}
  %multiply.2114 = f32[] multiply(f32[] %param_1.2253, f32[] %maximum.66), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=115}
  %convert.80 = f32[] convert(s32[] %param_0.1405), metadata={op_type="convert_element_type" op_name="pmap(_multi_device_update_fn)/convert_element_type[ new_dtype=float32\n                                                    weak_type=True ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=116}
  %maximum.65 = f32[] maximum(f32[] %convert.80, f32[] %constant.21326), metadata={op_type="max" op_name="pmap(_multi_device_update_fn)/max" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=116}
  ROOT %divide.274 = f32[] divide(f32[] %multiply.2114, f32[] %maximum.65), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=115}
}

%parallel_broadcast.5943 (p: f32[]) -> f32[64,8,1024] {
  %p = f32[] parameter(0)
  ROOT %broadcast.5943.clone = f32[64,8,1024]{2,1,0} broadcast(f32[] %p), dimensions={}, outer_dimension_partitions={8}, metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/broadcast_in_dim[ broadcast_dimensions=(  )\n                                                     shape=(64, 8, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%parallel_broadcast.5949 (p.1: f32[]) -> f32[64,8,2048] {
  %p.1 = f32[] parameter(0)
  ROOT %broadcast.5949.clone = f32[64,8,2048]{2,1,0} broadcast(f32[] %p.1), dimensions={}, outer_dimension_partitions={9}, metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/scan/broadcast_in_dim[ broadcast_dimensions=(  )\n                                                     shape=(64, 8, 2048) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
}

%parallel_negate.13245 (p.2: f32[8,64,256]) -> f32[8,64,256] {
  %p.2 = f32[8,64,256]{2,1,0} parameter(0)
  ROOT %negate.13245.clone = f32[8,64,256]{2,1,0} negate(f32[8,64,256]{2,1,0} %p.2), outer_dimension_partitions={2}, metadata={op_type="neg" op_name="pmap(_multi_device_update_fn)/neg" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/core.py" source_line=794}
}

%parallel_broadcast.17492 (p.3: f32[]) -> f32[32000,1024] {
  %p.3 = f32[] parameter(0)
  ROOT %broadcast.17492.clone = f32[32000,1024]{1,0} broadcast(f32[] %p.3), dimensions={}, outer_dimension_partitions={9}, metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/broadcast_in_dim[ broadcast_dimensions=(  )\n                                                shape=(32000, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/core.py" source_line=182}
}

%parallel_broadcast.18033 (p.4: f32[]) -> f32[256,1024] {
  %p.4 = f32[] parameter(0)
  ROOT %broadcast.18033.clone = f32[256,1024]{1,0} broadcast(f32[] %p.4), dimensions={}, outer_dimension_partitions={4}, metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/broadcast_in_dim[ broadcast_dimensions=(  )\n                                                shape=(256, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/core.py" source_line=182}
}

%parallel_multiply.18528 (p.5: f32[32000,1024]) -> f32[32000,1024] {
  %p.5 = f32[32000,1024]{1,0} parameter(0)
  ROOT %multiply.18528.clone = f32[32000,1024]{1,0} multiply(f32[32000,1024]{1,0} %p.5, f32[32000,1024]{1,0} %p.5), outer_dimension_partitions={9}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
}

%parallel_multiply.18654 (p.6: f32[2048,4096]) -> f32[2048,4096] {
  %p.6 = f32[2048,4096]{1,0} parameter(0)
  ROOT %multiply.18654.clone = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %p.6, f32[2048,4096]{1,0} %p.6), outer_dimension_partitions={9}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
}

%parallel_multiply.18858 (p.7: f32[2048,4096]) -> f32[2048,4096] {
  %p.7 = f32[2048,4096]{1,0} parameter(0)
  ROOT %multiply.18858.clone = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %p.7, f32[2048,4096]{1,0} %p.7), outer_dimension_partitions={9}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
}

%parallel_multiply.19062 (p.8: f32[2048,4096]) -> f32[2048,4096] {
  %p.8 = f32[2048,4096]{1,0} parameter(0)
  ROOT %multiply.19062.clone = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %p.8, f32[2048,4096]{1,0} %p.8), outer_dimension_partitions={9}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
}

%parallel_multiply.19266 (p.9: f32[2048,4096]) -> f32[2048,4096] {
  %p.9 = f32[2048,4096]{1,0} parameter(0)
  ROOT %multiply.19266.clone = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %p.9, f32[2048,4096]{1,0} %p.9), outer_dimension_partitions={9}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
}

%parallel_multiply.19470 (p.10: f32[256,1024]) -> f32[256,1024] {
  %p.10 = f32[256,1024]{1,0} parameter(0)
  ROOT %multiply.19470.clone = f32[256,1024]{1,0} multiply(f32[256,1024]{1,0} %p.10, f32[256,1024]{1,0} %p.10), outer_dimension_partitions={4}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
}

%parallel_multiply.19596 (p.11: f32[2048,4096]) -> f32[2048,4096] {
  %p.11 = f32[2048,4096]{1,0} parameter(0)
  ROOT %multiply.19596.clone = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %p.11, f32[2048,4096]{1,0} %p.11), outer_dimension_partitions={9}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
}

%parallel_multiply.19800 (p.12: f32[1024,1024]) -> f32[1024,1024] {
  %p.12 = f32[1024,1024]{1,0} parameter(0)
  ROOT %multiply.19800.clone = f32[1024,1024]{1,0} multiply(f32[1024,1024]{1,0} %p.12, f32[1024,1024]{1,0} %p.12), outer_dimension_partitions={9}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
}

%parallel_multiply.20004 (p.13: f32[1024,1024]) -> f32[1024,1024] {
  %p.13 = f32[1024,1024]{1,0} parameter(0)
  ROOT %multiply.20004.clone = f32[1024,1024]{1,0} multiply(f32[1024,1024]{1,0} %p.13, f32[1024,1024]{1,0} %p.13), outer_dimension_partitions={9}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
}

%parallel_multiply.20208 (p.14: f32[1024,1024]) -> f32[1024,1024] {
  %p.14 = f32[1024,1024]{1,0} parameter(0)
  ROOT %multiply.20208.clone = f32[1024,1024]{1,0} multiply(f32[1024,1024]{1,0} %p.14, f32[1024,1024]{1,0} %p.14), outer_dimension_partitions={9}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
}

%parallel_multiply.20412 (p.15: f32[1024,1024]) -> f32[1024,1024] {
  %p.15 = f32[1024,1024]{1,0} parameter(0)
  ROOT %multiply.20412.clone = f32[1024,1024]{1,0} multiply(f32[1024,1024]{1,0} %p.15, f32[1024,1024]{1,0} %p.15), outer_dimension_partitions={9}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
}

%parallel_multiply.20616 (p.16: f32[2048,4096]) -> f32[2048,4096] {
  %p.16 = f32[2048,4096]{1,0} parameter(0)
  ROOT %multiply.20616.clone = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %p.16, f32[2048,4096]{1,0} %p.16), outer_dimension_partitions={9}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
}

%parallel_multiply.20820 (p.17: f32[2048,4096]) -> f32[2048,4096] {
  %p.17 = f32[2048,4096]{1,0} parameter(0)
  ROOT %multiply.20820.clone = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %p.17, f32[2048,4096]{1,0} %p.17), outer_dimension_partitions={9}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
}

%parallel_multiply.21024 (p.18: f32[2048,4096]) -> f32[2048,4096] {
  %p.18 = f32[2048,4096]{1,0} parameter(0)
  ROOT %multiply.21024.clone = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %p.18, f32[2048,4096]{1,0} %p.18), outer_dimension_partitions={9}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
}

%parallel_multiply.21228 (p.19: f32[2048,4096]) -> f32[2048,4096] {
  %p.19 = f32[2048,4096]{1,0} parameter(0)
  ROOT %multiply.21228.clone = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %p.19, f32[2048,4096]{1,0} %p.19), outer_dimension_partitions={9}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
}

%parallel_multiply.21432 (p.20: f32[1024,256]) -> f32[1024,256] {
  %p.20 = f32[1024,256]{1,0} parameter(0)
  ROOT %multiply.21432.clone = f32[1024,256]{1,0} multiply(f32[1024,256]{1,0} %p.20, f32[1024,256]{1,0} %p.20), outer_dimension_partitions={4}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
}

%parallel_reduce-window.10 (p.21: f32[32000,1024], p.22: f32[]) -> f32[32000,32] {
  %p.21 = f32[32000,1024]{1,0} parameter(0)
  %p.22 = f32[] parameter(1)
  ROOT %reduce-window.10.clone = f32[32000,32]{1,0} reduce-window(f32[32000,1024]{1,0} %p.21, f32[] %p.22), window={size=1x32 stride=1x32}, to_apply=%primitive_computation_add__1.18546, outer_dimension_partitions={9}
}

%parallel_reduce-window.12 (p.23: f32[32000,1024], p.24: f32[]) -> f32[1000,1024] {
  %p.23 = f32[32000,1024]{1,0} parameter(0)
  %p.24 = f32[] parameter(1)
  ROOT %reduce-window.12.clone = f32[1000,1024]{1,0} reduce-window(f32[32000,1024]{1,0} %p.23, f32[] %p.24), window={size=32x1 stride=32x1}, to_apply=%primitive_computation_add__1.18560, outer_dimension_partitions={9}
}

%parallel_reduce-window.15 (p.25: f32[2048,4096], p.26: f32[]) -> f32[2048,128] {
  %p.25 = f32[2048,4096]{1,0} parameter(0)
  %p.26 = f32[] parameter(1)
  ROOT %reduce-window.15.clone = f32[2048,128]{1,0} reduce-window(f32[2048,4096]{1,0} %p.25, f32[] %p.26), window={size=1x32 stride=1x32}, to_apply=%primitive_computation_add__1.18672, outer_dimension_partitions={4}
}

%parallel_reduce-window.17 (p.27: f32[2048,4096], p.28: f32[]) -> f32[64,4096] {
  %p.27 = f32[2048,4096]{1,0} parameter(0)
  %p.28 = f32[] parameter(1)
  ROOT %reduce-window.17.clone = f32[64,4096]{1,0} reduce-window(f32[2048,4096]{1,0} %p.27, f32[] %p.28), window={size=32x1 stride=32x1}, to_apply=%primitive_computation_add__1.18686, outer_dimension_partitions={4}
}

%parallel_reduce-window.22 (p.29: f32[2048,4096], p.30: f32[]) -> f32[2048,128] {
  %p.29 = f32[2048,4096]{1,0} parameter(0)
  %p.30 = f32[] parameter(1)
  ROOT %reduce-window.22.clone = f32[2048,128]{1,0} reduce-window(f32[2048,4096]{1,0} %p.29, f32[] %p.30), window={size=1x32 stride=1x32}, to_apply=%primitive_computation_add__1.18876, outer_dimension_partitions={4}
}

%parallel_reduce-window.24 (p.31: f32[2048,4096], p.32: f32[]) -> f32[64,4096] {
  %p.31 = f32[2048,4096]{1,0} parameter(0)
  %p.32 = f32[] parameter(1)
  ROOT %reduce-window.24.clone = f32[64,4096]{1,0} reduce-window(f32[2048,4096]{1,0} %p.31, f32[] %p.32), window={size=32x1 stride=32x1}, to_apply=%primitive_computation_add__1.18890, outer_dimension_partitions={4}
}

%parallel_reduce-window.29 (p.33: f32[2048,4096], p.34: f32[]) -> f32[2048,128] {
  %p.33 = f32[2048,4096]{1,0} parameter(0)
  %p.34 = f32[] parameter(1)
  ROOT %reduce-window.29.clone = f32[2048,128]{1,0} reduce-window(f32[2048,4096]{1,0} %p.33, f32[] %p.34), window={size=1x32 stride=1x32}, to_apply=%primitive_computation_add__1.19080, outer_dimension_partitions={4}
}

%parallel_reduce-window.31 (p.35: f32[2048,4096], p.36: f32[]) -> f32[64,4096] {
  %p.35 = f32[2048,4096]{1,0} parameter(0)
  %p.36 = f32[] parameter(1)
  ROOT %reduce-window.31.clone = f32[64,4096]{1,0} reduce-window(f32[2048,4096]{1,0} %p.35, f32[] %p.36), window={size=32x1 stride=32x1}, to_apply=%primitive_computation_add__1.19094, outer_dimension_partitions={4}
}

%parallel_reduce-window.36 (p.37: f32[2048,4096], p.38: f32[]) -> f32[2048,128] {
  %p.37 = f32[2048,4096]{1,0} parameter(0)
  %p.38 = f32[] parameter(1)
  ROOT %reduce-window.36.clone = f32[2048,128]{1,0} reduce-window(f32[2048,4096]{1,0} %p.37, f32[] %p.38), window={size=1x32 stride=1x32}, to_apply=%primitive_computation_add__1.19284, outer_dimension_partitions={4}
}

%parallel_reduce-window.38 (p.39: f32[2048,4096], p.40: f32[]) -> f32[64,4096] {
  %p.39 = f32[2048,4096]{1,0} parameter(0)
  %p.40 = f32[] parameter(1)
  ROOT %reduce-window.38.clone = f32[64,4096]{1,0} reduce-window(f32[2048,4096]{1,0} %p.39, f32[] %p.40), window={size=32x1 stride=32x1}, to_apply=%primitive_computation_add__1.19298, outer_dimension_partitions={4}
}

%parallel_reduce-window.48 (p.41: f32[2048,4096], p.42: f32[]) -> f32[2048,128] {
  %p.41 = f32[2048,4096]{1,0} parameter(0)
  %p.42 = f32[] parameter(1)
  ROOT %reduce-window.48.clone = f32[2048,128]{1,0} reduce-window(f32[2048,4096]{1,0} %p.41, f32[] %p.42), window={size=1x32 stride=1x32}, to_apply=%primitive_computation_add__1.19614, outer_dimension_partitions={4}
}

%parallel_reduce-window.50 (p.43: f32[2048,4096], p.44: f32[]) -> f32[64,4096] {
  %p.43 = f32[2048,4096]{1,0} parameter(0)
  %p.44 = f32[] parameter(1)
  ROOT %reduce-window.50.clone = f32[64,4096]{1,0} reduce-window(f32[2048,4096]{1,0} %p.43, f32[] %p.44), window={size=32x1 stride=32x1}, to_apply=%primitive_computation_add__1.19628, outer_dimension_partitions={4}
}

%parallel_reduce-window.83 (p.45: f32[2048,4096], p.46: f32[]) -> f32[2048,128] {
  %p.45 = f32[2048,4096]{1,0} parameter(0)
  %p.46 = f32[] parameter(1)
  ROOT %reduce-window.83.clone = f32[2048,128]{1,0} reduce-window(f32[2048,4096]{1,0} %p.45, f32[] %p.46), window={size=1x32 stride=1x32}, to_apply=%primitive_computation_add__1.20634, outer_dimension_partitions={4}
}

%parallel_reduce-window.85 (p.47: f32[2048,4096], p.48: f32[]) -> f32[64,4096] {
  %p.47 = f32[2048,4096]{1,0} parameter(0)
  %p.48 = f32[] parameter(1)
  ROOT %reduce-window.85.clone = f32[64,4096]{1,0} reduce-window(f32[2048,4096]{1,0} %p.47, f32[] %p.48), window={size=32x1 stride=32x1}, to_apply=%primitive_computation_add__1.20648, outer_dimension_partitions={4}
}

%parallel_reduce-window.90 (p.49: f32[2048,4096], p.50: f32[]) -> f32[2048,128] {
  %p.49 = f32[2048,4096]{1,0} parameter(0)
  %p.50 = f32[] parameter(1)
  ROOT %reduce-window.90.clone = f32[2048,128]{1,0} reduce-window(f32[2048,4096]{1,0} %p.49, f32[] %p.50), window={size=1x32 stride=1x32}, to_apply=%primitive_computation_add__1.20838, outer_dimension_partitions={4}
}

%parallel_reduce-window.92 (p.51: f32[2048,4096], p.52: f32[]) -> f32[64,4096] {
  %p.51 = f32[2048,4096]{1,0} parameter(0)
  %p.52 = f32[] parameter(1)
  ROOT %reduce-window.92.clone = f32[64,4096]{1,0} reduce-window(f32[2048,4096]{1,0} %p.51, f32[] %p.52), window={size=32x1 stride=32x1}, to_apply=%primitive_computation_add__1.20852, outer_dimension_partitions={4}
}

%parallel_reduce-window.97 (p.53: f32[2048,4096], p.54: f32[]) -> f32[2048,128] {
  %p.53 = f32[2048,4096]{1,0} parameter(0)
  %p.54 = f32[] parameter(1)
  ROOT %reduce-window.97.clone = f32[2048,128]{1,0} reduce-window(f32[2048,4096]{1,0} %p.53, f32[] %p.54), window={size=1x32 stride=1x32}, to_apply=%primitive_computation_add__1.21042, outer_dimension_partitions={4}
}

%parallel_reduce-window.99 (p.55: f32[2048,4096], p.56: f32[]) -> f32[64,4096] {
  %p.55 = f32[2048,4096]{1,0} parameter(0)
  %p.56 = f32[] parameter(1)
  ROOT %reduce-window.99.clone = f32[64,4096]{1,0} reduce-window(f32[2048,4096]{1,0} %p.55, f32[] %p.56), window={size=32x1 stride=32x1}, to_apply=%primitive_computation_add__1.21056, outer_dimension_partitions={4}
}

%parallel_reduce-window.104 (p.57: f32[2048,4096], p.58: f32[]) -> f32[2048,128] {
  %p.57 = f32[2048,4096]{1,0} parameter(0)
  %p.58 = f32[] parameter(1)
  ROOT %reduce-window.104.clone = f32[2048,128]{1,0} reduce-window(f32[2048,4096]{1,0} %p.57, f32[] %p.58), window={size=1x32 stride=1x32}, to_apply=%primitive_computation_add__1.21246, outer_dimension_partitions={4}
}

%parallel_reduce-window.106 (p.59: f32[2048,4096], p.60: f32[]) -> f32[64,4096] {
  %p.59 = f32[2048,4096]{1,0} parameter(0)
  %p.60 = f32[] parameter(1)
  ROOT %reduce-window.106.clone = f32[64,4096]{1,0} reduce-window(f32[2048,4096]{1,0} %p.59, f32[] %p.60), window={size=32x1 stride=32x1}, to_apply=%primitive_computation_add__1.21260, outer_dimension_partitions={4}
}

%parallel_broadcast.308 (p.61: f32[]) -> f32[2048,4096] {
  %p.61 = f32[] parameter(0)
  ROOT %broadcast.308.clone = f32[2048,4096]{1,0} broadcast(f32[] %p.61), dimensions={}, outer_dimension_partitions={9}
}

%parallel_copy.26 (p.89: f32[64,8,1024]) -> f32[64,8,1024] {
  %p.89 = f32[64,8,1024]{2,0,1} parameter(0)
  ROOT %copy.26.clone = f32[64,8,1024]{2,1,0} copy(f32[64,8,1024]{2,0,1} %p.89), outer_dimension_partitions={8}
}

%parallel_copy.28 (p.90: f32[64,8,1024]) -> f32[64,8,1024] {
  %p.90 = f32[64,8,1024]{2,0,1} parameter(0)
  ROOT %copy.28.clone = f32[64,8,1024]{2,1,0} copy(f32[64,8,1024]{2,0,1} %p.90), outer_dimension_partitions={8}
}

%parallel_copy.35 (p.91: f32[64,8,1024]) -> f32[64,8,1024] {
  %p.91 = f32[64,8,1024]{2,0,1} parameter(0)
  ROOT %copy.35.clone = f32[64,8,1024]{2,1,0} copy(f32[64,8,1024]{2,0,1} %p.91), outer_dimension_partitions={8}
}

%parallel_copy.41 (p.92: f32[64,8,1024]) -> f32[64,8,1024] {
  %p.92 = f32[64,8,1024]{2,0,1} parameter(0)
  ROOT %copy.41.clone = f32[64,8,1024]{2,1,0} copy(f32[64,8,1024]{2,0,1} %p.92), outer_dimension_partitions={8}
}

%parallel_copy.46 (p.93: f32[64,8,1024]) -> f32[64,8,1024] {
  %p.93 = f32[64,8,1024]{2,0,1} parameter(0)
  ROOT %copy.46.clone = f32[64,8,1024]{2,1,0} copy(f32[64,8,1024]{2,0,1} %p.93), outer_dimension_partitions={8}
}

%parallel_copy.47 (p.94: f32[64,8,1024]) -> f32[64,8,1024] {
  %p.94 = f32[64,8,1024]{2,0,1} parameter(0)
  ROOT %copy.47.clone = f32[64,8,1024]{2,1,0} copy(f32[64,8,1024]{2,0,1} %p.94), outer_dimension_partitions={8}
}

%fused_computation.286.clone (param_0.1408: f32[8,64,1], param_1.2256: f32[8,64], param_2.1916: f32[8,64,1], param_3.1530: f32[8,64], param_4.873: f32[256], param_5.594: f32[512,256], param_6.513: s32[8,64]) -> f32[8,64,256] {
  %param_6.513 = s32[8,64]{1,0} parameter(6)
  %broadcast.2471 = s32[8,64,256]{2,1,0} broadcast(s32[8,64]{1,0} %param_6.513), dimensions={0,1}, metadata={op_type="eq" op_name="pmap(_multi_device_update_fn)/eq" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/core.py" source_line=776}
  %iota.67 = s32[8,64,256]{2,1,0} iota(), iota_dimension=2, metadata={op_type="eq" op_name="pmap(_multi_device_update_fn)/eq" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/core.py" source_line=776}
  %compare.2816 = pred[8,64,256]{2,1,0} compare(s32[8,64,256]{2,1,0} %broadcast.2471, s32[8,64,256]{2,1,0} %iota.67), direction=EQ, metadata={op_type="eq" op_name="pmap(_multi_device_update_fn)/eq" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/core.py" source_line=776}
  %param_5.594 = f32[512,256]{1,0} parameter(5)
  %reshape.3434 = f32[8,64,256]{2,1,0} reshape(f32[512,256]{1,0} %param_5.594), metadata={op_type="dot_general" op_name="pmap(_multi_device_update_fn)/dot_general[ dimension_numbers=(((2,), (0,)), ((), ()))\n                                           precision=None\n                                           preferred_element_type=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/core.py" source_line=96}
  %param_4.873 = f32[256]{0} parameter(4)
  %broadcast.2470 = f32[8,64,256]{2,1,0} broadcast(f32[256]{0} %param_4.873), dimensions={2}, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/core.py" source_line=96}
  %add.4396 = f32[8,64,256]{2,1,0} add(f32[8,64,256]{2,1,0} %reshape.3434, f32[8,64,256]{2,1,0} %broadcast.2470), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/core.py" source_line=96}
  %param_3.1530 = f32[8,64]{1,0} parameter(3)
  %reshape.3432 = f32[8,64,1]{1,0,2} reshape(f32[8,64]{1,0} %param_3.1530), metadata={op_type="log" op_name="pmap(_multi_device_update_fn)/log" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=94}
  %copy.74 = f32[8,64,1]{2,1,0} copy(f32[8,64,1]{1,0,2} %reshape.3432), metadata={op_type="log" op_name="pmap(_multi_device_update_fn)/log" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=94}
  %param_2.1916 = f32[8,64,1]{2,1,0} parameter(2)
  %add.4395 = f32[8,64,1]{2,1,0} add(f32[8,64,1]{2,1,0} %copy.74, f32[8,64,1]{2,1,0} %param_2.1916), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=94}
  %reshape.3433 = f32[8,64]{1,0} reshape(f32[8,64,1]{2,1,0} %add.4395), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/core.py" source_line=794}
  %broadcast.2468 = f32[8,64,256]{2,1,0} broadcast(f32[8,64]{1,0} %reshape.3433), dimensions={0,1}, metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/core.py" source_line=794}
  %subtract.718 = f32[8,64,256]{2,1,0} subtract(f32[8,64,256]{2,1,0} %add.4396, f32[8,64,256]{2,1,0} %broadcast.2468), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/core.py" source_line=794}
  %param_1.2256 = f32[8,64]{1,0} parameter(1)
  %reshape.3430 = f32[8,64,1]{1,0,2} reshape(f32[8,64]{1,0} %param_1.2256), metadata={op_type="log" op_name="pmap(_multi_device_update_fn)/log" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=94}
  %copy.73 = f32[8,64,1]{2,1,0} copy(f32[8,64,1]{1,0,2} %reshape.3430), metadata={op_type="log" op_name="pmap(_multi_device_update_fn)/log" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=94}
  %param_0.1408 = f32[8,64,1]{2,1,0} parameter(0)
  %add.4394 = f32[8,64,1]{2,1,0} add(f32[8,64,1]{2,1,0} %copy.73, f32[8,64,1]{2,1,0} %param_0.1408), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=94}
  %reshape.3431 = f32[8,64]{1,0} reshape(f32[8,64,1]{2,1,0} %add.4394), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/core.py" source_line=794}
  %broadcast.2467 = f32[8,64,256]{2,1,0} broadcast(f32[8,64]{1,0} %reshape.3431), dimensions={0,1}, metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/core.py" source_line=794}
  %subtract.719 = f32[8,64,256]{2,1,0} subtract(f32[8,64,256]{2,1,0} %subtract.718, f32[8,64,256]{2,1,0} %broadcast.2467), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/core.py" source_line=794}
  %constant.21331 = f32[] constant(0)
  %broadcast.2466 = f32[8,64,256]{2,1,0} broadcast(f32[] %constant.21331), dimensions={}
  ROOT %select.2703 = f32[8,64,256]{2,1,0} select(pred[8,64,256]{2,1,0} %compare.2816, f32[8,64,256]{2,1,0} %subtract.719, f32[8,64,256]{2,1,0} %broadcast.2466), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/metrics.py" source_line=581}
}

%parallel_fusion.286 (p.95: f32[8,64,1], p.96: f32[8,64], p.97: f32[8,64,1], p.98: f32[8,64], p.99: f32[256], p.100: f32[512,256], p.101: s32[8,64]) -> f32[8,64,256] {
  %p.95 = f32[8,64,1]{2,1,0} parameter(0)
  %p.96 = f32[8,64]{1,0} parameter(1)
  %p.97 = f32[8,64,1]{2,1,0} parameter(2)
  %p.98 = f32[8,64]{1,0} parameter(3)
  %p.99 = f32[256]{0} parameter(4)
  %p.100 = f32[512,256]{1,0} parameter(5)
  %p.101 = s32[8,64]{1,0} parameter(6)
  ROOT %fusion.286.clone = f32[8,64,256]{2,1,0} fusion(f32[8,64,1]{2,1,0} %p.95, f32[8,64]{1,0} %p.96, f32[8,64,1]{2,1,0} %p.97, f32[8,64]{1,0} %p.98, f32[256]{0} %p.99, /*index=5*/f32[512,256]{1,0} %p.100, s32[8,64]{1,0} %p.101), kind=kLoop, calls=%fused_computation.286.clone, outer_dimension_partitions={2}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/metrics.py" source_line=581}
}

%fused_computation.289.clone (param_0.1409: f32[1024,256]) -> f32[262144] {
  %param_0.1409 = f32[1024,256]{1,0} parameter(0)
  %constant.21332 = f32[] constant(0.0625)
  %broadcast.2473 = f32[1024,256]{1,0} broadcast(f32[] %constant.21332), dimensions={}
  %multiply.2115 = f32[1024,256]{1,0} multiply(f32[1024,256]{1,0} %param_0.1409, f32[1024,256]{1,0} %broadcast.2473), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=200}
  ROOT %reshape.3435 = f32[262144]{0} reshape(f32[1024,256]{1,0} %multiply.2115), metadata={op_type="reshape" op_name="pmap(_multi_device_update_fn)/reshape[ dimensions=None\n                                       new_sizes=(262144,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
}

%parallel_fusion.289 (p.102: f32[1024,256]) -> f32[262144] {
  %p.102 = f32[1024,256]{1,0} parameter(0)
  ROOT %fusion.289.clone = f32[262144]{0} fusion(f32[1024,256]{1,0} %p.102), kind=kLoop, calls=%fused_computation.289.clone, outer_dimension_partitions={4}, metadata={op_type="reshape" op_name="pmap(_multi_device_update_fn)/reshape[ dimensions=None\n                                       new_sizes=(262144,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
}

%fused_computation.292.clone (param_0.1410: f32[2048,4096]) -> f32[8388608] {
  %param_0.1410 = f32[2048,4096]{1,0} parameter(0)
  %constant.21333 = f32[] constant(0.0625)
  %broadcast.2474 = f32[2048,4096]{1,0} broadcast(f32[] %constant.21333), dimensions={}
  %multiply.2116 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %param_0.1410, f32[2048,4096]{1,0} %broadcast.2474), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=200}
  ROOT %reshape.3436 = f32[8388608]{0} reshape(f32[2048,4096]{1,0} %multiply.2116), metadata={op_type="reshape" op_name="pmap(_multi_device_update_fn)/reshape[ dimensions=None\n                                       new_sizes=(8388608,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
}

%parallel_fusion.292 (p.103: f32[2048,4096]) -> f32[8388608] {
  %p.103 = f32[2048,4096]{1,0} parameter(0)
  ROOT %fusion.292.clone = f32[8388608]{0} fusion(f32[2048,4096]{1,0} %p.103), kind=kLoop, calls=%fused_computation.292.clone, outer_dimension_partitions={9}, metadata={op_type="reshape" op_name="pmap(_multi_device_update_fn)/reshape[ dimensions=None\n                                       new_sizes=(8388608,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
}

%fused_computation.295.clone (param_0.1411: f32[2048,4096]) -> f32[8388608] {
  %param_0.1411 = f32[2048,4096]{1,0} parameter(0)
  %constant.21335 = f32[] constant(0.0625)
  %broadcast.2475 = f32[2048,4096]{1,0} broadcast(f32[] %constant.21335), dimensions={}
  %multiply.2117 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %param_0.1411, f32[2048,4096]{1,0} %broadcast.2475), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=200}
  ROOT %reshape.3437 = f32[8388608]{0} reshape(f32[2048,4096]{1,0} %multiply.2117), metadata={op_type="reshape" op_name="pmap(_multi_device_update_fn)/reshape[ dimensions=None\n                                       new_sizes=(8388608,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
}

%parallel_fusion.295 (p.104: f32[2048,4096]) -> f32[8388608] {
  %p.104 = f32[2048,4096]{1,0} parameter(0)
  ROOT %fusion.295.clone = f32[8388608]{0} fusion(f32[2048,4096]{1,0} %p.104), kind=kLoop, calls=%fused_computation.295.clone, outer_dimension_partitions={9}, metadata={op_type="reshape" op_name="pmap(_multi_device_update_fn)/reshape[ dimensions=None\n                                       new_sizes=(8388608,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
}

%fused_computation.298.clone (param_0.1412: f32[2048,4096]) -> f32[8388608] {
  %param_0.1412 = f32[2048,4096]{1,0} parameter(0)
  %constant.21336 = f32[] constant(0.0625)
  %broadcast.2476 = f32[2048,4096]{1,0} broadcast(f32[] %constant.21336), dimensions={}
  %multiply.2118 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %param_0.1412, f32[2048,4096]{1,0} %broadcast.2476), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=200}
  ROOT %reshape.3438 = f32[8388608]{0} reshape(f32[2048,4096]{1,0} %multiply.2118), metadata={op_type="reshape" op_name="pmap(_multi_device_update_fn)/reshape[ dimensions=None\n                                       new_sizes=(8388608,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
}

%parallel_fusion.298 (p.105: f32[2048,4096]) -> f32[8388608] {
  %p.105 = f32[2048,4096]{1,0} parameter(0)
  ROOT %fusion.298.clone = f32[8388608]{0} fusion(f32[2048,4096]{1,0} %p.105), kind=kLoop, calls=%fused_computation.298.clone, outer_dimension_partitions={9}, metadata={op_type="reshape" op_name="pmap(_multi_device_update_fn)/reshape[ dimensions=None\n                                       new_sizes=(8388608,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
}

%fused_computation.301.clone (param_0.1413: f32[2048,4096]) -> f32[8388608] {
  %param_0.1413 = f32[2048,4096]{1,0} parameter(0)
  %constant.21337 = f32[] constant(0.0625)
  %broadcast.2477 = f32[2048,4096]{1,0} broadcast(f32[] %constant.21337), dimensions={}
  %multiply.2119 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %param_0.1413, f32[2048,4096]{1,0} %broadcast.2477), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=200}
  ROOT %reshape.3439 = f32[8388608]{0} reshape(f32[2048,4096]{1,0} %multiply.2119), metadata={op_type="reshape" op_name="pmap(_multi_device_update_fn)/reshape[ dimensions=None\n                                       new_sizes=(8388608,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
}

%parallel_fusion.301 (p.106: f32[2048,4096]) -> f32[8388608] {
  %p.106 = f32[2048,4096]{1,0} parameter(0)
  ROOT %fusion.301.clone = f32[8388608]{0} fusion(f32[2048,4096]{1,0} %p.106), kind=kLoop, calls=%fused_computation.301.clone, outer_dimension_partitions={9}, metadata={op_type="reshape" op_name="pmap(_multi_device_update_fn)/reshape[ dimensions=None\n                                       new_sizes=(8388608,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
}

%fused_computation.304.clone (param_0.1414: f32[1024,1024]) -> f32[1048576] {
  %param_0.1414 = f32[1024,1024]{1,0} parameter(0)
  %constant.21338 = f32[] constant(0.0625)
  %broadcast.2478 = f32[1024,1024]{1,0} broadcast(f32[] %constant.21338), dimensions={}
  %multiply.2120 = f32[1024,1024]{1,0} multiply(f32[1024,1024]{1,0} %param_0.1414, f32[1024,1024]{1,0} %broadcast.2478), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=200}
  ROOT %reshape.3440 = f32[1048576]{0} reshape(f32[1024,1024]{1,0} %multiply.2120), metadata={op_type="reshape" op_name="pmap(_multi_device_update_fn)/reshape[ dimensions=None\n                                       new_sizes=(1048576,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
}

%parallel_fusion.304 (p.107: f32[1024,1024]) -> f32[1048576] {
  %p.107 = f32[1024,1024]{1,0} parameter(0)
  ROOT %fusion.304.clone = f32[1048576]{0} fusion(f32[1024,1024]{1,0} %p.107), kind=kLoop, calls=%fused_computation.304.clone, outer_dimension_partitions={9}, metadata={op_type="reshape" op_name="pmap(_multi_device_update_fn)/reshape[ dimensions=None\n                                       new_sizes=(1048576,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
}

%fused_computation.307.clone (param_0.1415: f32[1024,1024]) -> f32[1048576] {
  %param_0.1415 = f32[1024,1024]{1,0} parameter(0)
  %constant.21339 = f32[] constant(0.0625)
  %broadcast.2479 = f32[1024,1024]{1,0} broadcast(f32[] %constant.21339), dimensions={}
  %multiply.2121 = f32[1024,1024]{1,0} multiply(f32[1024,1024]{1,0} %param_0.1415, f32[1024,1024]{1,0} %broadcast.2479), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=200}
  ROOT %reshape.3441 = f32[1048576]{0} reshape(f32[1024,1024]{1,0} %multiply.2121), metadata={op_type="reshape" op_name="pmap(_multi_device_update_fn)/reshape[ dimensions=None\n                                       new_sizes=(1048576,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
}

%parallel_fusion.307 (p.108: f32[1024,1024]) -> f32[1048576] {
  %p.108 = f32[1024,1024]{1,0} parameter(0)
  ROOT %fusion.307.clone = f32[1048576]{0} fusion(f32[1024,1024]{1,0} %p.108), kind=kLoop, calls=%fused_computation.307.clone, outer_dimension_partitions={9}, metadata={op_type="reshape" op_name="pmap(_multi_device_update_fn)/reshape[ dimensions=None\n                                       new_sizes=(1048576,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
}

%fused_computation.310.clone (param_0.1416: f32[1024,1024]) -> f32[1048576] {
  %param_0.1416 = f32[1024,1024]{1,0} parameter(0)
  %constant.21340 = f32[] constant(0.0625)
  %broadcast.2480 = f32[1024,1024]{1,0} broadcast(f32[] %constant.21340), dimensions={}
  %multiply.2122 = f32[1024,1024]{1,0} multiply(f32[1024,1024]{1,0} %param_0.1416, f32[1024,1024]{1,0} %broadcast.2480), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=200}
  ROOT %reshape.3442 = f32[1048576]{0} reshape(f32[1024,1024]{1,0} %multiply.2122), metadata={op_type="reshape" op_name="pmap(_multi_device_update_fn)/reshape[ dimensions=None\n                                       new_sizes=(1048576,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
}

%parallel_fusion.310 (p.109: f32[1024,1024]) -> f32[1048576] {
  %p.109 = f32[1024,1024]{1,0} parameter(0)
  ROOT %fusion.310.clone = f32[1048576]{0} fusion(f32[1024,1024]{1,0} %p.109), kind=kLoop, calls=%fused_computation.310.clone, outer_dimension_partitions={9}, metadata={op_type="reshape" op_name="pmap(_multi_device_update_fn)/reshape[ dimensions=None\n                                       new_sizes=(1048576,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
}

%fused_computation.313.clone (param_0.1417: f32[1024,1024]) -> f32[1048576] {
  %param_0.1417 = f32[1024,1024]{1,0} parameter(0)
  %constant.21341 = f32[] constant(0.0625)
  %broadcast.2481 = f32[1024,1024]{1,0} broadcast(f32[] %constant.21341), dimensions={}
  %multiply.2123 = f32[1024,1024]{1,0} multiply(f32[1024,1024]{1,0} %param_0.1417, f32[1024,1024]{1,0} %broadcast.2481), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=200}
  ROOT %reshape.3443 = f32[1048576]{0} reshape(f32[1024,1024]{1,0} %multiply.2123), metadata={op_type="reshape" op_name="pmap(_multi_device_update_fn)/reshape[ dimensions=None\n                                       new_sizes=(1048576,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
}

%parallel_fusion.313 (p.110: f32[1024,1024]) -> f32[1048576] {
  %p.110 = f32[1024,1024]{1,0} parameter(0)
  ROOT %fusion.313.clone = f32[1048576]{0} fusion(f32[1024,1024]{1,0} %p.110), kind=kLoop, calls=%fused_computation.313.clone, outer_dimension_partitions={9}, metadata={op_type="reshape" op_name="pmap(_multi_device_update_fn)/reshape[ dimensions=None\n                                       new_sizes=(1048576,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
}

%fused_computation.316.clone (param_0.1418: f32[2048,4096]) -> f32[8388608] {
  %param_0.1418 = f32[2048,4096]{1,0} parameter(0)
  %constant.21343 = f32[] constant(0.0625)
  %broadcast.2483 = f32[2048,4096]{1,0} broadcast(f32[] %constant.21343), dimensions={}
  %multiply.2124 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %param_0.1418, f32[2048,4096]{1,0} %broadcast.2483), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=200}
  ROOT %reshape.3444 = f32[8388608]{0} reshape(f32[2048,4096]{1,0} %multiply.2124), metadata={op_type="reshape" op_name="pmap(_multi_device_update_fn)/reshape[ dimensions=None\n                                       new_sizes=(8388608,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
}

%parallel_fusion.316 (p.111: f32[2048,4096]) -> f32[8388608] {
  %p.111 = f32[2048,4096]{1,0} parameter(0)
  ROOT %fusion.316.clone = f32[8388608]{0} fusion(f32[2048,4096]{1,0} %p.111), kind=kLoop, calls=%fused_computation.316.clone, outer_dimension_partitions={9}, metadata={op_type="reshape" op_name="pmap(_multi_device_update_fn)/reshape[ dimensions=None\n                                       new_sizes=(8388608,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
}

%fused_computation.318.clone (param_0.1419: f32[256,1024]) -> f32[262144] {
  %param_0.1419 = f32[256,1024]{1,0} parameter(0)
  %constant.21344 = f32[] constant(0.0625)
  %broadcast.2484 = f32[256,1024]{1,0} broadcast(f32[] %constant.21344), dimensions={}
  %multiply.2125 = f32[256,1024]{1,0} multiply(f32[256,1024]{1,0} %param_0.1419, f32[256,1024]{1,0} %broadcast.2484), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=200}
  ROOT %reshape.3445 = f32[262144]{0} reshape(f32[256,1024]{1,0} %multiply.2125), metadata={op_type="reshape" op_name="pmap(_multi_device_update_fn)/reshape[ dimensions=None\n                                       new_sizes=(262144,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
}

%parallel_fusion.318 (p.112: f32[256,1024]) -> f32[262144] {
  %p.112 = f32[256,1024]{1,0} parameter(0)
  ROOT %fusion.318.clone = f32[262144]{0} fusion(f32[256,1024]{1,0} %p.112), kind=kLoop, calls=%fused_computation.318.clone, outer_dimension_partitions={4}, metadata={op_type="reshape" op_name="pmap(_multi_device_update_fn)/reshape[ dimensions=None\n                                       new_sizes=(262144,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
}

%fused_computation.321.clone (param_0.1420: f32[2048,4096]) -> f32[8388608] {
  %param_0.1420 = f32[2048,4096]{1,0} parameter(0)
  %constant.21345 = f32[] constant(0.0625)
  %broadcast.2486 = f32[2048,4096]{1,0} broadcast(f32[] %constant.21345), dimensions={}
  %multiply.2126 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %param_0.1420, f32[2048,4096]{1,0} %broadcast.2486), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=200}
  ROOT %reshape.3446 = f32[8388608]{0} reshape(f32[2048,4096]{1,0} %multiply.2126), metadata={op_type="reshape" op_name="pmap(_multi_device_update_fn)/reshape[ dimensions=None\n                                       new_sizes=(8388608,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
}

%parallel_fusion.321 (p.113: f32[2048,4096]) -> f32[8388608] {
  %p.113 = f32[2048,4096]{1,0} parameter(0)
  ROOT %fusion.321.clone = f32[8388608]{0} fusion(f32[2048,4096]{1,0} %p.113), kind=kLoop, calls=%fused_computation.321.clone, outer_dimension_partitions={9}, metadata={op_type="reshape" op_name="pmap(_multi_device_update_fn)/reshape[ dimensions=None\n                                       new_sizes=(8388608,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
}

%fused_computation.324.clone (param_0.1421: f32[2048,4096]) -> f32[8388608] {
  %param_0.1421 = f32[2048,4096]{1,0} parameter(0)
  %constant.21346 = f32[] constant(0.0625)
  %broadcast.2487 = f32[2048,4096]{1,0} broadcast(f32[] %constant.21346), dimensions={}
  %multiply.2127 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %param_0.1421, f32[2048,4096]{1,0} %broadcast.2487), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=200}
  ROOT %reshape.3447 = f32[8388608]{0} reshape(f32[2048,4096]{1,0} %multiply.2127), metadata={op_type="reshape" op_name="pmap(_multi_device_update_fn)/reshape[ dimensions=None\n                                       new_sizes=(8388608,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
}

%parallel_fusion.324 (p.114: f32[2048,4096]) -> f32[8388608] {
  %p.114 = f32[2048,4096]{1,0} parameter(0)
  ROOT %fusion.324.clone = f32[8388608]{0} fusion(f32[2048,4096]{1,0} %p.114), kind=kLoop, calls=%fused_computation.324.clone, outer_dimension_partitions={9}, metadata={op_type="reshape" op_name="pmap(_multi_device_update_fn)/reshape[ dimensions=None\n                                       new_sizes=(8388608,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
}

%fused_computation.327.clone (param_0.1422: f32[2048,4096]) -> f32[8388608] {
  %param_0.1422 = f32[2048,4096]{1,0} parameter(0)
  %constant.21347 = f32[] constant(0.0625)
  %broadcast.2488 = f32[2048,4096]{1,0} broadcast(f32[] %constant.21347), dimensions={}
  %multiply.2128 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %param_0.1422, f32[2048,4096]{1,0} %broadcast.2488), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=200}
  ROOT %reshape.3448 = f32[8388608]{0} reshape(f32[2048,4096]{1,0} %multiply.2128), metadata={op_type="reshape" op_name="pmap(_multi_device_update_fn)/reshape[ dimensions=None\n                                       new_sizes=(8388608,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
}

%parallel_fusion.327 (p.115: f32[2048,4096]) -> f32[8388608] {
  %p.115 = f32[2048,4096]{1,0} parameter(0)
  ROOT %fusion.327.clone = f32[8388608]{0} fusion(f32[2048,4096]{1,0} %p.115), kind=kLoop, calls=%fused_computation.327.clone, outer_dimension_partitions={9}, metadata={op_type="reshape" op_name="pmap(_multi_device_update_fn)/reshape[ dimensions=None\n                                       new_sizes=(8388608,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
}

%fused_computation.330.clone (param_0.1423: f32[2048,4096]) -> f32[8388608] {
  %param_0.1423 = f32[2048,4096]{1,0} parameter(0)
  %constant.21349 = f32[] constant(0.0625)
  %broadcast.2489 = f32[2048,4096]{1,0} broadcast(f32[] %constant.21349), dimensions={}
  %multiply.2129 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %param_0.1423, f32[2048,4096]{1,0} %broadcast.2489), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=200}
  ROOT %reshape.3449 = f32[8388608]{0} reshape(f32[2048,4096]{1,0} %multiply.2129), metadata={op_type="reshape" op_name="pmap(_multi_device_update_fn)/reshape[ dimensions=None\n                                       new_sizes=(8388608,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
}

%parallel_fusion.330 (p.116: f32[2048,4096]) -> f32[8388608] {
  %p.116 = f32[2048,4096]{1,0} parameter(0)
  ROOT %fusion.330.clone = f32[8388608]{0} fusion(f32[2048,4096]{1,0} %p.116), kind=kLoop, calls=%fused_computation.330.clone, outer_dimension_partitions={9}, metadata={op_type="reshape" op_name="pmap(_multi_device_update_fn)/reshape[ dimensions=None\n                                       new_sizes=(8388608,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
}

%fused_computation.331.clone (param_0.1424: f32[32000,1024]) -> f32[32768000] {
  %param_0.1424 = f32[32000,1024]{1,0} parameter(0)
  %constant.21350 = f32[] constant(0.0625)
  %broadcast.2490 = f32[32000,1024]{1,0} broadcast(f32[] %constant.21350), dimensions={}
  %multiply.2130 = f32[32000,1024]{1,0} multiply(f32[32000,1024]{1,0} %param_0.1424, f32[32000,1024]{1,0} %broadcast.2490), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=200}
  ROOT %reshape.3450 = f32[32768000]{0} reshape(f32[32000,1024]{1,0} %multiply.2130), metadata={op_type="reshape" op_name="pmap(_multi_device_update_fn)/reshape[ dimensions=None\n                                       new_sizes=(32768000,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
}

%parallel_fusion.331 (p.117: f32[32000,1024]) -> f32[32768000] {
  %p.117 = f32[32000,1024]{1,0} parameter(0)
  ROOT %fusion.331.clone = f32[32768000]{0} fusion(f32[32000,1024]{1,0} %p.117), kind=kLoop, calls=%fused_computation.331.clone, outer_dimension_partitions={9}, metadata={op_type="reshape" op_name="pmap(_multi_device_update_fn)/reshape[ dimensions=None\n                                       new_sizes=(32768000,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
}

%fused_computation.338.clone (param_0.1425: f32[], param_1.2257: f32[256], param_2.1917: f32[1024,256], param_3.1531: f32[1024], param_4.874: f32[], param_5.595: f32[], param_6.514: f32[], param_7.448: f32[1024,256], param_8.340: f32[], param_9.282: f32[], param_10.221: s32[]) -> f32[1024,256] {
  %constant.21351 = f32[] constant(1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/metrics.py" source_line=617}
  %param_10.221 = s32[] parameter(10)
  %constant.21354 = s32[] constant(1), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=113}
  %compare.2818 = pred[] compare(s32[] %param_10.221, s32[] %constant.21354), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=113}
  %param_8.340 = f32[] parameter(8)
  %param_9.282 = f32[] parameter(9)
  %select.2704 = f32[] select(pred[] %compare.2818, f32[] %param_8.340, f32[] %param_9.282), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/jit(_where)/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=112}
  %subtract.720 = f32[] subtract(f32[] %constant.21351, f32[] %select.2704), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  %broadcast.2496 = f32[1024,256]{1,0} broadcast(f32[] %subtract.720), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  %param_7.448 = f32[1024,256]{1,0} parameter(7)
  %multiply.2136 = f32[1024,256]{1,0} multiply(f32[1024,256]{1,0} %broadcast.2496, f32[1024,256]{1,0} %param_7.448), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  %param_4.874 = f32[] parameter(4)
  %param_5.595 = f32[] parameter(5)
  %param_6.514 = f32[] parameter(6)
  %maximum.68 = f32[] maximum(f32[] %param_5.595, f32[] %param_6.514), metadata={op_type="max" op_name="pmap(_multi_device_update_fn)/max" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=122}
  %multiply.2134 = f32[] multiply(f32[] %param_4.874, f32[] %maximum.68), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=122}
  %broadcast.2495 = f32[1024,256]{1,0} broadcast(f32[] %multiply.2134), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=152}
  %param_2.1917 = f32[1024,256]{1,0} parameter(2)
  %param_3.1531 = f32[1024]{0} parameter(3)
  %constant.21353 = f32[] constant(0.0625)
  %broadcast.2493 = f32[1024]{0} broadcast(f32[] %constant.21353), dimensions={}
  %multiply.2131 = f32[1024]{0} multiply(f32[1024]{0} %param_3.1531, f32[1024]{0} %broadcast.2493)
  %broadcast.2494 = f32[1024,256]{1,0} broadcast(f32[1024]{0} %multiply.2131), dimensions={0}
  %multiply.2132 = f32[1024,256]{1,0} multiply(f32[1024,256]{1,0} %param_2.1917, f32[1024,256]{1,0} %broadcast.2494), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  %param_1.2257 = f32[256]{0} parameter(1)
  %broadcast.2492 = f32[1024,256]{1,0} broadcast(f32[256]{0} %param_1.2257), dimensions={1}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  %multiply.2133 = f32[1024,256]{1,0} multiply(f32[1024,256]{1,0} %multiply.2132, f32[1024,256]{1,0} %broadcast.2492), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  %param_0.1425 = f32[] parameter(0)
  %maximum.67 = f32[] maximum(f32[] %constant.21351, f32[] %param_0.1425), metadata={op_type="max" op_name="pmap(_multi_device_update_fn)/max" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %broadcast.2491 = f32[1024,256]{1,0} broadcast(f32[] %maximum.67), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=150}
  %divide.275 = f32[1024,256]{1,0} divide(f32[1024,256]{1,0} %multiply.2133, f32[1024,256]{1,0} %broadcast.2491), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=150}
  %multiply.2135 = f32[1024,256]{1,0} multiply(f32[1024,256]{1,0} %broadcast.2495, f32[1024,256]{1,0} %divide.275), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=152}
  ROOT %subtract.721 = f32[1024,256]{1,0} subtract(f32[1024,256]{1,0} %multiply.2136, f32[1024,256]{1,0} %multiply.2135), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
}

%parallel_fusion.338 (p.118: f32[], p.119: f32[256], p.120: f32[1024,256], p.121: f32[1024], p.122: f32[], p.123: f32[], p.124: f32[], p.125: f32[1024,256], p.126: f32[], p.127: f32[], p.128: s32[]) -> f32[1024,256] {
  %p.118 = f32[] parameter(0)
  %p.119 = f32[256]{0} parameter(1)
  %p.120 = f32[1024,256]{1,0} parameter(2)
  %p.121 = f32[1024]{0} parameter(3)
  %p.122 = f32[] parameter(4)
  %p.123 = f32[] parameter(5)
  %p.124 = f32[] parameter(6)
  %p.125 = f32[1024,256]{1,0} parameter(7)
  %p.126 = f32[] parameter(8)
  %p.127 = f32[] parameter(9)
  %p.128 = s32[] parameter(10)
  ROOT %fusion.338.clone = f32[1024,256]{1,0} fusion(f32[] %p.118, f32[256]{0} %p.119, f32[1024,256]{1,0} %p.120, f32[1024]{0} %p.121, f32[] %p.122, /*index=5*/f32[] %p.123, f32[] %p.124, f32[1024,256]{1,0} %p.125, f32[] %p.126, f32[] %p.127, /*index=10*/s32[] %p.128), kind=kLoop, calls=%fused_computation.338.clone, outer_dimension_partitions={4}, metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
}

%fused_computation.340.clone (param_0.1426: f32[256], param_1.2258: f32[1024,256], param_2.1918: f32[1024]) -> f32[1024,256] {
  %param_1.2258 = f32[1024,256]{1,0} parameter(1)
  %param_2.1918 = f32[1024]{0} parameter(2)
  %constant.21356 = f32[] constant(0.0625)
  %broadcast.2498 = f32[1024]{0} broadcast(f32[] %constant.21356), dimensions={}
  %multiply.2137 = f32[1024]{0} multiply(f32[1024]{0} %param_2.1918, f32[1024]{0} %broadcast.2498)
  %broadcast.2500 = f32[1024,256]{1,0} broadcast(f32[1024]{0} %multiply.2137), dimensions={0}
  %multiply.2138 = f32[1024,256]{1,0} multiply(f32[1024,256]{1,0} %param_1.2258, f32[1024,256]{1,0} %broadcast.2500), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  %param_0.1426 = f32[256]{0} parameter(0)
  %broadcast.2497 = f32[1024,256]{1,0} broadcast(f32[256]{0} %param_0.1426), dimensions={1}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  %multiply.2139 = f32[1024,256]{1,0} multiply(f32[1024,256]{1,0} %multiply.2138, f32[1024,256]{1,0} %broadcast.2497), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  ROOT %multiply.2140 = f32[1024,256]{1,0} multiply(f32[1024,256]{1,0} %multiply.2139, f32[1024,256]{1,0} %multiply.2139), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
}

%parallel_fusion.340 (p.129: f32[256], p.130: f32[1024,256], p.131: f32[1024]) -> f32[1024,256] {
  %p.129 = f32[256]{0} parameter(0)
  %p.130 = f32[1024,256]{1,0} parameter(1)
  %p.131 = f32[1024]{0} parameter(2)
  ROOT %fusion.340.clone = f32[1024,256]{1,0} fusion(f32[256]{0} %p.129, f32[1024,256]{1,0} %p.130, f32[1024]{0} %p.131), kind=kLoop, calls=%fused_computation.340.clone, outer_dimension_partitions={4}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
}

%fused_computation.345.clone (param_0.1427: f32[1024,256]) -> f32[1024,256] {
  %param_0.1427 = f32[1024,256]{1,0} parameter(0)
  %constant.21357 = f32[] constant(0.0625)
  %broadcast.2501 = f32[1024,256]{1,0} broadcast(f32[] %constant.21357), dimensions={}
  %multiply.2141 = f32[1024,256]{1,0} multiply(f32[1024,256]{1,0} %param_0.1427, f32[1024,256]{1,0} %broadcast.2501), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=200}
  ROOT %multiply.2142 = f32[1024,256]{1,0} multiply(f32[1024,256]{1,0} %multiply.2141, f32[1024,256]{1,0} %multiply.2141), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=126}
}

%parallel_fusion.345 (p.132: f32[1024,256]) -> f32[1024,256] {
  %p.132 = f32[1024,256]{1,0} parameter(0)
  ROOT %fusion.345.clone = f32[1024,256]{1,0} fusion(f32[1024,256]{1,0} %p.132), kind=kLoop, calls=%fused_computation.345.clone, outer_dimension_partitions={4}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=126}
}

%fused_computation.346.clone (param_0.1428: f32[8,64,256]) -> f32[256,512] {
  %param_0.1428 = f32[8,64,256]{2,1,0} parameter(0)
  %transpose.116 = f32[256,8,64]{2,1,0} transpose(f32[8,64,256]{2,1,0} %param_0.1428), dimensions={2,0,1}
  ROOT %reshape.3451 = f32[256,512]{1,0} reshape(f32[256,8,64]{2,1,0} %transpose.116)
}

%parallel_fusion.346 (p.133: f32[8,64,256]) -> f32[256,512] {
  %p.133 = f32[8,64,256]{2,1,0} parameter(0)
  ROOT %fusion.346.clone = f32[256,512]{1,0} fusion(f32[8,64,256]{2,1,0} %p.133), kind=kLoop, calls=%fused_computation.346.clone, outer_dimension_partitions={2}
}

%fused_computation.354.clone (param_0.1429: f32[], param_1.2259: f32[4096], param_2.1919: f32[2048,4096], param_3.1532: f32[2048], param_4.875: f32[], param_5.596: f32[], param_6.515: f32[], param_7.449: f32[2048,4096], param_8.341: f32[], param_9.283: f32[], param_10.222: s32[]) -> f32[2048,4096] {
  %constant.21358 = f32[] constant(1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/metrics.py" source_line=617}
  %param_10.222 = s32[] parameter(10)
  %constant.21360 = s32[] constant(1), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=113}
  %compare.2819 = pred[] compare(s32[] %param_10.222, s32[] %constant.21360), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=113}
  %param_8.341 = f32[] parameter(8)
  %param_9.283 = f32[] parameter(9)
  %select.2705 = f32[] select(pred[] %compare.2819, f32[] %param_8.341, f32[] %param_9.283), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/jit(_where)/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=112}
  %subtract.722 = f32[] subtract(f32[] %constant.21358, f32[] %select.2705), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  %broadcast.2508 = f32[2048,4096]{1,0} broadcast(f32[] %subtract.722), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  %param_7.449 = f32[2048,4096]{1,0} parameter(7)
  %multiply.2148 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %broadcast.2508, f32[2048,4096]{1,0} %param_7.449), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  %param_4.875 = f32[] parameter(4)
  %param_5.596 = f32[] parameter(5)
  %param_6.515 = f32[] parameter(6)
  %maximum.70 = f32[] maximum(f32[] %param_5.596, f32[] %param_6.515), metadata={op_type="max" op_name="pmap(_multi_device_update_fn)/max" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=122}
  %multiply.2146 = f32[] multiply(f32[] %param_4.875, f32[] %maximum.70), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=122}
  %broadcast.2507 = f32[2048,4096]{1,0} broadcast(f32[] %multiply.2146), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=152}
  %param_2.1919 = f32[2048,4096]{1,0} parameter(2)
  %param_3.1532 = f32[2048]{0} parameter(3)
  %constant.21359 = f32[] constant(0.0625)
  %broadcast.2505 = f32[2048]{0} broadcast(f32[] %constant.21359), dimensions={}
  %multiply.2143 = f32[2048]{0} multiply(f32[2048]{0} %param_3.1532, f32[2048]{0} %broadcast.2505)
  %broadcast.2506 = f32[2048,4096]{1,0} broadcast(f32[2048]{0} %multiply.2143), dimensions={0}
  %multiply.2144 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %param_2.1919, f32[2048,4096]{1,0} %broadcast.2506), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  %param_1.2259 = f32[4096]{0} parameter(1)
  %broadcast.2504 = f32[2048,4096]{1,0} broadcast(f32[4096]{0} %param_1.2259), dimensions={1}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  %multiply.2145 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %multiply.2144, f32[2048,4096]{1,0} %broadcast.2504), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  %param_0.1429 = f32[] parameter(0)
  %maximum.69 = f32[] maximum(f32[] %constant.21358, f32[] %param_0.1429), metadata={op_type="max" op_name="pmap(_multi_device_update_fn)/max" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %broadcast.2503 = f32[2048,4096]{1,0} broadcast(f32[] %maximum.69), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=150}
  %divide.276 = f32[2048,4096]{1,0} divide(f32[2048,4096]{1,0} %multiply.2145, f32[2048,4096]{1,0} %broadcast.2503), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=150}
  %multiply.2147 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %broadcast.2507, f32[2048,4096]{1,0} %divide.276), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=152}
  ROOT %subtract.723 = f32[2048,4096]{1,0} subtract(f32[2048,4096]{1,0} %multiply.2148, f32[2048,4096]{1,0} %multiply.2147), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
}

%parallel_fusion.354 (p.134: f32[], p.135: f32[4096], p.136: f32[2048,4096], p.137: f32[2048], p.138: f32[], p.139: f32[], p.140: f32[], p.141: f32[2048,4096], p.142: f32[], p.143: f32[], p.144: s32[]) -> f32[2048,4096] {
  %p.134 = f32[] parameter(0)
  %p.135 = f32[4096]{0} parameter(1)
  %p.136 = f32[2048,4096]{1,0} parameter(2)
  %p.137 = f32[2048]{0} parameter(3)
  %p.138 = f32[] parameter(4)
  %p.139 = f32[] parameter(5)
  %p.140 = f32[] parameter(6)
  %p.141 = f32[2048,4096]{1,0} parameter(7)
  %p.142 = f32[] parameter(8)
  %p.143 = f32[] parameter(9)
  %p.144 = s32[] parameter(10)
  ROOT %fusion.354.clone = f32[2048,4096]{1,0} fusion(f32[] %p.134, f32[4096]{0} %p.135, f32[2048,4096]{1,0} %p.136, f32[2048]{0} %p.137, f32[] %p.138, /*index=5*/f32[] %p.139, f32[] %p.140, f32[2048,4096]{1,0} %p.141, f32[] %p.142, f32[] %p.143, /*index=10*/s32[] %p.144), kind=kLoop, calls=%fused_computation.354.clone, outer_dimension_partitions={9}, metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
}

%fused_computation.356.clone (param_0.1430: f32[4096], param_1.2260: f32[2048,4096], param_2.1920: f32[2048]) -> f32[2048,4096] {
  %param_1.2260 = f32[2048,4096]{1,0} parameter(1)
  %param_2.1920 = f32[2048]{0} parameter(2)
  %constant.21362 = f32[] constant(0.0625)
  %broadcast.2510 = f32[2048]{0} broadcast(f32[] %constant.21362), dimensions={}
  %multiply.2149 = f32[2048]{0} multiply(f32[2048]{0} %param_2.1920, f32[2048]{0} %broadcast.2510)
  %broadcast.2512 = f32[2048,4096]{1,0} broadcast(f32[2048]{0} %multiply.2149), dimensions={0}
  %multiply.2150 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %param_1.2260, f32[2048,4096]{1,0} %broadcast.2512), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  %param_0.1430 = f32[4096]{0} parameter(0)
  %broadcast.2509 = f32[2048,4096]{1,0} broadcast(f32[4096]{0} %param_0.1430), dimensions={1}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  %multiply.2151 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %multiply.2150, f32[2048,4096]{1,0} %broadcast.2509), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  ROOT %multiply.2152 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %multiply.2151, f32[2048,4096]{1,0} %multiply.2151), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
}

%parallel_fusion.356 (p.145: f32[4096], p.146: f32[2048,4096], p.147: f32[2048]) -> f32[2048,4096] {
  %p.145 = f32[4096]{0} parameter(0)
  %p.146 = f32[2048,4096]{1,0} parameter(1)
  %p.147 = f32[2048]{0} parameter(2)
  ROOT %fusion.356.clone = f32[2048,4096]{1,0} fusion(f32[4096]{0} %p.145, f32[2048,4096]{1,0} %p.146, f32[2048]{0} %p.147), kind=kLoop, calls=%fused_computation.356.clone, outer_dimension_partitions={9}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
}

%fused_computation.361.clone (param_0.1431: f32[2048,4096]) -> f32[2048,4096] {
  %param_0.1431 = f32[2048,4096]{1,0} parameter(0)
  %constant.21363 = f32[] constant(0.0625)
  %broadcast.2513 = f32[2048,4096]{1,0} broadcast(f32[] %constant.21363), dimensions={}
  %multiply.2153 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %param_0.1431, f32[2048,4096]{1,0} %broadcast.2513), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=200}
  ROOT %multiply.2154 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %multiply.2153, f32[2048,4096]{1,0} %multiply.2153), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=126}
}

%parallel_fusion.361 (p.148: f32[2048,4096]) -> f32[2048,4096] {
  %p.148 = f32[2048,4096]{1,0} parameter(0)
  ROOT %fusion.361.clone = f32[2048,4096]{1,0} fusion(f32[2048,4096]{1,0} %p.148), kind=kLoop, calls=%fused_computation.361.clone, outer_dimension_partitions={9}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=126}
}

%fused_computation.369.clone (param_0.1432: f32[], param_1.2261: f32[4096], param_2.1921: f32[2048,4096], param_3.1533: f32[2048], param_4.876: f32[], param_5.597: f32[], param_6.516: f32[], param_7.450: f32[2048,4096], param_8.342: f32[], param_9.284: f32[], param_10.223: s32[]) -> f32[2048,4096] {
  %constant.21364 = f32[] constant(1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/metrics.py" source_line=617}
  %param_10.223 = s32[] parameter(10)
  %constant.21367 = s32[] constant(1), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=113}
  %compare.2820 = pred[] compare(s32[] %param_10.223, s32[] %constant.21367), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=113}
  %param_8.342 = f32[] parameter(8)
  %param_9.284 = f32[] parameter(9)
  %select.2706 = f32[] select(pred[] %compare.2820, f32[] %param_8.342, f32[] %param_9.284), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/jit(_where)/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=112}
  %subtract.724 = f32[] subtract(f32[] %constant.21364, f32[] %select.2706), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  %broadcast.2522 = f32[2048,4096]{1,0} broadcast(f32[] %subtract.724), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  %param_7.450 = f32[2048,4096]{1,0} parameter(7)
  %multiply.2160 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %broadcast.2522, f32[2048,4096]{1,0} %param_7.450), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  %param_4.876 = f32[] parameter(4)
  %param_5.597 = f32[] parameter(5)
  %param_6.516 = f32[] parameter(6)
  %maximum.72 = f32[] maximum(f32[] %param_5.597, f32[] %param_6.516), metadata={op_type="max" op_name="pmap(_multi_device_update_fn)/max" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=122}
  %multiply.2158 = f32[] multiply(f32[] %param_4.876, f32[] %maximum.72), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=122}
  %broadcast.2521 = f32[2048,4096]{1,0} broadcast(f32[] %multiply.2158), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=152}
  %param_2.1921 = f32[2048,4096]{1,0} parameter(2)
  %param_3.1533 = f32[2048]{0} parameter(3)
  %constant.21365 = f32[] constant(0.0625)
  %broadcast.2518 = f32[2048]{0} broadcast(f32[] %constant.21365), dimensions={}
  %multiply.2155 = f32[2048]{0} multiply(f32[2048]{0} %param_3.1533, f32[2048]{0} %broadcast.2518)
  %broadcast.2519 = f32[2048,4096]{1,0} broadcast(f32[2048]{0} %multiply.2155), dimensions={0}
  %multiply.2156 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %param_2.1921, f32[2048,4096]{1,0} %broadcast.2519), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  %param_1.2261 = f32[4096]{0} parameter(1)
  %broadcast.2516 = f32[2048,4096]{1,0} broadcast(f32[4096]{0} %param_1.2261), dimensions={1}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  %multiply.2157 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %multiply.2156, f32[2048,4096]{1,0} %broadcast.2516), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  %param_0.1432 = f32[] parameter(0)
  %maximum.71 = f32[] maximum(f32[] %constant.21364, f32[] %param_0.1432), metadata={op_type="max" op_name="pmap(_multi_device_update_fn)/max" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %broadcast.2515 = f32[2048,4096]{1,0} broadcast(f32[] %maximum.71), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=150}
  %divide.277 = f32[2048,4096]{1,0} divide(f32[2048,4096]{1,0} %multiply.2157, f32[2048,4096]{1,0} %broadcast.2515), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=150}
  %multiply.2159 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %broadcast.2521, f32[2048,4096]{1,0} %divide.277), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=152}
  ROOT %subtract.725 = f32[2048,4096]{1,0} subtract(f32[2048,4096]{1,0} %multiply.2160, f32[2048,4096]{1,0} %multiply.2159), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
}

%parallel_fusion.369 (p.149: f32[], p.150: f32[4096], p.151: f32[2048,4096], p.152: f32[2048], p.153: f32[], p.154: f32[], p.155: f32[], p.156: f32[2048,4096], p.157: f32[], p.158: f32[], p.159: s32[]) -> f32[2048,4096] {
  %p.149 = f32[] parameter(0)
  %p.150 = f32[4096]{0} parameter(1)
  %p.151 = f32[2048,4096]{1,0} parameter(2)
  %p.152 = f32[2048]{0} parameter(3)
  %p.153 = f32[] parameter(4)
  %p.154 = f32[] parameter(5)
  %p.155 = f32[] parameter(6)
  %p.156 = f32[2048,4096]{1,0} parameter(7)
  %p.157 = f32[] parameter(8)
  %p.158 = f32[] parameter(9)
  %p.159 = s32[] parameter(10)
  ROOT %fusion.369.clone = f32[2048,4096]{1,0} fusion(f32[] %p.149, f32[4096]{0} %p.150, f32[2048,4096]{1,0} %p.151, f32[2048]{0} %p.152, f32[] %p.153, /*index=5*/f32[] %p.154, f32[] %p.155, f32[2048,4096]{1,0} %p.156, f32[] %p.157, f32[] %p.158, /*index=10*/s32[] %p.159), kind=kLoop, calls=%fused_computation.369.clone, outer_dimension_partitions={9}, metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
}

%fused_computation.371.clone (param_0.1433: f32[4096], param_1.2262: f32[2048,4096], param_2.1922: f32[2048]) -> f32[2048,4096] {
  %param_1.2262 = f32[2048,4096]{1,0} parameter(1)
  %param_2.1922 = f32[2048]{0} parameter(2)
  %constant.21368 = f32[] constant(0.0625)
  %broadcast.2526 = f32[2048]{0} broadcast(f32[] %constant.21368), dimensions={}
  %multiply.2161 = f32[2048]{0} multiply(f32[2048]{0} %param_2.1922, f32[2048]{0} %broadcast.2526)
  %broadcast.2527 = f32[2048,4096]{1,0} broadcast(f32[2048]{0} %multiply.2161), dimensions={0}
  %multiply.2162 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %param_1.2262, f32[2048,4096]{1,0} %broadcast.2527), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  %param_0.1433 = f32[4096]{0} parameter(0)
  %broadcast.2524 = f32[2048,4096]{1,0} broadcast(f32[4096]{0} %param_0.1433), dimensions={1}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  %multiply.2163 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %multiply.2162, f32[2048,4096]{1,0} %broadcast.2524), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  ROOT %multiply.2164 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %multiply.2163, f32[2048,4096]{1,0} %multiply.2163), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
}

%parallel_fusion.371 (p.160: f32[4096], p.161: f32[2048,4096], p.162: f32[2048]) -> f32[2048,4096] {
  %p.160 = f32[4096]{0} parameter(0)
  %p.161 = f32[2048,4096]{1,0} parameter(1)
  %p.162 = f32[2048]{0} parameter(2)
  ROOT %fusion.371.clone = f32[2048,4096]{1,0} fusion(f32[4096]{0} %p.160, f32[2048,4096]{1,0} %p.161, f32[2048]{0} %p.162), kind=kLoop, calls=%fused_computation.371.clone, outer_dimension_partitions={9}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
}

%fused_computation.376.clone (param_0.1434: f32[2048,4096]) -> f32[2048,4096] {
  %param_0.1434 = f32[2048,4096]{1,0} parameter(0)
  %constant.21369 = f32[] constant(0.0625)
  %broadcast.2528 = f32[2048,4096]{1,0} broadcast(f32[] %constant.21369), dimensions={}
  %multiply.2165 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %param_0.1434, f32[2048,4096]{1,0} %broadcast.2528), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=200}
  ROOT %multiply.2166 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %multiply.2165, f32[2048,4096]{1,0} %multiply.2165), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=126}
}

%parallel_fusion.376 (p.163: f32[2048,4096]) -> f32[2048,4096] {
  %p.163 = f32[2048,4096]{1,0} parameter(0)
  ROOT %fusion.376.clone = f32[2048,4096]{1,0} fusion(f32[2048,4096]{1,0} %p.163), kind=kLoop, calls=%fused_computation.376.clone, outer_dimension_partitions={9}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=126}
}

%fused_computation.384.clone (param_0.1435: f32[], param_1.2263: f32[4096], param_2.1923: f32[2048,4096], param_3.1534: f32[2048], param_4.877: f32[], param_5.598: f32[], param_6.517: f32[], param_7.451: f32[2048,4096], param_8.343: f32[], param_9.285: f32[], param_10.224: s32[]) -> f32[2048,4096] {
  %constant.21370 = f32[] constant(1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/metrics.py" source_line=617}
  %param_10.224 = s32[] parameter(10)
  %constant.21372 = s32[] constant(1), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=113}
  %compare.2821 = pred[] compare(s32[] %param_10.224, s32[] %constant.21372), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=113}
  %param_8.343 = f32[] parameter(8)
  %param_9.285 = f32[] parameter(9)
  %select.2708 = f32[] select(pred[] %compare.2821, f32[] %param_8.343, f32[] %param_9.285), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/jit(_where)/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=112}
  %subtract.726 = f32[] subtract(f32[] %constant.21370, f32[] %select.2708), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  %broadcast.2534 = f32[2048,4096]{1,0} broadcast(f32[] %subtract.726), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  %param_7.451 = f32[2048,4096]{1,0} parameter(7)
  %multiply.2172 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %broadcast.2534, f32[2048,4096]{1,0} %param_7.451), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  %param_4.877 = f32[] parameter(4)
  %param_5.598 = f32[] parameter(5)
  %param_6.517 = f32[] parameter(6)
  %maximum.74 = f32[] maximum(f32[] %param_5.598, f32[] %param_6.517), metadata={op_type="max" op_name="pmap(_multi_device_update_fn)/max" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=122}
  %multiply.2170 = f32[] multiply(f32[] %param_4.877, f32[] %maximum.74), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=122}
  %broadcast.2533 = f32[2048,4096]{1,0} broadcast(f32[] %multiply.2170), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=152}
  %param_2.1923 = f32[2048,4096]{1,0} parameter(2)
  %param_3.1534 = f32[2048]{0} parameter(3)
  %constant.21371 = f32[] constant(0.0625)
  %broadcast.2531 = f32[2048]{0} broadcast(f32[] %constant.21371), dimensions={}
  %multiply.2167 = f32[2048]{0} multiply(f32[2048]{0} %param_3.1534, f32[2048]{0} %broadcast.2531)
  %broadcast.2532 = f32[2048,4096]{1,0} broadcast(f32[2048]{0} %multiply.2167), dimensions={0}
  %multiply.2168 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %param_2.1923, f32[2048,4096]{1,0} %broadcast.2532), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  %param_1.2263 = f32[4096]{0} parameter(1)
  %broadcast.2530 = f32[2048,4096]{1,0} broadcast(f32[4096]{0} %param_1.2263), dimensions={1}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  %multiply.2169 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %multiply.2168, f32[2048,4096]{1,0} %broadcast.2530), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  %param_0.1435 = f32[] parameter(0)
  %maximum.73 = f32[] maximum(f32[] %constant.21370, f32[] %param_0.1435), metadata={op_type="max" op_name="pmap(_multi_device_update_fn)/max" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %broadcast.2529 = f32[2048,4096]{1,0} broadcast(f32[] %maximum.73), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=150}
  %divide.278 = f32[2048,4096]{1,0} divide(f32[2048,4096]{1,0} %multiply.2169, f32[2048,4096]{1,0} %broadcast.2529), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=150}
  %multiply.2171 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %broadcast.2533, f32[2048,4096]{1,0} %divide.278), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=152}
  ROOT %subtract.727 = f32[2048,4096]{1,0} subtract(f32[2048,4096]{1,0} %multiply.2172, f32[2048,4096]{1,0} %multiply.2171), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
}

%parallel_fusion.384 (p.164: f32[], p.165: f32[4096], p.166: f32[2048,4096], p.167: f32[2048], p.168: f32[], p.169: f32[], p.170: f32[], p.171: f32[2048,4096], p.172: f32[], p.173: f32[], p.174: s32[]) -> f32[2048,4096] {
  %p.164 = f32[] parameter(0)
  %p.165 = f32[4096]{0} parameter(1)
  %p.166 = f32[2048,4096]{1,0} parameter(2)
  %p.167 = f32[2048]{0} parameter(3)
  %p.168 = f32[] parameter(4)
  %p.169 = f32[] parameter(5)
  %p.170 = f32[] parameter(6)
  %p.171 = f32[2048,4096]{1,0} parameter(7)
  %p.172 = f32[] parameter(8)
  %p.173 = f32[] parameter(9)
  %p.174 = s32[] parameter(10)
  ROOT %fusion.384.clone = f32[2048,4096]{1,0} fusion(f32[] %p.164, f32[4096]{0} %p.165, f32[2048,4096]{1,0} %p.166, f32[2048]{0} %p.167, f32[] %p.168, /*index=5*/f32[] %p.169, f32[] %p.170, f32[2048,4096]{1,0} %p.171, f32[] %p.172, f32[] %p.173, /*index=10*/s32[] %p.174), kind=kLoop, calls=%fused_computation.384.clone, outer_dimension_partitions={9}, metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
}

%fused_computation.386.clone (param_0.1436: f32[4096], param_1.2264: f32[2048,4096], param_2.1924: f32[2048]) -> f32[2048,4096] {
  %param_1.2264 = f32[2048,4096]{1,0} parameter(1)
  %param_2.1924 = f32[2048]{0} parameter(2)
  %constant.21373 = f32[] constant(0.0625)
  %broadcast.2536 = f32[2048]{0} broadcast(f32[] %constant.21373), dimensions={}
  %multiply.2173 = f32[2048]{0} multiply(f32[2048]{0} %param_2.1924, f32[2048]{0} %broadcast.2536)
  %broadcast.2537 = f32[2048,4096]{1,0} broadcast(f32[2048]{0} %multiply.2173), dimensions={0}
  %multiply.2174 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %param_1.2264, f32[2048,4096]{1,0} %broadcast.2537), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  %param_0.1436 = f32[4096]{0} parameter(0)
  %broadcast.2535 = f32[2048,4096]{1,0} broadcast(f32[4096]{0} %param_0.1436), dimensions={1}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  %multiply.2175 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %multiply.2174, f32[2048,4096]{1,0} %broadcast.2535), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  ROOT %multiply.2176 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %multiply.2175, f32[2048,4096]{1,0} %multiply.2175), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
}

%parallel_fusion.386 (p.175: f32[4096], p.176: f32[2048,4096], p.177: f32[2048]) -> f32[2048,4096] {
  %p.175 = f32[4096]{0} parameter(0)
  %p.176 = f32[2048,4096]{1,0} parameter(1)
  %p.177 = f32[2048]{0} parameter(2)
  ROOT %fusion.386.clone = f32[2048,4096]{1,0} fusion(f32[4096]{0} %p.175, f32[2048,4096]{1,0} %p.176, f32[2048]{0} %p.177), kind=kLoop, calls=%fused_computation.386.clone, outer_dimension_partitions={9}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
}

%fused_computation.391.clone (param_0.1437: f32[2048,4096]) -> f32[2048,4096] {
  %param_0.1437 = f32[2048,4096]{1,0} parameter(0)
  %constant.21374 = f32[] constant(0.0625)
  %broadcast.2538 = f32[2048,4096]{1,0} broadcast(f32[] %constant.21374), dimensions={}
  %multiply.2177 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %param_0.1437, f32[2048,4096]{1,0} %broadcast.2538), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=200}
  ROOT %multiply.2178 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %multiply.2177, f32[2048,4096]{1,0} %multiply.2177), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=126}
}

%parallel_fusion.391 (p.178: f32[2048,4096]) -> f32[2048,4096] {
  %p.178 = f32[2048,4096]{1,0} parameter(0)
  ROOT %fusion.391.clone = f32[2048,4096]{1,0} fusion(f32[2048,4096]{1,0} %p.178), kind=kLoop, calls=%fused_computation.391.clone, outer_dimension_partitions={9}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=126}
}

%fused_computation.399.clone (param_0.1438: f32[], param_1.2265: f32[4096], param_2.1925: f32[2048,4096], param_3.1535: f32[2048], param_4.878: f32[], param_5.599: f32[], param_6.518: f32[], param_7.452: f32[2048,4096], param_8.344: f32[], param_9.286: f32[], param_10.225: s32[]) -> f32[2048,4096] {
  %constant.21375 = f32[] constant(1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/metrics.py" source_line=617}
  %param_10.225 = s32[] parameter(10)
  %constant.21378 = s32[] constant(1), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=113}
  %compare.2822 = pred[] compare(s32[] %param_10.225, s32[] %constant.21378), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=113}
  %param_8.344 = f32[] parameter(8)
  %param_9.286 = f32[] parameter(9)
  %select.2709 = f32[] select(pred[] %compare.2822, f32[] %param_8.344, f32[] %param_9.286), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/jit(_where)/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=112}
  %subtract.728 = f32[] subtract(f32[] %constant.21375, f32[] %select.2709), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  %broadcast.2544 = f32[2048,4096]{1,0} broadcast(f32[] %subtract.728), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  %param_7.452 = f32[2048,4096]{1,0} parameter(7)
  %multiply.2184 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %broadcast.2544, f32[2048,4096]{1,0} %param_7.452), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  %param_4.878 = f32[] parameter(4)
  %param_5.599 = f32[] parameter(5)
  %param_6.518 = f32[] parameter(6)
  %maximum.76 = f32[] maximum(f32[] %param_5.599, f32[] %param_6.518), metadata={op_type="max" op_name="pmap(_multi_device_update_fn)/max" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=122}
  %multiply.2182 = f32[] multiply(f32[] %param_4.878, f32[] %maximum.76), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=122}
  %broadcast.2543 = f32[2048,4096]{1,0} broadcast(f32[] %multiply.2182), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=152}
  %param_2.1925 = f32[2048,4096]{1,0} parameter(2)
  %param_3.1535 = f32[2048]{0} parameter(3)
  %constant.21377 = f32[] constant(0.0625)
  %broadcast.2541 = f32[2048]{0} broadcast(f32[] %constant.21377), dimensions={}
  %multiply.2179 = f32[2048]{0} multiply(f32[2048]{0} %param_3.1535, f32[2048]{0} %broadcast.2541)
  %broadcast.2542 = f32[2048,4096]{1,0} broadcast(f32[2048]{0} %multiply.2179), dimensions={0}
  %multiply.2180 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %param_2.1925, f32[2048,4096]{1,0} %broadcast.2542), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  %param_1.2265 = f32[4096]{0} parameter(1)
  %broadcast.2540 = f32[2048,4096]{1,0} broadcast(f32[4096]{0} %param_1.2265), dimensions={1}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  %multiply.2181 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %multiply.2180, f32[2048,4096]{1,0} %broadcast.2540), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  %param_0.1438 = f32[] parameter(0)
  %maximum.75 = f32[] maximum(f32[] %constant.21375, f32[] %param_0.1438), metadata={op_type="max" op_name="pmap(_multi_device_update_fn)/max" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %broadcast.2539 = f32[2048,4096]{1,0} broadcast(f32[] %maximum.75), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=150}
  %divide.279 = f32[2048,4096]{1,0} divide(f32[2048,4096]{1,0} %multiply.2181, f32[2048,4096]{1,0} %broadcast.2539), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=150}
  %multiply.2183 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %broadcast.2543, f32[2048,4096]{1,0} %divide.279), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=152}
  ROOT %subtract.729 = f32[2048,4096]{1,0} subtract(f32[2048,4096]{1,0} %multiply.2184, f32[2048,4096]{1,0} %multiply.2183), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
}

%parallel_fusion.399 (p.179: f32[], p.180: f32[4096], p.181: f32[2048,4096], p.182: f32[2048], p.183: f32[], p.184: f32[], p.185: f32[], p.186: f32[2048,4096], p.187: f32[], p.188: f32[], p.189: s32[]) -> f32[2048,4096] {
  %p.179 = f32[] parameter(0)
  %p.180 = f32[4096]{0} parameter(1)
  %p.181 = f32[2048,4096]{1,0} parameter(2)
  %p.182 = f32[2048]{0} parameter(3)
  %p.183 = f32[] parameter(4)
  %p.184 = f32[] parameter(5)
  %p.185 = f32[] parameter(6)
  %p.186 = f32[2048,4096]{1,0} parameter(7)
  %p.187 = f32[] parameter(8)
  %p.188 = f32[] parameter(9)
  %p.189 = s32[] parameter(10)
  ROOT %fusion.399.clone = f32[2048,4096]{1,0} fusion(f32[] %p.179, f32[4096]{0} %p.180, f32[2048,4096]{1,0} %p.181, f32[2048]{0} %p.182, f32[] %p.183, /*index=5*/f32[] %p.184, f32[] %p.185, f32[2048,4096]{1,0} %p.186, f32[] %p.187, f32[] %p.188, /*index=10*/s32[] %p.189), kind=kLoop, calls=%fused_computation.399.clone, outer_dimension_partitions={9}, metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
}

%fused_computation.401.clone (param_0.1439: f32[4096], param_1.2266: f32[2048,4096], param_2.1926: f32[2048]) -> f32[2048,4096] {
  %param_1.2266 = f32[2048,4096]{1,0} parameter(1)
  %param_2.1926 = f32[2048]{0} parameter(2)
  %constant.21379 = f32[] constant(0.0625)
  %broadcast.2546 = f32[2048]{0} broadcast(f32[] %constant.21379), dimensions={}
  %multiply.2185 = f32[2048]{0} multiply(f32[2048]{0} %param_2.1926, f32[2048]{0} %broadcast.2546)
  %broadcast.2547 = f32[2048,4096]{1,0} broadcast(f32[2048]{0} %multiply.2185), dimensions={0}
  %multiply.2186 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %param_1.2266, f32[2048,4096]{1,0} %broadcast.2547), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  %param_0.1439 = f32[4096]{0} parameter(0)
  %broadcast.2545 = f32[2048,4096]{1,0} broadcast(f32[4096]{0} %param_0.1439), dimensions={1}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  %multiply.2187 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %multiply.2186, f32[2048,4096]{1,0} %broadcast.2545), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  ROOT %multiply.2188 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %multiply.2187, f32[2048,4096]{1,0} %multiply.2187), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
}

%parallel_fusion.401 (p.190: f32[4096], p.191: f32[2048,4096], p.192: f32[2048]) -> f32[2048,4096] {
  %p.190 = f32[4096]{0} parameter(0)
  %p.191 = f32[2048,4096]{1,0} parameter(1)
  %p.192 = f32[2048]{0} parameter(2)
  ROOT %fusion.401.clone = f32[2048,4096]{1,0} fusion(f32[4096]{0} %p.190, f32[2048,4096]{1,0} %p.191, f32[2048]{0} %p.192), kind=kLoop, calls=%fused_computation.401.clone, outer_dimension_partitions={9}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
}

%fused_computation.406.clone (param_0.1440: f32[2048,4096]) -> f32[2048,4096] {
  %param_0.1440 = f32[2048,4096]{1,0} parameter(0)
  %constant.21380 = f32[] constant(0.0625)
  %broadcast.2549 = f32[2048,4096]{1,0} broadcast(f32[] %constant.21380), dimensions={}
  %multiply.2189 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %param_0.1440, f32[2048,4096]{1,0} %broadcast.2549), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=200}
  ROOT %multiply.2190 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %multiply.2189, f32[2048,4096]{1,0} %multiply.2189), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=126}
}

%parallel_fusion.406 (p.193: f32[2048,4096]) -> f32[2048,4096] {
  %p.193 = f32[2048,4096]{1,0} parameter(0)
  ROOT %fusion.406.clone = f32[2048,4096]{1,0} fusion(f32[2048,4096]{1,0} %p.193), kind=kLoop, calls=%fused_computation.406.clone, outer_dimension_partitions={9}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=126}
}

%fused_computation.414.clone (param_0.1441: f32[], param_1.2267: f32[1024], param_2.1927: f32[1024,1024], param_3.1536: f32[1024], param_4.879: f32[], param_5.600: f32[], param_6.519: f32[], param_7.453: f32[1024,1024], param_8.345: f32[], param_9.287: f32[], param_10.226: s32[]) -> f32[1024,1024] {
  %constant.21382 = f32[] constant(1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/metrics.py" source_line=617}
  %param_10.226 = s32[] parameter(10)
  %constant.21384 = s32[] constant(1), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=113}
  %compare.2823 = pred[] compare(s32[] %param_10.226, s32[] %constant.21384), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=113}
  %param_8.345 = f32[] parameter(8)
  %param_9.287 = f32[] parameter(9)
  %select.2710 = f32[] select(pred[] %compare.2823, f32[] %param_8.345, f32[] %param_9.287), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/jit(_where)/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=112}
  %subtract.730 = f32[] subtract(f32[] %constant.21382, f32[] %select.2710), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  %broadcast.2555 = f32[1024,1024]{1,0} broadcast(f32[] %subtract.730), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  %param_7.453 = f32[1024,1024]{1,0} parameter(7)
  %multiply.2196 = f32[1024,1024]{1,0} multiply(f32[1024,1024]{1,0} %broadcast.2555, f32[1024,1024]{1,0} %param_7.453), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  %param_4.879 = f32[] parameter(4)
  %param_5.600 = f32[] parameter(5)
  %param_6.519 = f32[] parameter(6)
  %maximum.78 = f32[] maximum(f32[] %param_5.600, f32[] %param_6.519), metadata={op_type="max" op_name="pmap(_multi_device_update_fn)/max" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=122}
  %multiply.2194 = f32[] multiply(f32[] %param_4.879, f32[] %maximum.78), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=122}
  %broadcast.2554 = f32[1024,1024]{1,0} broadcast(f32[] %multiply.2194), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=152}
  %param_2.1927 = f32[1024,1024]{1,0} parameter(2)
  %param_3.1536 = f32[1024]{0} parameter(3)
  %constant.21383 = f32[] constant(0.0625)
  %broadcast.2552 = f32[1024]{0} broadcast(f32[] %constant.21383), dimensions={}
  %multiply.2191 = f32[1024]{0} multiply(f32[1024]{0} %param_3.1536, f32[1024]{0} %broadcast.2552)
  %broadcast.2553 = f32[1024,1024]{1,0} broadcast(f32[1024]{0} %multiply.2191), dimensions={0}
  %multiply.2192 = f32[1024,1024]{1,0} multiply(f32[1024,1024]{1,0} %param_2.1927, f32[1024,1024]{1,0} %broadcast.2553), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  %param_1.2267 = f32[1024]{0} parameter(1)
  %broadcast.2551 = f32[1024,1024]{1,0} broadcast(f32[1024]{0} %param_1.2267), dimensions={1}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  %multiply.2193 = f32[1024,1024]{1,0} multiply(f32[1024,1024]{1,0} %multiply.2192, f32[1024,1024]{1,0} %broadcast.2551), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  %param_0.1441 = f32[] parameter(0)
  %maximum.77 = f32[] maximum(f32[] %constant.21382, f32[] %param_0.1441), metadata={op_type="max" op_name="pmap(_multi_device_update_fn)/max" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %broadcast.2550 = f32[1024,1024]{1,0} broadcast(f32[] %maximum.77), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=150}
  %divide.280 = f32[1024,1024]{1,0} divide(f32[1024,1024]{1,0} %multiply.2193, f32[1024,1024]{1,0} %broadcast.2550), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=150}
  %multiply.2195 = f32[1024,1024]{1,0} multiply(f32[1024,1024]{1,0} %broadcast.2554, f32[1024,1024]{1,0} %divide.280), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=152}
  ROOT %subtract.731 = f32[1024,1024]{1,0} subtract(f32[1024,1024]{1,0} %multiply.2196, f32[1024,1024]{1,0} %multiply.2195), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
}

%parallel_fusion.414 (p.194: f32[], p.195: f32[1024], p.196: f32[1024,1024], p.197: f32[1024], p.198: f32[], p.199: f32[], p.200: f32[], p.201: f32[1024,1024], p.202: f32[], p.203: f32[], p.204: s32[]) -> f32[1024,1024] {
  %p.194 = f32[] parameter(0)
  %p.195 = f32[1024]{0} parameter(1)
  %p.196 = f32[1024,1024]{1,0} parameter(2)
  %p.197 = f32[1024]{0} parameter(3)
  %p.198 = f32[] parameter(4)
  %p.199 = f32[] parameter(5)
  %p.200 = f32[] parameter(6)
  %p.201 = f32[1024,1024]{1,0} parameter(7)
  %p.202 = f32[] parameter(8)
  %p.203 = f32[] parameter(9)
  %p.204 = s32[] parameter(10)
  ROOT %fusion.414.clone = f32[1024,1024]{1,0} fusion(f32[] %p.194, f32[1024]{0} %p.195, f32[1024,1024]{1,0} %p.196, f32[1024]{0} %p.197, f32[] %p.198, /*index=5*/f32[] %p.199, f32[] %p.200, f32[1024,1024]{1,0} %p.201, f32[] %p.202, f32[] %p.203, /*index=10*/s32[] %p.204), kind=kLoop, calls=%fused_computation.414.clone, outer_dimension_partitions={9}, metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
}

%fused_computation.416.clone (param_0.1442: f32[1024], param_1.2268: f32[1024,1024], param_2.1928: f32[1024]) -> f32[1024,1024] {
  %param_1.2268 = f32[1024,1024]{1,0} parameter(1)
  %param_2.1928 = f32[1024]{0} parameter(2)
  %constant.21385 = f32[] constant(0.0625)
  %broadcast.2557 = f32[1024]{0} broadcast(f32[] %constant.21385), dimensions={}
  %multiply.2197 = f32[1024]{0} multiply(f32[1024]{0} %param_2.1928, f32[1024]{0} %broadcast.2557)
  %broadcast.2558 = f32[1024,1024]{1,0} broadcast(f32[1024]{0} %multiply.2197), dimensions={0}
  %multiply.2198 = f32[1024,1024]{1,0} multiply(f32[1024,1024]{1,0} %param_1.2268, f32[1024,1024]{1,0} %broadcast.2558), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  %param_0.1442 = f32[1024]{0} parameter(0)
  %broadcast.2556 = f32[1024,1024]{1,0} broadcast(f32[1024]{0} %param_0.1442), dimensions={1}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  %multiply.2199 = f32[1024,1024]{1,0} multiply(f32[1024,1024]{1,0} %multiply.2198, f32[1024,1024]{1,0} %broadcast.2556), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  ROOT %multiply.2200 = f32[1024,1024]{1,0} multiply(f32[1024,1024]{1,0} %multiply.2199, f32[1024,1024]{1,0} %multiply.2199), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
}

%parallel_fusion.416 (p.205: f32[1024], p.206: f32[1024,1024], p.207: f32[1024]) -> f32[1024,1024] {
  %p.205 = f32[1024]{0} parameter(0)
  %p.206 = f32[1024,1024]{1,0} parameter(1)
  %p.207 = f32[1024]{0} parameter(2)
  ROOT %fusion.416.clone = f32[1024,1024]{1,0} fusion(f32[1024]{0} %p.205, f32[1024,1024]{1,0} %p.206, f32[1024]{0} %p.207), kind=kLoop, calls=%fused_computation.416.clone, outer_dimension_partitions={9}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
}

%fused_computation.421.clone (param_0.1443: f32[1024,1024]) -> f32[1024,1024] {
  %param_0.1443 = f32[1024,1024]{1,0} parameter(0)
  %constant.21386 = f32[] constant(0.0625)
  %broadcast.2559 = f32[1024,1024]{1,0} broadcast(f32[] %constant.21386), dimensions={}
  %multiply.2201 = f32[1024,1024]{1,0} multiply(f32[1024,1024]{1,0} %param_0.1443, f32[1024,1024]{1,0} %broadcast.2559), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=200}
  ROOT %multiply.2202 = f32[1024,1024]{1,0} multiply(f32[1024,1024]{1,0} %multiply.2201, f32[1024,1024]{1,0} %multiply.2201), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=126}
}

%parallel_fusion.421 (p.208: f32[1024,1024]) -> f32[1024,1024] {
  %p.208 = f32[1024,1024]{1,0} parameter(0)
  ROOT %fusion.421.clone = f32[1024,1024]{1,0} fusion(f32[1024,1024]{1,0} %p.208), kind=kLoop, calls=%fused_computation.421.clone, outer_dimension_partitions={9}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=126}
}

%fused_computation.422.clone (param_0.1444: f32[64,8,1024]) -> f32[1024,512] {
  %param_0.1444 = f32[64,8,1024]{2,1,0} parameter(0)
  %transpose.117 = f32[1024,8,64]{0,1,2} transpose(f32[64,8,1024]{2,1,0} %param_0.1444), dimensions={2,1,0}
  %copy.75 = f32[1024,8,64]{2,1,0} copy(f32[1024,8,64]{0,1,2} %transpose.117)
  ROOT %reshape.3452 = f32[1024,512]{1,0} reshape(f32[1024,8,64]{2,1,0} %copy.75)
}

%parallel_fusion.422 (p.209: f32[64,8,1024]) -> f32[1024,512] {
  %p.209 = f32[64,8,1024]{2,1,0} parameter(0)
  ROOT %fusion.422.clone = f32[1024,512]{1,0} fusion(f32[64,8,1024]{2,1,0} %p.209), kind=kLoop, calls=%fused_computation.422.clone, outer_dimension_partitions={8}
}

%fused_computation.430.clone (param_0.1445: f32[], param_1.2269: f32[1024], param_2.1929: f32[1024,1024], param_3.1537: f32[1024], param_4.880: f32[], param_5.601: f32[], param_6.520: f32[], param_7.454: f32[1024,1024], param_8.346: f32[], param_9.288: f32[], param_10.227: s32[]) -> f32[1024,1024] {
  %constant.21388 = f32[] constant(1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/metrics.py" source_line=617}
  %param_10.227 = s32[] parameter(10)
  %constant.21390 = s32[] constant(1), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=113}
  %compare.2824 = pred[] compare(s32[] %param_10.227, s32[] %constant.21390), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=113}
  %param_8.346 = f32[] parameter(8)
  %param_9.288 = f32[] parameter(9)
  %select.2711 = f32[] select(pred[] %compare.2824, f32[] %param_8.346, f32[] %param_9.288), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/jit(_where)/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=112}
  %subtract.732 = f32[] subtract(f32[] %constant.21388, f32[] %select.2711), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  %broadcast.2565 = f32[1024,1024]{1,0} broadcast(f32[] %subtract.732), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  %param_7.454 = f32[1024,1024]{1,0} parameter(7)
  %multiply.2208 = f32[1024,1024]{1,0} multiply(f32[1024,1024]{1,0} %broadcast.2565, f32[1024,1024]{1,0} %param_7.454), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  %param_4.880 = f32[] parameter(4)
  %param_5.601 = f32[] parameter(5)
  %param_6.520 = f32[] parameter(6)
  %maximum.80 = f32[] maximum(f32[] %param_5.601, f32[] %param_6.520), metadata={op_type="max" op_name="pmap(_multi_device_update_fn)/max" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=122}
  %multiply.2206 = f32[] multiply(f32[] %param_4.880, f32[] %maximum.80), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=122}
  %broadcast.2564 = f32[1024,1024]{1,0} broadcast(f32[] %multiply.2206), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=152}
  %param_2.1929 = f32[1024,1024]{1,0} parameter(2)
  %param_3.1537 = f32[1024]{0} parameter(3)
  %constant.21389 = f32[] constant(0.0625)
  %broadcast.2562 = f32[1024]{0} broadcast(f32[] %constant.21389), dimensions={}
  %multiply.2203 = f32[1024]{0} multiply(f32[1024]{0} %param_3.1537, f32[1024]{0} %broadcast.2562)
  %broadcast.2563 = f32[1024,1024]{1,0} broadcast(f32[1024]{0} %multiply.2203), dimensions={0}
  %multiply.2204 = f32[1024,1024]{1,0} multiply(f32[1024,1024]{1,0} %param_2.1929, f32[1024,1024]{1,0} %broadcast.2563), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  %param_1.2269 = f32[1024]{0} parameter(1)
  %broadcast.2561 = f32[1024,1024]{1,0} broadcast(f32[1024]{0} %param_1.2269), dimensions={1}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  %multiply.2205 = f32[1024,1024]{1,0} multiply(f32[1024,1024]{1,0} %multiply.2204, f32[1024,1024]{1,0} %broadcast.2561), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  %param_0.1445 = f32[] parameter(0)
  %maximum.79 = f32[] maximum(f32[] %constant.21388, f32[] %param_0.1445), metadata={op_type="max" op_name="pmap(_multi_device_update_fn)/max" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %broadcast.2560 = f32[1024,1024]{1,0} broadcast(f32[] %maximum.79), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=150}
  %divide.281 = f32[1024,1024]{1,0} divide(f32[1024,1024]{1,0} %multiply.2205, f32[1024,1024]{1,0} %broadcast.2560), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=150}
  %multiply.2207 = f32[1024,1024]{1,0} multiply(f32[1024,1024]{1,0} %broadcast.2564, f32[1024,1024]{1,0} %divide.281), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=152}
  ROOT %subtract.733 = f32[1024,1024]{1,0} subtract(f32[1024,1024]{1,0} %multiply.2208, f32[1024,1024]{1,0} %multiply.2207), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
}

%parallel_fusion.430 (p.210: f32[], p.211: f32[1024], p.212: f32[1024,1024], p.213: f32[1024], p.214: f32[], p.215: f32[], p.216: f32[], p.217: f32[1024,1024], p.218: f32[], p.219: f32[], p.220: s32[]) -> f32[1024,1024] {
  %p.210 = f32[] parameter(0)
  %p.211 = f32[1024]{0} parameter(1)
  %p.212 = f32[1024,1024]{1,0} parameter(2)
  %p.213 = f32[1024]{0} parameter(3)
  %p.214 = f32[] parameter(4)
  %p.215 = f32[] parameter(5)
  %p.216 = f32[] parameter(6)
  %p.217 = f32[1024,1024]{1,0} parameter(7)
  %p.218 = f32[] parameter(8)
  %p.219 = f32[] parameter(9)
  %p.220 = s32[] parameter(10)
  ROOT %fusion.430.clone = f32[1024,1024]{1,0} fusion(f32[] %p.210, f32[1024]{0} %p.211, f32[1024,1024]{1,0} %p.212, f32[1024]{0} %p.213, f32[] %p.214, /*index=5*/f32[] %p.215, f32[] %p.216, f32[1024,1024]{1,0} %p.217, f32[] %p.218, f32[] %p.219, /*index=10*/s32[] %p.220), kind=kLoop, calls=%fused_computation.430.clone, outer_dimension_partitions={9}, metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
}

%fused_computation.432.clone (param_0.1446: f32[1024], param_1.2270: f32[1024,1024], param_2.1930: f32[1024]) -> f32[1024,1024] {
  %param_1.2270 = f32[1024,1024]{1,0} parameter(1)
  %param_2.1930 = f32[1024]{0} parameter(2)
  %constant.21392 = f32[] constant(0.0625)
  %broadcast.2567 = f32[1024]{0} broadcast(f32[] %constant.21392), dimensions={}
  %multiply.2209 = f32[1024]{0} multiply(f32[1024]{0} %param_2.1930, f32[1024]{0} %broadcast.2567)
  %broadcast.2568 = f32[1024,1024]{1,0} broadcast(f32[1024]{0} %multiply.2209), dimensions={0}
  %multiply.2210 = f32[1024,1024]{1,0} multiply(f32[1024,1024]{1,0} %param_1.2270, f32[1024,1024]{1,0} %broadcast.2568), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  %param_0.1446 = f32[1024]{0} parameter(0)
  %broadcast.2566 = f32[1024,1024]{1,0} broadcast(f32[1024]{0} %param_0.1446), dimensions={1}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  %multiply.2211 = f32[1024,1024]{1,0} multiply(f32[1024,1024]{1,0} %multiply.2210, f32[1024,1024]{1,0} %broadcast.2566), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  ROOT %multiply.2212 = f32[1024,1024]{1,0} multiply(f32[1024,1024]{1,0} %multiply.2211, f32[1024,1024]{1,0} %multiply.2211), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
}

%parallel_fusion.432 (p.221: f32[1024], p.222: f32[1024,1024], p.223: f32[1024]) -> f32[1024,1024] {
  %p.221 = f32[1024]{0} parameter(0)
  %p.222 = f32[1024,1024]{1,0} parameter(1)
  %p.223 = f32[1024]{0} parameter(2)
  ROOT %fusion.432.clone = f32[1024,1024]{1,0} fusion(f32[1024]{0} %p.221, f32[1024,1024]{1,0} %p.222, f32[1024]{0} %p.223), kind=kLoop, calls=%fused_computation.432.clone, outer_dimension_partitions={9}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
}

%fused_computation.437.clone (param_0.1447: f32[1024,1024]) -> f32[1024,1024] {
  %param_0.1447 = f32[1024,1024]{1,0} parameter(0)
  %constant.21393 = f32[] constant(0.0625)
  %broadcast.2569 = f32[1024,1024]{1,0} broadcast(f32[] %constant.21393), dimensions={}
  %multiply.2213 = f32[1024,1024]{1,0} multiply(f32[1024,1024]{1,0} %param_0.1447, f32[1024,1024]{1,0} %broadcast.2569), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=200}
  ROOT %multiply.2214 = f32[1024,1024]{1,0} multiply(f32[1024,1024]{1,0} %multiply.2213, f32[1024,1024]{1,0} %multiply.2213), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=126}
}

%parallel_fusion.437 (p.224: f32[1024,1024]) -> f32[1024,1024] {
  %p.224 = f32[1024,1024]{1,0} parameter(0)
  ROOT %fusion.437.clone = f32[1024,1024]{1,0} fusion(f32[1024,1024]{1,0} %p.224), kind=kLoop, calls=%fused_computation.437.clone, outer_dimension_partitions={9}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=126}
}

%fused_computation.438.clone (param_0.1448: f32[8,1024,64]) -> f32[1024,512] {
  %param_0.1448 = f32[8,1024,64]{2,1,0} parameter(0)
  %reshape.3453 = f32[8,1,1024,64]{3,2,1,0} reshape(f32[8,1024,64]{2,1,0} %param_0.1448), metadata={op_type="dot_general" op_name="pmap(_multi_device_update_fn)/dot_general[ dimension_numbers=(((1,), (1,)), ((0,), (0,)))\n                                           precision=None\n                                           preferred_element_type=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/attention.py" source_line=293}
  %transpose.118 = f32[8,64,1,1024]{3,2,1,0} transpose(f32[8,1,1024,64]{3,2,1,0} %reshape.3453), dimensions={0,3,1,2}, metadata={op_type="transpose" op_name="pmap(_multi_device_update_fn)/transpose[ permutation=(0, 2, 1, 3) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/attention.py" source_line=360}
  %reshape.3454 = f32[8,64,1024]{2,1,0} reshape(f32[8,64,1,1024]{3,2,1,0} %transpose.118), metadata={op_type="reshape" op_name="pmap(_multi_device_update_fn)/reshape[ dimensions=None\n                                       new_sizes=(8, 64, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/attention.py" source_line=359}
  %transpose.119 = f32[1024,8,64]{2,1,0} transpose(f32[8,64,1024]{2,1,0} %reshape.3454), dimensions={2,0,1}
  ROOT %reshape.3455 = f32[1024,512]{1,0} reshape(f32[1024,8,64]{2,1,0} %transpose.119)
}

%parallel_fusion.438 (p.225: f32[8,1024,64]) -> f32[1024,512] {
  %p.225 = f32[8,1024,64]{2,1,0} parameter(0)
  ROOT %fusion.438.clone = f32[1024,512]{1,0} fusion(f32[8,1024,64]{2,1,0} %p.225), kind=kLoop, calls=%fused_computation.438.clone, outer_dimension_partitions={8}
}

%fused_computation.446.clone (param_0.1449: f32[], param_1.2271: f32[1024], param_2.1931: f32[1024,1024], param_3.1538: f32[1024], param_4.881: f32[], param_5.602: f32[], param_6.521: f32[], param_7.455: f32[1024,1024], param_8.347: f32[], param_9.289: f32[], param_10.228: s32[]) -> f32[1024,1024] {
  %constant.21394 = f32[] constant(1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/metrics.py" source_line=617}
  %param_10.228 = s32[] parameter(10)
  %constant.21396 = s32[] constant(1), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=113}
  %compare.2825 = pred[] compare(s32[] %param_10.228, s32[] %constant.21396), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=113}
  %param_8.347 = f32[] parameter(8)
  %param_9.289 = f32[] parameter(9)
  %select.2712 = f32[] select(pred[] %compare.2825, f32[] %param_8.347, f32[] %param_9.289), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/jit(_where)/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=112}
  %subtract.734 = f32[] subtract(f32[] %constant.21394, f32[] %select.2712), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  %broadcast.2576 = f32[1024,1024]{1,0} broadcast(f32[] %subtract.734), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  %param_7.455 = f32[1024,1024]{1,0} parameter(7)
  %multiply.2220 = f32[1024,1024]{1,0} multiply(f32[1024,1024]{1,0} %broadcast.2576, f32[1024,1024]{1,0} %param_7.455), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  %param_4.881 = f32[] parameter(4)
  %param_5.602 = f32[] parameter(5)
  %param_6.521 = f32[] parameter(6)
  %maximum.82 = f32[] maximum(f32[] %param_5.602, f32[] %param_6.521), metadata={op_type="max" op_name="pmap(_multi_device_update_fn)/max" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=122}
  %multiply.2218 = f32[] multiply(f32[] %param_4.881, f32[] %maximum.82), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=122}
  %broadcast.2575 = f32[1024,1024]{1,0} broadcast(f32[] %multiply.2218), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=152}
  %param_2.1931 = f32[1024,1024]{1,0} parameter(2)
  %param_3.1538 = f32[1024]{0} parameter(3)
  %constant.21395 = f32[] constant(0.0625)
  %broadcast.2573 = f32[1024]{0} broadcast(f32[] %constant.21395), dimensions={}
  %multiply.2215 = f32[1024]{0} multiply(f32[1024]{0} %param_3.1538, f32[1024]{0} %broadcast.2573)
  %broadcast.2574 = f32[1024,1024]{1,0} broadcast(f32[1024]{0} %multiply.2215), dimensions={0}
  %multiply.2216 = f32[1024,1024]{1,0} multiply(f32[1024,1024]{1,0} %param_2.1931, f32[1024,1024]{1,0} %broadcast.2574), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  %param_1.2271 = f32[1024]{0} parameter(1)
  %broadcast.2572 = f32[1024,1024]{1,0} broadcast(f32[1024]{0} %param_1.2271), dimensions={1}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  %multiply.2217 = f32[1024,1024]{1,0} multiply(f32[1024,1024]{1,0} %multiply.2216, f32[1024,1024]{1,0} %broadcast.2572), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  %param_0.1449 = f32[] parameter(0)
  %maximum.81 = f32[] maximum(f32[] %constant.21394, f32[] %param_0.1449), metadata={op_type="max" op_name="pmap(_multi_device_update_fn)/max" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %broadcast.2570 = f32[1024,1024]{1,0} broadcast(f32[] %maximum.81), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=150}
  %divide.282 = f32[1024,1024]{1,0} divide(f32[1024,1024]{1,0} %multiply.2217, f32[1024,1024]{1,0} %broadcast.2570), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=150}
  %multiply.2219 = f32[1024,1024]{1,0} multiply(f32[1024,1024]{1,0} %broadcast.2575, f32[1024,1024]{1,0} %divide.282), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=152}
  ROOT %subtract.735 = f32[1024,1024]{1,0} subtract(f32[1024,1024]{1,0} %multiply.2220, f32[1024,1024]{1,0} %multiply.2219), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
}

%parallel_fusion.446 (p.226: f32[], p.227: f32[1024], p.228: f32[1024,1024], p.229: f32[1024], p.230: f32[], p.231: f32[], p.232: f32[], p.233: f32[1024,1024], p.234: f32[], p.235: f32[], p.236: s32[]) -> f32[1024,1024] {
  %p.226 = f32[] parameter(0)
  %p.227 = f32[1024]{0} parameter(1)
  %p.228 = f32[1024,1024]{1,0} parameter(2)
  %p.229 = f32[1024]{0} parameter(3)
  %p.230 = f32[] parameter(4)
  %p.231 = f32[] parameter(5)
  %p.232 = f32[] parameter(6)
  %p.233 = f32[1024,1024]{1,0} parameter(7)
  %p.234 = f32[] parameter(8)
  %p.235 = f32[] parameter(9)
  %p.236 = s32[] parameter(10)
  ROOT %fusion.446.clone = f32[1024,1024]{1,0} fusion(f32[] %p.226, f32[1024]{0} %p.227, f32[1024,1024]{1,0} %p.228, f32[1024]{0} %p.229, f32[] %p.230, /*index=5*/f32[] %p.231, f32[] %p.232, f32[1024,1024]{1,0} %p.233, f32[] %p.234, f32[] %p.235, /*index=10*/s32[] %p.236), kind=kLoop, calls=%fused_computation.446.clone, outer_dimension_partitions={9}, metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
}

%fused_computation.448.clone (param_0.1450: f32[1024], param_1.2272: f32[1024,1024], param_2.1932: f32[1024]) -> f32[1024,1024] {
  %param_1.2272 = f32[1024,1024]{1,0} parameter(1)
  %param_2.1932 = f32[1024]{0} parameter(2)
  %constant.21398 = f32[] constant(0.0625)
  %broadcast.2578 = f32[1024]{0} broadcast(f32[] %constant.21398), dimensions={}
  %multiply.2221 = f32[1024]{0} multiply(f32[1024]{0} %param_2.1932, f32[1024]{0} %broadcast.2578)
  %broadcast.2579 = f32[1024,1024]{1,0} broadcast(f32[1024]{0} %multiply.2221), dimensions={0}
  %multiply.2222 = f32[1024,1024]{1,0} multiply(f32[1024,1024]{1,0} %param_1.2272, f32[1024,1024]{1,0} %broadcast.2579), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  %param_0.1450 = f32[1024]{0} parameter(0)
  %broadcast.2577 = f32[1024,1024]{1,0} broadcast(f32[1024]{0} %param_0.1450), dimensions={1}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  %multiply.2223 = f32[1024,1024]{1,0} multiply(f32[1024,1024]{1,0} %multiply.2222, f32[1024,1024]{1,0} %broadcast.2577), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  ROOT %multiply.2224 = f32[1024,1024]{1,0} multiply(f32[1024,1024]{1,0} %multiply.2223, f32[1024,1024]{1,0} %multiply.2223), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
}

%parallel_fusion.448 (p.237: f32[1024], p.238: f32[1024,1024], p.239: f32[1024]) -> f32[1024,1024] {
  %p.237 = f32[1024]{0} parameter(0)
  %p.238 = f32[1024,1024]{1,0} parameter(1)
  %p.239 = f32[1024]{0} parameter(2)
  ROOT %fusion.448.clone = f32[1024,1024]{1,0} fusion(f32[1024]{0} %p.237, f32[1024,1024]{1,0} %p.238, f32[1024]{0} %p.239), kind=kLoop, calls=%fused_computation.448.clone, outer_dimension_partitions={9}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
}

%fused_computation.453.clone (param_0.1451: f32[1024,1024]) -> f32[1024,1024] {
  %param_0.1451 = f32[1024,1024]{1,0} parameter(0)
  %constant.21399 = f32[] constant(0.0625)
  %broadcast.2580 = f32[1024,1024]{1,0} broadcast(f32[] %constant.21399), dimensions={}
  %multiply.2225 = f32[1024,1024]{1,0} multiply(f32[1024,1024]{1,0} %param_0.1451, f32[1024,1024]{1,0} %broadcast.2580), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=200}
  ROOT %multiply.2226 = f32[1024,1024]{1,0} multiply(f32[1024,1024]{1,0} %multiply.2225, f32[1024,1024]{1,0} %multiply.2225), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=126}
}

%parallel_fusion.453 (p.240: f32[1024,1024]) -> f32[1024,1024] {
  %p.240 = f32[1024,1024]{1,0} parameter(0)
  ROOT %fusion.453.clone = f32[1024,1024]{1,0} fusion(f32[1024,1024]{1,0} %p.240), kind=kLoop, calls=%fused_computation.453.clone, outer_dimension_partitions={9}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=126}
}

%fused_computation.454.clone (param_0.1452: f32[8,64,1024]) -> f32[1024,512] {
  %param_0.1452 = f32[8,64,1024]{2,1,0} parameter(0)
  %transpose.120 = f32[1024,8,64]{2,1,0} transpose(f32[8,64,1024]{2,1,0} %param_0.1452), dimensions={2,0,1}
  ROOT %reshape.3456 = f32[1024,512]{1,0} reshape(f32[1024,8,64]{2,1,0} %transpose.120)
}

%parallel_fusion.454 (p.241: f32[8,64,1024]) -> f32[1024,512] {
  %p.241 = f32[8,64,1024]{2,1,0} parameter(0)
  ROOT %fusion.454.clone = f32[1024,512]{1,0} fusion(f32[8,64,1024]{2,1,0} %p.241), kind=kLoop, calls=%fused_computation.454.clone, outer_dimension_partitions={8}
}

%fused_computation.462.clone (param_0.1453: f32[], param_1.2273: f32[1024], param_2.1933: f32[1024,1024], param_3.1539: f32[1024], param_4.882: f32[], param_5.603: f32[], param_6.522: f32[], param_7.456: f32[1024,1024], param_8.348: f32[], param_9.290: f32[], param_10.229: s32[]) -> f32[1024,1024] {
  %constant.21400 = f32[] constant(1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/metrics.py" source_line=617}
  %param_10.229 = s32[] parameter(10)
  %constant.21403 = s32[] constant(1), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=113}
  %compare.2826 = pred[] compare(s32[] %param_10.229, s32[] %constant.21403), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=113}
  %param_8.348 = f32[] parameter(8)
  %param_9.290 = f32[] parameter(9)
  %select.2713 = f32[] select(pred[] %compare.2826, f32[] %param_8.348, f32[] %param_9.290), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/jit(_where)/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=112}
  %subtract.736 = f32[] subtract(f32[] %constant.21400, f32[] %select.2713), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  %broadcast.2586 = f32[1024,1024]{1,0} broadcast(f32[] %subtract.736), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  %param_7.456 = f32[1024,1024]{1,0} parameter(7)
  %multiply.2232 = f32[1024,1024]{1,0} multiply(f32[1024,1024]{1,0} %broadcast.2586, f32[1024,1024]{1,0} %param_7.456), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  %param_4.882 = f32[] parameter(4)
  %param_5.603 = f32[] parameter(5)
  %param_6.522 = f32[] parameter(6)
  %maximum.84 = f32[] maximum(f32[] %param_5.603, f32[] %param_6.522), metadata={op_type="max" op_name="pmap(_multi_device_update_fn)/max" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=122}
  %multiply.2230 = f32[] multiply(f32[] %param_4.882, f32[] %maximum.84), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=122}
  %broadcast.2585 = f32[1024,1024]{1,0} broadcast(f32[] %multiply.2230), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=152}
  %param_2.1933 = f32[1024,1024]{1,0} parameter(2)
  %param_3.1539 = f32[1024]{0} parameter(3)
  %constant.21401 = f32[] constant(0.0625)
  %broadcast.2583 = f32[1024]{0} broadcast(f32[] %constant.21401), dimensions={}
  %multiply.2227 = f32[1024]{0} multiply(f32[1024]{0} %param_3.1539, f32[1024]{0} %broadcast.2583)
  %broadcast.2584 = f32[1024,1024]{1,0} broadcast(f32[1024]{0} %multiply.2227), dimensions={0}
  %multiply.2228 = f32[1024,1024]{1,0} multiply(f32[1024,1024]{1,0} %param_2.1933, f32[1024,1024]{1,0} %broadcast.2584), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  %param_1.2273 = f32[1024]{0} parameter(1)
  %broadcast.2582 = f32[1024,1024]{1,0} broadcast(f32[1024]{0} %param_1.2273), dimensions={1}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  %multiply.2229 = f32[1024,1024]{1,0} multiply(f32[1024,1024]{1,0} %multiply.2228, f32[1024,1024]{1,0} %broadcast.2582), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  %param_0.1453 = f32[] parameter(0)
  %maximum.83 = f32[] maximum(f32[] %constant.21400, f32[] %param_0.1453), metadata={op_type="max" op_name="pmap(_multi_device_update_fn)/max" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %broadcast.2581 = f32[1024,1024]{1,0} broadcast(f32[] %maximum.83), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=150}
  %divide.283 = f32[1024,1024]{1,0} divide(f32[1024,1024]{1,0} %multiply.2229, f32[1024,1024]{1,0} %broadcast.2581), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=150}
  %multiply.2231 = f32[1024,1024]{1,0} multiply(f32[1024,1024]{1,0} %broadcast.2585, f32[1024,1024]{1,0} %divide.283), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=152}
  ROOT %subtract.737 = f32[1024,1024]{1,0} subtract(f32[1024,1024]{1,0} %multiply.2232, f32[1024,1024]{1,0} %multiply.2231), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
}

%parallel_fusion.462 (p.242: f32[], p.243: f32[1024], p.244: f32[1024,1024], p.245: f32[1024], p.246: f32[], p.247: f32[], p.248: f32[], p.249: f32[1024,1024], p.250: f32[], p.251: f32[], p.252: s32[]) -> f32[1024,1024] {
  %p.242 = f32[] parameter(0)
  %p.243 = f32[1024]{0} parameter(1)
  %p.244 = f32[1024,1024]{1,0} parameter(2)
  %p.245 = f32[1024]{0} parameter(3)
  %p.246 = f32[] parameter(4)
  %p.247 = f32[] parameter(5)
  %p.248 = f32[] parameter(6)
  %p.249 = f32[1024,1024]{1,0} parameter(7)
  %p.250 = f32[] parameter(8)
  %p.251 = f32[] parameter(9)
  %p.252 = s32[] parameter(10)
  ROOT %fusion.462.clone = f32[1024,1024]{1,0} fusion(f32[] %p.242, f32[1024]{0} %p.243, f32[1024,1024]{1,0} %p.244, f32[1024]{0} %p.245, f32[] %p.246, /*index=5*/f32[] %p.247, f32[] %p.248, f32[1024,1024]{1,0} %p.249, f32[] %p.250, f32[] %p.251, /*index=10*/s32[] %p.252), kind=kLoop, calls=%fused_computation.462.clone, outer_dimension_partitions={9}, metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
}

%fused_computation.464.clone (param_0.1454: f32[1024], param_1.2274: f32[1024,1024], param_2.1934: f32[1024]) -> f32[1024,1024] {
  %param_1.2274 = f32[1024,1024]{1,0} parameter(1)
  %param_2.1934 = f32[1024]{0} parameter(2)
  %constant.21404 = f32[] constant(0.0625)
  %broadcast.2588 = f32[1024]{0} broadcast(f32[] %constant.21404), dimensions={}
  %multiply.2233 = f32[1024]{0} multiply(f32[1024]{0} %param_2.1934, f32[1024]{0} %broadcast.2588)
  %broadcast.2589 = f32[1024,1024]{1,0} broadcast(f32[1024]{0} %multiply.2233), dimensions={0}
  %multiply.2234 = f32[1024,1024]{1,0} multiply(f32[1024,1024]{1,0} %param_1.2274, f32[1024,1024]{1,0} %broadcast.2589), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  %param_0.1454 = f32[1024]{0} parameter(0)
  %broadcast.2587 = f32[1024,1024]{1,0} broadcast(f32[1024]{0} %param_0.1454), dimensions={1}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  %multiply.2235 = f32[1024,1024]{1,0} multiply(f32[1024,1024]{1,0} %multiply.2234, f32[1024,1024]{1,0} %broadcast.2587), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  ROOT %multiply.2236 = f32[1024,1024]{1,0} multiply(f32[1024,1024]{1,0} %multiply.2235, f32[1024,1024]{1,0} %multiply.2235), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
}

%parallel_fusion.464 (p.253: f32[1024], p.254: f32[1024,1024], p.255: f32[1024]) -> f32[1024,1024] {
  %p.253 = f32[1024]{0} parameter(0)
  %p.254 = f32[1024,1024]{1,0} parameter(1)
  %p.255 = f32[1024]{0} parameter(2)
  ROOT %fusion.464.clone = f32[1024,1024]{1,0} fusion(f32[1024]{0} %p.253, f32[1024,1024]{1,0} %p.254, f32[1024]{0} %p.255), kind=kLoop, calls=%fused_computation.464.clone, outer_dimension_partitions={9}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
}

%fused_computation.469.clone (param_0.1455: f32[1024,1024]) -> f32[1024,1024] {
  %param_0.1455 = f32[1024,1024]{1,0} parameter(0)
  %constant.21405 = f32[] constant(0.0625)
  %broadcast.2590 = f32[1024,1024]{1,0} broadcast(f32[] %constant.21405), dimensions={}
  %multiply.2237 = f32[1024,1024]{1,0} multiply(f32[1024,1024]{1,0} %param_0.1455, f32[1024,1024]{1,0} %broadcast.2590), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=200}
  ROOT %multiply.2238 = f32[1024,1024]{1,0} multiply(f32[1024,1024]{1,0} %multiply.2237, f32[1024,1024]{1,0} %multiply.2237), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=126}
}

%parallel_fusion.469 (p.256: f32[1024,1024]) -> f32[1024,1024] {
  %p.256 = f32[1024,1024]{1,0} parameter(0)
  ROOT %fusion.469.clone = f32[1024,1024]{1,0} fusion(f32[1024,1024]{1,0} %p.256), kind=kLoop, calls=%fused_computation.469.clone, outer_dimension_partitions={9}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=126}
}

%fused_computation.470.clone (param_0.1456: f32[8,64,1024]) -> f32[1024,512] {
  %param_0.1456 = f32[8,64,1024]{2,1,0} parameter(0)
  %transpose.121 = f32[1024,8,64]{2,1,0} transpose(f32[8,64,1024]{2,1,0} %param_0.1456), dimensions={2,0,1}
  ROOT %reshape.3457 = f32[1024,512]{1,0} reshape(f32[1024,8,64]{2,1,0} %transpose.121)
}

%parallel_fusion.470 (p.257: f32[8,64,1024]) -> f32[1024,512] {
  %p.257 = f32[8,64,1024]{2,1,0} parameter(0)
  ROOT %fusion.470.clone = f32[1024,512]{1,0} fusion(f32[8,64,1024]{2,1,0} %p.257), kind=kLoop, calls=%fused_computation.470.clone, outer_dimension_partitions={8}
}

%fused_computation.478.clone (param_0.1457: f32[], param_1.2275: f32[4096], param_2.1935: f32[2048,4096], param_3.1540: f32[2048], param_4.883: f32[], param_5.604: f32[], param_6.523: f32[], param_7.457: f32[2048,4096], param_8.349: f32[], param_9.291: f32[], param_10.230: s32[]) -> f32[2048,4096] {
  %constant.21406 = f32[] constant(1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/metrics.py" source_line=617}
  %param_10.230 = s32[] parameter(10)
  %constant.21409 = s32[] constant(1), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=113}
  %compare.2827 = pred[] compare(s32[] %param_10.230, s32[] %constant.21409), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=113}
  %param_8.349 = f32[] parameter(8)
  %param_9.291 = f32[] parameter(9)
  %select.2715 = f32[] select(pred[] %compare.2827, f32[] %param_8.349, f32[] %param_9.291), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/jit(_where)/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=112}
  %subtract.738 = f32[] subtract(f32[] %constant.21406, f32[] %select.2715), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  %broadcast.2597 = f32[2048,4096]{1,0} broadcast(f32[] %subtract.738), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  %param_7.457 = f32[2048,4096]{1,0} parameter(7)
  %multiply.2244 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %broadcast.2597, f32[2048,4096]{1,0} %param_7.457), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  %param_4.883 = f32[] parameter(4)
  %param_5.604 = f32[] parameter(5)
  %param_6.523 = f32[] parameter(6)
  %maximum.86 = f32[] maximum(f32[] %param_5.604, f32[] %param_6.523), metadata={op_type="max" op_name="pmap(_multi_device_update_fn)/max" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=122}
  %multiply.2242 = f32[] multiply(f32[] %param_4.883, f32[] %maximum.86), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=122}
  %broadcast.2596 = f32[2048,4096]{1,0} broadcast(f32[] %multiply.2242), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=152}
  %param_2.1935 = f32[2048,4096]{1,0} parameter(2)
  %param_3.1540 = f32[2048]{0} parameter(3)
  %constant.21408 = f32[] constant(0.0625)
  %broadcast.2593 = f32[2048]{0} broadcast(f32[] %constant.21408), dimensions={}
  %multiply.2239 = f32[2048]{0} multiply(f32[2048]{0} %param_3.1540, f32[2048]{0} %broadcast.2593)
  %broadcast.2595 = f32[2048,4096]{1,0} broadcast(f32[2048]{0} %multiply.2239), dimensions={0}
  %multiply.2240 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %param_2.1935, f32[2048,4096]{1,0} %broadcast.2595), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  %param_1.2275 = f32[4096]{0} parameter(1)
  %broadcast.2592 = f32[2048,4096]{1,0} broadcast(f32[4096]{0} %param_1.2275), dimensions={1}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  %multiply.2241 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %multiply.2240, f32[2048,4096]{1,0} %broadcast.2592), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  %param_0.1457 = f32[] parameter(0)
  %maximum.85 = f32[] maximum(f32[] %constant.21406, f32[] %param_0.1457), metadata={op_type="max" op_name="pmap(_multi_device_update_fn)/max" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %broadcast.2591 = f32[2048,4096]{1,0} broadcast(f32[] %maximum.85), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=150}
  %divide.284 = f32[2048,4096]{1,0} divide(f32[2048,4096]{1,0} %multiply.2241, f32[2048,4096]{1,0} %broadcast.2591), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=150}
  %multiply.2243 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %broadcast.2596, f32[2048,4096]{1,0} %divide.284), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=152}
  ROOT %subtract.739 = f32[2048,4096]{1,0} subtract(f32[2048,4096]{1,0} %multiply.2244, f32[2048,4096]{1,0} %multiply.2243), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
}

%parallel_fusion.478 (p.258: f32[], p.259: f32[4096], p.260: f32[2048,4096], p.261: f32[2048], p.262: f32[], p.263: f32[], p.264: f32[], p.265: f32[2048,4096], p.266: f32[], p.267: f32[], p.268: s32[]) -> f32[2048,4096] {
  %p.258 = f32[] parameter(0)
  %p.259 = f32[4096]{0} parameter(1)
  %p.260 = f32[2048,4096]{1,0} parameter(2)
  %p.261 = f32[2048]{0} parameter(3)
  %p.262 = f32[] parameter(4)
  %p.263 = f32[] parameter(5)
  %p.264 = f32[] parameter(6)
  %p.265 = f32[2048,4096]{1,0} parameter(7)
  %p.266 = f32[] parameter(8)
  %p.267 = f32[] parameter(9)
  %p.268 = s32[] parameter(10)
  ROOT %fusion.478.clone = f32[2048,4096]{1,0} fusion(f32[] %p.258, f32[4096]{0} %p.259, f32[2048,4096]{1,0} %p.260, f32[2048]{0} %p.261, f32[] %p.262, /*index=5*/f32[] %p.263, f32[] %p.264, f32[2048,4096]{1,0} %p.265, f32[] %p.266, f32[] %p.267, /*index=10*/s32[] %p.268), kind=kLoop, calls=%fused_computation.478.clone, outer_dimension_partitions={9}, metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
}

%fused_computation.480.clone (param_0.1458: f32[4096], param_1.2276: f32[2048,4096], param_2.1936: f32[2048]) -> f32[2048,4096] {
  %param_1.2276 = f32[2048,4096]{1,0} parameter(1)
  %param_2.1936 = f32[2048]{0} parameter(2)
  %constant.21410 = f32[] constant(0.0625)
  %broadcast.2599 = f32[2048]{0} broadcast(f32[] %constant.21410), dimensions={}
  %multiply.2245 = f32[2048]{0} multiply(f32[2048]{0} %param_2.1936, f32[2048]{0} %broadcast.2599)
  %broadcast.2600 = f32[2048,4096]{1,0} broadcast(f32[2048]{0} %multiply.2245), dimensions={0}
  %multiply.2246 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %param_1.2276, f32[2048,4096]{1,0} %broadcast.2600), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  %param_0.1458 = f32[4096]{0} parameter(0)
  %broadcast.2598 = f32[2048,4096]{1,0} broadcast(f32[4096]{0} %param_0.1458), dimensions={1}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  %multiply.2247 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %multiply.2246, f32[2048,4096]{1,0} %broadcast.2598), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  ROOT %multiply.2248 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %multiply.2247, f32[2048,4096]{1,0} %multiply.2247), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
}

%parallel_fusion.480 (p.269: f32[4096], p.270: f32[2048,4096], p.271: f32[2048]) -> f32[2048,4096] {
  %p.269 = f32[4096]{0} parameter(0)
  %p.270 = f32[2048,4096]{1,0} parameter(1)
  %p.271 = f32[2048]{0} parameter(2)
  ROOT %fusion.480.clone = f32[2048,4096]{1,0} fusion(f32[4096]{0} %p.269, f32[2048,4096]{1,0} %p.270, f32[2048]{0} %p.271), kind=kLoop, calls=%fused_computation.480.clone, outer_dimension_partitions={9}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
}

%fused_computation.485.clone (param_0.1459: f32[2048,4096]) -> f32[2048,4096] {
  %param_0.1459 = f32[2048,4096]{1,0} parameter(0)
  %constant.21411 = f32[] constant(0.0625)
  %broadcast.2601 = f32[2048,4096]{1,0} broadcast(f32[] %constant.21411), dimensions={}
  %multiply.2249 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %param_0.1459, f32[2048,4096]{1,0} %broadcast.2601), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=200}
  ROOT %multiply.2250 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %multiply.2249, f32[2048,4096]{1,0} %multiply.2249), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=126}
}

%parallel_fusion.485 (p.272: f32[2048,4096]) -> f32[2048,4096] {
  %p.272 = f32[2048,4096]{1,0} parameter(0)
  ROOT %fusion.485.clone = f32[2048,4096]{1,0} fusion(f32[2048,4096]{1,0} %p.272), kind=kLoop, calls=%fused_computation.485.clone, outer_dimension_partitions={9}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=126}
}

%fused_computation.487.clone (param_0.1460: f32[], param_1.2277: f32[1024], param_2.1937: f32[256,1024], param_3.1541: f32[256], param_4.884: f32[], param_5.605: f32[], param_6.524: f32[], param_7.458: f32[256,1024], param_8.350: f32[], param_9.292: f32[], param_10.231: s32[]) -> f32[256,1024] {
  %constant.21413 = f32[] constant(1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/metrics.py" source_line=617}
  %param_10.231 = s32[] parameter(10)
  %constant.21415 = s32[] constant(1), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=113}
  %compare.2828 = pred[] compare(s32[] %param_10.231, s32[] %constant.21415), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=113}
  %param_8.350 = f32[] parameter(8)
  %param_9.292 = f32[] parameter(9)
  %select.2716 = f32[] select(pred[] %compare.2828, f32[] %param_8.350, f32[] %param_9.292), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/jit(_where)/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=112}
  %subtract.740 = f32[] subtract(f32[] %constant.21413, f32[] %select.2716), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  %broadcast.2607 = f32[256,1024]{1,0} broadcast(f32[] %subtract.740), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  %param_7.458 = f32[256,1024]{1,0} parameter(7)
  %multiply.2256 = f32[256,1024]{1,0} multiply(f32[256,1024]{1,0} %broadcast.2607, f32[256,1024]{1,0} %param_7.458), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  %param_4.884 = f32[] parameter(4)
  %param_5.605 = f32[] parameter(5)
  %param_6.524 = f32[] parameter(6)
  %maximum.88 = f32[] maximum(f32[] %param_5.605, f32[] %param_6.524), metadata={op_type="max" op_name="pmap(_multi_device_update_fn)/max" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=122}
  %multiply.2254 = f32[] multiply(f32[] %param_4.884, f32[] %maximum.88), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=122}
  %broadcast.2606 = f32[256,1024]{1,0} broadcast(f32[] %multiply.2254), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=152}
  %param_2.1937 = f32[256,1024]{1,0} parameter(2)
  %param_3.1541 = f32[256]{0} parameter(3)
  %constant.21414 = f32[] constant(0.0625)
  %broadcast.2604 = f32[256]{0} broadcast(f32[] %constant.21414), dimensions={}
  %multiply.2251 = f32[256]{0} multiply(f32[256]{0} %param_3.1541, f32[256]{0} %broadcast.2604)
  %broadcast.2605 = f32[256,1024]{1,0} broadcast(f32[256]{0} %multiply.2251), dimensions={0}
  %multiply.2252 = f32[256,1024]{1,0} multiply(f32[256,1024]{1,0} %param_2.1937, f32[256,1024]{1,0} %broadcast.2605), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  %param_1.2277 = f32[1024]{0} parameter(1)
  %broadcast.2603 = f32[256,1024]{1,0} broadcast(f32[1024]{0} %param_1.2277), dimensions={1}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  %multiply.2253 = f32[256,1024]{1,0} multiply(f32[256,1024]{1,0} %multiply.2252, f32[256,1024]{1,0} %broadcast.2603), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  %param_0.1460 = f32[] parameter(0)
  %maximum.87 = f32[] maximum(f32[] %constant.21413, f32[] %param_0.1460), metadata={op_type="max" op_name="pmap(_multi_device_update_fn)/max" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %broadcast.2602 = f32[256,1024]{1,0} broadcast(f32[] %maximum.87), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=150}
  %divide.285 = f32[256,1024]{1,0} divide(f32[256,1024]{1,0} %multiply.2253, f32[256,1024]{1,0} %broadcast.2602), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=150}
  %multiply.2255 = f32[256,1024]{1,0} multiply(f32[256,1024]{1,0} %broadcast.2606, f32[256,1024]{1,0} %divide.285), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=152}
  ROOT %subtract.741 = f32[256,1024]{1,0} subtract(f32[256,1024]{1,0} %multiply.2256, f32[256,1024]{1,0} %multiply.2255), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
}

%parallel_fusion.487 (p.273: f32[], p.274: f32[1024], p.275: f32[256,1024], p.276: f32[256], p.277: f32[], p.278: f32[], p.279: f32[], p.280: f32[256,1024], p.281: f32[], p.282: f32[], p.283: s32[]) -> f32[256,1024] {
  %p.273 = f32[] parameter(0)
  %p.274 = f32[1024]{0} parameter(1)
  %p.275 = f32[256,1024]{1,0} parameter(2)
  %p.276 = f32[256]{0} parameter(3)
  %p.277 = f32[] parameter(4)
  %p.278 = f32[] parameter(5)
  %p.279 = f32[] parameter(6)
  %p.280 = f32[256,1024]{1,0} parameter(7)
  %p.281 = f32[] parameter(8)
  %p.282 = f32[] parameter(9)
  %p.283 = s32[] parameter(10)
  ROOT %fusion.487.clone = f32[256,1024]{1,0} fusion(f32[] %p.273, f32[1024]{0} %p.274, f32[256,1024]{1,0} %p.275, f32[256]{0} %p.276, f32[] %p.277, /*index=5*/f32[] %p.278, f32[] %p.279, f32[256,1024]{1,0} %p.280, f32[] %p.281, f32[] %p.282, /*index=10*/s32[] %p.283), kind=kLoop, calls=%fused_computation.487.clone, outer_dimension_partitions={4}, metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
}

%fused_computation.489.clone (param_0.1461: f32[1024], param_1.2278: f32[256,1024], param_2.1938: f32[256]) -> f32[256,1024] {
  %param_1.2278 = f32[256,1024]{1,0} parameter(1)
  %param_2.1938 = f32[256]{0} parameter(2)
  %constant.21416 = f32[] constant(0.0625)
  %broadcast.2609 = f32[256]{0} broadcast(f32[] %constant.21416), dimensions={}
  %multiply.2257 = f32[256]{0} multiply(f32[256]{0} %param_2.1938, f32[256]{0} %broadcast.2609)
  %broadcast.2610 = f32[256,1024]{1,0} broadcast(f32[256]{0} %multiply.2257), dimensions={0}
  %multiply.2258 = f32[256,1024]{1,0} multiply(f32[256,1024]{1,0} %param_1.2278, f32[256,1024]{1,0} %broadcast.2610), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  %param_0.1461 = f32[1024]{0} parameter(0)
  %broadcast.2608 = f32[256,1024]{1,0} broadcast(f32[1024]{0} %param_0.1461), dimensions={1}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  %multiply.2259 = f32[256,1024]{1,0} multiply(f32[256,1024]{1,0} %multiply.2258, f32[256,1024]{1,0} %broadcast.2608), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  ROOT %multiply.2260 = f32[256,1024]{1,0} multiply(f32[256,1024]{1,0} %multiply.2259, f32[256,1024]{1,0} %multiply.2259), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
}

%parallel_fusion.489 (p.284: f32[1024], p.285: f32[256,1024], p.286: f32[256]) -> f32[256,1024] {
  %p.284 = f32[1024]{0} parameter(0)
  %p.285 = f32[256,1024]{1,0} parameter(1)
  %p.286 = f32[256]{0} parameter(2)
  ROOT %fusion.489.clone = f32[256,1024]{1,0} fusion(f32[1024]{0} %p.284, f32[256,1024]{1,0} %p.285, f32[256]{0} %p.286), kind=kLoop, calls=%fused_computation.489.clone, outer_dimension_partitions={4}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
}

%fused_computation.494.clone (param_0.1462: f32[256,1024]) -> f32[256,1024] {
  %param_0.1462 = f32[256,1024]{1,0} parameter(0)
  %constant.21417 = f32[] constant(0.0625)
  %broadcast.2611 = f32[256,1024]{1,0} broadcast(f32[] %constant.21417), dimensions={}
  %multiply.2261 = f32[256,1024]{1,0} multiply(f32[256,1024]{1,0} %param_0.1462, f32[256,1024]{1,0} %broadcast.2611), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=200}
  ROOT %multiply.2262 = f32[256,1024]{1,0} multiply(f32[256,1024]{1,0} %multiply.2261, f32[256,1024]{1,0} %multiply.2261), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=126}
}

%parallel_fusion.494 (p.287: f32[256,1024]) -> f32[256,1024] {
  %p.287 = f32[256,1024]{1,0} parameter(0)
  ROOT %fusion.494.clone = f32[256,1024]{1,0} fusion(f32[256,1024]{1,0} %p.287), kind=kLoop, calls=%fused_computation.494.clone, outer_dimension_partitions={4}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=126}
}

%fused_computation.495.clone (param_0.1463: f32[64,8,1024]) -> f32[512,1024] {
  %param_0.1463 = f32[64,8,1024]{2,1,0} parameter(0)
  %transpose.122 = f32[8,64,1024]{2,1,0} transpose(f32[64,8,1024]{2,1,0} %param_0.1463), dimensions={1,0,2}, metadata={op_type="transpose" op_name="pmap(_multi_device_update_fn)/transpose[ permutation=(1, 0, 2) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/combinators.py" source_line=342}
  ROOT %reshape.3458 = f32[512,1024]{1,0} reshape(f32[8,64,1024]{2,1,0} %transpose.122)
}

%parallel_fusion.495 (p.288: f32[64,8,1024]) -> f32[512,1024] {
  %p.288 = f32[64,8,1024]{2,1,0} parameter(0)
  ROOT %fusion.495.clone = f32[512,1024]{1,0} fusion(f32[64,8,1024]{2,1,0} %p.288), kind=kLoop, calls=%fused_computation.495.clone, outer_dimension_partitions={8}
}

%fused_computation.496.clone (param_0.1464: f32[512,1024], param_1.2279: f32[64,8,1024]) -> f32[64,8,1024] {
  %param_1.2279 = f32[64,8,1024]{2,1,0} parameter(1)
  %transpose.123 = f32[8,64,1024]{2,1,0} transpose(f32[64,8,1024]{2,1,0} %param_1.2279), dimensions={1,0,2}, metadata={op_type="transpose" op_name="pmap(_multi_device_update_fn)/transpose[ permutation=(1, 0, 2) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/combinators.py" source_line=342}
  %param_0.1464 = f32[512,1024]{1,0} parameter(0)
  %reshape.3459 = f32[8,64,1024]{2,1,0} reshape(f32[512,1024]{1,0} %param_0.1464), metadata={op_type="dot_general" op_name="pmap(_multi_device_update_fn)/dot_general[ dimension_numbers=(((2,), (1,)), ((), ()))\n                                           precision=None\n                                           preferred_element_type=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/core.py" source_line=96}
  %add.4397 = f32[8,64,1024]{2,1,0} add(f32[8,64,1024]{2,1,0} %transpose.123, f32[8,64,1024]{2,1,0} %reshape.3459), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=238}
  ROOT %transpose.124 = f32[64,8,1024]{2,0,1} transpose(f32[8,64,1024]{2,1,0} %add.4397), dimensions={1,0,2}, metadata={op_type="transpose" op_name="pmap(_multi_device_update_fn)/transpose[ permutation=(1, 0, 2) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/combinators.py" source_line=342}
}

%parallel_fusion.496 (p.289: f32[512,1024], p.290: f32[64,8,1024]) -> f32[64,8,1024] {
  %p.289 = f32[512,1024]{1,0} parameter(0)
  %p.290 = f32[64,8,1024]{2,1,0} parameter(1)
  ROOT %fusion.496.clone = f32[64,8,1024]{2,0,1} fusion(f32[512,1024]{1,0} %p.289, f32[64,8,1024]{2,1,0} %p.290), kind=kLoop, calls=%fused_computation.496.clone, outer_dimension_partitions={8}, metadata={op_type="transpose" op_name="pmap(_multi_device_update_fn)/transpose[ permutation=(1, 0, 2) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/combinators.py" source_line=342}
}

%fused_computation.506.clone (param_0.1465: f32[], param_1.2280: f32[4096], param_2.1939: f32[2048,4096], param_3.1542: f32[2048], param_4.885: f32[], param_5.606: f32[], param_6.525: f32[], param_7.459: f32[2048,4096], param_8.351: f32[], param_9.293: f32[], param_10.232: s32[]) -> f32[2048,4096] {
  %constant.21418 = f32[] constant(1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/metrics.py" source_line=617}
  %param_10.232 = s32[] parameter(10)
  %constant.21421 = s32[] constant(1), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=113}
  %compare.2829 = pred[] compare(s32[] %param_10.232, s32[] %constant.21421), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=113}
  %param_8.351 = f32[] parameter(8)
  %param_9.293 = f32[] parameter(9)
  %select.2717 = f32[] select(pred[] %compare.2829, f32[] %param_8.351, f32[] %param_9.293), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/jit(_where)/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=112}
  %subtract.742 = f32[] subtract(f32[] %constant.21418, f32[] %select.2717), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  %broadcast.2618 = f32[2048,4096]{1,0} broadcast(f32[] %subtract.742), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  %param_7.459 = f32[2048,4096]{1,0} parameter(7)
  %multiply.2268 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %broadcast.2618, f32[2048,4096]{1,0} %param_7.459), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  %param_4.885 = f32[] parameter(4)
  %param_5.606 = f32[] parameter(5)
  %param_6.525 = f32[] parameter(6)
  %maximum.90 = f32[] maximum(f32[] %param_5.606, f32[] %param_6.525), metadata={op_type="max" op_name="pmap(_multi_device_update_fn)/max" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=122}
  %multiply.2266 = f32[] multiply(f32[] %param_4.885, f32[] %maximum.90), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=122}
  %broadcast.2616 = f32[2048,4096]{1,0} broadcast(f32[] %multiply.2266), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=152}
  %param_2.1939 = f32[2048,4096]{1,0} parameter(2)
  %param_3.1542 = f32[2048]{0} parameter(3)
  %constant.21419 = f32[] constant(0.0625)
  %broadcast.2614 = f32[2048]{0} broadcast(f32[] %constant.21419), dimensions={}
  %multiply.2263 = f32[2048]{0} multiply(f32[2048]{0} %param_3.1542, f32[2048]{0} %broadcast.2614)
  %broadcast.2615 = f32[2048,4096]{1,0} broadcast(f32[2048]{0} %multiply.2263), dimensions={0}
  %multiply.2264 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %param_2.1939, f32[2048,4096]{1,0} %broadcast.2615), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  %param_1.2280 = f32[4096]{0} parameter(1)
  %broadcast.2613 = f32[2048,4096]{1,0} broadcast(f32[4096]{0} %param_1.2280), dimensions={1}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  %multiply.2265 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %multiply.2264, f32[2048,4096]{1,0} %broadcast.2613), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  %param_0.1465 = f32[] parameter(0)
  %maximum.89 = f32[] maximum(f32[] %constant.21418, f32[] %param_0.1465), metadata={op_type="max" op_name="pmap(_multi_device_update_fn)/max" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %broadcast.2612 = f32[2048,4096]{1,0} broadcast(f32[] %maximum.89), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=150}
  %divide.286 = f32[2048,4096]{1,0} divide(f32[2048,4096]{1,0} %multiply.2265, f32[2048,4096]{1,0} %broadcast.2612), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=150}
  %multiply.2267 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %broadcast.2616, f32[2048,4096]{1,0} %divide.286), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=152}
  ROOT %subtract.743 = f32[2048,4096]{1,0} subtract(f32[2048,4096]{1,0} %multiply.2268, f32[2048,4096]{1,0} %multiply.2267), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
}

%parallel_fusion.506 (p.291: f32[], p.292: f32[4096], p.293: f32[2048,4096], p.294: f32[2048], p.295: f32[], p.296: f32[], p.297: f32[], p.298: f32[2048,4096], p.299: f32[], p.300: f32[], p.301: s32[]) -> f32[2048,4096] {
  %p.291 = f32[] parameter(0)
  %p.292 = f32[4096]{0} parameter(1)
  %p.293 = f32[2048,4096]{1,0} parameter(2)
  %p.294 = f32[2048]{0} parameter(3)
  %p.295 = f32[] parameter(4)
  %p.296 = f32[] parameter(5)
  %p.297 = f32[] parameter(6)
  %p.298 = f32[2048,4096]{1,0} parameter(7)
  %p.299 = f32[] parameter(8)
  %p.300 = f32[] parameter(9)
  %p.301 = s32[] parameter(10)
  ROOT %fusion.506.clone = f32[2048,4096]{1,0} fusion(f32[] %p.291, f32[4096]{0} %p.292, f32[2048,4096]{1,0} %p.293, f32[2048]{0} %p.294, f32[] %p.295, /*index=5*/f32[] %p.296, f32[] %p.297, f32[2048,4096]{1,0} %p.298, f32[] %p.299, f32[] %p.300, /*index=10*/s32[] %p.301), kind=kLoop, calls=%fused_computation.506.clone, outer_dimension_partitions={9}, metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
}

%fused_computation.508.clone (param_0.1466: f32[4096], param_1.2281: f32[2048,4096], param_2.1940: f32[2048]) -> f32[2048,4096] {
  %param_1.2281 = f32[2048,4096]{1,0} parameter(1)
  %param_2.1940 = f32[2048]{0} parameter(2)
  %constant.21422 = f32[] constant(0.0625)
  %broadcast.2620 = f32[2048]{0} broadcast(f32[] %constant.21422), dimensions={}
  %multiply.2269 = f32[2048]{0} multiply(f32[2048]{0} %param_2.1940, f32[2048]{0} %broadcast.2620)
  %broadcast.2621 = f32[2048,4096]{1,0} broadcast(f32[2048]{0} %multiply.2269), dimensions={0}
  %multiply.2270 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %param_1.2281, f32[2048,4096]{1,0} %broadcast.2621), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  %param_0.1466 = f32[4096]{0} parameter(0)
  %broadcast.2619 = f32[2048,4096]{1,0} broadcast(f32[4096]{0} %param_0.1466), dimensions={1}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  %multiply.2271 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %multiply.2270, f32[2048,4096]{1,0} %broadcast.2619), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  ROOT %multiply.2272 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %multiply.2271, f32[2048,4096]{1,0} %multiply.2271), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
}

%parallel_fusion.508 (p.302: f32[4096], p.303: f32[2048,4096], p.304: f32[2048]) -> f32[2048,4096] {
  %p.302 = f32[4096]{0} parameter(0)
  %p.303 = f32[2048,4096]{1,0} parameter(1)
  %p.304 = f32[2048]{0} parameter(2)
  ROOT %fusion.508.clone = f32[2048,4096]{1,0} fusion(f32[4096]{0} %p.302, f32[2048,4096]{1,0} %p.303, f32[2048]{0} %p.304), kind=kLoop, calls=%fused_computation.508.clone, outer_dimension_partitions={9}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
}

%fused_computation.513.clone (param_0.1467: f32[2048,4096]) -> f32[2048,4096] {
  %param_0.1467 = f32[2048,4096]{1,0} parameter(0)
  %constant.21423 = f32[] constant(0.0625)
  %broadcast.2622 = f32[2048,4096]{1,0} broadcast(f32[] %constant.21423), dimensions={}
  %multiply.2273 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %param_0.1467, f32[2048,4096]{1,0} %broadcast.2622), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=200}
  ROOT %multiply.2274 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %multiply.2273, f32[2048,4096]{1,0} %multiply.2273), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=126}
}

%parallel_fusion.513 (p.305: f32[2048,4096]) -> f32[2048,4096] {
  %p.305 = f32[2048,4096]{1,0} parameter(0)
  ROOT %fusion.513.clone = f32[2048,4096]{1,0} fusion(f32[2048,4096]{1,0} %p.305), kind=kLoop, calls=%fused_computation.513.clone, outer_dimension_partitions={9}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=126}
}

%fused_computation.521.clone (param_0.1468: f32[], param_1.2282: f32[4096], param_2.1941: f32[2048,4096], param_3.1543: f32[2048], param_4.886: f32[], param_5.607: f32[], param_6.526: f32[], param_7.460: f32[2048,4096], param_8.352: f32[], param_9.294: f32[], param_10.233: s32[]) -> f32[2048,4096] {
  %constant.21424 = f32[] constant(1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/metrics.py" source_line=617}
  %param_10.233 = s32[] parameter(10)
  %constant.21427 = s32[] constant(1), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=113}
  %compare.2830 = pred[] compare(s32[] %param_10.233, s32[] %constant.21427), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=113}
  %param_8.352 = f32[] parameter(8)
  %param_9.294 = f32[] parameter(9)
  %select.2718 = f32[] select(pred[] %compare.2830, f32[] %param_8.352, f32[] %param_9.294), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/jit(_where)/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=112}
  %subtract.744 = f32[] subtract(f32[] %constant.21424, f32[] %select.2718), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  %broadcast.2628 = f32[2048,4096]{1,0} broadcast(f32[] %subtract.744), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  %param_7.460 = f32[2048,4096]{1,0} parameter(7)
  %multiply.2280 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %broadcast.2628, f32[2048,4096]{1,0} %param_7.460), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  %param_4.886 = f32[] parameter(4)
  %param_5.607 = f32[] parameter(5)
  %param_6.526 = f32[] parameter(6)
  %maximum.92 = f32[] maximum(f32[] %param_5.607, f32[] %param_6.526), metadata={op_type="max" op_name="pmap(_multi_device_update_fn)/max" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=122}
  %multiply.2278 = f32[] multiply(f32[] %param_4.886, f32[] %maximum.92), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=122}
  %broadcast.2627 = f32[2048,4096]{1,0} broadcast(f32[] %multiply.2278), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=152}
  %param_2.1941 = f32[2048,4096]{1,0} parameter(2)
  %param_3.1543 = f32[2048]{0} parameter(3)
  %constant.21425 = f32[] constant(0.0625)
  %broadcast.2625 = f32[2048]{0} broadcast(f32[] %constant.21425), dimensions={}
  %multiply.2275 = f32[2048]{0} multiply(f32[2048]{0} %param_3.1543, f32[2048]{0} %broadcast.2625)
  %broadcast.2626 = f32[2048,4096]{1,0} broadcast(f32[2048]{0} %multiply.2275), dimensions={0}
  %multiply.2276 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %param_2.1941, f32[2048,4096]{1,0} %broadcast.2626), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  %param_1.2282 = f32[4096]{0} parameter(1)
  %broadcast.2624 = f32[2048,4096]{1,0} broadcast(f32[4096]{0} %param_1.2282), dimensions={1}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  %multiply.2277 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %multiply.2276, f32[2048,4096]{1,0} %broadcast.2624), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  %param_0.1468 = f32[] parameter(0)
  %maximum.91 = f32[] maximum(f32[] %constant.21424, f32[] %param_0.1468), metadata={op_type="max" op_name="pmap(_multi_device_update_fn)/max" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %broadcast.2623 = f32[2048,4096]{1,0} broadcast(f32[] %maximum.91), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=150}
  %divide.287 = f32[2048,4096]{1,0} divide(f32[2048,4096]{1,0} %multiply.2277, f32[2048,4096]{1,0} %broadcast.2623), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=150}
  %multiply.2279 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %broadcast.2627, f32[2048,4096]{1,0} %divide.287), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=152}
  ROOT %subtract.745 = f32[2048,4096]{1,0} subtract(f32[2048,4096]{1,0} %multiply.2280, f32[2048,4096]{1,0} %multiply.2279), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
}

%parallel_fusion.521 (p.306: f32[], p.307: f32[4096], p.308: f32[2048,4096], p.309: f32[2048], p.310: f32[], p.311: f32[], p.312: f32[], p.313: f32[2048,4096], p.314: f32[], p.315: f32[], p.316: s32[]) -> f32[2048,4096] {
  %p.306 = f32[] parameter(0)
  %p.307 = f32[4096]{0} parameter(1)
  %p.308 = f32[2048,4096]{1,0} parameter(2)
  %p.309 = f32[2048]{0} parameter(3)
  %p.310 = f32[] parameter(4)
  %p.311 = f32[] parameter(5)
  %p.312 = f32[] parameter(6)
  %p.313 = f32[2048,4096]{1,0} parameter(7)
  %p.314 = f32[] parameter(8)
  %p.315 = f32[] parameter(9)
  %p.316 = s32[] parameter(10)
  ROOT %fusion.521.clone = f32[2048,4096]{1,0} fusion(f32[] %p.306, f32[4096]{0} %p.307, f32[2048,4096]{1,0} %p.308, f32[2048]{0} %p.309, f32[] %p.310, /*index=5*/f32[] %p.311, f32[] %p.312, f32[2048,4096]{1,0} %p.313, f32[] %p.314, f32[] %p.315, /*index=10*/s32[] %p.316), kind=kLoop, calls=%fused_computation.521.clone, outer_dimension_partitions={9}, metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
}

%fused_computation.523.clone (param_0.1469: f32[4096], param_1.2283: f32[2048,4096], param_2.1942: f32[2048]) -> f32[2048,4096] {
  %param_1.2283 = f32[2048,4096]{1,0} parameter(1)
  %param_2.1942 = f32[2048]{0} parameter(2)
  %constant.21428 = f32[] constant(0.0625)
  %broadcast.2630 = f32[2048]{0} broadcast(f32[] %constant.21428), dimensions={}
  %multiply.2281 = f32[2048]{0} multiply(f32[2048]{0} %param_2.1942, f32[2048]{0} %broadcast.2630)
  %broadcast.2631 = f32[2048,4096]{1,0} broadcast(f32[2048]{0} %multiply.2281), dimensions={0}
  %multiply.2282 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %param_1.2283, f32[2048,4096]{1,0} %broadcast.2631), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  %param_0.1469 = f32[4096]{0} parameter(0)
  %broadcast.2629 = f32[2048,4096]{1,0} broadcast(f32[4096]{0} %param_0.1469), dimensions={1}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  %multiply.2283 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %multiply.2282, f32[2048,4096]{1,0} %broadcast.2629), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  ROOT %multiply.2284 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %multiply.2283, f32[2048,4096]{1,0} %multiply.2283), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
}

%parallel_fusion.523 (p.317: f32[4096], p.318: f32[2048,4096], p.319: f32[2048]) -> f32[2048,4096] {
  %p.317 = f32[4096]{0} parameter(0)
  %p.318 = f32[2048,4096]{1,0} parameter(1)
  %p.319 = f32[2048]{0} parameter(2)
  ROOT %fusion.523.clone = f32[2048,4096]{1,0} fusion(f32[4096]{0} %p.317, f32[2048,4096]{1,0} %p.318, f32[2048]{0} %p.319), kind=kLoop, calls=%fused_computation.523.clone, outer_dimension_partitions={9}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
}

%fused_computation.528.clone (param_0.1470: f32[2048,4096]) -> f32[2048,4096] {
  %param_0.1470 = f32[2048,4096]{1,0} parameter(0)
  %constant.21429 = f32[] constant(0.0625)
  %broadcast.2632 = f32[2048,4096]{1,0} broadcast(f32[] %constant.21429), dimensions={}
  %multiply.2285 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %param_0.1470, f32[2048,4096]{1,0} %broadcast.2632), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=200}
  ROOT %multiply.2286 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %multiply.2285, f32[2048,4096]{1,0} %multiply.2285), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=126}
}

%parallel_fusion.528 (p.320: f32[2048,4096]) -> f32[2048,4096] {
  %p.320 = f32[2048,4096]{1,0} parameter(0)
  ROOT %fusion.528.clone = f32[2048,4096]{1,0} fusion(f32[2048,4096]{1,0} %p.320), kind=kLoop, calls=%fused_computation.528.clone, outer_dimension_partitions={9}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=126}
}

%fused_computation.536.clone (param_0.1471: f32[], param_1.2284: f32[4096], param_2.1943: f32[2048,4096], param_3.1544: f32[2048], param_4.887: f32[], param_5.608: f32[], param_6.527: f32[], param_7.461: f32[2048,4096], param_8.353: f32[], param_9.295: f32[], param_10.234: s32[]) -> f32[2048,4096] {
  %constant.21431 = f32[] constant(1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/metrics.py" source_line=617}
  %param_10.234 = s32[] parameter(10)
  %constant.21434 = s32[] constant(1), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=113}
  %compare.2831 = pred[] compare(s32[] %param_10.234, s32[] %constant.21434), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=113}
  %param_8.353 = f32[] parameter(8)
  %param_9.295 = f32[] parameter(9)
  %select.2719 = f32[] select(pred[] %compare.2831, f32[] %param_8.353, f32[] %param_9.295), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/jit(_where)/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=112}
  %subtract.746 = f32[] subtract(f32[] %constant.21431, f32[] %select.2719), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  %broadcast.2638 = f32[2048,4096]{1,0} broadcast(f32[] %subtract.746), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  %param_7.461 = f32[2048,4096]{1,0} parameter(7)
  %multiply.2292 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %broadcast.2638, f32[2048,4096]{1,0} %param_7.461), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  %param_4.887 = f32[] parameter(4)
  %param_5.608 = f32[] parameter(5)
  %param_6.527 = f32[] parameter(6)
  %maximum.94 = f32[] maximum(f32[] %param_5.608, f32[] %param_6.527), metadata={op_type="max" op_name="pmap(_multi_device_update_fn)/max" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=122}
  %multiply.2290 = f32[] multiply(f32[] %param_4.887, f32[] %maximum.94), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=122}
  %broadcast.2637 = f32[2048,4096]{1,0} broadcast(f32[] %multiply.2290), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=152}
  %param_2.1943 = f32[2048,4096]{1,0} parameter(2)
  %param_3.1544 = f32[2048]{0} parameter(3)
  %constant.21432 = f32[] constant(0.0625)
  %broadcast.2635 = f32[2048]{0} broadcast(f32[] %constant.21432), dimensions={}
  %multiply.2287 = f32[2048]{0} multiply(f32[2048]{0} %param_3.1544, f32[2048]{0} %broadcast.2635)
  %broadcast.2636 = f32[2048,4096]{1,0} broadcast(f32[2048]{0} %multiply.2287), dimensions={0}
  %multiply.2288 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %param_2.1943, f32[2048,4096]{1,0} %broadcast.2636), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  %param_1.2284 = f32[4096]{0} parameter(1)
  %broadcast.2634 = f32[2048,4096]{1,0} broadcast(f32[4096]{0} %param_1.2284), dimensions={1}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  %multiply.2289 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %multiply.2288, f32[2048,4096]{1,0} %broadcast.2634), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  %param_0.1471 = f32[] parameter(0)
  %maximum.93 = f32[] maximum(f32[] %constant.21431, f32[] %param_0.1471), metadata={op_type="max" op_name="pmap(_multi_device_update_fn)/max" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %broadcast.2633 = f32[2048,4096]{1,0} broadcast(f32[] %maximum.93), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=150}
  %divide.288 = f32[2048,4096]{1,0} divide(f32[2048,4096]{1,0} %multiply.2289, f32[2048,4096]{1,0} %broadcast.2633), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=150}
  %multiply.2291 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %broadcast.2637, f32[2048,4096]{1,0} %divide.288), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=152}
  ROOT %subtract.747 = f32[2048,4096]{1,0} subtract(f32[2048,4096]{1,0} %multiply.2292, f32[2048,4096]{1,0} %multiply.2291), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
}

%parallel_fusion.536 (p.321: f32[], p.322: f32[4096], p.323: f32[2048,4096], p.324: f32[2048], p.325: f32[], p.326: f32[], p.327: f32[], p.328: f32[2048,4096], p.329: f32[], p.330: f32[], p.331: s32[]) -> f32[2048,4096] {
  %p.321 = f32[] parameter(0)
  %p.322 = f32[4096]{0} parameter(1)
  %p.323 = f32[2048,4096]{1,0} parameter(2)
  %p.324 = f32[2048]{0} parameter(3)
  %p.325 = f32[] parameter(4)
  %p.326 = f32[] parameter(5)
  %p.327 = f32[] parameter(6)
  %p.328 = f32[2048,4096]{1,0} parameter(7)
  %p.329 = f32[] parameter(8)
  %p.330 = f32[] parameter(9)
  %p.331 = s32[] parameter(10)
  ROOT %fusion.536.clone = f32[2048,4096]{1,0} fusion(f32[] %p.321, f32[4096]{0} %p.322, f32[2048,4096]{1,0} %p.323, f32[2048]{0} %p.324, f32[] %p.325, /*index=5*/f32[] %p.326, f32[] %p.327, f32[2048,4096]{1,0} %p.328, f32[] %p.329, f32[] %p.330, /*index=10*/s32[] %p.331), kind=kLoop, calls=%fused_computation.536.clone, outer_dimension_partitions={9}, metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
}

%fused_computation.538.clone (param_0.1472: f32[4096], param_1.2285: f32[2048,4096], param_2.1944: f32[2048]) -> f32[2048,4096] {
  %param_1.2285 = f32[2048,4096]{1,0} parameter(1)
  %param_2.1944 = f32[2048]{0} parameter(2)
  %constant.21435 = f32[] constant(0.0625)
  %broadcast.2641 = f32[2048]{0} broadcast(f32[] %constant.21435), dimensions={}
  %multiply.2293 = f32[2048]{0} multiply(f32[2048]{0} %param_2.1944, f32[2048]{0} %broadcast.2641)
  %broadcast.2642 = f32[2048,4096]{1,0} broadcast(f32[2048]{0} %multiply.2293), dimensions={0}
  %multiply.2294 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %param_1.2285, f32[2048,4096]{1,0} %broadcast.2642), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  %param_0.1472 = f32[4096]{0} parameter(0)
  %broadcast.2639 = f32[2048,4096]{1,0} broadcast(f32[4096]{0} %param_0.1472), dimensions={1}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  %multiply.2295 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %multiply.2294, f32[2048,4096]{1,0} %broadcast.2639), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  ROOT %multiply.2296 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %multiply.2295, f32[2048,4096]{1,0} %multiply.2295), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
}

%parallel_fusion.538 (p.332: f32[4096], p.333: f32[2048,4096], p.334: f32[2048]) -> f32[2048,4096] {
  %p.332 = f32[4096]{0} parameter(0)
  %p.333 = f32[2048,4096]{1,0} parameter(1)
  %p.334 = f32[2048]{0} parameter(2)
  ROOT %fusion.538.clone = f32[2048,4096]{1,0} fusion(f32[4096]{0} %p.332, f32[2048,4096]{1,0} %p.333, f32[2048]{0} %p.334), kind=kLoop, calls=%fused_computation.538.clone, outer_dimension_partitions={9}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
}

%fused_computation.543.clone (param_0.1473: f32[2048,4096]) -> f32[2048,4096] {
  %param_0.1473 = f32[2048,4096]{1,0} parameter(0)
  %constant.21436 = f32[] constant(0.0625)
  %broadcast.2643 = f32[2048,4096]{1,0} broadcast(f32[] %constant.21436), dimensions={}
  %multiply.2297 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %param_0.1473, f32[2048,4096]{1,0} %broadcast.2643), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=200}
  ROOT %multiply.2298 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %multiply.2297, f32[2048,4096]{1,0} %multiply.2297), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=126}
}

%parallel_fusion.543 (p.335: f32[2048,4096]) -> f32[2048,4096] {
  %p.335 = f32[2048,4096]{1,0} parameter(0)
  ROOT %fusion.543.clone = f32[2048,4096]{1,0} fusion(f32[2048,4096]{1,0} %p.335), kind=kLoop, calls=%fused_computation.543.clone, outer_dimension_partitions={9}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=126}
}

%fused_computation.551.clone (param_0.1474: f32[], param_1.2286: f32[4096], param_2.1945: f32[2048,4096], param_3.1545: f32[2048], param_4.888: f32[], param_5.609: f32[], param_6.528: f32[], param_7.462: f32[2048,4096], param_8.354: f32[], param_9.296: f32[], param_10.235: s32[]) -> f32[2048,4096] {
  %constant.21437 = f32[] constant(1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/metrics.py" source_line=617}
  %param_10.235 = s32[] parameter(10)
  %constant.21440 = s32[] constant(1), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=113}
  %compare.2832 = pred[] compare(s32[] %param_10.235, s32[] %constant.21440), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=113}
  %param_8.354 = f32[] parameter(8)
  %param_9.296 = f32[] parameter(9)
  %select.2720 = f32[] select(pred[] %compare.2832, f32[] %param_8.354, f32[] %param_9.296), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/jit(_where)/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=112}
  %subtract.748 = f32[] subtract(f32[] %constant.21437, f32[] %select.2720), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  %broadcast.2649 = f32[2048,4096]{1,0} broadcast(f32[] %subtract.748), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  %param_7.462 = f32[2048,4096]{1,0} parameter(7)
  %multiply.2304 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %broadcast.2649, f32[2048,4096]{1,0} %param_7.462), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  %param_4.888 = f32[] parameter(4)
  %param_5.609 = f32[] parameter(5)
  %param_6.528 = f32[] parameter(6)
  %maximum.96 = f32[] maximum(f32[] %param_5.609, f32[] %param_6.528), metadata={op_type="max" op_name="pmap(_multi_device_update_fn)/max" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=122}
  %multiply.2302 = f32[] multiply(f32[] %param_4.888, f32[] %maximum.96), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=122}
  %broadcast.2648 = f32[2048,4096]{1,0} broadcast(f32[] %multiply.2302), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=152}
  %param_2.1945 = f32[2048,4096]{1,0} parameter(2)
  %param_3.1545 = f32[2048]{0} parameter(3)
  %constant.21438 = f32[] constant(0.0625)
  %broadcast.2646 = f32[2048]{0} broadcast(f32[] %constant.21438), dimensions={}
  %multiply.2299 = f32[2048]{0} multiply(f32[2048]{0} %param_3.1545, f32[2048]{0} %broadcast.2646)
  %broadcast.2647 = f32[2048,4096]{1,0} broadcast(f32[2048]{0} %multiply.2299), dimensions={0}
  %multiply.2300 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %param_2.1945, f32[2048,4096]{1,0} %broadcast.2647), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  %param_1.2286 = f32[4096]{0} parameter(1)
  %broadcast.2645 = f32[2048,4096]{1,0} broadcast(f32[4096]{0} %param_1.2286), dimensions={1}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  %multiply.2301 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %multiply.2300, f32[2048,4096]{1,0} %broadcast.2645), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  %param_0.1474 = f32[] parameter(0)
  %maximum.95 = f32[] maximum(f32[] %constant.21437, f32[] %param_0.1474), metadata={op_type="max" op_name="pmap(_multi_device_update_fn)/max" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %broadcast.2644 = f32[2048,4096]{1,0} broadcast(f32[] %maximum.95), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=150}
  %divide.289 = f32[2048,4096]{1,0} divide(f32[2048,4096]{1,0} %multiply.2301, f32[2048,4096]{1,0} %broadcast.2644), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=150}
  %multiply.2303 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %broadcast.2648, f32[2048,4096]{1,0} %divide.289), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=152}
  ROOT %subtract.749 = f32[2048,4096]{1,0} subtract(f32[2048,4096]{1,0} %multiply.2304, f32[2048,4096]{1,0} %multiply.2303), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
}

%parallel_fusion.551 (p.336: f32[], p.337: f32[4096], p.338: f32[2048,4096], p.339: f32[2048], p.340: f32[], p.341: f32[], p.342: f32[], p.343: f32[2048,4096], p.344: f32[], p.345: f32[], p.346: s32[]) -> f32[2048,4096] {
  %p.336 = f32[] parameter(0)
  %p.337 = f32[4096]{0} parameter(1)
  %p.338 = f32[2048,4096]{1,0} parameter(2)
  %p.339 = f32[2048]{0} parameter(3)
  %p.340 = f32[] parameter(4)
  %p.341 = f32[] parameter(5)
  %p.342 = f32[] parameter(6)
  %p.343 = f32[2048,4096]{1,0} parameter(7)
  %p.344 = f32[] parameter(8)
  %p.345 = f32[] parameter(9)
  %p.346 = s32[] parameter(10)
  ROOT %fusion.551.clone = f32[2048,4096]{1,0} fusion(f32[] %p.336, f32[4096]{0} %p.337, f32[2048,4096]{1,0} %p.338, f32[2048]{0} %p.339, f32[] %p.340, /*index=5*/f32[] %p.341, f32[] %p.342, f32[2048,4096]{1,0} %p.343, f32[] %p.344, f32[] %p.345, /*index=10*/s32[] %p.346), kind=kLoop, calls=%fused_computation.551.clone, outer_dimension_partitions={9}, metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
}

%fused_computation.553.clone (param_0.1475: f32[4096], param_1.2287: f32[2048,4096], param_2.1946: f32[2048]) -> f32[2048,4096] {
  %param_1.2287 = f32[2048,4096]{1,0} parameter(1)
  %param_2.1946 = f32[2048]{0} parameter(2)
  %constant.21441 = f32[] constant(0.0625)
  %broadcast.2651 = f32[2048]{0} broadcast(f32[] %constant.21441), dimensions={}
  %multiply.2305 = f32[2048]{0} multiply(f32[2048]{0} %param_2.1946, f32[2048]{0} %broadcast.2651)
  %broadcast.2652 = f32[2048,4096]{1,0} broadcast(f32[2048]{0} %multiply.2305), dimensions={0}
  %multiply.2306 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %param_1.2287, f32[2048,4096]{1,0} %broadcast.2652), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  %param_0.1475 = f32[4096]{0} parameter(0)
  %broadcast.2650 = f32[2048,4096]{1,0} broadcast(f32[4096]{0} %param_0.1475), dimensions={1}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  %multiply.2307 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %multiply.2306, f32[2048,4096]{1,0} %broadcast.2650), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  ROOT %multiply.2308 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %multiply.2307, f32[2048,4096]{1,0} %multiply.2307), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
}

%parallel_fusion.553 (p.347: f32[4096], p.348: f32[2048,4096], p.349: f32[2048]) -> f32[2048,4096] {
  %p.347 = f32[4096]{0} parameter(0)
  %p.348 = f32[2048,4096]{1,0} parameter(1)
  %p.349 = f32[2048]{0} parameter(2)
  ROOT %fusion.553.clone = f32[2048,4096]{1,0} fusion(f32[4096]{0} %p.347, f32[2048,4096]{1,0} %p.348, f32[2048]{0} %p.349), kind=kLoop, calls=%fused_computation.553.clone, outer_dimension_partitions={9}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
}

%fused_computation.558.clone (param_0.1476: f32[2048,4096]) -> f32[2048,4096] {
  %param_0.1476 = f32[2048,4096]{1,0} parameter(0)
  %constant.21442 = f32[] constant(0.0625)
  %broadcast.2653 = f32[2048,4096]{1,0} broadcast(f32[] %constant.21442), dimensions={}
  %multiply.2309 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %param_0.1476, f32[2048,4096]{1,0} %broadcast.2653), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=200}
  ROOT %multiply.2310 = f32[2048,4096]{1,0} multiply(f32[2048,4096]{1,0} %multiply.2309, f32[2048,4096]{1,0} %multiply.2309), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=126}
}

%parallel_fusion.558 (p.350: f32[2048,4096]) -> f32[2048,4096] {
  %p.350 = f32[2048,4096]{1,0} parameter(0)
  ROOT %fusion.558.clone = f32[2048,4096]{1,0} fusion(f32[2048,4096]{1,0} %p.350), kind=kLoop, calls=%fused_computation.558.clone, outer_dimension_partitions={9}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=126}
}

%fused_computation.560.clone (param_0.1477: f32[], param_1.2288: f32[1024], param_2.1947: f32[32000,1024], param_3.1546: f32[32000], param_4.889: f32[], param_5.610: f32[], param_6.529: f32[], param_7.463: f32[32000,1024], param_8.355: f32[], param_9.297: f32[], param_10.236: s32[]) -> f32[32000,1024] {
  %constant.21443 = f32[] constant(1), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/metrics.py" source_line=617}
  %param_10.236 = s32[] parameter(10)
  %constant.21446 = s32[] constant(1), metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=113}
  %compare.2833 = pred[] compare(s32[] %param_10.236, s32[] %constant.21446), direction=LT, metadata={op_type="lt" op_name="pmap(_multi_device_update_fn)/lt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=113}
  %param_8.355 = f32[] parameter(8)
  %param_9.297 = f32[] parameter(9)
  %select.2721 = f32[] select(pred[] %compare.2833, f32[] %param_8.355, f32[] %param_9.297), metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/jit(_where)/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=112}
  %subtract.750 = f32[] subtract(f32[] %constant.21443, f32[] %select.2721), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  %broadcast.2659 = f32[32000,1024]{1,0} broadcast(f32[] %subtract.750), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  %param_7.463 = f32[32000,1024]{1,0} parameter(7)
  %multiply.2316 = f32[32000,1024]{1,0} multiply(f32[32000,1024]{1,0} %broadcast.2659, f32[32000,1024]{1,0} %param_7.463), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  %param_4.889 = f32[] parameter(4)
  %param_5.610 = f32[] parameter(5)
  %param_6.529 = f32[] parameter(6)
  %maximum.98 = f32[] maximum(f32[] %param_5.610, f32[] %param_6.529), metadata={op_type="max" op_name="pmap(_multi_device_update_fn)/max" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=122}
  %multiply.2314 = f32[] multiply(f32[] %param_4.889, f32[] %maximum.98), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=122}
  %broadcast.2658 = f32[32000,1024]{1,0} broadcast(f32[] %multiply.2314), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=152}
  %param_2.1947 = f32[32000,1024]{1,0} parameter(2)
  %param_3.1546 = f32[32000]{0} parameter(3)
  %constant.21445 = f32[] constant(0.0625)
  %broadcast.2656 = f32[32000]{0} broadcast(f32[] %constant.21445), dimensions={}
  %multiply.2311 = f32[32000]{0} multiply(f32[32000]{0} %param_3.1546, f32[32000]{0} %broadcast.2656)
  %broadcast.2657 = f32[32000,1024]{1,0} broadcast(f32[32000]{0} %multiply.2311), dimensions={0}
  %multiply.2312 = f32[32000,1024]{1,0} multiply(f32[32000,1024]{1,0} %param_2.1947, f32[32000,1024]{1,0} %broadcast.2657), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  %param_1.2288 = f32[1024]{0} parameter(1)
  %broadcast.2655 = f32[32000,1024]{1,0} broadcast(f32[1024]{0} %param_1.2288), dimensions={1}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  %multiply.2313 = f32[32000,1024]{1,0} multiply(f32[32000,1024]{1,0} %multiply.2312, f32[32000,1024]{1,0} %broadcast.2655), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  %param_0.1477 = f32[] parameter(0)
  %maximum.97 = f32[] maximum(f32[] %constant.21443, f32[] %param_0.1477), metadata={op_type="max" op_name="pmap(_multi_device_update_fn)/max" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %broadcast.2654 = f32[32000,1024]{1,0} broadcast(f32[] %maximum.97), dimensions={}, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=150}
  %divide.290 = f32[32000,1024]{1,0} divide(f32[32000,1024]{1,0} %multiply.2313, f32[32000,1024]{1,0} %broadcast.2654), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=150}
  %multiply.2315 = f32[32000,1024]{1,0} multiply(f32[32000,1024]{1,0} %broadcast.2658, f32[32000,1024]{1,0} %divide.290), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=152}
  ROOT %subtract.751 = f32[32000,1024]{1,0} subtract(f32[32000,1024]{1,0} %multiply.2316, f32[32000,1024]{1,0} %multiply.2315), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
}

%parallel_fusion.560 (p.351: f32[], p.352: f32[1024], p.353: f32[32000,1024], p.354: f32[32000], p.355: f32[], p.356: f32[], p.357: f32[], p.358: f32[32000,1024], p.359: f32[], p.360: f32[], p.361: s32[]) -> f32[32000,1024] {
  %p.351 = f32[] parameter(0)
  %p.352 = f32[1024]{0} parameter(1)
  %p.353 = f32[32000,1024]{1,0} parameter(2)
  %p.354 = f32[32000]{0} parameter(3)
  %p.355 = f32[] parameter(4)
  %p.356 = f32[] parameter(5)
  %p.357 = f32[] parameter(6)
  %p.358 = f32[32000,1024]{1,0} parameter(7)
  %p.359 = f32[] parameter(8)
  %p.360 = f32[] parameter(9)
  %p.361 = s32[] parameter(10)
  ROOT %fusion.560.clone = f32[32000,1024]{1,0} fusion(f32[] %p.351, f32[1024]{0} %p.352, f32[32000,1024]{1,0} %p.353, f32[32000]{0} %p.354, f32[] %p.355, /*index=5*/f32[] %p.356, f32[] %p.357, f32[32000,1024]{1,0} %p.358, f32[] %p.359, f32[] %p.360, /*index=10*/s32[] %p.361), kind=kLoop, calls=%fused_computation.560.clone, outer_dimension_partitions={9}, metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
}

%fused_computation.562.clone (param_0.1478: f32[1024], param_1.2289: f32[32000,1024], param_2.1948: f32[32000]) -> f32[32000,1024] {
  %param_1.2289 = f32[32000,1024]{1,0} parameter(1)
  %param_2.1948 = f32[32000]{0} parameter(2)
  %constant.21447 = f32[] constant(0.0625)
  %broadcast.2661 = f32[32000]{0} broadcast(f32[] %constant.21447), dimensions={}
  %multiply.2317 = f32[32000]{0} multiply(f32[32000]{0} %param_2.1948, f32[32000]{0} %broadcast.2661)
  %broadcast.2662 = f32[32000,1024]{1,0} broadcast(f32[32000]{0} %multiply.2317), dimensions={0}
  %multiply.2318 = f32[32000,1024]{1,0} multiply(f32[32000,1024]{1,0} %param_1.2289, f32[32000,1024]{1,0} %broadcast.2662), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  %param_0.1478 = f32[1024]{0} parameter(0)
  %broadcast.2660 = f32[32000,1024]{1,0} broadcast(f32[1024]{0} %param_0.1478), dimensions={1}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  %multiply.2319 = f32[32000,1024]{1,0} multiply(f32[32000,1024]{1,0} %multiply.2318, f32[32000,1024]{1,0} %broadcast.2660), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=139}
  ROOT %multiply.2320 = f32[32000,1024]{1,0} multiply(f32[32000,1024]{1,0} %multiply.2319, f32[32000,1024]{1,0} %multiply.2319), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
}

%parallel_fusion.562 (p.362: f32[1024], p.363: f32[32000,1024], p.364: f32[32000]) -> f32[32000,1024] {
  %p.362 = f32[1024]{0} parameter(0)
  %p.363 = f32[32000,1024]{1,0} parameter(1)
  %p.364 = f32[32000]{0} parameter(2)
  ROOT %fusion.562.clone = f32[32000,1024]{1,0} fusion(f32[1024]{0} %p.362, f32[32000,1024]{1,0} %p.363, f32[32000]{0} %p.364), kind=kLoop, calls=%fused_computation.562.clone, outer_dimension_partitions={9}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
}

%fused_computation.567.clone (param_0.1479: f32[32000,1024]) -> f32[32000,1024] {
  %param_0.1479 = f32[32000,1024]{1,0} parameter(0)
  %constant.21448 = f32[] constant(0.0625)
  %broadcast.2664 = f32[32000,1024]{1,0} broadcast(f32[] %constant.21448), dimensions={}
  %multiply.2321 = f32[32000,1024]{1,0} multiply(f32[32000,1024]{1,0} %param_0.1479, f32[32000,1024]{1,0} %broadcast.2664), metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=200}
  ROOT %multiply.2322 = f32[32000,1024]{1,0} multiply(f32[32000,1024]{1,0} %multiply.2321, f32[32000,1024]{1,0} %multiply.2321), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=126}
}

%parallel_fusion.567 (p.365: f32[32000,1024]) -> f32[32000,1024] {
  %p.365 = f32[32000,1024]{1,0} parameter(0)
  ROOT %fusion.567.clone = f32[32000,1024]{1,0} fusion(f32[32000,1024]{1,0} %p.365), kind=kLoop, calls=%fused_computation.567.clone, outer_dimension_partitions={9}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=126}
}

%fused_computation.569.clone (param_0.1480: f32[64,8,1024]) -> f32[512,1024] {
  %param_0.1480 = f32[64,8,1024]{2,1,0} parameter(0)
  %transpose.125 = f32[8,64,1024]{2,1,0} transpose(f32[64,8,1024]{2,1,0} %param_0.1480), dimensions={1,0,2}, metadata={op_type="transpose" op_name="pmap(_multi_device_update_fn)/transpose[ permutation=(1, 0, 2) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/combinators.py" source_line=342}
  ROOT %reshape.3460 = f32[512,1024]{1,0} reshape(f32[8,64,1024]{2,1,0} %transpose.125)
}

%parallel_fusion.569 (p.366: f32[64,8,1024]) -> f32[512,1024] {
  %p.366 = f32[64,8,1024]{2,1,0} parameter(0)
  ROOT %fusion.569.clone = f32[512,1024]{1,0} fusion(f32[64,8,1024]{2,1,0} %p.366), kind=kLoop, calls=%fused_computation.569.clone, outer_dimension_partitions={8}
}

%fused_computation.570.clone (param_0.1481: f32[512,1024], param_1.2290: f32[512,1024]) -> f32[64,8,1024] {
  %param_0.1481 = f32[512,1024]{1,0} parameter(0)
  %param_1.2290 = f32[512,1024]{1,0} parameter(1)
  %add.4398 = f32[512,1024]{1,0} add(f32[512,1024]{1,0} %param_0.1481, f32[512,1024]{1,0} %param_1.2290), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=238}
  %reshape.3461 = f32[8,64,1024]{2,1,0} reshape(f32[512,1024]{1,0} %add.4398), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=238}
  ROOT %transpose.126 = f32[64,8,1024]{2,0,1} transpose(f32[8,64,1024]{2,1,0} %reshape.3461), dimensions={1,0,2}, metadata={op_type="transpose" op_name="pmap(_multi_device_update_fn)/transpose[ permutation=(1, 0, 2) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/combinators.py" source_line=342}
}

%parallel_fusion.570 (p.367: f32[512,1024], p.368: f32[512,1024]) -> f32[64,8,1024] {
  %p.367 = f32[512,1024]{1,0} parameter(0)
  %p.368 = f32[512,1024]{1,0} parameter(1)
  ROOT %fusion.570.clone = f32[64,8,1024]{2,0,1} fusion(f32[512,1024]{1,0} %p.367, f32[512,1024]{1,0} %p.368), kind=kLoop, calls=%fused_computation.570.clone, outer_dimension_partitions={8}, metadata={op_type="transpose" op_name="pmap(_multi_device_update_fn)/transpose[ permutation=(1, 0, 2) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/combinators.py" source_line=342}
}

%fused_computation.574.clone (param_0.1482: f32[1024], param_1.2291: f32[512,1024]) -> f32[8,1024,64] {
  %param_1.2291 = f32[512,1024]{1,0} parameter(1)
  %reshape.3462 = f32[8,64,1024]{2,1,0} reshape(f32[512,1024]{1,0} %param_1.2291), metadata={op_type="dot_general" op_name="pmap(_multi_device_update_fn)/dot_general[ dimension_numbers=(((2,), (0,)), ((), ()))\n                                           precision=None\n                                           preferred_element_type=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/core.py" source_line=96}
  %param_0.1482 = f32[1024]{0} parameter(0)
  %broadcast.2665 = f32[8,64,1024]{2,1,0} broadcast(f32[1024]{0} %param_0.1482), dimensions={2}, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/core.py" source_line=96}
  %add.4399 = f32[8,64,1024]{2,1,0} add(f32[8,64,1024]{2,1,0} %reshape.3462, f32[8,64,1024]{2,1,0} %broadcast.2665), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/core.py" source_line=96}
  %reshape.3463 = f32[8,1,64,1024]{3,2,0,1} reshape(f32[8,64,1024]{2,1,0} %add.4399), metadata={op_type="transpose" op_name="pmap(_multi_device_update_fn)/transpose[ permutation=(0, 2, 1, 3) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/attention.py" source_line=360}
  %copy.76 = f32[8,1,64,1024]{3,2,1,0} copy(f32[8,1,64,1024]{3,2,0,1} %reshape.3463), metadata={op_type="transpose" op_name="pmap(_multi_device_update_fn)/transpose[ permutation=(0, 2, 1, 3) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/attention.py" source_line=360}
  %transpose.127 = f32[8,1,1024,64]{3,2,1,0} transpose(f32[8,1,64,1024]{3,2,1,0} %copy.76), dimensions={0,1,3,2}
  ROOT %reshape.3464 = f32[8,1024,64]{2,1,0} reshape(f32[8,1,1024,64]{3,2,1,0} %transpose.127)
}

%parallel_fusion.574 (p.369: f32[1024], p.370: f32[512,1024]) -> f32[8,1024,64] {
  %p.369 = f32[1024]{0} parameter(0)
  %p.370 = f32[512,1024]{1,0} parameter(1)
  ROOT %fusion.574.clone = f32[8,1024,64]{2,1,0} fusion(f32[1024]{0} %p.369, f32[512,1024]{1,0} %p.370), kind=kLoop, calls=%fused_computation.574.clone, outer_dimension_partitions={8}
}

%fused_computation.575.clone (param_0.1483: f32[8,1024,64]) -> f32[512,1024] {
  %param_0.1483 = f32[8,1024,64]{2,1,0} parameter(0)
  %reshape.3465 = f32[8,1,1024,64]{3,2,1,0} reshape(f32[8,1024,64]{2,1,0} %param_0.1483), metadata={op_type="dot_general" op_name="pmap(_multi_device_update_fn)/dot_general[ dimension_numbers=(((1,), (1,)), ((0,), (0,)))\n                                           precision=None\n                                           preferred_element_type=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/attention.py" source_line=293}
  %transpose.128 = f32[8,64,1,1024]{3,2,1,0} transpose(f32[8,1,1024,64]{3,2,1,0} %reshape.3465), dimensions={0,3,1,2}, metadata={op_type="transpose" op_name="pmap(_multi_device_update_fn)/transpose[ permutation=(0, 2, 1, 3) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/attention.py" source_line=360}
  ROOT %reshape.3466 = f32[512,1024]{1,0} reshape(f32[8,64,1,1024]{3,2,1,0} %transpose.128)
}

%parallel_fusion.575 (p.371: f32[8,1024,64]) -> f32[512,1024] {
  %p.371 = f32[8,1024,64]{2,1,0} parameter(0)
  ROOT %fusion.575.clone = f32[512,1024]{1,0} fusion(f32[8,1024,64]{2,1,0} %p.371), kind=kLoop, calls=%fused_computation.575.clone, outer_dimension_partitions={8}
}

%fused_computation.576.clone (param_0.1484: f32[512,1024]) -> f32[8,1024,64] {
  %param_0.1484 = f32[512,1024]{1,0} parameter(0)
  %reshape.3467 = f32[8,64,1,1024]{3,1,0,2} reshape(f32[512,1024]{1,0} %param_0.1484), metadata={op_type="transpose" op_name="pmap(_multi_device_update_fn)/transpose[ permutation=(0, 2, 1, 3) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/attention.py" source_line=293}
  %copy.77 = f32[8,64,1,1024]{3,2,1,0} copy(f32[8,64,1,1024]{3,1,0,2} %reshape.3467), metadata={op_type="transpose" op_name="pmap(_multi_device_update_fn)/transpose[ permutation=(0, 2, 1, 3) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/attention.py" source_line=293}
  %transpose.129 = f32[8,1,1024,64]{3,2,1,0} transpose(f32[8,64,1,1024]{3,2,1,0} %copy.77), dimensions={0,2,3,1}
  ROOT %reshape.3468 = f32[8,1024,64]{2,1,0} reshape(f32[8,1,1024,64]{3,2,1,0} %transpose.129)
}

%parallel_fusion.576 (p.372: f32[512,1024]) -> f32[8,1024,64] {
  %p.372 = f32[512,1024]{1,0} parameter(0)
  ROOT %fusion.576.clone = f32[8,1024,64]{2,1,0} fusion(f32[512,1024]{1,0} %p.372), kind=kLoop, calls=%fused_computation.576.clone, outer_dimension_partitions={8}
}

%fused_computation.577.clone (param_0.1485: f32[64,8,1024]) -> f32[512,1024] {
  %param_0.1485 = f32[64,8,1024]{2,1,0} parameter(0)
  %transpose.130 = f32[8,64,1024]{2,1,0} transpose(f32[64,8,1024]{2,1,0} %param_0.1485), dimensions={1,0,2}, metadata={op_type="transpose" op_name="pmap(_multi_device_update_fn)/transpose[ permutation=(1, 0, 2) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/combinators.py" source_line=342}
  ROOT %reshape.3469 = f32[512,1024]{1,0} reshape(f32[8,64,1024]{2,1,0} %transpose.130)
}

%parallel_fusion.577 (p.373: f32[64,8,1024]) -> f32[512,1024] {
  %p.373 = f32[64,8,1024]{2,1,0} parameter(0)
  ROOT %fusion.577.clone = f32[512,1024]{1,0} fusion(f32[64,8,1024]{2,1,0} %p.373), kind=kLoop, calls=%fused_computation.577.clone, outer_dimension_partitions={8}
}

%fused_computation.578.clone (param_0.1486: f32[512,1024]) -> f32[64,8,1024] {
  %param_0.1486 = f32[512,1024]{1,0} parameter(0)
  %reshape.3470 = f32[8,64,1024]{2,1,0} reshape(f32[512,1024]{1,0} %param_0.1486), metadata={op_type="dot_general" op_name="pmap(_multi_device_update_fn)/dot_general[ dimension_numbers=(((2,), (1,)), ((), ()))\n                                           precision=None\n                                           preferred_element_type=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/core.py" source_line=96}
  ROOT %transpose.131 = f32[64,8,1024]{2,0,1} transpose(f32[8,64,1024]{2,1,0} %reshape.3470), dimensions={1,0,2}, metadata={op_type="transpose" op_name="pmap(_multi_device_update_fn)/transpose[ permutation=(1, 0, 2) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/combinators.py" source_line=342}
}

%parallel_fusion.578 (p.374: f32[512,1024]) -> f32[64,8,1024] {
  %p.374 = f32[512,1024]{1,0} parameter(0)
  ROOT %fusion.578.clone = f32[64,8,1024]{2,0,1} fusion(f32[512,1024]{1,0} %p.374), kind=kLoop, calls=%fused_computation.578.clone, outer_dimension_partitions={8}, metadata={op_type="transpose" op_name="pmap(_multi_device_update_fn)/transpose[ permutation=(1, 0, 2) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/combinators.py" source_line=342}
}

%fused_computation.579.clone (param_0.1487: f32[8,64,256], param_1.2292: f32[8,64,256], param_2.1949: f32[8,64]) -> f32[8,64,256] {
  %param_0.1487 = f32[8,64,256]{2,1,0} parameter(0)
  %param_2.1949 = f32[8,64]{1,0} parameter(2)
  %broadcast.2666 = f32[8,64,256]{2,1,0} broadcast(f32[8,64]{1,0} %param_2.1949), dimensions={0,1}, metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/broadcast_in_dim[ broadcast_dimensions=(0, 1)\n                                                shape=(8, 64, 256) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=94}
  %param_1.2292 = f32[8,64,256]{2,1,0} parameter(1)
  %multiply.2323 = f32[8,64,256]{2,1,0} multiply(f32[8,64,256]{2,1,0} %broadcast.2666, f32[8,64,256]{2,1,0} %param_1.2292), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=94}
  ROOT %add.4400 = f32[8,64,256]{2,1,0} add(f32[8,64,256]{2,1,0} %param_0.1487, f32[8,64,256]{2,1,0} %multiply.2323), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=238}
}

%parallel_fusion.579 (p.375: f32[8,64,256], p.376: f32[8,64,256], p.377: f32[8,64]) -> f32[8,64,256] {
  %p.375 = f32[8,64,256]{2,1,0} parameter(0)
  %p.376 = f32[8,64,256]{2,1,0} parameter(1)
  %p.377 = f32[8,64]{1,0} parameter(2)
  ROOT %fusion.579.clone = f32[8,64,256]{2,1,0} fusion(f32[8,64,256]{2,1,0} %p.375, f32[8,64,256]{2,1,0} %p.376, f32[8,64]{1,0} %p.377), kind=kLoop, calls=%fused_computation.579.clone, outer_dimension_partitions={2}, metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=238}
}

%fused_computation.581.clone (param_0.1488: f32[8,64,256], param_1.2293: f32[8,64], param_2.1950: f32[8,64], param_3.1547: f32[], param_4.890: s32[8,64]) -> f32[8,64,256] {
  %param_4.890 = s32[8,64]{1,0} parameter(4)
  %broadcast.2672 = s32[8,64,256]{2,1,0} broadcast(s32[8,64]{1,0} %param_4.890), dimensions={0,1}, metadata={op_type="eq" op_name="pmap(_multi_device_update_fn)/eq" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/core.py" source_line=776}
  %iota.68 = s32[8,64,256]{2,1,0} iota(), iota_dimension=2, metadata={op_type="eq" op_name="pmap(_multi_device_update_fn)/eq" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/core.py" source_line=776}
  %compare.2834 = pred[8,64,256]{2,1,0} compare(s32[8,64,256]{2,1,0} %broadcast.2672, s32[8,64,256]{2,1,0} %iota.68), direction=EQ, metadata={op_type="eq" op_name="pmap(_multi_device_update_fn)/eq" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/core.py" source_line=776}
  %param_3.1547 = f32[] parameter(3)
  %broadcast.2670 = f32[8,64]{1,0} broadcast(f32[] %param_3.1547), dimensions={}, metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/broadcast_in_dim[ broadcast_dimensions=(  )\n                                                shape=(8, 64) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/metrics.py" source_line=617}
  %param_2.1950 = f32[8,64]{1,0} parameter(2)
  %multiply.2325 = f32[8,64]{1,0} multiply(f32[8,64]{1,0} %broadcast.2670, f32[8,64]{1,0} %param_2.1950), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/metrics.py" source_line=617}
  %constant.21451 = f32[] constant(-1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/metrics.py" source_line=581}
  %broadcast.2669 = f32[8,64]{1,0} broadcast(f32[] %constant.21451), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/metrics.py" source_line=581}
  %multiply.2326 = f32[8,64]{1,0} multiply(f32[8,64]{1,0} %multiply.2325, f32[8,64]{1,0} %broadcast.2669), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/metrics.py" source_line=581}
  %broadcast.2671 = f32[8,64,256]{2,1,0} broadcast(f32[8,64]{1,0} %multiply.2326), dimensions={0,1}, metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/broadcast_in_dim[ broadcast_dimensions=(0, 1)\n                                                shape=(8, 64, 256) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/metrics.py" source_line=581}
  %constant.21450 = f32[] constant(0)
  %broadcast.2668 = f32[8,64,256]{2,1,0} broadcast(f32[] %constant.21450), dimensions={}
  %select.2723 = f32[8,64,256]{2,1,0} select(pred[8,64,256]{2,1,0} %compare.2834, f32[8,64,256]{2,1,0} %broadcast.2671, f32[8,64,256]{2,1,0} %broadcast.2668), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/metrics.py" source_line=581}
  %param_1.2293 = f32[8,64]{1,0} parameter(1)
  %broadcast.2667 = f32[8,64,256]{2,1,0} broadcast(f32[8,64]{1,0} %param_1.2293), dimensions={0,1}, metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/broadcast_in_dim[ broadcast_dimensions=(0, 1)\n                                                shape=(8, 64, 256) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=94}
  %param_0.1488 = f32[8,64,256]{2,1,0} parameter(0)
  %multiply.2324 = f32[8,64,256]{2,1,0} multiply(f32[8,64,256]{2,1,0} %broadcast.2667, f32[8,64,256]{2,1,0} %param_0.1488), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=94}
  ROOT %add.4401 = f32[8,64,256]{2,1,0} add(f32[8,64,256]{2,1,0} %select.2723, f32[8,64,256]{2,1,0} %multiply.2324), metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=238}
}

%parallel_fusion.581 (p.378: f32[8,64,256], p.379: f32[8,64], p.380: f32[8,64], p.381: f32[], p.382: s32[8,64]) -> f32[8,64,256] {
  %p.378 = f32[8,64,256]{2,1,0} parameter(0)
  %p.379 = f32[8,64]{1,0} parameter(1)
  %p.380 = f32[8,64]{1,0} parameter(2)
  %p.381 = f32[] parameter(3)
  %p.382 = s32[8,64]{1,0} parameter(4)
  ROOT %fusion.581.clone = f32[8,64,256]{2,1,0} fusion(f32[8,64,256]{2,1,0} %p.378, f32[8,64]{1,0} %p.379, f32[8,64]{1,0} %p.380, f32[] %p.381, s32[8,64]{1,0} %p.382), kind=kLoop, calls=%fused_computation.581.clone, outer_dimension_partitions={2}, metadata={op_type="add_any" op_name="pmap(_multi_device_update_fn)/add_any" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=238}
}

%fused_computation.583.clone (param_0.1489: f32[8,64,1], param_1.2294: f32[8,64,1], param_2.1951: f32[8,64], param_3.1548: f32[256], param_4.891: f32[512,256]) -> f32[8,64,256] {
  %param_4.891 = f32[512,256]{1,0} parameter(4)
  %reshape.3474 = f32[8,64,256]{2,1,0} reshape(f32[512,256]{1,0} %param_4.891), metadata={op_type="dot_general" op_name="pmap(_multi_device_update_fn)/dot_general[ dimension_numbers=(((2,), (0,)), ((), ()))\n                                           precision=None\n                                           preferred_element_type=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/core.py" source_line=96}
  %param_3.1548 = f32[256]{0} parameter(3)
  %broadcast.2675 = f32[8,64,256]{2,1,0} broadcast(f32[256]{0} %param_3.1548), dimensions={2}, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/core.py" source_line=96}
  %add.4403 = f32[8,64,256]{2,1,0} add(f32[8,64,256]{2,1,0} %reshape.3474, f32[8,64,256]{2,1,0} %broadcast.2675), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/core.py" source_line=96}
  %param_2.1951 = f32[8,64]{1,0} parameter(2)
  %reshape.3472 = f32[8,64,1]{1,0,2} reshape(f32[8,64]{1,0} %param_2.1951), metadata={op_type="log" op_name="pmap(_multi_device_update_fn)/log" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=94}
  %copy.78 = f32[8,64,1]{2,1,0} copy(f32[8,64,1]{1,0,2} %reshape.3472), metadata={op_type="log" op_name="pmap(_multi_device_update_fn)/log" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=94}
  %param_1.2294 = f32[8,64,1]{2,1,0} parameter(1)
  %add.4402 = f32[8,64,1]{2,1,0} add(f32[8,64,1]{2,1,0} %copy.78, f32[8,64,1]{2,1,0} %param_1.2294), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=94}
  %reshape.3473 = f32[8,64]{1,0} reshape(f32[8,64,1]{2,1,0} %add.4402), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/core.py" source_line=794}
  %broadcast.2674 = f32[8,64,256]{2,1,0} broadcast(f32[8,64]{1,0} %reshape.3473), dimensions={0,1}, metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/core.py" source_line=794}
  %subtract.752 = f32[8,64,256]{2,1,0} subtract(f32[8,64,256]{2,1,0} %add.4403, f32[8,64,256]{2,1,0} %broadcast.2674), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/core.py" source_line=794}
  %param_0.1489 = f32[8,64,1]{2,1,0} parameter(0)
  %reshape.3471 = f32[8,64]{1,0} reshape(f32[8,64,1]{2,1,0} %param_0.1489), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=94}
  %broadcast.2673 = f32[8,64,256]{2,1,0} broadcast(f32[8,64]{1,0} %reshape.3471), dimensions={0,1}, metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=94}
  %subtract.753 = f32[8,64,256]{2,1,0} subtract(f32[8,64,256]{2,1,0} %subtract.752, f32[8,64,256]{2,1,0} %broadcast.2673), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=94}
  ROOT %exponential.193 = f32[8,64,256]{2,1,0} exponential(f32[8,64,256]{2,1,0} %subtract.753), metadata={op_type="exp" op_name="pmap(_multi_device_update_fn)/exp" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=94}
}

%parallel_fusion.583 (p.383: f32[8,64,1], p.384: f32[8,64,1], p.385: f32[8,64], p.386: f32[256], p.387: f32[512,256]) -> f32[8,64,256] {
  %p.383 = f32[8,64,1]{2,1,0} parameter(0)
  %p.384 = f32[8,64,1]{2,1,0} parameter(1)
  %p.385 = f32[8,64]{1,0} parameter(2)
  %p.386 = f32[256]{0} parameter(3)
  %p.387 = f32[512,256]{1,0} parameter(4)
  ROOT %fusion.583.clone = f32[8,64,256]{2,1,0} fusion(f32[8,64,1]{2,1,0} %p.383, f32[8,64,1]{2,1,0} %p.384, f32[8,64]{1,0} %p.385, f32[256]{0} %p.386, f32[512,256]{1,0} %p.387), kind=kLoop, calls=%fused_computation.583.clone, outer_dimension_partitions={2}, metadata={op_type="exp" op_name="pmap(_multi_device_update_fn)/exp" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=94}
}

%fused_computation.585.clone (param_0.1490: f32[8,64,1], param_1.2295: f32[8,64], param_2.1952: f32[256], param_3.1549: f32[512,256]) -> f32[8,64,256] {
  %param_3.1549 = f32[512,256]{1,0} parameter(3)
  %reshape.3477 = f32[8,64,256]{2,1,0} reshape(f32[512,256]{1,0} %param_3.1549), metadata={op_type="dot_general" op_name="pmap(_multi_device_update_fn)/dot_general[ dimension_numbers=(((2,), (0,)), ((), ()))\n                                           precision=None\n                                           preferred_element_type=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/core.py" source_line=96}
  %param_2.1952 = f32[256]{0} parameter(2)
  %broadcast.2677 = f32[8,64,256]{2,1,0} broadcast(f32[256]{0} %param_2.1952), dimensions={2}, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/core.py" source_line=96}
  %add.4405 = f32[8,64,256]{2,1,0} add(f32[8,64,256]{2,1,0} %reshape.3477, f32[8,64,256]{2,1,0} %broadcast.2677), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/core.py" source_line=96}
  %param_1.2295 = f32[8,64]{1,0} parameter(1)
  %reshape.3475 = f32[8,64,1]{1,0,2} reshape(f32[8,64]{1,0} %param_1.2295), metadata={op_type="log" op_name="pmap(_multi_device_update_fn)/log" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=94}
  %copy.79 = f32[8,64,1]{2,1,0} copy(f32[8,64,1]{1,0,2} %reshape.3475), metadata={op_type="log" op_name="pmap(_multi_device_update_fn)/log" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=94}
  %param_0.1490 = f32[8,64,1]{2,1,0} parameter(0)
  %add.4404 = f32[8,64,1]{2,1,0} add(f32[8,64,1]{2,1,0} %copy.79, f32[8,64,1]{2,1,0} %param_0.1490), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=94}
  %reshape.3476 = f32[8,64]{1,0} reshape(f32[8,64,1]{2,1,0} %add.4404), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/core.py" source_line=794}
  %broadcast.2676 = f32[8,64,256]{2,1,0} broadcast(f32[8,64]{1,0} %reshape.3476), dimensions={0,1}, metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/core.py" source_line=794}
  ROOT %subtract.754 = f32[8,64,256]{2,1,0} subtract(f32[8,64,256]{2,1,0} %add.4405, f32[8,64,256]{2,1,0} %broadcast.2676), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/core.py" source_line=794}
}

%parallel_fusion.585 (p.388: f32[8,64,1], p.389: f32[8,64], p.390: f32[256], p.391: f32[512,256]) -> f32[8,64,256] {
  %p.388 = f32[8,64,1]{2,1,0} parameter(0)
  %p.389 = f32[8,64]{1,0} parameter(1)
  %p.390 = f32[256]{0} parameter(2)
  %p.391 = f32[512,256]{1,0} parameter(3)
  ROOT %fusion.585.clone = f32[8,64,256]{2,1,0} fusion(f32[8,64,1]{2,1,0} %p.388, f32[8,64]{1,0} %p.389, f32[256]{0} %p.390, f32[512,256]{1,0} %p.391), kind=kLoop, calls=%fused_computation.585.clone, outer_dimension_partitions={2}, metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/core.py" source_line=794}
}

%fused_computation.586.clone (param_0.1491: f32[8,64,1], param_1.2296: f32[256], param_2.1953: f32[512,256]) -> f32[8,64,256] {
  %param_2.1953 = f32[512,256]{1,0} parameter(2)
  %reshape.3479 = f32[8,64,256]{2,1,0} reshape(f32[512,256]{1,0} %param_2.1953), metadata={op_type="dot_general" op_name="pmap(_multi_device_update_fn)/dot_general[ dimension_numbers=(((2,), (0,)), ((), ()))\n                                           precision=None\n                                           preferred_element_type=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/core.py" source_line=96}
  %param_1.2296 = f32[256]{0} parameter(1)
  %broadcast.2679 = f32[8,64,256]{2,1,0} broadcast(f32[256]{0} %param_1.2296), dimensions={2}, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/core.py" source_line=96}
  %add.4406 = f32[8,64,256]{2,1,0} add(f32[8,64,256]{2,1,0} %reshape.3479, f32[8,64,256]{2,1,0} %broadcast.2679), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/core.py" source_line=96}
  %param_0.1491 = f32[8,64,1]{2,1,0} parameter(0)
  %reshape.3478 = f32[8,64]{1,0} reshape(f32[8,64,1]{2,1,0} %param_0.1491), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=94}
  %broadcast.2678 = f32[8,64,256]{2,1,0} broadcast(f32[8,64]{1,0} %reshape.3478), dimensions={0,1}, metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=94}
  %subtract.755 = f32[8,64,256]{2,1,0} subtract(f32[8,64,256]{2,1,0} %add.4406, f32[8,64,256]{2,1,0} %broadcast.2678), metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=94}
  ROOT %exponential.194 = f32[8,64,256]{2,1,0} exponential(f32[8,64,256]{2,1,0} %subtract.755), metadata={op_type="exp" op_name="pmap(_multi_device_update_fn)/exp" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=94}
}

%parallel_fusion.586 (p.392: f32[8,64,1], p.393: f32[256], p.394: f32[512,256]) -> f32[8,64,256] {
  %p.392 = f32[8,64,1]{2,1,0} parameter(0)
  %p.393 = f32[256]{0} parameter(1)
  %p.394 = f32[512,256]{1,0} parameter(2)
  ROOT %fusion.586.clone = f32[8,64,256]{2,1,0} fusion(f32[8,64,1]{2,1,0} %p.392, f32[256]{0} %p.393, f32[512,256]{1,0} %p.394), kind=kLoop, calls=%fused_computation.586.clone, outer_dimension_partitions={2}, metadata={op_type="exp" op_name="pmap(_multi_device_update_fn)/exp" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=94}
}

%fused_computation.588.clone (param_0.1492: f32[256], param_1.2297: f32[512,256]) -> f32[8,64,256] {
  %param_1.2297 = f32[512,256]{1,0} parameter(1)
  %reshape.3480 = f32[8,64,256]{2,1,0} reshape(f32[512,256]{1,0} %param_1.2297), metadata={op_type="dot_general" op_name="pmap(_multi_device_update_fn)/dot_general[ dimension_numbers=(((2,), (0,)), ((), ()))\n                                           precision=None\n                                           preferred_element_type=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/core.py" source_line=96}
  %param_0.1492 = f32[256]{0} parameter(0)
  %broadcast.2680 = f32[8,64,256]{2,1,0} broadcast(f32[256]{0} %param_0.1492), dimensions={2}, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/core.py" source_line=96}
  ROOT %add.4407 = f32[8,64,256]{2,1,0} add(f32[8,64,256]{2,1,0} %reshape.3480, f32[8,64,256]{2,1,0} %broadcast.2680), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/core.py" source_line=96}
}

%parallel_fusion.588 (p.395: f32[256], p.396: f32[512,256]) -> f32[8,64,256] {
  %p.395 = f32[256]{0} parameter(0)
  %p.396 = f32[512,256]{1,0} parameter(1)
  ROOT %fusion.588.clone = f32[8,64,256]{2,1,0} fusion(f32[256]{0} %p.395, f32[512,256]{1,0} %p.396), kind=kLoop, calls=%fused_computation.588.clone, outer_dimension_partitions={2}, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/core.py" source_line=96}
}

%fused_computation.589.clone (param_0.1493: f32[64,8,1024]) -> f32[512,1024] {
  %param_0.1493 = f32[64,8,1024]{2,1,0} parameter(0)
  %transpose.132 = f32[8,64,1024]{2,1,0} transpose(f32[64,8,1024]{2,1,0} %param_0.1493), dimensions={1,0,2}, metadata={op_type="transpose" op_name="pmap(_multi_device_update_fn)/transpose[ permutation=(1, 0, 2) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/combinators.py" source_line=342}
  ROOT %reshape.3481 = f32[512,1024]{1,0} reshape(f32[8,64,1024]{2,1,0} %transpose.132)
}

%parallel_fusion.589 (p.397: f32[64,8,1024]) -> f32[512,1024] {
  %p.397 = f32[64,8,1024]{2,1,0} parameter(0)
  ROOT %fusion.589.clone = f32[512,1024]{1,0} fusion(f32[64,8,1024]{2,1,0} %p.397), kind=kLoop, calls=%fused_computation.589.clone, outer_dimension_partitions={8}
}

%fused_computation.590.clone (param_0.1494: f32[1024], param_1.2298: f32[512,1024], param_2.1954: f32[64,8,1024]) -> f32[64,8,1024] {
  %param_2.1954 = f32[64,8,1024]{2,1,0} parameter(2)
  %transpose.133 = f32[8,64,1024]{2,1,0} transpose(f32[64,8,1024]{2,1,0} %param_2.1954), dimensions={1,0,2}, metadata={op_type="transpose" op_name="pmap(_multi_device_update_fn)/transpose[ permutation=(1, 0, 2) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/combinators.py" source_line=342}
  %param_1.2298 = f32[512,1024]{1,0} parameter(1)
  %reshape.3482 = f32[8,64,1024]{2,1,0} reshape(f32[512,1024]{1,0} %param_1.2298), metadata={op_type="dot_general" op_name="pmap(_multi_device_update_fn)/dot_general[ dimension_numbers=(((2,), (0,)), ((), ()))\n                                           precision=None\n                                           preferred_element_type=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/core.py" source_line=96}
  %param_0.1494 = f32[1024]{0} parameter(0)
  %broadcast.2681 = f32[8,64,1024]{2,1,0} broadcast(f32[1024]{0} %param_0.1494), dimensions={2}, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/core.py" source_line=96}
  %add.4408 = f32[8,64,1024]{2,1,0} add(f32[8,64,1024]{2,1,0} %reshape.3482, f32[8,64,1024]{2,1,0} %broadcast.2681), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/core.py" source_line=96}
  %add.4409 = f32[8,64,1024]{2,1,0} add(f32[8,64,1024]{2,1,0} %transpose.133, f32[8,64,1024]{2,1,0} %add.4408), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/combinators.py" source_line=843}
  ROOT %transpose.134 = f32[64,8,1024]{2,0,1} transpose(f32[8,64,1024]{2,1,0} %add.4409), dimensions={1,0,2}, metadata={op_type="transpose" op_name="pmap(_multi_device_update_fn)/transpose[ permutation=(1, 0, 2) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/combinators.py" source_line=342}
}

%parallel_fusion.590 (p.398: f32[1024], p.399: f32[512,1024], p.400: f32[64,8,1024]) -> f32[64,8,1024] {
  %p.398 = f32[1024]{0} parameter(0)
  %p.399 = f32[512,1024]{1,0} parameter(1)
  %p.400 = f32[64,8,1024]{2,1,0} parameter(2)
  ROOT %fusion.590.clone = f32[64,8,1024]{2,0,1} fusion(f32[1024]{0} %p.398, f32[512,1024]{1,0} %p.399, f32[64,8,1024]{2,1,0} %p.400), kind=kLoop, calls=%fused_computation.590.clone, outer_dimension_partitions={8}, metadata={op_type="transpose" op_name="pmap(_multi_device_update_fn)/transpose[ permutation=(1, 0, 2) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/combinators.py" source_line=342}
}

%fused_computation.591.clone (param_0.1495: f32[1024], param_1.2299: f32[512,1024]) -> f32[8,64,1024] {
  %param_1.2299 = f32[512,1024]{1,0} parameter(1)
  %reshape.3483 = f32[8,64,1024]{2,1,0} reshape(f32[512,1024]{1,0} %param_1.2299), metadata={op_type="dot_general" op_name="pmap(_multi_device_update_fn)/dot_general[ dimension_numbers=(((2,), (0,)), ((), ()))\n                                           precision=None\n                                           preferred_element_type=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/core.py" source_line=96}
  %param_0.1495 = f32[1024]{0} parameter(0)
  %broadcast.2682 = f32[8,64,1024]{2,1,0} broadcast(f32[1024]{0} %param_0.1495), dimensions={2}, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/core.py" source_line=96}
  ROOT %add.4410 = f32[8,64,1024]{2,1,0} add(f32[8,64,1024]{2,1,0} %reshape.3483, f32[8,64,1024]{2,1,0} %broadcast.2682), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/core.py" source_line=96}
}

%parallel_fusion.591 (p.401: f32[1024], p.402: f32[512,1024]) -> f32[8,64,1024] {
  %p.401 = f32[1024]{0} parameter(0)
  %p.402 = f32[512,1024]{1,0} parameter(1)
  ROOT %fusion.591.clone = f32[8,64,1024]{2,1,0} fusion(f32[1024]{0} %p.401, f32[512,1024]{1,0} %p.402), kind=kLoop, calls=%fused_computation.591.clone, outer_dimension_partitions={8}, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/core.py" source_line=96}
}

%fused_computation.597.clone (param_0.1496: f32[1024], param_1.2300: f32[512,1024]) -> f32[8,1024,64] {
  %param_1.2300 = f32[512,1024]{1,0} parameter(1)
  %reshape.3484 = f32[8,64,1024]{2,1,0} reshape(f32[512,1024]{1,0} %param_1.2300), metadata={op_type="dot_general" op_name="pmap(_multi_device_update_fn)/dot_general[ dimension_numbers=(((2,), (0,)), ((), ()))\n                                           precision=None\n                                           preferred_element_type=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/core.py" source_line=96}
  %param_0.1496 = f32[1024]{0} parameter(0)
  %broadcast.2683 = f32[8,64,1024]{2,1,0} broadcast(f32[1024]{0} %param_0.1496), dimensions={2}, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/core.py" source_line=96}
  %add.4411 = f32[8,64,1024]{2,1,0} add(f32[8,64,1024]{2,1,0} %reshape.3484, f32[8,64,1024]{2,1,0} %broadcast.2683), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/core.py" source_line=96}
  %reshape.3485 = f32[8,1,64,1024]{3,2,0,1} reshape(f32[8,64,1024]{2,1,0} %add.4411), metadata={op_type="transpose" op_name="pmap(_multi_device_update_fn)/transpose[ permutation=(0, 2, 1, 3) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/attention.py" source_line=360}
  %copy.80 = f32[8,1,64,1024]{3,2,1,0} copy(f32[8,1,64,1024]{3,2,0,1} %reshape.3485), metadata={op_type="transpose" op_name="pmap(_multi_device_update_fn)/transpose[ permutation=(0, 2, 1, 3) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/attention.py" source_line=360}
  %transpose.135 = f32[8,1024,1,64]{1,3,2,0} transpose(f32[8,1,64,1024]{3,2,1,0} %copy.80), dimensions={0,3,1,2}
  %copy.81 = f32[8,1024,1,64]{3,2,1,0} copy(f32[8,1024,1,64]{1,3,2,0} %transpose.135)
  ROOT %reshape.3486 = f32[8,1024,64]{2,1,0} reshape(f32[8,1024,1,64]{3,2,1,0} %copy.81)
}

%parallel_fusion.597 (p.403: f32[1024], p.404: f32[512,1024]) -> f32[8,1024,64] {
  %p.403 = f32[1024]{0} parameter(0)
  %p.404 = f32[512,1024]{1,0} parameter(1)
  ROOT %fusion.597.clone = f32[8,1024,64]{2,1,0} fusion(f32[1024]{0} %p.403, f32[512,1024]{1,0} %p.404), kind=kLoop, calls=%fused_computation.597.clone, outer_dimension_partitions={8}
}

%fused_computation.598.clone (param_0.1497: f32[1024], param_1.2301: f32[512,1024]) -> f32[8,64,1024] {
  %param_1.2301 = f32[512,1024]{1,0} parameter(1)
  %reshape.3487 = f32[8,64,1024]{2,1,0} reshape(f32[512,1024]{1,0} %param_1.2301), metadata={op_type="dot_general" op_name="pmap(_multi_device_update_fn)/dot_general[ dimension_numbers=(((2,), (0,)), ((), ()))\n                                           precision=None\n                                           preferred_element_type=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/core.py" source_line=96}
  %param_0.1497 = f32[1024]{0} parameter(0)
  %broadcast.2684 = f32[8,64,1024]{2,1,0} broadcast(f32[1024]{0} %param_0.1497), dimensions={2}, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/core.py" source_line=96}
  ROOT %add.4412 = f32[8,64,1024]{2,1,0} add(f32[8,64,1024]{2,1,0} %reshape.3487, f32[8,64,1024]{2,1,0} %broadcast.2684), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/core.py" source_line=96}
}

%parallel_fusion.598 (p.405: f32[1024], p.406: f32[512,1024]) -> f32[8,64,1024] {
  %p.405 = f32[1024]{0} parameter(0)
  %p.406 = f32[512,1024]{1,0} parameter(1)
  ROOT %fusion.598.clone = f32[8,64,1024]{2,1,0} fusion(f32[1024]{0} %p.405, f32[512,1024]{1,0} %p.406), kind=kLoop, calls=%fused_computation.598.clone, outer_dimension_partitions={8}, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/core.py" source_line=96}
}

%fused_computation.599.clone (param_0.1498: f32[64,8,1024]) -> f32[512,1024] {
  %param_0.1498 = f32[64,8,1024]{2,1,0} parameter(0)
  %transpose.136 = f32[8,64,1024]{2,1,0} transpose(f32[64,8,1024]{2,1,0} %param_0.1498), dimensions={1,0,2}, metadata={op_type="transpose" op_name="pmap(_multi_device_update_fn)/transpose[ permutation=(1, 0, 2) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/combinators.py" source_line=342}
  ROOT %reshape.3488 = f32[512,1024]{1,0} reshape(f32[8,64,1024]{2,1,0} %transpose.136)
}

%parallel_fusion.599 (p.407: f32[64,8,1024]) -> f32[512,1024] {
  %p.407 = f32[64,8,1024]{2,1,0} parameter(0)
  ROOT %fusion.599.clone = f32[512,1024]{1,0} fusion(f32[64,8,1024]{2,1,0} %p.407), kind=kLoop, calls=%fused_computation.599.clone, outer_dimension_partitions={8}
}

%fused_computation.600.clone (param_0.1499: f32[32000,1024], param_1.2302: s32[8,64]) -> f32[64,8,1024] {
  %param_0.1499 = f32[32000,1024]{1,0} parameter(0)
  %param_1.2302 = s32[8,64]{1,0} parameter(1)
  %reshape.3489 = s32[8,64,1]{1,0,2} reshape(s32[8,64]{1,0} %param_1.2302), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/broadcast_in_dim[ broadcast_dimensions=(0, 1)\n                                                shape=(8, 64, 1) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/core.py" source_line=182}
  %copy.82 = s32[8,64,1]{2,1,0} copy(s32[8,64,1]{1,0,2} %reshape.3489), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/broadcast_in_dim[ broadcast_dimensions=(0, 1)\n                                                shape=(8, 64, 1) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/core.py" source_line=182}
  %gather.6 = f32[8,64,1024]{2,1,0} gather(f32[32000,1024]{1,0} %param_0.1499, s32[8,64,1]{2,1,0} %copy.82), offset_dims={2}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=2, slice_sizes={1,1024}, metadata={op_type="gather" op_name="pmap(_multi_device_update_fn)/gather[ dimension_numbers=GatherDimensionNumbers(offset_dims=(2,), collapsed_slice_dims=(0,), start_index_map=(0,))\n                                      indices_are_sorted=False\n                                      slice_sizes=(1, 1024)\n                                      unique_indices=False ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/core.py" source_line=182}
  ROOT %transpose.137 = f32[64,8,1024]{2,0,1} transpose(f32[8,64,1024]{2,1,0} %gather.6), dimensions={1,0,2}, metadata={op_type="transpose" op_name="pmap(_multi_device_update_fn)/transpose[ permutation=(1, 0, 2) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/combinators.py" source_line=342}
}

%parallel_fusion.600 (p.408: f32[32000,1024], p.409: s32[8,64]) -> f32[64,8,1024] {
  %p.408 = f32[32000,1024]{1,0} parameter(0)
  %p.409 = s32[8,64]{1,0} parameter(1)
  ROOT %fusion.600.clone = f32[64,8,1024]{2,0,1} fusion(f32[32000,1024]{1,0} %p.408, s32[8,64]{1,0} %p.409), kind=kLoop, calls=%fused_computation.600.clone, outer_dimension_partitions={8}, metadata={op_type="transpose" op_name="pmap(_multi_device_update_fn)/transpose[ permutation=(1, 0, 2) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/combinators.py" source_line=342}
}

%fused_computation.601.clone (param_0.1500: f32[1024], param_1.2303: f32[512,1024]) -> f32[8,64,1024] {
  %param_1.2303 = f32[512,1024]{1,0} parameter(1)
  %reshape.3490 = f32[8,64,1024]{2,1,0} reshape(f32[512,1024]{1,0} %param_1.2303), metadata={op_type="dot_general" op_name="pmap(_multi_device_update_fn)/dot_general[ dimension_numbers=(((2,), (0,)), ((), ()))\n                                           precision=None\n                                           preferred_element_type=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/core.py" source_line=96}
  %param_0.1500 = f32[1024]{0} parameter(0)
  %broadcast.2685 = f32[8,64,1024]{2,1,0} broadcast(f32[1024]{0} %param_0.1500), dimensions={2}, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/core.py" source_line=96}
  ROOT %add.4413 = f32[8,64,1024]{2,1,0} add(f32[8,64,1024]{2,1,0} %reshape.3490, f32[8,64,1024]{2,1,0} %broadcast.2685), metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/core.py" source_line=96}
}

%parallel_fusion.601 (p.410: f32[1024], p.411: f32[512,1024]) -> f32[8,64,1024] {
  %p.410 = f32[1024]{0} parameter(0)
  %p.411 = f32[512,1024]{1,0} parameter(1)
  ROOT %fusion.601.clone = f32[8,64,1024]{2,1,0} fusion(f32[1024]{0} %p.410, f32[512,1024]{1,0} %p.411), kind=kLoop, calls=%fused_computation.601.clone, outer_dimension_partitions={8}, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/core.py" source_line=96}
}

%fused_computation.602.clone (param_0.1501: f32[64,8,1024]) -> f32[512,1024] {
  %param_0.1501 = f32[64,8,1024]{2,1,0} parameter(0)
  %transpose.138 = f32[8,64,1024]{2,1,0} transpose(f32[64,8,1024]{2,1,0} %param_0.1501), dimensions={1,0,2}, metadata={op_type="transpose" op_name="pmap(_multi_device_update_fn)/transpose[ permutation=(1, 0, 2) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/combinators.py" source_line=342}
  ROOT %reshape.3491 = f32[512,1024]{1,0} reshape(f32[8,64,1024]{2,1,0} %transpose.138)
}

%parallel_fusion.602 (p.412: f32[64,8,1024]) -> f32[512,1024] {
  %p.412 = f32[64,8,1024]{2,1,0} parameter(0)
  ROOT %fusion.602.clone = f32[512,1024]{1,0} fusion(f32[64,8,1024]{2,1,0} %p.412), kind=kLoop, calls=%fused_computation.602.clone, outer_dimension_partitions={8}
}

%fused_computation.643.clone (param_0.1502: f32[256,1024], param_1.2304: s32[8,65]) -> f32[64,8,1024] {
  %param_0.1502 = f32[256,1024]{1,0} parameter(0)
  %param_1.2304 = s32[8,65]{1,0} parameter(1)
  %slice.1454 = s32[8,64]{1,0} slice(s32[8,65]{1,0} %param_1.2304), slice={[0:8], [0:64]}, metadata={op_type="gather" op_name="pmap(_multi_device_update_fn)/gather[ dimension_numbers=GatherDimensionNumbers(offset_dims=(0, 1), collapsed_slice_dims=(), start_index_map=(1,))\n                                      indices_are_sorted=True\n                                      slice_sizes=(8, 64)\n                                      unique_indices=True ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/attention.py" source_line=556}
  %reshape.3492 = s32[8,64,1]{1,0,2} reshape(s32[8,64]{1,0} %slice.1454), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/broadcast_in_dim[ broadcast_dimensions=(0, 1)\n                                                shape=(8, 64, 1) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/core.py" source_line=182}
  %copy.83 = s32[8,64,1]{2,1,0} copy(s32[8,64,1]{1,0,2} %reshape.3492), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/broadcast_in_dim[ broadcast_dimensions=(0, 1)\n                                                shape=(8, 64, 1) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/core.py" source_line=182}
  %gather.7 = f32[8,64,1024]{2,1,0} gather(f32[256,1024]{1,0} %param_0.1502, s32[8,64,1]{2,1,0} %copy.83), offset_dims={2}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=2, slice_sizes={1,1024}, metadata={op_type="gather" op_name="pmap(_multi_device_update_fn)/gather[ dimension_numbers=GatherDimensionNumbers(offset_dims=(2,), collapsed_slice_dims=(0,), start_index_map=(0,))\n                                      indices_are_sorted=False\n                                      slice_sizes=(1, 1024)\n                                      unique_indices=False ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/core.py" source_line=182}
  ROOT %transpose.139 = f32[64,8,1024]{2,0,1} transpose(f32[8,64,1024]{2,1,0} %gather.7), dimensions={1,0,2}, metadata={op_type="transpose" op_name="pmap(_multi_device_update_fn)/transpose[ permutation=(1, 0, 2) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/combinators.py" source_line=342}
}

%parallel_fusion.643 (p.413: f32[256,1024], p.414: s32[8,65]) -> f32[64,8,1024] {
  %p.413 = f32[256,1024]{1,0} parameter(0)
  %p.414 = s32[8,65]{1,0} parameter(1)
  ROOT %fusion.643.clone = f32[64,8,1024]{2,0,1} fusion(f32[256,1024]{1,0} %p.413, s32[8,65]{1,0} %p.414), kind=kLoop, calls=%fused_computation.643.clone, outer_dimension_partitions={8}, metadata={op_type="transpose" op_name="pmap(_multi_device_update_fn)/transpose[ permutation=(1, 0, 2) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/combinators.py" source_line=342}
}

%fused_computation.644.clone (param_0.1503: f32[8,64], param_1.2305: f32[], param_2.1955: s32[8,64]) -> f32[8,64,256] {
  %param_2.1955 = s32[8,64]{1,0} parameter(2)
  %broadcast.2691 = s32[8,64,256]{2,1,0} broadcast(s32[8,64]{1,0} %param_2.1955), dimensions={0,1}, metadata={op_type="eq" op_name="pmap(_multi_device_update_fn)/eq" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/core.py" source_line=776}
  %iota.69 = s32[8,64,256]{2,1,0} iota(), iota_dimension=2, metadata={op_type="eq" op_name="pmap(_multi_device_update_fn)/eq" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/core.py" source_line=776}
  %compare.2835 = pred[8,64,256]{2,1,0} compare(s32[8,64,256]{2,1,0} %broadcast.2691, s32[8,64,256]{2,1,0} %iota.69), direction=EQ, metadata={op_type="eq" op_name="pmap(_multi_device_update_fn)/eq" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/core.py" source_line=776}
  %param_1.2305 = f32[] parameter(1)
  %broadcast.2689 = f32[8,64]{1,0} broadcast(f32[] %param_1.2305), dimensions={}, metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/broadcast_in_dim[ broadcast_dimensions=(  )\n                                                shape=(8, 64) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/metrics.py" source_line=617}
  %param_0.1503 = f32[8,64]{1,0} parameter(0)
  %multiply.2327 = f32[8,64]{1,0} multiply(f32[8,64]{1,0} %broadcast.2689, f32[8,64]{1,0} %param_0.1503), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/metrics.py" source_line=617}
  %constant.21453 = f32[] constant(-1), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/metrics.py" source_line=581}
  %broadcast.2688 = f32[8,64]{1,0} broadcast(f32[] %constant.21453), dimensions={}, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/metrics.py" source_line=581}
  %multiply.2328 = f32[8,64]{1,0} multiply(f32[8,64]{1,0} %multiply.2327, f32[8,64]{1,0} %broadcast.2688), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/metrics.py" source_line=581}
  %broadcast.2690 = f32[8,64,256]{2,1,0} broadcast(f32[8,64]{1,0} %multiply.2328), dimensions={0,1}, metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/broadcast_in_dim[ broadcast_dimensions=(0, 1)\n                                                shape=(8, 64, 256) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/metrics.py" source_line=581}
  %constant.21452 = f32[] constant(0)
  %broadcast.2687 = f32[8,64,256]{2,1,0} broadcast(f32[] %constant.21452), dimensions={}
  %select.2724 = f32[8,64,256]{2,1,0} select(pred[8,64,256]{2,1,0} %compare.2835, f32[8,64,256]{2,1,0} %broadcast.2690, f32[8,64,256]{2,1,0} %broadcast.2687), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/metrics.py" source_line=581}
  ROOT %negate.219 = f32[8,64,256]{2,1,0} negate(f32[8,64,256]{2,1,0} %select.2724), metadata={op_type="neg" op_name="pmap(_multi_device_update_fn)/neg" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/core.py" source_line=794}
}

%parallel_fusion.644 (p.415: f32[8,64], p.416: f32[], p.417: s32[8,64]) -> f32[8,64,256] {
  %p.415 = f32[8,64]{1,0} parameter(0)
  %p.416 = f32[] parameter(1)
  %p.417 = s32[8,64]{1,0} parameter(2)
  ROOT %fusion.644.clone = f32[8,64,256]{2,1,0} fusion(f32[8,64]{1,0} %p.415, f32[] %p.416, s32[8,64]{1,0} %p.417), kind=kLoop, calls=%fused_computation.644.clone, outer_dimension_partitions={2}, metadata={op_type="neg" op_name="pmap(_multi_device_update_fn)/neg" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/core.py" source_line=794}
}

ENTRY %pmap__multi_device_update_fn__2.21607 (parameter.82: f32[32000,1024], parameter.83: f32[2048,4096], parameter.84: f32[4096], parameter.85: f32[2048,4096], parameter.86: f32[4096], parameter.87: f32[2048,4096], parameter.88: f32[4096], parameter.89: f32[2048,4096], parameter.90: f32[4096], parameter.91: f32[256,1024], parameter.92: f32[2048,4096], parameter.93: f32[4096], parameter.94: f32[1024,1024], parameter.95: f32[1024], parameter.96: f32[1024,1024], parameter.97: f32[1024], parameter.98: f32[1024,1024], parameter.99: f32[1024], parameter.100: f32[1024,1024], parameter.101: f32[1024], parameter.102: f32[2048,4096], parameter.103: f32[4096], parameter.104: f32[2048,4096], parameter.105: f32[4096], parameter.106: f32[2048,4096], parameter.107: f32[4096], parameter.108: f32[2048,4096], parameter.109: f32[4096], parameter.110: f32[1024,256], parameter.111: f32[256], parameter.112: f32[32000], parameter.113: f32[1024], parameter.114: f32[2048], parameter.115: f32[4096], parameter.116: f32[4096], parameter.117: f32[2048], parameter.118: f32[4096], parameter.119: f32[4096], parameter.120: f32[2048], parameter.121: f32[4096], parameter.122: f32[4096], parameter.123: f32[2048], parameter.124: f32[4096], parameter.125: f32[4096], parameter.126: f32[256], parameter.127: f32[1024], parameter.128: f32[2048], parameter.129: f32[4096], parameter.130: f32[4096], parameter.131: f32[1024], parameter.132: f32[1024], parameter.133: f32[1024], parameter.134: f32[1024], parameter.135: f32[1024], parameter.136: f32[1024], parameter.137: f32[1024], parameter.138: f32[1024], parameter.139: f32[1024], parameter.140: f32[1024], parameter.141: f32[1024], parameter.142: f32[1024], parameter.143: f32[2048], parameter.144: f32[4096], parameter.145: f32[4096], parameter.146: f32[2048], parameter.147: f32[4096], parameter.148: f32[4096], parameter.149: f32[2048], parameter.150: f32[4096], parameter.151: f32[4096], parameter.152: f32[2048], parameter.153: f32[4096], parameter.154: f32[4096], parameter.155: f32[1024], parameter.156: f32[256], parameter.157: f32[256], parameter.158: s32[], parameter.159: f32[], parameter.160: f32[], parameter.161: f32[], parameter.162: f32[], parameter.163: f32[], parameter.164: f32[], parameter.165: s32[], parameter.166: f32[], parameter.167: s32[8,64], parameter.168: s32[8,64], parameter.169: f32[8,64], parameter.170: u32[2]) -> (f32[32000,1024], f32[2048,4096], f32[4096], f32[2048,4096], f32[4096], /*index=5*/f32[2048,4096], f32[4096], f32[2048,4096], f32[4096], f32[256,1024], /*index=10*/f32[2048,4096], f32[4096], f32[1024,1024], f32[1024], f32[1024,1024], /*index=15*/f32[1024], f32[1024,1024], f32[1024], f32[1024,1024], f32[1024], /*index=20*/f32[2048,4096], f32[4096], f32[2048,4096], f32[4096], f32[2048,4096], /*index=25*/f32[4096], f32[2048,4096], f32[4096], f32[1024,256], f32[256], /*index=30*/f32[32000], f32[1024], f32[2048], f32[4096], f32[4096], /*index=35*/f32[2048], f32[4096], f32[4096], f32[2048], f32[4096], /*index=40*/f32[4096], f32[2048], f32[4096], f32[4096], f32[256], /*index=45*/f32[1024], f32[2048], f32[4096], f32[4096], f32[1024], /*index=50*/f32[1024], f32[1024], f32[1024], f32[1024], f32[1024], /*index=55*/f32[1024], f32[1024], f32[1024], f32[1024], f32[1024], /*index=60*/f32[1024], f32[2048], f32[4096], f32[4096], f32[2048], /*index=65*/f32[4096], f32[4096], f32[2048], f32[4096], f32[4096], /*index=70*/f32[2048], f32[4096], f32[4096], f32[1024], f32[256], /*index=75*/f32[256], f32[], f32[], f32[]) {
  %parameter.159 = f32[] parameter(77), parameter_replication={false}
  %parameter.160 = f32[] parameter(78), parameter_replication={false}
  %constant.1356 = s32[] constant(0), metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %copy.929 = s32[] copy(s32[] %constant.1356)
  %constant.1 = f32[] constant(0)
  %call.59 = f32[32000,1024]{1,0} call(f32[] %constant.1), to_apply=%parallel_broadcast.17492
  %parameter.167 = s32[8,64]{1,0} parameter(85), parameter_replication={false}
  %bitcast = s32[512]{0} bitcast(s32[8,64]{1,0} %parameter.167)
  %parameter.111 = f32[256]{0} parameter(29), parameter_replication={false}
  %parameter.101 = f32[1024]{0} parameter(19), parameter_replication={false}
  %parameter.95 = f32[1024]{0} parameter(13), parameter_replication={false}
  %parameter.91 = f32[256,1024]{1,0} parameter(9), parameter_replication={false}
  %parameter.168 = s32[8,64]{1,0} parameter(86), parameter_replication={false}, metadata={op_type="pad" op_name="pmap(_multi_device_update_fn)/jit(_pad)/pad[ padding_config=((0, 0, 0), (0, 0, 0)) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/attention.py" source_line=741}
  %pad.2 = s32[8,65]{1,0} pad(s32[8,64]{1,0} %parameter.168, s32[] %constant.1356), padding=0_0x1_0, metadata={op_type="pad" op_name="pmap(_multi_device_update_fn)/jit(_pad)/pad[ padding_config=((0, 0, 0), (1, 0, 0)) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/attention.py" source_line=741}
  %call.209 = f32[64,8,1024]{2,0,1} call(f32[256,1024]{1,0} %parameter.91, s32[8,65]{1,0} %pad.2), to_apply=%parallel_fusion.643
  %call.109 = f32[64,8,1024]{2,1,0} call(f32[64,8,1024]{2,0,1} %call.209), to_apply=%parallel_copy.26
  %parameter.92 = f32[2048,4096]{1,0} parameter(10), parameter_replication={false}
  %parameter.93 = f32[4096]{0} parameter(11), parameter_replication={false}
  %bitcast.1 = f32[1,4096]{1,0} bitcast(f32[4096]{0} %parameter.93), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/broadcast_in_dim[ broadcast_dimensions=(1,)\n                                                shape=(1, 4096) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %copy.212 = s32[] copy(s32[] %constant.1356)
  %broadcast.5905 = f32[8,2048]{1,0} broadcast(f32[] %constant.1), dimensions={}, metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/broadcast_in_dim[ broadcast_dimensions=(  )\n                                                shape=(8, 2048) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=88}
  %copy.213 = f32[8,2048]{1,0} copy(f32[8,2048]{1,0} %broadcast.5905)
  %call.56 = f32[64,8,1024]{2,1,0} call(f32[] %constant.1), to_apply=%parallel_broadcast.5943
  %copy.214 = f32[64,8,1024]{2,1,0} copy(f32[64,8,1024]{2,1,0} %call.56)
  %copy.215 = f32[64,8,1024]{2,1,0} copy(f32[64,8,1024]{2,1,0} %call.56)
  %copy.216 = f32[64,8,1024]{2,1,0} copy(f32[64,8,1024]{2,1,0} %call.56)
  %call.57 = f32[64,8,2048]{2,1,0} call(f32[] %constant.1), to_apply=%parallel_broadcast.5949
  %copy.217 = f32[64,8,2048]{2,1,0} copy(f32[64,8,2048]{2,1,0} %call.57)
  %copy.218 = f32[64,8,1024]{2,1,0} copy(f32[64,8,1024]{2,1,0} %call.56)
  %copy.219 = f32[64,8,1024]{2,1,0} copy(f32[64,8,1024]{2,1,0} %call.56)
  %copy.220 = f32[64,8,1024]{2,1,0} copy(f32[64,8,1024]{2,1,0} %call.56)
  %copy.221 = f32[64,8,1024]{2,1,0} copy(f32[64,8,1024]{2,1,0} %call.56)
  %copy.222 = f32[64,8,1024]{2,1,0} copy(f32[64,8,1024]{2,1,0} %call.56)
  %copy.223 = f32[64,8,1024]{2,1,0} copy(f32[64,8,1024]{2,1,0} %call.56)
  %copy.224 = f32[64,8,1024]{2,1,0} copy(f32[64,8,1024]{2,1,0} %call.56)
  %copy.225 = f32[64,8,1024]{2,1,0} copy(f32[64,8,1024]{2,1,0} %call.56)
  %copy.226 = f32[64,8,1024]{2,1,0} copy(f32[64,8,1024]{2,1,0} %call.56)
  %tuple.1265 = (f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) tuple(f32[64,8,1024]{2,1,0} %call.109, f32[2048,4096]{1,0} %parameter.92, f32[1,4096]{1,0} %bitcast.1, s32[] %copy.212, f32[8,2048]{1,0} %copy.213, /*index=5*/f32[64,8,1024]{2,1,0} %copy.214, f32[64,8,1024]{2,1,0} %copy.215, f32[64,8,1024]{2,1,0} %copy.216, f32[64,8,2048]{2,1,0} %copy.217, f32[64,8,1024]{2,1,0} %copy.218, /*index=10*/f32[64,8,1024]{2,1,0} %copy.219, f32[64,8,1024]{2,1,0} %copy.220, f32[64,8,1024]{2,1,0} %copy.221, f32[64,8,1024]{2,1,0} %copy.222, f32[64,8,1024]{2,1,0} %copy.223, /*index=15*/f32[64,8,1024]{2,1,0} %copy.224, f32[64,8,1024]{2,1,0} %copy.225, f32[64,8,1024]{2,1,0} %copy.226)
  %while.197 = (f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) while((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %tuple.1265), condition=%wide.cond_computation__165.6393.clone.clone.clone.clone, body=%wide.body_computation__165.5972.clone.clone.clone.clone.clone
  %get-tuple-element.24842 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %while.197), index=5, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %call.208 = f32[512,1024]{1,0} call(f32[64,8,1024]{2,1,0} %get-tuple-element.24842), to_apply=%parallel_fusion.602
  %parameter.94 = f32[1024,1024]{1,0} parameter(12), parameter_replication={false}
  %dot = f32[512,1024]{1,0} dot(f32[512,1024]{1,0} %call.208, f32[1024,1024]{1,0} %parameter.94), lhs_contracting_dims={1}, rhs_contracting_dims={0}
  %call.207 = f32[8,64,1024]{2,1,0} call(f32[1024]{0} %parameter.95, f32[512,1024]{1,0} %dot), to_apply=%parallel_fusion.601
  %parameter.97 = f32[1024]{0} parameter(15), parameter_replication={false}
  %parameter.82 = f32[32000,1024]{1,0} parameter(0), parameter_replication={false}
  %call.206 = f32[64,8,1024]{2,0,1} call(f32[32000,1024]{1,0} %parameter.82, s32[8,64]{1,0} %parameter.167), to_apply=%parallel_fusion.600
  %call.110 = f32[64,8,1024]{2,1,0} call(f32[64,8,1024]{2,0,1} %call.206), to_apply=%parallel_copy.28
  %parameter.83 = f32[2048,4096]{1,0} parameter(1), parameter_replication={false}
  %parameter.84 = f32[4096]{0} parameter(2), parameter_replication={false}
  %bitcast.2 = f32[1,4096]{1,0} bitcast(f32[4096]{0} %parameter.84), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/broadcast_in_dim[ broadcast_dimensions=(1,)\n                                                shape=(1, 4096) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %copy.257 = s32[] copy(s32[] %constant.1356)
  %copy.258 = f32[8,2048]{1,0} copy(f32[8,2048]{1,0} %broadcast.5905)
  %copy.259 = f32[64,8,1024]{2,1,0} copy(f32[64,8,1024]{2,1,0} %call.56)
  %copy.260 = f32[64,8,1024]{2,1,0} copy(f32[64,8,1024]{2,1,0} %call.56)
  %copy.261 = f32[64,8,1024]{2,1,0} copy(f32[64,8,1024]{2,1,0} %call.56)
  %copy.262 = f32[64,8,2048]{2,1,0} copy(f32[64,8,2048]{2,1,0} %call.57)
  %copy.263 = f32[64,8,1024]{2,1,0} copy(f32[64,8,1024]{2,1,0} %call.56)
  %copy.264 = f32[64,8,1024]{2,1,0} copy(f32[64,8,1024]{2,1,0} %call.56)
  %copy.265 = f32[64,8,1024]{2,1,0} copy(f32[64,8,1024]{2,1,0} %call.56)
  %copy.266 = f32[64,8,1024]{2,1,0} copy(f32[64,8,1024]{2,1,0} %call.56)
  %copy.267 = f32[64,8,1024]{2,1,0} copy(f32[64,8,1024]{2,1,0} %call.56)
  %copy.268 = f32[64,8,1024]{2,1,0} copy(f32[64,8,1024]{2,1,0} %call.56)
  %copy.269 = f32[64,8,1024]{2,1,0} copy(f32[64,8,1024]{2,1,0} %call.56)
  %copy.270 = f32[64,8,1024]{2,1,0} copy(f32[64,8,1024]{2,1,0} %call.56)
  %copy.271 = f32[64,8,1024]{2,1,0} copy(f32[64,8,1024]{2,1,0} %call.56)
  %tuple.1268 = (f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) tuple(f32[64,8,1024]{2,1,0} %call.110, f32[2048,4096]{1,0} %parameter.83, f32[1,4096]{1,0} %bitcast.2, s32[] %copy.257, f32[8,2048]{1,0} %copy.258, /*index=5*/f32[64,8,1024]{2,1,0} %copy.259, f32[64,8,1024]{2,1,0} %copy.260, f32[64,8,1024]{2,1,0} %copy.261, f32[64,8,2048]{2,1,0} %copy.262, f32[64,8,1024]{2,1,0} %copy.263, /*index=10*/f32[64,8,1024]{2,1,0} %copy.264, f32[64,8,1024]{2,1,0} %copy.265, f32[64,8,1024]{2,1,0} %copy.266, f32[64,8,1024]{2,1,0} %copy.267, f32[64,8,1024]{2,1,0} %copy.268, /*index=15*/f32[64,8,1024]{2,1,0} %copy.269, f32[64,8,1024]{2,1,0} %copy.270, f32[64,8,1024]{2,1,0} %copy.271)
  %while.193 = (f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) while((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %tuple.1268), condition=%wide.cond_computation__147.1781.clone.clone.clone.clone, body=%wide.body_computation__147.1360.clone.clone.clone.clone.clone
  %get-tuple-element.24402 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %while.193), index=5, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %parameter.85 = f32[2048,4096]{1,0} parameter(3), parameter_replication={false}
  %parameter.86 = f32[4096]{0} parameter(4), parameter_replication={false}
  %bitcast.3 = f32[1,4096]{1,0} bitcast(f32[4096]{0} %parameter.86), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/broadcast_in_dim[ broadcast_dimensions=(1,)\n                                                shape=(1, 4096) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %copy.302 = s32[] copy(s32[] %constant.1356)
  %copy.303 = f32[8,2048]{1,0} copy(f32[8,2048]{1,0} %broadcast.5905)
  %copy.304 = f32[64,8,1024]{2,1,0} copy(f32[64,8,1024]{2,1,0} %call.56)
  %copy.305 = f32[64,8,1024]{2,1,0} copy(f32[64,8,1024]{2,1,0} %call.56)
  %copy.306 = f32[64,8,1024]{2,1,0} copy(f32[64,8,1024]{2,1,0} %call.56)
  %copy.307 = f32[64,8,2048]{2,1,0} copy(f32[64,8,2048]{2,1,0} %call.57)
  %copy.308 = f32[64,8,1024]{2,1,0} copy(f32[64,8,1024]{2,1,0} %call.56)
  %copy.309 = f32[64,8,1024]{2,1,0} copy(f32[64,8,1024]{2,1,0} %call.56)
  %copy.310 = f32[64,8,1024]{2,1,0} copy(f32[64,8,1024]{2,1,0} %call.56)
  %copy.311 = f32[64,8,1024]{2,1,0} copy(f32[64,8,1024]{2,1,0} %call.56)
  %copy.312 = f32[64,8,1024]{2,1,0} copy(f32[64,8,1024]{2,1,0} %call.56)
  %copy.313 = f32[64,8,1024]{2,1,0} copy(f32[64,8,1024]{2,1,0} %call.56)
  %copy.314 = f32[64,8,1024]{2,1,0} copy(f32[64,8,1024]{2,1,0} %call.56)
  %copy.315 = f32[64,8,1024]{2,1,0} copy(f32[64,8,1024]{2,1,0} %call.56)
  %copy.316 = f32[64,8,1024]{2,1,0} copy(f32[64,8,1024]{2,1,0} %call.56)
  %tuple.1271 = (f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) tuple(f32[64,8,1024]{2,1,0} %get-tuple-element.24402, f32[2048,4096]{1,0} %parameter.85, f32[1,4096]{1,0} %bitcast.3, s32[] %copy.302, f32[8,2048]{1,0} %copy.303, /*index=5*/f32[64,8,1024]{2,1,0} %copy.304, f32[64,8,1024]{2,1,0} %copy.305, f32[64,8,1024]{2,1,0} %copy.306, f32[64,8,2048]{2,1,0} %copy.307, f32[64,8,1024]{2,1,0} %copy.308, /*index=10*/f32[64,8,1024]{2,1,0} %copy.309, f32[64,8,1024]{2,1,0} %copy.310, f32[64,8,1024]{2,1,0} %copy.311, f32[64,8,1024]{2,1,0} %copy.312, f32[64,8,1024]{2,1,0} %copy.313, /*index=15*/f32[64,8,1024]{2,1,0} %copy.314, f32[64,8,1024]{2,1,0} %copy.315, f32[64,8,1024]{2,1,0} %copy.316)
  %while.194 = (f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) while((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %tuple.1271), condition=%wide.cond_computation__151.2830.clone.clone.clone.clone, body=%wide.body_computation__151.2409.clone.clone.clone.clone.clone
  %get-tuple-element.24512 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %while.194), index=5, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %parameter.87 = f32[2048,4096]{1,0} parameter(5), parameter_replication={false}
  %parameter.88 = f32[4096]{0} parameter(6), parameter_replication={false}
  %bitcast.4 = f32[1,4096]{1,0} bitcast(f32[4096]{0} %parameter.88), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/broadcast_in_dim[ broadcast_dimensions=(1,)\n                                                shape=(1, 4096) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %copy.347 = s32[] copy(s32[] %constant.1356)
  %copy.348 = f32[8,2048]{1,0} copy(f32[8,2048]{1,0} %broadcast.5905)
  %copy.349 = f32[64,8,1024]{2,1,0} copy(f32[64,8,1024]{2,1,0} %call.56)
  %copy.350 = f32[64,8,1024]{2,1,0} copy(f32[64,8,1024]{2,1,0} %call.56)
  %copy.351 = f32[64,8,1024]{2,1,0} copy(f32[64,8,1024]{2,1,0} %call.56)
  %copy.352 = f32[64,8,2048]{2,1,0} copy(f32[64,8,2048]{2,1,0} %call.57)
  %copy.353 = f32[64,8,1024]{2,1,0} copy(f32[64,8,1024]{2,1,0} %call.56)
  %copy.354 = f32[64,8,1024]{2,1,0} copy(f32[64,8,1024]{2,1,0} %call.56)
  %copy.355 = f32[64,8,1024]{2,1,0} copy(f32[64,8,1024]{2,1,0} %call.56)
  %copy.356 = f32[64,8,1024]{2,1,0} copy(f32[64,8,1024]{2,1,0} %call.56)
  %copy.357 = f32[64,8,1024]{2,1,0} copy(f32[64,8,1024]{2,1,0} %call.56)
  %copy.358 = f32[64,8,1024]{2,1,0} copy(f32[64,8,1024]{2,1,0} %call.56)
  %copy.359 = f32[64,8,1024]{2,1,0} copy(f32[64,8,1024]{2,1,0} %call.56)
  %copy.360 = f32[64,8,1024]{2,1,0} copy(f32[64,8,1024]{2,1,0} %call.56)
  %copy.361 = f32[64,8,1024]{2,1,0} copy(f32[64,8,1024]{2,1,0} %call.56)
  %tuple.1275 = (f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) tuple(f32[64,8,1024]{2,1,0} %get-tuple-element.24512, f32[2048,4096]{1,0} %parameter.87, f32[1,4096]{1,0} %bitcast.4, s32[] %copy.347, f32[8,2048]{1,0} %copy.348, /*index=5*/f32[64,8,1024]{2,1,0} %copy.349, f32[64,8,1024]{2,1,0} %copy.350, f32[64,8,1024]{2,1,0} %copy.351, f32[64,8,2048]{2,1,0} %copy.352, f32[64,8,1024]{2,1,0} %copy.353, /*index=10*/f32[64,8,1024]{2,1,0} %copy.354, f32[64,8,1024]{2,1,0} %copy.355, f32[64,8,1024]{2,1,0} %copy.356, f32[64,8,1024]{2,1,0} %copy.357, f32[64,8,1024]{2,1,0} %copy.358, /*index=15*/f32[64,8,1024]{2,1,0} %copy.359, f32[64,8,1024]{2,1,0} %copy.360, f32[64,8,1024]{2,1,0} %copy.361)
  %while.195 = (f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) while((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %tuple.1275), condition=%wide.cond_computation__155.3879.clone.clone.clone.clone, body=%wide.body_computation__155.3458.clone.clone.clone.clone.clone
  %get-tuple-element.24622 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %while.195), index=5, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %parameter.89 = f32[2048,4096]{1,0} parameter(7), parameter_replication={false}
  %parameter.90 = f32[4096]{0} parameter(8), parameter_replication={false}
  %bitcast.5 = f32[1,4096]{1,0} bitcast(f32[4096]{0} %parameter.90), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/broadcast_in_dim[ broadcast_dimensions=(1,)\n                                                shape=(1, 4096) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %copy.392 = s32[] copy(s32[] %constant.1356)
  %copy.393 = f32[8,2048]{1,0} copy(f32[8,2048]{1,0} %broadcast.5905)
  %copy.394 = f32[64,8,1024]{2,1,0} copy(f32[64,8,1024]{2,1,0} %call.56)
  %copy.395 = f32[64,8,1024]{2,1,0} copy(f32[64,8,1024]{2,1,0} %call.56)
  %copy.396 = f32[64,8,1024]{2,1,0} copy(f32[64,8,1024]{2,1,0} %call.56)
  %copy.397 = f32[64,8,2048]{2,1,0} copy(f32[64,8,2048]{2,1,0} %call.57)
  %copy.398 = f32[64,8,1024]{2,1,0} copy(f32[64,8,1024]{2,1,0} %call.56)
  %copy.399 = f32[64,8,1024]{2,1,0} copy(f32[64,8,1024]{2,1,0} %call.56)
  %copy.400 = f32[64,8,1024]{2,1,0} copy(f32[64,8,1024]{2,1,0} %call.56)
  %copy.401 = f32[64,8,1024]{2,1,0} copy(f32[64,8,1024]{2,1,0} %call.56)
  %copy.402 = f32[64,8,1024]{2,1,0} copy(f32[64,8,1024]{2,1,0} %call.56)
  %copy.403 = f32[64,8,1024]{2,1,0} copy(f32[64,8,1024]{2,1,0} %call.56)
  %copy.404 = f32[64,8,1024]{2,1,0} copy(f32[64,8,1024]{2,1,0} %call.56)
  %copy.405 = f32[64,8,1024]{2,1,0} copy(f32[64,8,1024]{2,1,0} %call.56)
  %copy.406 = f32[64,8,1024]{2,1,0} copy(f32[64,8,1024]{2,1,0} %call.56)
  %tuple.1279 = (f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) tuple(f32[64,8,1024]{2,1,0} %get-tuple-element.24622, f32[2048,4096]{1,0} %parameter.89, f32[1,4096]{1,0} %bitcast.5, s32[] %copy.392, f32[8,2048]{1,0} %copy.393, /*index=5*/f32[64,8,1024]{2,1,0} %copy.394, f32[64,8,1024]{2,1,0} %copy.395, f32[64,8,1024]{2,1,0} %copy.396, f32[64,8,2048]{2,1,0} %copy.397, f32[64,8,1024]{2,1,0} %copy.398, /*index=10*/f32[64,8,1024]{2,1,0} %copy.399, f32[64,8,1024]{2,1,0} %copy.400, f32[64,8,1024]{2,1,0} %copy.401, f32[64,8,1024]{2,1,0} %copy.402, f32[64,8,1024]{2,1,0} %copy.403, /*index=15*/f32[64,8,1024]{2,1,0} %copy.404, f32[64,8,1024]{2,1,0} %copy.405, f32[64,8,1024]{2,1,0} %copy.406)
  %while.196 = (f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) while((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %tuple.1279), condition=%wide.cond_computation__159.4928.clone.clone.clone.clone, body=%wide.body_computation__159.4507.clone.clone.clone.clone.clone
  %get-tuple-element.24732 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %while.196), index=5, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %call.205 = f32[512,1024]{1,0} call(f32[64,8,1024]{2,1,0} %get-tuple-element.24732), to_apply=%parallel_fusion.599
  %parameter.96 = f32[1024,1024]{1,0} parameter(14), parameter_replication={false}
  %dot.1 = f32[512,1024]{1,0} dot(f32[512,1024]{1,0} %call.205, f32[1024,1024]{1,0} %parameter.96), lhs_contracting_dims={1}, rhs_contracting_dims={0}
  %call.203 = f32[8,1024,64]{2,1,0} call(f32[1024]{0} %parameter.97, f32[512,1024]{1,0} %dot.1), to_apply=%parallel_fusion.597
  %dot.3 = f32[8,64,64]{2,1,0} dot(f32[8,64,1024]{2,1,0} %call.207, f32[8,1024,64]{2,1,0} %call.203), lhs_batch_dims={0}, lhs_contracting_dims={2}, rhs_batch_dims={0}, rhs_contracting_dims={1}
  %fusion.596 = f32[8,1,64,64]{3,2,1,0} fusion(f32[8,64,64]{2,1,0} %dot.3, s32[8,64]{1,0} %parameter.167), kind=kLoop, calls=%fused_computation.596, metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/jit(jvp(_where))/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/attention.py" source_line=283}
  %constant.8154 = f32[] constant(-inf), metadata={op_type="reduce_max" op_name="pmap(_multi_device_update_fn)/reduce_max[ axes=(3,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=94}
  %reduce-window.1 = f32[8,1,64,2]{3,2,1,0} reduce-window(f32[8,1,64,64]{3,2,1,0} %fusion.596, f32[] %constant.8154), window={size=1x1x1x32 stride=1x1x1x32}, to_apply=%primitive_computation_max.8155
  %reduce.3 = f32[8,1,64]{2,1,0} reduce(f32[8,1,64,2]{3,2,1,0} %reduce-window.1, f32[] %constant.8154), dimensions={3}, to_apply=%primitive_computation_max.8155, metadata={op_type="reduce_max" op_name="pmap(_multi_device_update_fn)/reduce_max[ axes=(3,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=94}
  %fusion.595 = f32[8,1,64,1]{3,2,1,0} fusion(f32[8,1,64]{2,1,0} %reduce.3), kind=kLoop, calls=%fused_computation.595, metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=94}
  %fusion.594 = f32[8,1,64,64]{3,2,1,0} fusion(f32[8,1,64,1]{3,2,1,0} %fusion.595, f32[8,64,64]{2,1,0} %dot.3, s32[8,64]{1,0} %parameter.167), kind=kLoop, calls=%fused_computation.594, metadata={op_type="exp" op_name="pmap(_multi_device_update_fn)/exp" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=94}
  %reduce-window.2 = f32[8,1,64,2]{3,2,1,0} reduce-window(f32[8,1,64,64]{3,2,1,0} %fusion.594, f32[] %constant.1), window={size=1x1x1x32 stride=1x1x1x32}, to_apply=%primitive_computation_add__1.8183
  %reduce.4 = f32[8,1,64]{2,1,0} reduce(f32[8,1,64,2]{3,2,1,0} %reduce-window.2, f32[] %constant.1), dimensions={3}, to_apply=%primitive_computation_add__1.8183, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(3,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=94}
  %log = f32[8,1,64]{2,1,0} log(f32[8,1,64]{2,1,0} %reduce.4), metadata={op_type="log" op_name="pmap(_multi_device_update_fn)/log" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=94}
  %fusion.593 = f32[8,1,64,64]{3,2,1,0} fusion(f32[8,1,64,1]{3,2,1,0} %fusion.595, f32[8,1,64]{2,1,0} %log, f32[8,64,64]{2,1,0} %dot.3, s32[8,64]{1,0} %parameter.167), kind=kLoop, calls=%fused_computation.593, metadata={op_type="exp" op_name="pmap(_multi_device_update_fn)/exp" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/attention.py" source_line=287}
  %copy.605 = s32[] copy(s32[] %constant.1356)
  %copy.581 = s32[] copy(s32[] %constant.1356)
  %copy.557 = s32[] copy(s32[] %constant.1356)
  %copy.533 = s32[] copy(s32[] %constant.1356)
  %copy.509 = s32[] copy(s32[] %constant.1356)
  %copy.485 = s32[] copy(s32[] %constant.1356)
  %copy.461 = s32[] copy(s32[] %constant.1356)
  %copy.437 = s32[] copy(s32[] %constant.1356)
  %parameter.170 = u32[2]{0} parameter(88), parameter_replication={false}
  %fusion.641 = u32[2]{0} fusion(u32[2]{0} %parameter.170), kind=kLoop, calls=%fused_computation.641, metadata={op_type="add" op_name="add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %fusion.639 = u32[2]{0} fusion(u32[2]{0} %parameter.170), kind=kLoop, calls=%fused_computation.639, metadata={op_type="add" op_name="add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %fusion.640 = u32[] fusion(u32[2]{0} %parameter.170), kind=kLoop, calls=%fused_computation.640, metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %fusion.638 = u32[] fusion(u32[2]{0} %parameter.170), kind=kLoop, calls=%fused_computation.638, metadata={op_type="xor" op_name="xor" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %fusion.642 = u32[] fusion(u32[2]{0} %parameter.170), kind=kLoop, calls=%fused_computation.642, metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %constant.473 = u32[4]{0} constant({13, 15, 26, 6}), metadata={op_type="threefry2x32" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/threefry2x32" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %copy.956 = u32[4]{0} copy(u32[4]{0} %constant.473)
  %copy.443 = u32[4]{0} copy(u32[4]{0} %copy.956)
  %constant.474 = u32[4]{0} constant({17, 29, 16, 24}), metadata={op_type="threefry2x32" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/threefry2x32" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %copy.957 = u32[4]{0} copy(u32[4]{0} %constant.474)
  %copy.444 = u32[4]{0} copy(u32[4]{0} %copy.957)
  %tuple.1282 = (s32[], u32[2]{0}, u32[2]{0}, u32[], u32[], /*index=5*/u32[], u32[4]{0}, u32[4]{0}) tuple(s32[] %copy.437, u32[2]{0} %fusion.641, u32[2]{0} %fusion.639, u32[] %fusion.640, u32[] %fusion.638, /*index=5*/u32[] %fusion.642, u32[4]{0} %copy.443, u32[4]{0} %copy.444)
  %while.140 = (s32[], u32[2]{0}, u32[2]{0}, u32[], u32[], /*index=5*/u32[], u32[4]{0}, u32[4]{0}) while((s32[], u32[2]{0}, u32[2]{0}, u32[], u32[], /*index=5*/u32[], u32[4]{0}, u32[4]{0}) %tuple.1282), condition=%cond_computation__140.242.clone.clone, body=%body_computation__140.172.clone.clone.clone
  %get-tuple-element.15068 = u32[2]{0} get-tuple-element((s32[], u32[2]{0}, u32[2]{0}, u32[], u32[], /*index=5*/u32[], u32[4]{0}, u32[4]{0}) %while.140), index=1, metadata={op_type="while" op_name="scan/while[ body_nconsts=0\n            cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %fusion.636 = u32[11]{0} fusion(u32[2]{0} %get-tuple-element.15068), kind=kLoop, calls=%fused_computation.636, metadata={op_type="add" op_name="add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %fusion.634 = u32[11]{0} fusion(u32[2]{0} %get-tuple-element.15068), kind=kLoop, calls=%fused_computation.634, metadata={op_type="add" op_name="add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %fusion.635 = u32[] fusion(u32[2]{0} %get-tuple-element.15068), kind=kLoop, calls=%fused_computation.635, metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %fusion.633 = u32[] fusion(u32[2]{0} %get-tuple-element.15068), kind=kLoop, calls=%fused_computation.633, metadata={op_type="xor" op_name="xor" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %fusion.637 = u32[] fusion(u32[2]{0} %get-tuple-element.15068), kind=kLoop, calls=%fused_computation.637, metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %copy.467 = u32[4]{0} copy(u32[4]{0} %copy.956)
  %copy.468 = u32[4]{0} copy(u32[4]{0} %copy.957)
  %tuple.1286 = (s32[], u32[11]{0}, u32[11]{0}, u32[], u32[], /*index=5*/u32[], u32[4]{0}, u32[4]{0}) tuple(s32[] %copy.461, u32[11]{0} %fusion.636, u32[11]{0} %fusion.634, u32[] %fusion.635, u32[] %fusion.633, /*index=5*/u32[] %fusion.637, u32[4]{0} %copy.467, u32[4]{0} %copy.468)
  %while.141 = (s32[], u32[11]{0}, u32[11]{0}, u32[], u32[], /*index=5*/u32[], u32[4]{0}, u32[4]{0}) while((s32[], u32[11]{0}, u32[11]{0}, u32[], u32[], /*index=5*/u32[], u32[4]{0}, u32[4]{0}) %tuple.1286), condition=%cond_computation__141.398.clone.clone, body=%body_computation__141.328.clone.clone.clone
  %get-tuple-element.15120 = u32[11]{0} get-tuple-element((s32[], u32[11]{0}, u32[11]{0}, u32[], u32[], /*index=5*/u32[], u32[4]{0}, u32[4]{0}) %while.141), index=1, metadata={op_type="while" op_name="scan/while[ body_nconsts=0\n            cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.15121 = u32[11]{0} get-tuple-element((s32[], u32[11]{0}, u32[11]{0}, u32[], u32[], /*index=5*/u32[], u32[4]{0}, u32[4]{0}) %while.141), index=2, metadata={op_type="while" op_name="scan/while[ body_nconsts=0\n            cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %concatenate.48 = u32[22]{0} concatenate(u32[11]{0} %get-tuple-element.15120, u32[11]{0} %get-tuple-element.15121), dimensions={0}, metadata={op_type="concatenate" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/concatenate[ dimension=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %fusion.631 = u32[2]{0} fusion(u32[22]{0} %concatenate.48), kind=kLoop, calls=%fused_computation.631, metadata={op_type="add" op_name="add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %fusion.629 = u32[2]{0} fusion(u32[22]{0} %concatenate.48), kind=kLoop, calls=%fused_computation.629, metadata={op_type="add" op_name="add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %fusion.630 = u32[] fusion(u32[22]{0} %concatenate.48), kind=kLoop, calls=%fused_computation.630, metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %fusion.628 = u32[] fusion(u32[22]{0} %concatenate.48), kind=kLoop, calls=%fused_computation.628, metadata={op_type="xor" op_name="xor" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %fusion.632 = u32[] fusion(u32[22]{0} %concatenate.48), kind=kLoop, calls=%fused_computation.632, metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %copy.491 = u32[4]{0} copy(u32[4]{0} %copy.956)
  %copy.492 = u32[4]{0} copy(u32[4]{0} %copy.957)
  %tuple.1289 = (s32[], u32[2]{0}, u32[2]{0}, u32[], u32[], /*index=5*/u32[], u32[4]{0}, u32[4]{0}) tuple(s32[] %copy.485, u32[2]{0} %fusion.631, u32[2]{0} %fusion.629, u32[] %fusion.630, u32[] %fusion.628, /*index=5*/u32[] %fusion.632, u32[4]{0} %copy.491, u32[4]{0} %copy.492)
  %while.142 = (s32[], u32[2]{0}, u32[2]{0}, u32[], u32[], /*index=5*/u32[], u32[4]{0}, u32[4]{0}) while((s32[], u32[2]{0}, u32[2]{0}, u32[], u32[], /*index=5*/u32[], u32[4]{0}, u32[4]{0}) %tuple.1289), condition=%cond_computation__166.6565.clone.clone, body=%body_computation__166.6495.clone.clone.clone
  %get-tuple-element.15172 = u32[2]{0} get-tuple-element((s32[], u32[2]{0}, u32[2]{0}, u32[], u32[], /*index=5*/u32[], u32[4]{0}, u32[4]{0}) %while.142), index=1, metadata={op_type="while" op_name="scan/while[ body_nconsts=0\n            cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %fusion.626 = u32[2]{0} fusion(u32[2]{0} %get-tuple-element.15172), kind=kLoop, calls=%fused_computation.626, metadata={op_type="add" op_name="add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %fusion.624 = u32[2]{0} fusion(u32[2]{0} %get-tuple-element.15172), kind=kLoop, calls=%fused_computation.624, metadata={op_type="add" op_name="add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %fusion.625 = u32[] fusion(u32[2]{0} %get-tuple-element.15172), kind=kLoop, calls=%fused_computation.625, metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %fusion.623 = u32[] fusion(u32[2]{0} %get-tuple-element.15172), kind=kLoop, calls=%fused_computation.623, metadata={op_type="xor" op_name="xor" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %fusion.627 = u32[] fusion(u32[2]{0} %get-tuple-element.15172), kind=kLoop, calls=%fused_computation.627, metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %copy.515 = u32[4]{0} copy(u32[4]{0} %copy.956)
  %copy.516 = u32[4]{0} copy(u32[4]{0} %copy.957)
  %tuple.1292 = (s32[], u32[2]{0}, u32[2]{0}, u32[], u32[], /*index=5*/u32[], u32[4]{0}, u32[4]{0}) tuple(s32[] %copy.509, u32[2]{0} %fusion.626, u32[2]{0} %fusion.624, u32[] %fusion.625, u32[] %fusion.623, /*index=5*/u32[] %fusion.627, u32[4]{0} %copy.515, u32[4]{0} %copy.516)
  %while.143 = (s32[], u32[2]{0}, u32[2]{0}, u32[], u32[], /*index=5*/u32[], u32[4]{0}, u32[4]{0}) while((s32[], u32[2]{0}, u32[2]{0}, u32[], u32[], /*index=5*/u32[], u32[4]{0}, u32[4]{0}) %tuple.1292), condition=%cond_computation__167.6721.clone.clone, body=%body_computation__167.6651.clone.clone.clone
  %get-tuple-element.15224 = u32[2]{0} get-tuple-element((s32[], u32[2]{0}, u32[2]{0}, u32[], u32[], /*index=5*/u32[], u32[4]{0}, u32[4]{0}) %while.143), index=1, metadata={op_type="while" op_name="scan/while[ body_nconsts=0\n            cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.15225 = u32[2]{0} get-tuple-element((s32[], u32[2]{0}, u32[2]{0}, u32[], u32[], /*index=5*/u32[], u32[4]{0}, u32[4]{0}) %while.143), index=2, metadata={op_type="while" op_name="scan/while[ body_nconsts=0\n            cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %concatenate.73 = u32[4]{0} concatenate(u32[2]{0} %get-tuple-element.15224, u32[2]{0} %get-tuple-element.15225), dimensions={0}, metadata={op_type="concatenate" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/concatenate[ dimension=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %fusion.621 = u32[2]{0} fusion(u32[4]{0} %concatenate.73), kind=kLoop, calls=%fused_computation.621, metadata={op_type="add" op_name="add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %fusion.619 = u32[2]{0} fusion(u32[4]{0} %concatenate.73), kind=kLoop, calls=%fused_computation.619, metadata={op_type="add" op_name="add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %fusion.620 = u32[] fusion(u32[4]{0} %concatenate.73), kind=kLoop, calls=%fused_computation.620, metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %fusion.618 = u32[] fusion(u32[4]{0} %concatenate.73), kind=kLoop, calls=%fused_computation.618, metadata={op_type="xor" op_name="xor" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %fusion.622 = u32[] fusion(u32[4]{0} %concatenate.73), kind=kLoop, calls=%fused_computation.622, metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %copy.539 = u32[4]{0} copy(u32[4]{0} %copy.956)
  %copy.540 = u32[4]{0} copy(u32[4]{0} %copy.957)
  %tuple.1295 = (s32[], u32[2]{0}, u32[2]{0}, u32[], u32[], /*index=5*/u32[], u32[4]{0}, u32[4]{0}) tuple(s32[] %copy.533, u32[2]{0} %fusion.621, u32[2]{0} %fusion.619, u32[] %fusion.620, u32[] %fusion.618, /*index=5*/u32[] %fusion.622, u32[4]{0} %copy.539, u32[4]{0} %copy.540)
  %while.144 = (s32[], u32[2]{0}, u32[2]{0}, u32[], u32[], /*index=5*/u32[], u32[4]{0}, u32[4]{0}) while((s32[], u32[2]{0}, u32[2]{0}, u32[], u32[], /*index=5*/u32[], u32[4]{0}, u32[4]{0}) %tuple.1295), condition=%cond_computation__168.6877.clone.clone, body=%body_computation__168.6807.clone.clone.clone
  %get-tuple-element.15347 = u32[2]{0} get-tuple-element((s32[], u32[2]{0}, u32[2]{0}, u32[], u32[], /*index=5*/u32[], u32[4]{0}, u32[4]{0}) %while.144), index=1, metadata={op_type="while" op_name="scan/while[ body_nconsts=0\n            cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.15348 = u32[2]{0} get-tuple-element((s32[], u32[2]{0}, u32[2]{0}, u32[], u32[], /*index=5*/u32[], u32[4]{0}, u32[4]{0}) %while.144), index=2, metadata={op_type="while" op_name="scan/while[ body_nconsts=0\n            cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %concatenate.74 = u32[4]{0} concatenate(u32[2]{0} %get-tuple-element.15347, u32[2]{0} %get-tuple-element.15348), dimensions={0}, metadata={op_type="concatenate" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/concatenate[ dimension=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %fusion.616 = u32[3]{0} fusion(u32[4]{0} %concatenate.74), kind=kLoop, calls=%fused_computation.616, metadata={op_type="add" op_name="add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %fusion.614 = u32[3]{0} fusion(u32[4]{0} %concatenate.74), kind=kLoop, calls=%fused_computation.614, metadata={op_type="add" op_name="add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %fusion.615 = u32[] fusion(u32[4]{0} %concatenate.74), kind=kLoop, calls=%fused_computation.615, metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %fusion.613 = u32[] fusion(u32[4]{0} %concatenate.74), kind=kLoop, calls=%fused_computation.613, metadata={op_type="xor" op_name="xor" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %fusion.617 = u32[] fusion(u32[4]{0} %concatenate.74), kind=kLoop, calls=%fused_computation.617, metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %copy.563 = u32[4]{0} copy(u32[4]{0} %copy.956)
  %copy.564 = u32[4]{0} copy(u32[4]{0} %copy.957)
  %tuple.1298 = (s32[], u32[3]{0}, u32[3]{0}, u32[], u32[], /*index=5*/u32[], u32[4]{0}, u32[4]{0}) tuple(s32[] %copy.557, u32[3]{0} %fusion.616, u32[3]{0} %fusion.614, u32[] %fusion.615, u32[] %fusion.613, /*index=5*/u32[] %fusion.617, u32[4]{0} %copy.563, u32[4]{0} %copy.564)
  %while.145 = (s32[], u32[3]{0}, u32[3]{0}, u32[], u32[], /*index=5*/u32[], u32[4]{0}, u32[4]{0}) while((s32[], u32[3]{0}, u32[3]{0}, u32[], u32[], /*index=5*/u32[], u32[4]{0}, u32[4]{0}) %tuple.1298), condition=%cond_computation__169.7033.clone.clone, body=%body_computation__169.6963.clone.clone.clone
  %get-tuple-element.15400 = u32[3]{0} get-tuple-element((s32[], u32[3]{0}, u32[3]{0}, u32[], u32[], /*index=5*/u32[], u32[4]{0}, u32[4]{0}) %while.145), index=1, metadata={op_type="while" op_name="scan/while[ body_nconsts=0\n            cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.15401 = u32[3]{0} get-tuple-element((s32[], u32[3]{0}, u32[3]{0}, u32[], u32[], /*index=5*/u32[], u32[4]{0}, u32[4]{0}) %while.145), index=2, metadata={op_type="while" op_name="scan/while[ body_nconsts=0\n            cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %concatenate.75 = u32[6]{0} concatenate(u32[3]{0} %get-tuple-element.15400, u32[3]{0} %get-tuple-element.15401), dimensions={0}, metadata={op_type="concatenate" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/concatenate[ dimension=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %fusion.611 = u32[3]{0} fusion(u32[6]{0} %concatenate.75), kind=kLoop, calls=%fused_computation.611, metadata={op_type="add" op_name="add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %fusion.609 = u32[3]{0} fusion(u32[6]{0} %concatenate.75), kind=kLoop, calls=%fused_computation.609, metadata={op_type="add" op_name="add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %fusion.610 = u32[] fusion(u32[6]{0} %concatenate.75), kind=kLoop, calls=%fused_computation.610, metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %fusion.608 = u32[] fusion(u32[6]{0} %concatenate.75), kind=kLoop, calls=%fused_computation.608, metadata={op_type="xor" op_name="xor" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %fusion.612 = u32[] fusion(u32[6]{0} %concatenate.75), kind=kLoop, calls=%fused_computation.612, metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %copy.587 = u32[4]{0} copy(u32[4]{0} %copy.956)
  %copy.588 = u32[4]{0} copy(u32[4]{0} %copy.957)
  %tuple.1301 = (s32[], u32[3]{0}, u32[3]{0}, u32[], u32[], /*index=5*/u32[], u32[4]{0}, u32[4]{0}) tuple(s32[] %copy.581, u32[3]{0} %fusion.611, u32[3]{0} %fusion.609, u32[] %fusion.610, u32[] %fusion.608, /*index=5*/u32[] %fusion.612, u32[4]{0} %copy.587, u32[4]{0} %copy.588)
  %while.146 = (s32[], u32[3]{0}, u32[3]{0}, u32[], u32[], /*index=5*/u32[], u32[4]{0}, u32[4]{0}) while((s32[], u32[3]{0}, u32[3]{0}, u32[], u32[], /*index=5*/u32[], u32[4]{0}, u32[4]{0}) %tuple.1301), condition=%cond_computation__170.7191.clone.clone, body=%body_computation__170.7121.clone.clone.clone
  %get-tuple-element.15453 = u32[3]{0} get-tuple-element((s32[], u32[3]{0}, u32[3]{0}, u32[], u32[], /*index=5*/u32[], u32[4]{0}, u32[4]{0}) %while.146), index=1, metadata={op_type="while" op_name="scan/while[ body_nconsts=0\n            cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.15454 = u32[3]{0} get-tuple-element((s32[], u32[3]{0}, u32[3]{0}, u32[], u32[], /*index=5*/u32[], u32[4]{0}, u32[4]{0}) %while.146), index=2, metadata={op_type="while" op_name="scan/while[ body_nconsts=0\n            cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %concatenate.76 = u32[6]{0} concatenate(u32[3]{0} %get-tuple-element.15453, u32[3]{0} %get-tuple-element.15454), dimensions={0}, metadata={op_type="concatenate" op_name="pmap(_multi_device_update_fn)/jit(_split)/jit(threefry_2x32)/concatenate[ dimension=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=71}
  %fusion.606 = u32[16384]{0} fusion(u32[6]{0} %concatenate.76), kind=kLoop, calls=%fused_computation.606, metadata={op_type="add" op_name="add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %fusion.604 = u32[16384]{0} fusion(u32[6]{0} %concatenate.76), kind=kLoop, calls=%fused_computation.604, metadata={op_type="add" op_name="add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %fusion.605 = u32[] fusion(u32[6]{0} %concatenate.76), kind=kLoop, calls=%fused_computation.605, metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/jit(_bernoulli)/jit(_uniform)/jit(_random_bits)/jit(threefry_2x32)/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=86}
  %fusion.603 = u32[] fusion(u32[6]{0} %concatenate.76), kind=kLoop, calls=%fused_computation.603, metadata={op_type="xor" op_name="xor" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %fusion.607 = u32[] fusion(u32[6]{0} %concatenate.76), kind=kLoop, calls=%fused_computation.607, metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/jit(_bernoulli)/jit(_uniform)/jit(_random_bits)/jit(threefry_2x32)/squeeze[ dimensions=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=86}
  %tuple.1304 = (s32[], u32[16384]{0}, u32[16384]{0}, u32[], u32[], /*index=5*/u32[], u32[4]{0}, u32[4]{0}) tuple(s32[] %copy.605, u32[16384]{0} %fusion.606, u32[16384]{0} %fusion.604, u32[] %fusion.605, u32[] %fusion.603, /*index=5*/u32[] %fusion.607, u32[4]{0} %copy.956, u32[4]{0} %copy.957)
  %while.147 = (s32[], u32[16384]{0}, u32[16384]{0}, u32[], u32[], /*index=5*/u32[], u32[4]{0}, u32[4]{0}) while((s32[], u32[16384]{0}, u32[16384]{0}, u32[], u32[], /*index=5*/u32[], u32[4]{0}, u32[4]{0}) %tuple.1304), condition=%cond_computation__175.8296.clone.clone, body=%body_computation__175.8226.clone.clone.clone
  %get-tuple-element.15530 = u32[16384]{0} get-tuple-element((s32[], u32[16384]{0}, u32[16384]{0}, u32[], u32[], /*index=5*/u32[], u32[4]{0}, u32[4]{0}) %while.147), index=1, metadata={op_type="while" op_name="scan/while[ body_nconsts=0\n            cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.15531 = u32[16384]{0} get-tuple-element((s32[], u32[16384]{0}, u32[16384]{0}, u32[], u32[], /*index=5*/u32[], u32[4]{0}, u32[4]{0}) %while.147), index=2, metadata={op_type="while" op_name="scan/while[ body_nconsts=0\n            cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %concatenate.93 = u32[32768]{0} concatenate(u32[16384]{0} %get-tuple-element.15530, u32[16384]{0} %get-tuple-element.15531), dimensions={0}, metadata={op_type="concatenate" op_name="pmap(_multi_device_update_fn)/jit(_bernoulli)/jit(_uniform)/jit(_random_bits)/jit(threefry_2x32)/concatenate[ dimension=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=86}
  %fusion.592 = f32[8,64,64]{2,1,0} fusion(f32[8,1,64,64]{3,2,1,0} %fusion.593, u32[32768]{0} %concatenate.93), kind=kLoop, calls=%fused_computation.592, metadata={op_type="squeeze" op_name="pmap(_multi_device_update_fn)/squeeze[ dimensions=(1,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/attention.py" source_line=293}
  %parameter.99 = f32[1024]{0} parameter(17), parameter_replication={false}
  %parameter.98 = f32[1024,1024]{1,0} parameter(16), parameter_replication={false}
  %dot.2 = f32[512,1024]{1,0} dot(f32[512,1024]{1,0} %call.205, f32[1024,1024]{1,0} %parameter.98), lhs_contracting_dims={1}, rhs_contracting_dims={0}
  %call.202 = f32[8,64,1024]{2,1,0} call(f32[1024]{0} %parameter.99, f32[512,1024]{1,0} %dot.2), to_apply=%parallel_fusion.591
  %dot.4 = f32[8,64,1024]{2,1,0} dot(f32[8,64,64]{2,1,0} %fusion.592, f32[8,64,1024]{2,1,0} %call.202), lhs_batch_dims={0}, lhs_contracting_dims={2}, rhs_batch_dims={0}, rhs_contracting_dims={1}
  %bitcast.6 = f32[512,1024]{1,0} bitcast(f32[8,64,1024]{2,1,0} %dot.4)
  %parameter.100 = f32[1024,1024]{1,0} parameter(18), parameter_replication={false}
  %dot.5 = f32[512,1024]{1,0} dot(f32[512,1024]{1,0} %bitcast.6, f32[1024,1024]{1,0} %parameter.100), lhs_contracting_dims={1}, rhs_contracting_dims={0}
  %call.201 = f32[64,8,1024]{2,0,1} call(f32[1024]{0} %parameter.101, f32[512,1024]{1,0} %dot.5, f32[64,8,1024]{2,1,0} %get-tuple-element.24842), to_apply=%parallel_fusion.590
  %call.111 = f32[64,8,1024]{2,1,0} call(f32[64,8,1024]{2,0,1} %call.201), to_apply=%parallel_copy.35
  %parameter.102 = f32[2048,4096]{1,0} parameter(20), parameter_replication={false}
  %parameter.103 = f32[4096]{0} parameter(21), parameter_replication={false}
  %bitcast.7 = f32[1,4096]{1,0} bitcast(f32[4096]{0} %parameter.103), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/broadcast_in_dim[ broadcast_dimensions=(1,)\n                                                shape=(1, 4096) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %copy.629 = s32[] copy(s32[] %constant.1356)
  %copy.630 = f32[8,2048]{1,0} copy(f32[8,2048]{1,0} %broadcast.5905)
  %copy.631 = f32[64,8,1024]{2,1,0} copy(f32[64,8,1024]{2,1,0} %call.56)
  %copy.632 = f32[64,8,1024]{2,1,0} copy(f32[64,8,1024]{2,1,0} %call.56)
  %copy.633 = f32[64,8,1024]{2,1,0} copy(f32[64,8,1024]{2,1,0} %call.56)
  %copy.634 = f32[64,8,2048]{2,1,0} copy(f32[64,8,2048]{2,1,0} %call.57)
  %copy.635 = f32[64,8,1024]{2,1,0} copy(f32[64,8,1024]{2,1,0} %call.56)
  %copy.636 = f32[64,8,1024]{2,1,0} copy(f32[64,8,1024]{2,1,0} %call.56)
  %copy.637 = f32[64,8,1024]{2,1,0} copy(f32[64,8,1024]{2,1,0} %call.56)
  %copy.638 = f32[64,8,1024]{2,1,0} copy(f32[64,8,1024]{2,1,0} %call.56)
  %copy.639 = f32[64,8,1024]{2,1,0} copy(f32[64,8,1024]{2,1,0} %call.56)
  %copy.640 = f32[64,8,1024]{2,1,0} copy(f32[64,8,1024]{2,1,0} %call.56)
  %copy.641 = f32[64,8,1024]{2,1,0} copy(f32[64,8,1024]{2,1,0} %call.56)
  %copy.642 = f32[64,8,1024]{2,1,0} copy(f32[64,8,1024]{2,1,0} %call.56)
  %copy.643 = f32[64,8,1024]{2,1,0} copy(f32[64,8,1024]{2,1,0} %call.56)
  %tuple.1308 = (f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) tuple(f32[64,8,1024]{2,1,0} %call.111, f32[2048,4096]{1,0} %parameter.102, f32[1,4096]{1,0} %bitcast.7, s32[] %copy.629, f32[8,2048]{1,0} %copy.630, /*index=5*/f32[64,8,1024]{2,1,0} %copy.631, f32[64,8,1024]{2,1,0} %copy.632, f32[64,8,1024]{2,1,0} %copy.633, f32[64,8,2048]{2,1,0} %copy.634, f32[64,8,1024]{2,1,0} %copy.635, /*index=10*/f32[64,8,1024]{2,1,0} %copy.636, f32[64,8,1024]{2,1,0} %copy.637, f32[64,8,1024]{2,1,0} %copy.638, f32[64,8,1024]{2,1,0} %copy.639, f32[64,8,1024]{2,1,0} %copy.640, /*index=15*/f32[64,8,1024]{2,1,0} %copy.641, f32[64,8,1024]{2,1,0} %copy.642, f32[64,8,1024]{2,1,0} %copy.643)
  %while.198 = (f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) while((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %tuple.1308), condition=%wide.cond_computation__180.9635.clone.clone.clone.clone, body=%wide.body_computation__180.9214.clone.clone.clone.clone.clone
  %get-tuple-element.24952 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %while.198), index=5, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %parameter.104 = f32[2048,4096]{1,0} parameter(22), parameter_replication={false}
  %parameter.105 = f32[4096]{0} parameter(23), parameter_replication={false}
  %bitcast.8 = f32[1,4096]{1,0} bitcast(f32[4096]{0} %parameter.105), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/broadcast_in_dim[ broadcast_dimensions=(1,)\n                                                shape=(1, 4096) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %copy.674 = s32[] copy(s32[] %constant.1356)
  %copy.675 = f32[8,2048]{1,0} copy(f32[8,2048]{1,0} %broadcast.5905)
  %copy.676 = f32[64,8,1024]{2,1,0} copy(f32[64,8,1024]{2,1,0} %call.56)
  %copy.677 = f32[64,8,1024]{2,1,0} copy(f32[64,8,1024]{2,1,0} %call.56)
  %copy.678 = f32[64,8,1024]{2,1,0} copy(f32[64,8,1024]{2,1,0} %call.56)
  %copy.679 = f32[64,8,2048]{2,1,0} copy(f32[64,8,2048]{2,1,0} %call.57)
  %copy.680 = f32[64,8,1024]{2,1,0} copy(f32[64,8,1024]{2,1,0} %call.56)
  %copy.681 = f32[64,8,1024]{2,1,0} copy(f32[64,8,1024]{2,1,0} %call.56)
  %copy.682 = f32[64,8,1024]{2,1,0} copy(f32[64,8,1024]{2,1,0} %call.56)
  %copy.683 = f32[64,8,1024]{2,1,0} copy(f32[64,8,1024]{2,1,0} %call.56)
  %copy.684 = f32[64,8,1024]{2,1,0} copy(f32[64,8,1024]{2,1,0} %call.56)
  %copy.685 = f32[64,8,1024]{2,1,0} copy(f32[64,8,1024]{2,1,0} %call.56)
  %copy.686 = f32[64,8,1024]{2,1,0} copy(f32[64,8,1024]{2,1,0} %call.56)
  %copy.687 = f32[64,8,1024]{2,1,0} copy(f32[64,8,1024]{2,1,0} %call.56)
  %copy.688 = f32[64,8,1024]{2,1,0} copy(f32[64,8,1024]{2,1,0} %call.56)
  %tuple.1311 = (f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) tuple(f32[64,8,1024]{2,1,0} %get-tuple-element.24952, f32[2048,4096]{1,0} %parameter.104, f32[1,4096]{1,0} %bitcast.8, s32[] %copy.674, f32[8,2048]{1,0} %copy.675, /*index=5*/f32[64,8,1024]{2,1,0} %copy.676, f32[64,8,1024]{2,1,0} %copy.677, f32[64,8,1024]{2,1,0} %copy.678, f32[64,8,2048]{2,1,0} %copy.679, f32[64,8,1024]{2,1,0} %copy.680, /*index=10*/f32[64,8,1024]{2,1,0} %copy.681, f32[64,8,1024]{2,1,0} %copy.682, f32[64,8,1024]{2,1,0} %copy.683, f32[64,8,1024]{2,1,0} %copy.684, f32[64,8,1024]{2,1,0} %copy.685, /*index=15*/f32[64,8,1024]{2,1,0} %copy.686, f32[64,8,1024]{2,1,0} %copy.687, f32[64,8,1024]{2,1,0} %copy.688)
  %while.199 = (f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) while((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %tuple.1311), condition=%wide.cond_computation__184.10684.clone.clone.clone.clone, body=%wide.body_computation__184.10263.clone.clone.clone.clone.clone
  %get-tuple-element.25062 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %while.199), index=5, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %parameter.106 = f32[2048,4096]{1,0} parameter(24), parameter_replication={false}
  %parameter.107 = f32[4096]{0} parameter(25), parameter_replication={false}
  %bitcast.9 = f32[1,4096]{1,0} bitcast(f32[4096]{0} %parameter.107), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/broadcast_in_dim[ broadcast_dimensions=(1,)\n                                                shape=(1, 4096) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %copy.719 = s32[] copy(s32[] %constant.1356)
  %copy.720 = f32[8,2048]{1,0} copy(f32[8,2048]{1,0} %broadcast.5905)
  %copy.721 = f32[64,8,1024]{2,1,0} copy(f32[64,8,1024]{2,1,0} %call.56)
  %copy.722 = f32[64,8,1024]{2,1,0} copy(f32[64,8,1024]{2,1,0} %call.56)
  %copy.723 = f32[64,8,1024]{2,1,0} copy(f32[64,8,1024]{2,1,0} %call.56)
  %copy.724 = f32[64,8,2048]{2,1,0} copy(f32[64,8,2048]{2,1,0} %call.57)
  %copy.725 = f32[64,8,1024]{2,1,0} copy(f32[64,8,1024]{2,1,0} %call.56)
  %copy.726 = f32[64,8,1024]{2,1,0} copy(f32[64,8,1024]{2,1,0} %call.56)
  %copy.727 = f32[64,8,1024]{2,1,0} copy(f32[64,8,1024]{2,1,0} %call.56)
  %copy.728 = f32[64,8,1024]{2,1,0} copy(f32[64,8,1024]{2,1,0} %call.56)
  %copy.729 = f32[64,8,1024]{2,1,0} copy(f32[64,8,1024]{2,1,0} %call.56)
  %copy.730 = f32[64,8,1024]{2,1,0} copy(f32[64,8,1024]{2,1,0} %call.56)
  %copy.731 = f32[64,8,1024]{2,1,0} copy(f32[64,8,1024]{2,1,0} %call.56)
  %copy.732 = f32[64,8,1024]{2,1,0} copy(f32[64,8,1024]{2,1,0} %call.56)
  %copy.733 = f32[64,8,1024]{2,1,0} copy(f32[64,8,1024]{2,1,0} %call.56)
  %tuple.1314 = (f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) tuple(f32[64,8,1024]{2,1,0} %get-tuple-element.25062, f32[2048,4096]{1,0} %parameter.106, f32[1,4096]{1,0} %bitcast.9, s32[] %copy.719, f32[8,2048]{1,0} %copy.720, /*index=5*/f32[64,8,1024]{2,1,0} %copy.721, f32[64,8,1024]{2,1,0} %copy.722, f32[64,8,1024]{2,1,0} %copy.723, f32[64,8,2048]{2,1,0} %copy.724, f32[64,8,1024]{2,1,0} %copy.725, /*index=10*/f32[64,8,1024]{2,1,0} %copy.726, f32[64,8,1024]{2,1,0} %copy.727, f32[64,8,1024]{2,1,0} %copy.728, f32[64,8,1024]{2,1,0} %copy.729, f32[64,8,1024]{2,1,0} %copy.730, /*index=15*/f32[64,8,1024]{2,1,0} %copy.731, f32[64,8,1024]{2,1,0} %copy.732, f32[64,8,1024]{2,1,0} %copy.733)
  %while.200 = (f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) while((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %tuple.1314), condition=%wide.cond_computation__188.11733.clone.clone.clone.clone, body=%wide.body_computation__188.11312.clone.clone.clone.clone.clone
  %get-tuple-element.25172 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %while.200), index=5, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %parameter.108 = f32[2048,4096]{1,0} parameter(26), parameter_replication={false}
  %parameter.109 = f32[4096]{0} parameter(27), parameter_replication={false}
  %bitcast.10 = f32[1,4096]{1,0} bitcast(f32[4096]{0} %parameter.109), metadata={op_type="broadcast_in_dim" op_name="pmap(_multi_device_update_fn)/broadcast_in_dim[ broadcast_dimensions=(1,)\n                                                shape=(1, 4096) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/rnn.py" source_line=58}
  %copy.764 = s32[] copy(s32[] %constant.1356)
  %copy.765 = f32[8,2048]{1,0} copy(f32[8,2048]{1,0} %broadcast.5905)
  %copy.766 = f32[64,8,1024]{2,1,0} copy(f32[64,8,1024]{2,1,0} %call.56)
  %copy.767 = f32[64,8,1024]{2,1,0} copy(f32[64,8,1024]{2,1,0} %call.56)
  %copy.768 = f32[64,8,1024]{2,1,0} copy(f32[64,8,1024]{2,1,0} %call.56)
  %copy.770 = f32[64,8,1024]{2,1,0} copy(f32[64,8,1024]{2,1,0} %call.56)
  %copy.771 = f32[64,8,1024]{2,1,0} copy(f32[64,8,1024]{2,1,0} %call.56)
  %copy.772 = f32[64,8,1024]{2,1,0} copy(f32[64,8,1024]{2,1,0} %call.56)
  %copy.773 = f32[64,8,1024]{2,1,0} copy(f32[64,8,1024]{2,1,0} %call.56)
  %copy.774 = f32[64,8,1024]{2,1,0} copy(f32[64,8,1024]{2,1,0} %call.56)
  %copy.775 = f32[64,8,1024]{2,1,0} copy(f32[64,8,1024]{2,1,0} %call.56)
  %copy.776 = f32[64,8,1024]{2,1,0} copy(f32[64,8,1024]{2,1,0} %call.56)
  %copy.777 = f32[64,8,1024]{2,1,0} copy(f32[64,8,1024]{2,1,0} %call.56)
  %copy.778 = f32[64,8,1024]{2,1,0} copy(f32[64,8,1024]{2,1,0} %call.56)
  %tuple.1318 = (f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) tuple(f32[64,8,1024]{2,1,0} %get-tuple-element.25172, f32[2048,4096]{1,0} %parameter.108, f32[1,4096]{1,0} %bitcast.10, s32[] %copy.764, f32[8,2048]{1,0} %copy.765, /*index=5*/f32[64,8,1024]{2,1,0} %copy.766, f32[64,8,1024]{2,1,0} %copy.767, f32[64,8,1024]{2,1,0} %copy.768, f32[64,8,2048]{2,1,0} %call.57, f32[64,8,1024]{2,1,0} %copy.770, /*index=10*/f32[64,8,1024]{2,1,0} %copy.771, f32[64,8,1024]{2,1,0} %copy.772, f32[64,8,1024]{2,1,0} %copy.773, f32[64,8,1024]{2,1,0} %copy.774, f32[64,8,1024]{2,1,0} %copy.775, /*index=15*/f32[64,8,1024]{2,1,0} %copy.776, f32[64,8,1024]{2,1,0} %copy.777, f32[64,8,1024]{2,1,0} %copy.778)
  %while.201 = (f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) while((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %tuple.1318), condition=%wide.cond_computation__192.12782.clone.clone.clone.clone, body=%wide.body_computation__192.12361.clone.clone.clone.clone.clone
  %get-tuple-element.25282 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %while.201), index=5, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %call.200 = f32[512,1024]{1,0} call(f32[64,8,1024]{2,1,0} %get-tuple-element.25282), to_apply=%parallel_fusion.589
  %parameter.110 = f32[1024,256]{1,0} parameter(28), parameter_replication={false}
  %dot.6 = f32[512,256]{1,0} dot(f32[512,1024]{1,0} %call.200, f32[1024,256]{1,0} %parameter.110), lhs_contracting_dims={1}, rhs_contracting_dims={0}
  %call.199 = f32[8,64,256]{2,1,0} call(f32[256]{0} %parameter.111, f32[512,256]{1,0} %dot.6), to_apply=%parallel_fusion.588
  %reduce-window.3 = f32[8,64,8]{2,1,0} reduce-window(f32[8,64,256]{2,1,0} %call.199, f32[] %constant.8154), window={size=1x1x32 stride=1x1x32}, to_apply=%primitive_computation_max.12878
  %reduce.5 = f32[8,64]{1,0} reduce(f32[8,64,8]{2,1,0} %reduce-window.3, f32[] %constant.8154), dimensions={2}, to_apply=%primitive_computation_max.12878, metadata={op_type="reduce_max" op_name="pmap(_multi_device_update_fn)/reduce_max[ axes=(2,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=94}
  %fusion.587 = f32[8,64,1]{2,1,0} fusion(f32[8,64]{1,0} %reduce.5), kind=kLoop, calls=%fused_computation.587, metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=94}
  %call.198 = f32[8,64,256]{2,1,0} call(f32[8,64,1]{2,1,0} %fusion.587, f32[256]{0} %parameter.111, f32[512,256]{1,0} %dot.6), to_apply=%parallel_fusion.586
  %reduce-window.4 = f32[8,64,8]{2,1,0} reduce-window(f32[8,64,256]{2,1,0} %call.198, f32[] %constant.1), window={size=1x1x32 stride=1x1x32}, to_apply=%primitive_computation_add__1.12906
  %reduce.6 = f32[8,64]{1,0} reduce(f32[8,64,8]{2,1,0} %reduce-window.4, f32[] %constant.1), dimensions={2}, to_apply=%primitive_computation_add__1.12906, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(2,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=94}
  %log.1 = f32[8,64]{1,0} log(f32[8,64]{1,0} %reduce.6), metadata={op_type="log" op_name="pmap(_multi_device_update_fn)/log" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=94}
  %call.197 = f32[8,64,256]{2,1,0} call(f32[8,64,1]{2,1,0} %fusion.587, f32[8,64]{1,0} %log.1, f32[256]{0} %parameter.111, f32[512,256]{1,0} %dot.6), to_apply=%parallel_fusion.585
  %reduce-window.5 = f32[8,64,8]{2,1,0} reduce-window(f32[8,64,256]{2,1,0} %call.197, f32[] %constant.8154), window={size=1x1x32 stride=1x1x32}, to_apply=%primitive_computation_max.13106
  %reduce.7 = f32[8,64]{1,0} reduce(f32[8,64,8]{2,1,0} %reduce-window.5, f32[] %constant.8154), dimensions={2}, to_apply=%primitive_computation_max.13106, metadata={op_type="reduce_max" op_name="pmap(_multi_device_update_fn)/reduce_max[ axes=(2,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=94}
  %fusion.584 = f32[8,64,1]{2,1,0} fusion(f32[8,64]{1,0} %reduce.7), kind=kLoop, calls=%fused_computation.584, metadata={op_type="select" op_name="pmap(_multi_device_update_fn)/select" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=94}
  %call.196 = f32[8,64,256]{2,1,0} call(f32[8,64,1]{2,1,0} %fusion.584, f32[8,64,1]{2,1,0} %fusion.587, f32[8,64]{1,0} %log.1, f32[256]{0} %parameter.111, f32[512,256]{1,0} %dot.6), to_apply=%parallel_fusion.583
  %reduce-window.6 = f32[8,64,8]{2,1,0} reduce-window(f32[8,64,256]{2,1,0} %call.196, f32[] %constant.1), window={size=1x1x32 stride=1x1x32}, to_apply=%primitive_computation_add__1.13134
  %reduce.8 = f32[8,64]{1,0} reduce(f32[8,64,8]{2,1,0} %reduce-window.6, f32[] %constant.1), dimensions={2}, to_apply=%primitive_computation_add__1.13134, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(2,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=94}
  %parameter.169 = f32[8,64]{1,0} parameter(87), parameter_replication={false}
  %reduce.13206 = f32[] reduce(f32[8,64]{1,0} %parameter.169, f32[] %constant.1), dimensions={0,1}, to_apply=%primitive_computation_add__1.13202, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0, 1) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/metrics.py" source_line=102}
  %all-reduce.13211 = f32[] all-reduce(f32[] %reduce.13206), replica_groups={{0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15}}, to_apply=%primitive_computation_add__1.13207, metadata={op_type="psum" op_name="pmap(_multi_device_update_fn)/psum[ axes=(\'batch\',)\n                                    axis_index_groups=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=347}
  %fusion.645 = f32[] fusion(f32[] %all-reduce.13211), kind=kLoop, calls=%fused_computation.645, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/metrics.py" source_line=617}
  %call.210 = f32[8,64,256]{2,1,0} call(f32[8,64]{1,0} %parameter.169, f32[] %fusion.645, s32[8,64]{1,0} %parameter.168), to_apply=%parallel_fusion.644
  %reduce-window = f32[8,64,8]{2,1,0} reduce-window(f32[8,64,256]{2,1,0} %call.210, f32[] %constant.1), window={size=1x1x32 stride=1x1x32}, to_apply=%primitive_computation_add__1.13228
  %fusion.582 = f32[8,64]{1,0} fusion(f32[8,64]{1,0} %reduce.8, f32[8,64,8]{2,1,0} %reduce-window), kind=kLoop, calls=%fused_computation.582, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=94}
  %call.195 = f32[8,64,256]{2,1,0} call(f32[8,64,256]{2,1,0} %call.196, f32[8,64]{1,0} %fusion.582, f32[8,64]{1,0} %parameter.169, f32[] %fusion.645, s32[8,64]{1,0} %parameter.168), to_apply=%parallel_fusion.581
  %call.58 = f32[8,64,256]{2,1,0} call(f32[8,64,256]{2,1,0} %call.195), to_apply=%parallel_negate.13245
  %reduce-window.7 = f32[8,64,8]{2,1,0} reduce-window(f32[8,64,256]{2,1,0} %call.58, f32[] %constant.1), window={size=1x1x32 stride=1x1x32}, to_apply=%primitive_computation_add__1.13247
  %fusion.580 = f32[8,64]{1,0} fusion(f32[8,64]{1,0} %reduce.6, f32[8,64,8]{2,1,0} %reduce-window.7), kind=kLoop, calls=%fused_computation.580, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=94}
  %call.194 = f32[8,64,256]{2,1,0} call(f32[8,64,256]{2,1,0} %call.195, f32[8,64,256]{2,1,0} %call.198, f32[8,64]{1,0} %fusion.580), to_apply=%parallel_fusion.579
  %bitcast.11 = f32[512,256]{1,0} bitcast(f32[8,64,256]{2,1,0} %call.194)
  %dot.197 = f32[512,1024]{1,0} dot(f32[512,256]{1,0} %bitcast.11, f32[1024,256]{1,0} %parameter.110), lhs_contracting_dims={1}, rhs_contracting_dims={1}
  %call.193 = f32[64,8,1024]{2,0,1} call(f32[512,1024]{1,0} %dot.197), to_apply=%parallel_fusion.578
  %call.112 = f32[64,8,1024]{2,1,0} call(f32[64,8,1024]{2,0,1} %call.193), to_apply=%parallel_copy.41
  %get-tuple-element.25283 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %while.201), index=6, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.25284 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %while.201), index=7, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.25285 = f32[64,8,2048]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %while.201), index=8, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.25286 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %while.201), index=9, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.25287 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %while.201), index=10, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.25288 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %while.201), index=11, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.25289 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %while.201), index=12, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.25290 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %while.201), index=13, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.25291 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %while.201), index=14, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.25292 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %while.201), index=15, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.25293 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %while.201), index=16, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.25294 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %while.201), index=17, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %copy.809 = s32[] copy(s32[] %constant.1356)
  %call.97 = f32[2048,4096]{1,0} call(f32[] %constant.1), to_apply=%parallel_broadcast.308
  %copy.810 = f32[2048,4096]{1,0} copy(f32[2048,4096]{1,0} %call.97)
  %broadcast.309 = f32[4096]{0} broadcast(f32[] %constant.1), dimensions={}
  %copy.811 = f32[4096]{0} copy(f32[4096]{0} %broadcast.309)
  %copy.812 = f32[8,2048]{1,0} copy(f32[8,2048]{1,0} %broadcast.5905)
  %copy.813 = f32[64,8,1024]{2,1,0} copy(f32[64,8,1024]{2,1,0} %call.56)
  %tuple.1321 = (f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) tuple(f32[64,8,1024]{2,1,0} %call.112, f32[64,8,1024]{2,1,0} %get-tuple-element.25283, f32[64,8,1024]{2,1,0} %get-tuple-element.25284, f32[64,8,2048]{2,1,0} %get-tuple-element.25285, f32[64,8,1024]{2,1,0} %get-tuple-element.25286, /*index=5*/f32[64,8,1024]{2,1,0} %get-tuple-element.25287, f32[64,8,1024]{2,1,0} %get-tuple-element.25288, f32[64,8,1024]{2,1,0} %get-tuple-element.25289, f32[64,8,1024]{2,1,0} %get-tuple-element.25290, f32[64,8,1024]{2,1,0} %get-tuple-element.25291, /*index=10*/f32[64,8,1024]{2,1,0} %get-tuple-element.25292, f32[64,8,1024]{2,1,0} %get-tuple-element.25293, f32[64,8,1024]{2,1,0} %get-tuple-element.25294, f32[2048,4096]{1,0} %parameter.108, s32[] %copy.809, /*index=15*/f32[2048,4096]{1,0} %copy.810, f32[4096]{0} %copy.811, f32[8,2048]{1,0} %copy.812, f32[64,8,1024]{2,1,0} %copy.813)
  %while.202 = (f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) while((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %tuple.1321), condition=%wide.wide.cond_computation__194.13713.clone.clone.clone.clone, body=%wide.wide.body_computation__194.13302.clone.clone.clone.clone
  %get-tuple-element.25437 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %while.202), index=18, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=14\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.25173 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %while.200), index=6, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.25174 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %while.200), index=7, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.25175 = f32[64,8,2048]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %while.200), index=8, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.25176 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %while.200), index=9, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.25177 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %while.200), index=10, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.25178 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %while.200), index=11, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.25179 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %while.200), index=12, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.25180 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %while.200), index=13, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.25181 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %while.200), index=14, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.25182 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %while.200), index=15, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.25183 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %while.200), index=16, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.25184 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %while.200), index=17, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %copy.824 = s32[] copy(s32[] %constant.1356)
  %copy.825 = f32[2048,4096]{1,0} copy(f32[2048,4096]{1,0} %call.97)
  %copy.826 = f32[4096]{0} copy(f32[4096]{0} %broadcast.309)
  %copy.827 = f32[8,2048]{1,0} copy(f32[8,2048]{1,0} %broadcast.5905)
  %copy.828 = f32[64,8,1024]{2,1,0} copy(f32[64,8,1024]{2,1,0} %call.56)
  %tuple.1324 = (f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) tuple(f32[64,8,1024]{2,1,0} %get-tuple-element.25437, f32[64,8,1024]{2,1,0} %get-tuple-element.25173, f32[64,8,1024]{2,1,0} %get-tuple-element.25174, f32[64,8,2048]{2,1,0} %get-tuple-element.25175, f32[64,8,1024]{2,1,0} %get-tuple-element.25176, /*index=5*/f32[64,8,1024]{2,1,0} %get-tuple-element.25177, f32[64,8,1024]{2,1,0} %get-tuple-element.25178, f32[64,8,1024]{2,1,0} %get-tuple-element.25179, f32[64,8,1024]{2,1,0} %get-tuple-element.25180, f32[64,8,1024]{2,1,0} %get-tuple-element.25181, /*index=10*/f32[64,8,1024]{2,1,0} %get-tuple-element.25182, f32[64,8,1024]{2,1,0} %get-tuple-element.25183, f32[64,8,1024]{2,1,0} %get-tuple-element.25184, f32[2048,4096]{1,0} %parameter.106, s32[] %copy.824, /*index=15*/f32[2048,4096]{1,0} %copy.825, f32[4096]{0} %copy.826, f32[8,2048]{1,0} %copy.827, f32[64,8,1024]{2,1,0} %copy.828)
  %while.203 = (f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) while((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %tuple.1324), condition=%wide.wide.cond_computation__195.14225.clone.clone.clone.clone, body=%wide.wide.body_computation__195.13814.clone.clone.clone.clone
  %get-tuple-element.25580 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %while.203), index=18, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=14\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.25063 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %while.199), index=6, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.25064 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %while.199), index=7, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.25065 = f32[64,8,2048]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %while.199), index=8, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.25066 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %while.199), index=9, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.25067 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %while.199), index=10, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.25068 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %while.199), index=11, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.25069 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %while.199), index=12, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.25070 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %while.199), index=13, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.25071 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %while.199), index=14, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.25072 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %while.199), index=15, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.25073 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %while.199), index=16, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.25074 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %while.199), index=17, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %copy.839 = s32[] copy(s32[] %constant.1356)
  %copy.840 = f32[2048,4096]{1,0} copy(f32[2048,4096]{1,0} %call.97)
  %copy.841 = f32[4096]{0} copy(f32[4096]{0} %broadcast.309)
  %copy.842 = f32[8,2048]{1,0} copy(f32[8,2048]{1,0} %broadcast.5905)
  %copy.843 = f32[64,8,1024]{2,1,0} copy(f32[64,8,1024]{2,1,0} %call.56)
  %tuple.1327 = (f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) tuple(f32[64,8,1024]{2,1,0} %get-tuple-element.25580, f32[64,8,1024]{2,1,0} %get-tuple-element.25063, f32[64,8,1024]{2,1,0} %get-tuple-element.25064, f32[64,8,2048]{2,1,0} %get-tuple-element.25065, f32[64,8,1024]{2,1,0} %get-tuple-element.25066, /*index=5*/f32[64,8,1024]{2,1,0} %get-tuple-element.25067, f32[64,8,1024]{2,1,0} %get-tuple-element.25068, f32[64,8,1024]{2,1,0} %get-tuple-element.25069, f32[64,8,1024]{2,1,0} %get-tuple-element.25070, f32[64,8,1024]{2,1,0} %get-tuple-element.25071, /*index=10*/f32[64,8,1024]{2,1,0} %get-tuple-element.25072, f32[64,8,1024]{2,1,0} %get-tuple-element.25073, f32[64,8,1024]{2,1,0} %get-tuple-element.25074, f32[2048,4096]{1,0} %parameter.104, s32[] %copy.839, /*index=15*/f32[2048,4096]{1,0} %copy.840, f32[4096]{0} %copy.841, f32[8,2048]{1,0} %copy.842, f32[64,8,1024]{2,1,0} %copy.843)
  %while.204 = (f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) while((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %tuple.1327), condition=%wide.wide.cond_computation__196.14737.clone.clone.clone.clone, body=%wide.wide.body_computation__196.14326.clone.clone.clone.clone
  %get-tuple-element.25723 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %while.204), index=18, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=14\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.24953 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %while.198), index=6, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.24954 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %while.198), index=7, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.24955 = f32[64,8,2048]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %while.198), index=8, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.24956 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %while.198), index=9, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.24957 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %while.198), index=10, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.24958 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %while.198), index=11, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.24959 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %while.198), index=12, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.24960 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %while.198), index=13, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.24961 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %while.198), index=14, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.24962 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %while.198), index=15, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.24963 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %while.198), index=16, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.24964 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %while.198), index=17, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %copy.854 = s32[] copy(s32[] %constant.1356)
  %copy.855 = f32[2048,4096]{1,0} copy(f32[2048,4096]{1,0} %call.97)
  %copy.856 = f32[4096]{0} copy(f32[4096]{0} %broadcast.309)
  %copy.857 = f32[8,2048]{1,0} copy(f32[8,2048]{1,0} %broadcast.5905)
  %copy.858 = f32[64,8,1024]{2,1,0} copy(f32[64,8,1024]{2,1,0} %call.56)
  %tuple.1330 = (f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) tuple(f32[64,8,1024]{2,1,0} %get-tuple-element.25723, f32[64,8,1024]{2,1,0} %get-tuple-element.24953, f32[64,8,1024]{2,1,0} %get-tuple-element.24954, f32[64,8,2048]{2,1,0} %get-tuple-element.24955, f32[64,8,1024]{2,1,0} %get-tuple-element.24956, /*index=5*/f32[64,8,1024]{2,1,0} %get-tuple-element.24957, f32[64,8,1024]{2,1,0} %get-tuple-element.24958, f32[64,8,1024]{2,1,0} %get-tuple-element.24959, f32[64,8,1024]{2,1,0} %get-tuple-element.24960, f32[64,8,1024]{2,1,0} %get-tuple-element.24961, /*index=10*/f32[64,8,1024]{2,1,0} %get-tuple-element.24962, f32[64,8,1024]{2,1,0} %get-tuple-element.24963, f32[64,8,1024]{2,1,0} %get-tuple-element.24964, f32[2048,4096]{1,0} %parameter.102, s32[] %copy.854, /*index=15*/f32[2048,4096]{1,0} %copy.855, f32[4096]{0} %copy.856, f32[8,2048]{1,0} %copy.857, f32[64,8,1024]{2,1,0} %copy.858)
  %while.205 = (f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) while((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %tuple.1330), condition=%wide.wide.cond_computation__197.15249.clone.clone.clone.clone, body=%wide.wide.body_computation__197.14838.clone.clone.clone.clone
  %get-tuple-element.25866 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %while.205), index=18, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=14\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %call.192 = f32[512,1024]{1,0} call(f32[64,8,1024]{2,1,0} %get-tuple-element.25866), to_apply=%parallel_fusion.577
  %dot.198 = f32[512,1024]{1,0} dot(f32[512,1024]{1,0} %call.192, f32[1024,1024]{1,0} %parameter.100), lhs_contracting_dims={1}, rhs_contracting_dims={1}
  %call.191 = f32[8,1024,64]{2,1,0} call(f32[512,1024]{1,0} %dot.198), to_apply=%parallel_fusion.576
  %dot.11 = f32[8,1024,64]{2,1,0} dot(f32[8,1024,64]{2,1,0} %call.191, f32[8,64,64]{2,1,0} %fusion.592), lhs_batch_dims={0}, lhs_contracting_dims={2}, rhs_batch_dims={0}, rhs_contracting_dims={1}
  %call.190 = f32[512,1024]{1,0} call(f32[8,1024,64]{2,1,0} %dot.11), to_apply=%parallel_fusion.575
  %dot.199 = f32[512,1024]{1,0} dot(f32[512,1024]{1,0} %call.190, f32[1024,1024]{1,0} %parameter.98), lhs_contracting_dims={1}, rhs_contracting_dims={1}
  %bitcast.12 = f32[8,64,1024]{2,1,0} bitcast(f32[512,1024]{1,0} %dot.198)
  %call.189 = f32[8,1024,64]{2,1,0} call(f32[1024]{0} %parameter.99, f32[512,1024]{1,0} %dot.2), to_apply=%parallel_fusion.574
  %dot.14 = f32[8,64,64]{2,1,0} dot(f32[8,64,1024]{2,1,0} %bitcast.12, f32[8,1024,64]{2,1,0} %call.189), lhs_batch_dims={0}, lhs_contracting_dims={2}, rhs_batch_dims={0}, rhs_contracting_dims={1}, metadata={op_type="dot_general" op_name="pmap(_multi_device_update_fn)/dot_general[ dimension_numbers=(((2, 3), (1, 3)), ((0,), (0,)))\n                                           precision=None\n                                           preferred_element_type=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/attention.py" source_line=293}
  %fusion.573 = f32[8,1,64,64]{3,2,1,0} fusion(f32[8,1,64,64]{3,2,1,0} %fusion.593, f32[8,64,64]{2,1,0} %dot.14, u32[32768]{0} %concatenate.93), kind=kLoop, calls=%fused_computation.573, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/attention.py" source_line=287}
  %negate.15387 = f32[8,1,64,64]{3,2,1,0} negate(f32[8,1,64,64]{3,2,1,0} %fusion.573), metadata={op_type="neg" op_name="pmap(_multi_device_update_fn)/neg" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/attention.py" source_line=287}
  %reduce-window.8 = f32[8,1,64,2]{3,2,1,0} reduce-window(f32[8,1,64,64]{3,2,1,0} %negate.15387, f32[] %constant.1), window={size=1x1x1x32 stride=1x1x1x32}, to_apply=%primitive_computation_add__1.15389
  %fusion.572 = f32[8,1,64]{2,1,0} fusion(f32[8,1,64]{2,1,0} %reduce.4, f32[8,1,64,2]{3,2,1,0} %reduce-window.8), kind=kLoop, calls=%fused_computation.572, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=94}
  %fusion.571 = f32[8,64,64]{2,1,0} fusion(f32[8,1,64,64]{3,2,1,0} %fusion.573, f32[8,1,64,64]{3,2,1,0} %fusion.594, f32[8,1,64]{2,1,0} %fusion.572, s32[8,64]{1,0} %parameter.167), kind=kLoop, calls=%fused_computation.571
  %dot.15 = f32[8,64,1024]{2,1,0} dot(f32[8,64,64]{2,1,0} %fusion.571, f32[8,64,1024]{2,1,0} %call.207), lhs_batch_dims={0}, lhs_contracting_dims={2}, rhs_batch_dims={0}, rhs_contracting_dims={1}, metadata={op_type="reshape" op_name="pmap(_multi_device_update_fn)/reshape[ dimensions=None\n                                       new_sizes=(8, 64, 1024) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/attention.py" source_line=359}
  %bitcast.13 = f32[512,1024]{1,0} bitcast(f32[8,64,1024]{2,1,0} %dot.15)
  %dot.200 = f32[512,1024]{1,0} dot(f32[512,1024]{1,0} %bitcast.13, f32[1024,1024]{1,0} %parameter.96), lhs_contracting_dims={1}, rhs_contracting_dims={1}
  %call.188 = f32[64,8,1024]{2,0,1} call(f32[512,1024]{1,0} %dot.199, f32[512,1024]{1,0} %dot.200), to_apply=%parallel_fusion.570
  %call.113 = f32[64,8,1024]{2,1,0} call(f32[64,8,1024]{2,0,1} %call.188), to_apply=%parallel_copy.46
  %get-tuple-element.24733 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %while.196), index=6, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.24734 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %while.196), index=7, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.24735 = f32[64,8,2048]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %while.196), index=8, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.24736 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %while.196), index=9, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.24737 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %while.196), index=10, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.24738 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %while.196), index=11, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.24739 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %while.196), index=12, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.24740 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %while.196), index=13, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.24741 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %while.196), index=14, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.24742 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %while.196), index=15, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.24743 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %while.196), index=16, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.24744 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %while.196), index=17, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %copy.869 = s32[] copy(s32[] %constant.1356)
  %copy.870 = f32[2048,4096]{1,0} copy(f32[2048,4096]{1,0} %call.97)
  %copy.871 = f32[4096]{0} copy(f32[4096]{0} %broadcast.309)
  %copy.872 = f32[8,2048]{1,0} copy(f32[8,2048]{1,0} %broadcast.5905)
  %copy.873 = f32[64,8,1024]{2,1,0} copy(f32[64,8,1024]{2,1,0} %call.56)
  %tuple.1333 = (f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) tuple(f32[64,8,1024]{2,1,0} %call.113, f32[64,8,1024]{2,1,0} %get-tuple-element.24733, f32[64,8,1024]{2,1,0} %get-tuple-element.24734, f32[64,8,2048]{2,1,0} %get-tuple-element.24735, f32[64,8,1024]{2,1,0} %get-tuple-element.24736, /*index=5*/f32[64,8,1024]{2,1,0} %get-tuple-element.24737, f32[64,8,1024]{2,1,0} %get-tuple-element.24738, f32[64,8,1024]{2,1,0} %get-tuple-element.24739, f32[64,8,1024]{2,1,0} %get-tuple-element.24740, f32[64,8,1024]{2,1,0} %get-tuple-element.24741, /*index=10*/f32[64,8,1024]{2,1,0} %get-tuple-element.24742, f32[64,8,1024]{2,1,0} %get-tuple-element.24743, f32[64,8,1024]{2,1,0} %get-tuple-element.24744, f32[2048,4096]{1,0} %parameter.89, s32[] %copy.869, /*index=15*/f32[2048,4096]{1,0} %copy.870, f32[4096]{0} %copy.871, f32[8,2048]{1,0} %copy.872, f32[64,8,1024]{2,1,0} %copy.873)
  %while.206 = (f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) while((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %tuple.1333), condition=%wide.wide.cond_computation__198.15875.clone.clone.clone.clone, body=%wide.wide.body_computation__198.15464.clone.clone.clone.clone
  %get-tuple-element.26009 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %while.206), index=18, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=14\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.24623 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %while.195), index=6, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.24624 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %while.195), index=7, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.24625 = f32[64,8,2048]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %while.195), index=8, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.24626 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %while.195), index=9, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.24627 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %while.195), index=10, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.24628 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %while.195), index=11, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.24629 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %while.195), index=12, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.24630 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %while.195), index=13, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.24631 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %while.195), index=14, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.24632 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %while.195), index=15, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.24633 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %while.195), index=16, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.24634 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %while.195), index=17, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %copy.884 = s32[] copy(s32[] %constant.1356)
  %copy.885 = f32[2048,4096]{1,0} copy(f32[2048,4096]{1,0} %call.97)
  %copy.886 = f32[4096]{0} copy(f32[4096]{0} %broadcast.309)
  %copy.887 = f32[8,2048]{1,0} copy(f32[8,2048]{1,0} %broadcast.5905)
  %copy.888 = f32[64,8,1024]{2,1,0} copy(f32[64,8,1024]{2,1,0} %call.56)
  %tuple.1336 = (f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) tuple(f32[64,8,1024]{2,1,0} %get-tuple-element.26009, f32[64,8,1024]{2,1,0} %get-tuple-element.24623, f32[64,8,1024]{2,1,0} %get-tuple-element.24624, f32[64,8,2048]{2,1,0} %get-tuple-element.24625, f32[64,8,1024]{2,1,0} %get-tuple-element.24626, /*index=5*/f32[64,8,1024]{2,1,0} %get-tuple-element.24627, f32[64,8,1024]{2,1,0} %get-tuple-element.24628, f32[64,8,1024]{2,1,0} %get-tuple-element.24629, f32[64,8,1024]{2,1,0} %get-tuple-element.24630, f32[64,8,1024]{2,1,0} %get-tuple-element.24631, /*index=10*/f32[64,8,1024]{2,1,0} %get-tuple-element.24632, f32[64,8,1024]{2,1,0} %get-tuple-element.24633, f32[64,8,1024]{2,1,0} %get-tuple-element.24634, f32[2048,4096]{1,0} %parameter.87, s32[] %copy.884, /*index=15*/f32[2048,4096]{1,0} %copy.885, f32[4096]{0} %copy.886, f32[8,2048]{1,0} %copy.887, f32[64,8,1024]{2,1,0} %copy.888)
  %while.207 = (f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) while((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %tuple.1336), condition=%wide.wide.cond_computation__199.16387.clone.clone.clone.clone, body=%wide.wide.body_computation__199.15976.clone.clone.clone.clone
  %get-tuple-element.26152 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %while.207), index=18, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=14\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.24513 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %while.194), index=6, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.24514 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %while.194), index=7, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.24515 = f32[64,8,2048]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %while.194), index=8, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.24516 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %while.194), index=9, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.24517 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %while.194), index=10, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.24518 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %while.194), index=11, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.24519 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %while.194), index=12, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.24520 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %while.194), index=13, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.24521 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %while.194), index=14, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.24522 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %while.194), index=15, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.24523 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %while.194), index=16, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.24524 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %while.194), index=17, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %copy.899 = s32[] copy(s32[] %constant.1356)
  %copy.900 = f32[2048,4096]{1,0} copy(f32[2048,4096]{1,0} %call.97)
  %copy.901 = f32[4096]{0} copy(f32[4096]{0} %broadcast.309)
  %copy.902 = f32[8,2048]{1,0} copy(f32[8,2048]{1,0} %broadcast.5905)
  %copy.903 = f32[64,8,1024]{2,1,0} copy(f32[64,8,1024]{2,1,0} %call.56)
  %tuple.1339 = (f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) tuple(f32[64,8,1024]{2,1,0} %get-tuple-element.26152, f32[64,8,1024]{2,1,0} %get-tuple-element.24513, f32[64,8,1024]{2,1,0} %get-tuple-element.24514, f32[64,8,2048]{2,1,0} %get-tuple-element.24515, f32[64,8,1024]{2,1,0} %get-tuple-element.24516, /*index=5*/f32[64,8,1024]{2,1,0} %get-tuple-element.24517, f32[64,8,1024]{2,1,0} %get-tuple-element.24518, f32[64,8,1024]{2,1,0} %get-tuple-element.24519, f32[64,8,1024]{2,1,0} %get-tuple-element.24520, f32[64,8,1024]{2,1,0} %get-tuple-element.24521, /*index=10*/f32[64,8,1024]{2,1,0} %get-tuple-element.24522, f32[64,8,1024]{2,1,0} %get-tuple-element.24523, f32[64,8,1024]{2,1,0} %get-tuple-element.24524, f32[2048,4096]{1,0} %parameter.85, s32[] %copy.899, /*index=15*/f32[2048,4096]{1,0} %copy.900, f32[4096]{0} %copy.901, f32[8,2048]{1,0} %copy.902, f32[64,8,1024]{2,1,0} %copy.903)
  %while.208 = (f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) while((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %tuple.1339), condition=%wide.wide.cond_computation__200.16899.clone.clone.clone.clone, body=%wide.wide.body_computation__200.16488.clone.clone.clone.clone
  %get-tuple-element.26295 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %while.208), index=18, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=14\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.24403 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %while.193), index=6, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.24404 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %while.193), index=7, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.24405 = f32[64,8,2048]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %while.193), index=8, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.24406 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %while.193), index=9, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.24407 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %while.193), index=10, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.24408 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %while.193), index=11, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.24409 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %while.193), index=12, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.24410 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %while.193), index=13, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.24411 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %while.193), index=14, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.24412 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %while.193), index=15, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.24413 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %while.193), index=16, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.24414 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %while.193), index=17, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %copy.914 = s32[] copy(s32[] %constant.1356)
  %copy.915 = f32[2048,4096]{1,0} copy(f32[2048,4096]{1,0} %call.97)
  %copy.916 = f32[4096]{0} copy(f32[4096]{0} %broadcast.309)
  %copy.917 = f32[8,2048]{1,0} copy(f32[8,2048]{1,0} %broadcast.5905)
  %copy.918 = f32[64,8,1024]{2,1,0} copy(f32[64,8,1024]{2,1,0} %call.56)
  %tuple.1342 = (f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) tuple(f32[64,8,1024]{2,1,0} %get-tuple-element.26295, f32[64,8,1024]{2,1,0} %get-tuple-element.24403, f32[64,8,1024]{2,1,0} %get-tuple-element.24404, f32[64,8,2048]{2,1,0} %get-tuple-element.24405, f32[64,8,1024]{2,1,0} %get-tuple-element.24406, /*index=5*/f32[64,8,1024]{2,1,0} %get-tuple-element.24407, f32[64,8,1024]{2,1,0} %get-tuple-element.24408, f32[64,8,1024]{2,1,0} %get-tuple-element.24409, f32[64,8,1024]{2,1,0} %get-tuple-element.24410, f32[64,8,1024]{2,1,0} %get-tuple-element.24411, /*index=10*/f32[64,8,1024]{2,1,0} %get-tuple-element.24412, f32[64,8,1024]{2,1,0} %get-tuple-element.24413, f32[64,8,1024]{2,1,0} %get-tuple-element.24414, f32[2048,4096]{1,0} %parameter.83, s32[] %copy.914, /*index=15*/f32[2048,4096]{1,0} %copy.915, f32[4096]{0} %copy.916, f32[8,2048]{1,0} %copy.917, f32[64,8,1024]{2,1,0} %copy.918)
  %while.209 = (f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) while((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %tuple.1342), condition=%wide.wide.cond_computation__201.17411.clone.clone.clone.clone, body=%wide.wide.body_computation__201.17000.clone.clone.clone.clone
  %get-tuple-element.26438 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %while.209), index=18, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=14\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %call.187 = f32[512,1024]{1,0} call(f32[64,8,1024]{2,1,0} %get-tuple-element.26438), to_apply=%parallel_fusion.569
  %tuple.1345 = (s32[], f32[32000,1024]{1,0}, s32[512]{0}, f32[512,1024]{1,0}) tuple(s32[] %copy.929, f32[32000,1024]{1,0} %call.59, s32[512]{0} %bitcast, f32[512,1024]{1,0} %call.187)
  %while.92 = (s32[], f32[32000,1024]{1,0}, s32[512]{0}, f32[512,1024]{1,0}) while((s32[], f32[32000,1024]{1,0}, s32[512]{0}, f32[512,1024]{1,0}) %tuple.1345), condition=%while_cond, body=%while_body, metadata={op_type="scatter-add" op_name="pmap(_multi_device_update_fn)/scatter-add[ dimension_numbers=ScatterDimensionNumbers(update_window_dims=(2,), inserted_window_dims=(0,), scatter_dims_to_operand_dims=(0,))\n                                           indices_are_sorted=False\n                                           unique_indices=False\n                                           update_consts=(  ) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/core.py" source_line=182}
  %get-tuple-element.3535 = f32[32000,1024]{1,0} get-tuple-element((s32[], f32[32000,1024]{1,0}, s32[512]{0}, f32[512,1024]{1,0}) %while.92), index=1, metadata={op_type="scatter-add" op_name="pmap(_multi_device_update_fn)/scatter-add[ dimension_numbers=ScatterDimensionNumbers(update_window_dims=(2,), inserted_window_dims=(0,), scatter_dims_to_operand_dims=(0,))\n                                           indices_are_sorted=False\n                                           unique_indices=False\n                                           update_consts=(  ) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/core.py" source_line=182}
  %all-reduce.18043 = f32[32000,1024]{1,0} all-reduce(f32[32000,1024]{1,0} %get-tuple-element.3535), replica_groups={{0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15}}, to_apply=%primitive_computation_add__1.18039, metadata={op_type="psum" op_name="pmap(_multi_device_update_fn)/psum[ axes=(\'batch\',)\n                                    axis_index_groups=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=347}
  %call.186 = f32[32000,1024]{1,0} call(f32[32000,1024]{1,0} %all-reduce.18043), to_apply=%parallel_fusion.567
  %call.78 = f32[1000,1024]{1,0} call(f32[32000,1024]{1,0} %call.186, f32[] %constant.1), to_apply=%parallel_reduce-window.12
  %reduce-window.121 = f32[32,1024]{1,0} reduce-window(f32[1000,1024]{1,0} %call.78, f32[] %constant.1), window={size=32x1 stride=32x1 pad=12_12x0_0}, to_apply=%primitive_computation_add__1.18560
  %reduce-window.218 = f32[1,1024]{1,0} reduce-window(f32[32,1024]{1,0} %reduce-window.121, f32[] %constant.1), window={size=32x1 stride=32x1}, to_apply=%primitive_computation_add__1.18560
  %parameter.113 = f32[1024]{0} parameter(31), parameter_replication={false}
  %parameter.161 = f32[] parameter(79), parameter_replication={false}
  %parameter.158 = s32[] parameter(76), parameter_replication={false}, metadata={op_type="convert_element_type" op_name="pmap(_multi_device_update_fn)/convert_element_type[ new_dtype=int32\n                                                    weak_type=False ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=115}
  %fusion.568 = f32[] fusion(f32[] %parameter.161, s32[] %parameter.158), kind=kLoop, calls=%fused_computation.568, metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=85}
  %fusion.564 = f32[1024]{0} fusion(f32[1,1024]{1,0} %reduce-window.218, f32[1024]{0} %parameter.113, f32[] %fusion.568), kind=kLoop, calls=%fused_computation.564, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
  %parameter.162 = f32[] parameter(80), parameter_replication={false}
  %fusion.563 = f32[1024]{0} fusion(f32[1024]{0} %fusion.564, f32[] %parameter.162), kind=kLoop, calls=%fused_computation.563, metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
  %call.77 = f32[32000,32]{1,0} call(f32[32000,1024]{1,0} %call.186, f32[] %constant.1), to_apply=%parallel_reduce-window.10
  %reduce-window.119 = f32[32000,1]{1,0} reduce-window(f32[32000,32]{1,0} %call.77, f32[] %constant.1), window={size=1x32 stride=1x32}, to_apply=%primitive_computation_add__1.18546
  %parameter.112 = f32[32000]{0} parameter(30), parameter_replication={false}
  %fusion.566 = f32[32000]{0} fusion(f32[32000,1]{1,0} %reduce-window.119, f32[32000]{0} %parameter.112, f32[] %fusion.568), kind=kLoop, calls=%fused_computation.566, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=131}
  %reduce-window.11 = f32[1000]{0} reduce-window(f32[32000]{0} %fusion.566, f32[] %constant.1), window={size=32 stride=32}, to_apply=%primitive_computation_add__1.18572
  %reduce-window.120 = f32[32]{0} reduce-window(f32[1000]{0} %reduce-window.11, f32[] %constant.1), window={size=32 stride=32 pad=12_12}, to_apply=%primitive_computation_add__1.18572
  %reduce-window.217 = f32[1]{0} reduce-window(f32[32]{0} %reduce-window.120, f32[] %constant.1), window={size=32 stride=32}, to_apply=%primitive_computation_add__1.18572
  %fusion.565 = f32[32000]{0} fusion(f32[32000]{0} %fusion.566, f32[] %parameter.162, f32[1]{0} %reduce-window.217), kind=kLoop, calls=%fused_computation.565, metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  %call.185 = f32[32000,1024]{1,0} call(f32[1024]{0} %fusion.563, f32[32000,1024]{1,0} %all-reduce.18043, f32[32000]{0} %fusion.565), to_apply=%parallel_fusion.562
  %reduce-window.13 = f32[1000,32]{1,0} reduce-window(f32[32000,1024]{1,0} %call.185, f32[] %constant.1), window={size=32x32 stride=32x32}, to_apply=%primitive_computation_add__1.18604
  %reduce-window.122 = f32[32,1]{1,0} reduce-window(f32[1000,32]{1,0} %reduce-window.13, f32[] %constant.1), window={size=32x32 stride=32x32 pad=12_12x0_0}, to_apply=%primitive_computation_add__1.18604
  %fusion.561 = f32[] fusion(f32[] %parameter.160, f32[32,1]{1,0} %reduce-window.122), kind=kLoop, calls=%fused_computation.561, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %parameter.164 = f32[] parameter(82), parameter_replication={false}
  %call.61 = f32[32000,1024]{1,0} call(f32[32000,1024]{1,0} %parameter.82), to_apply=%parallel_multiply.18528
  %reduce-window.9 = f32[1000,32]{1,0} reduce-window(f32[32000,1024]{1,0} %call.61, f32[] %constant.1), window={size=32x32 stride=32x32}, to_apply=%primitive_computation_add__1.18530
  %reduce-window.118 = f32[32,1]{1,0} reduce-window(f32[1000,32]{1,0} %reduce-window.9, f32[] %constant.1), window={size=32x32 stride=32x32 pad=12_12x0_0}, to_apply=%primitive_computation_add__1.18530
  %fusion.646 = f32[] fusion(f32[32,1]{1,0} %reduce-window.118), kind=kLoop, calls=%fused_computation.646, metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %parameter.163 = f32[] parameter(81), parameter_replication={false}
  %parameter.166 = f32[] parameter(84), parameter_replication={false}
  %parameter.165 = s32[] parameter(83), parameter_replication={false}
  %fusion.647 = f32[] fusion(s32[] %parameter.165, f32[] %parameter.166, s32[] %parameter.158), kind=kLoop, calls=%fused_computation.647, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=115}
  %call.184 = f32[32000,1024]{1,0} call(f32[] %fusion.561, f32[1024]{0} %fusion.563, f32[32000,1024]{1,0} %all-reduce.18043, f32[32000]{0} %fusion.565, f32[] %parameter.164, /*index=5*/f32[] %fusion.646, f32[] %parameter.163, f32[32000,1024]{1,0} %parameter.82, f32[] %parameter.166, f32[] %fusion.647, /*index=10*/s32[] %parameter.165), to_apply=%parallel_fusion.560
  %get-tuple-element.26435 = f32[2048,4096]{1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %while.209), index=15, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=14\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %all-reduce.18048 = f32[2048,4096]{1,0} all-reduce(f32[2048,4096]{1,0} %get-tuple-element.26435), replica_groups={{0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15}}, to_apply=%primitive_computation_add__1.18044, metadata={op_type="psum" op_name="pmap(_multi_device_update_fn)/psum[ axes=(\'batch\',)\n                                    axis_index_groups=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=347}
  %call.183 = f32[2048,4096]{1,0} call(f32[2048,4096]{1,0} %all-reduce.18048), to_apply=%parallel_fusion.558
  %call.80 = f32[64,4096]{1,0} call(f32[2048,4096]{1,0} %call.183, f32[] %constant.1), to_apply=%parallel_reduce-window.17
  %reduce-window.126 = f32[2,4096]{1,0} reduce-window(f32[64,4096]{1,0} %call.80, f32[] %constant.1), window={size=32x1 stride=32x1}, to_apply=%primitive_computation_add__1.18686
  %reduce.149 = f32[4096]{0} reduce(f32[2,4096]{1,0} %reduce-window.126, f32[] %constant.1), dimensions={0}, to_apply=%primitive_computation_add__1.18686, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
  %parameter.115 = f32[4096]{0} parameter(33), parameter_replication={false}
  %fusion.555 = f32[4096]{0} fusion(f32[4096]{0} %reduce.149, f32[4096]{0} %parameter.115, f32[] %fusion.568), kind=kLoop, calls=%fused_computation.555, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
  %fusion.554 = f32[4096]{0} fusion(f32[4096]{0} %fusion.555, f32[] %parameter.162), kind=kLoop, calls=%fused_computation.554, metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
  %call.79 = f32[2048,128]{1,0} call(f32[2048,4096]{1,0} %call.183, f32[] %constant.1), to_apply=%parallel_reduce-window.15
  %reduce-window.124 = f32[2048,4]{1,0} reduce-window(f32[2048,128]{1,0} %call.79, f32[] %constant.1), window={size=1x32 stride=1x32}, to_apply=%primitive_computation_add__1.18672
  %parameter.114 = f32[2048]{0} parameter(32), parameter_replication={false}
  %fusion.557 = f32[2048]{0} fusion(f32[2048,4]{1,0} %reduce-window.124, f32[2048]{0} %parameter.114, f32[] %fusion.568), kind=kLoop, calls=%fused_computation.557, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=131}
  %reduce-window.16 = f32[64]{0} reduce-window(f32[2048]{0} %fusion.557, f32[] %constant.1), window={size=32 stride=32}, to_apply=%primitive_computation_add__1.18698
  %reduce-window.125 = f32[2]{0} reduce-window(f32[64]{0} %reduce-window.16, f32[] %constant.1), window={size=32 stride=32}, to_apply=%primitive_computation_add__1.18698
  %reduce.148 = f32[] reduce(f32[2]{0} %reduce-window.125, f32[] %constant.1), dimensions={0}, to_apply=%primitive_computation_add__1.18698, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=135}
  %fusion.556 = f32[2048]{0} fusion(f32[2048]{0} %fusion.557, f32[] %parameter.162, f32[] %reduce.148), kind=kLoop, calls=%fused_computation.556, metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  %call.182 = f32[2048,4096]{1,0} call(f32[4096]{0} %fusion.554, f32[2048,4096]{1,0} %all-reduce.18048, f32[2048]{0} %fusion.556), to_apply=%parallel_fusion.553
  %reduce-window.18 = f32[64,128]{1,0} reduce-window(f32[2048,4096]{1,0} %call.182, f32[] %constant.1), window={size=32x32 stride=32x32}, to_apply=%primitive_computation_add__1.18730
  %reduce-window.127 = f32[2,4]{1,0} reduce-window(f32[64,128]{1,0} %reduce-window.18, f32[] %constant.1), window={size=32x32 stride=32x32}, to_apply=%primitive_computation_add__1.18730
  %fusion.552 = f32[] fusion(f32[] %parameter.160, f32[2,4]{1,0} %reduce-window.127), kind=kLoop, calls=%fused_computation.552, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %call.62 = f32[2048,4096]{1,0} call(f32[2048,4096]{1,0} %parameter.83), to_apply=%parallel_multiply.18654
  %reduce-window.14 = f32[64,128]{1,0} reduce-window(f32[2048,4096]{1,0} %call.62, f32[] %constant.1), window={size=32x32 stride=32x32}, to_apply=%primitive_computation_add__1.18656
  %reduce-window.123 = f32[2,4]{1,0} reduce-window(f32[64,128]{1,0} %reduce-window.14, f32[] %constant.1), window={size=32x32 stride=32x32}, to_apply=%primitive_computation_add__1.18656
  %fusion.559 = f32[] fusion(f32[2,4]{1,0} %reduce-window.123), kind=kLoop, calls=%fused_computation.559, metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %call.181 = f32[2048,4096]{1,0} call(f32[] %fusion.552, f32[4096]{0} %fusion.554, f32[2048,4096]{1,0} %all-reduce.18048, f32[2048]{0} %fusion.556, f32[] %parameter.164, /*index=5*/f32[] %fusion.559, f32[] %parameter.163, f32[2048,4096]{1,0} %parameter.83, f32[] %parameter.166, f32[] %fusion.647, /*index=10*/s32[] %parameter.165), to_apply=%parallel_fusion.551
  %parameter.116 = f32[4096]{0} parameter(34), parameter_replication={false}
  %get-tuple-element.26436 = f32[4096]{0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %while.209), index=16, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=14\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %all-reduce.18053 = f32[4096]{0} all-reduce(f32[4096]{0} %get-tuple-element.26436), replica_groups={{0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15}}, to_apply=%primitive_computation_add__1.18049, metadata={op_type="psum" op_name="pmap(_multi_device_update_fn)/psum[ axes=(\'batch\',)\n                                    axis_index_groups=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=347}
  %fusion.548 = f32[4096]{0} fusion(f32[4096]{0} %parameter.116, f32[4096]{0} %all-reduce.18053, f32[] %fusion.568), kind=kLoop, calls=%fused_computation.548, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=143}
  %fusion.547 = f32[4096]{0} fusion(f32[4096]{0} %fusion.548, f32[4096]{0} %all-reduce.18053, f32[] %parameter.162), kind=kLoop, calls=%fused_computation.547, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=145}
  %multiply.18806 = f32[4096]{0} multiply(f32[4096]{0} %fusion.547, f32[4096]{0} %fusion.547), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %reduce-window.20 = f32[128]{0} reduce-window(f32[4096]{0} %multiply.18806, f32[] %constant.1), window={size=32 stride=32}, to_apply=%primitive_computation_add__1.18808
  %reduce-window.129 = f32[4]{0} reduce-window(f32[128]{0} %reduce-window.20, f32[] %constant.1), window={size=32 stride=32}, to_apply=%primitive_computation_add__1.18808
  %fusion.546 = f32[] fusion(f32[] %parameter.160, f32[4]{0} %reduce-window.129), kind=kLoop, calls=%fused_computation.546, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %multiply.18780 = f32[4096]{0} multiply(f32[4096]{0} %parameter.84, f32[4096]{0} %parameter.84), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %reduce-window.19 = f32[128]{0} reduce-window(f32[4096]{0} %multiply.18780, f32[] %constant.1), window={size=32 stride=32}, to_apply=%primitive_computation_add__1.18782
  %reduce-window.128 = f32[4]{0} reduce-window(f32[128]{0} %reduce-window.19, f32[] %constant.1), window={size=32 stride=32}, to_apply=%primitive_computation_add__1.18782
  %fusion.550 = f32[] fusion(f32[4]{0} %reduce-window.128), kind=kLoop, calls=%fused_computation.550, metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %fusion.545 = f32[4096]{0} fusion(f32[4096]{0} %fusion.547, f32[] %fusion.546, f32[] %parameter.164, f32[] %fusion.550, f32[] %parameter.163, /*index=5*/f32[4096]{0} %parameter.84, f32[] %parameter.166, f32[] %fusion.647, s32[] %parameter.165), kind=kLoop, calls=%fused_computation.545, metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  %get-tuple-element.26292 = f32[2048,4096]{1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %while.208), index=15, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=14\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %all-reduce.18058 = f32[2048,4096]{1,0} all-reduce(f32[2048,4096]{1,0} %get-tuple-element.26292), replica_groups={{0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15}}, to_apply=%primitive_computation_add__1.18054, metadata={op_type="psum" op_name="pmap(_multi_device_update_fn)/psum[ axes=(\'batch\',)\n                                    axis_index_groups=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=347}
  %call.180 = f32[2048,4096]{1,0} call(f32[2048,4096]{1,0} %all-reduce.18058), to_apply=%parallel_fusion.543
  %call.82 = f32[64,4096]{1,0} call(f32[2048,4096]{1,0} %call.180, f32[] %constant.1), to_apply=%parallel_reduce-window.24
  %reduce-window.133 = f32[2,4096]{1,0} reduce-window(f32[64,4096]{1,0} %call.82, f32[] %constant.1), window={size=32x1 stride=32x1}, to_apply=%primitive_computation_add__1.18890
  %reduce.156 = f32[4096]{0} reduce(f32[2,4096]{1,0} %reduce-window.133, f32[] %constant.1), dimensions={0}, to_apply=%primitive_computation_add__1.18890, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
  %parameter.118 = f32[4096]{0} parameter(36), parameter_replication={false}
  %fusion.540 = f32[4096]{0} fusion(f32[4096]{0} %reduce.156, f32[4096]{0} %parameter.118, f32[] %fusion.568), kind=kLoop, calls=%fused_computation.540, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
  %fusion.539 = f32[4096]{0} fusion(f32[4096]{0} %fusion.540, f32[] %parameter.162), kind=kLoop, calls=%fused_computation.539, metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
  %call.81 = f32[2048,128]{1,0} call(f32[2048,4096]{1,0} %call.180, f32[] %constant.1), to_apply=%parallel_reduce-window.22
  %reduce-window.131 = f32[2048,4]{1,0} reduce-window(f32[2048,128]{1,0} %call.81, f32[] %constant.1), window={size=1x32 stride=1x32}, to_apply=%primitive_computation_add__1.18876
  %parameter.117 = f32[2048]{0} parameter(35), parameter_replication={false}
  %fusion.542 = f32[2048]{0} fusion(f32[2048,4]{1,0} %reduce-window.131, f32[2048]{0} %parameter.117, f32[] %fusion.568), kind=kLoop, calls=%fused_computation.542, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=131}
  %reduce-window.23 = f32[64]{0} reduce-window(f32[2048]{0} %fusion.542, f32[] %constant.1), window={size=32 stride=32}, to_apply=%primitive_computation_add__1.18902
  %reduce-window.132 = f32[2]{0} reduce-window(f32[64]{0} %reduce-window.23, f32[] %constant.1), window={size=32 stride=32}, to_apply=%primitive_computation_add__1.18902
  %reduce.155 = f32[] reduce(f32[2]{0} %reduce-window.132, f32[] %constant.1), dimensions={0}, to_apply=%primitive_computation_add__1.18902, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=135}
  %fusion.541 = f32[2048]{0} fusion(f32[2048]{0} %fusion.542, f32[] %reduce.155, f32[] %parameter.162), kind=kLoop, calls=%fused_computation.541, metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  %call.179 = f32[2048,4096]{1,0} call(f32[4096]{0} %fusion.539, f32[2048,4096]{1,0} %all-reduce.18058, f32[2048]{0} %fusion.541), to_apply=%parallel_fusion.538
  %reduce-window.25 = f32[64,128]{1,0} reduce-window(f32[2048,4096]{1,0} %call.179, f32[] %constant.1), window={size=32x32 stride=32x32}, to_apply=%primitive_computation_add__1.18934
  %reduce-window.134 = f32[2,4]{1,0} reduce-window(f32[64,128]{1,0} %reduce-window.25, f32[] %constant.1), window={size=32x32 stride=32x32}, to_apply=%primitive_computation_add__1.18934
  %fusion.537 = f32[] fusion(f32[] %parameter.160, f32[2,4]{1,0} %reduce-window.134), kind=kLoop, calls=%fused_computation.537, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %call.63 = f32[2048,4096]{1,0} call(f32[2048,4096]{1,0} %parameter.85), to_apply=%parallel_multiply.18858
  %reduce-window.21 = f32[64,128]{1,0} reduce-window(f32[2048,4096]{1,0} %call.63, f32[] %constant.1), window={size=32x32 stride=32x32}, to_apply=%primitive_computation_add__1.18860
  %reduce-window.130 = f32[2,4]{1,0} reduce-window(f32[64,128]{1,0} %reduce-window.21, f32[] %constant.1), window={size=32x32 stride=32x32}, to_apply=%primitive_computation_add__1.18860
  %fusion.544 = f32[] fusion(f32[2,4]{1,0} %reduce-window.130), kind=kLoop, calls=%fused_computation.544, metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %call.178 = f32[2048,4096]{1,0} call(f32[] %fusion.537, f32[4096]{0} %fusion.539, f32[2048,4096]{1,0} %all-reduce.18058, f32[2048]{0} %fusion.541, f32[] %parameter.164, /*index=5*/f32[] %fusion.544, f32[] %parameter.163, f32[2048,4096]{1,0} %parameter.85, f32[] %parameter.166, f32[] %fusion.647, /*index=10*/s32[] %parameter.165), to_apply=%parallel_fusion.536
  %parameter.119 = f32[4096]{0} parameter(37), parameter_replication={false}
  %get-tuple-element.26293 = f32[4096]{0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %while.208), index=16, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=14\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %all-reduce.18063 = f32[4096]{0} all-reduce(f32[4096]{0} %get-tuple-element.26293), replica_groups={{0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15}}, to_apply=%primitive_computation_add__1.18059, metadata={op_type="psum" op_name="pmap(_multi_device_update_fn)/psum[ axes=(\'batch\',)\n                                    axis_index_groups=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=347}
  %fusion.533 = f32[4096]{0} fusion(f32[4096]{0} %parameter.119, f32[4096]{0} %all-reduce.18063, f32[] %fusion.568), kind=kLoop, calls=%fused_computation.533, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=143}
  %fusion.532 = f32[4096]{0} fusion(f32[4096]{0} %fusion.533, f32[4096]{0} %all-reduce.18063, f32[] %parameter.162), kind=kLoop, calls=%fused_computation.532, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=145}
  %multiply.19010 = f32[4096]{0} multiply(f32[4096]{0} %fusion.532, f32[4096]{0} %fusion.532), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %reduce-window.27 = f32[128]{0} reduce-window(f32[4096]{0} %multiply.19010, f32[] %constant.1), window={size=32 stride=32}, to_apply=%primitive_computation_add__1.19012
  %reduce-window.136 = f32[4]{0} reduce-window(f32[128]{0} %reduce-window.27, f32[] %constant.1), window={size=32 stride=32}, to_apply=%primitive_computation_add__1.19012
  %fusion.531 = f32[] fusion(f32[] %parameter.160, f32[4]{0} %reduce-window.136), kind=kLoop, calls=%fused_computation.531, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %multiply.18984 = f32[4096]{0} multiply(f32[4096]{0} %parameter.86, f32[4096]{0} %parameter.86), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %reduce-window.26 = f32[128]{0} reduce-window(f32[4096]{0} %multiply.18984, f32[] %constant.1), window={size=32 stride=32}, to_apply=%primitive_computation_add__1.18986
  %reduce-window.135 = f32[4]{0} reduce-window(f32[128]{0} %reduce-window.26, f32[] %constant.1), window={size=32 stride=32}, to_apply=%primitive_computation_add__1.18986
  %fusion.535 = f32[] fusion(f32[4]{0} %reduce-window.135), kind=kLoop, calls=%fused_computation.535, metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %fusion.530 = f32[4096]{0} fusion(f32[4096]{0} %fusion.532, f32[] %fusion.531, f32[] %parameter.164, f32[] %fusion.535, f32[] %parameter.163, /*index=5*/f32[4096]{0} %parameter.86, f32[] %parameter.166, f32[] %fusion.647, s32[] %parameter.165), kind=kLoop, calls=%fused_computation.530, metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  %get-tuple-element.26149 = f32[2048,4096]{1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %while.207), index=15, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=14\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %all-reduce.18068 = f32[2048,4096]{1,0} all-reduce(f32[2048,4096]{1,0} %get-tuple-element.26149), replica_groups={{0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15}}, to_apply=%primitive_computation_add__1.18064, metadata={op_type="psum" op_name="pmap(_multi_device_update_fn)/psum[ axes=(\'batch\',)\n                                    axis_index_groups=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=347}
  %call.177 = f32[2048,4096]{1,0} call(f32[2048,4096]{1,0} %all-reduce.18068), to_apply=%parallel_fusion.528
  %call.84 = f32[64,4096]{1,0} call(f32[2048,4096]{1,0} %call.177, f32[] %constant.1), to_apply=%parallel_reduce-window.31
  %reduce-window.140 = f32[2,4096]{1,0} reduce-window(f32[64,4096]{1,0} %call.84, f32[] %constant.1), window={size=32x1 stride=32x1}, to_apply=%primitive_computation_add__1.19094
  %reduce.163 = f32[4096]{0} reduce(f32[2,4096]{1,0} %reduce-window.140, f32[] %constant.1), dimensions={0}, to_apply=%primitive_computation_add__1.19094, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
  %parameter.121 = f32[4096]{0} parameter(39), parameter_replication={false}
  %fusion.525 = f32[4096]{0} fusion(f32[4096]{0} %reduce.163, f32[4096]{0} %parameter.121, f32[] %fusion.568), kind=kLoop, calls=%fused_computation.525, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
  %fusion.524 = f32[4096]{0} fusion(f32[4096]{0} %fusion.525, f32[] %parameter.162), kind=kLoop, calls=%fused_computation.524, metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
  %call.83 = f32[2048,128]{1,0} call(f32[2048,4096]{1,0} %call.177, f32[] %constant.1), to_apply=%parallel_reduce-window.29
  %reduce-window.138 = f32[2048,4]{1,0} reduce-window(f32[2048,128]{1,0} %call.83, f32[] %constant.1), window={size=1x32 stride=1x32}, to_apply=%primitive_computation_add__1.19080
  %parameter.120 = f32[2048]{0} parameter(38), parameter_replication={false}
  %fusion.527 = f32[2048]{0} fusion(f32[2048,4]{1,0} %reduce-window.138, f32[2048]{0} %parameter.120, f32[] %fusion.568), kind=kLoop, calls=%fused_computation.527, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=131}
  %reduce-window.30 = f32[64]{0} reduce-window(f32[2048]{0} %fusion.527, f32[] %constant.1), window={size=32 stride=32}, to_apply=%primitive_computation_add__1.19106
  %reduce-window.139 = f32[2]{0} reduce-window(f32[64]{0} %reduce-window.30, f32[] %constant.1), window={size=32 stride=32}, to_apply=%primitive_computation_add__1.19106
  %reduce.162 = f32[] reduce(f32[2]{0} %reduce-window.139, f32[] %constant.1), dimensions={0}, to_apply=%primitive_computation_add__1.19106, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=135}
  %fusion.526 = f32[2048]{0} fusion(f32[2048]{0} %fusion.527, f32[] %reduce.162, f32[] %parameter.162), kind=kLoop, calls=%fused_computation.526, metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  %call.176 = f32[2048,4096]{1,0} call(f32[4096]{0} %fusion.524, f32[2048,4096]{1,0} %all-reduce.18068, f32[2048]{0} %fusion.526), to_apply=%parallel_fusion.523
  %reduce-window.32 = f32[64,128]{1,0} reduce-window(f32[2048,4096]{1,0} %call.176, f32[] %constant.1), window={size=32x32 stride=32x32}, to_apply=%primitive_computation_add__1.19138
  %reduce-window.141 = f32[2,4]{1,0} reduce-window(f32[64,128]{1,0} %reduce-window.32, f32[] %constant.1), window={size=32x32 stride=32x32}, to_apply=%primitive_computation_add__1.19138
  %fusion.522 = f32[] fusion(f32[] %parameter.160, f32[2,4]{1,0} %reduce-window.141), kind=kLoop, calls=%fused_computation.522, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %call.64 = f32[2048,4096]{1,0} call(f32[2048,4096]{1,0} %parameter.87), to_apply=%parallel_multiply.19062
  %reduce-window.28 = f32[64,128]{1,0} reduce-window(f32[2048,4096]{1,0} %call.64, f32[] %constant.1), window={size=32x32 stride=32x32}, to_apply=%primitive_computation_add__1.19064
  %reduce-window.137 = f32[2,4]{1,0} reduce-window(f32[64,128]{1,0} %reduce-window.28, f32[] %constant.1), window={size=32x32 stride=32x32}, to_apply=%primitive_computation_add__1.19064
  %fusion.529 = f32[] fusion(f32[2,4]{1,0} %reduce-window.137), kind=kLoop, calls=%fused_computation.529, metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %call.175 = f32[2048,4096]{1,0} call(f32[] %fusion.522, f32[4096]{0} %fusion.524, f32[2048,4096]{1,0} %all-reduce.18068, f32[2048]{0} %fusion.526, f32[] %parameter.164, /*index=5*/f32[] %fusion.529, f32[] %parameter.163, f32[2048,4096]{1,0} %parameter.87, f32[] %parameter.166, f32[] %fusion.647, /*index=10*/s32[] %parameter.165), to_apply=%parallel_fusion.521
  %parameter.122 = f32[4096]{0} parameter(40), parameter_replication={false}
  %get-tuple-element.26150 = f32[4096]{0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %while.207), index=16, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=14\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %all-reduce.18073 = f32[4096]{0} all-reduce(f32[4096]{0} %get-tuple-element.26150), replica_groups={{0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15}}, to_apply=%primitive_computation_add__1.18069, metadata={op_type="psum" op_name="pmap(_multi_device_update_fn)/psum[ axes=(\'batch\',)\n                                    axis_index_groups=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=347}
  %fusion.518 = f32[4096]{0} fusion(f32[4096]{0} %parameter.122, f32[4096]{0} %all-reduce.18073, f32[] %fusion.568), kind=kLoop, calls=%fused_computation.518, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=143}
  %fusion.517 = f32[4096]{0} fusion(f32[4096]{0} %fusion.518, f32[4096]{0} %all-reduce.18073, f32[] %parameter.162), kind=kLoop, calls=%fused_computation.517, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=145}
  %multiply.19214 = f32[4096]{0} multiply(f32[4096]{0} %fusion.517, f32[4096]{0} %fusion.517), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %reduce-window.34 = f32[128]{0} reduce-window(f32[4096]{0} %multiply.19214, f32[] %constant.1), window={size=32 stride=32}, to_apply=%primitive_computation_add__1.19216
  %reduce-window.143 = f32[4]{0} reduce-window(f32[128]{0} %reduce-window.34, f32[] %constant.1), window={size=32 stride=32}, to_apply=%primitive_computation_add__1.19216
  %fusion.516 = f32[] fusion(f32[] %parameter.160, f32[4]{0} %reduce-window.143), kind=kLoop, calls=%fused_computation.516, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %multiply.19188 = f32[4096]{0} multiply(f32[4096]{0} %parameter.88, f32[4096]{0} %parameter.88), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %reduce-window.33 = f32[128]{0} reduce-window(f32[4096]{0} %multiply.19188, f32[] %constant.1), window={size=32 stride=32}, to_apply=%primitive_computation_add__1.19190
  %reduce-window.142 = f32[4]{0} reduce-window(f32[128]{0} %reduce-window.33, f32[] %constant.1), window={size=32 stride=32}, to_apply=%primitive_computation_add__1.19190
  %fusion.520 = f32[] fusion(f32[4]{0} %reduce-window.142), kind=kLoop, calls=%fused_computation.520, metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %fusion.515 = f32[4096]{0} fusion(f32[4096]{0} %fusion.517, f32[] %fusion.516, f32[] %parameter.164, f32[] %fusion.520, f32[] %parameter.163, /*index=5*/f32[4096]{0} %parameter.88, f32[] %parameter.166, f32[] %fusion.647, s32[] %parameter.165), kind=kLoop, calls=%fused_computation.515, metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  %get-tuple-element.26006 = f32[2048,4096]{1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %while.206), index=15, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=14\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %all-reduce.18078 = f32[2048,4096]{1,0} all-reduce(f32[2048,4096]{1,0} %get-tuple-element.26006), replica_groups={{0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15}}, to_apply=%primitive_computation_add__1.18074, metadata={op_type="psum" op_name="pmap(_multi_device_update_fn)/psum[ axes=(\'batch\',)\n                                    axis_index_groups=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=347}
  %call.174 = f32[2048,4096]{1,0} call(f32[2048,4096]{1,0} %all-reduce.18078), to_apply=%parallel_fusion.513
  %call.86 = f32[64,4096]{1,0} call(f32[2048,4096]{1,0} %call.174, f32[] %constant.1), to_apply=%parallel_reduce-window.38
  %reduce-window.147 = f32[2,4096]{1,0} reduce-window(f32[64,4096]{1,0} %call.86, f32[] %constant.1), window={size=32x1 stride=32x1}, to_apply=%primitive_computation_add__1.19298
  %reduce.170 = f32[4096]{0} reduce(f32[2,4096]{1,0} %reduce-window.147, f32[] %constant.1), dimensions={0}, to_apply=%primitive_computation_add__1.19298, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
  %parameter.124 = f32[4096]{0} parameter(42), parameter_replication={false}
  %fusion.510 = f32[4096]{0} fusion(f32[4096]{0} %reduce.170, f32[4096]{0} %parameter.124, f32[] %fusion.568), kind=kLoop, calls=%fused_computation.510, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
  %fusion.509 = f32[4096]{0} fusion(f32[4096]{0} %fusion.510, f32[] %parameter.162), kind=kLoop, calls=%fused_computation.509, metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
  %call.85 = f32[2048,128]{1,0} call(f32[2048,4096]{1,0} %call.174, f32[] %constant.1), to_apply=%parallel_reduce-window.36
  %reduce-window.145 = f32[2048,4]{1,0} reduce-window(f32[2048,128]{1,0} %call.85, f32[] %constant.1), window={size=1x32 stride=1x32}, to_apply=%primitive_computation_add__1.19284
  %parameter.123 = f32[2048]{0} parameter(41), parameter_replication={false}
  %fusion.512 = f32[2048]{0} fusion(f32[2048,4]{1,0} %reduce-window.145, f32[2048]{0} %parameter.123, f32[] %fusion.568), kind=kLoop, calls=%fused_computation.512, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=131}
  %reduce-window.37 = f32[64]{0} reduce-window(f32[2048]{0} %fusion.512, f32[] %constant.1), window={size=32 stride=32}, to_apply=%primitive_computation_add__1.19310
  %reduce-window.146 = f32[2]{0} reduce-window(f32[64]{0} %reduce-window.37, f32[] %constant.1), window={size=32 stride=32}, to_apply=%primitive_computation_add__1.19310
  %reduce.169 = f32[] reduce(f32[2]{0} %reduce-window.146, f32[] %constant.1), dimensions={0}, to_apply=%primitive_computation_add__1.19310, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=135}
  %fusion.511 = f32[2048]{0} fusion(f32[2048]{0} %fusion.512, f32[] %reduce.169, f32[] %parameter.162), kind=kLoop, calls=%fused_computation.511, metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  %call.173 = f32[2048,4096]{1,0} call(f32[4096]{0} %fusion.509, f32[2048,4096]{1,0} %all-reduce.18078, f32[2048]{0} %fusion.511), to_apply=%parallel_fusion.508
  %reduce-window.39 = f32[64,128]{1,0} reduce-window(f32[2048,4096]{1,0} %call.173, f32[] %constant.1), window={size=32x32 stride=32x32}, to_apply=%primitive_computation_add__1.19342
  %reduce-window.148 = f32[2,4]{1,0} reduce-window(f32[64,128]{1,0} %reduce-window.39, f32[] %constant.1), window={size=32x32 stride=32x32}, to_apply=%primitive_computation_add__1.19342
  %fusion.507 = f32[] fusion(f32[] %parameter.160, f32[2,4]{1,0} %reduce-window.148), kind=kLoop, calls=%fused_computation.507, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %call.65 = f32[2048,4096]{1,0} call(f32[2048,4096]{1,0} %parameter.89), to_apply=%parallel_multiply.19266
  %reduce-window.35 = f32[64,128]{1,0} reduce-window(f32[2048,4096]{1,0} %call.65, f32[] %constant.1), window={size=32x32 stride=32x32}, to_apply=%primitive_computation_add__1.19268
  %reduce-window.144 = f32[2,4]{1,0} reduce-window(f32[64,128]{1,0} %reduce-window.35, f32[] %constant.1), window={size=32x32 stride=32x32}, to_apply=%primitive_computation_add__1.19268
  %fusion.514 = f32[] fusion(f32[2,4]{1,0} %reduce-window.144), kind=kLoop, calls=%fused_computation.514, metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %call.172 = f32[2048,4096]{1,0} call(f32[] %fusion.507, f32[4096]{0} %fusion.509, f32[2048,4096]{1,0} %all-reduce.18078, f32[2048]{0} %fusion.511, f32[] %parameter.164, /*index=5*/f32[] %fusion.514, f32[] %parameter.163, f32[2048,4096]{1,0} %parameter.89, f32[] %parameter.166, f32[] %fusion.647, /*index=10*/s32[] %parameter.165), to_apply=%parallel_fusion.506
  %parameter.125 = f32[4096]{0} parameter(43), parameter_replication={false}
  %get-tuple-element.26007 = f32[4096]{0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %while.206), index=16, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=14\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %all-reduce.18083 = f32[4096]{0} all-reduce(f32[4096]{0} %get-tuple-element.26007), replica_groups={{0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15}}, to_apply=%primitive_computation_add__1.18079, metadata={op_type="psum" op_name="pmap(_multi_device_update_fn)/psum[ axes=(\'batch\',)\n                                    axis_index_groups=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=347}
  %fusion.503 = f32[4096]{0} fusion(f32[4096]{0} %parameter.125, f32[4096]{0} %all-reduce.18083, f32[] %fusion.568), kind=kLoop, calls=%fused_computation.503, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=143}
  %fusion.502 = f32[4096]{0} fusion(f32[4096]{0} %fusion.503, f32[4096]{0} %all-reduce.18083, f32[] %parameter.162), kind=kLoop, calls=%fused_computation.502, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=145}
  %multiply.19418 = f32[4096]{0} multiply(f32[4096]{0} %fusion.502, f32[4096]{0} %fusion.502), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %reduce-window.41 = f32[128]{0} reduce-window(f32[4096]{0} %multiply.19418, f32[] %constant.1), window={size=32 stride=32}, to_apply=%primitive_computation_add__1.19420
  %reduce-window.150 = f32[4]{0} reduce-window(f32[128]{0} %reduce-window.41, f32[] %constant.1), window={size=32 stride=32}, to_apply=%primitive_computation_add__1.19420
  %fusion.501 = f32[] fusion(f32[] %parameter.160, f32[4]{0} %reduce-window.150), kind=kLoop, calls=%fused_computation.501, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %multiply.19392 = f32[4096]{0} multiply(f32[4096]{0} %parameter.90, f32[4096]{0} %parameter.90), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %reduce-window.40 = f32[128]{0} reduce-window(f32[4096]{0} %multiply.19392, f32[] %constant.1), window={size=32 stride=32}, to_apply=%primitive_computation_add__1.19394
  %reduce-window.149 = f32[4]{0} reduce-window(f32[128]{0} %reduce-window.40, f32[] %constant.1), window={size=32 stride=32}, to_apply=%primitive_computation_add__1.19394
  %fusion.505 = f32[] fusion(f32[4]{0} %reduce-window.149), kind=kLoop, calls=%fused_computation.505, metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %fusion.500 = f32[4096]{0} fusion(f32[4096]{0} %fusion.502, f32[] %fusion.501, f32[] %parameter.164, f32[] %fusion.505, f32[] %parameter.163, /*index=5*/f32[4096]{0} %parameter.90, f32[] %parameter.166, f32[] %fusion.647, s32[] %parameter.165), kind=kLoop, calls=%fused_computation.500, metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  %copy.950 = s32[] copy(s32[] %constant.1356)
  %call.60 = f32[256,1024]{1,0} call(f32[] %constant.1), to_apply=%parallel_broadcast.18033
  %fusion.498 = s32[512]{0} fusion(s32[8,65]{1,0} %pad.2), kind=kLoop, calls=%fused_computation.498
  %fusion.497 = f32[8,64,64]{2,1,0} fusion(f32[8,1,64,64]{3,2,1,0} %fusion.573, f32[8,1,64,64]{3,2,1,0} %fusion.594, f32[8,1,64]{2,1,0} %fusion.572, s32[8,64]{1,0} %parameter.167), kind=kLoop, calls=%fused_computation.497
  %call.204 = f32[8,64,1024]{2,1,0} call(f32[1024]{0} %parameter.97, f32[512,1024]{1,0} %dot.1), to_apply=%parallel_fusion.598
  %dot.18 = f32[8,64,1024]{2,1,0} dot(f32[8,64,64]{2,1,0} %fusion.497, f32[8,64,1024]{2,1,0} %call.204), lhs_batch_dims={0}, lhs_contracting_dims={2}, rhs_batch_dims={0}, rhs_contracting_dims={1}, metadata={op_type="dot_general" op_name="pmap(_multi_device_update_fn)/dot_general[ dimension_numbers=(((2, 3), (1, 3)), ((0,), (0,)))\n                                           precision=None\n                                           preferred_element_type=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/attention.py" source_line=281}
  %bitcast.14 = f32[512,1024]{1,0} bitcast(f32[8,64,1024]{2,1,0} %dot.18)
  %dot.201 = f32[512,1024]{1,0} dot(f32[512,1024]{1,0} %bitcast.14, f32[1024,1024]{1,0} %parameter.94), lhs_contracting_dims={1}, rhs_contracting_dims={1}
  %call.171 = f32[64,8,1024]{2,0,1} call(f32[512,1024]{1,0} %dot.201, f32[64,8,1024]{2,1,0} %get-tuple-element.25866), to_apply=%parallel_fusion.496
  %call.114 = f32[64,8,1024]{2,1,0} call(f32[64,8,1024]{2,0,1} %call.171), to_apply=%parallel_copy.47
  %get-tuple-element.24843 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %while.197), index=6, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.24844 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %while.197), index=7, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.24845 = f32[64,8,2048]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %while.197), index=8, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.24846 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %while.197), index=9, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.24847 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %while.197), index=10, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.24848 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %while.197), index=11, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.24849 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %while.197), index=12, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.24850 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %while.197), index=13, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.24851 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %while.197), index=14, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.24852 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %while.197), index=15, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.24853 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %while.197), index=16, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %get-tuple-element.24854 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, f32[1,4096]{1,0}, s32[], f32[8,2048]{1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=15*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}) %while.197), index=17, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=3\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %copy.935 = s32[] copy(s32[] %constant.1356)
  %copy.936 = f32[2048,4096]{1,0} copy(f32[2048,4096]{1,0} %call.97)
  %copy.937 = f32[4096]{0} copy(f32[4096]{0} %broadcast.309)
  %copy.938 = f32[8,2048]{1,0} copy(f32[8,2048]{1,0} %broadcast.5905)
  %copy.939 = f32[64,8,1024]{2,1,0} copy(f32[64,8,1024]{2,1,0} %call.56)
  %tuple.1348 = (f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) tuple(f32[64,8,1024]{2,1,0} %call.114, f32[64,8,1024]{2,1,0} %get-tuple-element.24843, f32[64,8,1024]{2,1,0} %get-tuple-element.24844, f32[64,8,2048]{2,1,0} %get-tuple-element.24845, f32[64,8,1024]{2,1,0} %get-tuple-element.24846, /*index=5*/f32[64,8,1024]{2,1,0} %get-tuple-element.24847, f32[64,8,1024]{2,1,0} %get-tuple-element.24848, f32[64,8,1024]{2,1,0} %get-tuple-element.24849, f32[64,8,1024]{2,1,0} %get-tuple-element.24850, f32[64,8,1024]{2,1,0} %get-tuple-element.24851, /*index=10*/f32[64,8,1024]{2,1,0} %get-tuple-element.24852, f32[64,8,1024]{2,1,0} %get-tuple-element.24853, f32[64,8,1024]{2,1,0} %get-tuple-element.24854, f32[2048,4096]{1,0} %parameter.92, s32[] %copy.935, /*index=15*/f32[2048,4096]{1,0} %copy.936, f32[4096]{0} %copy.937, f32[8,2048]{1,0} %copy.938, f32[64,8,1024]{2,1,0} %copy.939)
  %while.210 = (f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) while((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %tuple.1348), condition=%wide.wide.cond_computation__202.17952.clone.clone.clone.clone, body=%wide.wide.body_computation__202.17541.clone.clone.clone.clone
  %get-tuple-element.26581 = f32[64,8,1024]{2,1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %while.210), index=18, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=14\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %call.170 = f32[512,1024]{1,0} call(f32[64,8,1024]{2,1,0} %get-tuple-element.26581), to_apply=%parallel_fusion.495
  %tuple.1351 = (s32[], f32[256,1024]{1,0}, s32[512]{0}, f32[512,1024]{1,0}) tuple(s32[] %copy.950, f32[256,1024]{1,0} %call.60, s32[512]{0} %fusion.498, f32[512,1024]{1,0} %call.170)
  %while.93 = (s32[], f32[256,1024]{1,0}, s32[512]{0}, f32[512,1024]{1,0}) while((s32[], f32[256,1024]{1,0}, s32[512]{0}, f32[512,1024]{1,0}) %tuple.1351), condition=%while_cond.1, body=%while_body.1, metadata={op_type="scatter-add" op_name="pmap(_multi_device_update_fn)/scatter-add[ dimension_numbers=ScatterDimensionNumbers(update_window_dims=(2,), inserted_window_dims=(0,), scatter_dims_to_operand_dims=(0,))\n                                           indices_are_sorted=False\n                                           unique_indices=False\n                                           update_consts=(  ) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/core.py" source_line=182}
  %get-tuple-element.3544 = f32[256,1024]{1,0} get-tuple-element((s32[], f32[256,1024]{1,0}, s32[512]{0}, f32[512,1024]{1,0}) %while.93), index=1, metadata={op_type="scatter-add" op_name="pmap(_multi_device_update_fn)/scatter-add[ dimension_numbers=ScatterDimensionNumbers(update_window_dims=(2,), inserted_window_dims=(0,), scatter_dims_to_operand_dims=(0,))\n                                           indices_are_sorted=False\n                                           unique_indices=False\n                                           update_consts=(  ) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/core.py" source_line=182}
  %all-reduce.18088 = f32[256,1024]{1,0} all-reduce(f32[256,1024]{1,0} %get-tuple-element.3544), replica_groups={{0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15}}, to_apply=%primitive_computation_add__1.18084, metadata={op_type="psum" op_name="pmap(_multi_device_update_fn)/psum[ axes=(\'batch\',)\n                                    axis_index_groups=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=347}
  %call.169 = f32[256,1024]{1,0} call(f32[256,1024]{1,0} %all-reduce.18088), to_apply=%parallel_fusion.494
  %reduce-window.45 = f32[8,1024]{1,0} reduce-window(f32[256,1024]{1,0} %call.169, f32[] %constant.1), window={size=32x1 stride=32x1}, to_apply=%primitive_computation_add__1.19502
  %reduce.47 = f32[1024]{0} reduce(f32[8,1024]{1,0} %reduce-window.45, f32[] %constant.1), dimensions={0}, to_apply=%primitive_computation_add__1.19502, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
  %parameter.127 = f32[1024]{0} parameter(45), parameter_replication={false}
  %fusion.491 = f32[1024]{0} fusion(f32[1024]{0} %reduce.47, f32[1024]{0} %parameter.127, f32[] %fusion.568), kind=kLoop, calls=%fused_computation.491, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
  %fusion.490 = f32[1024]{0} fusion(f32[1024]{0} %fusion.491, f32[] %parameter.162), kind=kLoop, calls=%fused_computation.490, metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
  %reduce-window.43 = f32[256,32]{1,0} reduce-window(f32[256,1024]{1,0} %call.169, f32[] %constant.1), window={size=1x32 stride=1x32}, to_apply=%primitive_computation_add__1.19488
  %reduce-window.151 = f32[256,1]{1,0} reduce-window(f32[256,32]{1,0} %reduce-window.43, f32[] %constant.1), window={size=1x32 stride=1x32}, to_apply=%primitive_computation_add__1.19488
  %parameter.126 = f32[256]{0} parameter(44), parameter_replication={false}
  %fusion.493 = f32[256]{0} fusion(f32[256,1]{1,0} %reduce-window.151, f32[256]{0} %parameter.126, f32[] %fusion.568), kind=kLoop, calls=%fused_computation.493, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=131}
  %reduce-window.44 = f32[8]{0} reduce-window(f32[256]{0} %fusion.493, f32[] %constant.1), window={size=32 stride=32}, to_apply=%primitive_computation_add__1.19514
  %reduce.46 = f32[] reduce(f32[8]{0} %reduce-window.44, f32[] %constant.1), dimensions={0}, to_apply=%primitive_computation_add__1.19514, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=135}
  %fusion.492 = f32[256]{0} fusion(f32[256]{0} %fusion.493, f32[] %parameter.162, f32[] %reduce.46), kind=kLoop, calls=%fused_computation.492, metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  %call.168 = f32[256,1024]{1,0} call(f32[1024]{0} %fusion.490, f32[256,1024]{1,0} %all-reduce.18088, f32[256]{0} %fusion.492), to_apply=%parallel_fusion.489
  %reduce-window.46 = f32[8,32]{1,0} reduce-window(f32[256,1024]{1,0} %call.168, f32[] %constant.1), window={size=32x32 stride=32x32}, to_apply=%primitive_computation_add__1.19546
  %fusion.488 = f32[] fusion(f32[] %parameter.160, f32[8,32]{1,0} %reduce-window.46), kind=kLoop, calls=%fused_computation.488, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %call.66 = f32[256,1024]{1,0} call(f32[256,1024]{1,0} %parameter.91), to_apply=%parallel_multiply.19470
  %reduce-window.42 = f32[8,32]{1,0} reduce-window(f32[256,1024]{1,0} %call.66, f32[] %constant.1), window={size=32x32 stride=32x32}, to_apply=%primitive_computation_add__1.19472
  %fusion.499 = f32[] fusion(f32[8,32]{1,0} %reduce-window.42), kind=kLoop, calls=%fused_computation.499, metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %call.167 = f32[256,1024]{1,0} call(f32[] %fusion.488, f32[1024]{0} %fusion.490, f32[256,1024]{1,0} %all-reduce.18088, f32[256]{0} %fusion.492, f32[] %parameter.164, /*index=5*/f32[] %fusion.499, f32[] %parameter.163, f32[256,1024]{1,0} %parameter.91, f32[] %parameter.166, f32[] %fusion.647, /*index=10*/s32[] %parameter.165), to_apply=%parallel_fusion.487
  %get-tuple-element.26578 = f32[2048,4096]{1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %while.210), index=15, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=14\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %all-reduce.18093 = f32[2048,4096]{1,0} all-reduce(f32[2048,4096]{1,0} %get-tuple-element.26578), replica_groups={{0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15}}, to_apply=%primitive_computation_add__1.18089, metadata={op_type="psum" op_name="pmap(_multi_device_update_fn)/psum[ axes=(\'batch\',)\n                                    axis_index_groups=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=347}
  %call.166 = f32[2048,4096]{1,0} call(f32[2048,4096]{1,0} %all-reduce.18093), to_apply=%parallel_fusion.485
  %call.88 = f32[64,4096]{1,0} call(f32[2048,4096]{1,0} %call.166, f32[] %constant.1), to_apply=%parallel_reduce-window.50
  %reduce-window.155 = f32[2,4096]{1,0} reduce-window(f32[64,4096]{1,0} %call.88, f32[] %constant.1), window={size=32x1 stride=32x1}, to_apply=%primitive_computation_add__1.19628
  %reduce.178 = f32[4096]{0} reduce(f32[2,4096]{1,0} %reduce-window.155, f32[] %constant.1), dimensions={0}, to_apply=%primitive_computation_add__1.19628, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
  %parameter.129 = f32[4096]{0} parameter(47), parameter_replication={false}
  %fusion.482 = f32[4096]{0} fusion(f32[4096]{0} %reduce.178, f32[4096]{0} %parameter.129, f32[] %fusion.568), kind=kLoop, calls=%fused_computation.482, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
  %fusion.481 = f32[4096]{0} fusion(f32[4096]{0} %fusion.482, f32[] %parameter.162), kind=kLoop, calls=%fused_computation.481, metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
  %call.87 = f32[2048,128]{1,0} call(f32[2048,4096]{1,0} %call.166, f32[] %constant.1), to_apply=%parallel_reduce-window.48
  %reduce-window.153 = f32[2048,4]{1,0} reduce-window(f32[2048,128]{1,0} %call.87, f32[] %constant.1), window={size=1x32 stride=1x32}, to_apply=%primitive_computation_add__1.19614
  %parameter.128 = f32[2048]{0} parameter(46), parameter_replication={false}
  %fusion.484 = f32[2048]{0} fusion(f32[2048,4]{1,0} %reduce-window.153, f32[2048]{0} %parameter.128, f32[] %fusion.568), kind=kLoop, calls=%fused_computation.484, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=131}
  %reduce-window.49 = f32[64]{0} reduce-window(f32[2048]{0} %fusion.484, f32[] %constant.1), window={size=32 stride=32}, to_apply=%primitive_computation_add__1.19640
  %reduce-window.154 = f32[2]{0} reduce-window(f32[64]{0} %reduce-window.49, f32[] %constant.1), window={size=32 stride=32}, to_apply=%primitive_computation_add__1.19640
  %reduce.177 = f32[] reduce(f32[2]{0} %reduce-window.154, f32[] %constant.1), dimensions={0}, to_apply=%primitive_computation_add__1.19640, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=135}
  %fusion.483 = f32[2048]{0} fusion(f32[2048]{0} %fusion.484, f32[] %reduce.177, f32[] %parameter.162), kind=kLoop, calls=%fused_computation.483, metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  %call.165 = f32[2048,4096]{1,0} call(f32[4096]{0} %fusion.481, f32[2048,4096]{1,0} %all-reduce.18093, f32[2048]{0} %fusion.483), to_apply=%parallel_fusion.480
  %reduce-window.51 = f32[64,128]{1,0} reduce-window(f32[2048,4096]{1,0} %call.165, f32[] %constant.1), window={size=32x32 stride=32x32}, to_apply=%primitive_computation_add__1.19672
  %reduce-window.156 = f32[2,4]{1,0} reduce-window(f32[64,128]{1,0} %reduce-window.51, f32[] %constant.1), window={size=32x32 stride=32x32}, to_apply=%primitive_computation_add__1.19672
  %fusion.479 = f32[] fusion(f32[] %parameter.160, f32[2,4]{1,0} %reduce-window.156), kind=kLoop, calls=%fused_computation.479, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %call.67 = f32[2048,4096]{1,0} call(f32[2048,4096]{1,0} %parameter.92), to_apply=%parallel_multiply.19596
  %reduce-window.47 = f32[64,128]{1,0} reduce-window(f32[2048,4096]{1,0} %call.67, f32[] %constant.1), window={size=32x32 stride=32x32}, to_apply=%primitive_computation_add__1.19598
  %reduce-window.152 = f32[2,4]{1,0} reduce-window(f32[64,128]{1,0} %reduce-window.47, f32[] %constant.1), window={size=32x32 stride=32x32}, to_apply=%primitive_computation_add__1.19598
  %fusion.486 = f32[] fusion(f32[2,4]{1,0} %reduce-window.152), kind=kLoop, calls=%fused_computation.486, metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %call.164 = f32[2048,4096]{1,0} call(f32[] %fusion.479, f32[4096]{0} %fusion.481, f32[2048,4096]{1,0} %all-reduce.18093, f32[2048]{0} %fusion.483, f32[] %parameter.164, /*index=5*/f32[] %fusion.486, f32[] %parameter.163, f32[2048,4096]{1,0} %parameter.92, f32[] %parameter.166, f32[] %fusion.647, /*index=10*/s32[] %parameter.165), to_apply=%parallel_fusion.478
  %parameter.130 = f32[4096]{0} parameter(48), parameter_replication={false}
  %get-tuple-element.26579 = f32[4096]{0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %while.210), index=16, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=14\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %all-reduce.18098 = f32[4096]{0} all-reduce(f32[4096]{0} %get-tuple-element.26579), replica_groups={{0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15}}, to_apply=%primitive_computation_add__1.18094, metadata={op_type="psum" op_name="pmap(_multi_device_update_fn)/psum[ axes=(\'batch\',)\n                                    axis_index_groups=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=347}
  %fusion.475 = f32[4096]{0} fusion(f32[4096]{0} %parameter.130, f32[4096]{0} %all-reduce.18098, f32[] %fusion.568), kind=kLoop, calls=%fused_computation.475, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=143}
  %fusion.474 = f32[4096]{0} fusion(f32[4096]{0} %fusion.475, f32[4096]{0} %all-reduce.18098, f32[] %parameter.162), kind=kLoop, calls=%fused_computation.474, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=145}
  %multiply.19748 = f32[4096]{0} multiply(f32[4096]{0} %fusion.474, f32[4096]{0} %fusion.474), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %reduce-window.53 = f32[128]{0} reduce-window(f32[4096]{0} %multiply.19748, f32[] %constant.1), window={size=32 stride=32}, to_apply=%primitive_computation_add__1.19750
  %reduce-window.158 = f32[4]{0} reduce-window(f32[128]{0} %reduce-window.53, f32[] %constant.1), window={size=32 stride=32}, to_apply=%primitive_computation_add__1.19750
  %fusion.473 = f32[] fusion(f32[] %parameter.160, f32[4]{0} %reduce-window.158), kind=kLoop, calls=%fused_computation.473, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %multiply.19722 = f32[4096]{0} multiply(f32[4096]{0} %parameter.93, f32[4096]{0} %parameter.93), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %reduce-window.52 = f32[128]{0} reduce-window(f32[4096]{0} %multiply.19722, f32[] %constant.1), window={size=32 stride=32}, to_apply=%primitive_computation_add__1.19724
  %reduce-window.157 = f32[4]{0} reduce-window(f32[128]{0} %reduce-window.52, f32[] %constant.1), window={size=32 stride=32}, to_apply=%primitive_computation_add__1.19724
  %fusion.477 = f32[] fusion(f32[4]{0} %reduce-window.157), kind=kLoop, calls=%fused_computation.477, metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %fusion.472 = f32[4096]{0} fusion(f32[4096]{0} %fusion.474, f32[] %fusion.473, f32[] %parameter.164, f32[] %fusion.477, f32[] %parameter.163, /*index=5*/f32[4096]{0} %parameter.93, f32[] %parameter.166, f32[] %fusion.647, s32[] %parameter.165), kind=kLoop, calls=%fused_computation.472, metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  %call.163 = f32[1024,512]{1,0} call(f32[8,64,1024]{2,1,0} %dot.18), to_apply=%parallel_fusion.470
  %dot.30 = f32[1024,1024]{1,0} dot(f32[512,1024]{1,0} %call.208, f32[1024,512]{1,0} %call.163), lhs_contracting_dims={0}, rhs_contracting_dims={1}, metadata={op_type="transpose" op_name="pmap(_multi_device_update_fn)/transpose[ permutation=(1, 0) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/core.py" source_line=96}
  %all-reduce.18103 = f32[1024,1024]{1,0} all-reduce(f32[1024,1024]{1,0} %dot.30), replica_groups={{0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15}}, to_apply=%primitive_computation_add__1.18099, metadata={op_type="psum" op_name="pmap(_multi_device_update_fn)/psum[ axes=(\'batch\',)\n                                    axis_index_groups=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=347}
  %call.162 = f32[1024,1024]{1,0} call(f32[1024,1024]{1,0} %all-reduce.18103), to_apply=%parallel_fusion.469
  %reduce-window.57 = f32[32,1024]{1,0} reduce-window(f32[1024,1024]{1,0} %call.162, f32[] %constant.1), window={size=32x1 stride=32x1}, to_apply=%primitive_computation_add__1.19832
  %reduce-window.162 = f32[1,1024]{1,0} reduce-window(f32[32,1024]{1,0} %reduce-window.57, f32[] %constant.1), window={size=32x1 stride=32x1}, to_apply=%primitive_computation_add__1.19832
  %parameter.132 = f32[1024]{0} parameter(50), parameter_replication={false}
  %fusion.466 = f32[1024]{0} fusion(f32[1,1024]{1,0} %reduce-window.162, f32[1024]{0} %parameter.132, f32[] %fusion.568), kind=kLoop, calls=%fused_computation.466, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
  %fusion.465 = f32[1024]{0} fusion(f32[1024]{0} %fusion.466, f32[] %parameter.162), kind=kLoop, calls=%fused_computation.465, metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
  %reduce-window.55 = f32[1024,32]{1,0} reduce-window(f32[1024,1024]{1,0} %call.162, f32[] %constant.1), window={size=1x32 stride=1x32}, to_apply=%primitive_computation_add__1.19818
  %reduce-window.160 = f32[1024,1]{1,0} reduce-window(f32[1024,32]{1,0} %reduce-window.55, f32[] %constant.1), window={size=1x32 stride=1x32}, to_apply=%primitive_computation_add__1.19818
  %parameter.131 = f32[1024]{0} parameter(49), parameter_replication={false}
  %fusion.468 = f32[1024]{0} fusion(f32[1024,1]{1,0} %reduce-window.160, f32[1024]{0} %parameter.131, f32[] %fusion.568), kind=kLoop, calls=%fused_computation.468, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=131}
  %reduce-window.56 = f32[32]{0} reduce-window(f32[1024]{0} %fusion.468, f32[] %constant.1), window={size=32 stride=32}, to_apply=%primitive_computation_add__1.19844
  %reduce-window.161 = f32[1]{0} reduce-window(f32[32]{0} %reduce-window.56, f32[] %constant.1), window={size=32 stride=32}, to_apply=%primitive_computation_add__1.19844
  %fusion.467 = f32[1024]{0} fusion(f32[1024]{0} %fusion.468, f32[1]{0} %reduce-window.161, f32[] %parameter.162), kind=kLoop, calls=%fused_computation.467, metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  %call.161 = f32[1024,1024]{1,0} call(f32[1024]{0} %fusion.465, f32[1024,1024]{1,0} %all-reduce.18103, f32[1024]{0} %fusion.467), to_apply=%parallel_fusion.464
  %reduce-window.58 = f32[32,32]{1,0} reduce-window(f32[1024,1024]{1,0} %call.161, f32[] %constant.1), window={size=32x32 stride=32x32}, to_apply=%primitive_computation_add__1.19876
  %reduce-window.163 = f32[1,1]{1,0} reduce-window(f32[32,32]{1,0} %reduce-window.58, f32[] %constant.1), window={size=32x32 stride=32x32}, to_apply=%primitive_computation_add__1.19876
  %fusion.463 = f32[] fusion(f32[] %parameter.160, f32[1,1]{1,0} %reduce-window.163), kind=kLoop, calls=%fused_computation.463, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %call.68 = f32[1024,1024]{1,0} call(f32[1024,1024]{1,0} %parameter.94), to_apply=%parallel_multiply.19800
  %reduce-window.54 = f32[32,32]{1,0} reduce-window(f32[1024,1024]{1,0} %call.68, f32[] %constant.1), window={size=32x32 stride=32x32}, to_apply=%primitive_computation_add__1.19802
  %reduce-window.159 = f32[1,1]{1,0} reduce-window(f32[32,32]{1,0} %reduce-window.54, f32[] %constant.1), window={size=32x32 stride=32x32}, to_apply=%primitive_computation_add__1.19802
  %fusion.471 = f32[] fusion(f32[1,1]{1,0} %reduce-window.159), kind=kLoop, calls=%fused_computation.471, metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %call.160 = f32[1024,1024]{1,0} call(f32[] %fusion.463, f32[1024]{0} %fusion.465, f32[1024,1024]{1,0} %all-reduce.18103, f32[1024]{0} %fusion.467, f32[] %parameter.164, /*index=5*/f32[] %fusion.471, f32[] %parameter.163, f32[1024,1024]{1,0} %parameter.94, f32[] %parameter.166, f32[] %fusion.647, /*index=10*/s32[] %parameter.165), to_apply=%parallel_fusion.462
  %parameter.133 = f32[1024]{0} parameter(51), parameter_replication={false}
  %reduce.17507 = f32[1024]{0} reduce(f32[8,64,1024]{2,1,0} %dot.18, f32[] %constant.1), dimensions={0,1}, to_apply=%primitive_computation_add__1.17503, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0, 1) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/core.py" source_line=96}
  %all-reduce.18108 = f32[1024]{0} all-reduce(f32[1024]{0} %reduce.17507), replica_groups={{0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15}}, to_apply=%primitive_computation_add__1.18104, metadata={op_type="psum" op_name="pmap(_multi_device_update_fn)/psum[ axes=(\'batch\',)\n                                    axis_index_groups=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=347}
  %fusion.459 = f32[1024]{0} fusion(f32[1024]{0} %parameter.133, f32[1024]{0} %all-reduce.18108, f32[] %fusion.568), kind=kLoop, calls=%fused_computation.459, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=143}
  %fusion.458 = f32[1024]{0} fusion(f32[1024]{0} %fusion.459, f32[1024]{0} %all-reduce.18108, f32[] %parameter.162), kind=kLoop, calls=%fused_computation.458, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=145}
  %multiply.19952 = f32[1024]{0} multiply(f32[1024]{0} %fusion.458, f32[1024]{0} %fusion.458), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %reduce-window.60 = f32[32]{0} reduce-window(f32[1024]{0} %multiply.19952, f32[] %constant.1), window={size=32 stride=32}, to_apply=%primitive_computation_add__1.19954
  %reduce-window.165 = f32[1]{0} reduce-window(f32[32]{0} %reduce-window.60, f32[] %constant.1), window={size=32 stride=32}, to_apply=%primitive_computation_add__1.19954
  %fusion.457 = f32[] fusion(f32[] %parameter.160, f32[1]{0} %reduce-window.165), kind=kLoop, calls=%fused_computation.457, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %multiply.19926 = f32[1024]{0} multiply(f32[1024]{0} %parameter.95, f32[1024]{0} %parameter.95), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %reduce-window.59 = f32[32]{0} reduce-window(f32[1024]{0} %multiply.19926, f32[] %constant.1), window={size=32 stride=32}, to_apply=%primitive_computation_add__1.19928
  %reduce-window.164 = f32[1]{0} reduce-window(f32[32]{0} %reduce-window.59, f32[] %constant.1), window={size=32 stride=32}, to_apply=%primitive_computation_add__1.19928
  %fusion.461 = f32[] fusion(f32[1]{0} %reduce-window.164), kind=kLoop, calls=%fused_computation.461, metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %fusion.456 = f32[1024]{0} fusion(f32[1024]{0} %fusion.458, f32[] %fusion.457, f32[] %parameter.164, f32[] %fusion.461, f32[] %parameter.163, /*index=5*/f32[1024]{0} %parameter.95, f32[] %parameter.166, f32[] %fusion.647, s32[] %parameter.165), kind=kLoop, calls=%fused_computation.456, metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  %call.159 = f32[1024,512]{1,0} call(f32[8,64,1024]{2,1,0} %dot.15), to_apply=%parallel_fusion.454
  %dot.31 = f32[1024,1024]{1,0} dot(f32[512,1024]{1,0} %call.205, f32[1024,512]{1,0} %call.159), lhs_contracting_dims={0}, rhs_contracting_dims={1}, metadata={op_type="transpose" op_name="pmap(_multi_device_update_fn)/transpose[ permutation=(1, 0) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/core.py" source_line=96}
  %all-reduce.18113 = f32[1024,1024]{1,0} all-reduce(f32[1024,1024]{1,0} %dot.31), replica_groups={{0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15}}, to_apply=%primitive_computation_add__1.18109, metadata={op_type="psum" op_name="pmap(_multi_device_update_fn)/psum[ axes=(\'batch\',)\n                                    axis_index_groups=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=347}
  %call.158 = f32[1024,1024]{1,0} call(f32[1024,1024]{1,0} %all-reduce.18113), to_apply=%parallel_fusion.453
  %reduce-window.64 = f32[32,1024]{1,0} reduce-window(f32[1024,1024]{1,0} %call.158, f32[] %constant.1), window={size=32x1 stride=32x1}, to_apply=%primitive_computation_add__1.20036
  %reduce-window.169 = f32[1,1024]{1,0} reduce-window(f32[32,1024]{1,0} %reduce-window.64, f32[] %constant.1), window={size=32x1 stride=32x1}, to_apply=%primitive_computation_add__1.20036
  %parameter.135 = f32[1024]{0} parameter(53), parameter_replication={false}
  %fusion.450 = f32[1024]{0} fusion(f32[1,1024]{1,0} %reduce-window.169, f32[1024]{0} %parameter.135, f32[] %fusion.568), kind=kLoop, calls=%fused_computation.450, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
  %fusion.449 = f32[1024]{0} fusion(f32[1024]{0} %fusion.450, f32[] %parameter.162), kind=kLoop, calls=%fused_computation.449, metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
  %reduce-window.62 = f32[1024,32]{1,0} reduce-window(f32[1024,1024]{1,0} %call.158, f32[] %constant.1), window={size=1x32 stride=1x32}, to_apply=%primitive_computation_add__1.20022
  %reduce-window.167 = f32[1024,1]{1,0} reduce-window(f32[1024,32]{1,0} %reduce-window.62, f32[] %constant.1), window={size=1x32 stride=1x32}, to_apply=%primitive_computation_add__1.20022
  %parameter.134 = f32[1024]{0} parameter(52), parameter_replication={false}
  %fusion.452 = f32[1024]{0} fusion(f32[1024,1]{1,0} %reduce-window.167, f32[1024]{0} %parameter.134, f32[] %fusion.568), kind=kLoop, calls=%fused_computation.452, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=131}
  %reduce-window.63 = f32[32]{0} reduce-window(f32[1024]{0} %fusion.452, f32[] %constant.1), window={size=32 stride=32}, to_apply=%primitive_computation_add__1.20048
  %reduce-window.168 = f32[1]{0} reduce-window(f32[32]{0} %reduce-window.63, f32[] %constant.1), window={size=32 stride=32}, to_apply=%primitive_computation_add__1.20048
  %fusion.451 = f32[1024]{0} fusion(f32[1024]{0} %fusion.452, f32[1]{0} %reduce-window.168, f32[] %parameter.162), kind=kLoop, calls=%fused_computation.451, metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  %call.157 = f32[1024,1024]{1,0} call(f32[1024]{0} %fusion.449, f32[1024,1024]{1,0} %all-reduce.18113, f32[1024]{0} %fusion.451), to_apply=%parallel_fusion.448
  %reduce-window.65 = f32[32,32]{1,0} reduce-window(f32[1024,1024]{1,0} %call.157, f32[] %constant.1), window={size=32x32 stride=32x32}, to_apply=%primitive_computation_add__1.20080
  %reduce-window.170 = f32[1,1]{1,0} reduce-window(f32[32,32]{1,0} %reduce-window.65, f32[] %constant.1), window={size=32x32 stride=32x32}, to_apply=%primitive_computation_add__1.20080
  %fusion.447 = f32[] fusion(f32[] %parameter.160, f32[1,1]{1,0} %reduce-window.170), kind=kLoop, calls=%fused_computation.447, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %call.69 = f32[1024,1024]{1,0} call(f32[1024,1024]{1,0} %parameter.96), to_apply=%parallel_multiply.20004
  %reduce-window.61 = f32[32,32]{1,0} reduce-window(f32[1024,1024]{1,0} %call.69, f32[] %constant.1), window={size=32x32 stride=32x32}, to_apply=%primitive_computation_add__1.20006
  %reduce-window.166 = f32[1,1]{1,0} reduce-window(f32[32,32]{1,0} %reduce-window.61, f32[] %constant.1), window={size=32x32 stride=32x32}, to_apply=%primitive_computation_add__1.20006
  %fusion.455 = f32[] fusion(f32[1,1]{1,0} %reduce-window.166), kind=kLoop, calls=%fused_computation.455, metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %call.156 = f32[1024,1024]{1,0} call(f32[] %fusion.447, f32[1024]{0} %fusion.449, f32[1024,1024]{1,0} %all-reduce.18113, f32[1024]{0} %fusion.451, f32[] %parameter.164, /*index=5*/f32[] %fusion.455, f32[] %parameter.163, f32[1024,1024]{1,0} %parameter.96, f32[] %parameter.166, f32[] %fusion.647, /*index=10*/s32[] %parameter.165), to_apply=%parallel_fusion.446
  %parameter.136 = f32[1024]{0} parameter(54), parameter_replication={false}
  %reduce.240 = f32[1024]{0} reduce(f32[8,64,1024]{2,1,0} %dot.15, f32[] %constant.1), dimensions={0,1}, to_apply=%primitive_computation_add__1.15426, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0, 1) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/core.py" source_line=96}
  %all-reduce.18118 = f32[1024]{0} all-reduce(f32[1024]{0} %reduce.240), replica_groups={{0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15}}, to_apply=%primitive_computation_add__1.18114, metadata={op_type="psum" op_name="pmap(_multi_device_update_fn)/psum[ axes=(\'batch\',)\n                                    axis_index_groups=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=347}
  %fusion.443 = f32[1024]{0} fusion(f32[1024]{0} %parameter.136, f32[1024]{0} %all-reduce.18118, f32[] %fusion.568), kind=kLoop, calls=%fused_computation.443, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=143}
  %fusion.442 = f32[1024]{0} fusion(f32[1024]{0} %fusion.443, f32[1024]{0} %all-reduce.18118, f32[] %parameter.162), kind=kLoop, calls=%fused_computation.442, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=145}
  %multiply.20156 = f32[1024]{0} multiply(f32[1024]{0} %fusion.442, f32[1024]{0} %fusion.442), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %reduce-window.67 = f32[32]{0} reduce-window(f32[1024]{0} %multiply.20156, f32[] %constant.1), window={size=32 stride=32}, to_apply=%primitive_computation_add__1.20158
  %reduce-window.172 = f32[1]{0} reduce-window(f32[32]{0} %reduce-window.67, f32[] %constant.1), window={size=32 stride=32}, to_apply=%primitive_computation_add__1.20158
  %fusion.441 = f32[] fusion(f32[] %parameter.160, f32[1]{0} %reduce-window.172), kind=kLoop, calls=%fused_computation.441, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %multiply.20130 = f32[1024]{0} multiply(f32[1024]{0} %parameter.97, f32[1024]{0} %parameter.97), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %reduce-window.66 = f32[32]{0} reduce-window(f32[1024]{0} %multiply.20130, f32[] %constant.1), window={size=32 stride=32}, to_apply=%primitive_computation_add__1.20132
  %reduce-window.171 = f32[1]{0} reduce-window(f32[32]{0} %reduce-window.66, f32[] %constant.1), window={size=32 stride=32}, to_apply=%primitive_computation_add__1.20132
  %fusion.445 = f32[] fusion(f32[1]{0} %reduce-window.171), kind=kLoop, calls=%fused_computation.445, metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %fusion.440 = f32[1024]{0} fusion(f32[1024]{0} %fusion.442, f32[] %fusion.441, f32[] %parameter.164, f32[] %fusion.445, f32[] %parameter.163, /*index=5*/f32[1024]{0} %parameter.97, f32[] %parameter.166, f32[] %fusion.647, s32[] %parameter.165), kind=kLoop, calls=%fused_computation.440, metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  %call.155 = f32[1024,512]{1,0} call(f32[8,1024,64]{2,1,0} %dot.11), to_apply=%parallel_fusion.438
  %dot.32 = f32[1024,1024]{1,0} dot(f32[512,1024]{1,0} %call.205, f32[1024,512]{1,0} %call.155), lhs_contracting_dims={0}, rhs_contracting_dims={1}, metadata={op_type="transpose" op_name="pmap(_multi_device_update_fn)/transpose[ permutation=(1, 0) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/core.py" source_line=96}
  %all-reduce.18123 = f32[1024,1024]{1,0} all-reduce(f32[1024,1024]{1,0} %dot.32), replica_groups={{0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15}}, to_apply=%primitive_computation_add__1.18119, metadata={op_type="psum" op_name="pmap(_multi_device_update_fn)/psum[ axes=(\'batch\',)\n                                    axis_index_groups=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=347}
  %call.154 = f32[1024,1024]{1,0} call(f32[1024,1024]{1,0} %all-reduce.18123), to_apply=%parallel_fusion.437
  %reduce-window.71 = f32[32,1024]{1,0} reduce-window(f32[1024,1024]{1,0} %call.154, f32[] %constant.1), window={size=32x1 stride=32x1}, to_apply=%primitive_computation_add__1.20240
  %reduce-window.176 = f32[1,1024]{1,0} reduce-window(f32[32,1024]{1,0} %reduce-window.71, f32[] %constant.1), window={size=32x1 stride=32x1}, to_apply=%primitive_computation_add__1.20240
  %parameter.138 = f32[1024]{0} parameter(56), parameter_replication={false}
  %fusion.434 = f32[1024]{0} fusion(f32[1,1024]{1,0} %reduce-window.176, f32[1024]{0} %parameter.138, f32[] %fusion.568), kind=kLoop, calls=%fused_computation.434, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
  %fusion.433 = f32[1024]{0} fusion(f32[1024]{0} %fusion.434, f32[] %parameter.162), kind=kLoop, calls=%fused_computation.433, metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
  %reduce-window.69 = f32[1024,32]{1,0} reduce-window(f32[1024,1024]{1,0} %call.154, f32[] %constant.1), window={size=1x32 stride=1x32}, to_apply=%primitive_computation_add__1.20226
  %reduce-window.174 = f32[1024,1]{1,0} reduce-window(f32[1024,32]{1,0} %reduce-window.69, f32[] %constant.1), window={size=1x32 stride=1x32}, to_apply=%primitive_computation_add__1.20226
  %parameter.137 = f32[1024]{0} parameter(55), parameter_replication={false}
  %fusion.436 = f32[1024]{0} fusion(f32[1024,1]{1,0} %reduce-window.174, f32[1024]{0} %parameter.137, f32[] %fusion.568), kind=kLoop, calls=%fused_computation.436, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=131}
  %reduce-window.70 = f32[32]{0} reduce-window(f32[1024]{0} %fusion.436, f32[] %constant.1), window={size=32 stride=32}, to_apply=%primitive_computation_add__1.20252
  %reduce-window.175 = f32[1]{0} reduce-window(f32[32]{0} %reduce-window.70, f32[] %constant.1), window={size=32 stride=32}, to_apply=%primitive_computation_add__1.20252
  %fusion.435 = f32[1024]{0} fusion(f32[1024]{0} %fusion.436, f32[1]{0} %reduce-window.175, f32[] %parameter.162), kind=kLoop, calls=%fused_computation.435, metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  %call.153 = f32[1024,1024]{1,0} call(f32[1024]{0} %fusion.433, f32[1024,1024]{1,0} %all-reduce.18123, f32[1024]{0} %fusion.435), to_apply=%parallel_fusion.432
  %reduce-window.72 = f32[32,32]{1,0} reduce-window(f32[1024,1024]{1,0} %call.153, f32[] %constant.1), window={size=32x32 stride=32x32}, to_apply=%primitive_computation_add__1.20284
  %reduce-window.177 = f32[1,1]{1,0} reduce-window(f32[32,32]{1,0} %reduce-window.72, f32[] %constant.1), window={size=32x32 stride=32x32}, to_apply=%primitive_computation_add__1.20284
  %fusion.431 = f32[] fusion(f32[] %parameter.160, f32[1,1]{1,0} %reduce-window.177), kind=kLoop, calls=%fused_computation.431, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %call.70 = f32[1024,1024]{1,0} call(f32[1024,1024]{1,0} %parameter.98), to_apply=%parallel_multiply.20208
  %reduce-window.68 = f32[32,32]{1,0} reduce-window(f32[1024,1024]{1,0} %call.70, f32[] %constant.1), window={size=32x32 stride=32x32}, to_apply=%primitive_computation_add__1.20210
  %reduce-window.173 = f32[1,1]{1,0} reduce-window(f32[32,32]{1,0} %reduce-window.68, f32[] %constant.1), window={size=32x32 stride=32x32}, to_apply=%primitive_computation_add__1.20210
  %fusion.439 = f32[] fusion(f32[1,1]{1,0} %reduce-window.173), kind=kLoop, calls=%fused_computation.439, metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %call.152 = f32[1024,1024]{1,0} call(f32[] %fusion.431, f32[1024]{0} %fusion.433, f32[1024,1024]{1,0} %all-reduce.18123, f32[1024]{0} %fusion.435, f32[] %parameter.164, /*index=5*/f32[] %fusion.439, f32[] %parameter.163, f32[1024,1024]{1,0} %parameter.98, f32[] %parameter.166, f32[] %fusion.647, /*index=10*/s32[] %parameter.165), to_apply=%parallel_fusion.430
  %parameter.139 = f32[1024]{0} parameter(57), parameter_replication={false}
  %reduce.253 = f32[1024]{0} reduce(f32[8,1024,64]{2,1,0} %dot.11, f32[] %constant.1), dimensions={0,2}, to_apply=%primitive_computation_add__1.15354, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0, 1) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/core.py" source_line=96}
  %all-reduce.18128 = f32[1024]{0} all-reduce(f32[1024]{0} %reduce.253), replica_groups={{0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15}}, to_apply=%primitive_computation_add__1.18124, metadata={op_type="psum" op_name="pmap(_multi_device_update_fn)/psum[ axes=(\'batch\',)\n                                    axis_index_groups=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=347}
  %fusion.427 = f32[1024]{0} fusion(f32[1024]{0} %parameter.139, f32[1024]{0} %all-reduce.18128, f32[] %fusion.568), kind=kLoop, calls=%fused_computation.427, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=143}
  %fusion.426 = f32[1024]{0} fusion(f32[1024]{0} %fusion.427, f32[1024]{0} %all-reduce.18128, f32[] %parameter.162), kind=kLoop, calls=%fused_computation.426, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=145}
  %multiply.20360 = f32[1024]{0} multiply(f32[1024]{0} %fusion.426, f32[1024]{0} %fusion.426), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %reduce-window.74 = f32[32]{0} reduce-window(f32[1024]{0} %multiply.20360, f32[] %constant.1), window={size=32 stride=32}, to_apply=%primitive_computation_add__1.20362
  %reduce-window.179 = f32[1]{0} reduce-window(f32[32]{0} %reduce-window.74, f32[] %constant.1), window={size=32 stride=32}, to_apply=%primitive_computation_add__1.20362
  %fusion.425 = f32[] fusion(f32[] %parameter.160, f32[1]{0} %reduce-window.179), kind=kLoop, calls=%fused_computation.425, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %multiply.20334 = f32[1024]{0} multiply(f32[1024]{0} %parameter.99, f32[1024]{0} %parameter.99), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %reduce-window.73 = f32[32]{0} reduce-window(f32[1024]{0} %multiply.20334, f32[] %constant.1), window={size=32 stride=32}, to_apply=%primitive_computation_add__1.20336
  %reduce-window.178 = f32[1]{0} reduce-window(f32[32]{0} %reduce-window.73, f32[] %constant.1), window={size=32 stride=32}, to_apply=%primitive_computation_add__1.20336
  %fusion.429 = f32[] fusion(f32[1]{0} %reduce-window.178), kind=kLoop, calls=%fused_computation.429, metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %fusion.424 = f32[1024]{0} fusion(f32[1024]{0} %fusion.426, f32[] %fusion.425, f32[] %parameter.164, f32[] %fusion.429, f32[] %parameter.163, /*index=5*/f32[1024]{0} %parameter.99, f32[] %parameter.166, f32[] %fusion.647, s32[] %parameter.165), kind=kLoop, calls=%fused_computation.424, metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  %call.151 = f32[1024,512]{1,0} call(f32[64,8,1024]{2,1,0} %get-tuple-element.25866), to_apply=%parallel_fusion.422
  %dot.33 = f32[1024,1024]{1,0} dot(f32[512,1024]{1,0} %bitcast.6, f32[1024,512]{1,0} %call.151), lhs_contracting_dims={0}, rhs_contracting_dims={1}, metadata={op_type="transpose" op_name="pmap(_multi_device_update_fn)/transpose[ permutation=(1, 0) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/core.py" source_line=96}
  %all-reduce.18133 = f32[1024,1024]{1,0} all-reduce(f32[1024,1024]{1,0} %dot.33), replica_groups={{0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15}}, to_apply=%primitive_computation_add__1.18129, metadata={op_type="psum" op_name="pmap(_multi_device_update_fn)/psum[ axes=(\'batch\',)\n                                    axis_index_groups=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=347}
  %call.150 = f32[1024,1024]{1,0} call(f32[1024,1024]{1,0} %all-reduce.18133), to_apply=%parallel_fusion.421
  %reduce-window.78 = f32[32,1024]{1,0} reduce-window(f32[1024,1024]{1,0} %call.150, f32[] %constant.1), window={size=32x1 stride=32x1}, to_apply=%primitive_computation_add__1.20444
  %reduce-window.183 = f32[1,1024]{1,0} reduce-window(f32[32,1024]{1,0} %reduce-window.78, f32[] %constant.1), window={size=32x1 stride=32x1}, to_apply=%primitive_computation_add__1.20444
  %parameter.141 = f32[1024]{0} parameter(59), parameter_replication={false}
  %fusion.418 = f32[1024]{0} fusion(f32[1,1024]{1,0} %reduce-window.183, f32[1024]{0} %parameter.141, f32[] %fusion.568), kind=kLoop, calls=%fused_computation.418, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
  %fusion.417 = f32[1024]{0} fusion(f32[1024]{0} %fusion.418, f32[] %parameter.162), kind=kLoop, calls=%fused_computation.417, metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
  %reduce-window.76 = f32[1024,32]{1,0} reduce-window(f32[1024,1024]{1,0} %call.150, f32[] %constant.1), window={size=1x32 stride=1x32}, to_apply=%primitive_computation_add__1.20430
  %reduce-window.181 = f32[1024,1]{1,0} reduce-window(f32[1024,32]{1,0} %reduce-window.76, f32[] %constant.1), window={size=1x32 stride=1x32}, to_apply=%primitive_computation_add__1.20430
  %parameter.140 = f32[1024]{0} parameter(58), parameter_replication={false}
  %fusion.420 = f32[1024]{0} fusion(f32[1024,1]{1,0} %reduce-window.181, f32[1024]{0} %parameter.140, f32[] %fusion.568), kind=kLoop, calls=%fused_computation.420, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=131}
  %reduce-window.77 = f32[32]{0} reduce-window(f32[1024]{0} %fusion.420, f32[] %constant.1), window={size=32 stride=32}, to_apply=%primitive_computation_add__1.20456
  %reduce-window.182 = f32[1]{0} reduce-window(f32[32]{0} %reduce-window.77, f32[] %constant.1), window={size=32 stride=32}, to_apply=%primitive_computation_add__1.20456
  %fusion.419 = f32[1024]{0} fusion(f32[1024]{0} %fusion.420, f32[1]{0} %reduce-window.182, f32[] %parameter.162), kind=kLoop, calls=%fused_computation.419, metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  %call.149 = f32[1024,1024]{1,0} call(f32[1024]{0} %fusion.417, f32[1024,1024]{1,0} %all-reduce.18133, f32[1024]{0} %fusion.419), to_apply=%parallel_fusion.416
  %reduce-window.79 = f32[32,32]{1,0} reduce-window(f32[1024,1024]{1,0} %call.149, f32[] %constant.1), window={size=32x32 stride=32x32}, to_apply=%primitive_computation_add__1.20488
  %reduce-window.184 = f32[1,1]{1,0} reduce-window(f32[32,32]{1,0} %reduce-window.79, f32[] %constant.1), window={size=32x32 stride=32x32}, to_apply=%primitive_computation_add__1.20488
  %fusion.415 = f32[] fusion(f32[] %parameter.160, f32[1,1]{1,0} %reduce-window.184), kind=kLoop, calls=%fused_computation.415, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %call.71 = f32[1024,1024]{1,0} call(f32[1024,1024]{1,0} %parameter.100), to_apply=%parallel_multiply.20412
  %reduce-window.75 = f32[32,32]{1,0} reduce-window(f32[1024,1024]{1,0} %call.71, f32[] %constant.1), window={size=32x32 stride=32x32}, to_apply=%primitive_computation_add__1.20414
  %reduce-window.180 = f32[1,1]{1,0} reduce-window(f32[32,32]{1,0} %reduce-window.75, f32[] %constant.1), window={size=32x32 stride=32x32}, to_apply=%primitive_computation_add__1.20414
  %fusion.423 = f32[] fusion(f32[1,1]{1,0} %reduce-window.180), kind=kLoop, calls=%fused_computation.423, metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %call.148 = f32[1024,1024]{1,0} call(f32[] %fusion.415, f32[1024]{0} %fusion.417, f32[1024,1024]{1,0} %all-reduce.18133, f32[1024]{0} %fusion.419, f32[] %parameter.164, /*index=5*/f32[] %fusion.423, f32[] %parameter.163, f32[1024,1024]{1,0} %parameter.100, f32[] %parameter.166, f32[] %fusion.647, /*index=10*/s32[] %parameter.165), to_apply=%parallel_fusion.414
  %parameter.142 = f32[1024]{0} parameter(60), parameter_replication={false}
  %reduce.122 = f32[1024]{0} reduce(f32[64,8,1024]{2,1,0} %get-tuple-element.25866, f32[] %constant.1), dimensions={1,0}, to_apply=%primitive_computation_add__1.15330, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0, 1) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/core.py" source_line=96}
  %all-reduce.18138 = f32[1024]{0} all-reduce(f32[1024]{0} %reduce.122), replica_groups={{0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15}}, to_apply=%primitive_computation_add__1.18134, metadata={op_type="psum" op_name="pmap(_multi_device_update_fn)/psum[ axes=(\'batch\',)\n                                    axis_index_groups=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=347}
  %fusion.411 = f32[1024]{0} fusion(f32[1024]{0} %parameter.142, f32[1024]{0} %all-reduce.18138, f32[] %fusion.568), kind=kLoop, calls=%fused_computation.411, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=143}
  %fusion.410 = f32[1024]{0} fusion(f32[1024]{0} %fusion.411, f32[1024]{0} %all-reduce.18138, f32[] %parameter.162), kind=kLoop, calls=%fused_computation.410, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=145}
  %multiply.20564 = f32[1024]{0} multiply(f32[1024]{0} %fusion.410, f32[1024]{0} %fusion.410), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %reduce-window.81 = f32[32]{0} reduce-window(f32[1024]{0} %multiply.20564, f32[] %constant.1), window={size=32 stride=32}, to_apply=%primitive_computation_add__1.20566
  %reduce-window.186 = f32[1]{0} reduce-window(f32[32]{0} %reduce-window.81, f32[] %constant.1), window={size=32 stride=32}, to_apply=%primitive_computation_add__1.20566
  %fusion.409 = f32[] fusion(f32[] %parameter.160, f32[1]{0} %reduce-window.186), kind=kLoop, calls=%fused_computation.409, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %multiply.20538 = f32[1024]{0} multiply(f32[1024]{0} %parameter.101, f32[1024]{0} %parameter.101), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %reduce-window.80 = f32[32]{0} reduce-window(f32[1024]{0} %multiply.20538, f32[] %constant.1), window={size=32 stride=32}, to_apply=%primitive_computation_add__1.20540
  %reduce-window.185 = f32[1]{0} reduce-window(f32[32]{0} %reduce-window.80, f32[] %constant.1), window={size=32 stride=32}, to_apply=%primitive_computation_add__1.20540
  %fusion.413 = f32[] fusion(f32[1]{0} %reduce-window.185), kind=kLoop, calls=%fused_computation.413, metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %fusion.408 = f32[1024]{0} fusion(f32[1024]{0} %fusion.410, f32[] %fusion.409, f32[] %parameter.164, f32[] %fusion.413, f32[] %parameter.163, /*index=5*/f32[1024]{0} %parameter.101, f32[] %parameter.166, f32[] %fusion.647, s32[] %parameter.165), kind=kLoop, calls=%fused_computation.408, metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  %get-tuple-element.25863 = f32[2048,4096]{1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %while.205), index=15, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=14\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %all-reduce.18143 = f32[2048,4096]{1,0} all-reduce(f32[2048,4096]{1,0} %get-tuple-element.25863), replica_groups={{0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15}}, to_apply=%primitive_computation_add__1.18139, metadata={op_type="psum" op_name="pmap(_multi_device_update_fn)/psum[ axes=(\'batch\',)\n                                    axis_index_groups=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=347}
  %call.147 = f32[2048,4096]{1,0} call(f32[2048,4096]{1,0} %all-reduce.18143), to_apply=%parallel_fusion.406
  %call.90 = f32[64,4096]{1,0} call(f32[2048,4096]{1,0} %call.147, f32[] %constant.1), to_apply=%parallel_reduce-window.85
  %reduce-window.190 = f32[2,4096]{1,0} reduce-window(f32[64,4096]{1,0} %call.90, f32[] %constant.1), window={size=32x1 stride=32x1}, to_apply=%primitive_computation_add__1.20648
  %reduce.213 = f32[4096]{0} reduce(f32[2,4096]{1,0} %reduce-window.190, f32[] %constant.1), dimensions={0}, to_apply=%primitive_computation_add__1.20648, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
  %parameter.144 = f32[4096]{0} parameter(62), parameter_replication={false}
  %fusion.403 = f32[4096]{0} fusion(f32[4096]{0} %reduce.213, f32[4096]{0} %parameter.144, f32[] %fusion.568), kind=kLoop, calls=%fused_computation.403, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
  %fusion.402 = f32[4096]{0} fusion(f32[4096]{0} %fusion.403, f32[] %parameter.162), kind=kLoop, calls=%fused_computation.402, metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
  %call.89 = f32[2048,128]{1,0} call(f32[2048,4096]{1,0} %call.147, f32[] %constant.1), to_apply=%parallel_reduce-window.83
  %reduce-window.188 = f32[2048,4]{1,0} reduce-window(f32[2048,128]{1,0} %call.89, f32[] %constant.1), window={size=1x32 stride=1x32}, to_apply=%primitive_computation_add__1.20634
  %parameter.143 = f32[2048]{0} parameter(61), parameter_replication={false}
  %fusion.405 = f32[2048]{0} fusion(f32[2048,4]{1,0} %reduce-window.188, f32[2048]{0} %parameter.143, f32[] %fusion.568), kind=kLoop, calls=%fused_computation.405, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=131}
  %reduce-window.84 = f32[64]{0} reduce-window(f32[2048]{0} %fusion.405, f32[] %constant.1), window={size=32 stride=32}, to_apply=%primitive_computation_add__1.20660
  %reduce-window.189 = f32[2]{0} reduce-window(f32[64]{0} %reduce-window.84, f32[] %constant.1), window={size=32 stride=32}, to_apply=%primitive_computation_add__1.20660
  %reduce.212 = f32[] reduce(f32[2]{0} %reduce-window.189, f32[] %constant.1), dimensions={0}, to_apply=%primitive_computation_add__1.20660, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=135}
  %fusion.404 = f32[2048]{0} fusion(f32[2048]{0} %fusion.405, f32[] %reduce.212, f32[] %parameter.162), kind=kLoop, calls=%fused_computation.404, metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  %call.146 = f32[2048,4096]{1,0} call(f32[4096]{0} %fusion.402, f32[2048,4096]{1,0} %all-reduce.18143, f32[2048]{0} %fusion.404), to_apply=%parallel_fusion.401
  %reduce-window.86 = f32[64,128]{1,0} reduce-window(f32[2048,4096]{1,0} %call.146, f32[] %constant.1), window={size=32x32 stride=32x32}, to_apply=%primitive_computation_add__1.20692
  %reduce-window.191 = f32[2,4]{1,0} reduce-window(f32[64,128]{1,0} %reduce-window.86, f32[] %constant.1), window={size=32x32 stride=32x32}, to_apply=%primitive_computation_add__1.20692
  %fusion.400 = f32[] fusion(f32[] %parameter.160, f32[2,4]{1,0} %reduce-window.191), kind=kLoop, calls=%fused_computation.400, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %call.72 = f32[2048,4096]{1,0} call(f32[2048,4096]{1,0} %parameter.102), to_apply=%parallel_multiply.20616
  %reduce-window.82 = f32[64,128]{1,0} reduce-window(f32[2048,4096]{1,0} %call.72, f32[] %constant.1), window={size=32x32 stride=32x32}, to_apply=%primitive_computation_add__1.20618
  %reduce-window.187 = f32[2,4]{1,0} reduce-window(f32[64,128]{1,0} %reduce-window.82, f32[] %constant.1), window={size=32x32 stride=32x32}, to_apply=%primitive_computation_add__1.20618
  %fusion.407 = f32[] fusion(f32[2,4]{1,0} %reduce-window.187), kind=kLoop, calls=%fused_computation.407, metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %call.145 = f32[2048,4096]{1,0} call(f32[] %fusion.400, f32[4096]{0} %fusion.402, f32[2048,4096]{1,0} %all-reduce.18143, f32[2048]{0} %fusion.404, f32[] %parameter.164, /*index=5*/f32[] %fusion.407, f32[] %parameter.163, f32[2048,4096]{1,0} %parameter.102, f32[] %parameter.166, f32[] %fusion.647, /*index=10*/s32[] %parameter.165), to_apply=%parallel_fusion.399
  %parameter.145 = f32[4096]{0} parameter(63), parameter_replication={false}
  %get-tuple-element.25864 = f32[4096]{0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %while.205), index=16, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=14\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %all-reduce.18148 = f32[4096]{0} all-reduce(f32[4096]{0} %get-tuple-element.25864), replica_groups={{0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15}}, to_apply=%primitive_computation_add__1.18144, metadata={op_type="psum" op_name="pmap(_multi_device_update_fn)/psum[ axes=(\'batch\',)\n                                    axis_index_groups=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=347}
  %fusion.396 = f32[4096]{0} fusion(f32[4096]{0} %parameter.145, f32[4096]{0} %all-reduce.18148, f32[] %fusion.568), kind=kLoop, calls=%fused_computation.396, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=143}
  %fusion.395 = f32[4096]{0} fusion(f32[4096]{0} %fusion.396, f32[4096]{0} %all-reduce.18148, f32[] %parameter.162), kind=kLoop, calls=%fused_computation.395, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=145}
  %multiply.20768 = f32[4096]{0} multiply(f32[4096]{0} %fusion.395, f32[4096]{0} %fusion.395), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %reduce-window.88 = f32[128]{0} reduce-window(f32[4096]{0} %multiply.20768, f32[] %constant.1), window={size=32 stride=32}, to_apply=%primitive_computation_add__1.20770
  %reduce-window.193 = f32[4]{0} reduce-window(f32[128]{0} %reduce-window.88, f32[] %constant.1), window={size=32 stride=32}, to_apply=%primitive_computation_add__1.20770
  %fusion.394 = f32[] fusion(f32[] %parameter.160, f32[4]{0} %reduce-window.193), kind=kLoop, calls=%fused_computation.394, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %multiply.20742 = f32[4096]{0} multiply(f32[4096]{0} %parameter.103, f32[4096]{0} %parameter.103), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %reduce-window.87 = f32[128]{0} reduce-window(f32[4096]{0} %multiply.20742, f32[] %constant.1), window={size=32 stride=32}, to_apply=%primitive_computation_add__1.20744
  %reduce-window.192 = f32[4]{0} reduce-window(f32[128]{0} %reduce-window.87, f32[] %constant.1), window={size=32 stride=32}, to_apply=%primitive_computation_add__1.20744
  %fusion.398 = f32[] fusion(f32[4]{0} %reduce-window.192), kind=kLoop, calls=%fused_computation.398, metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %fusion.393 = f32[4096]{0} fusion(f32[4096]{0} %fusion.395, f32[] %fusion.394, f32[] %parameter.164, f32[] %fusion.398, f32[] %parameter.163, /*index=5*/f32[4096]{0} %parameter.103, f32[] %parameter.166, f32[] %fusion.647, s32[] %parameter.165), kind=kLoop, calls=%fused_computation.393, metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  %get-tuple-element.25720 = f32[2048,4096]{1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %while.204), index=15, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=14\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %all-reduce.18153 = f32[2048,4096]{1,0} all-reduce(f32[2048,4096]{1,0} %get-tuple-element.25720), replica_groups={{0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15}}, to_apply=%primitive_computation_add__1.18149, metadata={op_type="psum" op_name="pmap(_multi_device_update_fn)/psum[ axes=(\'batch\',)\n                                    axis_index_groups=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=347}
  %call.144 = f32[2048,4096]{1,0} call(f32[2048,4096]{1,0} %all-reduce.18153), to_apply=%parallel_fusion.391
  %call.92 = f32[64,4096]{1,0} call(f32[2048,4096]{1,0} %call.144, f32[] %constant.1), to_apply=%parallel_reduce-window.92
  %reduce-window.197 = f32[2,4096]{1,0} reduce-window(f32[64,4096]{1,0} %call.92, f32[] %constant.1), window={size=32x1 stride=32x1}, to_apply=%primitive_computation_add__1.20852
  %reduce.220 = f32[4096]{0} reduce(f32[2,4096]{1,0} %reduce-window.197, f32[] %constant.1), dimensions={0}, to_apply=%primitive_computation_add__1.20852, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
  %parameter.147 = f32[4096]{0} parameter(65), parameter_replication={false}
  %fusion.388 = f32[4096]{0} fusion(f32[4096]{0} %reduce.220, f32[4096]{0} %parameter.147, f32[] %fusion.568), kind=kLoop, calls=%fused_computation.388, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
  %fusion.387 = f32[4096]{0} fusion(f32[4096]{0} %fusion.388, f32[] %parameter.162), kind=kLoop, calls=%fused_computation.387, metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
  %call.91 = f32[2048,128]{1,0} call(f32[2048,4096]{1,0} %call.144, f32[] %constant.1), to_apply=%parallel_reduce-window.90
  %reduce-window.195 = f32[2048,4]{1,0} reduce-window(f32[2048,128]{1,0} %call.91, f32[] %constant.1), window={size=1x32 stride=1x32}, to_apply=%primitive_computation_add__1.20838
  %parameter.146 = f32[2048]{0} parameter(64), parameter_replication={false}
  %fusion.390 = f32[2048]{0} fusion(f32[2048,4]{1,0} %reduce-window.195, f32[2048]{0} %parameter.146, f32[] %fusion.568), kind=kLoop, calls=%fused_computation.390, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=131}
  %reduce-window.91 = f32[64]{0} reduce-window(f32[2048]{0} %fusion.390, f32[] %constant.1), window={size=32 stride=32}, to_apply=%primitive_computation_add__1.20864
  %reduce-window.196 = f32[2]{0} reduce-window(f32[64]{0} %reduce-window.91, f32[] %constant.1), window={size=32 stride=32}, to_apply=%primitive_computation_add__1.20864
  %reduce.219 = f32[] reduce(f32[2]{0} %reduce-window.196, f32[] %constant.1), dimensions={0}, to_apply=%primitive_computation_add__1.20864, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=135}
  %fusion.389 = f32[2048]{0} fusion(f32[2048]{0} %fusion.390, f32[] %reduce.219, f32[] %parameter.162), kind=kLoop, calls=%fused_computation.389, metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  %call.143 = f32[2048,4096]{1,0} call(f32[4096]{0} %fusion.387, f32[2048,4096]{1,0} %all-reduce.18153, f32[2048]{0} %fusion.389), to_apply=%parallel_fusion.386
  %reduce-window.93 = f32[64,128]{1,0} reduce-window(f32[2048,4096]{1,0} %call.143, f32[] %constant.1), window={size=32x32 stride=32x32}, to_apply=%primitive_computation_add__1.20896
  %reduce-window.198 = f32[2,4]{1,0} reduce-window(f32[64,128]{1,0} %reduce-window.93, f32[] %constant.1), window={size=32x32 stride=32x32}, to_apply=%primitive_computation_add__1.20896
  %fusion.385 = f32[] fusion(f32[] %parameter.160, f32[2,4]{1,0} %reduce-window.198), kind=kLoop, calls=%fused_computation.385, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %call.73 = f32[2048,4096]{1,0} call(f32[2048,4096]{1,0} %parameter.104), to_apply=%parallel_multiply.20820
  %reduce-window.89 = f32[64,128]{1,0} reduce-window(f32[2048,4096]{1,0} %call.73, f32[] %constant.1), window={size=32x32 stride=32x32}, to_apply=%primitive_computation_add__1.20822
  %reduce-window.194 = f32[2,4]{1,0} reduce-window(f32[64,128]{1,0} %reduce-window.89, f32[] %constant.1), window={size=32x32 stride=32x32}, to_apply=%primitive_computation_add__1.20822
  %fusion.392 = f32[] fusion(f32[2,4]{1,0} %reduce-window.194), kind=kLoop, calls=%fused_computation.392, metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %call.142 = f32[2048,4096]{1,0} call(f32[] %fusion.385, f32[4096]{0} %fusion.387, f32[2048,4096]{1,0} %all-reduce.18153, f32[2048]{0} %fusion.389, f32[] %parameter.164, /*index=5*/f32[] %fusion.392, f32[] %parameter.163, f32[2048,4096]{1,0} %parameter.104, f32[] %parameter.166, f32[] %fusion.647, /*index=10*/s32[] %parameter.165), to_apply=%parallel_fusion.384
  %parameter.148 = f32[4096]{0} parameter(66), parameter_replication={false}
  %get-tuple-element.25721 = f32[4096]{0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %while.204), index=16, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=14\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %all-reduce.18158 = f32[4096]{0} all-reduce(f32[4096]{0} %get-tuple-element.25721), replica_groups={{0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15}}, to_apply=%primitive_computation_add__1.18154, metadata={op_type="psum" op_name="pmap(_multi_device_update_fn)/psum[ axes=(\'batch\',)\n                                    axis_index_groups=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=347}
  %fusion.381 = f32[4096]{0} fusion(f32[4096]{0} %parameter.148, f32[4096]{0} %all-reduce.18158, f32[] %fusion.568), kind=kLoop, calls=%fused_computation.381, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=143}
  %fusion.380 = f32[4096]{0} fusion(f32[4096]{0} %fusion.381, f32[4096]{0} %all-reduce.18158, f32[] %parameter.162), kind=kLoop, calls=%fused_computation.380, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=145}
  %multiply.20972 = f32[4096]{0} multiply(f32[4096]{0} %fusion.380, f32[4096]{0} %fusion.380), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %reduce-window.95 = f32[128]{0} reduce-window(f32[4096]{0} %multiply.20972, f32[] %constant.1), window={size=32 stride=32}, to_apply=%primitive_computation_add__1.20974
  %reduce-window.200 = f32[4]{0} reduce-window(f32[128]{0} %reduce-window.95, f32[] %constant.1), window={size=32 stride=32}, to_apply=%primitive_computation_add__1.20974
  %fusion.379 = f32[] fusion(f32[] %parameter.160, f32[4]{0} %reduce-window.200), kind=kLoop, calls=%fused_computation.379, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %multiply.20946 = f32[4096]{0} multiply(f32[4096]{0} %parameter.105, f32[4096]{0} %parameter.105), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %reduce-window.94 = f32[128]{0} reduce-window(f32[4096]{0} %multiply.20946, f32[] %constant.1), window={size=32 stride=32}, to_apply=%primitive_computation_add__1.20948
  %reduce-window.199 = f32[4]{0} reduce-window(f32[128]{0} %reduce-window.94, f32[] %constant.1), window={size=32 stride=32}, to_apply=%primitive_computation_add__1.20948
  %fusion.383 = f32[] fusion(f32[4]{0} %reduce-window.199), kind=kLoop, calls=%fused_computation.383, metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %fusion.378 = f32[4096]{0} fusion(f32[4096]{0} %fusion.380, f32[] %fusion.379, f32[] %parameter.164, f32[] %fusion.383, f32[] %parameter.163, /*index=5*/f32[4096]{0} %parameter.105, f32[] %parameter.166, f32[] %fusion.647, s32[] %parameter.165), kind=kLoop, calls=%fused_computation.378, metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  %get-tuple-element.25577 = f32[2048,4096]{1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %while.203), index=15, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=14\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %all-reduce.18163 = f32[2048,4096]{1,0} all-reduce(f32[2048,4096]{1,0} %get-tuple-element.25577), replica_groups={{0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15}}, to_apply=%primitive_computation_add__1.18159, metadata={op_type="psum" op_name="pmap(_multi_device_update_fn)/psum[ axes=(\'batch\',)\n                                    axis_index_groups=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=347}
  %call.141 = f32[2048,4096]{1,0} call(f32[2048,4096]{1,0} %all-reduce.18163), to_apply=%parallel_fusion.376
  %call.94 = f32[64,4096]{1,0} call(f32[2048,4096]{1,0} %call.141, f32[] %constant.1), to_apply=%parallel_reduce-window.99
  %reduce-window.204 = f32[2,4096]{1,0} reduce-window(f32[64,4096]{1,0} %call.94, f32[] %constant.1), window={size=32x1 stride=32x1}, to_apply=%primitive_computation_add__1.21056
  %reduce.227 = f32[4096]{0} reduce(f32[2,4096]{1,0} %reduce-window.204, f32[] %constant.1), dimensions={0}, to_apply=%primitive_computation_add__1.21056, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
  %parameter.150 = f32[4096]{0} parameter(68), parameter_replication={false}
  %fusion.373 = f32[4096]{0} fusion(f32[4096]{0} %reduce.227, f32[4096]{0} %parameter.150, f32[] %fusion.568), kind=kLoop, calls=%fused_computation.373, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
  %fusion.372 = f32[4096]{0} fusion(f32[4096]{0} %fusion.373, f32[] %parameter.162), kind=kLoop, calls=%fused_computation.372, metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
  %call.93 = f32[2048,128]{1,0} call(f32[2048,4096]{1,0} %call.141, f32[] %constant.1), to_apply=%parallel_reduce-window.97
  %reduce-window.202 = f32[2048,4]{1,0} reduce-window(f32[2048,128]{1,0} %call.93, f32[] %constant.1), window={size=1x32 stride=1x32}, to_apply=%primitive_computation_add__1.21042
  %parameter.149 = f32[2048]{0} parameter(67), parameter_replication={false}
  %fusion.375 = f32[2048]{0} fusion(f32[2048,4]{1,0} %reduce-window.202, f32[2048]{0} %parameter.149, f32[] %fusion.568), kind=kLoop, calls=%fused_computation.375, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=131}
  %reduce-window.98 = f32[64]{0} reduce-window(f32[2048]{0} %fusion.375, f32[] %constant.1), window={size=32 stride=32}, to_apply=%primitive_computation_add__1.21068
  %reduce-window.203 = f32[2]{0} reduce-window(f32[64]{0} %reduce-window.98, f32[] %constant.1), window={size=32 stride=32}, to_apply=%primitive_computation_add__1.21068
  %reduce.226 = f32[] reduce(f32[2]{0} %reduce-window.203, f32[] %constant.1), dimensions={0}, to_apply=%primitive_computation_add__1.21068, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=135}
  %fusion.374 = f32[2048]{0} fusion(f32[2048]{0} %fusion.375, f32[] %reduce.226, f32[] %parameter.162), kind=kLoop, calls=%fused_computation.374, metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  %call.140 = f32[2048,4096]{1,0} call(f32[4096]{0} %fusion.372, f32[2048,4096]{1,0} %all-reduce.18163, f32[2048]{0} %fusion.374), to_apply=%parallel_fusion.371
  %reduce-window.100 = f32[64,128]{1,0} reduce-window(f32[2048,4096]{1,0} %call.140, f32[] %constant.1), window={size=32x32 stride=32x32}, to_apply=%primitive_computation_add__1.21100
  %reduce-window.205 = f32[2,4]{1,0} reduce-window(f32[64,128]{1,0} %reduce-window.100, f32[] %constant.1), window={size=32x32 stride=32x32}, to_apply=%primitive_computation_add__1.21100
  %fusion.370 = f32[] fusion(f32[] %parameter.160, f32[2,4]{1,0} %reduce-window.205), kind=kLoop, calls=%fused_computation.370, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %call.74 = f32[2048,4096]{1,0} call(f32[2048,4096]{1,0} %parameter.106), to_apply=%parallel_multiply.21024
  %reduce-window.96 = f32[64,128]{1,0} reduce-window(f32[2048,4096]{1,0} %call.74, f32[] %constant.1), window={size=32x32 stride=32x32}, to_apply=%primitive_computation_add__1.21026
  %reduce-window.201 = f32[2,4]{1,0} reduce-window(f32[64,128]{1,0} %reduce-window.96, f32[] %constant.1), window={size=32x32 stride=32x32}, to_apply=%primitive_computation_add__1.21026
  %fusion.377 = f32[] fusion(f32[2,4]{1,0} %reduce-window.201), kind=kLoop, calls=%fused_computation.377, metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %call.139 = f32[2048,4096]{1,0} call(f32[] %fusion.370, f32[4096]{0} %fusion.372, f32[2048,4096]{1,0} %all-reduce.18163, f32[2048]{0} %fusion.374, f32[] %parameter.164, /*index=5*/f32[] %fusion.377, f32[] %parameter.163, f32[2048,4096]{1,0} %parameter.106, f32[] %parameter.166, f32[] %fusion.647, /*index=10*/s32[] %parameter.165), to_apply=%parallel_fusion.369
  %parameter.151 = f32[4096]{0} parameter(69), parameter_replication={false}
  %get-tuple-element.25578 = f32[4096]{0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %while.203), index=16, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=14\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %all-reduce.18168 = f32[4096]{0} all-reduce(f32[4096]{0} %get-tuple-element.25578), replica_groups={{0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15}}, to_apply=%primitive_computation_add__1.18164, metadata={op_type="psum" op_name="pmap(_multi_device_update_fn)/psum[ axes=(\'batch\',)\n                                    axis_index_groups=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=347}
  %fusion.366 = f32[4096]{0} fusion(f32[4096]{0} %parameter.151, f32[4096]{0} %all-reduce.18168, f32[] %fusion.568), kind=kLoop, calls=%fused_computation.366, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=143}
  %fusion.365 = f32[4096]{0} fusion(f32[4096]{0} %fusion.366, f32[4096]{0} %all-reduce.18168, f32[] %parameter.162), kind=kLoop, calls=%fused_computation.365, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=145}
  %multiply.21176 = f32[4096]{0} multiply(f32[4096]{0} %fusion.365, f32[4096]{0} %fusion.365), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %reduce-window.102 = f32[128]{0} reduce-window(f32[4096]{0} %multiply.21176, f32[] %constant.1), window={size=32 stride=32}, to_apply=%primitive_computation_add__1.21178
  %reduce-window.207 = f32[4]{0} reduce-window(f32[128]{0} %reduce-window.102, f32[] %constant.1), window={size=32 stride=32}, to_apply=%primitive_computation_add__1.21178
  %fusion.364 = f32[] fusion(f32[] %parameter.160, f32[4]{0} %reduce-window.207), kind=kLoop, calls=%fused_computation.364, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %multiply.21150 = f32[4096]{0} multiply(f32[4096]{0} %parameter.107, f32[4096]{0} %parameter.107), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %reduce-window.101 = f32[128]{0} reduce-window(f32[4096]{0} %multiply.21150, f32[] %constant.1), window={size=32 stride=32}, to_apply=%primitive_computation_add__1.21152
  %reduce-window.206 = f32[4]{0} reduce-window(f32[128]{0} %reduce-window.101, f32[] %constant.1), window={size=32 stride=32}, to_apply=%primitive_computation_add__1.21152
  %fusion.368 = f32[] fusion(f32[4]{0} %reduce-window.206), kind=kLoop, calls=%fused_computation.368, metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %fusion.363 = f32[4096]{0} fusion(f32[4096]{0} %fusion.365, f32[] %fusion.364, f32[] %parameter.164, f32[] %fusion.368, f32[] %parameter.163, /*index=5*/f32[4096]{0} %parameter.107, f32[] %parameter.166, f32[] %fusion.647, s32[] %parameter.165), kind=kLoop, calls=%fused_computation.363, metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  %get-tuple-element.25434 = f32[2048,4096]{1,0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %while.202), index=15, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=14\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %all-reduce.18173 = f32[2048,4096]{1,0} all-reduce(f32[2048,4096]{1,0} %get-tuple-element.25434), replica_groups={{0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15}}, to_apply=%primitive_computation_add__1.18169, metadata={op_type="psum" op_name="pmap(_multi_device_update_fn)/psum[ axes=(\'batch\',)\n                                    axis_index_groups=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=347}
  %call.138 = f32[2048,4096]{1,0} call(f32[2048,4096]{1,0} %all-reduce.18173), to_apply=%parallel_fusion.361
  %call.96 = f32[64,4096]{1,0} call(f32[2048,4096]{1,0} %call.138, f32[] %constant.1), to_apply=%parallel_reduce-window.106
  %reduce-window.211 = f32[2,4096]{1,0} reduce-window(f32[64,4096]{1,0} %call.96, f32[] %constant.1), window={size=32x1 stride=32x1}, to_apply=%primitive_computation_add__1.21260
  %reduce.234 = f32[4096]{0} reduce(f32[2,4096]{1,0} %reduce-window.211, f32[] %constant.1), dimensions={0}, to_apply=%primitive_computation_add__1.21260, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
  %parameter.153 = f32[4096]{0} parameter(71), parameter_replication={false}
  %fusion.358 = f32[4096]{0} fusion(f32[4096]{0} %reduce.234, f32[4096]{0} %parameter.153, f32[] %fusion.568), kind=kLoop, calls=%fused_computation.358, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
  %fusion.357 = f32[4096]{0} fusion(f32[4096]{0} %fusion.358, f32[] %parameter.162), kind=kLoop, calls=%fused_computation.357, metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
  %call.95 = f32[2048,128]{1,0} call(f32[2048,4096]{1,0} %call.138, f32[] %constant.1), to_apply=%parallel_reduce-window.104
  %reduce-window.209 = f32[2048,4]{1,0} reduce-window(f32[2048,128]{1,0} %call.95, f32[] %constant.1), window={size=1x32 stride=1x32}, to_apply=%primitive_computation_add__1.21246
  %parameter.152 = f32[2048]{0} parameter(70), parameter_replication={false}
  %fusion.360 = f32[2048]{0} fusion(f32[2048,4]{1,0} %reduce-window.209, f32[2048]{0} %parameter.152, f32[] %fusion.568), kind=kLoop, calls=%fused_computation.360, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=131}
  %reduce-window.105 = f32[64]{0} reduce-window(f32[2048]{0} %fusion.360, f32[] %constant.1), window={size=32 stride=32}, to_apply=%primitive_computation_add__1.21272
  %reduce-window.210 = f32[2]{0} reduce-window(f32[64]{0} %reduce-window.105, f32[] %constant.1), window={size=32 stride=32}, to_apply=%primitive_computation_add__1.21272
  %reduce.233 = f32[] reduce(f32[2]{0} %reduce-window.210, f32[] %constant.1), dimensions={0}, to_apply=%primitive_computation_add__1.21272, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=135}
  %fusion.359 = f32[2048]{0} fusion(f32[2048]{0} %fusion.360, f32[] %reduce.233, f32[] %parameter.162), kind=kLoop, calls=%fused_computation.359, metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  %call.137 = f32[2048,4096]{1,0} call(f32[4096]{0} %fusion.357, f32[2048,4096]{1,0} %all-reduce.18173, f32[2048]{0} %fusion.359), to_apply=%parallel_fusion.356
  %reduce-window.107 = f32[64,128]{1,0} reduce-window(f32[2048,4096]{1,0} %call.137, f32[] %constant.1), window={size=32x32 stride=32x32}, to_apply=%primitive_computation_add__1.21304
  %reduce-window.212 = f32[2,4]{1,0} reduce-window(f32[64,128]{1,0} %reduce-window.107, f32[] %constant.1), window={size=32x32 stride=32x32}, to_apply=%primitive_computation_add__1.21304
  %fusion.355 = f32[] fusion(f32[] %parameter.160, f32[2,4]{1,0} %reduce-window.212), kind=kLoop, calls=%fused_computation.355, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %call.75 = f32[2048,4096]{1,0} call(f32[2048,4096]{1,0} %parameter.108), to_apply=%parallel_multiply.21228
  %reduce-window.103 = f32[64,128]{1,0} reduce-window(f32[2048,4096]{1,0} %call.75, f32[] %constant.1), window={size=32x32 stride=32x32}, to_apply=%primitive_computation_add__1.21230
  %reduce-window.208 = f32[2,4]{1,0} reduce-window(f32[64,128]{1,0} %reduce-window.103, f32[] %constant.1), window={size=32x32 stride=32x32}, to_apply=%primitive_computation_add__1.21230
  %fusion.362 = f32[] fusion(f32[2,4]{1,0} %reduce-window.208), kind=kLoop, calls=%fused_computation.362, metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %call.136 = f32[2048,4096]{1,0} call(f32[] %fusion.355, f32[4096]{0} %fusion.357, f32[2048,4096]{1,0} %all-reduce.18173, f32[2048]{0} %fusion.359, f32[] %parameter.164, /*index=5*/f32[] %fusion.362, f32[] %parameter.163, f32[2048,4096]{1,0} %parameter.108, f32[] %parameter.166, f32[] %fusion.647, /*index=10*/s32[] %parameter.165), to_apply=%parallel_fusion.354
  %parameter.154 = f32[4096]{0} parameter(72), parameter_replication={false}
  %get-tuple-element.25435 = f32[4096]{0} get-tuple-element((f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,2048]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=5*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, /*index=10*/f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[64,8,1024]{2,1,0}, f32[2048,4096]{1,0}, s32[], /*index=15*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[8,2048]{1,0}, f32[64,8,1024]{2,1,0}) %while.202), index=16, metadata={op_type="while" op_name="pmap(_multi_device_update_fn)/scan/while[ body_nconsts=14\n                                          cond_nconsts=0 ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=248}
  %all-reduce.18178 = f32[4096]{0} all-reduce(f32[4096]{0} %get-tuple-element.25435), replica_groups={{0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15}}, to_apply=%primitive_computation_add__1.18174, metadata={op_type="psum" op_name="pmap(_multi_device_update_fn)/psum[ axes=(\'batch\',)\n                                    axis_index_groups=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=347}
  %fusion.351 = f32[4096]{0} fusion(f32[4096]{0} %parameter.154, f32[4096]{0} %all-reduce.18178, f32[] %fusion.568), kind=kLoop, calls=%fused_computation.351, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=143}
  %fusion.350 = f32[4096]{0} fusion(f32[4096]{0} %fusion.351, f32[4096]{0} %all-reduce.18178, f32[] %parameter.162), kind=kLoop, calls=%fused_computation.350, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=145}
  %multiply.21380 = f32[4096]{0} multiply(f32[4096]{0} %fusion.350, f32[4096]{0} %fusion.350), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %reduce-window.109 = f32[128]{0} reduce-window(f32[4096]{0} %multiply.21380, f32[] %constant.1), window={size=32 stride=32}, to_apply=%primitive_computation_add__1.21382
  %reduce-window.214 = f32[4]{0} reduce-window(f32[128]{0} %reduce-window.109, f32[] %constant.1), window={size=32 stride=32}, to_apply=%primitive_computation_add__1.21382
  %fusion.349 = f32[] fusion(f32[] %parameter.160, f32[4]{0} %reduce-window.214), kind=kLoop, calls=%fused_computation.349, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %multiply.21354 = f32[4096]{0} multiply(f32[4096]{0} %parameter.109, f32[4096]{0} %parameter.109), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %reduce-window.108 = f32[128]{0} reduce-window(f32[4096]{0} %multiply.21354, f32[] %constant.1), window={size=32 stride=32}, to_apply=%primitive_computation_add__1.21356
  %reduce-window.213 = f32[4]{0} reduce-window(f32[128]{0} %reduce-window.108, f32[] %constant.1), window={size=32 stride=32}, to_apply=%primitive_computation_add__1.21356
  %fusion.353 = f32[] fusion(f32[4]{0} %reduce-window.213), kind=kLoop, calls=%fused_computation.353, metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %fusion.348 = f32[4096]{0} fusion(f32[4096]{0} %fusion.350, f32[] %fusion.349, f32[] %parameter.164, f32[] %fusion.353, f32[] %parameter.163, /*index=5*/f32[4096]{0} %parameter.109, f32[] %parameter.166, f32[] %fusion.647, s32[] %parameter.165), kind=kLoop, calls=%fused_computation.348, metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  %call.135 = f32[256,512]{1,0} call(f32[8,64,256]{2,1,0} %call.194), to_apply=%parallel_fusion.346
  %dot.34 = f32[1024,256]{1,0} dot(f32[512,1024]{1,0} %call.200, f32[256,512]{1,0} %call.135), lhs_contracting_dims={0}, rhs_contracting_dims={1}, metadata={op_type="transpose" op_name="pmap(_multi_device_update_fn)/transpose[ permutation=(1, 0) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/core.py" source_line=96}
  %all-reduce.18183 = f32[1024,256]{1,0} all-reduce(f32[1024,256]{1,0} %dot.34), replica_groups={{0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15}}, to_apply=%primitive_computation_add__1.18179, metadata={op_type="psum" op_name="pmap(_multi_device_update_fn)/psum[ axes=(\'batch\',)\n                                    axis_index_groups=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=347}
  %call.134 = f32[1024,256]{1,0} call(f32[1024,256]{1,0} %all-reduce.18183), to_apply=%parallel_fusion.345
  %reduce-window.113 = f32[32,256]{1,0} reduce-window(f32[1024,256]{1,0} %call.134, f32[] %constant.1), window={size=32x1 stride=32x1}, to_apply=%primitive_computation_add__1.21464
  %reduce-window.216 = f32[1,256]{1,0} reduce-window(f32[32,256]{1,0} %reduce-window.113, f32[] %constant.1), window={size=32x1 stride=32x1}, to_apply=%primitive_computation_add__1.21464
  %parameter.156 = f32[256]{0} parameter(74), parameter_replication={false}
  %fusion.342 = f32[256]{0} fusion(f32[1,256]{1,0} %reduce-window.216, f32[256]{0} %parameter.156, f32[] %fusion.568), kind=kLoop, calls=%fused_computation.342, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=133}
  %fusion.341 = f32[256]{0} fusion(f32[256]{0} %fusion.342, f32[] %parameter.162), kind=kLoop, calls=%fused_computation.341, metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=137}
  %reduce-window.111 = f32[1024,8]{1,0} reduce-window(f32[1024,256]{1,0} %call.134, f32[] %constant.1), window={size=1x32 stride=1x32}, to_apply=%primitive_computation_add__1.21450
  %parameter.155 = f32[1024]{0} parameter(73), parameter_replication={false}
  %fusion.344 = f32[1024]{0} fusion(f32[1024,8]{1,0} %reduce-window.111, f32[1024]{0} %parameter.155, f32[] %fusion.568), kind=kLoop, calls=%fused_computation.344, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=131}
  %reduce-window.112 = f32[32]{0} reduce-window(f32[1024]{0} %fusion.344, f32[] %constant.1), window={size=32 stride=32}, to_apply=%primitive_computation_add__1.21476
  %reduce-window.215 = f32[1]{0} reduce-window(f32[32]{0} %reduce-window.112, f32[] %constant.1), window={size=32 stride=32}, to_apply=%primitive_computation_add__1.21476
  %fusion.343 = f32[1024]{0} fusion(f32[1024]{0} %fusion.344, f32[1]{0} %reduce-window.215, f32[] %parameter.162), kind=kLoop, calls=%fused_computation.343, metadata={op_type="pow" op_name="pmap(_multi_device_update_fn)/pow" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=136}
  %call.133 = f32[1024,256]{1,0} call(f32[256]{0} %fusion.341, f32[1024,256]{1,0} %all-reduce.18183, f32[1024]{0} %fusion.343), to_apply=%parallel_fusion.340
  %reduce-window.114 = f32[32,8]{1,0} reduce-window(f32[1024,256]{1,0} %call.133, f32[] %constant.1), window={size=32x32 stride=32x32}, to_apply=%primitive_computation_add__1.21508
  %fusion.339 = f32[] fusion(f32[] %parameter.160, f32[32,8]{1,0} %reduce-window.114), kind=kLoop, calls=%fused_computation.339, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %call.76 = f32[1024,256]{1,0} call(f32[1024,256]{1,0} %parameter.110), to_apply=%parallel_multiply.21432
  %reduce-window.110 = f32[32,8]{1,0} reduce-window(f32[1024,256]{1,0} %call.76, f32[] %constant.1), window={size=32x32 stride=32x32}, to_apply=%primitive_computation_add__1.21434
  %fusion.347 = f32[] fusion(f32[32,8]{1,0} %reduce-window.110), kind=kLoop, calls=%fused_computation.347, metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %call.132 = f32[1024,256]{1,0} call(f32[] %fusion.339, f32[256]{0} %fusion.341, f32[1024,256]{1,0} %all-reduce.18183, f32[1024]{0} %fusion.343, f32[] %parameter.164, /*index=5*/f32[] %fusion.347, f32[] %parameter.163, f32[1024,256]{1,0} %parameter.110, f32[] %parameter.166, f32[] %fusion.647, /*index=10*/s32[] %parameter.165), to_apply=%parallel_fusion.338
  %parameter.157 = f32[256]{0} parameter(75), parameter_replication={false}
  %reduce.13269 = f32[256]{0} reduce(f32[8,64,256]{2,1,0} %call.194, f32[] %constant.1), dimensions={0,1}, to_apply=%primitive_computation_add__1.13265, metadata={op_type="reduce_sum" op_name="pmap(_multi_device_update_fn)/reduce_sum[ axes=(0, 1) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/core.py" source_line=96}
  %all-reduce.18188 = f32[256]{0} all-reduce(f32[256]{0} %reduce.13269), replica_groups={{0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15}}, to_apply=%primitive_computation_add__1.18184, metadata={op_type="psum" op_name="pmap(_multi_device_update_fn)/psum[ axes=(\'batch\',)\n                                    axis_index_groups=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=347}
  %fusion.335 = f32[256]{0} fusion(f32[256]{0} %parameter.157, f32[256]{0} %all-reduce.18188, f32[] %fusion.568), kind=kLoop, calls=%fused_computation.335, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=143}
  %fusion.334 = f32[256]{0} fusion(f32[256]{0} %fusion.335, f32[256]{0} %all-reduce.18188, f32[] %parameter.162), kind=kLoop, calls=%fused_computation.334, metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=145}
  %multiply.21584 = f32[256]{0} multiply(f32[256]{0} %fusion.334, f32[256]{0} %fusion.334), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %reduce-window.116 = f32[8]{0} reduce-window(f32[256]{0} %multiply.21584, f32[] %constant.1), window={size=32 stride=32}, to_apply=%primitive_computation_add__1.21586
  %fusion.333 = f32[] fusion(f32[] %parameter.160, f32[8]{0} %reduce-window.116), kind=kLoop, calls=%fused_computation.333, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=149}
  %multiply.21558 = f32[256]{0} multiply(f32[256]{0} %parameter.111, f32[256]{0} %parameter.111), metadata={op_type="mul" op_name="pmap(_multi_device_update_fn)/mul" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %reduce-window.115 = f32[8]{0} reduce-window(f32[256]{0} %multiply.21558, f32[] %constant.1), window={size=32 stride=32}, to_apply=%primitive_computation_add__1.21560
  %fusion.337 = f32[] fusion(f32[8]{0} %reduce-window.115), kind=kLoop, calls=%fused_computation.337, metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=123}
  %fusion.332 = f32[256]{0} fusion(f32[256]{0} %fusion.334, f32[] %fusion.333, f32[] %parameter.164, f32[] %fusion.337, f32[] %parameter.163, /*index=5*/f32[256]{0} %parameter.111, f32[] %parameter.166, f32[] %fusion.647, s32[] %parameter.165), kind=kLoop, calls=%fused_computation.332, metadata={op_type="sub" op_name="pmap(_multi_device_update_fn)/sub" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/adafactor.py" source_line=160}
  %call.131 = f32[32768000]{0} call(f32[32000,1024]{1,0} %all-reduce.18043), to_apply=%parallel_fusion.331
  %dot.18312 = f32[] dot(f32[32768000]{0} %call.131, f32[32768000]{0} %call.131), lhs_contracting_dims={0}, rhs_contracting_dims={0}, metadata={op_type="dot_general" op_name="pmap(_multi_device_update_fn)/dot_general[ dimension_numbers=(((0,), (0,)), ((), ()))\n                                           precision=None\n                                           preferred_element_type=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %call.130 = f32[8388608]{0} call(f32[2048,4096]{1,0} %all-reduce.18048), to_apply=%parallel_fusion.330
  %fusion.329 = f32[] fusion(f32[] %dot.18312, f32[8388608]{0} %call.130), kind=kOutput, calls=%fused_computation.329, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %fusion.549 = f32[4096]{0} fusion(f32[4096]{0} %all-reduce.18053), kind=kLoop, calls=%fused_computation.549, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=200}
  %fusion.328 = f32[] fusion(f32[] %fusion.329, f32[4096]{0} %fusion.549), kind=kOutput, calls=%fused_computation.328, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %call.129 = f32[8388608]{0} call(f32[2048,4096]{1,0} %all-reduce.18058), to_apply=%parallel_fusion.327
  %fusion.326 = f32[] fusion(f32[] %fusion.328, f32[8388608]{0} %call.129), kind=kOutput, calls=%fused_computation.326, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %fusion.534 = f32[4096]{0} fusion(f32[4096]{0} %all-reduce.18063), kind=kLoop, calls=%fused_computation.534, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=200}
  %fusion.325 = f32[] fusion(f32[] %fusion.326, f32[4096]{0} %fusion.534), kind=kOutput, calls=%fused_computation.325, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %call.128 = f32[8388608]{0} call(f32[2048,4096]{1,0} %all-reduce.18068), to_apply=%parallel_fusion.324
  %fusion.323 = f32[] fusion(f32[] %fusion.325, f32[8388608]{0} %call.128), kind=kOutput, calls=%fused_computation.323, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %fusion.519 = f32[4096]{0} fusion(f32[4096]{0} %all-reduce.18073), kind=kLoop, calls=%fused_computation.519, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=200}
  %fusion.322 = f32[] fusion(f32[] %fusion.323, f32[4096]{0} %fusion.519), kind=kOutput, calls=%fused_computation.322, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %call.127 = f32[8388608]{0} call(f32[2048,4096]{1,0} %all-reduce.18078), to_apply=%parallel_fusion.321
  %fusion.320 = f32[] fusion(f32[] %fusion.322, f32[8388608]{0} %call.127), kind=kOutput, calls=%fused_computation.320, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %fusion.504 = f32[4096]{0} fusion(f32[4096]{0} %all-reduce.18083), kind=kLoop, calls=%fused_computation.504, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=200}
  %fusion.319 = f32[] fusion(f32[] %fusion.320, f32[4096]{0} %fusion.504), kind=kOutput, calls=%fused_computation.319, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %call.126 = f32[262144]{0} call(f32[256,1024]{1,0} %all-reduce.18088), to_apply=%parallel_fusion.318
  %fusion.317 = f32[] fusion(f32[] %fusion.319, f32[262144]{0} %call.126), kind=kOutput, calls=%fused_computation.317, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %call.125 = f32[8388608]{0} call(f32[2048,4096]{1,0} %all-reduce.18093), to_apply=%parallel_fusion.316
  %fusion.315 = f32[] fusion(f32[] %fusion.317, f32[8388608]{0} %call.125), kind=kOutput, calls=%fused_computation.315, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %fusion.476 = f32[4096]{0} fusion(f32[4096]{0} %all-reduce.18098), kind=kLoop, calls=%fused_computation.476, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=200}
  %fusion.314 = f32[] fusion(f32[] %fusion.315, f32[4096]{0} %fusion.476), kind=kOutput, calls=%fused_computation.314, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %call.124 = f32[1048576]{0} call(f32[1024,1024]{1,0} %all-reduce.18103), to_apply=%parallel_fusion.313
  %fusion.312 = f32[] fusion(f32[] %fusion.314, f32[1048576]{0} %call.124), kind=kOutput, calls=%fused_computation.312, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %fusion.460 = f32[1024]{0} fusion(f32[1024]{0} %all-reduce.18108), kind=kLoop, calls=%fused_computation.460, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=200}
  %fusion.311 = f32[] fusion(f32[] %fusion.312, f32[1024]{0} %fusion.460), kind=kOutput, calls=%fused_computation.311, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %call.123 = f32[1048576]{0} call(f32[1024,1024]{1,0} %all-reduce.18113), to_apply=%parallel_fusion.310
  %fusion.309 = f32[] fusion(f32[] %fusion.311, f32[1048576]{0} %call.123), kind=kOutput, calls=%fused_computation.309, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %fusion.444 = f32[1024]{0} fusion(f32[1024]{0} %all-reduce.18118), kind=kLoop, calls=%fused_computation.444, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=200}
  %fusion.308 = f32[] fusion(f32[] %fusion.309, f32[1024]{0} %fusion.444), kind=kOutput, calls=%fused_computation.308, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %call.122 = f32[1048576]{0} call(f32[1024,1024]{1,0} %all-reduce.18123), to_apply=%parallel_fusion.307
  %fusion.306 = f32[] fusion(f32[] %fusion.308, f32[1048576]{0} %call.122), kind=kOutput, calls=%fused_computation.306, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %fusion.428 = f32[1024]{0} fusion(f32[1024]{0} %all-reduce.18128), kind=kLoop, calls=%fused_computation.428, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=200}
  %fusion.305 = f32[] fusion(f32[] %fusion.306, f32[1024]{0} %fusion.428), kind=kOutput, calls=%fused_computation.305, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %call.121 = f32[1048576]{0} call(f32[1024,1024]{1,0} %all-reduce.18133), to_apply=%parallel_fusion.304
  %fusion.303 = f32[] fusion(f32[] %fusion.305, f32[1048576]{0} %call.121), kind=kOutput, calls=%fused_computation.303, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %fusion.412 = f32[1024]{0} fusion(f32[1024]{0} %all-reduce.18138), kind=kLoop, calls=%fused_computation.412, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=200}
  %fusion.302 = f32[] fusion(f32[] %fusion.303, f32[1024]{0} %fusion.412), kind=kOutput, calls=%fused_computation.302, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %call.120 = f32[8388608]{0} call(f32[2048,4096]{1,0} %all-reduce.18143), to_apply=%parallel_fusion.301
  %fusion.300 = f32[] fusion(f32[] %fusion.302, f32[8388608]{0} %call.120), kind=kOutput, calls=%fused_computation.300, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %fusion.397 = f32[4096]{0} fusion(f32[4096]{0} %all-reduce.18148), kind=kLoop, calls=%fused_computation.397, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=200}
  %fusion.299 = f32[] fusion(f32[] %fusion.300, f32[4096]{0} %fusion.397), kind=kOutput, calls=%fused_computation.299, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %call.119 = f32[8388608]{0} call(f32[2048,4096]{1,0} %all-reduce.18153), to_apply=%parallel_fusion.298
  %fusion.297 = f32[] fusion(f32[] %fusion.299, f32[8388608]{0} %call.119), kind=kOutput, calls=%fused_computation.297, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %fusion.382 = f32[4096]{0} fusion(f32[4096]{0} %all-reduce.18158), kind=kLoop, calls=%fused_computation.382, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=200}
  %fusion.296 = f32[] fusion(f32[] %fusion.297, f32[4096]{0} %fusion.382), kind=kOutput, calls=%fused_computation.296, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %call.118 = f32[8388608]{0} call(f32[2048,4096]{1,0} %all-reduce.18163), to_apply=%parallel_fusion.295
  %fusion.294 = f32[] fusion(f32[] %fusion.296, f32[8388608]{0} %call.118), kind=kOutput, calls=%fused_computation.294, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %fusion.367 = f32[4096]{0} fusion(f32[4096]{0} %all-reduce.18168), kind=kLoop, calls=%fused_computation.367, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=200}
  %fusion.293 = f32[] fusion(f32[] %fusion.294, f32[4096]{0} %fusion.367), kind=kOutput, calls=%fused_computation.293, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %call.117 = f32[8388608]{0} call(f32[2048,4096]{1,0} %all-reduce.18173), to_apply=%parallel_fusion.292
  %fusion.291 = f32[] fusion(f32[] %fusion.293, f32[8388608]{0} %call.117), kind=kOutput, calls=%fused_computation.291, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %fusion.352 = f32[4096]{0} fusion(f32[4096]{0} %all-reduce.18178), kind=kLoop, calls=%fused_computation.352, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=200}
  %fusion.290 = f32[] fusion(f32[] %fusion.291, f32[4096]{0} %fusion.352), kind=kOutput, calls=%fused_computation.290, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %call.116 = f32[262144]{0} call(f32[1024,256]{1,0} %all-reduce.18183), to_apply=%parallel_fusion.289
  %fusion.288 = f32[] fusion(f32[] %fusion.290, f32[262144]{0} %call.116), kind=kOutput, calls=%fused_computation.288, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %fusion.336 = f32[256]{0} fusion(f32[256]{0} %all-reduce.18188), kind=kLoop, calls=%fused_computation.336, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/trainer.py" source_line=200}
  %fusion.287 = f32[] fusion(f32[] %fusion.288, f32[256]{0} %fusion.336), kind=kOutput, calls=%fused_computation.287, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %sqrt.18403 = f32[] sqrt(f32[] %fusion.287), metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %log.2 = f32[8,64]{1,0} log(f32[8,64]{1,0} %reduce.8), metadata={op_type="log" op_name="pmap(_multi_device_update_fn)/log" source_file="/usr/local/lib/python3.8/dist-packages/trax/fastmath/ops.py" source_line=94}
  %call.115 = f32[8,64,256]{2,1,0} call(f32[8,64,1]{2,1,0} %fusion.584, f32[8,64]{1,0} %log.2, f32[8,64,1]{2,1,0} %fusion.587, f32[8,64]{1,0} %log.1, f32[256]{0} %parameter.111, /*index=5*/f32[512,256]{1,0} %dot.6, s32[8,64]{1,0} %parameter.168), to_apply=%parallel_fusion.286
  %reduce-window.117 = f32[8,64,8]{2,1,0} reduce-window(f32[8,64,256]{2,1,0} %call.115, f32[] %constant.1), window={size=1x1x32 stride=1x1x32}, to_apply=%primitive_computation_add__1.13186
  %fusion.285 = f32[] fusion(f32[8,64]{1,0} %parameter.169, f32[8,64,8]{2,1,0} %reduce-window.117, f32[] %all-reduce.13211), kind=kLoop, calls=%fused_computation.285, metadata={op_type="div" op_name="pmap(_multi_device_update_fn)/div" source_file="/usr/local/lib/python3.8/dist-packages/trax/layers/metrics.py" source_line=617}
  %bitcast.15 = f32[32768000]{0} bitcast(f32[32000,1024]{1,0} %parameter.82), metadata={op_type="reshape" op_name="pmap(_multi_device_update_fn)/reshape[ dimensions=None\n                                       new_sizes=(32768000,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %dot.18406 = f32[] dot(f32[32768000]{0} %bitcast.15, f32[32768000]{0} %bitcast.15), lhs_contracting_dims={0}, rhs_contracting_dims={0}, metadata={op_type="dot_general" op_name="pmap(_multi_device_update_fn)/dot_general[ dimension_numbers=(((0,), (0,)), ((), ()))\n                                           precision=None\n                                           preferred_element_type=None ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %bitcast.16 = f32[8388608]{0} bitcast(f32[2048,4096]{1,0} %parameter.83), metadata={op_type="reshape" op_name="pmap(_multi_device_update_fn)/reshape[ dimensions=None\n                                       new_sizes=(8388608,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %fusion.284 = f32[] fusion(f32[] %dot.18406, f32[8388608]{0} %bitcast.16), kind=kOutput, calls=%fused_computation.284, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %fusion.283 = f32[] fusion(f32[] %fusion.284, f32[4096]{0} %parameter.84), kind=kOutput, calls=%fused_computation.283, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %bitcast.17 = f32[8388608]{0} bitcast(f32[2048,4096]{1,0} %parameter.85), metadata={op_type="reshape" op_name="pmap(_multi_device_update_fn)/reshape[ dimensions=None\n                                       new_sizes=(8388608,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %fusion.282 = f32[] fusion(f32[] %fusion.283, f32[8388608]{0} %bitcast.17), kind=kOutput, calls=%fused_computation.282, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %fusion.281 = f32[] fusion(f32[] %fusion.282, f32[4096]{0} %parameter.86), kind=kOutput, calls=%fused_computation.281, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %bitcast.18 = f32[8388608]{0} bitcast(f32[2048,4096]{1,0} %parameter.87), metadata={op_type="reshape" op_name="pmap(_multi_device_update_fn)/reshape[ dimensions=None\n                                       new_sizes=(8388608,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %fusion.280 = f32[] fusion(f32[] %fusion.281, f32[8388608]{0} %bitcast.18), kind=kOutput, calls=%fused_computation.280, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %fusion.279 = f32[] fusion(f32[] %fusion.280, f32[4096]{0} %parameter.88), kind=kOutput, calls=%fused_computation.279, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %bitcast.19 = f32[8388608]{0} bitcast(f32[2048,4096]{1,0} %parameter.89), metadata={op_type="reshape" op_name="pmap(_multi_device_update_fn)/reshape[ dimensions=None\n                                       new_sizes=(8388608,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %fusion.278 = f32[] fusion(f32[] %fusion.279, f32[8388608]{0} %bitcast.19), kind=kOutput, calls=%fused_computation.278, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %fusion.277 = f32[] fusion(f32[] %fusion.278, f32[4096]{0} %parameter.90), kind=kOutput, calls=%fused_computation.277, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %bitcast.20 = f32[262144]{0} bitcast(f32[256,1024]{1,0} %parameter.91), metadata={op_type="reshape" op_name="pmap(_multi_device_update_fn)/reshape[ dimensions=None\n                                       new_sizes=(262144,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %fusion.276 = f32[] fusion(f32[] %fusion.277, f32[262144]{0} %bitcast.20), kind=kOutput, calls=%fused_computation.276, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %bitcast.21 = f32[8388608]{0} bitcast(f32[2048,4096]{1,0} %parameter.92), metadata={op_type="reshape" op_name="pmap(_multi_device_update_fn)/reshape[ dimensions=None\n                                       new_sizes=(8388608,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %fusion.275 = f32[] fusion(f32[] %fusion.276, f32[8388608]{0} %bitcast.21), kind=kOutput, calls=%fused_computation.275, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %fusion.274 = f32[] fusion(f32[] %fusion.275, f32[4096]{0} %parameter.93), kind=kOutput, calls=%fused_computation.274, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %bitcast.22 = f32[1048576]{0} bitcast(f32[1024,1024]{1,0} %parameter.94), metadata={op_type="reshape" op_name="pmap(_multi_device_update_fn)/reshape[ dimensions=None\n                                       new_sizes=(1048576,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %fusion.273 = f32[] fusion(f32[] %fusion.274, f32[1048576]{0} %bitcast.22), kind=kOutput, calls=%fused_computation.273, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %fusion.272 = f32[] fusion(f32[] %fusion.273, f32[1024]{0} %parameter.95), kind=kOutput, calls=%fused_computation.272, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %bitcast.23 = f32[1048576]{0} bitcast(f32[1024,1024]{1,0} %parameter.96), metadata={op_type="reshape" op_name="pmap(_multi_device_update_fn)/reshape[ dimensions=None\n                                       new_sizes=(1048576,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %fusion.271 = f32[] fusion(f32[] %fusion.272, f32[1048576]{0} %bitcast.23), kind=kOutput, calls=%fused_computation.271, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %fusion.270 = f32[] fusion(f32[] %fusion.271, f32[1024]{0} %parameter.97), kind=kOutput, calls=%fused_computation.270, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %bitcast.24 = f32[1048576]{0} bitcast(f32[1024,1024]{1,0} %parameter.98), metadata={op_type="reshape" op_name="pmap(_multi_device_update_fn)/reshape[ dimensions=None\n                                       new_sizes=(1048576,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %fusion.269 = f32[] fusion(f32[] %fusion.270, f32[1048576]{0} %bitcast.24), kind=kOutput, calls=%fused_computation.269, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %fusion.268 = f32[] fusion(f32[] %fusion.269, f32[1024]{0} %parameter.99), kind=kOutput, calls=%fused_computation.268, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %bitcast.25 = f32[1048576]{0} bitcast(f32[1024,1024]{1,0} %parameter.100), metadata={op_type="reshape" op_name="pmap(_multi_device_update_fn)/reshape[ dimensions=None\n                                       new_sizes=(1048576,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %fusion.267 = f32[] fusion(f32[] %fusion.268, f32[1048576]{0} %bitcast.25), kind=kOutput, calls=%fused_computation.267, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %fusion.266 = f32[] fusion(f32[] %fusion.267, f32[1024]{0} %parameter.101), kind=kOutput, calls=%fused_computation.266, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %bitcast.26 = f32[8388608]{0} bitcast(f32[2048,4096]{1,0} %parameter.102), metadata={op_type="reshape" op_name="pmap(_multi_device_update_fn)/reshape[ dimensions=None\n                                       new_sizes=(8388608,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %fusion.265 = f32[] fusion(f32[] %fusion.266, f32[8388608]{0} %bitcast.26), kind=kOutput, calls=%fused_computation.265, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %fusion.264 = f32[] fusion(f32[] %fusion.265, f32[4096]{0} %parameter.103), kind=kOutput, calls=%fused_computation.264, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %bitcast.27 = f32[8388608]{0} bitcast(f32[2048,4096]{1,0} %parameter.104), metadata={op_type="reshape" op_name="pmap(_multi_device_update_fn)/reshape[ dimensions=None\n                                       new_sizes=(8388608,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %fusion.263 = f32[] fusion(f32[] %fusion.264, f32[8388608]{0} %bitcast.27), kind=kOutput, calls=%fused_computation.263, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %fusion.262 = f32[] fusion(f32[] %fusion.263, f32[4096]{0} %parameter.105), kind=kOutput, calls=%fused_computation.262, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %bitcast.28 = f32[8388608]{0} bitcast(f32[2048,4096]{1,0} %parameter.106), metadata={op_type="reshape" op_name="pmap(_multi_device_update_fn)/reshape[ dimensions=None\n                                       new_sizes=(8388608,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %fusion.261 = f32[] fusion(f32[] %fusion.262, f32[8388608]{0} %bitcast.28), kind=kOutput, calls=%fused_computation.261, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %fusion.260 = f32[] fusion(f32[] %fusion.261, f32[4096]{0} %parameter.107), kind=kOutput, calls=%fused_computation.260, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %bitcast.29 = f32[8388608]{0} bitcast(f32[2048,4096]{1,0} %parameter.108), metadata={op_type="reshape" op_name="pmap(_multi_device_update_fn)/reshape[ dimensions=None\n                                       new_sizes=(8388608,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %fusion.259 = f32[] fusion(f32[] %fusion.260, f32[8388608]{0} %bitcast.29), kind=kOutput, calls=%fused_computation.259, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %fusion.258 = f32[] fusion(f32[] %fusion.259, f32[4096]{0} %parameter.109), kind=kOutput, calls=%fused_computation.258, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %bitcast.30 = f32[262144]{0} bitcast(f32[1024,256]{1,0} %parameter.110), metadata={op_type="reshape" op_name="pmap(_multi_device_update_fn)/reshape[ dimensions=None\n                                       new_sizes=(262144,) ]" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %fusion.257 = f32[] fusion(f32[] %fusion.258, f32[262144]{0} %bitcast.30), kind=kOutput, calls=%fused_computation.257, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %fusion.256 = f32[] fusion(f32[] %fusion.257, f32[256]{0} %parameter.111), kind=kOutput, calls=%fused_computation.256, metadata={op_type="add" op_name="pmap(_multi_device_update_fn)/add" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  %sqrt.18497 = f32[] sqrt(f32[] %fusion.256), metadata={op_type="sqrt" op_name="pmap(_multi_device_update_fn)/sqrt" source_file="/usr/local/lib/python3.8/dist-packages/trax/optimizers/base.py" source_line=183}
  ROOT %tuple.21606 = (f32[32000,1024]{1,0}, f32[2048,4096]{1,0}, f32[4096]{0}, f32[2048,4096]{1,0}, f32[4096]{0}, /*index=5*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[2048,4096]{1,0}, f32[4096]{0}, f32[256,1024]{1,0}, /*index=10*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[1024,1024]{1,0}, f32[1024]{0}, f32[1024,1024]{1,0}, /*index=15*/f32[1024]{0}, f32[1024,1024]{1,0}, f32[1024]{0}, f32[1024,1024]{1,0}, f32[1024]{0}, /*index=20*/f32[2048,4096]{1,0}, f32[4096]{0}, f32[2048,4096]{1,0}, f32[4096]{0}, f32[2048,4096]{1,0}, /*index=25*/f32[4096]{0}, f32[2048,4096]{1,0}, f32[4096]{0}, f32[1024,256]{1,0}, f32[256]{0}, /*index=30*/f32[32000]{0}, f32[1024]{0}, f32[2048]{0}, f32[4096]{0}, f32[4096]{0}, /*index=35*/f32[2048]{0}, f32[4096]{0}, f32[4096]{0}, f32[2048]{0}, f32[4096]{0}, /*index=40*/f32[4096]{0}, f32[2048]{0}, f32[4096]{0}, f32[4096]{0}, f32[256]{0}, /*index=45*/f32[1024]{0}, f32[2048]{0}, f32[4096]{0}, f32[4096]{0}, f32[1024]{0}, /*index=50*/f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, /*index=55*/f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, f32[1024]{0}, /*index=60*/f32[1024]{0}, f32[2048]{0}, f32[4096]{0}, f32[4096]{0}, f32[2048]{0}, /*index=65*/f32[4096]{0}, f32[4096]{0}, f32[2048]{0}, f32[4096]{0}, f32[4096]{0}, /*index=70*/f32[2048]{0}, f32[4096]{0}, f32[4096]{0}, f32[1024]{0}, f32[256]{0}, /*index=75*/f32[256]{0}, f32[], f32[], f32[]) tuple(f32[32000,1024]{1,0} %call.184, f32[2048,4096]{1,0} %call.181, f32[4096]{0} %fusion.545, f32[2048,4096]{1,0} %call.178, f32[4096]{0} %fusion.530, /*index=5*/f32[2048,4096]{1,0} %call.175, f32[4096]{0} %fusion.515, f32[2048,4096]{1,0} %call.172, f32[4096]{0} %fusion.500, f32[256,1024]{1,0} %call.167, /*index=10*/f32[2048,4096]{1,0} %call.164, f32[4096]{0} %fusion.472, f32[1024,1024]{1,0} %call.160, f32[1024]{0} %fusion.456, f32[1024,1024]{1,0} %call.156, /*index=15*/f32[1024]{0} %fusion.440, f32[1024,1024]{1,0} %call.152, f32[1024]{0} %fusion.424, f32[1024,1024]{1,0} %call.148, f32[1024]{0} %fusion.408, /*index=20*/f32[2048,4096]{1,0} %call.145, f32[4096]{0} %fusion.393, f32[2048,4096]{1,0} %call.142, f32[4096]{0} %fusion.378, f32[2048,4096]{1,0} %call.139, /*index=25*/f32[4096]{0} %fusion.363, f32[2048,4096]{1,0} %call.136, f32[4096]{0} %fusion.348, f32[1024,256]{1,0} %call.132, f32[256]{0} %fusion.332, /*index=30*/f32[32000]{0} %fusion.566, f32[1024]{0} %fusion.564, f32[2048]{0} %fusion.557, f32[4096]{0} %fusion.555, f32[4096]{0} %fusion.548, /*index=35*/f32[2048]{0} %fusion.542, f32[4096]{0} %fusion.540, f32[4096]{0} %fusion.533, f32[2048]{0} %fusion.527, f32[4096]{0} %fusion.525, /*index=40*/f32[4096]{0} %fusion.518, f32[2048]{0} %fusion.512, f32[4096]{0} %fusion.510, f32[4096]{0} %fusion.503, f32[256]{0} %fusion.493, /*index=45*/f32[1024]{0} %fusion.491, f32[2048]{0} %fusion.484, f32[4096]{0} %fusion.482, f32[4096]{0} %fusion.475, f32[1024]{0} %fusion.468, /*index=50*/f32[1024]{0} %fusion.466, f32[1024]{0} %fusion.459, f32[1024]{0} %fusion.452, f32[1024]{0} %fusion.450, f32[1024]{0} %fusion.443, /*index=55*/f32[1024]{0} %fusion.436, f32[1024]{0} %fusion.434, f32[1024]{0} %fusion.427, f32[1024]{0} %fusion.420, f32[1024]{0} %fusion.418, /*index=60*/f32[1024]{0} %fusion.411, f32[2048]{0} %fusion.405, f32[4096]{0} %fusion.403, f32[4096]{0} %fusion.396, f32[2048]{0} %fusion.390, /*index=65*/f32[4096]{0} %fusion.388, f32[4096]{0} %fusion.381, f32[2048]{0} %fusion.375, f32[4096]{0} %fusion.373, f32[4096]{0} %fusion.366, /*index=70*/f32[2048]{0} %fusion.360, f32[4096]{0} %fusion.358, f32[4096]{0} %fusion.351, f32[1024]{0} %fusion.344, f32[256]{0} %fusion.342, /*index=75*/f32[256]{0} %fusion.335, f32[] %sqrt.18403, f32[] %fusion.285, f32[] %sqrt.18497)
}

